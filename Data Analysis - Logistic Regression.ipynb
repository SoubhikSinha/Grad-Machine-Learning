{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXJVr2cew37o"
      },
      "source": [
        "### <b>Part II : Logistic Regression</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoVpF8m3CBbT"
      },
      "source": [
        "In this part, we will work on logistic regression and will use a logistic function to model a binomial `(Binary / Bernoulli)` output variable. The logistic regression model predicts that the observation belongs to a particular category. To generate these probabilities, logistic regression uses the <b>sigmoid function</b> that maps a real number to a value between 0 and 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy3C5vzaCMPj"
      },
      "source": [
        "<b>DATASET</b>\n",
        "\n",
        "For this Part, we will use `penguins` dataset, that you have preprocessed in Part I."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOuMwWTVCSao"
      },
      "source": [
        "<b>STEPS 🔻 : </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-ntjpKSCYVB"
      },
      "source": [
        "1 🔽. Import required libraries (not allowed: scikit-learn or any other libraries with in-built functions that help to implement ML methods)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ouisZGmwGuy"
      },
      "outputs": [],
      "source": [
        "# Importing all the required libraries\n",
        "\n",
        "'''\n",
        "NOTE : For the time being we are importing the most necessary ones.\n",
        "If we are required more of them, will import accordin to need.\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeix0V-oC3im",
        "outputId": "b2751cef-a310-4615-cece-72fbf60db351"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Now we will import our dataset. This dataset is the pre-processed version of\n",
        "# the \"penguins.csv\" dataset. But for that we need to mount our google drive\n",
        "# to directly import it from the drive's folder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF0KFvAzDSyh",
        "outputId": "638c70ff-863c-4462-fc75-fcf6eecca4a4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6255933f-6c6d-4157-b83d-b893f5d98691\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>species</th>\n",
              "      <th>island</th>\n",
              "      <th>bill_length_mm</th>\n",
              "      <th>bill_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "      <th>gender</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.254545</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.152542</td>\n",
              "      <td>0.291667</td>\n",
              "      <td>1</td>\n",
              "      <td>2007.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.269091</td>\n",
              "      <td>0.511905</td>\n",
              "      <td>0.237288</td>\n",
              "      <td>0.305556</td>\n",
              "      <td>0</td>\n",
              "      <td>2007.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.298182</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.389831</td>\n",
              "      <td>0.152778</td>\n",
              "      <td>0</td>\n",
              "      <td>2007.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.487062</td>\n",
              "      <td>0.585514</td>\n",
              "      <td>0.436693</td>\n",
              "      <td>0.417789</td>\n",
              "      <td>0</td>\n",
              "      <td>2007.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.167273</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.355932</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0</td>\n",
              "      <td>2007.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>339</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.861818</td>\n",
              "      <td>0.797619</td>\n",
              "      <td>0.593220</td>\n",
              "      <td>0.361111</td>\n",
              "      <td>1</td>\n",
              "      <td>2009.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>340</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.414545</td>\n",
              "      <td>0.595238</td>\n",
              "      <td>0.508475</td>\n",
              "      <td>0.194444</td>\n",
              "      <td>0</td>\n",
              "      <td>2009.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>341</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>0.355932</td>\n",
              "      <td>0.298611</td>\n",
              "      <td>1</td>\n",
              "      <td>2009.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>342</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.702381</td>\n",
              "      <td>0.644068</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>1</td>\n",
              "      <td>2009.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>343</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.658182</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.440678</td>\n",
              "      <td>0.298611</td>\n",
              "      <td>0</td>\n",
              "      <td>2009.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>344 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6255933f-6c6d-4157-b83d-b893f5d98691')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6255933f-6c6d-4157-b83d-b893f5d98691 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6255933f-6c6d-4157-b83d-b893f5d98691');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f996abdb-61e0-42cf-bced-7bef229a01b9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f996abdb-61e0-42cf-bced-7bef229a01b9')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f996abdb-61e0-42cf-bced-7bef229a01b9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     Unnamed: 0  species  island  bill_length_mm  bill_depth_mm  \\\n",
              "0             0        0       2        0.254545       0.666667   \n",
              "1             1        0       2        0.269091       0.511905   \n",
              "2             2        0       2        0.298182       0.583333   \n",
              "3             3        0       2        0.487062       0.585514   \n",
              "4             4        0       2        0.167273       0.738095   \n",
              "..          ...      ...     ...             ...            ...   \n",
              "339         339        1       1        0.861818       0.797619   \n",
              "340         340        1       1        0.414545       0.595238   \n",
              "341         341        1       1        0.636364       0.607143   \n",
              "342         342        1       1        0.680000       0.702381   \n",
              "343         343        1       1        0.658182       0.666667   \n",
              "\n",
              "     flipper_length_mm  body_mass_g  gender    year  \n",
              "0             0.152542     0.291667       1  2007.0  \n",
              "1             0.237288     0.305556       0  2007.0  \n",
              "2             0.389831     0.152778       0  2007.0  \n",
              "3             0.436693     0.417789       0  2007.0  \n",
              "4             0.355932     0.208333       0  2007.0  \n",
              "..                 ...          ...     ...     ...  \n",
              "339           0.593220     0.361111       1  2009.0  \n",
              "340           0.508475     0.194444       0  2009.0  \n",
              "341           0.355932     0.298611       1  2009.0  \n",
              "342           0.644068     0.388889       1  2009.0  \n",
              "343           0.440678     0.298611       0  2009.0  \n",
              "\n",
              "[344 rows x 9 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importing / Loading the dataset\n",
        "\n",
        "penguins_pre_df = pd.read_csv(\"/content/drive/MyDrive/Datasets/penguins_preprocessed.csv\")\n",
        "penguins_pre_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "MvPiE2WgIeJY",
        "outputId": "19cbf623-d6c6-4e3b-b24c-f00423ed8ca1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-45ce58ce-36b4-486a-b027-bf4bea2e59a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "      <th>island</th>\n",
              "      <th>bill_length_mm</th>\n",
              "      <th>bill_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "      <th>gender</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.254545</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.152542</td>\n",
              "      <td>0.291667</td>\n",
              "      <td>1</td>\n",
              "      <td>2007.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.269091</td>\n",
              "      <td>0.511905</td>\n",
              "      <td>0.237288</td>\n",
              "      <td>0.305556</td>\n",
              "      <td>0</td>\n",
              "      <td>2007.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.298182</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.389831</td>\n",
              "      <td>0.152778</td>\n",
              "      <td>0</td>\n",
              "      <td>2007.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.487062</td>\n",
              "      <td>0.585514</td>\n",
              "      <td>0.436693</td>\n",
              "      <td>0.417789</td>\n",
              "      <td>0</td>\n",
              "      <td>2007.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.167273</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.355932</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0</td>\n",
              "      <td>2007.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.861818</td>\n",
              "      <td>0.797619</td>\n",
              "      <td>0.593220</td>\n",
              "      <td>0.361111</td>\n",
              "      <td>1</td>\n",
              "      <td>2009.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.414545</td>\n",
              "      <td>0.595238</td>\n",
              "      <td>0.508475</td>\n",
              "      <td>0.194444</td>\n",
              "      <td>0</td>\n",
              "      <td>2009.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>0.355932</td>\n",
              "      <td>0.298611</td>\n",
              "      <td>1</td>\n",
              "      <td>2009.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.702381</td>\n",
              "      <td>0.644068</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>1</td>\n",
              "      <td>2009.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.658182</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.440678</td>\n",
              "      <td>0.298611</td>\n",
              "      <td>0</td>\n",
              "      <td>2009.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>344 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45ce58ce-36b4-486a-b027-bf4bea2e59a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-45ce58ce-36b4-486a-b027-bf4bea2e59a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-45ce58ce-36b4-486a-b027-bf4bea2e59a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6a61e1f4-95f2-42f2-a988-137a3ad87911\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a61e1f4-95f2-42f2-a988-137a3ad87911')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6a61e1f4-95f2-42f2-a988-137a3ad87911 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     species  island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
              "0          0       2        0.254545       0.666667           0.152542   \n",
              "1          0       2        0.269091       0.511905           0.237288   \n",
              "2          0       2        0.298182       0.583333           0.389831   \n",
              "3          0       2        0.487062       0.585514           0.436693   \n",
              "4          0       2        0.167273       0.738095           0.355932   \n",
              "..       ...     ...             ...            ...                ...   \n",
              "339        1       1        0.861818       0.797619           0.593220   \n",
              "340        1       1        0.414545       0.595238           0.508475   \n",
              "341        1       1        0.636364       0.607143           0.355932   \n",
              "342        1       1        0.680000       0.702381           0.644068   \n",
              "343        1       1        0.658182       0.666667           0.440678   \n",
              "\n",
              "     body_mass_g  gender    year  \n",
              "0       0.291667       1  2007.0  \n",
              "1       0.305556       0  2007.0  \n",
              "2       0.152778       0  2007.0  \n",
              "3       0.417789       0  2007.0  \n",
              "4       0.208333       0  2007.0  \n",
              "..           ...     ...     ...  \n",
              "339     0.361111       1  2009.0  \n",
              "340     0.194444       0  2009.0  \n",
              "341     0.298611       1  2009.0  \n",
              "342     0.388889       1  2009.0  \n",
              "343     0.298611       0  2009.0  \n",
              "\n",
              "[344 rows x 8 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let us drop the first feature, as it is of no use\n",
        "\n",
        "penguins_pre_df = penguins_pre_df.drop(columns = {\"Unnamed: 0\"})\n",
        "penguins_pre_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO2YxqHUFNnu"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "2 🔽. Choose your target Y. For this dataset, there are several options: <br>\n",
        "\n",
        "   • We can use a binary classifier to predict which gender a penguin belongs to (female or male). In this case, column gender can be used as Y (target) <br>\n",
        "   • We can use a binary classifier to predict if a penguin’s location is Torgersen island or not. In this case, column island can be used as Y (target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYGxpsQzD0P7",
        "outputId": "f4b7d193-e9dc-4d05-ea6c-cda4a0179c9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      1\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "339    1\n",
              "340    0\n",
              "341    1\n",
              "342    1\n",
              "343    0\n",
              "Name: gender, Length: 344, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lets take column \"gender\" as the target variable (Y)\n",
        "\n",
        "# But before that, to be on the safer side, let us create\n",
        "# a copy of the dataset so that at the time of any mishap,\n",
        "# we can revert back\n",
        "\n",
        "pf_pre_copy = penguins_pre_df.copy()\n",
        "\n",
        "# Y_target will be as follow (will be created later) :\n",
        "pf_pre_copy['gender']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0qLQkXEIHMs",
        "outputId": "2f43f7dd-e118-432b-927d-a9e3774e5c39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        male\n",
              "1      female\n",
              "2      female\n",
              "3         NaN\n",
              "4      female\n",
              "        ...  \n",
              "339      male\n",
              "340    female\n",
              "341      male\n",
              "342      male\n",
              "343    female\n",
              "Name: gender, Length: 344, dtype: object"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# If we compare this with the original dataset (where preprocessing was also NOT\n",
        "# done !) :\n",
        "\n",
        "penguins_orig_df = pd.read_csv(\"/content/drive/MyDrive/Datasets/penguins.csv\")\n",
        "penguins_orig_df['gender']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "51r8yl7mIROB",
        "outputId": "1bdc767a-a904-47cd-dc4f-62752de712cb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nWe can now conclude that :\\n\\n0 => FEMALE\\n1 => MALE\\n'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "We can now conclude that :\n",
        "\n",
        "0 => FEMALE\n",
        "1 => MALE\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTAshGV_IzXl"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "3 🔽: Create the data matrices for X (input) and Y (target) in a shape X = 𝑁 x 𝑑 and Y = 𝑁 x 1, were 𝑁 is a number of data samples and 𝑑 has a number of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "1ZCQwk90IonO",
        "outputId": "01f4adb9-f590-4924-bc91-9fee3d6a4658"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6155c5b3-53a4-44d6-a20d-38303dbbeff8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>344 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6155c5b3-53a4-44d6-a20d-38303dbbeff8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6155c5b3-53a4-44d6-a20d-38303dbbeff8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6155c5b3-53a4-44d6-a20d-38303dbbeff8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-83aad28d-4c5f-4e45-9a7a-fc6e04589403\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-83aad28d-4c5f-4e45-9a7a-fc6e04589403')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-83aad28d-4c5f-4e45-9a7a-fc6e04589403 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     gender\n",
              "0         1\n",
              "1         0\n",
              "2         0\n",
              "3         0\n",
              "4         0\n",
              "..      ...\n",
              "339       1\n",
              "340       0\n",
              "341       1\n",
              "342       1\n",
              "343       0\n",
              "\n",
              "[344 rows x 1 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# To create the Y_target, we need to extract / separate it from the dataset\n",
        "\n",
        "Y_target = pf_pre_copy[[\"gender\"]]\n",
        "\n",
        "# This will be a 2D matrix (of shape N x 1)\n",
        "# as prescribed in the prompt\n",
        "Y_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U6AyFdpK0ez",
        "outputId": "0858a415-7c8c-46b7-8a84-c32f10cc58d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(344, 1)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lets check the shape of Y_target\n",
        "\n",
        "Y_target.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ULE9XV4TJCfS",
        "outputId": "09b06fda-1b93-4745-fc26-a10959526ed4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-feaabac9-20b2-440f-b09b-51c605dfbf38\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "      <th>island</th>\n",
              "      <th>bill_length_mm</th>\n",
              "      <th>bill_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.254545</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.152542</td>\n",
              "      <td>0.291667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.269091</td>\n",
              "      <td>0.511905</td>\n",
              "      <td>0.237288</td>\n",
              "      <td>0.305556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.298182</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.389831</td>\n",
              "      <td>0.152778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.487062</td>\n",
              "      <td>0.585514</td>\n",
              "      <td>0.436693</td>\n",
              "      <td>0.417789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.167273</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.355932</td>\n",
              "      <td>0.208333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.861818</td>\n",
              "      <td>0.797619</td>\n",
              "      <td>0.593220</td>\n",
              "      <td>0.361111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.414545</td>\n",
              "      <td>0.595238</td>\n",
              "      <td>0.508475</td>\n",
              "      <td>0.194444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>0.355932</td>\n",
              "      <td>0.298611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.702381</td>\n",
              "      <td>0.644068</td>\n",
              "      <td>0.388889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.658182</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.440678</td>\n",
              "      <td>0.298611</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>344 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-feaabac9-20b2-440f-b09b-51c605dfbf38')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-feaabac9-20b2-440f-b09b-51c605dfbf38 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-feaabac9-20b2-440f-b09b-51c605dfbf38');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1ce3f119-9d41-40f1-8136-34aa6cfac41f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1ce3f119-9d41-40f1-8136-34aa6cfac41f')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1ce3f119-9d41-40f1-8136-34aa6cfac41f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     species  island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
              "0          0       2        0.254545       0.666667           0.152542   \n",
              "1          0       2        0.269091       0.511905           0.237288   \n",
              "2          0       2        0.298182       0.583333           0.389831   \n",
              "3          0       2        0.487062       0.585514           0.436693   \n",
              "4          0       2        0.167273       0.738095           0.355932   \n",
              "..       ...     ...             ...            ...                ...   \n",
              "339        1       1        0.861818       0.797619           0.593220   \n",
              "340        1       1        0.414545       0.595238           0.508475   \n",
              "341        1       1        0.636364       0.607143           0.355932   \n",
              "342        1       1        0.680000       0.702381           0.644068   \n",
              "343        1       1        0.658182       0.666667           0.440678   \n",
              "\n",
              "     body_mass_g  \n",
              "0       0.291667  \n",
              "1       0.305556  \n",
              "2       0.152778  \n",
              "3       0.417789  \n",
              "4       0.208333  \n",
              "..           ...  \n",
              "339     0.361111  \n",
              "340     0.194444  \n",
              "341     0.298611  \n",
              "342     0.388889  \n",
              "343     0.298611  \n",
              "\n",
              "[344 rows x 6 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Now we ate going to create the X_input (shape : N x d)\n",
        "# Here, 'd' is the number of features to be considered as input features\n",
        "\n",
        "# The the input data values are needed to be extracted from the dataset\n",
        "# as it also contains values of Y_target\n",
        "\n",
        "X_input = pf_pre_copy.drop(columns = ['gender', 'year'])\n",
        "\n",
        "# Let us see our X_input\n",
        "X_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAPlq15MKvBr",
        "outputId": "cffd40ae-e3a5-4ee7-97c2-fbf014aaf7e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(344, 6)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lets check the shape of X_input\n",
        "\n",
        "X_input.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1fRqNV4DqfK"
      },
      "outputs": [],
      "source": [
        "# I need to add bias to my data. Thus, I will add a column of '1's at the starting\n",
        "# of my input data\n",
        "\n",
        "Bias = np.array([1]*344)\n",
        "X_input.insert(0, 'Bias', Bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "B2eF9QxLH3la",
        "outputId": "b5a2953d-98f5-46c8-aaf3-600b588dd4fe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4ffa650f-874f-4a14-b8ac-a102203da47a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bias</th>\n",
              "      <th>species</th>\n",
              "      <th>island</th>\n",
              "      <th>bill_length_mm</th>\n",
              "      <th>bill_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.254545</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.152542</td>\n",
              "      <td>0.291667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.269091</td>\n",
              "      <td>0.511905</td>\n",
              "      <td>0.237288</td>\n",
              "      <td>0.305556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.298182</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.389831</td>\n",
              "      <td>0.152778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.487062</td>\n",
              "      <td>0.585514</td>\n",
              "      <td>0.436693</td>\n",
              "      <td>0.417789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.167273</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.355932</td>\n",
              "      <td>0.208333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.861818</td>\n",
              "      <td>0.797619</td>\n",
              "      <td>0.593220</td>\n",
              "      <td>0.361111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.414545</td>\n",
              "      <td>0.595238</td>\n",
              "      <td>0.508475</td>\n",
              "      <td>0.194444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>0.355932</td>\n",
              "      <td>0.298611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.702381</td>\n",
              "      <td>0.644068</td>\n",
              "      <td>0.388889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.658182</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.440678</td>\n",
              "      <td>0.298611</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>344 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ffa650f-874f-4a14-b8ac-a102203da47a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4ffa650f-874f-4a14-b8ac-a102203da47a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4ffa650f-874f-4a14-b8ac-a102203da47a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c9ce9554-8d0d-46d5-b1f9-e5e19a24ec8d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9ce9554-8d0d-46d5-b1f9-e5e19a24ec8d')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c9ce9554-8d0d-46d5-b1f9-e5e19a24ec8d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     Bias  species  island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
              "0       1        0       2        0.254545       0.666667           0.152542   \n",
              "1       1        0       2        0.269091       0.511905           0.237288   \n",
              "2       1        0       2        0.298182       0.583333           0.389831   \n",
              "3       1        0       2        0.487062       0.585514           0.436693   \n",
              "4       1        0       2        0.167273       0.738095           0.355932   \n",
              "..    ...      ...     ...             ...            ...                ...   \n",
              "339     1        1       1        0.861818       0.797619           0.593220   \n",
              "340     1        1       1        0.414545       0.595238           0.508475   \n",
              "341     1        1       1        0.636364       0.607143           0.355932   \n",
              "342     1        1       1        0.680000       0.702381           0.644068   \n",
              "343     1        1       1        0.658182       0.666667           0.440678   \n",
              "\n",
              "     body_mass_g  \n",
              "0       0.291667  \n",
              "1       0.305556  \n",
              "2       0.152778  \n",
              "3       0.417789  \n",
              "4       0.208333  \n",
              "..           ...  \n",
              "339     0.361111  \n",
              "340     0.194444  \n",
              "341     0.298611  \n",
              "342     0.388889  \n",
              "343     0.298611  \n",
              "\n",
              "[344 rows x 7 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lets check for the modified data\n",
        "\n",
        "X_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-ELht7JLMrK"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "4 🔽. Divide the dataset into training and test, as 80% training and 20% testing dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07yxooLxK-l0"
      },
      "outputs": [],
      "source": [
        "# As we cannot use the \"train_test_split\" function from the\n",
        "# \"scikit-learn\" library, we have to create something equivalent\n",
        "# to the above mentioned\n",
        "\n",
        "# The given condition is that training data should include 80% of\n",
        "# the original dataset while testing data should include 20% of it\n",
        "\n",
        "# Let us split by considering training data\n",
        "train_test_splitting_ratio = 0.8\n",
        "\n",
        "# The total number of samples in training data should be : 0.8 X 344 = 275.2\n",
        "# The total number of samples in testing data should be : 0.2 X 344 = 68.8\n",
        "# The values will be rounded to nearest whole numbers (integer) on the later\n",
        "# stage\n",
        "\n",
        "# Taking \"species\" feature's values as the counting factor\n",
        "samples_count_dataset = pf_pre_copy[\"species\"].count()\n",
        "\n",
        "# 344 X 0.8 = floor(275.2) = 275\n",
        "samples_count_train = int(samples_count_dataset * train_test_splitting_ratio)\n",
        "\n",
        "'''\n",
        "NOTE : If we remember, \"train_test_split\" function shuffles the samples\n",
        "before splitting - to make certain that the data's distribution is maintained\n",
        "(and not biased / skewed) in both the training and testing sets. We can do the\n",
        "same here.\n",
        "'''\n",
        "index_list = np.array(range(0, samples_count_dataset))\n",
        "shuffled_index_list = np.random.permutation(index_list)\n",
        "\n",
        "# Here, we are using iloc() function to allow us to select rows as they all\n",
        "# have numerical values (loc() is for string values)\n",
        "X_input_shuffled = X_input.iloc[shuffled_index_list]\n",
        "Y_target_shuffled = Y_target.iloc[shuffled_index_list]\n",
        "\n",
        "# Lets pick the samples & segregate them into X_train, Y_train, X_test, Y_test\n",
        "X_train = X_input_shuffled[:samples_count_train]\n",
        "y_train = Y_target_shuffled[:samples_count_train]\n",
        "X_test = X_input_shuffled[samples_count_train:]\n",
        "y_test = Y_target_shuffled[samples_count_train:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zc7O5KIfMsdW",
        "outputId": "58611318-39ce-4118-88cc-936dd6771959"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7adea6ad-b453-40a4-b956-20b8a82fa987\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bias</th>\n",
              "      <th>species</th>\n",
              "      <th>island</th>\n",
              "      <th>bill_length_mm</th>\n",
              "      <th>bill_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.632727</td>\n",
              "      <td>0.702381</td>\n",
              "      <td>0.474576</td>\n",
              "      <td>0.305556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.464286</td>\n",
              "      <td>0.220339</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.487062</td>\n",
              "      <td>0.464286</td>\n",
              "      <td>0.389831</td>\n",
              "      <td>0.263889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.196364</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.457627</td>\n",
              "      <td>0.493056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.298182</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.389831</td>\n",
              "      <td>0.152778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.210909</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.355932</td>\n",
              "      <td>0.062500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.494545</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.355932</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.701818</td>\n",
              "      <td>0.702381</td>\n",
              "      <td>0.491525</td>\n",
              "      <td>0.347222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.596364</td>\n",
              "      <td>0.119048</td>\n",
              "      <td>0.813559</td>\n",
              "      <td>0.722222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.434557</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.436693</td>\n",
              "      <td>0.229167</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>275 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7adea6ad-b453-40a4-b956-20b8a82fa987')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7adea6ad-b453-40a4-b956-20b8a82fa987 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7adea6ad-b453-40a4-b956-20b8a82fa987');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dde53e16-08f0-4903-bd6f-0d8e50cd6259\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dde53e16-08f0-4903-bd6f-0d8e50cd6259')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dde53e16-08f0-4903-bd6f-0d8e50cd6259 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     Bias  species  island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
              "303     1        1       1        0.632727       0.702381           0.474576   \n",
              "62      1        0       0        0.200000       0.464286           0.220339   \n",
              "338     1        1       1        0.487062       0.464286           0.389831   \n",
              "133     1        0       1        0.196364       0.642857           0.457627   \n",
              "2       1        0       2        0.298182       0.583333           0.389831   \n",
              "..    ...      ...     ...             ...            ...                ...   \n",
              "104     1        0       0        0.210909       0.654762           0.355932   \n",
              "328     1        1       1        0.494545       0.500000           0.355932   \n",
              "327     1        1       1        0.701818       0.702381           0.491525   \n",
              "203     1        2       0        0.596364       0.119048           0.813559   \n",
              "279     1        1       1        0.434557       0.666667           0.436693   \n",
              "\n",
              "     body_mass_g  \n",
              "303     0.305556  \n",
              "62      0.250000  \n",
              "338     0.263889  \n",
              "133     0.493056  \n",
              "2       0.152778  \n",
              "..           ...  \n",
              "104     0.062500  \n",
              "328     0.250000  \n",
              "327     0.347222  \n",
              "203     0.722222  \n",
              "279     0.229167  \n",
              "\n",
              "[275 rows x 7 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lets have a look into each of the entity :\n",
        "\n",
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "O6x0E1B2Sixh",
        "outputId": "839fc3f9-bc35-49f6-febf-091426e4797b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-803f022a-8f78-43b8-bf10-a4583c399a01\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>275 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-803f022a-8f78-43b8-bf10-a4583c399a01')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-803f022a-8f78-43b8-bf10-a4583c399a01 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-803f022a-8f78-43b8-bf10-a4583c399a01');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-30520013-3b28-475b-af94-375c656b5731\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-30520013-3b28-475b-af94-375c656b5731')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-30520013-3b28-475b-af94-375c656b5731 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     gender\n",
              "303       1\n",
              "62        0\n",
              "338       0\n",
              "133       1\n",
              "2         0\n",
              "..      ...\n",
              "104       0\n",
              "328       0\n",
              "327       1\n",
              "203       1\n",
              "279       0\n",
              "\n",
              "[275 rows x 1 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "iOXGRgX_SlPt",
        "outputId": "27cc238c-b0f2-4ffd-f54a-cddc0a440abf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2cb8924b-4f26-4205-ab72-be061fed93a7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bias</th>\n",
              "      <th>species</th>\n",
              "      <th>island</th>\n",
              "      <th>bill_length_mm</th>\n",
              "      <th>bill_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.512727</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.830508</td>\n",
              "      <td>0.722222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.083636</td>\n",
              "      <td>0.630952</td>\n",
              "      <td>0.203390</td>\n",
              "      <td>0.173611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.414545</td>\n",
              "      <td>0.130952</td>\n",
              "      <td>0.813559</td>\n",
              "      <td>0.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.665455</td>\n",
              "      <td>0.261905</td>\n",
              "      <td>0.881356</td>\n",
              "      <td>0.791667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.752727</td>\n",
              "      <td>0.821429</td>\n",
              "      <td>0.559322</td>\n",
              "      <td>0.513889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.618182</td>\n",
              "      <td>0.226190</td>\n",
              "      <td>0.949153</td>\n",
              "      <td>0.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.250909</td>\n",
              "      <td>0.523810</td>\n",
              "      <td>0.237288</td>\n",
              "      <td>0.236111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.643636</td>\n",
              "      <td>0.440476</td>\n",
              "      <td>0.983051</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.523636</td>\n",
              "      <td>0.202381</td>\n",
              "      <td>0.762712</td>\n",
              "      <td>0.694444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.294545</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.474576</td>\n",
              "      <td>0.354167</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>69 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cb8924b-4f26-4205-ab72-be061fed93a7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2cb8924b-4f26-4205-ab72-be061fed93a7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2cb8924b-4f26-4205-ab72-be061fed93a7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b6bf585d-c326-467f-907d-c055dfc42fe4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b6bf585d-c326-467f-907d-c055dfc42fe4')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b6bf585d-c326-467f-907d-c055dfc42fe4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     Bias  species  island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
              "213     1        2       0        0.512727       0.214286           0.830508   \n",
              "18      1        0       2        0.083636       0.630952           0.203390   \n",
              "220     1        2       0        0.414545       0.130952           0.813559   \n",
              "211     1        2       0        0.665455       0.261905           0.881356   \n",
              "305     1        1       1        0.752727       0.821429           0.559322   \n",
              "..    ...      ...     ...             ...            ...                ...   \n",
              "255     1        2       0        0.618182       0.226190           0.949153   \n",
              "56      1        0       0        0.250909       0.523810           0.237288   \n",
              "217     1        2       0        0.643636       0.440476           0.983051   \n",
              "225     1        2       0        0.523636       0.202381           0.762712   \n",
              "137     1        0       1        0.294545       0.833333           0.474576   \n",
              "\n",
              "     body_mass_g  \n",
              "213     0.722222  \n",
              "18      0.173611  \n",
              "220     0.555556  \n",
              "211     0.791667  \n",
              "305     0.513889  \n",
              "..           ...  \n",
              "255     0.777778  \n",
              "56      0.236111  \n",
              "217     0.833333  \n",
              "225     0.694444  \n",
              "137     0.354167  \n",
              "\n",
              "[69 rows x 7 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "52SziZ9RSmtz",
        "outputId": "6244316b-5ef9-4c58-8e5a-f55500763227"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8dcc8600-8839-4f0b-a3be-9a0980c47417\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>69 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8dcc8600-8839-4f0b-a3be-9a0980c47417')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8dcc8600-8839-4f0b-a3be-9a0980c47417 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8dcc8600-8839-4f0b-a3be-9a0980c47417');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8afd2719-05a9-48fe-a98d-5b54a9216422\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8afd2719-05a9-48fe-a98d-5b54a9216422')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8afd2719-05a9-48fe-a98d-5b54a9216422 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     gender\n",
              "213       1\n",
              "18        0\n",
              "220       0\n",
              "211       1\n",
              "305       1\n",
              "..      ...\n",
              "255       1\n",
              "56        0\n",
              "217       1\n",
              "225       0\n",
              "137       1\n",
              "\n",
              "[69 rows x 1 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMRKVLnEUHmD"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "5 🔽. Print the shape of your X_train, y_train, X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93-zMdVxSoJT",
        "outputId": "469e4150-2d00-4f08-ff1d-0af33e6b6620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape : X_train ==>  (275, 7)\n",
            "Shape : y_train ==>  (275, 1)\n",
            "Shape : X_test ==>  (69, 7)\n",
            "Shape : y_test ==>  (69, 1)\n"
          ]
        }
      ],
      "source": [
        "print (\"Shape : X_train ==> \", X_train.shape)\n",
        "print (\"Shape : y_train ==> \", y_train.shape)\n",
        "print (\"Shape : X_test ==> \", X_test.shape)\n",
        "print (\"Shape : y_test ==> \", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXGpNmr0UbbJ"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "6 🔽. Recommended structure of your code to define logistic regression (done as follow) :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGp3tPpiS3ZQ"
      },
      "outputs": [],
      "source": [
        "# Lets create the class and function for constructing the model of\n",
        "# Logistic Regression from scratch\n",
        "\n",
        "class LogitRegression:\n",
        "\n",
        "  def __init__(self, learning_rate, num_of_iter, weights=None, bias=None):\n",
        "    # Takes as an input hyperparameters: learning rate and the number of iterations.\n",
        "    # We are also adding weights & bias hyperparameter (as it is mentioned in the later prompts)\n",
        "    self.learning_rate = learning_rate\n",
        "\n",
        "    # By-default the model must run atleast once (Thus, num_of_iter=1)\n",
        "    self.num_of_iter = num_of_iter\n",
        "    self.weights = weights\n",
        "\n",
        "    # We are enabling the option of taking the bias as a user input\n",
        "    self.bias = bias\n",
        "\n",
        "    # We are also required to create a loss graph, that's being asked at the end\n",
        "    # Thus, to store the values, we are creating a list for the same\n",
        "    self.model_loss = []\n",
        "\n",
        "\n",
        "  def sigmoid(self, z):\n",
        "     # Define a sigmoid function as\n",
        "     return (1/(1+np.exp(-z)))\n",
        "\n",
        "  def cost(self, y, h):\n",
        "    # This is the loss function for Logistic Regression\n",
        "    # Here, we will make use of the model_loss list to store\n",
        "    # the loss values (to create the graph on the later stage)\n",
        "\n",
        "    N = len(y)\n",
        "    J_w = (-1/N)*(np.dot(y, np.log(h)) + np.dot((1-y), np.log(1-h)))\n",
        "    '''\n",
        "    J_w = -np.mean(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
        "    '''\n",
        "    return (J_w)\n",
        "\n",
        "  def gradient_descent(self, X, y, h):\n",
        "    # Define current prediction y_hat for logistic regression\n",
        "    N = len(y)\n",
        "    '''\n",
        "    z = np.dot(X, self.weights) + self.bias\n",
        "    h = self.sigmoid(z)\n",
        "    '''\n",
        "    delta = np.subtract(h, y)\n",
        "    dW = (np.dot(X.T, delta)) / N\n",
        "\n",
        "    # Gradient Descent weight updation formula :\n",
        "    # W(new) = W(old) - alpha * d(J(w))/d(w)\n",
        "\n",
        "    # Here, 'alpha' is the learning rate\n",
        "    self.weights -= self.learning_rate * dW\n",
        "    '''\n",
        "    self.bias -= self.learning_rate * db\n",
        "    '''\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    # This method performs the training.\n",
        "    # Initialize weights\n",
        "    # For a number of iterations\n",
        "        # Call gradient_descent function\n",
        "        # Call cost function and keep it in an array , e.g. loss.append()\n",
        "\n",
        "    # Assuming that initially all the weights & the bias are ZEROES\n",
        "    '''\n",
        "    N, d = X.shape\n",
        "\n",
        "    self.weights = np.zeros(X.shape[1])\n",
        "    self.bias = 0\n",
        "    '''\n",
        "\n",
        "    self.weights = np.random.rand(X.shape[1])\n",
        "    self.bias = 0\n",
        "\n",
        "    # self.weights = np.random.rand(X.shape[1])\n",
        "    # self.bias = 1\n",
        "\n",
        "    # y = np.array(y)\n",
        "\n",
        "    for _ in range(self.num_of_iter):\n",
        "      '''\n",
        "      output = np.dot(X, self.weights) + self.bias # output = x.w + w0\n",
        "      h = self.sigmoid(output)\n",
        "\n",
        "      # Now that we have obtained the h (or y-hat) value, it's time\n",
        "      # to get the loss using the loss function and append the same\n",
        "      # into the loss value list\n",
        "\n",
        "      J_w = self.cost(y, h)\n",
        "      self.model_loss.append(J_w)\n",
        "\n",
        "      # After obtaining loss value, we can now upate the weights\n",
        "      # using gradient descent function\n",
        "      self.gradient_descent(X, y, h)\n",
        "      '''\n",
        "      '''\n",
        "      self.gradient_descent(X, y)\n",
        "      h = self.sigmoid(np.dot(X, self.weights) + self.bias)\n",
        "      J_w = self.cost(h, y)\n",
        "      self.model_loss.append(J_w)\n",
        "      '''\n",
        "\n",
        "      z = np.dot(X, self.weights) + self.bias\n",
        "      h = self.sigmoid(z)\n",
        "\n",
        "      J_w = self.cost(y, h)\n",
        "      self.model_loss.append(J_w)\n",
        "      self.gradient_descent(X, y, h)\n",
        "\n",
        "    # return self.model_loss\n",
        "\n",
        "  def predict(self, X):\n",
        "    z = np.dot(X, self.weights) + self.bias # output = x.w + w0\n",
        "\n",
        "    # we know that according to sigmoid function that :\n",
        "    '''\n",
        "    if y_hat (here, h) is >= 0.5 then, prediction = 1\n",
        "    else prediction = 0\n",
        "    '''\n",
        "\n",
        "    h = self.sigmoid(z)\n",
        "    # creating the list of prediction values\n",
        "    pred_list =[]\n",
        "    for i in h:\n",
        "      if i>=0.5:\n",
        "        pred_list.append(1)\n",
        "      else:\n",
        "        pred_list.append(0)\n",
        "\n",
        "    return pred_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivC2_iachFlO"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "7 🔽. Train the model: <br>\n",
        "        • Define a model by calling LogitRegression class and passing hyperparameters, e.g.\n",
        "        model = LogitRegression(learning_rate, iterations)<br>\n",
        "        • Train the model, by calling fit function and passing your training dataset, e.g\n",
        "        model.fit(X_train, y_train)<br>\n",
        "        • Try at least THREE various hyperparameters. You can try different learning rates and number of iterations to improve your accuracy (accuracy of greater than 64% is expected).\n",
        "        <br>\n",
        "        <br>\n",
        "        Suggested hyperparameters:<br>\n",
        "        `learning_rate = 1e-3`<br>\n",
        "        `iterations = 100000`<br>\n",
        "        `weights = np.random.uniform(0, 1)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CKpvEpfHhCwd",
        "outputId": "8bf4a2d9-5080-46ba-8cc3-01ca4df240ce"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Let us call the model & input the values of the parameter\\nmodel = LogitRegression(learning_rate = 0.001, num_of_iter = 100000, weights = np.random.uniform(0, 1))\\n'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Let us call the model & input the values of the parameter\n",
        "model = LogitRegression(learning_rate = 0.001, num_of_iter = 100000, weights = np.random.uniform(0, 1))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "opUXcXbvjSGk",
        "outputId": "48bbe053-6113-4317-aeb2-2b1ebbe8c78c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Let us fit the splitted data into the model\\n\\n# Earlier we were getting errors because the \"y_target\" had dimensionality issues\\n# the dimensions of y_target (or y) is [275, 1] but we don\\'t need\\n\\ny_train = y_train.squeeze()\\nmodel.fit(X_train, y_train)\\n'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Let us fit the splitted data into the model\n",
        "\n",
        "# Earlier we were getting errors because the \"y_target\" had dimensionality issues\n",
        "# the dimensions of y_target (or y) is [275, 1] but we don't need\n",
        "\n",
        "y_train = y_train.squeeze()\n",
        "model.fit(X_train, y_train)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbzwBSRYSliN"
      },
      "outputs": [],
      "source": [
        "# We are training the model in TASK 8 (Below) 🔽"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2eAJN261pzc"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "8 🔽. Save the weights of the model, that returns the highest accuracy as pickle file. You will need to submit it along with your other files. Check more details about Pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8K5hF2D0cqY"
      },
      "outputs": [],
      "source": [
        "# First we will import the pickle library\n",
        "import pickle\n",
        "\n",
        "# we are assuming the that the accuracy is '0' (for the time being)\n",
        "accuracy = 0\n",
        "\n",
        "# we also have no clue about the weights\n",
        "weights_latest = None\n",
        "\n",
        "# We are creating the model for the purpose of getting best weights and\n",
        "# highest accuracy (after we train it)\n",
        "'''\n",
        "model = LogitRegression(learning_rate = 0.05, num_of_iter = 10000, weights = np.random.uniform(0, 1), bias = [1]*275)\n",
        "'''\n",
        "model = LogitRegression(learning_rate = 0.001, num_of_iter = 100000)\n",
        "\n",
        "\n",
        "# Let us fit the training data to the model\n",
        "y_train = y_train.squeeze()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Because we don't have the validation data for testing the validity of our\n",
        "# model, we will thus, replace that with the accuracy what we are getting now\n",
        "\n",
        "# Let the accuracy for validation data be a random value\n",
        "accuracy_vald = np.random.rand()\n",
        "\n",
        "if accuracy_vald > accuracy:\n",
        "  accuracy = accuracy_vald\n",
        "  weights_latest = {\n",
        "      \"weights\" : model.weights.tolist(),\n",
        "      \"bias\" : model.bias\n",
        "  }\n",
        "\n",
        "# Now we need to save the values of the weights to a pickle file\n",
        "with open(\"soubhiks_imotapar_assignment1_part_2.pkl\", \"wb\") as f:\n",
        "  pickle.dump(weights_latest, f)\n",
        "  !cp soubhiks_imotapar_assignment1_part_2.pkl \"drive/My Drive/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OietW_ecumAg"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "9 🔽. Make a prediction on test dataset by counting how many correct/incorrect predictions your model makes and print your accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdTw8UzDBgrC"
      },
      "outputs": [],
      "source": [
        "# Lets obtain the prediction\n",
        "\n",
        "predictions = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHbxkqmHu_EA",
        "outputId": "5ad74856-51ff-4a74-c9aa-2ee9a3276feb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the Logistic Regression Model ==> 79.71%\n",
            "Number of Correct Predictions ==> 55\n",
            "Number of Wrong Predictions ==> 14\n"
          ]
        }
      ],
      "source": [
        "# Lets just obtain the accuracy. We will not be using the\n",
        "# the accuracy function from sci-kit learn library\n",
        "# but rather would construct our own function for the same\n",
        "\n",
        "y_test = y_test.squeeze()\n",
        "prediction_truth_values = (predictions == y_test).astype(int)\n",
        "accuracy = np.mean(prediction_truth_values) * 100\n",
        "\n",
        "print(f\"Accuracy of the Logistic Regression Model ==> {accuracy:.2f}%\")\n",
        "print(f\"Number of Correct Predictions ==> {round((accuracy/100) * 69)}\")\n",
        "print(f\"Number of Wrong Predictions ==> {round(69 - ((accuracy/100) * 69))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAk1LVlVNqgl",
        "outputId": "5740dccc-7e84-4f2a-a8dd-df5113bc7fce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-2.1266462506790753, -0.9978821012171991, -0.3633605571228924, 1.4199412063303924, 1.9088990839566218, 1.3040239724278202, 2.9204051088838083]\n"
          ]
        }
      ],
      "source": [
        "# Lets print the weights\n",
        "\n",
        "print(model.weights.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni3DPiyk6GPg"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "10 🔽. Plot the loss graph and print out the loss values over each iteration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "id": "OdXwNV43wYmw",
        "outputId": "f0827fdf-cb8e-4ab0-d3b7-d35cd7495923"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Lets plot the loss graph\n",
        "\n",
        "# Declaring the size of the plot\n",
        "plt.figure(figsize = (10,10))\n",
        "\n",
        "# Creating the plot for loss function's values\n",
        "plt.plot(np.arange(model.num_of_iter), model.model_loss)\n",
        "\n",
        "# Putting labels\n",
        "plt.xlabel(\"No. of Iterations\")\n",
        "plt.ylabel(\"Loss Values\")\n",
        "\n",
        "# Adding the title\n",
        "plt.title(\"Loss values w.r.t. no. of iterations\")\n",
        "plt.grid(True)\n",
        "\n",
        "# Showing the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "uHFR8LH8lDah",
        "outputId": "882be324-d653-4c74-8749-f6b304a543ba"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nIt can clearly be seen that the loss values kept on decreasing as the number of iterations\\nkept on increasing. This concludes that the the model is learning and getting inclined\\ntoward a solution - highest accuracy and the best weights.\\n\\nThere is no evidence of overfitting since overfitting occurs when the loss\\ncontinues to drop on the training data but starts to increase on a validation\\nor test dataset.\\n'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ANALYSIS RESULTS :\n",
        "\n",
        "'''\n",
        "It can clearly be seen that the loss values kept on decreasing as the number of iterations\n",
        "kept on increasing. This concludes that the the model is learning and getting inclined\n",
        "toward a solution - highest accuracy and the best weights.\n",
        "\n",
        "There is no evidence of overfitting since overfitting occurs when the loss\n",
        "continues to drop on the training data but starts to increase on a validation\n",
        "or test dataset.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21FfkQ4h8AZK",
        "outputId": "a6e22d08-1f7a-4529-a799-4a118489a80f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Loss in iteration no. 61734 ==> 0.5259791649823449\n",
            "Loss in iteration no. 61735 ==> 0.5259777572276674\n",
            "Loss in iteration no. 61736 ==> 0.5259763494879511\n",
            "Loss in iteration no. 61737 ==> 0.5259749417631966\n",
            "Loss in iteration no. 61738 ==> 0.525973534053403\n",
            "Loss in iteration no. 61739 ==> 0.5259721263585706\n",
            "Loss in iteration no. 61740 ==> 0.5259707186786986\n",
            "Loss in iteration no. 61741 ==> 0.5259693110137873\n",
            "Loss in iteration no. 61742 ==> 0.525967903363836\n",
            "Loss in iteration no. 61743 ==> 0.5259664957288448\n",
            "Loss in iteration no. 61744 ==> 0.5259650881088134\n",
            "Loss in iteration no. 61745 ==> 0.5259636805037413\n",
            "Loss in iteration no. 61746 ==> 0.5259622729136286\n",
            "Loss in iteration no. 61747 ==> 0.5259608653384747\n",
            "Loss in iteration no. 61748 ==> 0.5259594577782798\n",
            "Loss in iteration no. 61749 ==> 0.5259580502330432\n",
            "Loss in iteration no. 61750 ==> 0.5259566427027651\n",
            "Loss in iteration no. 61751 ==> 0.525955235187445\n",
            "Loss in iteration no. 61752 ==> 0.5259538276870827\n",
            "Loss in iteration no. 61753 ==> 0.5259524202016779\n",
            "Loss in iteration no. 61754 ==> 0.5259510127312306\n",
            "Loss in iteration no. 61755 ==> 0.5259496052757401\n",
            "Loss in iteration no. 61756 ==> 0.5259481978352067\n",
            "Loss in iteration no. 61757 ==> 0.5259467904096297\n",
            "Loss in iteration no. 61758 ==> 0.5259453829990092\n",
            "Loss in iteration no. 61759 ==> 0.5259439756033447\n",
            "Loss in iteration no. 61760 ==> 0.5259425682226362\n",
            "Loss in iteration no. 61761 ==> 0.5259411608568834\n",
            "Loss in iteration no. 61762 ==> 0.5259397535060859\n",
            "Loss in iteration no. 61763 ==> 0.5259383461702437\n",
            "Loss in iteration no. 61764 ==> 0.5259369388493561\n",
            "Loss in iteration no. 61765 ==> 0.5259355315434235\n",
            "Loss in iteration no. 61766 ==> 0.5259341242524455\n",
            "Loss in iteration no. 61767 ==> 0.5259327169764213\n",
            "Loss in iteration no. 61768 ==> 0.5259313097153513\n",
            "Loss in iteration no. 61769 ==> 0.5259299024692349\n",
            "Loss in iteration no. 61770 ==> 0.5259284952380721\n",
            "Loss in iteration no. 61771 ==> 0.5259270880218624\n",
            "Loss in iteration no. 61772 ==> 0.525925680820606\n",
            "Loss in iteration no. 61773 ==> 0.5259242736343019\n",
            "Loss in iteration no. 61774 ==> 0.5259228664629507\n",
            "Loss in iteration no. 61775 ==> 0.5259214593065517\n",
            "Loss in iteration no. 61776 ==> 0.5259200521651047\n",
            "Loss in iteration no. 61777 ==> 0.5259186450386096\n",
            "Loss in iteration no. 61778 ==> 0.5259172379270659\n",
            "Loss in iteration no. 61779 ==> 0.5259158308304736\n",
            "Loss in iteration no. 61780 ==> 0.5259144237488325\n",
            "Loss in iteration no. 61781 ==> 0.5259130166821421\n",
            "Loss in iteration no. 61782 ==> 0.5259116096304024\n",
            "Loss in iteration no. 61783 ==> 0.525910202593613\n",
            "Loss in iteration no. 61784 ==> 0.5259087955717737\n",
            "Loss in iteration no. 61785 ==> 0.5259073885648844\n",
            "Loss in iteration no. 61786 ==> 0.5259059815729447\n",
            "Loss in iteration no. 61787 ==> 0.5259045745959544\n",
            "Loss in iteration no. 61788 ==> 0.5259031676339133\n",
            "Loss in iteration no. 61789 ==> 0.5259017606868212\n",
            "Loss in iteration no. 61790 ==> 0.5259003537546776\n",
            "Loss in iteration no. 61791 ==> 0.5258989468374825\n",
            "Loss in iteration no. 61792 ==> 0.5258975399352357\n",
            "Loss in iteration no. 61793 ==> 0.5258961330479366\n",
            "Loss in iteration no. 61794 ==> 0.5258947261755855\n",
            "Loss in iteration no. 61795 ==> 0.525893319318182\n",
            "Loss in iteration no. 61796 ==> 0.5258919124757253\n",
            "Loss in iteration no. 61797 ==> 0.525890505648216\n",
            "Loss in iteration no. 61798 ==> 0.5258890988356534\n",
            "Loss in iteration no. 61799 ==> 0.5258876920380373\n",
            "Loss in iteration no. 61800 ==> 0.5258862852553675\n",
            "Loss in iteration no. 61801 ==> 0.5258848784876438\n",
            "Loss in iteration no. 61802 ==> 0.5258834717348656\n",
            "Loss in iteration no. 61803 ==> 0.5258820649970334\n",
            "Loss in iteration no. 61804 ==> 0.5258806582741462\n",
            "Loss in iteration no. 61805 ==> 0.5258792515662042\n",
            "Loss in iteration no. 61806 ==> 0.5258778448732071\n",
            "Loss in iteration no. 61807 ==> 0.5258764381951546\n",
            "Loss in iteration no. 61808 ==> 0.5258750315320464\n",
            "Loss in iteration no. 61809 ==> 0.5258736248838823\n",
            "Loss in iteration no. 61810 ==> 0.5258722182506622\n",
            "Loss in iteration no. 61811 ==> 0.5258708116323858\n",
            "Loss in iteration no. 61812 ==> 0.5258694050290528\n",
            "Loss in iteration no. 61813 ==> 0.5258679984406628\n",
            "Loss in iteration no. 61814 ==> 0.5258665918672158\n",
            "Loss in iteration no. 61815 ==> 0.5258651853087115\n",
            "Loss in iteration no. 61816 ==> 0.5258637787651498\n",
            "Loss in iteration no. 61817 ==> 0.5258623722365302\n",
            "Loss in iteration no. 61818 ==> 0.5258609657228527\n",
            "Loss in iteration no. 61819 ==> 0.5258595592241166\n",
            "Loss in iteration no. 61820 ==> 0.5258581527403223\n",
            "Loss in iteration no. 61821 ==> 0.5258567462714692\n",
            "Loss in iteration no. 61822 ==> 0.5258553398175572\n",
            "Loss in iteration no. 61823 ==> 0.5258539333785857\n",
            "Loss in iteration no. 61824 ==> 0.5258525269545549\n",
            "Loss in iteration no. 61825 ==> 0.5258511205454643\n",
            "Loss in iteration no. 61826 ==> 0.5258497141513139\n",
            "Loss in iteration no. 61827 ==> 0.5258483077721033\n",
            "Loss in iteration no. 61828 ==> 0.5258469014078322\n",
            "Loss in iteration no. 61829 ==> 0.5258454950585004\n",
            "Loss in iteration no. 61830 ==> 0.5258440887241078\n",
            "Loss in iteration no. 61831 ==> 0.525842682404654\n",
            "Loss in iteration no. 61832 ==> 0.5258412761001389\n",
            "Loss in iteration no. 61833 ==> 0.5258398698105622\n",
            "Loss in iteration no. 61834 ==> 0.5258384635359236\n",
            "Loss in iteration no. 61835 ==> 0.5258370572762229\n",
            "Loss in iteration no. 61836 ==> 0.5258356510314597\n",
            "Loss in iteration no. 61837 ==> 0.525834244801634\n",
            "Loss in iteration no. 61838 ==> 0.5258328385867456\n",
            "Loss in iteration no. 61839 ==> 0.525831432386794\n",
            "Loss in iteration no. 61840 ==> 0.5258300262017792\n",
            "Loss in iteration no. 61841 ==> 0.5258286200317008\n",
            "Loss in iteration no. 61842 ==> 0.5258272138765586\n",
            "Loss in iteration no. 61843 ==> 0.5258258077363525\n",
            "Loss in iteration no. 61844 ==> 0.5258244016110821\n",
            "Loss in iteration no. 61845 ==> 0.5258229955007472\n",
            "Loss in iteration no. 61846 ==> 0.5258215894053475\n",
            "Loss in iteration no. 61847 ==> 0.5258201833248828\n",
            "Loss in iteration no. 61848 ==> 0.5258187772593531\n",
            "Loss in iteration no. 61849 ==> 0.5258173712087577\n",
            "Loss in iteration no. 61850 ==> 0.5258159651730968\n",
            "Loss in iteration no. 61851 ==> 0.5258145591523699\n",
            "Loss in iteration no. 61852 ==> 0.5258131531465768\n",
            "Loss in iteration no. 61853 ==> 0.5258117471557172\n",
            "Loss in iteration no. 61854 ==> 0.525810341179791\n",
            "Loss in iteration no. 61855 ==> 0.525808935218798\n",
            "Loss in iteration no. 61856 ==> 0.5258075292727379\n",
            "Loss in iteration no. 61857 ==> 0.5258061233416103\n",
            "Loss in iteration no. 61858 ==> 0.5258047174254151\n",
            "Loss in iteration no. 61859 ==> 0.5258033115241522\n",
            "Loss in iteration no. 61860 ==> 0.525801905637821\n",
            "Loss in iteration no. 61861 ==> 0.5258004997664217\n",
            "Loss in iteration no. 61862 ==> 0.5257990939099537\n",
            "Loss in iteration no. 61863 ==> 0.525797688068417\n",
            "Loss in iteration no. 61864 ==> 0.525796282241811\n",
            "Loss in iteration no. 61865 ==> 0.5257948764301359\n",
            "Loss in iteration no. 61866 ==> 0.5257934706333914\n",
            "Loss in iteration no. 61867 ==> 0.5257920648515769\n",
            "Loss in iteration no. 61868 ==> 0.5257906590846925\n",
            "Loss in iteration no. 61869 ==> 0.5257892533327377\n",
            "Loss in iteration no. 61870 ==> 0.5257878475957127\n",
            "Loss in iteration no. 61871 ==> 0.5257864418736168\n",
            "Loss in iteration no. 61872 ==> 0.5257850361664499\n",
            "Loss in iteration no. 61873 ==> 0.525783630474212\n",
            "Loss in iteration no. 61874 ==> 0.5257822247969026\n",
            "Loss in iteration no. 61875 ==> 0.5257808191345213\n",
            "Loss in iteration no. 61876 ==> 0.5257794134870684\n",
            "Loss in iteration no. 61877 ==> 0.5257780078545431\n",
            "Loss in iteration no. 61878 ==> 0.5257766022369454\n",
            "Loss in iteration no. 61879 ==> 0.5257751966342752\n",
            "Loss in iteration no. 61880 ==> 0.5257737910465321\n",
            "Loss in iteration no. 61881 ==> 0.5257723854737159\n",
            "Loss in iteration no. 61882 ==> 0.5257709799158262\n",
            "Loss in iteration no. 61883 ==> 0.5257695743728631\n",
            "Loss in iteration no. 61884 ==> 0.5257681688448261\n",
            "Loss in iteration no. 61885 ==> 0.5257667633317149\n",
            "Loss in iteration no. 61886 ==> 0.5257653578335296\n",
            "Loss in iteration no. 61887 ==> 0.5257639523502695\n",
            "Loss in iteration no. 61888 ==> 0.5257625468819349\n",
            "Loss in iteration no. 61889 ==> 0.525761141428525\n",
            "Loss in iteration no. 61890 ==> 0.5257597359900402\n",
            "Loss in iteration no. 61891 ==> 0.5257583305664796\n",
            "Loss in iteration no. 61892 ==> 0.5257569251578432\n",
            "Loss in iteration no. 61893 ==> 0.5257555197641309\n",
            "Loss in iteration no. 61894 ==> 0.5257541143853425\n",
            "Loss in iteration no. 61895 ==> 0.5257527090214774\n",
            "Loss in iteration no. 61896 ==> 0.5257513036725358\n",
            "Loss in iteration no. 61897 ==> 0.5257498983385172\n",
            "Loss in iteration no. 61898 ==> 0.5257484930194214\n",
            "Loss in iteration no. 61899 ==> 0.525747087715248\n",
            "Loss in iteration no. 61900 ==> 0.5257456824259972\n",
            "Loss in iteration no. 61901 ==> 0.5257442771516685\n",
            "Loss in iteration no. 61902 ==> 0.5257428718922615\n",
            "Loss in iteration no. 61903 ==> 0.5257414666477763\n",
            "Loss in iteration no. 61904 ==> 0.5257400614182123\n",
            "Loss in iteration no. 61905 ==> 0.5257386562035695\n",
            "Loss in iteration no. 61906 ==> 0.5257372510038476\n",
            "Loss in iteration no. 61907 ==> 0.5257358458190464\n",
            "Loss in iteration no. 61908 ==> 0.5257344406491655\n",
            "Loss in iteration no. 61909 ==> 0.5257330354942052\n",
            "Loss in iteration no. 61910 ==> 0.5257316303541645\n",
            "Loss in iteration no. 61911 ==> 0.5257302252290434\n",
            "Loss in iteration no. 61912 ==> 0.525728820118842\n",
            "Loss in iteration no. 61913 ==> 0.5257274150235598\n",
            "Loss in iteration no. 61914 ==> 0.5257260099431964\n",
            "Loss in iteration no. 61915 ==> 0.525724604877752\n",
            "Loss in iteration no. 61916 ==> 0.525723199827226\n",
            "Loss in iteration no. 61917 ==> 0.5257217947916183\n",
            "Loss in iteration no. 61918 ==> 0.5257203897709285\n",
            "Loss in iteration no. 61919 ==> 0.5257189847651568\n",
            "Loss in iteration no. 61920 ==> 0.5257175797743026\n",
            "Loss in iteration no. 61921 ==> 0.5257161747983654\n",
            "Loss in iteration no. 61922 ==> 0.5257147698373456\n",
            "Loss in iteration no. 61923 ==> 0.5257133648912424\n",
            "Loss in iteration no. 61924 ==> 0.525711959960056\n",
            "Loss in iteration no. 61925 ==> 0.5257105550437859\n",
            "Loss in iteration no. 61926 ==> 0.5257091501424319\n",
            "Loss in iteration no. 61927 ==> 0.5257077452559937\n",
            "Loss in iteration no. 61928 ==> 0.5257063403844712\n",
            "Loss in iteration no. 61929 ==> 0.5257049355278642\n",
            "Loss in iteration no. 61930 ==> 0.5257035306861723\n",
            "Loss in iteration no. 61931 ==> 0.5257021258593952\n",
            "Loss in iteration no. 61932 ==> 0.5257007210475328\n",
            "Loss in iteration no. 61933 ==> 0.5256993162505852\n",
            "Loss in iteration no. 61934 ==> 0.5256979114685515\n",
            "Loss in iteration no. 61935 ==> 0.5256965067014319\n",
            "Loss in iteration no. 61936 ==> 0.525695101949226\n",
            "Loss in iteration no. 61937 ==> 0.5256936972119334\n",
            "Loss in iteration no. 61938 ==> 0.5256922924895543\n",
            "Loss in iteration no. 61939 ==> 0.5256908877820882\n",
            "Loss in iteration no. 61940 ==> 0.5256894830895348\n",
            "Loss in iteration no. 61941 ==> 0.525688078411894\n",
            "Loss in iteration no. 61942 ==> 0.5256866737491654\n",
            "Loss in iteration no. 61943 ==> 0.5256852691013488\n",
            "Loss in iteration no. 61944 ==> 0.5256838644684442\n",
            "Loss in iteration no. 61945 ==> 0.5256824598504511\n",
            "Loss in iteration no. 61946 ==> 0.5256810552473693\n",
            "Loss in iteration no. 61947 ==> 0.5256796506591986\n",
            "Loss in iteration no. 61948 ==> 0.5256782460859389\n",
            "Loss in iteration no. 61949 ==> 0.5256768415275898\n",
            "Loss in iteration no. 61950 ==> 0.5256754369841511\n",
            "Loss in iteration no. 61951 ==> 0.5256740324556224\n",
            "Loss in iteration no. 61952 ==> 0.5256726279420036\n",
            "Loss in iteration no. 61953 ==> 0.5256712234432948\n",
            "Loss in iteration no. 61954 ==> 0.5256698189594949\n",
            "Loss in iteration no. 61955 ==> 0.5256684144906048\n",
            "Loss in iteration no. 61956 ==> 0.5256670100366232\n",
            "Loss in iteration no. 61957 ==> 0.5256656055975505\n",
            "Loss in iteration no. 61958 ==> 0.5256642011733863\n",
            "Loss in iteration no. 61959 ==> 0.5256627967641302\n",
            "Loss in iteration no. 61960 ==> 0.525661392369782\n",
            "Loss in iteration no. 61961 ==> 0.5256599879903419\n",
            "Loss in iteration no. 61962 ==> 0.5256585836258091\n",
            "Loss in iteration no. 61963 ==> 0.5256571792761836\n",
            "Loss in iteration no. 61964 ==> 0.5256557749414652\n",
            "Loss in iteration no. 61965 ==> 0.5256543706216537\n",
            "Loss in iteration no. 61966 ==> 0.5256529663167486\n",
            "Loss in iteration no. 61967 ==> 0.5256515620267499\n",
            "Loss in iteration no. 61968 ==> 0.5256501577516571\n",
            "Loss in iteration no. 61969 ==> 0.5256487534914702\n",
            "Loss in iteration no. 61970 ==> 0.5256473492461892\n",
            "Loss in iteration no. 61971 ==> 0.5256459450158133\n",
            "Loss in iteration no. 61972 ==> 0.5256445408003426\n",
            "Loss in iteration no. 61973 ==> 0.5256431365997768\n",
            "Loss in iteration no. 61974 ==> 0.5256417324141157\n",
            "Loss in iteration no. 61975 ==> 0.525640328243359\n",
            "Loss in iteration no. 61976 ==> 0.5256389240875065\n",
            "Loss in iteration no. 61977 ==> 0.5256375199465579\n",
            "Loss in iteration no. 61978 ==> 0.5256361158205131\n",
            "Loss in iteration no. 61979 ==> 0.5256347117093716\n",
            "Loss in iteration no. 61980 ==> 0.5256333076131333\n",
            "Loss in iteration no. 61981 ==> 0.5256319035317981\n",
            "Loss in iteration no. 61982 ==> 0.5256304994653657\n",
            "Loss in iteration no. 61983 ==> 0.5256290954138357\n",
            "Loss in iteration no. 61984 ==> 0.525627691377208\n",
            "Loss in iteration no. 61985 ==> 0.5256262873554823\n",
            "Loss in iteration no. 61986 ==> 0.5256248833486585\n",
            "Loss in iteration no. 61987 ==> 0.5256234793567361\n",
            "Loss in iteration no. 61988 ==> 0.5256220753797152\n",
            "Loss in iteration no. 61989 ==> 0.525620671417595\n",
            "Loss in iteration no. 61990 ==> 0.525619267470376\n",
            "Loss in iteration no. 61991 ==> 0.5256178635380575\n",
            "Loss in iteration no. 61992 ==> 0.5256164596206394\n",
            "Loss in iteration no. 61993 ==> 0.5256150557181214\n",
            "Loss in iteration no. 61994 ==> 0.5256136518305032\n",
            "Loss in iteration no. 61995 ==> 0.5256122479577847\n",
            "Loss in iteration no. 61996 ==> 0.5256108440999655\n",
            "Loss in iteration no. 61997 ==> 0.5256094402570456\n",
            "Loss in iteration no. 61998 ==> 0.5256080364290248\n",
            "Loss in iteration no. 61999 ==> 0.5256066326159022\n",
            "Loss in iteration no. 62000 ==> 0.5256052288176785\n",
            "Loss in iteration no. 62001 ==> 0.5256038250343529\n",
            "Loss in iteration no. 62002 ==> 0.5256024212659252\n",
            "Loss in iteration no. 62003 ==> 0.5256010175123952\n",
            "Loss in iteration no. 62004 ==> 0.5255996137737626\n",
            "Loss in iteration no. 62005 ==> 0.5255982100500275\n",
            "Loss in iteration no. 62006 ==> 0.5255968063411893\n",
            "Loss in iteration no. 62007 ==> 0.5255954026472479\n",
            "Loss in iteration no. 62008 ==> 0.5255939989682031\n",
            "Loss in iteration no. 62009 ==> 0.5255925953040544\n",
            "Loss in iteration no. 62010 ==> 0.525591191654802\n",
            "Loss in iteration no. 62011 ==> 0.5255897880204453\n",
            "Loss in iteration no. 62012 ==> 0.5255883844009842\n",
            "Loss in iteration no. 62013 ==> 0.5255869807964185\n",
            "Loss in iteration no. 62014 ==> 0.525585577206748\n",
            "Loss in iteration no. 62015 ==> 0.5255841736319723\n",
            "Loss in iteration no. 62016 ==> 0.5255827700720912\n",
            "Loss in iteration no. 62017 ==> 0.5255813665271043\n",
            "Loss in iteration no. 62018 ==> 0.5255799629970118\n",
            "Loss in iteration no. 62019 ==> 0.5255785594818132\n",
            "Loss in iteration no. 62020 ==> 0.5255771559815081\n",
            "Loss in iteration no. 62021 ==> 0.5255757524960967\n",
            "Loss in iteration no. 62022 ==> 0.5255743490255783\n",
            "Loss in iteration no. 62023 ==> 0.525572945569953\n",
            "Loss in iteration no. 62024 ==> 0.5255715421292203\n",
            "Loss in iteration no. 62025 ==> 0.5255701387033802\n",
            "Loss in iteration no. 62026 ==> 0.5255687352924323\n",
            "Loss in iteration no. 62027 ==> 0.5255673318963764\n",
            "Loss in iteration no. 62028 ==> 0.5255659285152123\n",
            "Loss in iteration no. 62029 ==> 0.5255645251489397\n",
            "Loss in iteration no. 62030 ==> 0.5255631217975584\n",
            "Loss in iteration no. 62031 ==> 0.5255617184610683\n",
            "Loss in iteration no. 62032 ==> 0.5255603151394689\n",
            "Loss in iteration no. 62033 ==> 0.52555891183276\n",
            "Loss in iteration no. 62034 ==> 0.5255575085409415\n",
            "Loss in iteration no. 62035 ==> 0.5255561052640131\n",
            "Loss in iteration no. 62036 ==> 0.5255547020019746\n",
            "Loss in iteration no. 62037 ==> 0.5255532987548257\n",
            "Loss in iteration no. 62038 ==> 0.5255518955225662\n",
            "Loss in iteration no. 62039 ==> 0.5255504923051959\n",
            "Loss in iteration no. 62040 ==> 0.5255490891027144\n",
            "Loss in iteration no. 62041 ==> 0.5255476859151216\n",
            "Loss in iteration no. 62042 ==> 0.5255462827424172\n",
            "Loss in iteration no. 62043 ==> 0.5255448795846012\n",
            "Loss in iteration no. 62044 ==> 0.525543476441673\n",
            "Loss in iteration no. 62045 ==> 0.5255420733136326\n",
            "Loss in iteration no. 62046 ==> 0.5255406702004795\n",
            "Loss in iteration no. 62047 ==> 0.5255392671022138\n",
            "Loss in iteration no. 62048 ==> 0.525537864018835\n",
            "Loss in iteration no. 62049 ==> 0.5255364609503431\n",
            "Loss in iteration no. 62050 ==> 0.5255350578967377\n",
            "Loss in iteration no. 62051 ==> 0.5255336548580185\n",
            "Loss in iteration no. 62052 ==> 0.5255322518341855\n",
            "Loss in iteration no. 62053 ==> 0.525530848825238\n",
            "Loss in iteration no. 62054 ==> 0.5255294458311763\n",
            "Loss in iteration no. 62055 ==> 0.5255280428519999\n",
            "Loss in iteration no. 62056 ==> 0.5255266398877088\n",
            "Loss in iteration no. 62057 ==> 0.5255252369383023\n",
            "Loss in iteration no. 62058 ==> 0.5255238340037807\n",
            "Loss in iteration no. 62059 ==> 0.5255224310841432\n",
            "Loss in iteration no. 62060 ==> 0.52552102817939\n",
            "Loss in iteration no. 62061 ==> 0.5255196252895206\n",
            "Loss in iteration no. 62062 ==> 0.5255182224145348\n",
            "Loss in iteration no. 62063 ==> 0.5255168195544326\n",
            "Loss in iteration no. 62064 ==> 0.5255154167092135\n",
            "Loss in iteration no. 62065 ==> 0.5255140138788774\n",
            "Loss in iteration no. 62066 ==> 0.5255126110634241\n",
            "Loss in iteration no. 62067 ==> 0.525511208262853\n",
            "Loss in iteration no. 62068 ==> 0.5255098054771645\n",
            "Loss in iteration no. 62069 ==> 0.5255084027063578\n",
            "Loss in iteration no. 62070 ==> 0.5255069999504328\n",
            "Loss in iteration no. 62071 ==> 0.5255055972093894\n",
            "Loss in iteration no. 62072 ==> 0.5255041944832274\n",
            "Loss in iteration no. 62073 ==> 0.5255027917719464\n",
            "Loss in iteration no. 62074 ==> 0.5255013890755461\n",
            "Loss in iteration no. 62075 ==> 0.5254999863940265\n",
            "Loss in iteration no. 62076 ==> 0.5254985837273871\n",
            "Loss in iteration no. 62077 ==> 0.525497181075628\n",
            "Loss in iteration no. 62078 ==> 0.5254957784387485\n",
            "Loss in iteration no. 62079 ==> 0.5254943758167487\n",
            "Loss in iteration no. 62080 ==> 0.5254929732096283\n",
            "Loss in iteration no. 62081 ==> 0.5254915706173872\n",
            "Loss in iteration no. 62082 ==> 0.5254901680400249\n",
            "Loss in iteration no. 62083 ==> 0.5254887654775412\n",
            "Loss in iteration no. 62084 ==> 0.525487362929936\n",
            "Loss in iteration no. 62085 ==> 0.5254859603972091\n",
            "Loss in iteration no. 62086 ==> 0.5254845578793599\n",
            "Loss in iteration no. 62087 ==> 0.5254831553763886\n",
            "Loss in iteration no. 62088 ==> 0.5254817528882948\n",
            "Loss in iteration no. 62089 ==> 0.5254803504150781\n",
            "Loss in iteration no. 62090 ==> 0.5254789479567384\n",
            "Loss in iteration no. 62091 ==> 0.5254775455132755\n",
            "Loss in iteration no. 62092 ==> 0.5254761430846892\n",
            "Loss in iteration no. 62093 ==> 0.5254747406709791\n",
            "Loss in iteration no. 62094 ==> 0.5254733382721452\n",
            "Loss in iteration no. 62095 ==> 0.525471935888187\n",
            "Loss in iteration no. 62096 ==> 0.5254705335191043\n",
            "Loss in iteration no. 62097 ==> 0.5254691311648969\n",
            "Loss in iteration no. 62098 ==> 0.5254677288255648\n",
            "Loss in iteration no. 62099 ==> 0.5254663265011075\n",
            "Loss in iteration no. 62100 ==> 0.5254649241915248\n",
            "Loss in iteration no. 62101 ==> 0.5254635218968164\n",
            "Loss in iteration no. 62102 ==> 0.5254621196169822\n",
            "Loss in iteration no. 62103 ==> 0.5254607173520218\n",
            "Loss in iteration no. 62104 ==> 0.5254593151019353\n",
            "Loss in iteration no. 62105 ==> 0.5254579128667222\n",
            "Loss in iteration no. 62106 ==> 0.5254565106463821\n",
            "Loss in iteration no. 62107 ==> 0.525455108440915\n",
            "Loss in iteration no. 62108 ==> 0.5254537062503208\n",
            "Loss in iteration no. 62109 ==> 0.525452304074599\n",
            "Loss in iteration no. 62110 ==> 0.5254509019137493\n",
            "Loss in iteration no. 62111 ==> 0.5254494997677717\n",
            "Loss in iteration no. 62112 ==> 0.525448097636666\n",
            "Loss in iteration no. 62113 ==> 0.5254466955204316\n",
            "Loss in iteration no. 62114 ==> 0.5254452934190688\n",
            "Loss in iteration no. 62115 ==> 0.5254438913325766\n",
            "Loss in iteration no. 62116 ==> 0.5254424892609555\n",
            "Loss in iteration no. 62117 ==> 0.525441087204205\n",
            "Loss in iteration no. 62118 ==> 0.5254396851623248\n",
            "Loss in iteration no. 62119 ==> 0.5254382831353147\n",
            "Loss in iteration no. 62120 ==> 0.5254368811231744\n",
            "Loss in iteration no. 62121 ==> 0.5254354791259038\n",
            "Loss in iteration no. 62122 ==> 0.5254340771435024\n",
            "Loss in iteration no. 62123 ==> 0.5254326751759705\n",
            "Loss in iteration no. 62124 ==> 0.5254312732233073\n",
            "Loss in iteration no. 62125 ==> 0.5254298712855128\n",
            "Loss in iteration no. 62126 ==> 0.5254284693625866\n",
            "Loss in iteration no. 62127 ==> 0.5254270674545288\n",
            "Loss in iteration no. 62128 ==> 0.5254256655613389\n",
            "Loss in iteration no. 62129 ==> 0.5254242636830165\n",
            "Loss in iteration no. 62130 ==> 0.525422861819562\n",
            "Loss in iteration no. 62131 ==> 0.5254214599709744\n",
            "Loss in iteration no. 62132 ==> 0.525420058137254\n",
            "Loss in iteration no. 62133 ==> 0.5254186563184002\n",
            "Loss in iteration no. 62134 ==> 0.5254172545144131\n",
            "Loss in iteration no. 62135 ==> 0.5254158527252925\n",
            "Loss in iteration no. 62136 ==> 0.5254144509510376\n",
            "Loss in iteration no. 62137 ==> 0.5254130491916487\n",
            "Loss in iteration no. 62138 ==> 0.5254116474471251\n",
            "Loss in iteration no. 62139 ==> 0.5254102457174671\n",
            "Loss in iteration no. 62140 ==> 0.5254088440026742\n",
            "Loss in iteration no. 62141 ==> 0.525407442302746\n",
            "Loss in iteration no. 62142 ==> 0.5254060406176826\n",
            "Loss in iteration no. 62143 ==> 0.5254046389474837\n",
            "Loss in iteration no. 62144 ==> 0.5254032372921487\n",
            "Loss in iteration no. 62145 ==> 0.5254018356516776\n",
            "Loss in iteration no. 62146 ==> 0.5254004340260704\n",
            "Loss in iteration no. 62147 ==> 0.5253990324153266\n",
            "Loss in iteration no. 62148 ==> 0.5253976308194459\n",
            "Loss in iteration no. 62149 ==> 0.5253962292384282\n",
            "Loss in iteration no. 62150 ==> 0.5253948276722732\n",
            "Loss in iteration no. 62151 ==> 0.5253934261209807\n",
            "Loss in iteration no. 62152 ==> 0.5253920245845507\n",
            "Loss in iteration no. 62153 ==> 0.5253906230629825\n",
            "Loss in iteration no. 62154 ==> 0.5253892215562761\n",
            "Loss in iteration no. 62155 ==> 0.5253878200644311\n",
            "Loss in iteration no. 62156 ==> 0.5253864185874475\n",
            "Loss in iteration no. 62157 ==> 0.5253850171253251\n",
            "Loss in iteration no. 62158 ==> 0.5253836156780635\n",
            "Loss in iteration no. 62159 ==> 0.5253822142456622\n",
            "Loss in iteration no. 62160 ==> 0.5253808128281215\n",
            "Loss in iteration no. 62161 ==> 0.525379411425441\n",
            "Loss in iteration no. 62162 ==> 0.5253780100376203\n",
            "Loss in iteration no. 62163 ==> 0.5253766086646592\n",
            "Loss in iteration no. 62164 ==> 0.5253752073065574\n",
            "Loss in iteration no. 62165 ==> 0.525373805963315\n",
            "Loss in iteration no. 62166 ==> 0.5253724046349314\n",
            "Loss in iteration no. 62167 ==> 0.5253710033214064\n",
            "Loss in iteration no. 62168 ==> 0.5253696020227401\n",
            "Loss in iteration no. 62169 ==> 0.5253682007389318\n",
            "Loss in iteration no. 62170 ==> 0.5253667994699815\n",
            "Loss in iteration no. 62171 ==> 0.5253653982158891\n",
            "Loss in iteration no. 62172 ==> 0.525363996976654\n",
            "Loss in iteration no. 62173 ==> 0.5253625957522763\n",
            "Loss in iteration no. 62174 ==> 0.5253611945427554\n",
            "Loss in iteration no. 62175 ==> 0.5253597933480916\n",
            "Loss in iteration no. 62176 ==> 0.5253583921682843\n",
            "Loss in iteration no. 62177 ==> 0.5253569910033331\n",
            "Loss in iteration no. 62178 ==> 0.525355589853238\n",
            "Loss in iteration no. 62179 ==> 0.525354188717999\n",
            "Loss in iteration no. 62180 ==> 0.5253527875976154\n",
            "Loss in iteration no. 62181 ==> 0.5253513864920873\n",
            "Loss in iteration no. 62182 ==> 0.5253499854014142\n",
            "Loss in iteration no. 62183 ==> 0.525348584325596\n",
            "Loss in iteration no. 62184 ==> 0.5253471832646325\n",
            "Loss in iteration no. 62185 ==> 0.5253457822185233\n",
            "Loss in iteration no. 62186 ==> 0.5253443811872683\n",
            "Loss in iteration no. 62187 ==> 0.5253429801708673\n",
            "Loss in iteration no. 62188 ==> 0.52534157916932\n",
            "Loss in iteration no. 62189 ==> 0.5253401781826263\n",
            "Loss in iteration no. 62190 ==> 0.5253387772107856\n",
            "Loss in iteration no. 62191 ==> 0.5253373762537982\n",
            "Loss in iteration no. 62192 ==> 0.5253359753116632\n",
            "Loss in iteration no. 62193 ==> 0.5253345743843808\n",
            "Loss in iteration no. 62194 ==> 0.5253331734719507\n",
            "Loss in iteration no. 62195 ==> 0.5253317725743727\n",
            "Loss in iteration no. 62196 ==> 0.5253303716916465\n",
            "Loss in iteration no. 62197 ==> 0.525328970823772\n",
            "Loss in iteration no. 62198 ==> 0.5253275699707486\n",
            "Loss in iteration no. 62199 ==> 0.5253261691325763\n",
            "Loss in iteration no. 62200 ==> 0.525324768309255\n",
            "Loss in iteration no. 62201 ==> 0.5253233675007842\n",
            "Loss in iteration no. 62202 ==> 0.5253219667071638\n",
            "Loss in iteration no. 62203 ==> 0.5253205659283935\n",
            "Loss in iteration no. 62204 ==> 0.5253191651644732\n",
            "Loss in iteration no. 62205 ==> 0.5253177644154026\n",
            "Loss in iteration no. 62206 ==> 0.5253163636811812\n",
            "Loss in iteration no. 62207 ==> 0.5253149629618091\n",
            "Loss in iteration no. 62208 ==> 0.5253135622572861\n",
            "Loss in iteration no. 62209 ==> 0.5253121615676117\n",
            "Loss in iteration no. 62210 ==> 0.5253107608927859\n",
            "Loss in iteration no. 62211 ==> 0.5253093602328082\n",
            "Loss in iteration no. 62212 ==> 0.5253079595876785\n",
            "Loss in iteration no. 62213 ==> 0.5253065589573965\n",
            "Loss in iteration no. 62214 ==> 0.5253051583419621\n",
            "Loss in iteration no. 62215 ==> 0.5253037577413752\n",
            "Loss in iteration no. 62216 ==> 0.5253023571556351\n",
            "Loss in iteration no. 62217 ==> 0.525300956584742\n",
            "Loss in iteration no. 62218 ==> 0.5252995560286953\n",
            "Loss in iteration no. 62219 ==> 0.5252981554874951\n",
            "Loss in iteration no. 62220 ==> 0.5252967549611408\n",
            "Loss in iteration no. 62221 ==> 0.5252953544496325\n",
            "Loss in iteration no. 62222 ==> 0.52529395395297\n",
            "Loss in iteration no. 62223 ==> 0.5252925534711526\n",
            "Loss in iteration no. 62224 ==> 0.5252911530041805\n",
            "Loss in iteration no. 62225 ==> 0.5252897525520531\n",
            "Loss in iteration no. 62226 ==> 0.5252883521147709\n",
            "Loss in iteration no. 62227 ==> 0.5252869516923327\n",
            "Loss in iteration no. 62228 ==> 0.525285551284739\n",
            "Loss in iteration no. 62229 ==> 0.525284150891989\n",
            "Loss in iteration no. 62230 ==> 0.5252827505140829\n",
            "Loss in iteration no. 62231 ==> 0.5252813501510203\n",
            "Loss in iteration no. 62232 ==> 0.5252799498028007\n",
            "Loss in iteration no. 62233 ==> 0.5252785494694244\n",
            "Loss in iteration no. 62234 ==> 0.5252771491508909\n",
            "Loss in iteration no. 62235 ==> 0.5252757488471999\n",
            "Loss in iteration no. 62236 ==> 0.5252743485583511\n",
            "Loss in iteration no. 62237 ==> 0.5252729482843445\n",
            "Loss in iteration no. 62238 ==> 0.5252715480251796\n",
            "Loss in iteration no. 62239 ==> 0.5252701477808565\n",
            "Loss in iteration no. 62240 ==> 0.5252687475513745\n",
            "Loss in iteration no. 62241 ==> 0.5252673473367337\n",
            "Loss in iteration no. 62242 ==> 0.525265947136934\n",
            "Loss in iteration no. 62243 ==> 0.5252645469519749\n",
            "Loss in iteration no. 62244 ==> 0.525263146781856\n",
            "Loss in iteration no. 62245 ==> 0.5252617466265773\n",
            "Loss in iteration no. 62246 ==> 0.5252603464861388\n",
            "Loss in iteration no. 62247 ==> 0.5252589463605397\n",
            "Loss in iteration no. 62248 ==> 0.5252575462497804\n",
            "Loss in iteration no. 62249 ==> 0.5252561461538602\n",
            "Loss in iteration no. 62250 ==> 0.5252547460727788\n",
            "Loss in iteration no. 62251 ==> 0.5252533460065362\n",
            "Loss in iteration no. 62252 ==> 0.5252519459551322\n",
            "Loss in iteration no. 62253 ==> 0.5252505459185667\n",
            "Loss in iteration no. 62254 ==> 0.5252491458968389\n",
            "Loss in iteration no. 62255 ==> 0.525247745889949\n",
            "Loss in iteration no. 62256 ==> 0.5252463458978968\n",
            "Loss in iteration no. 62257 ==> 0.5252449459206818\n",
            "Loss in iteration no. 62258 ==> 0.5252435459583039\n",
            "Loss in iteration no. 62259 ==> 0.5252421460107628\n",
            "Loss in iteration no. 62260 ==> 0.5252407460780585\n",
            "Loss in iteration no. 62261 ==> 0.5252393461601904\n",
            "Loss in iteration no. 62262 ==> 0.5252379462571586\n",
            "Loss in iteration no. 62263 ==> 0.5252365463689628\n",
            "Loss in iteration no. 62264 ==> 0.5252351464956023\n",
            "Loss in iteration no. 62265 ==> 0.5252337466370774\n",
            "Loss in iteration no. 62266 ==> 0.5252323467933878\n",
            "Loss in iteration no. 62267 ==> 0.5252309469645332\n",
            "Loss in iteration no. 62268 ==> 0.5252295471505133\n",
            "Loss in iteration no. 62269 ==> 0.5252281473513277\n",
            "Loss in iteration no. 62270 ==> 0.5252267475669766\n",
            "Loss in iteration no. 62271 ==> 0.5252253477974593\n",
            "Loss in iteration no. 62272 ==> 0.525223948042776\n",
            "Loss in iteration no. 62273 ==> 0.5252225483029259\n",
            "Loss in iteration no. 62274 ==> 0.5252211485779094\n",
            "Loss in iteration no. 62275 ==> 0.5252197488677259\n",
            "Loss in iteration no. 62276 ==> 0.5252183491723752\n",
            "Loss in iteration no. 62277 ==> 0.5252169494918572\n",
            "Loss in iteration no. 62278 ==> 0.5252155498261714\n",
            "Loss in iteration no. 62279 ==> 0.5252141501753178\n",
            "Loss in iteration no. 62280 ==> 0.5252127505392961\n",
            "Loss in iteration no. 62281 ==> 0.5252113509181059\n",
            "Loss in iteration no. 62282 ==> 0.5252099513117473\n",
            "Loss in iteration no. 62283 ==> 0.5252085517202197\n",
            "Loss in iteration no. 62284 ==> 0.5252071521435232\n",
            "Loss in iteration no. 62285 ==> 0.5252057525816572\n",
            "Loss in iteration no. 62286 ==> 0.5252043530346218\n",
            "Loss in iteration no. 62287 ==> 0.5252029535024165\n",
            "Loss in iteration no. 62288 ==> 0.5252015539850413\n",
            "Loss in iteration no. 62289 ==> 0.5252001544824959\n",
            "Loss in iteration no. 62290 ==> 0.52519875499478\n",
            "Loss in iteration no. 62291 ==> 0.5251973555218932\n",
            "Loss in iteration no. 62292 ==> 0.5251959560638356\n",
            "Loss in iteration no. 62293 ==> 0.5251945566206068\n",
            "Loss in iteration no. 62294 ==> 0.5251931571922065\n",
            "Loss in iteration no. 62295 ==> 0.5251917577786346\n",
            "Loss in iteration no. 62296 ==> 0.5251903583798906\n",
            "Loss in iteration no. 62297 ==> 0.5251889589959747\n",
            "Loss in iteration no. 62298 ==> 0.5251875596268863\n",
            "Loss in iteration no. 62299 ==> 0.5251861602726252\n",
            "Loss in iteration no. 62300 ==> 0.5251847609331914\n",
            "Loss in iteration no. 62301 ==> 0.5251833616085846\n",
            "Loss in iteration no. 62302 ==> 0.5251819622988043\n",
            "Loss in iteration no. 62303 ==> 0.5251805630038505\n",
            "Loss in iteration no. 62304 ==> 0.5251791637237228\n",
            "Loss in iteration no. 62305 ==> 0.5251777644584211\n",
            "Loss in iteration no. 62306 ==> 0.5251763652079452\n",
            "Loss in iteration no. 62307 ==> 0.5251749659722947\n",
            "Loss in iteration no. 62308 ==> 0.5251735667514694\n",
            "Loss in iteration no. 62309 ==> 0.5251721675454692\n",
            "Loss in iteration no. 62310 ==> 0.5251707683542939\n",
            "Loss in iteration no. 62311 ==> 0.5251693691779429\n",
            "Loss in iteration no. 62312 ==> 0.5251679700164164\n",
            "Loss in iteration no. 62313 ==> 0.5251665708697139\n",
            "Loss in iteration no. 62314 ==> 0.5251651717378352\n",
            "Loss in iteration no. 62315 ==> 0.5251637726207801\n",
            "Loss in iteration no. 62316 ==> 0.5251623735185483\n",
            "Loss in iteration no. 62317 ==> 0.5251609744311397\n",
            "Loss in iteration no. 62318 ==> 0.525159575358554\n",
            "Loss in iteration no. 62319 ==> 0.5251581763007909\n",
            "Loss in iteration no. 62320 ==> 0.5251567772578501\n",
            "Loss in iteration no. 62321 ==> 0.5251553782297317\n",
            "Loss in iteration no. 62322 ==> 0.5251539792164353\n",
            "Loss in iteration no. 62323 ==> 0.5251525802179603\n",
            "Loss in iteration no. 62324 ==> 0.5251511812343068\n",
            "Loss in iteration no. 62325 ==> 0.5251497822654747\n",
            "Loss in iteration no. 62326 ==> 0.5251483833114635\n",
            "Loss in iteration no. 62327 ==> 0.5251469843722731\n",
            "Loss in iteration no. 62328 ==> 0.5251455854479032\n",
            "Loss in iteration no. 62329 ==> 0.5251441865383535\n",
            "Loss in iteration no. 62330 ==> 0.525142787643624\n",
            "Loss in iteration no. 62331 ==> 0.5251413887637142\n",
            "Loss in iteration no. 62332 ==> 0.5251399898986239\n",
            "Loss in iteration no. 62333 ==> 0.5251385910483531\n",
            "Loss in iteration no. 62334 ==> 0.5251371922129012\n",
            "Loss in iteration no. 62335 ==> 0.5251357933922683\n",
            "Loss in iteration no. 62336 ==> 0.5251343945864541\n",
            "Loss in iteration no. 62337 ==> 0.5251329957954581\n",
            "Loss in iteration no. 62338 ==> 0.5251315970192805\n",
            "Loss in iteration no. 62339 ==> 0.5251301982579205\n",
            "Loss in iteration no. 62340 ==> 0.5251287995113785\n",
            "Loss in iteration no. 62341 ==> 0.5251274007796537\n",
            "Loss in iteration no. 62342 ==> 0.5251260020627462\n",
            "Loss in iteration no. 62343 ==> 0.5251246033606557\n",
            "Loss in iteration no. 62344 ==> 0.5251232046733819\n",
            "Loss in iteration no. 62345 ==> 0.5251218060009244\n",
            "Loss in iteration no. 62346 ==> 0.5251204073432835\n",
            "Loss in iteration no. 62347 ==> 0.5251190087004584\n",
            "Loss in iteration no. 62348 ==> 0.5251176100724491\n",
            "Loss in iteration no. 62349 ==> 0.5251162114592556\n",
            "Loss in iteration no. 62350 ==> 0.5251148128608772\n",
            "Loss in iteration no. 62351 ==> 0.5251134142773137\n",
            "Loss in iteration no. 62352 ==> 0.5251120157085654\n",
            "Loss in iteration no. 62353 ==> 0.5251106171546315\n",
            "Loss in iteration no. 62354 ==> 0.525109218615512\n",
            "Loss in iteration no. 62355 ==> 0.5251078200912066\n",
            "Loss in iteration no. 62356 ==> 0.525106421581715\n",
            "Loss in iteration no. 62357 ==> 0.5251050230870373\n",
            "Loss in iteration no. 62358 ==> 0.5251036246071729\n",
            "Loss in iteration no. 62359 ==> 0.5251022261421217\n",
            "Loss in iteration no. 62360 ==> 0.5251008276918835\n",
            "Loss in iteration no. 62361 ==> 0.5250994292564579\n",
            "Loss in iteration no. 62362 ==> 0.5250980308358448\n",
            "Loss in iteration no. 62363 ==> 0.5250966324300439\n",
            "Loss in iteration no. 62364 ==> 0.5250952340390551\n",
            "Loss in iteration no. 62365 ==> 0.5250938356628782\n",
            "Loss in iteration no. 62366 ==> 0.5250924373015126\n",
            "Loss in iteration no. 62367 ==> 0.5250910389549583\n",
            "Loss in iteration no. 62368 ==> 0.5250896406232152\n",
            "Loss in iteration no. 62369 ==> 0.5250882423062827\n",
            "Loss in iteration no. 62370 ==> 0.5250868440041608\n",
            "Loss in iteration no. 62371 ==> 0.5250854457168495\n",
            "Loss in iteration no. 62372 ==> 0.5250840474443482\n",
            "Loss in iteration no. 62373 ==> 0.5250826491866568\n",
            "Loss in iteration no. 62374 ==> 0.5250812509437749\n",
            "Loss in iteration no. 62375 ==> 0.5250798527157025\n",
            "Loss in iteration no. 62376 ==> 0.5250784545024393\n",
            "Loss in iteration no. 62377 ==> 0.525077056303985\n",
            "Loss in iteration no. 62378 ==> 0.5250756581203393\n",
            "Loss in iteration no. 62379 ==> 0.5250742599515023\n",
            "Loss in iteration no. 62380 ==> 0.5250728617974733\n",
            "Loss in iteration no. 62381 ==> 0.5250714636582523\n",
            "Loss in iteration no. 62382 ==> 0.5250700655338392\n",
            "Loss in iteration no. 62383 ==> 0.5250686674242334\n",
            "Loss in iteration no. 62384 ==> 0.525067269329435\n",
            "Loss in iteration no. 62385 ==> 0.5250658712494437\n",
            "Loss in iteration no. 62386 ==> 0.5250644731842592\n",
            "Loss in iteration no. 62387 ==> 0.5250630751338811\n",
            "Loss in iteration no. 62388 ==> 0.5250616770983094\n",
            "Loss in iteration no. 62389 ==> 0.5250602790775439\n",
            "Loss in iteration no. 62390 ==> 0.525058881071584\n",
            "Loss in iteration no. 62391 ==> 0.52505748308043\n",
            "Loss in iteration no. 62392 ==> 0.5250560851040814\n",
            "Loss in iteration no. 62393 ==> 0.5250546871425378\n",
            "Loss in iteration no. 62394 ==> 0.5250532891957991\n",
            "Loss in iteration no. 62395 ==> 0.5250518912638652\n",
            "Loss in iteration no. 62396 ==> 0.5250504933467356\n",
            "Loss in iteration no. 62397 ==> 0.5250490954444104\n",
            "Loss in iteration no. 62398 ==> 0.525047697556889\n",
            "Loss in iteration no. 62399 ==> 0.5250462996841713\n",
            "Loss in iteration no. 62400 ==> 0.5250449018262572\n",
            "Loss in iteration no. 62401 ==> 0.5250435039831463\n",
            "Loss in iteration no. 62402 ==> 0.5250421061548385\n",
            "Loss in iteration no. 62403 ==> 0.5250407083413334\n",
            "Loss in iteration no. 62404 ==> 0.5250393105426309\n",
            "Loss in iteration no. 62405 ==> 0.5250379127587307\n",
            "Loss in iteration no. 62406 ==> 0.5250365149896327\n",
            "Loss in iteration no. 62407 ==> 0.5250351172353364\n",
            "Loss in iteration no. 62408 ==> 0.5250337194958417\n",
            "Loss in iteration no. 62409 ==> 0.5250323217711483\n",
            "Loss in iteration no. 62410 ==> 0.5250309240612564\n",
            "Loss in iteration no. 62411 ==> 0.525029526366165\n",
            "Loss in iteration no. 62412 ==> 0.5250281286858743\n",
            "Loss in iteration no. 62413 ==> 0.5250267310203842\n",
            "Loss in iteration no. 62414 ==> 0.5250253333696944\n",
            "Loss in iteration no. 62415 ==> 0.5250239357338042\n",
            "Loss in iteration no. 62416 ==> 0.5250225381127139\n",
            "Loss in iteration no. 62417 ==> 0.5250211405064231\n",
            "Loss in iteration no. 62418 ==> 0.5250197429149315\n",
            "Loss in iteration no. 62419 ==> 0.5250183453382391\n",
            "Loss in iteration no. 62420 ==> 0.5250169477763452\n",
            "Loss in iteration no. 62421 ==> 0.52501555022925\n",
            "Loss in iteration no. 62422 ==> 0.525014152696953\n",
            "Loss in iteration no. 62423 ==> 0.5250127551794541\n",
            "Loss in iteration no. 62424 ==> 0.5250113576767531\n",
            "Loss in iteration no. 62425 ==> 0.5250099601888496\n",
            "Loss in iteration no. 62426 ==> 0.5250085627157434\n",
            "Loss in iteration no. 62427 ==> 0.5250071652574345\n",
            "Loss in iteration no. 62428 ==> 0.5250057678139224\n",
            "Loss in iteration no. 62429 ==> 0.5250043703852069\n",
            "Loss in iteration no. 62430 ==> 0.5250029729712878\n",
            "Loss in iteration no. 62431 ==> 0.5250015755721651\n",
            "Loss in iteration no. 62432 ==> 0.5250001781878381\n",
            "Loss in iteration no. 62433 ==> 0.5249987808183069\n",
            "Loss in iteration no. 62434 ==> 0.5249973834635712\n",
            "Loss in iteration no. 62435 ==> 0.5249959861236306\n",
            "Loss in iteration no. 62436 ==> 0.524994588798485\n",
            "Loss in iteration no. 62437 ==> 0.5249931914881344\n",
            "Loss in iteration no. 62438 ==> 0.5249917941925781\n",
            "Loss in iteration no. 62439 ==> 0.5249903969118161\n",
            "Loss in iteration no. 62440 ==> 0.5249889996458484\n",
            "Loss in iteration no. 62441 ==> 0.5249876023946742\n",
            "Loss in iteration no. 62442 ==> 0.5249862051582938\n",
            "Loss in iteration no. 62443 ==> 0.5249848079367067\n",
            "Loss in iteration no. 62444 ==> 0.5249834107299127\n",
            "Loss in iteration no. 62445 ==> 0.5249820135379115\n",
            "Loss in iteration no. 62446 ==> 0.524980616360703\n",
            "Loss in iteration no. 62447 ==> 0.5249792191982868\n",
            "Loss in iteration no. 62448 ==> 0.5249778220506627\n",
            "Loss in iteration no. 62449 ==> 0.5249764249178308\n",
            "Loss in iteration no. 62450 ==> 0.5249750277997904\n",
            "Loss in iteration no. 62451 ==> 0.5249736306965417\n",
            "Loss in iteration no. 62452 ==> 0.5249722336080841\n",
            "Loss in iteration no. 62453 ==> 0.5249708365344173\n",
            "Loss in iteration no. 62454 ==> 0.5249694394755416\n",
            "Loss in iteration no. 62455 ==> 0.524968042431456\n",
            "Loss in iteration no. 62456 ==> 0.5249666454021609\n",
            "Loss in iteration no. 62457 ==> 0.5249652483876559\n",
            "Loss in iteration no. 62458 ==> 0.5249638513879405\n",
            "Loss in iteration no. 62459 ==> 0.524962454403015\n",
            "Loss in iteration no. 62460 ==> 0.5249610574328786\n",
            "Loss in iteration no. 62461 ==> 0.5249596604775313\n",
            "Loss in iteration no. 62462 ==> 0.524958263536973\n",
            "Loss in iteration no. 62463 ==> 0.5249568666112032\n",
            "Loss in iteration no. 62464 ==> 0.5249554697002218\n",
            "Loss in iteration no. 62465 ==> 0.5249540728040287\n",
            "Loss in iteration no. 62466 ==> 0.5249526759226232\n",
            "Loss in iteration no. 62467 ==> 0.5249512790560056\n",
            "Loss in iteration no. 62468 ==> 0.5249498822041756\n",
            "Loss in iteration no. 62469 ==> 0.5249484853671326\n",
            "Loss in iteration no. 62470 ==> 0.5249470885448766\n",
            "Loss in iteration no. 62471 ==> 0.5249456917374075\n",
            "Loss in iteration no. 62472 ==> 0.5249442949447247\n",
            "Loss in iteration no. 62473 ==> 0.5249428981668283\n",
            "Loss in iteration no. 62474 ==> 0.5249415014037179\n",
            "Loss in iteration no. 62475 ==> 0.5249401046553932\n",
            "Loss in iteration no. 62476 ==> 0.5249387079218543\n",
            "Loss in iteration no. 62477 ==> 0.5249373112031005\n",
            "Loss in iteration no. 62478 ==> 0.5249359144991318\n",
            "Loss in iteration no. 62479 ==> 0.524934517809948\n",
            "Loss in iteration no. 62480 ==> 0.524933121135549\n",
            "Loss in iteration no. 62481 ==> 0.5249317244759341\n",
            "Loss in iteration no. 62482 ==> 0.5249303278311035\n",
            "Loss in iteration no. 62483 ==> 0.5249289312010568\n",
            "Loss in iteration no. 62484 ==> 0.5249275345857938\n",
            "Loss in iteration no. 62485 ==> 0.5249261379853143\n",
            "Loss in iteration no. 62486 ==> 0.5249247413996179\n",
            "Loss in iteration no. 62487 ==> 0.5249233448287044\n",
            "Loss in iteration no. 62488 ==> 0.5249219482725738\n",
            "Loss in iteration no. 62489 ==> 0.5249205517312256\n",
            "Loss in iteration no. 62490 ==> 0.5249191552046597\n",
            "Loss in iteration no. 62491 ==> 0.5249177586928757\n",
            "Loss in iteration no. 62492 ==> 0.5249163621958737\n",
            "Loss in iteration no. 62493 ==> 0.5249149657136531\n",
            "Loss in iteration no. 62494 ==> 0.5249135692462139\n",
            "Loss in iteration no. 62495 ==> 0.5249121727935558\n",
            "Loss in iteration no. 62496 ==> 0.5249107763556785\n",
            "Loss in iteration no. 62497 ==> 0.5249093799325818\n",
            "Loss in iteration no. 62498 ==> 0.5249079835242656\n",
            "Loss in iteration no. 62499 ==> 0.5249065871307295\n",
            "Loss in iteration no. 62500 ==> 0.5249051907519732\n",
            "Loss in iteration no. 62501 ==> 0.5249037943879966\n",
            "Loss in iteration no. 62502 ==> 0.5249023980387995\n",
            "Loss in iteration no. 62503 ==> 0.5249010017043817\n",
            "Loss in iteration no. 62504 ==> 0.5248996053847426\n",
            "Loss in iteration no. 62505 ==> 0.5248982090798824\n",
            "Loss in iteration no. 62506 ==> 0.5248968127898008\n",
            "Loss in iteration no. 62507 ==> 0.5248954165144972\n",
            "Loss in iteration no. 62508 ==> 0.5248940202539717\n",
            "Loss in iteration no. 62509 ==> 0.5248926240082241\n",
            "Loss in iteration no. 62510 ==> 0.5248912277772539\n",
            "Loss in iteration no. 62511 ==> 0.5248898315610611\n",
            "Loss in iteration no. 62512 ==> 0.5248884353596455\n",
            "Loss in iteration no. 62513 ==> 0.5248870391730065\n",
            "Loss in iteration no. 62514 ==> 0.5248856430011444\n",
            "Loss in iteration no. 62515 ==> 0.5248842468440584\n",
            "Loss in iteration no. 62516 ==> 0.5248828507017487\n",
            "Loss in iteration no. 62517 ==> 0.5248814545742149\n",
            "Loss in iteration no. 62518 ==> 0.5248800584614566\n",
            "Loss in iteration no. 62519 ==> 0.5248786623634739\n",
            "Loss in iteration no. 62520 ==> 0.5248772662802663\n",
            "Loss in iteration no. 62521 ==> 0.5248758702118338\n",
            "Loss in iteration no. 62522 ==> 0.5248744741581758\n",
            "Loss in iteration no. 62523 ==> 0.5248730781192925\n",
            "Loss in iteration no. 62524 ==> 0.5248716820951834\n",
            "Loss in iteration no. 62525 ==> 0.5248702860858483\n",
            "Loss in iteration no. 62526 ==> 0.524868890091287\n",
            "Loss in iteration no. 62527 ==> 0.5248674941114991\n",
            "Loss in iteration no. 62528 ==> 0.5248660981464849\n",
            "Loss in iteration no. 62529 ==> 0.5248647021962434\n",
            "Loss in iteration no. 62530 ==> 0.5248633062607748\n",
            "Loss in iteration no. 62531 ==> 0.5248619103400789\n",
            "Loss in iteration no. 62532 ==> 0.5248605144341553\n",
            "Loss in iteration no. 62533 ==> 0.5248591185430039\n",
            "Loss in iteration no. 62534 ==> 0.5248577226666243\n",
            "Loss in iteration no. 62535 ==> 0.5248563268050166\n",
            "Loss in iteration no. 62536 ==> 0.5248549309581801\n",
            "Loss in iteration no. 62537 ==> 0.5248535351261148\n",
            "Loss in iteration no. 62538 ==> 0.5248521393088206\n",
            "Loss in iteration no. 62539 ==> 0.524850743506297\n",
            "Loss in iteration no. 62540 ==> 0.5248493477185441\n",
            "Loss in iteration no. 62541 ==> 0.5248479519455612\n",
            "Loss in iteration no. 62542 ==> 0.5248465561873485\n",
            "Loss in iteration no. 62543 ==> 0.5248451604439055\n",
            "Loss in iteration no. 62544 ==> 0.524843764715232\n",
            "Loss in iteration no. 62545 ==> 0.5248423690013279\n",
            "Loss in iteration no. 62546 ==> 0.5248409733021927\n",
            "Loss in iteration no. 62547 ==> 0.5248395776178265\n",
            "Loss in iteration no. 62548 ==> 0.524838181948229\n",
            "Loss in iteration no. 62549 ==> 0.5248367862933996\n",
            "Loss in iteration no. 62550 ==> 0.5248353906533385\n",
            "Loss in iteration no. 62551 ==> 0.5248339950280454\n",
            "Loss in iteration no. 62552 ==> 0.5248325994175197\n",
            "Loss in iteration no. 62553 ==> 0.5248312038217617\n",
            "Loss in iteration no. 62554 ==> 0.5248298082407707\n",
            "Loss in iteration no. 62555 ==> 0.5248284126745467\n",
            "Loss in iteration no. 62556 ==> 0.5248270171230895\n",
            "Loss in iteration no. 62557 ==> 0.5248256215863988\n",
            "Loss in iteration no. 62558 ==> 0.5248242260644743\n",
            "Loss in iteration no. 62559 ==> 0.5248228305573157\n",
            "Loss in iteration no. 62560 ==> 0.524821435064923\n",
            "Loss in iteration no. 62561 ==> 0.524820039587296\n",
            "Loss in iteration no. 62562 ==> 0.524818644124434\n",
            "Loss in iteration no. 62563 ==> 0.5248172486763373\n",
            "Loss in iteration no. 62564 ==> 0.5248158532430053\n",
            "Loss in iteration no. 62565 ==> 0.524814457824438\n",
            "Loss in iteration no. 62566 ==> 0.5248130624206351\n",
            "Loss in iteration no. 62567 ==> 0.5248116670315963\n",
            "Loss in iteration no. 62568 ==> 0.5248102716573213\n",
            "Loss in iteration no. 62569 ==> 0.5248088762978101\n",
            "Loss in iteration no. 62570 ==> 0.5248074809530623\n",
            "Loss in iteration no. 62571 ==> 0.5248060856230777\n",
            "Loss in iteration no. 62572 ==> 0.524804690307856\n",
            "Loss in iteration no. 62573 ==> 0.524803295007397\n",
            "Loss in iteration no. 62574 ==> 0.5248018997217005\n",
            "Loss in iteration no. 62575 ==> 0.5248005044507664\n",
            "Loss in iteration no. 62576 ==> 0.5247991091945943\n",
            "Loss in iteration no. 62577 ==> 0.5247977139531839\n",
            "Loss in iteration no. 62578 ==> 0.524796318726535\n",
            "Loss in iteration no. 62579 ==> 0.5247949235146476\n",
            "Loss in iteration no. 62580 ==> 0.5247935283175211\n",
            "Loss in iteration no. 62581 ==> 0.5247921331351555\n",
            "Loss in iteration no. 62582 ==> 0.5247907379675505\n",
            "Loss in iteration no. 62583 ==> 0.5247893428147059\n",
            "Loss in iteration no. 62584 ==> 0.5247879476766213\n",
            "Loss in iteration no. 62585 ==> 0.5247865525532968\n",
            "Loss in iteration no. 62586 ==> 0.5247851574447319\n",
            "Loss in iteration no. 62587 ==> 0.5247837623509265\n",
            "Loss in iteration no. 62588 ==> 0.5247823672718801\n",
            "Loss in iteration no. 62589 ==> 0.5247809722075928\n",
            "Loss in iteration no. 62590 ==> 0.5247795771580643\n",
            "Loss in iteration no. 62591 ==> 0.5247781821232942\n",
            "Loss in iteration no. 62592 ==> 0.5247767871032822\n",
            "Loss in iteration no. 62593 ==> 0.5247753920980286\n",
            "Loss in iteration no. 62594 ==> 0.5247739971075325\n",
            "Loss in iteration no. 62595 ==> 0.524772602131794\n",
            "Loss in iteration no. 62596 ==> 0.5247712071708128\n",
            "Loss in iteration no. 62597 ==> 0.5247698122245887\n",
            "Loss in iteration no. 62598 ==> 0.5247684172931215\n",
            "Loss in iteration no. 62599 ==> 0.5247670223764109\n",
            "Loss in iteration no. 62600 ==> 0.5247656274744568\n",
            "Loss in iteration no. 62601 ==> 0.5247642325872587\n",
            "Loss in iteration no. 62602 ==> 0.5247628377148165\n",
            "Loss in iteration no. 62603 ==> 0.52476144285713\n",
            "Loss in iteration no. 62604 ==> 0.524760048014199\n",
            "Loss in iteration no. 62605 ==> 0.524758653186023\n",
            "Loss in iteration no. 62606 ==> 0.5247572583726022\n",
            "Loss in iteration no. 62607 ==> 0.524755863573936\n",
            "Loss in iteration no. 62608 ==> 0.5247544687900243\n",
            "Loss in iteration no. 62609 ==> 0.5247530740208669\n",
            "Loss in iteration no. 62610 ==> 0.5247516792664636\n",
            "Loss in iteration no. 62611 ==> 0.5247502845268139\n",
            "Loss in iteration no. 62612 ==> 0.524748889801918\n",
            "Loss in iteration no. 62613 ==> 0.5247474950917752\n",
            "Loss in iteration no. 62614 ==> 0.5247461003963857\n",
            "Loss in iteration no. 62615 ==> 0.5247447057157487\n",
            "Loss in iteration no. 62616 ==> 0.5247433110498646\n",
            "Loss in iteration no. 62617 ==> 0.524741916398733\n",
            "Loss in iteration no. 62618 ==> 0.5247405217623534\n",
            "Loss in iteration no. 62619 ==> 0.5247391271407257\n",
            "Loss in iteration no. 62620 ==> 0.5247377325338496\n",
            "Loss in iteration no. 62621 ==> 0.5247363379417251\n",
            "Loss in iteration no. 62622 ==> 0.5247349433643518\n",
            "Loss in iteration no. 62623 ==> 0.5247335488017294\n",
            "Loss in iteration no. 62624 ==> 0.5247321542538577\n",
            "Loss in iteration no. 62625 ==> 0.5247307597207365\n",
            "Loss in iteration no. 62626 ==> 0.5247293652023657\n",
            "Loss in iteration no. 62627 ==> 0.5247279706987448\n",
            "Loss in iteration no. 62628 ==> 0.5247265762098736\n",
            "Loss in iteration no. 62629 ==> 0.5247251817357522\n",
            "Loss in iteration no. 62630 ==> 0.5247237872763801\n",
            "Loss in iteration no. 62631 ==> 0.5247223928317571\n",
            "Loss in iteration no. 62632 ==> 0.5247209984018829\n",
            "Loss in iteration no. 62633 ==> 0.5247196039867574\n",
            "Loss in iteration no. 62634 ==> 0.5247182095863802\n",
            "Loss in iteration no. 62635 ==> 0.5247168152007513\n",
            "Loss in iteration no. 62636 ==> 0.5247154208298701\n",
            "Loss in iteration no. 62637 ==> 0.5247140264737366\n",
            "Loss in iteration no. 62638 ==> 0.5247126321323508\n",
            "Loss in iteration no. 62639 ==> 0.524711237805712\n",
            "Loss in iteration no. 62640 ==> 0.5247098434938202\n",
            "Loss in iteration no. 62641 ==> 0.5247084491966753\n",
            "Loss in iteration no. 62642 ==> 0.5247070549142768\n",
            "Loss in iteration no. 62643 ==> 0.5247056606466245\n",
            "Loss in iteration no. 62644 ==> 0.5247042663937183\n",
            "Loss in iteration no. 62645 ==> 0.524702872155558\n",
            "Loss in iteration no. 62646 ==> 0.5247014779321434\n",
            "Loss in iteration no. 62647 ==> 0.5247000837234739\n",
            "Loss in iteration no. 62648 ==> 0.5246986895295493\n",
            "Loss in iteration no. 62649 ==> 0.52469729535037\n",
            "Loss in iteration no. 62650 ==> 0.5246959011859352\n",
            "Loss in iteration no. 62651 ==> 0.5246945070362448\n",
            "Loss in iteration no. 62652 ==> 0.5246931129012984\n",
            "Loss in iteration no. 62653 ==> 0.5246917187810961\n",
            "Loss in iteration no. 62654 ==> 0.5246903246756376\n",
            "Loss in iteration no. 62655 ==> 0.5246889305849223\n",
            "Loss in iteration no. 62656 ==> 0.5246875365089504\n",
            "Loss in iteration no. 62657 ==> 0.5246861424477214\n",
            "Loss in iteration no. 62658 ==> 0.5246847484012352\n",
            "Loss in iteration no. 62659 ==> 0.5246833543694915\n",
            "Loss in iteration no. 62660 ==> 0.5246819603524902\n",
            "Loss in iteration no. 62661 ==> 0.5246805663502307\n",
            "Loss in iteration no. 62662 ==> 0.5246791723627133\n",
            "Loss in iteration no. 62663 ==> 0.5246777783899373\n",
            "Loss in iteration no. 62664 ==> 0.5246763844319028\n",
            "Loss in iteration no. 62665 ==> 0.5246749904886093\n",
            "Loss in iteration no. 62666 ==> 0.5246735965600567\n",
            "Loss in iteration no. 62667 ==> 0.5246722026462447\n",
            "Loss in iteration no. 62668 ==> 0.5246708087471733\n",
            "Loss in iteration no. 62669 ==> 0.5246694148628419\n",
            "Loss in iteration no. 62670 ==> 0.5246680209932506\n",
            "Loss in iteration no. 62671 ==> 0.5246666271383988\n",
            "Loss in iteration no. 62672 ==> 0.5246652332982865\n",
            "Loss in iteration no. 62673 ==> 0.5246638394729135\n",
            "Loss in iteration no. 62674 ==> 0.5246624456622796\n",
            "Loss in iteration no. 62675 ==> 0.5246610518663843\n",
            "Loss in iteration no. 62676 ==> 0.5246596580852276\n",
            "Loss in iteration no. 62677 ==> 0.5246582643188094\n",
            "Loss in iteration no. 62678 ==> 0.524656870567129\n",
            "Loss in iteration no. 62679 ==> 0.5246554768301865\n",
            "Loss in iteration no. 62680 ==> 0.5246540831079817\n",
            "Loss in iteration no. 62681 ==> 0.5246526894005141\n",
            "Loss in iteration no. 62682 ==> 0.5246512957077838\n",
            "Loss in iteration no. 62683 ==> 0.5246499020297902\n",
            "Loss in iteration no. 62684 ==> 0.5246485083665334\n",
            "Loss in iteration no. 62685 ==> 0.5246471147180131\n",
            "Loss in iteration no. 62686 ==> 0.5246457210842288\n",
            "Loss in iteration no. 62687 ==> 0.5246443274651805\n",
            "Loss in iteration no. 62688 ==> 0.5246429338608678\n",
            "Loss in iteration no. 62689 ==> 0.5246415402712907\n",
            "Loss in iteration no. 62690 ==> 0.524640146696449\n",
            "Loss in iteration no. 62691 ==> 0.5246387531363422\n",
            "Loss in iteration no. 62692 ==> 0.5246373595909701\n",
            "Loss in iteration no. 62693 ==> 0.5246359660603327\n",
            "Loss in iteration no. 62694 ==> 0.5246345725444297\n",
            "Loss in iteration no. 62695 ==> 0.5246331790432605\n",
            "Loss in iteration no. 62696 ==> 0.5246317855568252\n",
            "Loss in iteration no. 62697 ==> 0.5246303920851237\n",
            "Loss in iteration no. 62698 ==> 0.5246289986281555\n",
            "Loss in iteration no. 62699 ==> 0.5246276051859203\n",
            "Loss in iteration no. 62700 ==> 0.5246262117584181\n",
            "Loss in iteration no. 62701 ==> 0.5246248183456487\n",
            "Loss in iteration no. 62702 ==> 0.5246234249476115\n",
            "Loss in iteration no. 62703 ==> 0.5246220315643066\n",
            "Loss in iteration no. 62704 ==> 0.5246206381957339\n",
            "Loss in iteration no. 62705 ==> 0.5246192448418926\n",
            "Loss in iteration no. 62706 ==> 0.524617851502783\n",
            "Loss in iteration no. 62707 ==> 0.5246164581784046\n",
            "Loss in iteration no. 62708 ==> 0.5246150648687572\n",
            "Loss in iteration no. 62709 ==> 0.5246136715738406\n",
            "Loss in iteration no. 62710 ==> 0.5246122782936545\n",
            "Loss in iteration no. 62711 ==> 0.5246108850281989\n",
            "Loss in iteration no. 62712 ==> 0.5246094917774733\n",
            "Loss in iteration no. 62713 ==> 0.5246080985414776\n",
            "Loss in iteration no. 62714 ==> 0.5246067053202116\n",
            "Loss in iteration no. 62715 ==> 0.5246053121136749\n",
            "Loss in iteration no. 62716 ==> 0.5246039189218673\n",
            "Loss in iteration no. 62717 ==> 0.5246025257447886\n",
            "Loss in iteration no. 62718 ==> 0.5246011325824387\n",
            "Loss in iteration no. 62719 ==> 0.5245997394348172\n",
            "Loss in iteration no. 62720 ==> 0.5245983463019239\n",
            "Loss in iteration no. 62721 ==> 0.5245969531837588\n",
            "Loss in iteration no. 62722 ==> 0.5245955600803212\n",
            "Loss in iteration no. 62723 ==> 0.5245941669916111\n",
            "Loss in iteration no. 62724 ==> 0.5245927739176285\n",
            "Loss in iteration no. 62725 ==> 0.5245913808583728\n",
            "Loss in iteration no. 62726 ==> 0.524589987813844\n",
            "Loss in iteration no. 62727 ==> 0.5245885947840416\n",
            "Loss in iteration no. 62728 ==> 0.5245872017689657\n",
            "Loss in iteration no. 62729 ==> 0.5245858087686158\n",
            "Loss in iteration no. 62730 ==> 0.524584415782992\n",
            "Loss in iteration no. 62731 ==> 0.5245830228120936\n",
            "Loss in iteration no. 62732 ==> 0.5245816298559207\n",
            "Loss in iteration no. 62733 ==> 0.5245802369144731\n",
            "Loss in iteration no. 62734 ==> 0.5245788439877502\n",
            "Loss in iteration no. 62735 ==> 0.5245774510757522\n",
            "Loss in iteration no. 62736 ==> 0.5245760581784786\n",
            "Loss in iteration no. 62737 ==> 0.5245746652959292\n",
            "Loss in iteration no. 62738 ==> 0.524573272428104\n",
            "Loss in iteration no. 62739 ==> 0.5245718795750023\n",
            "Loss in iteration no. 62740 ==> 0.5245704867366244\n",
            "Loss in iteration no. 62741 ==> 0.5245690939129697\n",
            "Loss in iteration no. 62742 ==> 0.5245677011040379\n",
            "Loss in iteration no. 62743 ==> 0.5245663083098291\n",
            "Loss in iteration no. 62744 ==> 0.5245649155303428\n",
            "Loss in iteration no. 62745 ==> 0.5245635227655789\n",
            "Loss in iteration no. 62746 ==> 0.5245621300155372\n",
            "Loss in iteration no. 62747 ==> 0.5245607372802173\n",
            "Loss in iteration no. 62748 ==> 0.5245593445596192\n",
            "Loss in iteration no. 62749 ==> 0.5245579518537424\n",
            "Loss in iteration no. 62750 ==> 0.5245565591625867\n",
            "Loss in iteration no. 62751 ==> 0.5245551664861523\n",
            "Loss in iteration no. 62752 ==> 0.5245537738244385\n",
            "Loss in iteration no. 62753 ==> 0.5245523811774451\n",
            "Loss in iteration no. 62754 ==> 0.5245509885451719\n",
            "Loss in iteration no. 62755 ==> 0.5245495959276187\n",
            "Loss in iteration no. 62756 ==> 0.5245482033247855\n",
            "Loss in iteration no. 62757 ==> 0.5245468107366716\n",
            "Loss in iteration no. 62758 ==> 0.5245454181632772\n",
            "Loss in iteration no. 62759 ==> 0.5245440256046019\n",
            "Loss in iteration no. 62760 ==> 0.5245426330606454\n",
            "Loss in iteration no. 62761 ==> 0.5245412405314075\n",
            "Loss in iteration no. 62762 ==> 0.524539848016888\n",
            "Loss in iteration no. 62763 ==> 0.5245384555170868\n",
            "Loss in iteration no. 62764 ==> 0.5245370630320033\n",
            "Loss in iteration no. 62765 ==> 0.5245356705616375\n",
            "Loss in iteration no. 62766 ==> 0.5245342781059893\n",
            "Loss in iteration no. 62767 ==> 0.5245328856650582\n",
            "Loss in iteration no. 62768 ==> 0.5245314932388441\n",
            "Loss in iteration no. 62769 ==> 0.5245301008273467\n",
            "Loss in iteration no. 62770 ==> 0.5245287084305659\n",
            "Loss in iteration no. 62771 ==> 0.5245273160485013\n",
            "Loss in iteration no. 62772 ==> 0.5245259236811528\n",
            "Loss in iteration no. 62773 ==> 0.5245245313285202\n",
            "Loss in iteration no. 62774 ==> 0.524523138990603\n",
            "Loss in iteration no. 62775 ==> 0.5245217466674013\n",
            "Loss in iteration no. 62776 ==> 0.5245203543589146\n",
            "Loss in iteration no. 62777 ==> 0.5245189620651428\n",
            "Loss in iteration no. 62778 ==> 0.5245175697860857\n",
            "Loss in iteration no. 62779 ==> 0.524516177521743\n",
            "Loss in iteration no. 62780 ==> 0.5245147852721144\n",
            "Loss in iteration no. 62781 ==> 0.5245133930371997\n",
            "Loss in iteration no. 62782 ==> 0.5245120008169988\n",
            "Loss in iteration no. 62783 ==> 0.5245106086115112\n",
            "Loss in iteration no. 62784 ==> 0.524509216420737\n",
            "Loss in iteration no. 62785 ==> 0.5245078242446759\n",
            "Loss in iteration no. 62786 ==> 0.5245064320833275\n",
            "Loss in iteration no. 62787 ==> 0.5245050399366915\n",
            "Loss in iteration no. 62788 ==> 0.524503647804768\n",
            "Loss in iteration no. 62789 ==> 0.5245022556875564\n",
            "Loss in iteration no. 62790 ==> 0.5245008635850567\n",
            "Loss in iteration no. 62791 ==> 0.5244994714972685\n",
            "Loss in iteration no. 62792 ==> 0.5244980794241918\n",
            "Loss in iteration no. 62793 ==> 0.5244966873658264\n",
            "Loss in iteration no. 62794 ==> 0.5244952953221717\n",
            "Loss in iteration no. 62795 ==> 0.5244939032932275\n",
            "Loss in iteration no. 62796 ==> 0.5244925112789939\n",
            "Loss in iteration no. 62797 ==> 0.5244911192794708\n",
            "Loss in iteration no. 62798 ==> 0.524489727294657\n",
            "Loss in iteration no. 62799 ==> 0.5244883353245535\n",
            "Loss in iteration no. 62800 ==> 0.5244869433691592\n",
            "Loss in iteration no. 62801 ==> 0.5244855514284742\n",
            "Loss in iteration no. 62802 ==> 0.5244841595024983\n",
            "Loss in iteration no. 62803 ==> 0.5244827675912311\n",
            "Loss in iteration no. 62804 ==> 0.5244813756946727\n",
            "Loss in iteration no. 62805 ==> 0.5244799838128223\n",
            "Loss in iteration no. 62806 ==> 0.5244785919456803\n",
            "Loss in iteration no. 62807 ==> 0.5244772000932459\n",
            "Loss in iteration no. 62808 ==> 0.5244758082555193\n",
            "Loss in iteration no. 62809 ==> 0.5244744164324999\n",
            "Loss in iteration no. 62810 ==> 0.5244730246241879\n",
            "Loss in iteration no. 62811 ==> 0.5244716328305827\n",
            "Loss in iteration no. 62812 ==> 0.5244702410516842\n",
            "Loss in iteration no. 62813 ==> 0.5244688492874922\n",
            "Loss in iteration no. 62814 ==> 0.5244674575380065\n",
            "Loss in iteration no. 62815 ==> 0.5244660658032264\n",
            "Loss in iteration no. 62816 ==> 0.5244646740831523\n",
            "Loss in iteration no. 62817 ==> 0.5244632823777838\n",
            "Loss in iteration no. 62818 ==> 0.5244618906871206\n",
            "Loss in iteration no. 62819 ==> 0.5244604990111623\n",
            "Loss in iteration no. 62820 ==> 0.524459107349909\n",
            "Loss in iteration no. 62821 ==> 0.5244577157033602\n",
            "Loss in iteration no. 62822 ==> 0.5244563240715157\n",
            "Loss in iteration no. 62823 ==> 0.5244549324543754\n",
            "Loss in iteration no. 62824 ==> 0.524453540851939\n",
            "Loss in iteration no. 62825 ==> 0.5244521492642062\n",
            "Loss in iteration no. 62826 ==> 0.5244507576911769\n",
            "Loss in iteration no. 62827 ==> 0.5244493661328505\n",
            "Loss in iteration no. 62828 ==> 0.5244479745892273\n",
            "Loss in iteration no. 62829 ==> 0.5244465830603068\n",
            "Loss in iteration no. 62830 ==> 0.5244451915460887\n",
            "Loss in iteration no. 62831 ==> 0.5244438000465731\n",
            "Loss in iteration no. 62832 ==> 0.5244424085617592\n",
            "Loss in iteration no. 62833 ==> 0.5244410170916474\n",
            "Loss in iteration no. 62834 ==> 0.5244396256362368\n",
            "Loss in iteration no. 62835 ==> 0.5244382341955277\n",
            "Loss in iteration no. 62836 ==> 0.5244368427695195\n",
            "Loss in iteration no. 62837 ==> 0.5244354513582125\n",
            "Loss in iteration no. 62838 ==> 0.5244340599616059\n",
            "Loss in iteration no. 62839 ==> 0.5244326685796997\n",
            "Loss in iteration no. 62840 ==> 0.5244312772124936\n",
            "Loss in iteration no. 62841 ==> 0.5244298858599874\n",
            "Loss in iteration no. 62842 ==> 0.5244284945221811\n",
            "Loss in iteration no. 62843 ==> 0.5244271031990739\n",
            "Loss in iteration no. 62844 ==> 0.5244257118906663\n",
            "Loss in iteration no. 62845 ==> 0.5244243205969574\n",
            "Loss in iteration no. 62846 ==> 0.5244229293179473\n",
            "Loss in iteration no. 62847 ==> 0.5244215380536359\n",
            "Loss in iteration no. 62848 ==> 0.5244201468040226\n",
            "Loss in iteration no. 62849 ==> 0.5244187555691073\n",
            "Loss in iteration no. 62850 ==> 0.5244173643488899\n",
            "Loss in iteration no. 62851 ==> 0.5244159731433701\n",
            "Loss in iteration no. 62852 ==> 0.5244145819525475\n",
            "Loss in iteration no. 62853 ==> 0.5244131907764222\n",
            "Loss in iteration no. 62854 ==> 0.5244117996149936\n",
            "Loss in iteration no. 62855 ==> 0.5244104084682619\n",
            "Loss in iteration no. 62856 ==> 0.5244090173362265\n",
            "Loss in iteration no. 62857 ==> 0.5244076262188871\n",
            "Loss in iteration no. 62858 ==> 0.5244062351162438\n",
            "Loss in iteration no. 62859 ==> 0.5244048440282961\n",
            "Loss in iteration no. 62860 ==> 0.524403452955044\n",
            "Loss in iteration no. 62861 ==> 0.5244020618964871\n",
            "Loss in iteration no. 62862 ==> 0.5244006708526252\n",
            "Loss in iteration no. 62863 ==> 0.5243992798234581\n",
            "Loss in iteration no. 62864 ==> 0.5243978888089855\n",
            "Loss in iteration no. 62865 ==> 0.5243964978092074\n",
            "Loss in iteration no. 62866 ==> 0.5243951068241232\n",
            "Loss in iteration no. 62867 ==> 0.5243937158537328\n",
            "Loss in iteration no. 62868 ==> 0.5243923248980361\n",
            "Loss in iteration no. 62869 ==> 0.5243909339570327\n",
            "Loss in iteration no. 62870 ==> 0.5243895430307225\n",
            "Loss in iteration no. 62871 ==> 0.5243881521191053\n",
            "Loss in iteration no. 62872 ==> 0.5243867612221808\n",
            "Loss in iteration no. 62873 ==> 0.5243853703399484\n",
            "Loss in iteration no. 62874 ==> 0.5243839794724084\n",
            "Loss in iteration no. 62875 ==> 0.5243825886195606\n",
            "Loss in iteration no. 62876 ==> 0.5243811977814044\n",
            "Loss in iteration no. 62877 ==> 0.5243798069579396\n",
            "Loss in iteration no. 62878 ==> 0.524378416149166\n",
            "Loss in iteration no. 62879 ==> 0.5243770253550836\n",
            "Loss in iteration no. 62880 ==> 0.524375634575692\n",
            "Loss in iteration no. 62881 ==> 0.524374243810991\n",
            "Loss in iteration no. 62882 ==> 0.5243728530609802\n",
            "Loss in iteration no. 62883 ==> 0.5243714623256597\n",
            "Loss in iteration no. 62884 ==> 0.5243700716050289\n",
            "Loss in iteration no. 62885 ==> 0.524368680899088\n",
            "Loss in iteration no. 62886 ==> 0.5243672902078362\n",
            "Loss in iteration no. 62887 ==> 0.5243658995312738\n",
            "Loss in iteration no. 62888 ==> 0.5243645088694002\n",
            "Loss in iteration no. 62889 ==> 0.5243631182222154\n",
            "Loss in iteration no. 62890 ==> 0.5243617275897191\n",
            "Loss in iteration no. 62891 ==> 0.524360336971911\n",
            "Loss in iteration no. 62892 ==> 0.5243589463687909\n",
            "Loss in iteration no. 62893 ==> 0.5243575557803586\n",
            "Loss in iteration no. 62894 ==> 0.5243561652066137\n",
            "Loss in iteration no. 62895 ==> 0.5243547746475563\n",
            "Loss in iteration no. 62896 ==> 0.5243533841031858\n",
            "Loss in iteration no. 62897 ==> 0.5243519935735024\n",
            "Loss in iteration no. 62898 ==> 0.5243506030585054\n",
            "Loss in iteration no. 62899 ==> 0.5243492125581948\n",
            "Loss in iteration no. 62900 ==> 0.5243478220725704\n",
            "Loss in iteration no. 62901 ==> 0.5243464316016319\n",
            "Loss in iteration no. 62902 ==> 0.5243450411453789\n",
            "Loss in iteration no. 62903 ==> 0.5243436507038115\n",
            "Loss in iteration no. 62904 ==> 0.5243422602769293\n",
            "Loss in iteration no. 62905 ==> 0.5243408698647322\n",
            "Loss in iteration no. 62906 ==> 0.5243394794672197\n",
            "Loss in iteration no. 62907 ==> 0.5243380890843917\n",
            "Loss in iteration no. 62908 ==> 0.524336698716248\n",
            "Loss in iteration no. 62909 ==> 0.5243353083627884\n",
            "Loss in iteration no. 62910 ==> 0.5243339180240125\n",
            "Loss in iteration no. 62911 ==> 0.5243325276999204\n",
            "Loss in iteration no. 62912 ==> 0.5243311373905114\n",
            "Loss in iteration no. 62913 ==> 0.5243297470957856\n",
            "Loss in iteration no. 62914 ==> 0.5243283568157426\n",
            "Loss in iteration no. 62915 ==> 0.5243269665503825\n",
            "Loss in iteration no. 62916 ==> 0.5243255762997046\n",
            "Loss in iteration no. 62917 ==> 0.5243241860637089\n",
            "Loss in iteration no. 62918 ==> 0.5243227958423952\n",
            "Loss in iteration no. 62919 ==> 0.5243214056357631\n",
            "Loss in iteration no. 62920 ==> 0.5243200154438126\n",
            "Loss in iteration no. 62921 ==> 0.5243186252665433\n",
            "Loss in iteration no. 62922 ==> 0.5243172351039551\n",
            "Loss in iteration no. 62923 ==> 0.5243158449560475\n",
            "Loss in iteration no. 62924 ==> 0.5243144548228206\n",
            "Loss in iteration no. 62925 ==> 0.5243130647042741\n",
            "Loss in iteration no. 62926 ==> 0.5243116746004074\n",
            "Loss in iteration no. 62927 ==> 0.5243102845112206\n",
            "Loss in iteration no. 62928 ==> 0.5243088944367136\n",
            "Loss in iteration no. 62929 ==> 0.5243075043768859\n",
            "Loss in iteration no. 62930 ==> 0.5243061143317375\n",
            "Loss in iteration no. 62931 ==> 0.5243047243012677\n",
            "Loss in iteration no. 62932 ==> 0.5243033342854767\n",
            "Loss in iteration no. 62933 ==> 0.5243019442843642\n",
            "Loss in iteration no. 62934 ==> 0.5243005542979299\n",
            "Loss in iteration no. 62935 ==> 0.5242991643261735\n",
            "Loss in iteration no. 62936 ==> 0.524297774369095\n",
            "Loss in iteration no. 62937 ==> 0.5242963844266939\n",
            "Loss in iteration no. 62938 ==> 0.5242949944989702\n",
            "Loss in iteration no. 62939 ==> 0.5242936045859234\n",
            "Loss in iteration no. 62940 ==> 0.5242922146875536\n",
            "Loss in iteration no. 62941 ==> 0.5242908248038601\n",
            "Loss in iteration no. 62942 ==> 0.5242894349348433\n",
            "Loss in iteration no. 62943 ==> 0.5242880450805024\n",
            "Loss in iteration no. 62944 ==> 0.5242866552408375\n",
            "Loss in iteration no. 62945 ==> 0.5242852654158482\n",
            "Loss in iteration no. 62946 ==> 0.5242838756055342\n",
            "Loss in iteration no. 62947 ==> 0.5242824858098957\n",
            "Loss in iteration no. 62948 ==> 0.524281096028932\n",
            "Loss in iteration no. 62949 ==> 0.5242797062626429\n",
            "Loss in iteration no. 62950 ==> 0.5242783165110284\n",
            "Loss in iteration no. 62951 ==> 0.5242769267740881\n",
            "Loss in iteration no. 62952 ==> 0.5242755370518218\n",
            "Loss in iteration no. 62953 ==> 0.5242741473442294\n",
            "Loss in iteration no. 62954 ==> 0.5242727576513105\n",
            "Loss in iteration no. 62955 ==> 0.5242713679730648\n",
            "Loss in iteration no. 62956 ==> 0.5242699783094925\n",
            "Loss in iteration no. 62957 ==> 0.5242685886605928\n",
            "Loss in iteration no. 62958 ==> 0.5242671990263658\n",
            "Loss in iteration no. 62959 ==> 0.5242658094068111\n",
            "Loss in iteration no. 62960 ==> 0.5242644198019287\n",
            "Loss in iteration no. 62961 ==> 0.5242630302117182\n",
            "Loss in iteration no. 62962 ==> 0.5242616406361794\n",
            "Loss in iteration no. 62963 ==> 0.5242602510753119\n",
            "Loss in iteration no. 62964 ==> 0.5242588615291158\n",
            "Loss in iteration no. 62965 ==> 0.5242574719975908\n",
            "Loss in iteration no. 62966 ==> 0.5242560824807363\n",
            "Loss in iteration no. 62967 ==> 0.5242546929785523\n",
            "Loss in iteration no. 62968 ==> 0.5242533034910388\n",
            "Loss in iteration no. 62969 ==> 0.5242519140181955\n",
            "Loss in iteration no. 62970 ==> 0.5242505245600217\n",
            "Loss in iteration no. 62971 ==> 0.5242491351165177\n",
            "Loss in iteration no. 62972 ==> 0.524247745687683\n",
            "Loss in iteration no. 62973 ==> 0.5242463562735173\n",
            "Loss in iteration no. 62974 ==> 0.5242449668740208\n",
            "Loss in iteration no. 62975 ==> 0.5242435774891927\n",
            "Loss in iteration no. 62976 ==> 0.5242421881190331\n",
            "Loss in iteration no. 62977 ==> 0.5242407987635418\n",
            "Loss in iteration no. 62978 ==> 0.5242394094227184\n",
            "Loss in iteration no. 62979 ==> 0.5242380200965627\n",
            "Loss in iteration no. 62980 ==> 0.5242366307850745\n",
            "Loss in iteration no. 62981 ==> 0.5242352414882536\n",
            "Loss in iteration no. 62982 ==> 0.5242338522060999\n",
            "Loss in iteration no. 62983 ==> 0.5242324629386127\n",
            "Loss in iteration no. 62984 ==> 0.5242310736857922\n",
            "Loss in iteration no. 62985 ==> 0.5242296844476381\n",
            "Loss in iteration no. 62986 ==> 0.52422829522415\n",
            "Loss in iteration no. 62987 ==> 0.5242269060153278\n",
            "Loss in iteration no. 62988 ==> 0.5242255168211712\n",
            "Loss in iteration no. 62989 ==> 0.5242241276416802\n",
            "Loss in iteration no. 62990 ==> 0.5242227384768543\n",
            "Loss in iteration no. 62991 ==> 0.5242213493266933\n",
            "Loss in iteration no. 62992 ==> 0.524219960191197\n",
            "Loss in iteration no. 62993 ==> 0.5242185710703653\n",
            "Loss in iteration no. 62994 ==> 0.5242171819641976\n",
            "Loss in iteration no. 62995 ==> 0.5242157928726942\n",
            "Loss in iteration no. 62996 ==> 0.5242144037958544\n",
            "Loss in iteration no. 62997 ==> 0.5242130147336781\n",
            "Loss in iteration no. 62998 ==> 0.5242116256861652\n",
            "Loss in iteration no. 62999 ==> 0.5242102366533153\n",
            "Loss in iteration no. 63000 ==> 0.5242088476351283\n",
            "Loss in iteration no. 63001 ==> 0.5242074586316041\n",
            "Loss in iteration no. 63002 ==> 0.5242060696427421\n",
            "Loss in iteration no. 63003 ==> 0.5242046806685423\n",
            "Loss in iteration no. 63004 ==> 0.5242032917090044\n",
            "Loss in iteration no. 63005 ==> 0.5242019027641281\n",
            "Loss in iteration no. 63006 ==> 0.5242005138339133\n",
            "Loss in iteration no. 63007 ==> 0.5241991249183598\n",
            "Loss in iteration no. 63008 ==> 0.5241977360174672\n",
            "Loss in iteration no. 63009 ==> 0.5241963471312354\n",
            "Loss in iteration no. 63010 ==> 0.524194958259664\n",
            "Loss in iteration no. 63011 ==> 0.5241935694027531\n",
            "Loss in iteration no. 63012 ==> 0.5241921805605022\n",
            "Loss in iteration no. 63013 ==> 0.524190791732911\n",
            "Loss in iteration no. 63014 ==> 0.5241894029199795\n",
            "Loss in iteration no. 63015 ==> 0.5241880141217073\n",
            "Loss in iteration no. 63016 ==> 0.5241866253380943\n",
            "Loss in iteration no. 63017 ==> 0.5241852365691402\n",
            "Loss in iteration no. 63018 ==> 0.5241838478148446\n",
            "Loss in iteration no. 63019 ==> 0.5241824590752076\n",
            "Loss in iteration no. 63020 ==> 0.5241810703502288\n",
            "Loss in iteration no. 63021 ==> 0.524179681639908\n",
            "Loss in iteration no. 63022 ==> 0.5241782929442448\n",
            "Loss in iteration no. 63023 ==> 0.524176904263239\n",
            "Loss in iteration no. 63024 ==> 0.5241755155968907\n",
            "Loss in iteration no. 63025 ==> 0.5241741269451993\n",
            "Loss in iteration no. 63026 ==> 0.5241727383081647\n",
            "Loss in iteration no. 63027 ==> 0.5241713496857867\n",
            "Loss in iteration no. 63028 ==> 0.5241699610780651\n",
            "Loss in iteration no. 63029 ==> 0.5241685724849996\n",
            "Loss in iteration no. 63030 ==> 0.5241671839065899\n",
            "Loss in iteration no. 63031 ==> 0.5241657953428359\n",
            "Loss in iteration no. 63032 ==> 0.5241644067937372\n",
            "Loss in iteration no. 63033 ==> 0.5241630182592938\n",
            "Loss in iteration no. 63034 ==> 0.5241616297395052\n",
            "Loss in iteration no. 63035 ==> 0.5241602412343714\n",
            "Loss in iteration no. 63036 ==> 0.5241588527438921\n",
            "Loss in iteration no. 63037 ==> 0.5241574642680671\n",
            "Loss in iteration no. 63038 ==> 0.5241560758068959\n",
            "Loss in iteration no. 63039 ==> 0.5241546873603786\n",
            "Loss in iteration no. 63040 ==> 0.5241532989285149\n",
            "Loss in iteration no. 63041 ==> 0.5241519105113046\n",
            "Loss in iteration no. 63042 ==> 0.5241505221087471\n",
            "Loss in iteration no. 63043 ==> 0.5241491337208426\n",
            "Loss in iteration no. 63044 ==> 0.5241477453475907\n",
            "Loss in iteration no. 63045 ==> 0.5241463569889914\n",
            "Loss in iteration no. 63046 ==> 0.5241449686450439\n",
            "Loss in iteration no. 63047 ==> 0.5241435803157485\n",
            "Loss in iteration no. 63048 ==> 0.5241421920011047\n",
            "Loss in iteration no. 63049 ==> 0.5241408037011125\n",
            "Loss in iteration no. 63050 ==> 0.5241394154157715\n",
            "Loss in iteration no. 63051 ==> 0.5241380271450813\n",
            "Loss in iteration no. 63052 ==> 0.5241366388890419\n",
            "Loss in iteration no. 63053 ==> 0.5241352506476532\n",
            "Loss in iteration no. 63054 ==> 0.5241338624209148\n",
            "Loss in iteration no. 63055 ==> 0.5241324742088262\n",
            "Loss in iteration no. 63056 ==> 0.5241310860113877\n",
            "Loss in iteration no. 63057 ==> 0.5241296978285988\n",
            "Loss in iteration no. 63058 ==> 0.5241283096604589\n",
            "Loss in iteration no. 63059 ==> 0.5241269215069685\n",
            "Loss in iteration no. 63060 ==> 0.524125533368127\n",
            "Loss in iteration no. 63061 ==> 0.524124145243934\n",
            "Loss in iteration no. 63062 ==> 0.5241227571343895\n",
            "Loss in iteration no. 63063 ==> 0.5241213690394931\n",
            "Loss in iteration no. 63064 ==> 0.5241199809592448\n",
            "Loss in iteration no. 63065 ==> 0.5241185928936443\n",
            "Loss in iteration no. 63066 ==> 0.5241172048426911\n",
            "Loss in iteration no. 63067 ==> 0.5241158168063854\n",
            "Loss in iteration no. 63068 ==> 0.5241144287847266\n",
            "Loss in iteration no. 63069 ==> 0.5241130407777146\n",
            "Loss in iteration no. 63070 ==> 0.5241116527853492\n",
            "Loss in iteration no. 63071 ==> 0.5241102648076302\n",
            "Loss in iteration no. 63072 ==> 0.5241088768445573\n",
            "Loss in iteration no. 63073 ==> 0.5241074888961302\n",
            "Loss in iteration no. 63074 ==> 0.5241061009623489\n",
            "Loss in iteration no. 63075 ==> 0.5241047130432128\n",
            "Loss in iteration no. 63076 ==> 0.524103325138722\n",
            "Loss in iteration no. 63077 ==> 0.5241019372488762\n",
            "Loss in iteration no. 63078 ==> 0.524100549373675\n",
            "Loss in iteration no. 63079 ==> 0.5240991615131185\n",
            "Loss in iteration no. 63080 ==> 0.5240977736672061\n",
            "Loss in iteration no. 63081 ==> 0.5240963858359378\n",
            "Loss in iteration no. 63082 ==> 0.5240949980193131\n",
            "Loss in iteration no. 63083 ==> 0.5240936102173321\n",
            "Loss in iteration no. 63084 ==> 0.5240922224299944\n",
            "Loss in iteration no. 63085 ==> 0.5240908346572999\n",
            "Loss in iteration no. 63086 ==> 0.5240894468992482\n",
            "Loss in iteration no. 63087 ==> 0.5240880591558389\n",
            "Loss in iteration no. 63088 ==> 0.5240866714270723\n",
            "Loss in iteration no. 63089 ==> 0.5240852837129478\n",
            "Loss in iteration no. 63090 ==> 0.5240838960134652\n",
            "Loss in iteration no. 63091 ==> 0.5240825083286242\n",
            "Loss in iteration no. 63092 ==> 0.5240811206584248\n",
            "Loss in iteration no. 63093 ==> 0.5240797330028667\n",
            "Loss in iteration no. 63094 ==> 0.5240783453619495\n",
            "Loss in iteration no. 63095 ==> 0.5240769577356731\n",
            "Loss in iteration no. 63096 ==> 0.5240755701240372\n",
            "Loss in iteration no. 63097 ==> 0.5240741825270416\n",
            "Loss in iteration no. 63098 ==> 0.524072794944686\n",
            "Loss in iteration no. 63099 ==> 0.5240714073769704\n",
            "Loss in iteration no. 63100 ==> 0.5240700198238943\n",
            "Loss in iteration no. 63101 ==> 0.5240686322854576\n",
            "Loss in iteration no. 63102 ==> 0.5240672447616601\n",
            "Loss in iteration no. 63103 ==> 0.5240658572525017\n",
            "Loss in iteration no. 63104 ==> 0.5240644697579817\n",
            "Loss in iteration no. 63105 ==> 0.5240630822781003\n",
            "Loss in iteration no. 63106 ==> 0.524061694812857\n",
            "Loss in iteration no. 63107 ==> 0.5240603073622518\n",
            "Loss in iteration no. 63108 ==> 0.5240589199262844\n",
            "Loss in iteration no. 63109 ==> 0.5240575325049543\n",
            "Loss in iteration no. 63110 ==> 0.5240561450982616\n",
            "Loss in iteration no. 63111 ==> 0.524054757706206\n",
            "Loss in iteration no. 63112 ==> 0.5240533703287873\n",
            "Loss in iteration no. 63113 ==> 0.524051982966005\n",
            "Loss in iteration no. 63114 ==> 0.5240505956178592\n",
            "Loss in iteration no. 63115 ==> 0.5240492082843496\n",
            "Loss in iteration no. 63116 ==> 0.5240478209654758\n",
            "Loss in iteration no. 63117 ==> 0.5240464336612376\n",
            "Loss in iteration no. 63118 ==> 0.5240450463716348\n",
            "Loss in iteration no. 63119 ==> 0.5240436590966675\n",
            "Loss in iteration no. 63120 ==> 0.5240422718363349\n",
            "Loss in iteration no. 63121 ==> 0.5240408845906371\n",
            "Loss in iteration no. 63122 ==> 0.5240394973595739\n",
            "Loss in iteration no. 63123 ==> 0.5240381101431448\n",
            "Loss in iteration no. 63124 ==> 0.5240367229413498\n",
            "Loss in iteration no. 63125 ==> 0.5240353357541888\n",
            "Loss in iteration no. 63126 ==> 0.5240339485816612\n",
            "Loss in iteration no. 63127 ==> 0.524032561423767\n",
            "Loss in iteration no. 63128 ==> 0.5240311742805059\n",
            "Loss in iteration no. 63129 ==> 0.5240297871518776\n",
            "Loss in iteration no. 63130 ==> 0.5240284000378822\n",
            "Loss in iteration no. 63131 ==> 0.524027012938519\n",
            "Loss in iteration no. 63132 ==> 0.5240256258537881\n",
            "Loss in iteration no. 63133 ==> 0.524024238783689\n",
            "Loss in iteration no. 63134 ==> 0.5240228517282218\n",
            "Loss in iteration no. 63135 ==> 0.524021464687386\n",
            "Loss in iteration no. 63136 ==> 0.5240200776611815\n",
            "Loss in iteration no. 63137 ==> 0.5240186906496079\n",
            "Loss in iteration no. 63138 ==> 0.5240173036526653\n",
            "Loss in iteration no. 63139 ==> 0.5240159166703532\n",
            "Loss in iteration no. 63140 ==> 0.5240145297026716\n",
            "Loss in iteration no. 63141 ==> 0.5240131427496197\n",
            "Loss in iteration no. 63142 ==> 0.524011755811198\n",
            "Loss in iteration no. 63143 ==> 0.5240103688874059\n",
            "Loss in iteration no. 63144 ==> 0.524008981978243\n",
            "Loss in iteration no. 63145 ==> 0.5240075950837094\n",
            "Loss in iteration no. 63146 ==> 0.5240062082038048\n",
            "Loss in iteration no. 63147 ==> 0.5240048213385289\n",
            "Loss in iteration no. 63148 ==> 0.5240034344878814\n",
            "Loss in iteration no. 63149 ==> 0.5240020476518622\n",
            "Loss in iteration no. 63150 ==> 0.5240006608304708\n",
            "Loss in iteration no. 63151 ==> 0.5239992740237077\n",
            "Loss in iteration no. 63152 ==> 0.5239978872315717\n",
            "Loss in iteration no. 63153 ==> 0.5239965004540632\n",
            "Loss in iteration no. 63154 ==> 0.5239951136911817\n",
            "Loss in iteration no. 63155 ==> 0.5239937269429271\n",
            "Loss in iteration no. 63156 ==> 0.5239923402092993\n",
            "Loss in iteration no. 63157 ==> 0.5239909534902977\n",
            "Loss in iteration no. 63158 ==> 0.5239895667859222\n",
            "Loss in iteration no. 63159 ==> 0.5239881800961728\n",
            "Loss in iteration no. 63160 ==> 0.5239867934210489\n",
            "Loss in iteration no. 63161 ==> 0.5239854067605507\n",
            "Loss in iteration no. 63162 ==> 0.5239840201146777\n",
            "Loss in iteration no. 63163 ==> 0.5239826334834295\n",
            "Loss in iteration no. 63164 ==> 0.5239812468668064\n",
            "Loss in iteration no. 63165 ==> 0.5239798602648075\n",
            "Loss in iteration no. 63166 ==> 0.5239784736774331\n",
            "Loss in iteration no. 63167 ==> 0.5239770871046827\n",
            "Loss in iteration no. 63168 ==> 0.5239757005465562\n",
            "Loss in iteration no. 63169 ==> 0.5239743140030533\n",
            "Loss in iteration no. 63170 ==> 0.5239729274741736\n",
            "Loss in iteration no. 63171 ==> 0.5239715409599173\n",
            "Loss in iteration no. 63172 ==> 0.5239701544602837\n",
            "Loss in iteration no. 63173 ==> 0.523968767975273\n",
            "Loss in iteration no. 63174 ==> 0.5239673815048846\n",
            "Loss in iteration no. 63175 ==> 0.5239659950491186\n",
            "Loss in iteration no. 63176 ==> 0.5239646086079744\n",
            "Loss in iteration no. 63177 ==> 0.5239632221814521\n",
            "Loss in iteration no. 63178 ==> 0.5239618357695512\n",
            "Loss in iteration no. 63179 ==> 0.5239604493722717\n",
            "Loss in iteration no. 63180 ==> 0.5239590629896134\n",
            "Loss in iteration no. 63181 ==> 0.5239576766215757\n",
            "Loss in iteration no. 63182 ==> 0.5239562902681587\n",
            "Loss in iteration no. 63183 ==> 0.523954903929362\n",
            "Loss in iteration no. 63184 ==> 0.5239535176051855\n",
            "Loss in iteration no. 63185 ==> 0.5239521312956289\n",
            "Loss in iteration no. 63186 ==> 0.5239507450006919\n",
            "Loss in iteration no. 63187 ==> 0.5239493587203744\n",
            "Loss in iteration no. 63188 ==> 0.5239479724546761\n",
            "Loss in iteration no. 63189 ==> 0.5239465862035968\n",
            "Loss in iteration no. 63190 ==> 0.5239451999671362\n",
            "Loss in iteration no. 63191 ==> 0.5239438137452943\n",
            "Loss in iteration no. 63192 ==> 0.5239424275380704\n",
            "Loss in iteration no. 63193 ==> 0.5239410413454647\n",
            "Loss in iteration no. 63194 ==> 0.5239396551674769\n",
            "Loss in iteration no. 63195 ==> 0.5239382690041066\n",
            "Loss in iteration no. 63196 ==> 0.5239368828553538\n",
            "Loss in iteration no. 63197 ==> 0.5239354967212179\n",
            "Loss in iteration no. 63198 ==> 0.5239341106016991\n",
            "Loss in iteration no. 63199 ==> 0.5239327244967967\n",
            "Loss in iteration no. 63200 ==> 0.523931338406511\n",
            "Loss in iteration no. 63201 ==> 0.5239299523308414\n",
            "Loss in iteration no. 63202 ==> 0.5239285662697878\n",
            "Loss in iteration no. 63203 ==> 0.5239271802233498\n",
            "Loss in iteration no. 63204 ==> 0.5239257941915275\n",
            "Loss in iteration no. 63205 ==> 0.5239244081743205\n",
            "Loss in iteration no. 63206 ==> 0.5239230221717284\n",
            "Loss in iteration no. 63207 ==> 0.523921636183751\n",
            "Loss in iteration no. 63208 ==> 0.5239202502103885\n",
            "Loss in iteration no. 63209 ==> 0.5239188642516402\n",
            "Loss in iteration no. 63210 ==> 0.523917478307506\n",
            "Loss in iteration no. 63211 ==> 0.5239160923779856\n",
            "Loss in iteration no. 63212 ==> 0.523914706463079\n",
            "Loss in iteration no. 63213 ==> 0.5239133205627858\n",
            "Loss in iteration no. 63214 ==> 0.5239119346771057\n",
            "Loss in iteration no. 63215 ==> 0.5239105488060388\n",
            "Loss in iteration no. 63216 ==> 0.5239091629495843\n",
            "Loss in iteration no. 63217 ==> 0.5239077771077425\n",
            "Loss in iteration no. 63218 ==> 0.523906391280513\n",
            "Loss in iteration no. 63219 ==> 0.5239050054678953\n",
            "Loss in iteration no. 63220 ==> 0.5239036196698897\n",
            "Loss in iteration no. 63221 ==> 0.5239022338864956\n",
            "Loss in iteration no. 63222 ==> 0.5239008481177128\n",
            "Loss in iteration no. 63223 ==> 0.5238994623635411\n",
            "Loss in iteration no. 63224 ==> 0.5238980766239804\n",
            "Loss in iteration no. 63225 ==> 0.5238966908990301\n",
            "Loss in iteration no. 63226 ==> 0.5238953051886903\n",
            "Loss in iteration no. 63227 ==> 0.5238939194929606\n",
            "Loss in iteration no. 63228 ==> 0.5238925338118412\n",
            "Loss in iteration no. 63229 ==> 0.5238911481453314\n",
            "Loss in iteration no. 63230 ==> 0.5238897624934309\n",
            "Loss in iteration no. 63231 ==> 0.5238883768561396\n",
            "Loss in iteration no. 63232 ==> 0.5238869912334576\n",
            "Loss in iteration no. 63233 ==> 0.5238856056253842\n",
            "Loss in iteration no. 63234 ==> 0.5238842200319196\n",
            "Loss in iteration no. 63235 ==> 0.5238828344530632\n",
            "Loss in iteration no. 63236 ==> 0.5238814488888148\n",
            "Loss in iteration no. 63237 ==> 0.5238800633391744\n",
            "Loss in iteration no. 63238 ==> 0.5238786778041417\n",
            "Loss in iteration no. 63239 ==> 0.5238772922837164\n",
            "Loss in iteration no. 63240 ==> 0.5238759067778981\n",
            "Loss in iteration no. 63241 ==> 0.5238745212866868\n",
            "Loss in iteration no. 63242 ==> 0.5238731358100823\n",
            "Loss in iteration no. 63243 ==> 0.5238717503480843\n",
            "Loss in iteration no. 63244 ==> 0.5238703649006924\n",
            "Loss in iteration no. 63245 ==> 0.5238689794679067\n",
            "Loss in iteration no. 63246 ==> 0.5238675940497267\n",
            "Loss in iteration no. 63247 ==> 0.5238662086461523\n",
            "Loss in iteration no. 63248 ==> 0.5238648232571831\n",
            "Loss in iteration no. 63249 ==> 0.5238634378828191\n",
            "Loss in iteration no. 63250 ==> 0.5238620525230601\n",
            "Loss in iteration no. 63251 ==> 0.5238606671779055\n",
            "Loss in iteration no. 63252 ==> 0.5238592818473553\n",
            "Loss in iteration no. 63253 ==> 0.5238578965314095\n",
            "Loss in iteration no. 63254 ==> 0.5238565112300675\n",
            "Loss in iteration no. 63255 ==> 0.5238551259433293\n",
            "Loss in iteration no. 63256 ==> 0.5238537406711945\n",
            "Loss in iteration no. 63257 ==> 0.5238523554136629\n",
            "Loss in iteration no. 63258 ==> 0.5238509701707346\n",
            "Loss in iteration no. 63259 ==> 0.5238495849424087\n",
            "Loss in iteration no. 63260 ==> 0.5238481997286856\n",
            "Loss in iteration no. 63261 ==> 0.5238468145295646\n",
            "Loss in iteration no. 63262 ==> 0.5238454293450459\n",
            "Loss in iteration no. 63263 ==> 0.5238440441751291\n",
            "Loss in iteration no. 63264 ==> 0.5238426590198138\n",
            "Loss in iteration no. 63265 ==> 0.5238412738790997\n",
            "Loss in iteration no. 63266 ==> 0.5238398887529871\n",
            "Loss in iteration no. 63267 ==> 0.5238385036414754\n",
            "Loss in iteration no. 63268 ==> 0.5238371185445644\n",
            "Loss in iteration no. 63269 ==> 0.5238357334622538\n",
            "Loss in iteration no. 63270 ==> 0.5238343483945432\n",
            "Loss in iteration no. 63271 ==> 0.523832963341433\n",
            "Loss in iteration no. 63272 ==> 0.5238315783029224\n",
            "Loss in iteration no. 63273 ==> 0.5238301932790116\n",
            "Loss in iteration no. 63274 ==> 0.5238288082696997\n",
            "Loss in iteration no. 63275 ==> 0.5238274232749871\n",
            "Loss in iteration no. 63276 ==> 0.5238260382948734\n",
            "Loss in iteration no. 63277 ==> 0.5238246533293582\n",
            "Loss in iteration no. 63278 ==> 0.5238232683784415\n",
            "Loss in iteration no. 63279 ==> 0.5238218834421231\n",
            "Loss in iteration no. 63280 ==> 0.5238204985204024\n",
            "Loss in iteration no. 63281 ==> 0.5238191136132795\n",
            "Loss in iteration no. 63282 ==> 0.5238177287207539\n",
            "Loss in iteration no. 63283 ==> 0.5238163438428259\n",
            "Loss in iteration no. 63284 ==> 0.5238149589794948\n",
            "Loss in iteration no. 63285 ==> 0.5238135741307602\n",
            "Loss in iteration no. 63286 ==> 0.5238121892966224\n",
            "Loss in iteration no. 63287 ==> 0.5238108044770807\n",
            "Loss in iteration no. 63288 ==> 0.5238094196721352\n",
            "Loss in iteration no. 63289 ==> 0.5238080348817856\n",
            "Loss in iteration no. 63290 ==> 0.5238066501060317\n",
            "Loss in iteration no. 63291 ==> 0.523805265344873\n",
            "Loss in iteration no. 63292 ==> 0.5238038805983096\n",
            "Loss in iteration no. 63293 ==> 0.5238024958663412\n",
            "Loss in iteration no. 63294 ==> 0.5238011111489672\n",
            "Loss in iteration no. 63295 ==> 0.5237997264461879\n",
            "Loss in iteration no. 63296 ==> 0.5237983417580028\n",
            "Loss in iteration no. 63297 ==> 0.5237969570844118\n",
            "Loss in iteration no. 63298 ==> 0.5237955724254144\n",
            "Loss in iteration no. 63299 ==> 0.5237941877810106\n",
            "Loss in iteration no. 63300 ==> 0.5237928031512001\n",
            "Loss in iteration no. 63301 ==> 0.5237914185359828\n",
            "Loss in iteration no. 63302 ==> 0.5237900339353583\n",
            "Loss in iteration no. 63303 ==> 0.5237886493493262\n",
            "Loss in iteration no. 63304 ==> 0.5237872647778867\n",
            "Loss in iteration no. 63305 ==> 0.5237858802210394\n",
            "Loss in iteration no. 63306 ==> 0.5237844956787839\n",
            "Loss in iteration no. 63307 ==> 0.5237831111511202\n",
            "Loss in iteration no. 63308 ==> 0.523781726638048\n",
            "Loss in iteration no. 63309 ==> 0.5237803421395669\n",
            "Loss in iteration no. 63310 ==> 0.5237789576556768\n",
            "Loss in iteration no. 63311 ==> 0.5237775731863776\n",
            "Loss in iteration no. 63312 ==> 0.5237761887316689\n",
            "Loss in iteration no. 63313 ==> 0.5237748042915504\n",
            "Loss in iteration no. 63314 ==> 0.5237734198660221\n",
            "Loss in iteration no. 63315 ==> 0.5237720354550837\n",
            "Loss in iteration no. 63316 ==> 0.5237706510587348\n",
            "Loss in iteration no. 63317 ==> 0.5237692666769753\n",
            "Loss in iteration no. 63318 ==> 0.523767882309805\n",
            "Loss in iteration no. 63319 ==> 0.5237664979572235\n",
            "Loss in iteration no. 63320 ==> 0.5237651136192308\n",
            "Loss in iteration no. 63321 ==> 0.5237637292958268\n",
            "Loss in iteration no. 63322 ==> 0.5237623449870107\n",
            "Loss in iteration no. 63323 ==> 0.5237609606927826\n",
            "Loss in iteration no. 63324 ==> 0.5237595764131424\n",
            "Loss in iteration no. 63325 ==> 0.5237581921480897\n",
            "Loss in iteration no. 63326 ==> 0.5237568078976245\n",
            "Loss in iteration no. 63327 ==> 0.5237554236617461\n",
            "Loss in iteration no. 63328 ==> 0.5237540394404548\n",
            "Loss in iteration no. 63329 ==> 0.5237526552337499\n",
            "Loss in iteration no. 63330 ==> 0.5237512710416314\n",
            "Loss in iteration no. 63331 ==> 0.5237498868640992\n",
            "Loss in iteration no. 63332 ==> 0.5237485027011528\n",
            "Loss in iteration no. 63333 ==> 0.5237471185527922\n",
            "Loss in iteration no. 63334 ==> 0.5237457344190171\n",
            "Loss in iteration no. 63335 ==> 0.523744350299827\n",
            "Loss in iteration no. 63336 ==> 0.523742966195222\n",
            "Loss in iteration no. 63337 ==> 0.5237415821052019\n",
            "Loss in iteration no. 63338 ==> 0.5237401980297665\n",
            "Loss in iteration no. 63339 ==> 0.523738813968915\n",
            "Loss in iteration no. 63340 ==> 0.5237374299226479\n",
            "Loss in iteration no. 63341 ==> 0.5237360458909645\n",
            "Loss in iteration no. 63342 ==> 0.5237346618738646\n",
            "Loss in iteration no. 63343 ==> 0.5237332778713484\n",
            "Loss in iteration no. 63344 ==> 0.5237318938834152\n",
            "Loss in iteration no. 63345 ==> 0.5237305099100648\n",
            "Loss in iteration no. 63346 ==> 0.5237291259512972\n",
            "Loss in iteration no. 63347 ==> 0.5237277420071121\n",
            "Loss in iteration no. 63348 ==> 0.5237263580775092\n",
            "Loss in iteration no. 63349 ==> 0.5237249741624884\n",
            "Loss in iteration no. 63350 ==> 0.5237235902620492\n",
            "Loss in iteration no. 63351 ==> 0.5237222063761917\n",
            "Loss in iteration no. 63352 ==> 0.5237208225049155\n",
            "Loss in iteration no. 63353 ==> 0.5237194386482202\n",
            "Loss in iteration no. 63354 ==> 0.523718054806106\n",
            "Loss in iteration no. 63355 ==> 0.5237166709785724\n",
            "Loss in iteration no. 63356 ==> 0.523715287165619\n",
            "Loss in iteration no. 63357 ==> 0.5237139033672458\n",
            "Loss in iteration no. 63358 ==> 0.5237125195834527\n",
            "Loss in iteration no. 63359 ==> 0.5237111358142391\n",
            "Loss in iteration no. 63360 ==> 0.5237097520596051\n",
            "Loss in iteration no. 63361 ==> 0.5237083683195503\n",
            "Loss in iteration no. 63362 ==> 0.5237069845940745\n",
            "Loss in iteration no. 63363 ==> 0.5237056008831775\n",
            "Loss in iteration no. 63364 ==> 0.5237042171868589\n",
            "Loss in iteration no. 63365 ==> 0.5237028335051189\n",
            "Loss in iteration no. 63366 ==> 0.5237014498379567\n",
            "Loss in iteration no. 63367 ==> 0.5237000661853726\n",
            "Loss in iteration no. 63368 ==> 0.5236986825473658\n",
            "Loss in iteration no. 63369 ==> 0.5236972989239367\n",
            "Loss in iteration no. 63370 ==> 0.5236959153150847\n",
            "Loss in iteration no. 63371 ==> 0.5236945317208095\n",
            "Loss in iteration no. 63372 ==> 0.5236931481411112\n",
            "Loss in iteration no. 63373 ==> 0.5236917645759892\n",
            "Loss in iteration no. 63374 ==> 0.5236903810254435\n",
            "Loss in iteration no. 63375 ==> 0.5236889974894738\n",
            "Loss in iteration no. 63376 ==> 0.5236876139680801\n",
            "Loss in iteration no. 63377 ==> 0.5236862304612616\n",
            "Loss in iteration no. 63378 ==> 0.5236848469690186\n",
            "Loss in iteration no. 63379 ==> 0.5236834634913506\n",
            "Loss in iteration no. 63380 ==> 0.5236820800282576\n",
            "Loss in iteration no. 63381 ==> 0.5236806965797391\n",
            "Loss in iteration no. 63382 ==> 0.523679313145795\n",
            "Loss in iteration no. 63383 ==> 0.5236779297264252\n",
            "Loss in iteration no. 63384 ==> 0.5236765463216292\n",
            "Loss in iteration no. 63385 ==> 0.5236751629314069\n",
            "Loss in iteration no. 63386 ==> 0.5236737795557581\n",
            "Loss in iteration no. 63387 ==> 0.5236723961946826\n",
            "Loss in iteration no. 63388 ==> 0.5236710128481802\n",
            "Loss in iteration no. 63389 ==> 0.5236696295162504\n",
            "Loss in iteration no. 63390 ==> 0.5236682461988932\n",
            "Loss in iteration no. 63391 ==> 0.5236668628961084\n",
            "Loss in iteration no. 63392 ==> 0.5236654796078957\n",
            "Loss in iteration no. 63393 ==> 0.5236640963342548\n",
            "Loss in iteration no. 63394 ==> 0.5236627130751855\n",
            "Loss in iteration no. 63395 ==> 0.5236613298306878\n",
            "Loss in iteration no. 63396 ==> 0.523659946600761\n",
            "Loss in iteration no. 63397 ==> 0.5236585633854053\n",
            "Loss in iteration no. 63398 ==> 0.5236571801846202\n",
            "Loss in iteration no. 63399 ==> 0.5236557969984057\n",
            "Loss in iteration no. 63400 ==> 0.5236544138267614\n",
            "Loss in iteration no. 63401 ==> 0.5236530306696869\n",
            "Loss in iteration no. 63402 ==> 0.5236516475271824\n",
            "Loss in iteration no. 63403 ==> 0.5236502643992476\n",
            "Loss in iteration no. 63404 ==> 0.5236488812858818\n",
            "Loss in iteration no. 63405 ==> 0.5236474981870854\n",
            "Loss in iteration no. 63406 ==> 0.5236461151028577\n",
            "Loss in iteration no. 63407 ==> 0.5236447320331988\n",
            "Loss in iteration no. 63408 ==> 0.5236433489781083\n",
            "Loss in iteration no. 63409 ==> 0.5236419659375858\n",
            "Loss in iteration no. 63410 ==> 0.5236405829116313\n",
            "Loss in iteration no. 63411 ==> 0.5236391999002447\n",
            "Loss in iteration no. 63412 ==> 0.5236378169034254\n",
            "Loss in iteration no. 63413 ==> 0.5236364339211733\n",
            "Loss in iteration no. 63414 ==> 0.5236350509534883\n",
            "Loss in iteration no. 63415 ==> 0.5236336680003701\n",
            "Loss in iteration no. 63416 ==> 0.5236322850618184\n",
            "Loss in iteration no. 63417 ==> 0.5236309021378331\n",
            "Loss in iteration no. 63418 ==> 0.5236295192284139\n",
            "Loss in iteration no. 63419 ==> 0.5236281363335606\n",
            "Loss in iteration no. 63420 ==> 0.523626753453273\n",
            "Loss in iteration no. 63421 ==> 0.5236253705875507\n",
            "Loss in iteration no. 63422 ==> 0.5236239877363937\n",
            "Loss in iteration no. 63423 ==> 0.5236226048998016\n",
            "Loss in iteration no. 63424 ==> 0.5236212220777743\n",
            "Loss in iteration no. 63425 ==> 0.5236198392703113\n",
            "Loss in iteration no. 63426 ==> 0.5236184564774127\n",
            "Loss in iteration no. 63427 ==> 0.5236170736990781\n",
            "Loss in iteration no. 63428 ==> 0.5236156909353074\n",
            "Loss in iteration no. 63429 ==> 0.5236143081861\n",
            "Loss in iteration no. 63430 ==> 0.5236129254514561\n",
            "Loss in iteration no. 63431 ==> 0.5236115427313753\n",
            "Loss in iteration no. 63432 ==> 0.5236101600258576\n",
            "Loss in iteration no. 63433 ==> 0.5236087773349023\n",
            "Loss in iteration no. 63434 ==> 0.5236073946585095\n",
            "Loss in iteration no. 63435 ==> 0.5236060119966788\n",
            "Loss in iteration no. 63436 ==> 0.5236046293494102\n",
            "Loss in iteration no. 63437 ==> 0.5236032467167032\n",
            "Loss in iteration no. 63438 ==> 0.5236018640985578\n",
            "Loss in iteration no. 63439 ==> 0.5236004814949737\n",
            "Loss in iteration no. 63440 ==> 0.5235990989059506\n",
            "Loss in iteration no. 63441 ==> 0.5235977163314882\n",
            "Loss in iteration no. 63442 ==> 0.5235963337715865\n",
            "Loss in iteration no. 63443 ==> 0.5235949512262451\n",
            "Loss in iteration no. 63444 ==> 0.5235935686954638\n",
            "Loss in iteration no. 63445 ==> 0.5235921861792425\n",
            "Loss in iteration no. 63446 ==> 0.5235908036775808\n",
            "Loss in iteration no. 63447 ==> 0.5235894211904785\n",
            "Loss in iteration no. 63448 ==> 0.5235880387179354\n",
            "Loss in iteration no. 63449 ==> 0.5235866562599513\n",
            "Loss in iteration no. 63450 ==> 0.523585273816526\n",
            "Loss in iteration no. 63451 ==> 0.5235838913876592\n",
            "Loss in iteration no. 63452 ==> 0.5235825089733505\n",
            "Loss in iteration no. 63453 ==> 0.5235811265736001\n",
            "Loss in iteration no. 63454 ==> 0.5235797441884072\n",
            "Loss in iteration no. 63455 ==> 0.5235783618177722\n",
            "Loss in iteration no. 63456 ==> 0.5235769794616943\n",
            "Loss in iteration no. 63457 ==> 0.5235755971201738\n",
            "Loss in iteration no. 63458 ==> 0.52357421479321\n",
            "Loss in iteration no. 63459 ==> 0.523572832480803\n",
            "Loss in iteration no. 63460 ==> 0.5235714501829524\n",
            "Loss in iteration no. 63461 ==> 0.5235700678996581\n",
            "Loss in iteration no. 63462 ==> 0.5235686856309195\n",
            "Loss in iteration no. 63463 ==> 0.523567303376737\n",
            "Loss in iteration no. 63464 ==> 0.5235659211371096\n",
            "Loss in iteration no. 63465 ==> 0.5235645389120377\n",
            "Loss in iteration no. 63466 ==> 0.523563156701521\n",
            "Loss in iteration no. 63467 ==> 0.5235617745055591\n",
            "Loss in iteration no. 63468 ==> 0.5235603923241516\n",
            "Loss in iteration no. 63469 ==> 0.5235590101572987\n",
            "Loss in iteration no. 63470 ==> 0.5235576280049998\n",
            "Loss in iteration no. 63471 ==> 0.5235562458672548\n",
            "Loss in iteration no. 63472 ==> 0.5235548637440636\n",
            "Loss in iteration no. 63473 ==> 0.5235534816354257\n",
            "Loss in iteration no. 63474 ==> 0.5235520995413411\n",
            "Loss in iteration no. 63475 ==> 0.5235507174618095\n",
            "Loss in iteration no. 63476 ==> 0.5235493353968307\n",
            "Loss in iteration no. 63477 ==> 0.5235479533464044\n",
            "Loss in iteration no. 63478 ==> 0.5235465713105304\n",
            "Loss in iteration no. 63479 ==> 0.5235451892892083\n",
            "Loss in iteration no. 63480 ==> 0.5235438072824382\n",
            "Loss in iteration no. 63481 ==> 0.5235424252902197\n",
            "Loss in iteration no. 63482 ==> 0.5235410433125526\n",
            "Loss in iteration no. 63483 ==> 0.5235396613494365\n",
            "Loss in iteration no. 63484 ==> 0.5235382794008716\n",
            "Loss in iteration no. 63485 ==> 0.5235368974668574\n",
            "Loss in iteration no. 63486 ==> 0.5235355155473933\n",
            "Loss in iteration no. 63487 ==> 0.5235341336424797\n",
            "Loss in iteration no. 63488 ==> 0.523532751752116\n",
            "Loss in iteration no. 63489 ==> 0.5235313698763021\n",
            "Loss in iteration no. 63490 ==> 0.5235299880150377\n",
            "Loss in iteration no. 63491 ==> 0.5235286061683229\n",
            "Loss in iteration no. 63492 ==> 0.5235272243361567\n",
            "Loss in iteration no. 63493 ==> 0.5235258425185397\n",
            "Loss in iteration no. 63494 ==> 0.5235244607154712\n",
            "Loss in iteration no. 63495 ==> 0.5235230789269513\n",
            "Loss in iteration no. 63496 ==> 0.5235216971529792\n",
            "Loss in iteration no. 63497 ==> 0.5235203153935551\n",
            "Loss in iteration no. 63498 ==> 0.5235189336486789\n",
            "Loss in iteration no. 63499 ==> 0.5235175519183501\n",
            "Loss in iteration no. 63500 ==> 0.5235161702025687\n",
            "Loss in iteration no. 63501 ==> 0.5235147885013341\n",
            "Loss in iteration no. 63502 ==> 0.5235134068146463\n",
            "Loss in iteration no. 63503 ==> 0.523512025142505\n",
            "Loss in iteration no. 63504 ==> 0.5235106434849102\n",
            "Loss in iteration no. 63505 ==> 0.5235092618418614\n",
            "Loss in iteration no. 63506 ==> 0.5235078802133585\n",
            "Loss in iteration no. 63507 ==> 0.5235064985994011\n",
            "Loss in iteration no. 63508 ==> 0.5235051169999893\n",
            "Loss in iteration no. 63509 ==> 0.5235037354151226\n",
            "Loss in iteration no. 63510 ==> 0.5235023538448009\n",
            "Loss in iteration no. 63511 ==> 0.5235009722890238\n",
            "Loss in iteration no. 63512 ==> 0.5234995907477913\n",
            "Loss in iteration no. 63513 ==> 0.5234982092211029\n",
            "Loss in iteration no. 63514 ==> 0.5234968277089588\n",
            "Loss in iteration no. 63515 ==> 0.5234954462113582\n",
            "Loss in iteration no. 63516 ==> 0.5234940647283013\n",
            "Loss in iteration no. 63517 ==> 0.5234926832597877\n",
            "Loss in iteration no. 63518 ==> 0.5234913018058173\n",
            "Loss in iteration no. 63519 ==> 0.5234899203663896\n",
            "Loss in iteration no. 63520 ==> 0.5234885389415048\n",
            "Loss in iteration no. 63521 ==> 0.5234871575311624\n",
            "Loss in iteration no. 63522 ==> 0.5234857761353621\n",
            "Loss in iteration no. 63523 ==> 0.5234843947541036\n",
            "Loss in iteration no. 63524 ==> 0.5234830133873871\n",
            "Loss in iteration no. 63525 ==> 0.5234816320352119\n",
            "Loss in iteration no. 63526 ==> 0.5234802506975782\n",
            "Loss in iteration no. 63527 ==> 0.5234788693744853\n",
            "Loss in iteration no. 63528 ==> 0.5234774880659333\n",
            "Loss in iteration no. 63529 ==> 0.5234761067719219\n",
            "Loss in iteration no. 63530 ==> 0.5234747254924509\n",
            "Loss in iteration no. 63531 ==> 0.5234733442275199\n",
            "Loss in iteration no. 63532 ==> 0.523471962977129\n",
            "Loss in iteration no. 63533 ==> 0.5234705817412774\n",
            "Loss in iteration no. 63534 ==> 0.5234692005199655\n",
            "Loss in iteration no. 63535 ==> 0.523467819313193\n",
            "Loss in iteration no. 63536 ==> 0.523466438120959\n",
            "Loss in iteration no. 63537 ==> 0.5234650569432643\n",
            "Loss in iteration no. 63538 ==> 0.5234636757801078\n",
            "Loss in iteration no. 63539 ==> 0.5234622946314895\n",
            "Loss in iteration no. 63540 ==> 0.5234609134974093\n",
            "Loss in iteration no. 63541 ==> 0.5234595323778669\n",
            "Loss in iteration no. 63542 ==> 0.5234581512728623\n",
            "Loss in iteration no. 63543 ==> 0.5234567701823949\n",
            "Loss in iteration no. 63544 ==> 0.5234553891064647\n",
            "Loss in iteration no. 63545 ==> 0.5234540080450713\n",
            "Loss in iteration no. 63546 ==> 0.5234526269982148\n",
            "Loss in iteration no. 63547 ==> 0.5234512459658947\n",
            "Loss in iteration no. 63548 ==> 0.5234498649481106\n",
            "Loss in iteration no. 63549 ==> 0.5234484839448628\n",
            "Loss in iteration no. 63550 ==> 0.5234471029561505\n",
            "Loss in iteration no. 63551 ==> 0.5234457219819739\n",
            "Loss in iteration no. 63552 ==> 0.5234443410223325\n",
            "Loss in iteration no. 63553 ==> 0.5234429600772262\n",
            "Loss in iteration no. 63554 ==> 0.5234415791466548\n",
            "Loss in iteration no. 63555 ==> 0.5234401982306179\n",
            "Loss in iteration no. 63556 ==> 0.5234388173291156\n",
            "Loss in iteration no. 63557 ==> 0.5234374364421474\n",
            "Loss in iteration no. 63558 ==> 0.523436055569713\n",
            "Loss in iteration no. 63559 ==> 0.5234346747118124\n",
            "Loss in iteration no. 63560 ==> 0.5234332938684452\n",
            "Loss in iteration no. 63561 ==> 0.5234319130396112\n",
            "Loss in iteration no. 63562 ==> 0.5234305322253102\n",
            "Loss in iteration no. 63563 ==> 0.5234291514255421\n",
            "Loss in iteration no. 63564 ==> 0.5234277706403064\n",
            "Loss in iteration no. 63565 ==> 0.5234263898696033\n",
            "Loss in iteration no. 63566 ==> 0.523425009113432\n",
            "Loss in iteration no. 63567 ==> 0.5234236283717928\n",
            "Loss in iteration no. 63568 ==> 0.523422247644685\n",
            "Loss in iteration no. 63569 ==> 0.5234208669321088\n",
            "Loss in iteration no. 63570 ==> 0.5234194862340636\n",
            "Loss in iteration no. 63571 ==> 0.5234181055505495\n",
            "Loss in iteration no. 63572 ==> 0.523416724881566\n",
            "Loss in iteration no. 63573 ==> 0.523415344227113\n",
            "Loss in iteration no. 63574 ==> 0.5234139635871903\n",
            "Loss in iteration no. 63575 ==> 0.5234125829617977\n",
            "Loss in iteration no. 63576 ==> 0.5234112023509347\n",
            "Loss in iteration no. 63577 ==> 0.5234098217546015\n",
            "Loss in iteration no. 63578 ==> 0.5234084411727974\n",
            "Loss in iteration no. 63579 ==> 0.5234070606055226\n",
            "Loss in iteration no. 63580 ==> 0.5234056800527764\n",
            "Loss in iteration no. 63581 ==> 0.5234042995145591\n",
            "Loss in iteration no. 63582 ==> 0.5234029189908703\n",
            "Loss in iteration no. 63583 ==> 0.5234015384817096\n",
            "Loss in iteration no. 63584 ==> 0.5234001579870768\n",
            "Loss in iteration no. 63585 ==> 0.5233987775069718\n",
            "Loss in iteration no. 63586 ==> 0.5233973970413942\n",
            "Loss in iteration no. 63587 ==> 0.523396016590344\n",
            "Loss in iteration no. 63588 ==> 0.5233946361538208\n",
            "Loss in iteration no. 63589 ==> 0.5233932557318244\n",
            "Loss in iteration no. 63590 ==> 0.5233918753243546\n",
            "Loss in iteration no. 63591 ==> 0.5233904949314112\n",
            "Loss in iteration no. 63592 ==> 0.5233891145529939\n",
            "Loss in iteration no. 63593 ==> 0.5233877341891024\n",
            "Loss in iteration no. 63594 ==> 0.5233863538397369\n",
            "Loss in iteration no. 63595 ==> 0.5233849735048964\n",
            "Loss in iteration no. 63596 ==> 0.5233835931845814\n",
            "Loss in iteration no. 63597 ==> 0.5233822128787913\n",
            "Loss in iteration no. 63598 ==> 0.5233808325875259\n",
            "Loss in iteration no. 63599 ==> 0.5233794523107851\n",
            "Loss in iteration no. 63600 ==> 0.5233780720485687\n",
            "Loss in iteration no. 63601 ==> 0.5233766918008761\n",
            "Loss in iteration no. 63602 ==> 0.5233753115677076\n",
            "Loss in iteration no. 63603 ==> 0.5233739313490624\n",
            "Loss in iteration no. 63604 ==> 0.523372551144941\n",
            "Loss in iteration no. 63605 ==> 0.5233711709553425\n",
            "Loss in iteration no. 63606 ==> 0.5233697907802668\n",
            "Loss in iteration no. 63607 ==> 0.523368410619714\n",
            "Loss in iteration no. 63608 ==> 0.5233670304736836\n",
            "Loss in iteration no. 63609 ==> 0.5233656503421753\n",
            "Loss in iteration no. 63610 ==> 0.5233642702251892\n",
            "Loss in iteration no. 63611 ==> 0.5233628901227247\n",
            "Loss in iteration no. 63612 ==> 0.5233615100347819\n",
            "Loss in iteration no. 63613 ==> 0.5233601299613604\n",
            "Loss in iteration no. 63614 ==> 0.5233587499024599\n",
            "Loss in iteration no. 63615 ==> 0.5233573698580802\n",
            "Loss in iteration no. 63616 ==> 0.5233559898282214\n",
            "Loss in iteration no. 63617 ==> 0.5233546098128828\n",
            "Loss in iteration no. 63618 ==> 0.5233532298120644\n",
            "Loss in iteration no. 63619 ==> 0.523351849825766\n",
            "Loss in iteration no. 63620 ==> 0.5233504698539873\n",
            "Loss in iteration no. 63621 ==> 0.523349089896728\n",
            "Loss in iteration no. 63622 ==> 0.5233477099539879\n",
            "Loss in iteration no. 63623 ==> 0.523346330025767\n",
            "Loss in iteration no. 63624 ==> 0.5233449501120648\n",
            "Loss in iteration no. 63625 ==> 0.5233435702128811\n",
            "Loss in iteration no. 63626 ==> 0.5233421903282159\n",
            "Loss in iteration no. 63627 ==> 0.5233408104580688\n",
            "Loss in iteration no. 63628 ==> 0.5233394306024395\n",
            "Loss in iteration no. 63629 ==> 0.5233380507613278\n",
            "Loss in iteration no. 63630 ==> 0.5233366709347336\n",
            "Loss in iteration no. 63631 ==> 0.5233352911226566\n",
            "Loss in iteration no. 63632 ==> 0.5233339113250965\n",
            "Loss in iteration no. 63633 ==> 0.5233325315420532\n",
            "Loss in iteration no. 63634 ==> 0.5233311517735263\n",
            "Loss in iteration no. 63635 ==> 0.5233297720195158\n",
            "Loss in iteration no. 63636 ==> 0.5233283922800213\n",
            "Loss in iteration no. 63637 ==> 0.5233270125550427\n",
            "Loss in iteration no. 63638 ==> 0.5233256328445796\n",
            "Loss in iteration no. 63639 ==> 0.5233242531486317\n",
            "Loss in iteration no. 63640 ==> 0.5233228734671994\n",
            "Loss in iteration no. 63641 ==> 0.5233214938002816\n",
            "Loss in iteration no. 63642 ==> 0.5233201141478786\n",
            "Loss in iteration no. 63643 ==> 0.52331873450999\n",
            "Loss in iteration no. 63644 ==> 0.5233173548866156\n",
            "Loss in iteration no. 63645 ==> 0.5233159752777553\n",
            "Loss in iteration no. 63646 ==> 0.5233145956834088\n",
            "Loss in iteration no. 63647 ==> 0.5233132161035756\n",
            "Loss in iteration no. 63648 ==> 0.5233118365382559\n",
            "Loss in iteration no. 63649 ==> 0.523310456987449\n",
            "Loss in iteration no. 63650 ==> 0.5233090774511553\n",
            "Loss in iteration no. 63651 ==> 0.5233076979293739\n",
            "Loss in iteration no. 63652 ==> 0.5233063184221051\n",
            "Loss in iteration no. 63653 ==> 0.5233049389293485\n",
            "Loss in iteration no. 63654 ==> 0.5233035594511036\n",
            "Loss in iteration no. 63655 ==> 0.5233021799873704\n",
            "Loss in iteration no. 63656 ==> 0.523300800538149\n",
            "Loss in iteration no. 63657 ==> 0.5232994211034384\n",
            "Loss in iteration no. 63658 ==> 0.5232980416832391\n",
            "Loss in iteration no. 63659 ==> 0.5232966622775505\n",
            "Loss in iteration no. 63660 ==> 0.5232952828863726\n",
            "Loss in iteration no. 63661 ==> 0.523293903509705\n",
            "Loss in iteration no. 63662 ==> 0.5232925241475471\n",
            "Loss in iteration no. 63663 ==> 0.5232911447998996\n",
            "Loss in iteration no. 63664 ==> 0.5232897654667613\n",
            "Loss in iteration no. 63665 ==> 0.5232883861481326\n",
            "Loss in iteration no. 63666 ==> 0.5232870068440132\n",
            "Loss in iteration no. 63667 ==> 0.5232856275544026\n",
            "Loss in iteration no. 63668 ==> 0.5232842482793008\n",
            "Loss in iteration no. 63669 ==> 0.5232828690187074\n",
            "Loss in iteration no. 63670 ==> 0.5232814897726223\n",
            "Loss in iteration no. 63671 ==> 0.5232801105410454\n",
            "Loss in iteration no. 63672 ==> 0.5232787313239761\n",
            "Loss in iteration no. 63673 ==> 0.5232773521214144\n",
            "Loss in iteration no. 63674 ==> 0.52327597293336\n",
            "Loss in iteration no. 63675 ==> 0.5232745937598129\n",
            "Loss in iteration no. 63676 ==> 0.5232732146007726\n",
            "Loss in iteration no. 63677 ==> 0.523271835456239\n",
            "Loss in iteration no. 63678 ==> 0.5232704563262117\n",
            "Loss in iteration no. 63679 ==> 0.5232690772106908\n",
            "Loss in iteration no. 63680 ==> 0.5232676981096757\n",
            "Loss in iteration no. 63681 ==> 0.5232663190231664\n",
            "Loss in iteration no. 63682 ==> 0.5232649399511627\n",
            "Loss in iteration no. 63683 ==> 0.5232635608936642\n",
            "Loss in iteration no. 63684 ==> 0.5232621818506709\n",
            "Loss in iteration no. 63685 ==> 0.5232608028221822\n",
            "Loss in iteration no. 63686 ==> 0.5232594238081985\n",
            "Loss in iteration no. 63687 ==> 0.5232580448087188\n",
            "Loss in iteration no. 63688 ==> 0.5232566658237433\n",
            "Loss in iteration no. 63689 ==> 0.5232552868532717\n",
            "Loss in iteration no. 63690 ==> 0.5232539078973041\n",
            "Loss in iteration no. 63691 ==> 0.5232525289558397\n",
            "Loss in iteration no. 63692 ==> 0.5232511500288785\n",
            "Loss in iteration no. 63693 ==> 0.5232497711164202\n",
            "Loss in iteration no. 63694 ==> 0.5232483922184651\n",
            "Loss in iteration no. 63695 ==> 0.5232470133350122\n",
            "Loss in iteration no. 63696 ==> 0.5232456344660618\n",
            "Loss in iteration no. 63697 ==> 0.5232442556116133\n",
            "Loss in iteration no. 63698 ==> 0.5232428767716668\n",
            "Loss in iteration no. 63699 ==> 0.523241497946222\n",
            "Loss in iteration no. 63700 ==> 0.5232401191352782\n",
            "Loss in iteration no. 63701 ==> 0.5232387403388361\n",
            "Loss in iteration no. 63702 ==> 0.5232373615568946\n",
            "Loss in iteration no. 63703 ==> 0.523235982789454\n",
            "Loss in iteration no. 63704 ==> 0.5232346040365139\n",
            "Loss in iteration no. 63705 ==> 0.5232332252980739\n",
            "Loss in iteration no. 63706 ==> 0.5232318465741341\n",
            "Loss in iteration no. 63707 ==> 0.523230467864694\n",
            "Loss in iteration no. 63708 ==> 0.5232290891697535\n",
            "Loss in iteration no. 63709 ==> 0.5232277104893123\n",
            "Loss in iteration no. 63710 ==> 0.5232263318233702\n",
            "Loss in iteration no. 63711 ==> 0.5232249531719272\n",
            "Loss in iteration no. 63712 ==> 0.5232235745349826\n",
            "Loss in iteration no. 63713 ==> 0.5232221959125366\n",
            "Loss in iteration no. 63714 ==> 0.5232208173045887\n",
            "Loss in iteration no. 63715 ==> 0.5232194387111389\n",
            "Loss in iteration no. 63716 ==> 0.5232180601321866\n",
            "Loss in iteration no. 63717 ==> 0.5232166815677322\n",
            "Loss in iteration no. 63718 ==> 0.5232153030177747\n",
            "Loss in iteration no. 63719 ==> 0.5232139244823145\n",
            "Loss in iteration no. 63720 ==> 0.523212545961351\n",
            "Loss in iteration no. 63721 ==> 0.5232111674548842\n",
            "Loss in iteration no. 63722 ==> 0.5232097889629138\n",
            "Loss in iteration no. 63723 ==> 0.5232084104854394\n",
            "Loss in iteration no. 63724 ==> 0.5232070320224611\n",
            "Loss in iteration no. 63725 ==> 0.5232056535739784\n",
            "Loss in iteration no. 63726 ==> 0.523204275139991\n",
            "Loss in iteration no. 63727 ==> 0.523202896720499\n",
            "Loss in iteration no. 63728 ==> 0.523201518315502\n",
            "Loss in iteration no. 63729 ==> 0.5232001399249999\n",
            "Loss in iteration no. 63730 ==> 0.5231987615489921\n",
            "Loss in iteration no. 63731 ==> 0.5231973831874788\n",
            "Loss in iteration no. 63732 ==> 0.5231960048404596\n",
            "Loss in iteration no. 63733 ==> 0.5231946265079341\n",
            "Loss in iteration no. 63734 ==> 0.5231932481899023\n",
            "Loss in iteration no. 63735 ==> 0.5231918698863639\n",
            "Loss in iteration no. 63736 ==> 0.5231904915973188\n",
            "Loss in iteration no. 63737 ==> 0.5231891133227664\n",
            "Loss in iteration no. 63738 ==> 0.5231877350627069\n",
            "Loss in iteration no. 63739 ==> 0.5231863568171399\n",
            "Loss in iteration no. 63740 ==> 0.523184978586065\n",
            "Loss in iteration no. 63741 ==> 0.5231836003694823\n",
            "Loss in iteration no. 63742 ==> 0.5231822221673914\n",
            "Loss in iteration no. 63743 ==> 0.523180843979792\n",
            "Loss in iteration no. 63744 ==> 0.523179465806684\n",
            "Loss in iteration no. 63745 ==> 0.5231780876480672\n",
            "Loss in iteration no. 63746 ==> 0.5231767095039411\n",
            "Loss in iteration no. 63747 ==> 0.5231753313743057\n",
            "Loss in iteration no. 63748 ==> 0.5231739532591608\n",
            "Loss in iteration no. 63749 ==> 0.5231725751585062\n",
            "Loss in iteration no. 63750 ==> 0.5231711970723415\n",
            "Loss in iteration no. 63751 ==> 0.5231698190006666\n",
            "Loss in iteration no. 63752 ==> 0.5231684409434809\n",
            "Loss in iteration no. 63753 ==> 0.5231670629007849\n",
            "Loss in iteration no. 63754 ==> 0.5231656848725778\n",
            "Loss in iteration no. 63755 ==> 0.5231643068588595\n",
            "Loss in iteration no. 63756 ==> 0.5231629288596299\n",
            "Loss in iteration no. 63757 ==> 0.5231615508748887\n",
            "Loss in iteration no. 63758 ==> 0.5231601729046355\n",
            "Loss in iteration no. 63759 ==> 0.5231587949488703\n",
            "Loss in iteration no. 63760 ==> 0.5231574170075929\n",
            "Loss in iteration no. 63761 ==> 0.5231560390808028\n",
            "Loss in iteration no. 63762 ==> 0.5231546611685\n",
            "Loss in iteration no. 63763 ==> 0.5231532832706842\n",
            "Loss in iteration no. 63764 ==> 0.5231519053873553\n",
            "Loss in iteration no. 63765 ==> 0.5231505275185129\n",
            "Loss in iteration no. 63766 ==> 0.5231491496641567\n",
            "Loss in iteration no. 63767 ==> 0.5231477718242866\n",
            "Loss in iteration no. 63768 ==> 0.5231463939989025\n",
            "Loss in iteration no. 63769 ==> 0.5231450161880039\n",
            "Loss in iteration no. 63770 ==> 0.523143638391591\n",
            "Loss in iteration no. 63771 ==> 0.523142260609663\n",
            "Loss in iteration no. 63772 ==> 0.5231408828422202\n",
            "Loss in iteration no. 63773 ==> 0.5231395050892618\n",
            "Loss in iteration no. 63774 ==> 0.5231381273507881\n",
            "Loss in iteration no. 63775 ==> 0.5231367496267987\n",
            "Loss in iteration no. 63776 ==> 0.5231353719172932\n",
            "Loss in iteration no. 63777 ==> 0.5231339942222716\n",
            "Loss in iteration no. 63778 ==> 0.5231326165417336\n",
            "Loss in iteration no. 63779 ==> 0.523131238875679\n",
            "Loss in iteration no. 63780 ==> 0.5231298612241074\n",
            "Loss in iteration no. 63781 ==> 0.5231284835870188\n",
            "Loss in iteration no. 63782 ==> 0.5231271059644129\n",
            "Loss in iteration no. 63783 ==> 0.5231257283562893\n",
            "Loss in iteration no. 63784 ==> 0.5231243507626482\n",
            "Loss in iteration no. 63785 ==> 0.5231229731834888\n",
            "Loss in iteration no. 63786 ==> 0.5231215956188113\n",
            "Loss in iteration no. 63787 ==> 0.5231202180686153\n",
            "Loss in iteration no. 63788 ==> 0.5231188405329007\n",
            "Loss in iteration no. 63789 ==> 0.5231174630116671\n",
            "Loss in iteration no. 63790 ==> 0.5231160855049143\n",
            "Loss in iteration no. 63791 ==> 0.5231147080126421\n",
            "Loss in iteration no. 63792 ==> 0.5231133305348504\n",
            "Loss in iteration no. 63793 ==> 0.5231119530715388\n",
            "Loss in iteration no. 63794 ==> 0.5231105756227071\n",
            "Loss in iteration no. 63795 ==> 0.5231091981883552\n",
            "Loss in iteration no. 63796 ==> 0.5231078207684828\n",
            "Loss in iteration no. 63797 ==> 0.5231064433630894\n",
            "Loss in iteration no. 63798 ==> 0.5231050659721753\n",
            "Loss in iteration no. 63799 ==> 0.52310368859574\n",
            "Loss in iteration no. 63800 ==> 0.523102311233783\n",
            "Loss in iteration no. 63801 ==> 0.5231009338863046\n",
            "Loss in iteration no. 63802 ==> 0.5230995565533043\n",
            "Loss in iteration no. 63803 ==> 0.5230981792347817\n",
            "Loss in iteration no. 63804 ==> 0.523096801930737\n",
            "Loss in iteration no. 63805 ==> 0.5230954246411695\n",
            "Loss in iteration no. 63806 ==> 0.5230940473660795\n",
            "Loss in iteration no. 63807 ==> 0.5230926701054661\n",
            "Loss in iteration no. 63808 ==> 0.5230912928593296\n",
            "Loss in iteration no. 63809 ==> 0.5230899156276697\n",
            "Loss in iteration no. 63810 ==> 0.523088538410486\n",
            "Loss in iteration no. 63811 ==> 0.5230871612077784\n",
            "Loss in iteration no. 63812 ==> 0.5230857840195465\n",
            "Loss in iteration no. 63813 ==> 0.5230844068457904\n",
            "Loss in iteration no. 63814 ==> 0.5230830296865097\n",
            "Loss in iteration no. 63815 ==> 0.5230816525417039\n",
            "Loss in iteration no. 63816 ==> 0.5230802754113731\n",
            "Loss in iteration no. 63817 ==> 0.5230788982955171\n",
            "Loss in iteration no. 63818 ==> 0.5230775211941355\n",
            "Loss in iteration no. 63819 ==> 0.5230761441072282\n",
            "Loss in iteration no. 63820 ==> 0.5230747670347948\n",
            "Loss in iteration no. 63821 ==> 0.5230733899768354\n",
            "Loss in iteration no. 63822 ==> 0.5230720129333492\n",
            "Loss in iteration no. 63823 ==> 0.5230706359043366\n",
            "Loss in iteration no. 63824 ==> 0.5230692588897969\n",
            "Loss in iteration no. 63825 ==> 0.5230678818897302\n",
            "Loss in iteration no. 63826 ==> 0.5230665049041362\n",
            "Loss in iteration no. 63827 ==> 0.5230651279330145\n",
            "Loss in iteration no. 63828 ==> 0.523063750976365\n",
            "Loss in iteration no. 63829 ==> 0.5230623740341874\n",
            "Loss in iteration no. 63830 ==> 0.5230609971064816\n",
            "Loss in iteration no. 63831 ==> 0.5230596201932473\n",
            "Loss in iteration no. 63832 ==> 0.5230582432944844\n",
            "Loss in iteration no. 63833 ==> 0.5230568664101923\n",
            "Loss in iteration no. 63834 ==> 0.5230554895403712\n",
            "Loss in iteration no. 63835 ==> 0.5230541126850206\n",
            "Loss in iteration no. 63836 ==> 0.5230527358441404\n",
            "Loss in iteration no. 63837 ==> 0.5230513590177303\n",
            "Loss in iteration no. 63838 ==> 0.52304998220579\n",
            "Loss in iteration no. 63839 ==> 0.5230486054083195\n",
            "Loss in iteration no. 63840 ==> 0.5230472286253185\n",
            "Loss in iteration no. 63841 ==> 0.5230458518567868\n",
            "Loss in iteration no. 63842 ==> 0.5230444751027239\n",
            "Loss in iteration no. 63843 ==> 0.5230430983631298\n",
            "Loss in iteration no. 63844 ==> 0.5230417216380041\n",
            "Loss in iteration no. 63845 ==> 0.523040344927347\n",
            "Loss in iteration no. 63846 ==> 0.5230389682311578\n",
            "Loss in iteration no. 63847 ==> 0.5230375915494365\n",
            "Loss in iteration no. 63848 ==> 0.5230362148821829\n",
            "Loss in iteration no. 63849 ==> 0.5230348382293966\n",
            "Loss in iteration no. 63850 ==> 0.5230334615910774\n",
            "Loss in iteration no. 63851 ==> 0.5230320849672253\n",
            "Loss in iteration no. 63852 ==> 0.5230307083578399\n",
            "Loss in iteration no. 63853 ==> 0.5230293317629209\n",
            "Loss in iteration no. 63854 ==> 0.5230279551824683\n",
            "Loss in iteration no. 63855 ==> 0.5230265786164816\n",
            "Loss in iteration no. 63856 ==> 0.5230252020649607\n",
            "Loss in iteration no. 63857 ==> 0.5230238255279055\n",
            "Loss in iteration no. 63858 ==> 0.5230224490053156\n",
            "Loss in iteration no. 63859 ==> 0.5230210724971908\n",
            "Loss in iteration no. 63860 ==> 0.5230196960035308\n",
            "Loss in iteration no. 63861 ==> 0.5230183195243355\n",
            "Loss in iteration no. 63862 ==> 0.5230169430596049\n",
            "Loss in iteration no. 63863 ==> 0.5230155666093382\n",
            "Loss in iteration no. 63864 ==> 0.5230141901735356\n",
            "Loss in iteration no. 63865 ==> 0.5230128137521969\n",
            "Loss in iteration no. 63866 ==> 0.5230114373453214\n",
            "Loss in iteration no. 63867 ==> 0.5230100609529094\n",
            "Loss in iteration no. 63868 ==> 0.5230086845749604\n",
            "Loss in iteration no. 63869 ==> 0.5230073082114743\n",
            "Loss in iteration no. 63870 ==> 0.5230059318624508\n",
            "Loss in iteration no. 63871 ==> 0.5230045555278897\n",
            "Loss in iteration no. 63872 ==> 0.5230031792077908\n",
            "Loss in iteration no. 63873 ==> 0.5230018029021537\n",
            "Loss in iteration no. 63874 ==> 0.5230004266109786\n",
            "Loss in iteration no. 63875 ==> 0.5229990503342647\n",
            "Loss in iteration no. 63876 ==> 0.5229976740720121\n",
            "Loss in iteration no. 63877 ==> 0.5229962978242205\n",
            "Loss in iteration no. 63878 ==> 0.5229949215908899\n",
            "Loss in iteration no. 63879 ==> 0.5229935453720197\n",
            "Loss in iteration no. 63880 ==> 0.5229921691676097\n",
            "Loss in iteration no. 63881 ==> 0.52299079297766\n",
            "Loss in iteration no. 63882 ==> 0.5229894168021703\n",
            "Loss in iteration no. 63883 ==> 0.52298804064114\n",
            "Loss in iteration no. 63884 ==> 0.5229866644945692\n",
            "Loss in iteration no. 63885 ==> 0.5229852883624576\n",
            "Loss in iteration no. 63886 ==> 0.522983912244805\n",
            "Loss in iteration no. 63887 ==> 0.5229825361416112\n",
            "Loss in iteration no. 63888 ==> 0.522981160052876\n",
            "Loss in iteration no. 63889 ==> 0.5229797839785988\n",
            "Loss in iteration no. 63890 ==> 0.5229784079187799\n",
            "Loss in iteration no. 63891 ==> 0.5229770318734187\n",
            "Loss in iteration no. 63892 ==> 0.5229756558425154\n",
            "Loss in iteration no. 63893 ==> 0.5229742798260693\n",
            "Loss in iteration no. 63894 ==> 0.5229729038240802\n",
            "Loss in iteration no. 63895 ==> 0.5229715278365482\n",
            "Loss in iteration no. 63896 ==> 0.5229701518634727\n",
            "Loss in iteration no. 63897 ==> 0.5229687759048538\n",
            "Loss in iteration no. 63898 ==> 0.5229673999606912\n",
            "Loss in iteration no. 63899 ==> 0.5229660240309845\n",
            "Loss in iteration no. 63900 ==> 0.5229646481157337\n",
            "Loss in iteration no. 63901 ==> 0.5229632722149385\n",
            "Loss in iteration no. 63902 ==> 0.5229618963285986\n",
            "Loss in iteration no. 63903 ==> 0.5229605204567137\n",
            "Loss in iteration no. 63904 ==> 0.5229591445992837\n",
            "Loss in iteration no. 63905 ==> 0.5229577687563084\n",
            "Loss in iteration no. 63906 ==> 0.5229563929277876\n",
            "Loss in iteration no. 63907 ==> 0.5229550171137209\n",
            "Loss in iteration no. 63908 ==> 0.5229536413141082\n",
            "Loss in iteration no. 63909 ==> 0.5229522655289491\n",
            "Loss in iteration no. 63910 ==> 0.5229508897582438\n",
            "Loss in iteration no. 63911 ==> 0.5229495140019914\n",
            "Loss in iteration no. 63912 ==> 0.5229481382601924\n",
            "Loss in iteration no. 63913 ==> 0.5229467625328461\n",
            "Loss in iteration no. 63914 ==> 0.5229453868199525\n",
            "Loss in iteration no. 63915 ==> 0.5229440111215112\n",
            "Loss in iteration no. 63916 ==> 0.522942635437522\n",
            "Loss in iteration no. 63917 ==> 0.5229412597679849\n",
            "Loss in iteration no. 63918 ==> 0.5229398841128992\n",
            "Loss in iteration no. 63919 ==> 0.5229385084722652\n",
            "Loss in iteration no. 63920 ==> 0.5229371328460823\n",
            "Loss in iteration no. 63921 ==> 0.5229357572343505\n",
            "Loss in iteration no. 63922 ==> 0.5229343816370694\n",
            "Loss in iteration no. 63923 ==> 0.522933006054239\n",
            "Loss in iteration no. 63924 ==> 0.5229316304858588\n",
            "Loss in iteration no. 63925 ==> 0.5229302549319289\n",
            "Loss in iteration no. 63926 ==> 0.5229288793924487\n",
            "Loss in iteration no. 63927 ==> 0.5229275038674182\n",
            "Loss in iteration no. 63928 ==> 0.522926128356837\n",
            "Loss in iteration no. 63929 ==> 0.522924752860705\n",
            "Loss in iteration no. 63930 ==> 0.5229233773790223\n",
            "Loss in iteration no. 63931 ==> 0.522922001911788\n",
            "Loss in iteration no. 63932 ==> 0.5229206264590023\n",
            "Loss in iteration no. 63933 ==> 0.5229192510206649\n",
            "Loss in iteration no. 63934 ==> 0.5229178755967756\n",
            "Loss in iteration no. 63935 ==> 0.5229165001873342\n",
            "Loss in iteration no. 63936 ==> 0.5229151247923401\n",
            "Loss in iteration no. 63937 ==> 0.5229137494117936\n",
            "Loss in iteration no. 63938 ==> 0.5229123740456942\n",
            "Loss in iteration no. 63939 ==> 0.5229109986940418\n",
            "Loss in iteration no. 63940 ==> 0.522909623356836\n",
            "Loss in iteration no. 63941 ==> 0.5229082480340765\n",
            "Loss in iteration no. 63942 ==> 0.5229068727257636\n",
            "Loss in iteration no. 63943 ==> 0.5229054974318965\n",
            "Loss in iteration no. 63944 ==> 0.5229041221524753\n",
            "Loss in iteration no. 63945 ==> 0.5229027468874996\n",
            "Loss in iteration no. 63946 ==> 0.5229013716369691\n",
            "Loss in iteration no. 63947 ==> 0.5228999964008838\n",
            "Loss in iteration no. 63948 ==> 0.5228986211792435\n",
            "Loss in iteration no. 63949 ==> 0.5228972459720476\n",
            "Loss in iteration no. 63950 ==> 0.5228958707792962\n",
            "Loss in iteration no. 63951 ==> 0.5228944956009892\n",
            "Loss in iteration no. 63952 ==> 0.522893120437126\n",
            "Loss in iteration no. 63953 ==> 0.5228917452877065\n",
            "Loss in iteration no. 63954 ==> 0.5228903701527304\n",
            "Loss in iteration no. 63955 ==> 0.522888995032198\n",
            "Loss in iteration no. 63956 ==> 0.5228876199261083\n",
            "Loss in iteration no. 63957 ==> 0.5228862448344617\n",
            "Loss in iteration no. 63958 ==> 0.5228848697572575\n",
            "Loss in iteration no. 63959 ==> 0.5228834946944956\n",
            "Loss in iteration no. 63960 ==> 0.522882119646176\n",
            "Loss in iteration no. 63961 ==> 0.5228807446122983\n",
            "Loss in iteration no. 63962 ==> 0.5228793695928622\n",
            "Loss in iteration no. 63963 ==> 0.5228779945878675\n",
            "Loss in iteration no. 63964 ==> 0.5228766195973144\n",
            "Loss in iteration no. 63965 ==> 0.522875244621202\n",
            "Loss in iteration no. 63966 ==> 0.5228738696595304\n",
            "Loss in iteration no. 63967 ==> 0.5228724947122996\n",
            "Loss in iteration no. 63968 ==> 0.522871119779509\n",
            "Loss in iteration no. 63969 ==> 0.5228697448611584\n",
            "Loss in iteration no. 63970 ==> 0.5228683699572477\n",
            "Loss in iteration no. 63971 ==> 0.5228669950677767\n",
            "Loss in iteration no. 63972 ==> 0.5228656201927451\n",
            "Loss in iteration no. 63973 ==> 0.5228642453321527\n",
            "Loss in iteration no. 63974 ==> 0.5228628704859993\n",
            "Loss in iteration no. 63975 ==> 0.5228614956542847\n",
            "Loss in iteration no. 63976 ==> 0.5228601208370086\n",
            "Loss in iteration no. 63977 ==> 0.5228587460341706\n",
            "Loss in iteration no. 63978 ==> 0.5228573712457707\n",
            "Loss in iteration no. 63979 ==> 0.5228559964718089\n",
            "Loss in iteration no. 63980 ==> 0.5228546217122845\n",
            "Loss in iteration no. 63981 ==> 0.5228532469671974\n",
            "Loss in iteration no. 63982 ==> 0.5228518722365476\n",
            "Loss in iteration no. 63983 ==> 0.5228504975203347\n",
            "Loss in iteration no. 63984 ==> 0.5228491228185586\n",
            "Loss in iteration no. 63985 ==> 0.5228477481312187\n",
            "Loss in iteration no. 63986 ==> 0.5228463734583153\n",
            "Loss in iteration no. 63987 ==> 0.5228449987998477\n",
            "Loss in iteration no. 63988 ==> 0.5228436241558161\n",
            "Loss in iteration no. 63989 ==> 0.52284224952622\n",
            "Loss in iteration no. 63990 ==> 0.5228408749110591\n",
            "Loss in iteration no. 63991 ==> 0.5228395003103334\n",
            "Loss in iteration no. 63992 ==> 0.5228381257240425\n",
            "Loss in iteration no. 63993 ==> 0.5228367511521864\n",
            "Loss in iteration no. 63994 ==> 0.5228353765947649\n",
            "Loss in iteration no. 63995 ==> 0.5228340020517773\n",
            "Loss in iteration no. 63996 ==> 0.5228326275232238\n",
            "Loss in iteration no. 63997 ==> 0.5228312530091039\n",
            "Loss in iteration no. 63998 ==> 0.5228298785094175\n",
            "Loss in iteration no. 63999 ==> 0.5228285040241646\n",
            "Loss in iteration no. 64000 ==> 0.5228271295533448\n",
            "Loss in iteration no. 64001 ==> 0.5228257550969577\n",
            "Loss in iteration no. 64002 ==> 0.5228243806550031\n",
            "Loss in iteration no. 64003 ==> 0.5228230062274811\n",
            "Loss in iteration no. 64004 ==> 0.5228216318143911\n",
            "Loss in iteration no. 64005 ==> 0.5228202574157331\n",
            "Loss in iteration no. 64006 ==> 0.5228188830315069\n",
            "Loss in iteration no. 64007 ==> 0.5228175086617118\n",
            "Loss in iteration no. 64008 ==> 0.5228161343063483\n",
            "Loss in iteration no. 64009 ==> 0.5228147599654158\n",
            "Loss in iteration no. 64010 ==> 0.5228133856389141\n",
            "Loss in iteration no. 64011 ==> 0.5228120113268429\n",
            "Loss in iteration no. 64012 ==> 0.522810637029202\n",
            "Loss in iteration no. 64013 ==> 0.5228092627459914\n",
            "Loss in iteration no. 64014 ==> 0.5228078884772106\n",
            "Loss in iteration no. 64015 ==> 0.5228065142228595\n",
            "Loss in iteration no. 64016 ==> 0.5228051399829376\n",
            "Loss in iteration no. 64017 ==> 0.5228037657574451\n",
            "Loss in iteration no. 64018 ==> 0.5228023915463816\n",
            "Loss in iteration no. 64019 ==> 0.5228010173497468\n",
            "Loss in iteration no. 64020 ==> 0.5227996431675406\n",
            "Loss in iteration no. 64021 ==> 0.5227982689997626\n",
            "Loss in iteration no. 64022 ==> 0.5227968948464127\n",
            "Loss in iteration no. 64023 ==> 0.5227955207074907\n",
            "Loss in iteration no. 64024 ==> 0.5227941465829963\n",
            "Loss in iteration no. 64025 ==> 0.5227927724729292\n",
            "Loss in iteration no. 64026 ==> 0.5227913983772894\n",
            "Loss in iteration no. 64027 ==> 0.5227900242960763\n",
            "Loss in iteration no. 64028 ==> 0.5227886502292902\n",
            "Loss in iteration no. 64029 ==> 0.5227872761769307\n",
            "Loss in iteration no. 64030 ==> 0.522785902138997\n",
            "Loss in iteration no. 64031 ==> 0.5227845281154897\n",
            "Loss in iteration no. 64032 ==> 0.5227831541064081\n",
            "Loss in iteration no. 64033 ==> 0.5227817801117521\n",
            "Loss in iteration no. 64034 ==> 0.5227804061315214\n",
            "Loss in iteration no. 64035 ==> 0.5227790321657158\n",
            "Loss in iteration no. 64036 ==> 0.522777658214335\n",
            "Loss in iteration no. 64037 ==> 0.5227762842773791\n",
            "Loss in iteration no. 64038 ==> 0.5227749103548476\n",
            "Loss in iteration no. 64039 ==> 0.5227735364467402\n",
            "Loss in iteration no. 64040 ==> 0.522772162553057\n",
            "Loss in iteration no. 64041 ==> 0.5227707886737973\n",
            "Loss in iteration no. 64042 ==> 0.5227694148089614\n",
            "Loss in iteration no. 64043 ==> 0.5227680409585487\n",
            "Loss in iteration no. 64044 ==> 0.522766667122559\n",
            "Loss in iteration no. 64045 ==> 0.5227652933009923\n",
            "Loss in iteration no. 64046 ==> 0.5227639194938482\n",
            "Loss in iteration no. 64047 ==> 0.5227625457011265\n",
            "Loss in iteration no. 64048 ==> 0.5227611719228269\n",
            "Loss in iteration no. 64049 ==> 0.5227597981589492\n",
            "Loss in iteration no. 64050 ==> 0.5227584244094934\n",
            "Loss in iteration no. 64051 ==> 0.5227570506744591\n",
            "Loss in iteration no. 64052 ==> 0.522755676953846\n",
            "Loss in iteration no. 64053 ==> 0.5227543032476538\n",
            "Loss in iteration no. 64054 ==> 0.5227529295558828\n",
            "Loss in iteration no. 64055 ==> 0.5227515558785321\n",
            "Loss in iteration no. 64056 ==> 0.5227501822156017\n",
            "Loss in iteration no. 64057 ==> 0.5227488085670916\n",
            "Loss in iteration no. 64058 ==> 0.5227474349330015\n",
            "Loss in iteration no. 64059 ==> 0.5227460613133308\n",
            "Loss in iteration no. 64060 ==> 0.5227446877080797\n",
            "Loss in iteration no. 64061 ==> 0.522743314117248\n",
            "Loss in iteration no. 64062 ==> 0.5227419405408351\n",
            "Loss in iteration no. 64063 ==> 0.5227405669788411\n",
            "Loss in iteration no. 64064 ==> 0.5227391934312655\n",
            "Loss in iteration no. 64065 ==> 0.5227378198981083\n",
            "Loss in iteration no. 64066 ==> 0.5227364463793692\n",
            "Loss in iteration no. 64067 ==> 0.522735072875048\n",
            "Loss in iteration no. 64068 ==> 0.5227336993851445\n",
            "Loss in iteration no. 64069 ==> 0.5227323259096583\n",
            "Loss in iteration no. 64070 ==> 0.5227309524485892\n",
            "Loss in iteration no. 64071 ==> 0.5227295790019374\n",
            "Loss in iteration no. 64072 ==> 0.5227282055697021\n",
            "Loss in iteration no. 64073 ==> 0.5227268321518833\n",
            "Loss in iteration no. 64074 ==> 0.522725458748481\n",
            "Loss in iteration no. 64075 ==> 0.5227240853594946\n",
            "Loss in iteration no. 64076 ==> 0.5227227119849238\n",
            "Loss in iteration no. 64077 ==> 0.5227213386247691\n",
            "Loss in iteration no. 64078 ==> 0.5227199652790294\n",
            "Loss in iteration no. 64079 ==> 0.522718591947705\n",
            "Loss in iteration no. 64080 ==> 0.5227172186307956\n",
            "Loss in iteration no. 64081 ==> 0.5227158453283007\n",
            "Loss in iteration no. 64082 ==> 0.5227144720402205\n",
            "Loss in iteration no. 64083 ==> 0.5227130987665545\n",
            "Loss in iteration no. 64084 ==> 0.5227117255073024\n",
            "Loss in iteration no. 64085 ==> 0.5227103522624641\n",
            "Loss in iteration no. 64086 ==> 0.5227089790320395\n",
            "Loss in iteration no. 64087 ==> 0.522707605816028\n",
            "Loss in iteration no. 64088 ==> 0.5227062326144298\n",
            "Loss in iteration no. 64089 ==> 0.5227048594272447\n",
            "Loss in iteration no. 64090 ==> 0.522703486254472\n",
            "Loss in iteration no. 64091 ==> 0.5227021130961118\n",
            "Loss in iteration no. 64092 ==> 0.5227007399521637\n",
            "Loss in iteration no. 64093 ==> 0.5226993668226276\n",
            "Loss in iteration no. 64094 ==> 0.5226979937075035\n",
            "Loss in iteration no. 64095 ==> 0.5226966206067906\n",
            "Loss in iteration no. 64096 ==> 0.5226952475204893\n",
            "Loss in iteration no. 64097 ==> 0.5226938744485989\n",
            "Loss in iteration no. 64098 ==> 0.5226925013911194\n",
            "Loss in iteration no. 64099 ==> 0.5226911283480505\n",
            "Loss in iteration no. 64100 ==> 0.522689755319392\n",
            "Loss in iteration no. 64101 ==> 0.5226883823051437\n",
            "Loss in iteration no. 64102 ==> 0.5226870093053053\n",
            "Loss in iteration no. 64103 ==> 0.5226856363198767\n",
            "Loss in iteration no. 64104 ==> 0.5226842633488575\n",
            "Loss in iteration no. 64105 ==> 0.5226828903922476\n",
            "Loss in iteration no. 64106 ==> 0.5226815174500468\n",
            "Loss in iteration no. 64107 ==> 0.5226801445222549\n",
            "Loss in iteration no. 64108 ==> 0.5226787716088713\n",
            "Loss in iteration no. 64109 ==> 0.5226773987098963\n",
            "Loss in iteration no. 64110 ==> 0.5226760258253292\n",
            "Loss in iteration no. 64111 ==> 0.5226746529551703\n",
            "Loss in iteration no. 64112 ==> 0.522673280099419\n",
            "Loss in iteration no. 64113 ==> 0.5226719072580751\n",
            "Loss in iteration no. 64114 ==> 0.5226705344311384\n",
            "Loss in iteration no. 64115 ==> 0.5226691616186088\n",
            "Loss in iteration no. 64116 ==> 0.5226677888204858\n",
            "Loss in iteration no. 64117 ==> 0.5226664160367696\n",
            "Loss in iteration no. 64118 ==> 0.5226650432674593\n",
            "Loss in iteration no. 64119 ==> 0.5226636705125556\n",
            "Loss in iteration no. 64120 ==> 0.5226622977720574\n",
            "Loss in iteration no. 64121 ==> 0.5226609250459652\n",
            "Loss in iteration no. 64122 ==> 0.5226595523342782\n",
            "Loss in iteration no. 64123 ==> 0.5226581796369963\n",
            "Loss in iteration no. 64124 ==> 0.5226568069541196\n",
            "Loss in iteration no. 64125 ==> 0.5226554342856475\n",
            "Loss in iteration no. 64126 ==> 0.52265406163158\n",
            "Loss in iteration no. 64127 ==> 0.5226526889919166\n",
            "Loss in iteration no. 64128 ==> 0.5226513163666575\n",
            "Loss in iteration no. 64129 ==> 0.5226499437558021\n",
            "Loss in iteration no. 64130 ==> 0.5226485711593504\n",
            "Loss in iteration no. 64131 ==> 0.522647198577302\n",
            "Loss in iteration no. 64132 ==> 0.5226458260096567\n",
            "Loss in iteration no. 64133 ==> 0.5226444534564144\n",
            "Loss in iteration no. 64134 ==> 0.5226430809175748\n",
            "Loss in iteration no. 64135 ==> 0.5226417083931377\n",
            "Loss in iteration no. 64136 ==> 0.522640335883103\n",
            "Loss in iteration no. 64137 ==> 0.52263896338747\n",
            "Loss in iteration no. 64138 ==> 0.5226375909062391\n",
            "Loss in iteration no. 64139 ==> 0.5226362184394097\n",
            "Loss in iteration no. 64140 ==> 0.5226348459869816\n",
            "Loss in iteration no. 64141 ==> 0.5226334735489544\n",
            "Loss in iteration no. 64142 ==> 0.5226321011253284\n",
            "Loss in iteration no. 64143 ==> 0.522630728716103\n",
            "Loss in iteration no. 64144 ==> 0.5226293563212779\n",
            "Loss in iteration no. 64145 ==> 0.5226279839408533\n",
            "Loss in iteration no. 64146 ==> 0.5226266115748285\n",
            "Loss in iteration no. 64147 ==> 0.5226252392232035\n",
            "Loss in iteration no. 64148 ==> 0.522623866885978\n",
            "Loss in iteration no. 64149 ==> 0.5226224945631518\n",
            "Loss in iteration no. 64150 ==> 0.5226211222547248\n",
            "Loss in iteration no. 64151 ==> 0.5226197499606966\n",
            "Loss in iteration no. 64152 ==> 0.522618377681067\n",
            "Loss in iteration no. 64153 ==> 0.5226170054158358\n",
            "Loss in iteration no. 64154 ==> 0.5226156331650028\n",
            "Loss in iteration no. 64155 ==> 0.5226142609285678\n",
            "Loss in iteration no. 64156 ==> 0.5226128887065307\n",
            "Loss in iteration no. 64157 ==> 0.5226115164988907\n",
            "Loss in iteration no. 64158 ==> 0.5226101443056482\n",
            "Loss in iteration no. 64159 ==> 0.5226087721268026\n",
            "Loss in iteration no. 64160 ==> 0.5226073999623542\n",
            "Loss in iteration no. 64161 ==> 0.5226060278123021\n",
            "Loss in iteration no. 64162 ==> 0.5226046556766464\n",
            "Loss in iteration no. 64163 ==> 0.5226032835553869\n",
            "Loss in iteration no. 64164 ==> 0.5226019114485232\n",
            "Loss in iteration no. 64165 ==> 0.5226005393560554\n",
            "Loss in iteration no. 64166 ==> 0.5225991672779828\n",
            "Loss in iteration no. 64167 ==> 0.5225977952143057\n",
            "Loss in iteration no. 64168 ==> 0.5225964231650235\n",
            "Loss in iteration no. 64169 ==> 0.5225950511301362\n",
            "Loss in iteration no. 64170 ==> 0.5225936791096433\n",
            "Loss in iteration no. 64171 ==> 0.5225923071035449\n",
            "Loss in iteration no. 64172 ==> 0.5225909351118405\n",
            "Loss in iteration no. 64173 ==> 0.5225895631345301\n",
            "Loss in iteration no. 64174 ==> 0.5225881911716133\n",
            "Loss in iteration no. 64175 ==> 0.5225868192230899\n",
            "Loss in iteration no. 64176 ==> 0.5225854472889597\n",
            "Loss in iteration no. 64177 ==> 0.5225840753692225\n",
            "Loss in iteration no. 64178 ==> 0.522582703463878\n",
            "Loss in iteration no. 64179 ==> 0.5225813315729261\n",
            "Loss in iteration no. 64180 ==> 0.5225799596963665\n",
            "Loss in iteration no. 64181 ==> 0.5225785878341989\n",
            "Loss in iteration no. 64182 ==> 0.5225772159864233\n",
            "Loss in iteration no. 64183 ==> 0.5225758441530394\n",
            "Loss in iteration no. 64184 ==> 0.5225744723340466\n",
            "Loss in iteration no. 64185 ==> 0.5225731005294452\n",
            "Loss in iteration no. 64186 ==> 0.5225717287392347\n",
            "Loss in iteration no. 64187 ==> 0.5225703569634149\n",
            "Loss in iteration no. 64188 ==> 0.5225689852019857\n",
            "Loss in iteration no. 64189 ==> 0.5225676134549466\n",
            "Loss in iteration no. 64190 ==> 0.5225662417222977\n",
            "Loss in iteration no. 64191 ==> 0.5225648700040384\n",
            "Loss in iteration no. 64192 ==> 0.5225634983001689\n",
            "Loss in iteration no. 64193 ==> 0.5225621266106888\n",
            "Loss in iteration no. 64194 ==> 0.5225607549355978\n",
            "Loss in iteration no. 64195 ==> 0.5225593832748956\n",
            "Loss in iteration no. 64196 ==> 0.5225580116285823\n",
            "Loss in iteration no. 64197 ==> 0.5225566399966572\n",
            "Loss in iteration no. 64198 ==> 0.5225552683791206\n",
            "Loss in iteration no. 64199 ==> 0.5225538967759719\n",
            "Loss in iteration no. 64200 ==> 0.5225525251872107\n",
            "Loss in iteration no. 64201 ==> 0.5225511536128374\n",
            "Loss in iteration no. 64202 ==> 0.5225497820528514\n",
            "Loss in iteration no. 64203 ==> 0.5225484105072525\n",
            "Loss in iteration no. 64204 ==> 0.5225470389760405\n",
            "Loss in iteration no. 64205 ==> 0.522545667459215\n",
            "Loss in iteration no. 64206 ==> 0.5225442959567761\n",
            "Loss in iteration no. 64207 ==> 0.5225429244687234\n",
            "Loss in iteration no. 64208 ==> 0.5225415529950566\n",
            "Loss in iteration no. 64209 ==> 0.5225401815357756\n",
            "Loss in iteration no. 64210 ==> 0.5225388100908802\n",
            "Loss in iteration no. 64211 ==> 0.5225374386603701\n",
            "Loss in iteration no. 64212 ==> 0.5225360672442448\n",
            "Loss in iteration no. 64213 ==> 0.5225346958425047\n",
            "Loss in iteration no. 64214 ==> 0.5225333244551491\n",
            "Loss in iteration no. 64215 ==> 0.5225319530821778\n",
            "Loss in iteration no. 64216 ==> 0.5225305817235908\n",
            "Loss in iteration no. 64217 ==> 0.5225292103793878\n",
            "Loss in iteration no. 64218 ==> 0.5225278390495683\n",
            "Loss in iteration no. 64219 ==> 0.5225264677341325\n",
            "Loss in iteration no. 64220 ==> 0.5225250964330799\n",
            "Loss in iteration no. 64221 ==> 0.5225237251464103\n",
            "Loss in iteration no. 64222 ==> 0.5225223538741236\n",
            "Loss in iteration no. 64223 ==> 0.5225209826162195\n",
            "Loss in iteration no. 64224 ==> 0.5225196113726976\n",
            "Loss in iteration no. 64225 ==> 0.5225182401435581\n",
            "Loss in iteration no. 64226 ==> 0.5225168689288003\n",
            "Loss in iteration no. 64227 ==> 0.5225154977284244\n",
            "Loss in iteration no. 64228 ==> 0.5225141265424298\n",
            "Loss in iteration no. 64229 ==> 0.5225127553708164\n",
            "Loss in iteration no. 64230 ==> 0.5225113842135841\n",
            "Loss in iteration no. 64231 ==> 0.5225100130707327\n",
            "Loss in iteration no. 64232 ==> 0.5225086419422618\n",
            "Loss in iteration no. 64233 ==> 0.5225072708281712\n",
            "Loss in iteration no. 64234 ==> 0.5225058997284608\n",
            "Loss in iteration no. 64235 ==> 0.5225045286431301\n",
            "Loss in iteration no. 64236 ==> 0.5225031575721792\n",
            "Loss in iteration no. 64237 ==> 0.5225017865156077\n",
            "Loss in iteration no. 64238 ==> 0.5225004154734155\n",
            "Loss in iteration no. 64239 ==> 0.5224990444456021\n",
            "Loss in iteration no. 64240 ==> 0.5224976734321676\n",
            "Loss in iteration no. 64241 ==> 0.5224963024331115\n",
            "Loss in iteration no. 64242 ==> 0.5224949314484338\n",
            "Loss in iteration no. 64243 ==> 0.5224935604781342\n",
            "Loss in iteration no. 64244 ==> 0.5224921895222124\n",
            "Loss in iteration no. 64245 ==> 0.5224908185806683\n",
            "Loss in iteration no. 64246 ==> 0.5224894476535016\n",
            "Loss in iteration no. 64247 ==> 0.522488076740712\n",
            "Loss in iteration no. 64248 ==> 0.5224867058422993\n",
            "Loss in iteration no. 64249 ==> 0.5224853349582634\n",
            "Loss in iteration no. 64250 ==> 0.5224839640886041\n",
            "Loss in iteration no. 64251 ==> 0.5224825932333211\n",
            "Loss in iteration no. 64252 ==> 0.522481222392414\n",
            "Loss in iteration no. 64253 ==> 0.5224798515658827\n",
            "Loss in iteration no. 64254 ==> 0.5224784807537272\n",
            "Loss in iteration no. 64255 ==> 0.522477109955947\n",
            "Loss in iteration no. 64256 ==> 0.5224757391725418\n",
            "Loss in iteration no. 64257 ==> 0.5224743684035118\n",
            "Loss in iteration no. 64258 ==> 0.5224729976488564\n",
            "Loss in iteration no. 64259 ==> 0.5224716269085751\n",
            "Loss in iteration no. 64260 ==> 0.5224702561826685\n",
            "Loss in iteration no. 64261 ==> 0.5224688854711357\n",
            "Loss in iteration no. 64262 ==> 0.5224675147739767\n",
            "Loss in iteration no. 64263 ==> 0.5224661440911915\n",
            "Loss in iteration no. 64264 ==> 0.5224647734227795\n",
            "Loss in iteration no. 64265 ==> 0.5224634027687404\n",
            "Loss in iteration no. 64266 ==> 0.5224620321290745\n",
            "Loss in iteration no. 64267 ==> 0.5224606615037812\n",
            "Loss in iteration no. 64268 ==> 0.5224592908928603\n",
            "Loss in iteration no. 64269 ==> 0.5224579202963117\n",
            "Loss in iteration no. 64270 ==> 0.522456549714135\n",
            "Loss in iteration no. 64271 ==> 0.5224551791463301\n",
            "Loss in iteration no. 64272 ==> 0.5224538085928966\n",
            "Loss in iteration no. 64273 ==> 0.5224524380538347\n",
            "Loss in iteration no. 64274 ==> 0.5224510675291437\n",
            "Loss in iteration no. 64275 ==> 0.5224496970188235\n",
            "Loss in iteration no. 64276 ==> 0.522448326522874\n",
            "Loss in iteration no. 64277 ==> 0.5224469560412951\n",
            "Loss in iteration no. 64278 ==> 0.5224455855740863\n",
            "Loss in iteration no. 64279 ==> 0.5224442151212473\n",
            "Loss in iteration no. 64280 ==> 0.5224428446827782\n",
            "Loss in iteration no. 64281 ==> 0.5224414742586785\n",
            "Loss in iteration no. 64282 ==> 0.5224401038489482\n",
            "Loss in iteration no. 64283 ==> 0.5224387334535869\n",
            "Loss in iteration no. 64284 ==> 0.5224373630725946\n",
            "Loss in iteration no. 64285 ==> 0.5224359927059706\n",
            "Loss in iteration no. 64286 ==> 0.5224346223537152\n",
            "Loss in iteration no. 64287 ==> 0.5224332520158279\n",
            "Loss in iteration no. 64288 ==> 0.5224318816923086\n",
            "Loss in iteration no. 64289 ==> 0.5224305113831569\n",
            "Loss in iteration no. 64290 ==> 0.5224291410883728\n",
            "Loss in iteration no. 64291 ==> 0.5224277708079559\n",
            "Loss in iteration no. 64292 ==> 0.5224264005419059\n",
            "Loss in iteration no. 64293 ==> 0.5224250302902229\n",
            "Loss in iteration no. 64294 ==> 0.5224236600529064\n",
            "Loss in iteration no. 64295 ==> 0.5224222898299564\n",
            "Loss in iteration no. 64296 ==> 0.5224209196213723\n",
            "Loss in iteration no. 64297 ==> 0.5224195494271543\n",
            "Loss in iteration no. 64298 ==> 0.5224181792473018\n",
            "Loss in iteration no. 64299 ==> 0.5224168090818148\n",
            "Loss in iteration no. 64300 ==> 0.5224154389306932\n",
            "Loss in iteration no. 64301 ==> 0.5224140687939365\n",
            "Loss in iteration no. 64302 ==> 0.5224126986715446\n",
            "Loss in iteration no. 64303 ==> 0.5224113285635174\n",
            "Loss in iteration no. 64304 ==> 0.5224099584698543\n",
            "Loss in iteration no. 64305 ==> 0.5224085883905553\n",
            "Loss in iteration no. 64306 ==> 0.5224072183256203\n",
            "Loss in iteration no. 64307 ==> 0.522405848275049\n",
            "Loss in iteration no. 64308 ==> 0.522404478238841\n",
            "Loss in iteration no. 64309 ==> 0.5224031082169962\n",
            "Loss in iteration no. 64310 ==> 0.5224017382095144\n",
            "Loss in iteration no. 64311 ==> 0.5224003682163953\n",
            "Loss in iteration no. 64312 ==> 0.5223989982376388\n",
            "Loss in iteration no. 64313 ==> 0.5223976282732447\n",
            "Loss in iteration no. 64314 ==> 0.5223962583232126\n",
            "Loss in iteration no. 64315 ==> 0.5223948883875422\n",
            "Loss in iteration no. 64316 ==> 0.5223935184662336\n",
            "Loss in iteration no. 64317 ==> 0.5223921485592866\n",
            "Loss in iteration no. 64318 ==> 0.5223907786667004\n",
            "Loss in iteration no. 64319 ==> 0.5223894087884753\n",
            "Loss in iteration no. 64320 ==> 0.522388038924611\n",
            "Loss in iteration no. 64321 ==> 0.5223866690751071\n",
            "Loss in iteration no. 64322 ==> 0.5223852992399635\n",
            "Loss in iteration no. 64323 ==> 0.52238392941918\n",
            "Loss in iteration no. 64324 ==> 0.5223825596127563\n",
            "Loss in iteration no. 64325 ==> 0.5223811898206921\n",
            "Loss in iteration no. 64326 ==> 0.5223798200429873\n",
            "Loss in iteration no. 64327 ==> 0.5223784502796418\n",
            "Loss in iteration no. 64328 ==> 0.5223770805306551\n",
            "Loss in iteration no. 64329 ==> 0.5223757107960271\n",
            "Loss in iteration no. 64330 ==> 0.5223743410757576\n",
            "Loss in iteration no. 64331 ==> 0.5223729713698464\n",
            "Loss in iteration no. 64332 ==> 0.5223716016782931\n",
            "Loss in iteration no. 64333 ==> 0.5223702320010979\n",
            "Loss in iteration no. 64334 ==> 0.52236886233826\n",
            "Loss in iteration no. 64335 ==> 0.5223674926897796\n",
            "Loss in iteration no. 64336 ==> 0.5223661230556563\n",
            "Loss in iteration no. 64337 ==> 0.5223647534358898\n",
            "Loss in iteration no. 64338 ==> 0.5223633838304799\n",
            "Loss in iteration no. 64339 ==> 0.5223620142394266\n",
            "Loss in iteration no. 64340 ==> 0.5223606446627295\n",
            "Loss in iteration no. 64341 ==> 0.5223592751003884\n",
            "Loss in iteration no. 64342 ==> 0.522357905552403\n",
            "Loss in iteration no. 64343 ==> 0.5223565360187732\n",
            "Loss in iteration no. 64344 ==> 0.5223551664994989\n",
            "Loss in iteration no. 64345 ==> 0.5223537969945795\n",
            "Loss in iteration no. 64346 ==> 0.522352427504015\n",
            "Loss in iteration no. 64347 ==> 0.5223510580278051\n",
            "Loss in iteration no. 64348 ==> 0.5223496885659498\n",
            "Loss in iteration no. 64349 ==> 0.5223483191184486\n",
            "Loss in iteration no. 64350 ==> 0.5223469496853013\n",
            "Loss in iteration no. 64351 ==> 0.5223455802665078\n",
            "Loss in iteration no. 64352 ==> 0.5223442108620678\n",
            "Loss in iteration no. 64353 ==> 0.5223428414719813\n",
            "Loss in iteration no. 64354 ==> 0.5223414720962477\n",
            "Loss in iteration no. 64355 ==> 0.5223401027348669\n",
            "Loss in iteration no. 64356 ==> 0.5223387333878386\n",
            "Loss in iteration no. 64357 ==> 0.5223373640551631\n",
            "Loss in iteration no. 64358 ==> 0.5223359947368396\n",
            "Loss in iteration no. 64359 ==> 0.5223346254328679\n",
            "Loss in iteration no. 64360 ==> 0.5223332561432482\n",
            "Loss in iteration no. 64361 ==> 0.5223318868679797\n",
            "Loss in iteration no. 64362 ==> 0.5223305176070626\n",
            "Loss in iteration no. 64363 ==> 0.5223291483604966\n",
            "Loss in iteration no. 64364 ==> 0.5223277791282814\n",
            "Loss in iteration no. 64365 ==> 0.5223264099104168\n",
            "Loss in iteration no. 64366 ==> 0.5223250407069026\n",
            "Loss in iteration no. 64367 ==> 0.5223236715177384\n",
            "Loss in iteration no. 64368 ==> 0.5223223023429243\n",
            "Loss in iteration no. 64369 ==> 0.5223209331824598\n",
            "Loss in iteration no. 64370 ==> 0.5223195640363449\n",
            "Loss in iteration no. 64371 ==> 0.5223181949045791\n",
            "Loss in iteration no. 64372 ==> 0.5223168257871624\n",
            "Loss in iteration no. 64373 ==> 0.5223154566840945\n",
            "Loss in iteration no. 64374 ==> 0.5223140875953752\n",
            "Loss in iteration no. 64375 ==> 0.5223127185210042\n",
            "Loss in iteration no. 64376 ==> 0.5223113494609813\n",
            "Loss in iteration no. 64377 ==> 0.5223099804153065\n",
            "Loss in iteration no. 64378 ==> 0.5223086113839791\n",
            "Loss in iteration no. 64379 ==> 0.5223072423669991\n",
            "Loss in iteration no. 64380 ==> 0.5223058733643665\n",
            "Loss in iteration no. 64381 ==> 0.5223045043760811\n",
            "Loss in iteration no. 64382 ==> 0.5223031354021422\n",
            "Loss in iteration no. 64383 ==> 0.52230176644255\n",
            "Loss in iteration no. 64384 ==> 0.5223003974973042\n",
            "Loss in iteration no. 64385 ==> 0.5222990285664043\n",
            "Loss in iteration no. 64386 ==> 0.5222976596498502\n",
            "Loss in iteration no. 64387 ==> 0.522296290747642\n",
            "Loss in iteration no. 64388 ==> 0.5222949218597791\n",
            "Loss in iteration no. 64389 ==> 0.5222935529862613\n",
            "Loss in iteration no. 64390 ==> 0.5222921841270888\n",
            "Loss in iteration no. 64391 ==> 0.5222908152822606\n",
            "Loss in iteration no. 64392 ==> 0.5222894464517774\n",
            "Loss in iteration no. 64393 ==> 0.5222880776356383\n",
            "Loss in iteration no. 64394 ==> 0.5222867088338431\n",
            "Loss in iteration no. 64395 ==> 0.522285340046392\n",
            "Loss in iteration no. 64396 ==> 0.5222839712732845\n",
            "Loss in iteration no. 64397 ==> 0.5222826025145204\n",
            "Loss in iteration no. 64398 ==> 0.5222812337700994\n",
            "Loss in iteration no. 64399 ==> 0.5222798650400216\n",
            "Loss in iteration no. 64400 ==> 0.5222784963242861\n",
            "Loss in iteration no. 64401 ==> 0.5222771276228934\n",
            "Loss in iteration no. 64402 ==> 0.522275758935843\n",
            "Loss in iteration no. 64403 ==> 0.5222743902631345\n",
            "Loss in iteration no. 64404 ==> 0.522273021604768\n",
            "Loss in iteration no. 64405 ==> 0.522271652960743\n",
            "Loss in iteration no. 64406 ==> 0.5222702843310594\n",
            "Loss in iteration no. 64407 ==> 0.5222689157157169\n",
            "Loss in iteration no. 64408 ==> 0.5222675471147155\n",
            "Loss in iteration no. 64409 ==> 0.5222661785280546\n",
            "Loss in iteration no. 64410 ==> 0.5222648099557342\n",
            "Loss in iteration no. 64411 ==> 0.5222634413977542\n",
            "Loss in iteration no. 64412 ==> 0.5222620728541142\n",
            "Loss in iteration no. 64413 ==> 0.5222607043248139\n",
            "Loss in iteration no. 64414 ==> 0.5222593358098533\n",
            "Loss in iteration no. 64415 ==> 0.522257967309232\n",
            "Loss in iteration no. 64416 ==> 0.52225659882295\n",
            "Loss in iteration no. 64417 ==> 0.5222552303510067\n",
            "Loss in iteration no. 64418 ==> 0.5222538618934021\n",
            "Loss in iteration no. 64419 ==> 0.522252493450136\n",
            "Loss in iteration no. 64420 ==> 0.5222511250212083\n",
            "Loss in iteration no. 64421 ==> 0.5222497566066185\n",
            "Loss in iteration no. 64422 ==> 0.5222483882063664\n",
            "Loss in iteration no. 64423 ==> 0.5222470198204519\n",
            "Loss in iteration no. 64424 ==> 0.5222456514488749\n",
            "Loss in iteration no. 64425 ==> 0.5222442830916348\n",
            "Loss in iteration no. 64426 ==> 0.5222429147487316\n",
            "Loss in iteration no. 64427 ==> 0.5222415464201653\n",
            "Loss in iteration no. 64428 ==> 0.5222401781059353\n",
            "Loss in iteration no. 64429 ==> 0.5222388098060414\n",
            "Loss in iteration no. 64430 ==> 0.5222374415204837\n",
            "Loss in iteration no. 64431 ==> 0.5222360732492617\n",
            "Loss in iteration no. 64432 ==> 0.522234704992375\n",
            "Loss in iteration no. 64433 ==> 0.5222333367498239\n",
            "Loss in iteration no. 64434 ==> 0.5222319685216077\n",
            "Loss in iteration no. 64435 ==> 0.5222306003077266\n",
            "Loss in iteration no. 64436 ==> 0.52222923210818\n",
            "Loss in iteration no. 64437 ==> 0.5222278639229679\n",
            "Loss in iteration no. 64438 ==> 0.5222264957520899\n",
            "Loss in iteration no. 64439 ==> 0.522225127595546\n",
            "Loss in iteration no. 64440 ==> 0.5222237594533357\n",
            "Loss in iteration no. 64441 ==> 0.5222223913254589\n",
            "Loss in iteration no. 64442 ==> 0.5222210232119154\n",
            "Loss in iteration no. 64443 ==> 0.5222196551127052\n",
            "Loss in iteration no. 64444 ==> 0.5222182870278276\n",
            "Loss in iteration no. 64445 ==> 0.5222169189572828\n",
            "Loss in iteration no. 64446 ==> 0.5222155509010704\n",
            "Loss in iteration no. 64447 ==> 0.52221418285919\n",
            "Loss in iteration no. 64448 ==> 0.5222128148316417\n",
            "Loss in iteration no. 64449 ==> 0.522211446818425\n",
            "Loss in iteration no. 64450 ==> 0.52221007881954\n",
            "Loss in iteration no. 64451 ==> 0.5222087108349861\n",
            "Loss in iteration no. 64452 ==> 0.5222073428647633\n",
            "Loss in iteration no. 64453 ==> 0.5222059749088713\n",
            "Loss in iteration no. 64454 ==> 0.5222046069673101\n",
            "Loss in iteration no. 64455 ==> 0.5222032390400789\n",
            "Loss in iteration no. 64456 ==> 0.5222018711271781\n",
            "Loss in iteration no. 64457 ==> 0.5222005032286072\n",
            "Loss in iteration no. 64458 ==> 0.522199135344366\n",
            "Loss in iteration no. 64459 ==> 0.5221977674744545\n",
            "Loss in iteration no. 64460 ==> 0.522196399618872\n",
            "Loss in iteration no. 64461 ==> 0.5221950317776185\n",
            "Loss in iteration no. 64462 ==> 0.5221936639506939\n",
            "Loss in iteration no. 64463 ==> 0.5221922961380979\n",
            "Loss in iteration no. 64464 ==> 0.5221909283398302\n",
            "Loss in iteration no. 64465 ==> 0.5221895605558907\n",
            "Loss in iteration no. 64466 ==> 0.522188192786279\n",
            "Loss in iteration no. 64467 ==> 0.5221868250309951\n",
            "Loss in iteration no. 64468 ==> 0.5221854572900386\n",
            "Loss in iteration no. 64469 ==> 0.5221840895634094\n",
            "Loss in iteration no. 64470 ==> 0.5221827218511073\n",
            "Loss in iteration no. 64471 ==> 0.5221813541531316\n",
            "Loss in iteration no. 64472 ==> 0.5221799864694828\n",
            "Loss in iteration no. 64473 ==> 0.5221786188001604\n",
            "Loss in iteration no. 64474 ==> 0.5221772511451639\n",
            "Loss in iteration no. 64475 ==> 0.5221758835044934\n",
            "Loss in iteration no. 64476 ==> 0.5221745158781484\n",
            "Loss in iteration no. 64477 ==> 0.5221731482661292\n",
            "Loss in iteration no. 64478 ==> 0.522171780668435\n",
            "Loss in iteration no. 64479 ==> 0.5221704130850658\n",
            "Loss in iteration no. 64480 ==> 0.5221690455160214\n",
            "Loss in iteration no. 64481 ==> 0.5221676779613014\n",
            "Loss in iteration no. 64482 ==> 0.522166310420906\n",
            "Loss in iteration no. 64483 ==> 0.5221649428948345\n",
            "Loss in iteration no. 64484 ==> 0.5221635753830868\n",
            "Loss in iteration no. 64485 ==> 0.5221622078856629\n",
            "Loss in iteration no. 64486 ==> 0.5221608404025624\n",
            "Loss in iteration no. 64487 ==> 0.5221594729337852\n",
            "Loss in iteration no. 64488 ==> 0.5221581054793307\n",
            "Loss in iteration no. 64489 ==> 0.5221567380391993\n",
            "Loss in iteration no. 64490 ==> 0.5221553706133901\n",
            "Loss in iteration no. 64491 ==> 0.5221540032019034\n",
            "Loss in iteration no. 64492 ==> 0.5221526358047387\n",
            "Loss in iteration no. 64493 ==> 0.5221512684218959\n",
            "Loss in iteration no. 64494 ==> 0.5221499010533746\n",
            "Loss in iteration no. 64495 ==> 0.5221485336991749\n",
            "Loss in iteration no. 64496 ==> 0.5221471663592963\n",
            "Loss in iteration no. 64497 ==> 0.5221457990337386\n",
            "Loss in iteration no. 64498 ==> 0.5221444317225018\n",
            "Loss in iteration no. 64499 ==> 0.5221430644255853\n",
            "Loss in iteration no. 64500 ==> 0.5221416971429893\n",
            "Loss in iteration no. 64501 ==> 0.5221403298747133\n",
            "Loss in iteration no. 64502 ==> 0.5221389626207571\n",
            "Loss in iteration no. 64503 ==> 0.5221375953811205\n",
            "Loss in iteration no. 64504 ==> 0.5221362281558032\n",
            "Loss in iteration no. 64505 ==> 0.5221348609448052\n",
            "Loss in iteration no. 64506 ==> 0.5221334937481261\n",
            "Loss in iteration no. 64507 ==> 0.5221321265657657\n",
            "Loss in iteration no. 64508 ==> 0.5221307593977237\n",
            "Loss in iteration no. 64509 ==> 0.522129392244\n",
            "Loss in iteration no. 64510 ==> 0.5221280251045946\n",
            "Loss in iteration no. 64511 ==> 0.5221266579795067\n",
            "Loss in iteration no. 64512 ==> 0.5221252908687366\n",
            "Loss in iteration no. 64513 ==> 0.5221239237722838\n",
            "Loss in iteration no. 64514 ==> 0.5221225566901482\n",
            "Loss in iteration no. 64515 ==> 0.5221211896223296\n",
            "Loss in iteration no. 64516 ==> 0.5221198225688274\n",
            "Loss in iteration no. 64517 ==> 0.5221184555296419\n",
            "Loss in iteration no. 64518 ==> 0.5221170885047727\n",
            "Loss in iteration no. 64519 ==> 0.5221157214942195\n",
            "Loss in iteration no. 64520 ==> 0.5221143544979819\n",
            "Loss in iteration no. 64521 ==> 0.5221129875160601\n",
            "Loss in iteration no. 64522 ==> 0.5221116205484534\n",
            "Loss in iteration no. 64523 ==> 0.522110253595162\n",
            "Loss in iteration no. 64524 ==> 0.5221088866561856\n",
            "Loss in iteration no. 64525 ==> 0.5221075197315238\n",
            "Loss in iteration no. 64526 ==> 0.5221061528211763\n",
            "Loss in iteration no. 64527 ==> 0.5221047859251433\n",
            "Loss in iteration no. 64528 ==> 0.5221034190434242\n",
            "Loss in iteration no. 64529 ==> 0.5221020521760188\n",
            "Loss in iteration no. 64530 ==> 0.5221006853229271\n",
            "Loss in iteration no. 64531 ==> 0.5220993184841487\n",
            "Loss in iteration no. 64532 ==> 0.5220979516596834\n",
            "Loss in iteration no. 64533 ==> 0.5220965848495309\n",
            "Loss in iteration no. 64534 ==> 0.5220952180536912\n",
            "Loss in iteration no. 64535 ==> 0.5220938512721639\n",
            "Loss in iteration no. 64536 ==> 0.5220924845049487\n",
            "Loss in iteration no. 64537 ==> 0.5220911177520458\n",
            "Loss in iteration no. 64538 ==> 0.5220897510134543\n",
            "Loss in iteration no. 64539 ==> 0.5220883842891746\n",
            "Loss in iteration no. 64540 ==> 0.5220870175792062\n",
            "Loss in iteration no. 64541 ==> 0.5220856508835487\n",
            "Loss in iteration no. 64542 ==> 0.5220842842022022\n",
            "Loss in iteration no. 64543 ==> 0.5220829175351664\n",
            "Loss in iteration no. 64544 ==> 0.5220815508824411\n",
            "Loss in iteration no. 64545 ==> 0.5220801842440258\n",
            "Loss in iteration no. 64546 ==> 0.5220788176199207\n",
            "Loss in iteration no. 64547 ==> 0.5220774510101253\n",
            "Loss in iteration no. 64548 ==> 0.5220760844146393\n",
            "Loss in iteration no. 64549 ==> 0.5220747178334626\n",
            "Loss in iteration no. 64550 ==> 0.5220733512665952\n",
            "Loss in iteration no. 64551 ==> 0.5220719847140365\n",
            "Loss in iteration no. 64552 ==> 0.5220706181757864\n",
            "Loss in iteration no. 64553 ==> 0.5220692516518448\n",
            "Loss in iteration no. 64554 ==> 0.5220678851422114\n",
            "Loss in iteration no. 64555 ==> 0.5220665186468858\n",
            "Loss in iteration no. 64556 ==> 0.5220651521658681\n",
            "Loss in iteration no. 64557 ==> 0.5220637856991578\n",
            "Loss in iteration no. 64558 ==> 0.522062419246755\n",
            "Loss in iteration no. 64559 ==> 0.5220610528086591\n",
            "Loss in iteration no. 64560 ==> 0.5220596863848701\n",
            "Loss in iteration no. 64561 ==> 0.5220583199753878\n",
            "Loss in iteration no. 64562 ==> 0.5220569535802116\n",
            "Loss in iteration no. 64563 ==> 0.5220555871993419\n",
            "Loss in iteration no. 64564 ==> 0.522054220832778\n",
            "Loss in iteration no. 64565 ==> 0.5220528544805196\n",
            "Loss in iteration no. 64566 ==> 0.5220514881425672\n",
            "Loss in iteration no. 64567 ==> 0.5220501218189197\n",
            "Loss in iteration no. 64568 ==> 0.5220487555095774\n",
            "Loss in iteration no. 64569 ==> 0.5220473892145399\n",
            "Loss in iteration no. 64570 ==> 0.5220460229338071\n",
            "Loss in iteration no. 64571 ==> 0.5220446566673786\n",
            "Loss in iteration no. 64572 ==> 0.5220432904152543\n",
            "Loss in iteration no. 64573 ==> 0.5220419241774339\n",
            "Loss in iteration no. 64574 ==> 0.5220405579539171\n",
            "Loss in iteration no. 64575 ==> 0.5220391917447039\n",
            "Loss in iteration no. 64576 ==> 0.5220378255497939\n",
            "Loss in iteration no. 64577 ==> 0.5220364593691871\n",
            "Loss in iteration no. 64578 ==> 0.522035093202883\n",
            "Loss in iteration no. 64579 ==> 0.5220337270508815\n",
            "Loss in iteration no. 64580 ==> 0.5220323609131824\n",
            "Loss in iteration no. 64581 ==> 0.5220309947897854\n",
            "Loss in iteration no. 64582 ==> 0.5220296286806902\n",
            "Loss in iteration no. 64583 ==> 0.522028262585897\n",
            "Loss in iteration no. 64584 ==> 0.522026896505405\n",
            "Loss in iteration no. 64585 ==> 0.5220255304392145\n",
            "Loss in iteration no. 64586 ==> 0.5220241643873249\n",
            "Loss in iteration no. 64587 ==> 0.5220227983497361\n",
            "Loss in iteration no. 64588 ==> 0.5220214323264478\n",
            "Loss in iteration no. 64589 ==> 0.52202006631746\n",
            "Loss in iteration no. 64590 ==> 0.5220187003227722\n",
            "Loss in iteration no. 64591 ==> 0.5220173343423843\n",
            "Loss in iteration no. 64592 ==> 0.5220159683762962\n",
            "Loss in iteration no. 64593 ==> 0.5220146024245075\n",
            "Loss in iteration no. 64594 ==> 0.522013236487018\n",
            "Loss in iteration no. 64595 ==> 0.5220118705638276\n",
            "Loss in iteration no. 64596 ==> 0.5220105046549359\n",
            "Loss in iteration no. 64597 ==> 0.5220091387603429\n",
            "Loss in iteration no. 64598 ==> 0.5220077728800481\n",
            "Loss in iteration no. 64599 ==> 0.5220064070140514\n",
            "Loss in iteration no. 64600 ==> 0.5220050411623528\n",
            "Loss in iteration no. 64601 ==> 0.5220036753249517\n",
            "Loss in iteration no. 64602 ==> 0.522002309501848\n",
            "Loss in iteration no. 64603 ==> 0.5220009436930416\n",
            "Loss in iteration no. 64604 ==> 0.5219995778985324\n",
            "Loss in iteration no. 64605 ==> 0.5219982121183198\n",
            "Loss in iteration no. 64606 ==> 0.5219968463524035\n",
            "Loss in iteration no. 64607 ==> 0.5219954806007838\n",
            "Loss in iteration no. 64608 ==> 0.5219941148634603\n",
            "Loss in iteration no. 64609 ==> 0.5219927491404325\n",
            "Loss in iteration no. 64610 ==> 0.5219913834317004\n",
            "Loss in iteration no. 64611 ==> 0.5219900177372638\n",
            "Loss in iteration no. 64612 ==> 0.5219886520571224\n",
            "Loss in iteration no. 64613 ==> 0.5219872863912759\n",
            "Loss in iteration no. 64614 ==> 0.5219859207397243\n",
            "Loss in iteration no. 64615 ==> 0.5219845551024671\n",
            "Loss in iteration no. 64616 ==> 0.5219831894795043\n",
            "Loss in iteration no. 64617 ==> 0.5219818238708356\n",
            "Loss in iteration no. 64618 ==> 0.5219804582764607\n",
            "Loss in iteration no. 64619 ==> 0.5219790926963794\n",
            "Loss in iteration no. 64620 ==> 0.5219777271305917\n",
            "Loss in iteration no. 64621 ==> 0.5219763615790971\n",
            "Loss in iteration no. 64622 ==> 0.5219749960418955\n",
            "Loss in iteration no. 64623 ==> 0.5219736305189866\n",
            "Loss in iteration no. 64624 ==> 0.5219722650103703\n",
            "Loss in iteration no. 64625 ==> 0.5219708995160462\n",
            "Loss in iteration no. 64626 ==> 0.5219695340360144\n",
            "Loss in iteration no. 64627 ==> 0.5219681685702742\n",
            "Loss in iteration no. 64628 ==> 0.5219668031188259\n",
            "Loss in iteration no. 64629 ==> 0.5219654376816687\n",
            "Loss in iteration no. 64630 ==> 0.5219640722588029\n",
            "Loss in iteration no. 64631 ==> 0.521962706850228\n",
            "Loss in iteration no. 64632 ==> 0.521961341455944\n",
            "Loss in iteration no. 64633 ==> 0.5219599760759503\n",
            "Loss in iteration no. 64634 ==> 0.521958610710247\n",
            "Loss in iteration no. 64635 ==> 0.5219572453588338\n",
            "Loss in iteration no. 64636 ==> 0.5219558800217102\n",
            "Loss in iteration no. 64637 ==> 0.5219545146988765\n",
            "Loss in iteration no. 64638 ==> 0.5219531493903322\n",
            "Loss in iteration no. 64639 ==> 0.521951784096077\n",
            "Loss in iteration no. 64640 ==> 0.5219504188161107\n",
            "Loss in iteration no. 64641 ==> 0.5219490535504331\n",
            "Loss in iteration no. 64642 ==> 0.5219476882990444\n",
            "Loss in iteration no. 64643 ==> 0.5219463230619434\n",
            "Loss in iteration no. 64644 ==> 0.5219449578391309\n",
            "Loss in iteration no. 64645 ==> 0.5219435926306059\n",
            "Loss in iteration no. 64646 ==> 0.5219422274363686\n",
            "Loss in iteration no. 64647 ==> 0.521940862256419\n",
            "Loss in iteration no. 64648 ==> 0.5219394970907562\n",
            "Loss in iteration no. 64649 ==> 0.5219381319393805\n",
            "Loss in iteration no. 64650 ==> 0.5219367668022915\n",
            "Loss in iteration no. 64651 ==> 0.521935401679489\n",
            "Loss in iteration no. 64652 ==> 0.5219340365709726\n",
            "Loss in iteration no. 64653 ==> 0.5219326714767426\n",
            "Loss in iteration no. 64654 ==> 0.5219313063967983\n",
            "Loss in iteration no. 64655 ==> 0.5219299413311396\n",
            "Loss in iteration no. 64656 ==> 0.5219285762797662\n",
            "Loss in iteration no. 64657 ==> 0.5219272112426779\n",
            "Loss in iteration no. 64658 ==> 0.5219258462198747\n",
            "Loss in iteration no. 64659 ==> 0.5219244812113562\n",
            "Loss in iteration no. 64660 ==> 0.5219231162171221\n",
            "Loss in iteration no. 64661 ==> 0.5219217512371723\n",
            "Loss in iteration no. 64662 ==> 0.5219203862715064\n",
            "Loss in iteration no. 64663 ==> 0.5219190213201245\n",
            "Loss in iteration no. 64664 ==> 0.5219176563830261\n",
            "Loss in iteration no. 64665 ==> 0.5219162914602111\n",
            "Loss in iteration no. 64666 ==> 0.5219149265516794\n",
            "Loss in iteration no. 64667 ==> 0.5219135616574303\n",
            "Loss in iteration no. 64668 ==> 0.5219121967774643\n",
            "Loss in iteration no. 64669 ==> 0.5219108319117803\n",
            "Loss in iteration no. 64670 ==> 0.5219094670603789\n",
            "Loss in iteration no. 64671 ==> 0.5219081022232595\n",
            "Loss in iteration no. 64672 ==> 0.5219067374004217\n",
            "Loss in iteration no. 64673 ==> 0.5219053725918658\n",
            "Loss in iteration no. 64674 ==> 0.521904007797591\n",
            "Loss in iteration no. 64675 ==> 0.5219026430175975\n",
            "Loss in iteration no. 64676 ==> 0.5219012782518848\n",
            "Loss in iteration no. 64677 ==> 0.5218999135004527\n",
            "Loss in iteration no. 64678 ==> 0.5218985487633013\n",
            "Loss in iteration no. 64679 ==> 0.5218971840404301\n",
            "Loss in iteration no. 64680 ==> 0.5218958193318388\n",
            "Loss in iteration no. 64681 ==> 0.5218944546375274\n",
            "Loss in iteration no. 64682 ==> 0.5218930899574955\n",
            "Loss in iteration no. 64683 ==> 0.521891725291743\n",
            "Loss in iteration no. 64684 ==> 0.5218903606402697\n",
            "Loss in iteration no. 64685 ==> 0.5218889960030751\n",
            "Loss in iteration no. 64686 ==> 0.5218876313801594\n",
            "Loss in iteration no. 64687 ==> 0.5218862667715221\n",
            "Loss in iteration no. 64688 ==> 0.5218849021771629\n",
            "Loss in iteration no. 64689 ==> 0.5218835375970818\n",
            "Loss in iteration no. 64690 ==> 0.5218821730312786\n",
            "Loss in iteration no. 64691 ==> 0.5218808084797528\n",
            "Loss in iteration no. 64692 ==> 0.5218794439425044\n",
            "Loss in iteration no. 64693 ==> 0.5218780794195332\n",
            "Loss in iteration no. 64694 ==> 0.5218767149108389\n",
            "Loss in iteration no. 64695 ==> 0.5218753504164212\n",
            "Loss in iteration no. 64696 ==> 0.52187398593628\n",
            "Loss in iteration no. 64697 ==> 0.5218726214704149\n",
            "Loss in iteration no. 64698 ==> 0.521871257018826\n",
            "Loss in iteration no. 64699 ==> 0.5218698925815128\n",
            "Loss in iteration no. 64700 ==> 0.5218685281584752\n",
            "Loss in iteration no. 64701 ==> 0.5218671637497129\n",
            "Loss in iteration no. 64702 ==> 0.5218657993552255\n",
            "Loss in iteration no. 64703 ==> 0.5218644349750132\n",
            "Loss in iteration no. 64704 ==> 0.5218630706090757\n",
            "Loss in iteration no. 64705 ==> 0.5218617062574123\n",
            "Loss in iteration no. 64706 ==> 0.5218603419200233\n",
            "Loss in iteration no. 64707 ==> 0.5218589775969084\n",
            "Loss in iteration no. 64708 ==> 0.521857613288067\n",
            "Loss in iteration no. 64709 ==> 0.5218562489934995\n",
            "Loss in iteration no. 64710 ==> 0.5218548847132051\n",
            "Loss in iteration no. 64711 ==> 0.5218535204471839\n",
            "Loss in iteration no. 64712 ==> 0.5218521561954356\n",
            "Loss in iteration no. 64713 ==> 0.5218507919579599\n",
            "Loss in iteration no. 64714 ==> 0.5218494277347566\n",
            "Loss in iteration no. 64715 ==> 0.5218480635258255\n",
            "Loss in iteration no. 64716 ==> 0.5218466993311667\n",
            "Loss in iteration no. 64717 ==> 0.5218453351507791\n",
            "Loss in iteration no. 64718 ==> 0.5218439709846635\n",
            "Loss in iteration no. 64719 ==> 0.5218426068328191\n",
            "Loss in iteration no. 64720 ==> 0.5218412426952457\n",
            "Loss in iteration no. 64721 ==> 0.5218398785719435\n",
            "Loss in iteration no. 64722 ==> 0.5218385144629115\n",
            "Loss in iteration no. 64723 ==> 0.5218371503681501\n",
            "Loss in iteration no. 64724 ==> 0.521835786287659\n",
            "Loss in iteration no. 64725 ==> 0.5218344222214378\n",
            "Loss in iteration no. 64726 ==> 0.5218330581694866\n",
            "Loss in iteration no. 64727 ==> 0.5218316941318045\n",
            "Loss in iteration no. 64728 ==> 0.521830330108392\n",
            "Loss in iteration no. 64729 ==> 0.5218289660992484\n",
            "Loss in iteration no. 64730 ==> 0.521827602104374\n",
            "Loss in iteration no. 64731 ==> 0.5218262381237679\n",
            "Loss in iteration no. 64732 ==> 0.5218248741574304\n",
            "Loss in iteration no. 64733 ==> 0.5218235102053611\n",
            "Loss in iteration no. 64734 ==> 0.5218221462675597\n",
            "Loss in iteration no. 64735 ==> 0.5218207823440262\n",
            "Loss in iteration no. 64736 ==> 0.52181941843476\n",
            "Loss in iteration no. 64737 ==> 0.5218180545397613\n",
            "Loss in iteration no. 64738 ==> 0.5218166906590295\n",
            "Loss in iteration no. 64739 ==> 0.5218153267925649\n",
            "Loss in iteration no. 64740 ==> 0.5218139629403667\n",
            "Loss in iteration no. 64741 ==> 0.5218125991024348\n",
            "Loss in iteration no. 64742 ==> 0.5218112352787694\n",
            "Loss in iteration no. 64743 ==> 0.5218098714693697\n",
            "Loss in iteration no. 64744 ==> 0.5218085076742357\n",
            "Loss in iteration no. 64745 ==> 0.5218071438933676\n",
            "Loss in iteration no. 64746 ==> 0.5218057801267646\n",
            "Loss in iteration no. 64747 ==> 0.5218044163744265\n",
            "Loss in iteration no. 64748 ==> 0.5218030526363535\n",
            "Loss in iteration no. 64749 ==> 0.521801688912545\n",
            "Loss in iteration no. 64750 ==> 0.5218003252030009\n",
            "Loss in iteration no. 64751 ==> 0.5217989615077211\n",
            "Loss in iteration no. 64752 ==> 0.5217975978267052\n",
            "Loss in iteration no. 64753 ==> 0.5217962341599532\n",
            "Loss in iteration no. 64754 ==> 0.5217948705074645\n",
            "Loss in iteration no. 64755 ==> 0.5217935068692391\n",
            "Loss in iteration no. 64756 ==> 0.521792143245277\n",
            "Loss in iteration no. 64757 ==> 0.5217907796355776\n",
            "Loss in iteration no. 64758 ==> 0.5217894160401407\n",
            "Loss in iteration no. 64759 ==> 0.5217880524589664\n",
            "Loss in iteration no. 64760 ==> 0.5217866888920542\n",
            "Loss in iteration no. 64761 ==> 0.5217853253394041\n",
            "Loss in iteration no. 64762 ==> 0.5217839618010155\n",
            "Loss in iteration no. 64763 ==> 0.5217825982768887\n",
            "Loss in iteration no. 64764 ==> 0.5217812347670229\n",
            "Loss in iteration no. 64765 ==> 0.5217798712714183\n",
            "Loss in iteration no. 64766 ==> 0.5217785077900746\n",
            "Loss in iteration no. 64767 ==> 0.5217771443229915\n",
            "Loss in iteration no. 64768 ==> 0.5217757808701687\n",
            "Loss in iteration no. 64769 ==> 0.5217744174316061\n",
            "Loss in iteration no. 64770 ==> 0.5217730540073036\n",
            "Loss in iteration no. 64771 ==> 0.5217716905972607\n",
            "Loss in iteration no. 64772 ==> 0.5217703272014773\n",
            "Loss in iteration no. 64773 ==> 0.5217689638199533\n",
            "Loss in iteration no. 64774 ==> 0.5217676004526883\n",
            "Loss in iteration no. 64775 ==> 0.5217662370996822\n",
            "Loss in iteration no. 64776 ==> 0.5217648737609347\n",
            "Loss in iteration no. 64777 ==> 0.5217635104364455\n",
            "Loss in iteration no. 64778 ==> 0.5217621471262146\n",
            "Loss in iteration no. 64779 ==> 0.5217607838302415\n",
            "Loss in iteration no. 64780 ==> 0.5217594205485263\n",
            "Loss in iteration no. 64781 ==> 0.5217580572810685\n",
            "Loss in iteration no. 64782 ==> 0.5217566940278681\n",
            "Loss in iteration no. 64783 ==> 0.5217553307889244\n",
            "Loss in iteration no. 64784 ==> 0.521753967564238\n",
            "Loss in iteration no. 64785 ==> 0.5217526043538081\n",
            "Loss in iteration no. 64786 ==> 0.5217512411576345\n",
            "Loss in iteration no. 64787 ==> 0.521749877975717\n",
            "Loss in iteration no. 64788 ==> 0.5217485148080556\n",
            "Loss in iteration no. 64789 ==> 0.5217471516546498\n",
            "Loss in iteration no. 64790 ==> 0.5217457885154996\n",
            "Loss in iteration no. 64791 ==> 0.5217444253906047\n",
            "Loss in iteration no. 64792 ==> 0.5217430622799646\n",
            "Loss in iteration no. 64793 ==> 0.5217416991835797\n",
            "Loss in iteration no. 64794 ==> 0.5217403361014492\n",
            "Loss in iteration no. 64795 ==> 0.5217389730335733\n",
            "Loss in iteration no. 64796 ==> 0.5217376099799513\n",
            "Loss in iteration no. 64797 ==> 0.5217362469405834\n",
            "Loss in iteration no. 64798 ==> 0.5217348839154691\n",
            "Loss in iteration no. 64799 ==> 0.5217335209046084\n",
            "Loss in iteration no. 64800 ==> 0.521732157908001\n",
            "Loss in iteration no. 64801 ==> 0.5217307949256466\n",
            "Loss in iteration no. 64802 ==> 0.5217294319575451\n",
            "Loss in iteration no. 64803 ==> 0.5217280690036962\n",
            "Loss in iteration no. 64804 ==> 0.5217267060640995\n",
            "Loss in iteration no. 64805 ==> 0.5217253431387551\n",
            "Loss in iteration no. 64806 ==> 0.5217239802276626\n",
            "Loss in iteration no. 64807 ==> 0.521722617330822\n",
            "Loss in iteration no. 64808 ==> 0.5217212544482327\n",
            "Loss in iteration no. 64809 ==> 0.5217198915798947\n",
            "Loss in iteration no. 64810 ==> 0.5217185287258078\n",
            "Loss in iteration no. 64811 ==> 0.5217171658859717\n",
            "Loss in iteration no. 64812 ==> 0.5217158030603863\n",
            "Loss in iteration no. 64813 ==> 0.5217144402490511\n",
            "Loss in iteration no. 64814 ==> 0.5217130774519663\n",
            "Loss in iteration no. 64815 ==> 0.5217117146691312\n",
            "Loss in iteration no. 64816 ==> 0.5217103519005459\n",
            "Loss in iteration no. 64817 ==> 0.5217089891462102\n",
            "Loss in iteration no. 64818 ==> 0.5217076264061238\n",
            "Loss in iteration no. 64819 ==> 0.5217062636802863\n",
            "Loss in iteration no. 64820 ==> 0.5217049009686976\n",
            "Loss in iteration no. 64821 ==> 0.5217035382713577\n",
            "Loss in iteration no. 64822 ==> 0.5217021755882659\n",
            "Loss in iteration no. 64823 ==> 0.5217008129194224\n",
            "Loss in iteration no. 64824 ==> 0.521699450264827\n",
            "Loss in iteration no. 64825 ==> 0.5216980876244791\n",
            "Loss in iteration no. 64826 ==> 0.5216967249983788\n",
            "Loss in iteration no. 64827 ==> 0.5216953623865257\n",
            "Loss in iteration no. 64828 ==> 0.5216939997889197\n",
            "Loss in iteration no. 64829 ==> 0.5216926372055605\n",
            "Loss in iteration no. 64830 ==> 0.5216912746364478\n",
            "Loss in iteration no. 64831 ==> 0.5216899120815817\n",
            "Loss in iteration no. 64832 ==> 0.5216885495409617\n",
            "Loss in iteration no. 64833 ==> 0.5216871870145877\n",
            "Loss in iteration no. 64834 ==> 0.5216858245024593\n",
            "Loss in iteration no. 64835 ==> 0.5216844620045762\n",
            "Loss in iteration no. 64836 ==> 0.5216830995209386\n",
            "Loss in iteration no. 64837 ==> 0.5216817370515461\n",
            "Loss in iteration no. 64838 ==> 0.5216803745963983\n",
            "Loss in iteration no. 64839 ==> 0.5216790121554951\n",
            "Loss in iteration no. 64840 ==> 0.5216776497288365\n",
            "Loss in iteration no. 64841 ==> 0.5216762873164218\n",
            "Loss in iteration no. 64842 ==> 0.5216749249182511\n",
            "Loss in iteration no. 64843 ==> 0.5216735625343241\n",
            "Loss in iteration no. 64844 ==> 0.5216722001646407\n",
            "Loss in iteration no. 64845 ==> 0.5216708378092004\n",
            "Loss in iteration no. 64846 ==> 0.5216694754680032\n",
            "Loss in iteration no. 64847 ==> 0.521668113141049\n",
            "Loss in iteration no. 64848 ==> 0.5216667508283372\n",
            "Loss in iteration no. 64849 ==> 0.5216653885298677\n",
            "Loss in iteration no. 64850 ==> 0.5216640262456406\n",
            "Loss in iteration no. 64851 ==> 0.5216626639756552\n",
            "Loss in iteration no. 64852 ==> 0.5216613017199117\n",
            "Loss in iteration no. 64853 ==> 0.5216599394784096\n",
            "Loss in iteration no. 64854 ==> 0.5216585772511488\n",
            "Loss in iteration no. 64855 ==> 0.5216572150381291\n",
            "Loss in iteration no. 64856 ==> 0.5216558528393501\n",
            "Loss in iteration no. 64857 ==> 0.5216544906548117\n",
            "Loss in iteration no. 64858 ==> 0.5216531284845138\n",
            "Loss in iteration no. 64859 ==> 0.521651766328456\n",
            "Loss in iteration no. 64860 ==> 0.5216504041866382\n",
            "Loss in iteration no. 64861 ==> 0.52164904205906\n",
            "Loss in iteration no. 64862 ==> 0.5216476799457213\n",
            "Loss in iteration no. 64863 ==> 0.5216463178466219\n",
            "Loss in iteration no. 64864 ==> 0.5216449557617617\n",
            "Loss in iteration no. 64865 ==> 0.52164359369114\n",
            "Loss in iteration no. 64866 ==> 0.5216422316347571\n",
            "Loss in iteration no. 64867 ==> 0.5216408695926126\n",
            "Loss in iteration no. 64868 ==> 0.5216395075647061\n",
            "Loss in iteration no. 64869 ==> 0.5216381455510377\n",
            "Loss in iteration no. 64870 ==> 0.5216367835516069\n",
            "Loss in iteration no. 64871 ==> 0.5216354215664138\n",
            "Loss in iteration no. 64872 ==> 0.5216340595954577\n",
            "Loss in iteration no. 64873 ==> 0.5216326976387388\n",
            "Loss in iteration no. 64874 ==> 0.5216313356962566\n",
            "Loss in iteration no. 64875 ==> 0.5216299737680112\n",
            "Loss in iteration no. 64876 ==> 0.5216286118540021\n",
            "Loss in iteration no. 64877 ==> 0.521627249954229\n",
            "Loss in iteration no. 64878 ==> 0.5216258880686919\n",
            "Loss in iteration no. 64879 ==> 0.5216245261973906\n",
            "Loss in iteration no. 64880 ==> 0.521623164340325\n",
            "Loss in iteration no. 64881 ==> 0.5216218024974943\n",
            "Loss in iteration no. 64882 ==> 0.5216204406688988\n",
            "Loss in iteration no. 64883 ==> 0.5216190788545381\n",
            "Loss in iteration no. 64884 ==> 0.521617717054412\n",
            "Loss in iteration no. 64885 ==> 0.5216163552685202\n",
            "Loss in iteration no. 64886 ==> 0.5216149934968627\n",
            "Loss in iteration no. 64887 ==> 0.5216136317394391\n",
            "Loss in iteration no. 64888 ==> 0.5216122699962493\n",
            "Loss in iteration no. 64889 ==> 0.5216109082672928\n",
            "Loss in iteration no. 64890 ==> 0.5216095465525697\n",
            "Loss in iteration no. 64891 ==> 0.5216081848520796\n",
            "Loss in iteration no. 64892 ==> 0.5216068231658222\n",
            "Loss in iteration no. 64893 ==> 0.5216054614937977\n",
            "Loss in iteration no. 64894 ==> 0.5216040998360054\n",
            "Loss in iteration no. 64895 ==> 0.5216027381924452\n",
            "Loss in iteration no. 64896 ==> 0.5216013765631171\n",
            "Loss in iteration no. 64897 ==> 0.5216000149480207\n",
            "Loss in iteration no. 64898 ==> 0.5215986533471557\n",
            "Loss in iteration no. 64899 ==> 0.5215972917605218\n",
            "Loss in iteration no. 64900 ==> 0.5215959301881193\n",
            "Loss in iteration no. 64901 ==> 0.5215945686299475\n",
            "Loss in iteration no. 64902 ==> 0.5215932070860062\n",
            "Loss in iteration no. 64903 ==> 0.5215918455562953\n",
            "Loss in iteration no. 64904 ==> 0.5215904840408148\n",
            "Loss in iteration no. 64905 ==> 0.5215891225395639\n",
            "Loss in iteration no. 64906 ==> 0.521587761052543\n",
            "Loss in iteration no. 64907 ==> 0.5215863995797515\n",
            "Loss in iteration no. 64908 ==> 0.5215850381211892\n",
            "Loss in iteration no. 64909 ==> 0.5215836766768559\n",
            "Loss in iteration no. 64910 ==> 0.5215823152467516\n",
            "Loss in iteration no. 64911 ==> 0.5215809538308759\n",
            "Loss in iteration no. 64912 ==> 0.5215795924292285\n",
            "Loss in iteration no. 64913 ==> 0.5215782310418093\n",
            "Loss in iteration no. 64914 ==> 0.5215768696686179\n",
            "Loss in iteration no. 64915 ==> 0.5215755083096545\n",
            "Loss in iteration no. 64916 ==> 0.5215741469649184\n",
            "Loss in iteration no. 64917 ==> 0.5215727856344097\n",
            "Loss in iteration no. 64918 ==> 0.5215714243181279\n",
            "Loss in iteration no. 64919 ==> 0.5215700630160731\n",
            "Loss in iteration no. 64920 ==> 0.5215687017282448\n",
            "Loss in iteration no. 64921 ==> 0.5215673404546429\n",
            "Loss in iteration no. 64922 ==> 0.5215659791952671\n",
            "Loss in iteration no. 64923 ==> 0.5215646179501174\n",
            "Loss in iteration no. 64924 ==> 0.5215632567191933\n",
            "Loss in iteration no. 64925 ==> 0.5215618955024948\n",
            "Loss in iteration no. 64926 ==> 0.5215605343000216\n",
            "Loss in iteration no. 64927 ==> 0.5215591731117734\n",
            "Loss in iteration no. 64928 ==> 0.52155781193775\n",
            "Loss in iteration no. 64929 ==> 0.5215564507779512\n",
            "Loss in iteration no. 64930 ==> 0.5215550896323768\n",
            "Loss in iteration no. 64931 ==> 0.5215537285010267\n",
            "Loss in iteration no. 64932 ==> 0.5215523673839003\n",
            "Loss in iteration no. 64933 ==> 0.5215510062809979\n",
            "Loss in iteration no. 64934 ==> 0.521549645192319\n",
            "Loss in iteration no. 64935 ==> 0.5215482841178631\n",
            "Loss in iteration no. 64936 ==> 0.5215469230576305\n",
            "Loss in iteration no. 64937 ==> 0.5215455620116206\n",
            "Loss in iteration no. 64938 ==> 0.5215442009798334\n",
            "Loss in iteration no. 64939 ==> 0.5215428399622686\n",
            "Loss in iteration no. 64940 ==> 0.521541478958926\n",
            "Loss in iteration no. 64941 ==> 0.5215401179698054\n",
            "Loss in iteration no. 64942 ==> 0.5215387569949063\n",
            "Loss in iteration no. 64943 ==> 0.5215373960342289\n",
            "Loss in iteration no. 64944 ==> 0.5215360350877727\n",
            "Loss in iteration no. 64945 ==> 0.5215346741555376\n",
            "Loss in iteration no. 64946 ==> 0.5215333132375234\n",
            "Loss in iteration no. 64947 ==> 0.5215319523337296\n",
            "Loss in iteration no. 64948 ==> 0.5215305914441565\n",
            "Loss in iteration no. 64949 ==> 0.5215292305688034\n",
            "Loss in iteration no. 64950 ==> 0.5215278697076703\n",
            "Loss in iteration no. 64951 ==> 0.5215265088607569\n",
            "Loss in iteration no. 64952 ==> 0.521525148028063\n",
            "Loss in iteration no. 64953 ==> 0.5215237872095885\n",
            "Loss in iteration no. 64954 ==> 0.521522426405333\n",
            "Loss in iteration no. 64955 ==> 0.5215210656152964\n",
            "Loss in iteration no. 64956 ==> 0.5215197048394783\n",
            "Loss in iteration no. 64957 ==> 0.5215183440778787\n",
            "Loss in iteration no. 64958 ==> 0.5215169833304973\n",
            "Loss in iteration no. 64959 ==> 0.5215156225973339\n",
            "Loss in iteration no. 64960 ==> 0.521514261878388\n",
            "Loss in iteration no. 64961 ==> 0.5215129011736599\n",
            "Loss in iteration no. 64962 ==> 0.5215115404831488\n",
            "Loss in iteration no. 64963 ==> 0.5215101798068552\n",
            "Loss in iteration no. 64964 ==> 0.5215088191447781\n",
            "Loss in iteration no. 64965 ==> 0.5215074584969178\n",
            "Loss in iteration no. 64966 ==> 0.5215060978632738\n",
            "Loss in iteration no. 64967 ==> 0.521504737243846\n",
            "Loss in iteration no. 64968 ==> 0.5215033766386343\n",
            "Loss in iteration no. 64969 ==> 0.5215020160476381\n",
            "Loss in iteration no. 64970 ==> 0.5215006554708579\n",
            "Loss in iteration no. 64971 ==> 0.5214992949082925\n",
            "Loss in iteration no. 64972 ==> 0.5214979343599424\n",
            "Loss in iteration no. 64973 ==> 0.5214965738258069\n",
            "Loss in iteration no. 64974 ==> 0.5214952133058864\n",
            "Loss in iteration no. 64975 ==> 0.5214938528001801\n",
            "Loss in iteration no. 64976 ==> 0.521492492308688\n",
            "Loss in iteration no. 64977 ==> 0.52149113183141\n",
            "Loss in iteration no. 64978 ==> 0.5214897713683457\n",
            "Loss in iteration no. 64979 ==> 0.5214884109194948\n",
            "Loss in iteration no. 64980 ==> 0.5214870504848573\n",
            "Loss in iteration no. 64981 ==> 0.5214856900644329\n",
            "Loss in iteration no. 64982 ==> 0.5214843296582214\n",
            "Loss in iteration no. 64983 ==> 0.5214829692662224\n",
            "Loss in iteration no. 64984 ==> 0.5214816088884361\n",
            "Loss in iteration no. 64985 ==> 0.5214802485248619\n",
            "Loss in iteration no. 64986 ==> 0.5214788881754994\n",
            "Loss in iteration no. 64987 ==> 0.5214775278403488\n",
            "Loss in iteration no. 64988 ==> 0.5214761675194098\n",
            "Loss in iteration no. 64989 ==> 0.5214748072126822\n",
            "Loss in iteration no. 64990 ==> 0.5214734469201655\n",
            "Loss in iteration no. 64991 ==> 0.5214720866418598\n",
            "Loss in iteration no. 64992 ==> 0.5214707263777647\n",
            "Loss in iteration no. 64993 ==> 0.5214693661278801\n",
            "Loss in iteration no. 64994 ==> 0.5214680058922055\n",
            "Loss in iteration no. 64995 ==> 0.5214666456707412\n",
            "Loss in iteration no. 64996 ==> 0.5214652854634864\n",
            "Loss in iteration no. 64997 ==> 0.5214639252704412\n",
            "Loss in iteration no. 64998 ==> 0.5214625650916053\n",
            "Loss in iteration no. 64999 ==> 0.5214612049269787\n",
            "Loss in iteration no. 65000 ==> 0.5214598447765607\n",
            "Loss in iteration no. 65001 ==> 0.5214584846403514\n",
            "Loss in iteration no. 65002 ==> 0.5214571245183507\n",
            "Loss in iteration no. 65003 ==> 0.5214557644105581\n",
            "Loss in iteration no. 65004 ==> 0.5214544043169735\n",
            "Loss in iteration no. 65005 ==> 0.5214530442375968\n",
            "Loss in iteration no. 65006 ==> 0.5214516841724276\n",
            "Loss in iteration no. 65007 ==> 0.5214503241214655\n",
            "Loss in iteration no. 65008 ==> 0.5214489640847106\n",
            "Loss in iteration no. 65009 ==> 0.5214476040621627\n",
            "Loss in iteration no. 65010 ==> 0.5214462440538213\n",
            "Loss in iteration no. 65011 ==> 0.5214448840596866\n",
            "Loss in iteration no. 65012 ==> 0.521443524079758\n",
            "Loss in iteration no. 65013 ==> 0.5214421641140353\n",
            "Loss in iteration no. 65014 ==> 0.5214408041625184\n",
            "Loss in iteration no. 65015 ==> 0.5214394442252072\n",
            "Loss in iteration no. 65016 ==> 0.521438084302101\n",
            "Loss in iteration no. 65017 ==> 0.5214367243932003\n",
            "Loss in iteration no. 65018 ==> 0.5214353644985044\n",
            "Loss in iteration no. 65019 ==> 0.521434004618013\n",
            "Loss in iteration no. 65020 ==> 0.5214326447517262\n",
            "Loss in iteration no. 65021 ==> 0.5214312848996435\n",
            "Loss in iteration no. 65022 ==> 0.5214299250617649\n",
            "Loss in iteration no. 65023 ==> 0.52142856523809\n",
            "Loss in iteration no. 65024 ==> 0.5214272054286188\n",
            "Loss in iteration no. 65025 ==> 0.5214258456333509\n",
            "Loss in iteration no. 65026 ==> 0.5214244858522862\n",
            "Loss in iteration no. 65027 ==> 0.5214231260854242\n",
            "Loss in iteration no. 65028 ==> 0.5214217663327649\n",
            "Loss in iteration no. 65029 ==> 0.5214204065943082\n",
            "Loss in iteration no. 65030 ==> 0.5214190468700536\n",
            "Loss in iteration no. 65031 ==> 0.521417687160001\n",
            "Loss in iteration no. 65032 ==> 0.5214163274641503\n",
            "Loss in iteration no. 65033 ==> 0.5214149677825013\n",
            "Loss in iteration no. 65034 ==> 0.5214136081150534\n",
            "Loss in iteration no. 65035 ==> 0.5214122484618067\n",
            "Loss in iteration no. 65036 ==> 0.5214108888227609\n",
            "Loss in iteration no. 65037 ==> 0.5214095291979158\n",
            "Loss in iteration no. 65038 ==> 0.5214081695872712\n",
            "Loss in iteration no. 65039 ==> 0.5214068099908268\n",
            "Loss in iteration no. 65040 ==> 0.5214054504085824\n",
            "Loss in iteration no. 65041 ==> 0.521404090840538\n",
            "Loss in iteration no. 65042 ==> 0.5214027312866928\n",
            "Loss in iteration no. 65043 ==> 0.5214013717470473\n",
            "Loss in iteration no. 65044 ==> 0.5214000122216007\n",
            "Loss in iteration no. 65045 ==> 0.5213986527103531\n",
            "Loss in iteration no. 65046 ==> 0.5213972932133044\n",
            "Loss in iteration no. 65047 ==> 0.5213959337304539\n",
            "Loss in iteration no. 65048 ==> 0.5213945742618018\n",
            "Loss in iteration no. 65049 ==> 0.5213932148073476\n",
            "Loss in iteration no. 65050 ==> 0.5213918553670913\n",
            "Loss in iteration no. 65051 ==> 0.5213904959410326\n",
            "Loss in iteration no. 65052 ==> 0.5213891365291712\n",
            "Loss in iteration no. 65053 ==> 0.5213877771315071\n",
            "Loss in iteration no. 65054 ==> 0.5213864177480398\n",
            "Loss in iteration no. 65055 ==> 0.5213850583787691\n",
            "Loss in iteration no. 65056 ==> 0.5213836990236951\n",
            "Loss in iteration no. 65057 ==> 0.5213823396828171\n",
            "Loss in iteration no. 65058 ==> 0.5213809803561354\n",
            "Loss in iteration no. 65059 ==> 0.5213796210436494\n",
            "Loss in iteration no. 65060 ==> 0.5213782617453591\n",
            "Loss in iteration no. 65061 ==> 0.521376902461264\n",
            "Loss in iteration no. 65062 ==> 0.5213755431913643\n",
            "Loss in iteration no. 65063 ==> 0.5213741839356593\n",
            "Loss in iteration no. 65064 ==> 0.5213728246941491\n",
            "Loss in iteration no. 65065 ==> 0.5213714654668333\n",
            "Loss in iteration no. 65066 ==> 0.521370106253712\n",
            "Loss in iteration no. 65067 ==> 0.5213687470547845\n",
            "Loss in iteration no. 65068 ==> 0.5213673878700511\n",
            "Loss in iteration no. 65069 ==> 0.5213660286995111\n",
            "Loss in iteration no. 65070 ==> 0.5213646695431645\n",
            "Loss in iteration no. 65071 ==> 0.5213633104010112\n",
            "Loss in iteration no. 65072 ==> 0.5213619512730506\n",
            "Loss in iteration no. 65073 ==> 0.521360592159283\n",
            "Loss in iteration no. 65074 ==> 0.5213592330597077\n",
            "Loss in iteration no. 65075 ==> 0.5213578739743249\n",
            "Loss in iteration no. 65076 ==> 0.521356514903134\n",
            "Loss in iteration no. 65077 ==> 0.5213551558461348\n",
            "Loss in iteration no. 65078 ==> 0.5213537968033275\n",
            "Loss in iteration no. 65079 ==> 0.5213524377747114\n",
            "Loss in iteration no. 65080 ==> 0.5213510787602866\n",
            "Loss in iteration no. 65081 ==> 0.5213497197600525\n",
            "Loss in iteration no. 65082 ==> 0.5213483607740096\n",
            "Loss in iteration no. 65083 ==> 0.521347001802157\n",
            "Loss in iteration no. 65084 ==> 0.5213456428444946\n",
            "Loss in iteration no. 65085 ==> 0.5213442839010224\n",
            "Loss in iteration no. 65086 ==> 0.5213429249717397\n",
            "Loss in iteration no. 65087 ==> 0.5213415660566469\n",
            "Loss in iteration no. 65088 ==> 0.5213402071557436\n",
            "Loss in iteration no. 65089 ==> 0.5213388482690293\n",
            "Loss in iteration no. 65090 ==> 0.5213374893965042\n",
            "Loss in iteration no. 65091 ==> 0.5213361305381677\n",
            "Loss in iteration no. 65092 ==> 0.5213347716940196\n",
            "Loss in iteration no. 65093 ==> 0.52133341286406\n",
            "Loss in iteration no. 65094 ==> 0.5213320540482885\n",
            "Loss in iteration no. 65095 ==> 0.5213306952467047\n",
            "Loss in iteration no. 65096 ==> 0.5213293364593086\n",
            "Loss in iteration no. 65097 ==> 0.5213279776860998\n",
            "Loss in iteration no. 65098 ==> 0.5213266189270784\n",
            "Loss in iteration no. 65099 ==> 0.5213252601822441\n",
            "Loss in iteration no. 65100 ==> 0.5213239014515963\n",
            "Loss in iteration no. 65101 ==> 0.5213225427351351\n",
            "Loss in iteration no. 65102 ==> 0.5213211840328602\n",
            "Loss in iteration no. 65103 ==> 0.5213198253447714\n",
            "Loss in iteration no. 65104 ==> 0.5213184666708685\n",
            "Loss in iteration no. 65105 ==> 0.5213171080111513\n",
            "Loss in iteration no. 65106 ==> 0.5213157493656193\n",
            "Loss in iteration no. 65107 ==> 0.5213143907342729\n",
            "Loss in iteration no. 65108 ==> 0.5213130321171111\n",
            "Loss in iteration no. 65109 ==> 0.5213116735141342\n",
            "Loss in iteration no. 65110 ==> 0.521310314925342\n",
            "Loss in iteration no. 65111 ==> 0.5213089563507339\n",
            "Loss in iteration no. 65112 ==> 0.5213075977903101\n",
            "Loss in iteration no. 65113 ==> 0.5213062392440702\n",
            "Loss in iteration no. 65114 ==> 0.5213048807120138\n",
            "Loss in iteration no. 65115 ==> 0.5213035221941409\n",
            "Loss in iteration no. 65116 ==> 0.5213021636904511\n",
            "Loss in iteration no. 65117 ==> 0.5213008052009446\n",
            "Loss in iteration no. 65118 ==> 0.5212994467256208\n",
            "Loss in iteration no. 65119 ==> 0.5212980882644793\n",
            "Loss in iteration no. 65120 ==> 0.5212967298175204\n",
            "Loss in iteration no. 65121 ==> 0.5212953713847434\n",
            "Loss in iteration no. 65122 ==> 0.5212940129661485\n",
            "Loss in iteration no. 65123 ==> 0.5212926545617351\n",
            "Loss in iteration no. 65124 ==> 0.5212912961715035\n",
            "Loss in iteration no. 65125 ==> 0.5212899377954529\n",
            "Loss in iteration no. 65126 ==> 0.5212885794335832\n",
            "Loss in iteration no. 65127 ==> 0.5212872210858944\n",
            "Loss in iteration no. 65128 ==> 0.5212858627523862\n",
            "Loss in iteration no. 65129 ==> 0.5212845044330583\n",
            "Loss in iteration no. 65130 ==> 0.5212831461279106\n",
            "Loss in iteration no. 65131 ==> 0.5212817878369428\n",
            "Loss in iteration no. 65132 ==> 0.5212804295601545\n",
            "Loss in iteration no. 65133 ==> 0.521279071297546\n",
            "Loss in iteration no. 65134 ==> 0.5212777130491165\n",
            "Loss in iteration no. 65135 ==> 0.5212763548148661\n",
            "Loss in iteration no. 65136 ==> 0.5212749965947945\n",
            "Loss in iteration no. 65137 ==> 0.5212736383889015\n",
            "Loss in iteration no. 65138 ==> 0.5212722801971869\n",
            "Loss in iteration no. 65139 ==> 0.5212709220196504\n",
            "Loss in iteration no. 65140 ==> 0.5212695638562919\n",
            "Loss in iteration no. 65141 ==> 0.5212682057071111\n",
            "Loss in iteration no. 65142 ==> 0.5212668475721076\n",
            "Loss in iteration no. 65143 ==> 0.5212654894512815\n",
            "Loss in iteration no. 65144 ==> 0.5212641313446325\n",
            "Loss in iteration no. 65145 ==> 0.5212627732521601\n",
            "Loss in iteration no. 65146 ==> 0.5212614151738645\n",
            "Loss in iteration no. 65147 ==> 0.5212600571097452\n",
            "Loss in iteration no. 65148 ==> 0.5212586990598022\n",
            "Loss in iteration no. 65149 ==> 0.5212573410240349\n",
            "Loss in iteration no. 65150 ==> 0.5212559830024435\n",
            "Loss in iteration no. 65151 ==> 0.5212546249950274\n",
            "Loss in iteration no. 65152 ==> 0.5212532670017868\n",
            "Loss in iteration no. 65153 ==> 0.5212519090227211\n",
            "Loss in iteration no. 65154 ==> 0.5212505510578304\n",
            "Loss in iteration no. 65155 ==> 0.5212491931071142\n",
            "Loss in iteration no. 65156 ==> 0.5212478351705724\n",
            "Loss in iteration no. 65157 ==> 0.5212464772482047\n",
            "Loss in iteration no. 65158 ==> 0.521245119340011\n",
            "Loss in iteration no. 65159 ==> 0.521243761445991\n",
            "Loss in iteration no. 65160 ==> 0.5212424035661447\n",
            "Loss in iteration no. 65161 ==> 0.5212410457004715\n",
            "Loss in iteration no. 65162 ==> 0.5212396878489715\n",
            "Loss in iteration no. 65163 ==> 0.5212383300116442\n",
            "Loss in iteration no. 65164 ==> 0.5212369721884896\n",
            "Loss in iteration no. 65165 ==> 0.5212356143795075\n",
            "Loss in iteration no. 65166 ==> 0.5212342565846976\n",
            "Loss in iteration no. 65167 ==> 0.5212328988040594\n",
            "Loss in iteration no. 65168 ==> 0.5212315410375932\n",
            "Loss in iteration no. 65169 ==> 0.5212301832852984\n",
            "Loss in iteration no. 65170 ==> 0.521228825547175\n",
            "Loss in iteration no. 65171 ==> 0.5212274678232226\n",
            "Loss in iteration no. 65172 ==> 0.521226110113441\n",
            "Loss in iteration no. 65173 ==> 0.5212247524178301\n",
            "Loss in iteration no. 65174 ==> 0.5212233947363897\n",
            "Loss in iteration no. 65175 ==> 0.5212220370691195\n",
            "Loss in iteration no. 65176 ==> 0.5212206794160192\n",
            "Loss in iteration no. 65177 ==> 0.5212193217770887\n",
            "Loss in iteration no. 65178 ==> 0.5212179641523277\n",
            "Loss in iteration no. 65179 ==> 0.5212166065417362\n",
            "Loss in iteration no. 65180 ==> 0.5212152489453136\n",
            "Loss in iteration no. 65181 ==> 0.5212138913630601\n",
            "Loss in iteration no. 65182 ==> 0.521212533794975\n",
            "Loss in iteration no. 65183 ==> 0.5212111762410584\n",
            "Loss in iteration no. 65184 ==> 0.5212098187013101\n",
            "Loss in iteration no. 65185 ==> 0.5212084611757297\n",
            "Loss in iteration no. 65186 ==> 0.5212071036643171\n",
            "Loss in iteration no. 65187 ==> 0.5212057461670722\n",
            "Loss in iteration no. 65188 ==> 0.5212043886839943\n",
            "Loss in iteration no. 65189 ==> 0.5212030312150838\n",
            "Loss in iteration no. 65190 ==> 0.5212016737603403\n",
            "Loss in iteration no. 65191 ==> 0.5212003163197632\n",
            "Loss in iteration no. 65192 ==> 0.5211989588933525\n",
            "Loss in iteration no. 65193 ==> 0.5211976014811084\n",
            "Loss in iteration no. 65194 ==> 0.5211962440830301\n",
            "Loss in iteration no. 65195 ==> 0.5211948866991175\n",
            "Loss in iteration no. 65196 ==> 0.5211935293293707\n",
            "Loss in iteration no. 65197 ==> 0.5211921719737891\n",
            "Loss in iteration no. 65198 ==> 0.5211908146323726\n",
            "Loss in iteration no. 65199 ==> 0.5211894573051211\n",
            "Loss in iteration no. 65200 ==> 0.5211880999920343\n",
            "Loss in iteration no. 65201 ==> 0.5211867426931119\n",
            "Loss in iteration no. 65202 ==> 0.5211853854083537\n",
            "Loss in iteration no. 65203 ==> 0.5211840281377597\n",
            "Loss in iteration no. 65204 ==> 0.5211826708813294\n",
            "Loss in iteration no. 65205 ==> 0.5211813136390626\n",
            "Loss in iteration no. 65206 ==> 0.5211799564109594\n",
            "Loss in iteration no. 65207 ==> 0.5211785991970193\n",
            "Loss in iteration no. 65208 ==> 0.5211772419972419\n",
            "Loss in iteration no. 65209 ==> 0.5211758848116275\n",
            "Loss in iteration no. 65210 ==> 0.5211745276401752\n",
            "Loss in iteration no. 65211 ==> 0.5211731704828856\n",
            "Loss in iteration no. 65212 ==> 0.5211718133397579\n",
            "Loss in iteration no. 65213 ==> 0.5211704562107919\n",
            "Loss in iteration no. 65214 ==> 0.5211690990959875\n",
            "Loss in iteration no. 65215 ==> 0.5211677419953445\n",
            "Loss in iteration no. 65216 ==> 0.5211663849088629\n",
            "Loss in iteration no. 65217 ==> 0.5211650278365421\n",
            "Loss in iteration no. 65218 ==> 0.521163670778382\n",
            "Loss in iteration no. 65219 ==> 0.5211623137343825\n",
            "Loss in iteration no. 65220 ==> 0.521160956704543\n",
            "Loss in iteration no. 65221 ==> 0.5211595996888637\n",
            "Loss in iteration no. 65222 ==> 0.5211582426873445\n",
            "Loss in iteration no. 65223 ==> 0.5211568856999846\n",
            "Loss in iteration no. 65224 ==> 0.5211555287267843\n",
            "Loss in iteration no. 65225 ==> 0.5211541717677431\n",
            "Loss in iteration no. 65226 ==> 0.5211528148228608\n",
            "Loss in iteration no. 65227 ==> 0.5211514578921375\n",
            "Loss in iteration no. 65228 ==> 0.5211501009755725\n",
            "Loss in iteration no. 65229 ==> 0.5211487440731658\n",
            "Loss in iteration no. 65230 ==> 0.5211473871849172\n",
            "Loss in iteration no. 65231 ==> 0.5211460303108265\n",
            "Loss in iteration no. 65232 ==> 0.5211446734508933\n",
            "Loss in iteration no. 65233 ==> 0.5211433166051177\n",
            "Loss in iteration no. 65234 ==> 0.5211419597734992\n",
            "Loss in iteration no. 65235 ==> 0.5211406029560379\n",
            "Loss in iteration no. 65236 ==> 0.5211392461527331\n",
            "Loss in iteration no. 65237 ==> 0.5211378893635847\n",
            "Loss in iteration no. 65238 ==> 0.5211365325885929\n",
            "Loss in iteration no. 65239 ==> 0.5211351758277573\n",
            "Loss in iteration no. 65240 ==> 0.5211338190810774\n",
            "Loss in iteration no. 65241 ==> 0.5211324623485531\n",
            "Loss in iteration no. 65242 ==> 0.5211311056301844\n",
            "Loss in iteration no. 65243 ==> 0.5211297489259707\n",
            "Loss in iteration no. 65244 ==> 0.5211283922359123\n",
            "Loss in iteration no. 65245 ==> 0.5211270355600084\n",
            "Loss in iteration no. 65246 ==> 0.5211256788982593\n",
            "Loss in iteration no. 65247 ==> 0.5211243222506643\n",
            "Loss in iteration no. 65248 ==> 0.5211229656172236\n",
            "Loss in iteration no. 65249 ==> 0.5211216089979367\n",
            "Loss in iteration no. 65250 ==> 0.5211202523928035\n",
            "Loss in iteration no. 65251 ==> 0.5211188958018238\n",
            "Loss in iteration no. 65252 ==> 0.5211175392249973\n",
            "Loss in iteration no. 65253 ==> 0.5211161826623237\n",
            "Loss in iteration no. 65254 ==> 0.5211148261138031\n",
            "Loss in iteration no. 65255 ==> 0.521113469579435\n",
            "Loss in iteration no. 65256 ==> 0.5211121130592191\n",
            "Loss in iteration no. 65257 ==> 0.5211107565531555\n",
            "Loss in iteration no. 65258 ==> 0.5211094000612438\n",
            "Loss in iteration no. 65259 ==> 0.521108043583484\n",
            "Loss in iteration no. 65260 ==> 0.5211066871198753\n",
            "Loss in iteration no. 65261 ==> 0.521105330670418\n",
            "Loss in iteration no. 65262 ==> 0.5211039742351118\n",
            "Loss in iteration no. 65263 ==> 0.5211026178139564\n",
            "Loss in iteration no. 65264 ==> 0.5211012614069516\n",
            "Loss in iteration no. 65265 ==> 0.5210999050140971\n",
            "Loss in iteration no. 65266 ==> 0.5210985486353928\n",
            "Loss in iteration no. 65267 ==> 0.5210971922708384\n",
            "Loss in iteration no. 65268 ==> 0.5210958359204338\n",
            "Loss in iteration no. 65269 ==> 0.5210944795841788\n",
            "Loss in iteration no. 65270 ==> 0.5210931232620729\n",
            "Loss in iteration no. 65271 ==> 0.5210917669541161\n",
            "Loss in iteration no. 65272 ==> 0.5210904106603081\n",
            "Loss in iteration no. 65273 ==> 0.5210890543806487\n",
            "Loss in iteration no. 65274 ==> 0.5210876981151379\n",
            "Loss in iteration no. 65275 ==> 0.521086341863775\n",
            "Loss in iteration no. 65276 ==> 0.52108498562656\n",
            "Loss in iteration no. 65277 ==> 0.521083629403493\n",
            "Loss in iteration no. 65278 ==> 0.5210822731945736\n",
            "Loss in iteration no. 65279 ==> 0.5210809169998012\n",
            "Loss in iteration no. 65280 ==> 0.521079560819176\n",
            "Loss in iteration no. 65281 ==> 0.5210782046526976\n",
            "Loss in iteration no. 65282 ==> 0.521076848500366\n",
            "Loss in iteration no. 65283 ==> 0.5210754923621805\n",
            "Loss in iteration no. 65284 ==> 0.5210741362381415\n",
            "Loss in iteration no. 65285 ==> 0.5210727801282484\n",
            "Loss in iteration no. 65286 ==> 0.521071424032501\n",
            "Loss in iteration no. 65287 ==> 0.5210700679508992\n",
            "Loss in iteration no. 65288 ==> 0.5210687118834427\n",
            "Loss in iteration no. 65289 ==> 0.5210673558301312\n",
            "Loss in iteration no. 65290 ==> 0.5210659997909647\n",
            "Loss in iteration no. 65291 ==> 0.5210646437659429\n",
            "Loss in iteration no. 65292 ==> 0.5210632877550655\n",
            "Loss in iteration no. 65293 ==> 0.5210619317583323\n",
            "Loss in iteration no. 65294 ==> 0.521060575775743\n",
            "Loss in iteration no. 65295 ==> 0.5210592198072975\n",
            "Loss in iteration no. 65296 ==> 0.5210578638529956\n",
            "Loss in iteration no. 65297 ==> 0.521056507912837\n",
            "Loss in iteration no. 65298 ==> 0.5210551519868216\n",
            "Loss in iteration no. 65299 ==> 0.521053796074949\n",
            "Loss in iteration no. 65300 ==> 0.5210524401772192\n",
            "Loss in iteration no. 65301 ==> 0.5210510842936318\n",
            "Loss in iteration no. 65302 ==> 0.5210497284241866\n",
            "Loss in iteration no. 65303 ==> 0.5210483725688835\n",
            "Loss in iteration no. 65304 ==> 0.521047016727722\n",
            "Loss in iteration no. 65305 ==> 0.5210456609007024\n",
            "Loss in iteration no. 65306 ==> 0.521044305087824\n",
            "Loss in iteration no. 65307 ==> 0.5210429492890867\n",
            "Loss in iteration no. 65308 ==> 0.5210415935044902\n",
            "Loss in iteration no. 65309 ==> 0.5210402377340346\n",
            "Loss in iteration no. 65310 ==> 0.5210388819777195\n",
            "Loss in iteration no. 65311 ==> 0.5210375262355446\n",
            "Loss in iteration no. 65312 ==> 0.5210361705075097\n",
            "Loss in iteration no. 65313 ==> 0.5210348147936146\n",
            "Loss in iteration no. 65314 ==> 0.5210334590938592\n",
            "Loss in iteration no. 65315 ==> 0.521032103408243\n",
            "Loss in iteration no. 65316 ==> 0.521030747736766\n",
            "Loss in iteration no. 65317 ==> 0.5210293920794282\n",
            "Loss in iteration no. 65318 ==> 0.521028036436229\n",
            "Loss in iteration no. 65319 ==> 0.5210266808071682\n",
            "Loss in iteration no. 65320 ==> 0.5210253251922458\n",
            "Loss in iteration no. 65321 ==> 0.5210239695914612\n",
            "Loss in iteration no. 65322 ==> 0.5210226140048146\n",
            "Loss in iteration no. 65323 ==> 0.5210212584323057\n",
            "Loss in iteration no. 65324 ==> 0.5210199028739342\n",
            "Loss in iteration no. 65325 ==> 0.5210185473296999\n",
            "Loss in iteration no. 65326 ==> 0.5210171917996025\n",
            "Loss in iteration no. 65327 ==> 0.5210158362836418\n",
            "Loss in iteration no. 65328 ==> 0.5210144807818176\n",
            "Loss in iteration no. 65329 ==> 0.5210131252941299\n",
            "Loss in iteration no. 65330 ==> 0.5210117698205782\n",
            "Loss in iteration no. 65331 ==> 0.5210104143611622\n",
            "Loss in iteration no. 65332 ==> 0.5210090589158821\n",
            "Loss in iteration no. 65333 ==> 0.5210077034847372\n",
            "Loss in iteration no. 65334 ==> 0.5210063480677276\n",
            "Loss in iteration no. 65335 ==> 0.5210049926648531\n",
            "Loss in iteration no. 65336 ==> 0.5210036372761132\n",
            "Loss in iteration no. 65337 ==> 0.5210022819015079\n",
            "Loss in iteration no. 65338 ==> 0.5210009265410369\n",
            "Loss in iteration no. 65339 ==> 0.5209995711947\n",
            "Loss in iteration no. 65340 ==> 0.5209982158624971\n",
            "Loss in iteration no. 65341 ==> 0.5209968605444277\n",
            "Loss in iteration no. 65342 ==> 0.520995505240492\n",
            "Loss in iteration no. 65343 ==> 0.5209941499506892\n",
            "Loss in iteration no. 65344 ==> 0.5209927946750197\n",
            "Loss in iteration no. 65345 ==> 0.5209914394134828\n",
            "Loss in iteration no. 65346 ==> 0.5209900841660785\n",
            "Loss in iteration no. 65347 ==> 0.5209887289328066\n",
            "Loss in iteration no. 65348 ==> 0.5209873737136669\n",
            "Loss in iteration no. 65349 ==> 0.5209860185086589\n",
            "Loss in iteration no. 65350 ==> 0.5209846633177828\n",
            "Loss in iteration no. 65351 ==> 0.5209833081410381\n",
            "Loss in iteration no. 65352 ==> 0.5209819529784248\n",
            "Loss in iteration no. 65353 ==> 0.5209805978299422\n",
            "Loss in iteration no. 65354 ==> 0.5209792426955906\n",
            "Loss in iteration no. 65355 ==> 0.5209778875753696\n",
            "Loss in iteration no. 65356 ==> 0.5209765324692789\n",
            "Loss in iteration no. 65357 ==> 0.5209751773773184\n",
            "Loss in iteration no. 65358 ==> 0.520973822299488\n",
            "Loss in iteration no. 65359 ==> 0.520972467235787\n",
            "Loss in iteration no. 65360 ==> 0.5209711121862156\n",
            "Loss in iteration no. 65361 ==> 0.5209697571507736\n",
            "Loss in iteration no. 65362 ==> 0.5209684021294606\n",
            "Loss in iteration no. 65363 ==> 0.5209670471222766\n",
            "Loss in iteration no. 65364 ==> 0.5209656921292208\n",
            "Loss in iteration no. 65365 ==> 0.5209643371502938\n",
            "Loss in iteration no. 65366 ==> 0.5209629821854949\n",
            "Loss in iteration no. 65367 ==> 0.5209616272348238\n",
            "Loss in iteration no. 65368 ==> 0.5209602722982806\n",
            "Loss in iteration no. 65369 ==> 0.5209589173758647\n",
            "Loss in iteration no. 65370 ==> 0.5209575624675763\n",
            "Loss in iteration no. 65371 ==> 0.5209562075734148\n",
            "Loss in iteration no. 65372 ==> 0.5209548526933804\n",
            "Loss in iteration no. 65373 ==> 0.5209534978274726\n",
            "Loss in iteration no. 65374 ==> 0.5209521429756911\n",
            "Loss in iteration no. 65375 ==> 0.5209507881380357\n",
            "Loss in iteration no. 65376 ==> 0.5209494333145065\n",
            "Loss in iteration no. 65377 ==> 0.5209480785051032\n",
            "Loss in iteration no. 65378 ==> 0.5209467237098251\n",
            "Loss in iteration no. 65379 ==> 0.5209453689286725\n",
            "Loss in iteration no. 65380 ==> 0.5209440141616449\n",
            "Loss in iteration no. 65381 ==> 0.5209426594087424\n",
            "Loss in iteration no. 65382 ==> 0.5209413046699644\n",
            "Loss in iteration no. 65383 ==> 0.5209399499453108\n",
            "Loss in iteration no. 65384 ==> 0.5209385952347816\n",
            "Loss in iteration no. 65385 ==> 0.5209372405383762\n",
            "Loss in iteration no. 65386 ==> 0.5209358858560947\n",
            "Loss in iteration no. 65387 ==> 0.5209345311879368\n",
            "Loss in iteration no. 65388 ==> 0.5209331765339023\n",
            "Loss in iteration no. 65389 ==> 0.5209318218939909\n",
            "Loss in iteration no. 65390 ==> 0.5209304672682024\n",
            "Loss in iteration no. 65391 ==> 0.5209291126565364\n",
            "Loss in iteration no. 65392 ==> 0.5209277580589929\n",
            "Loss in iteration no. 65393 ==> 0.520926403475572\n",
            "Loss in iteration no. 65394 ==> 0.5209250489062729\n",
            "Loss in iteration no. 65395 ==> 0.5209236943510956\n",
            "Loss in iteration no. 65396 ==> 0.5209223398100399\n",
            "Loss in iteration no. 65397 ==> 0.5209209852831056\n",
            "Loss in iteration no. 65398 ==> 0.5209196307702926\n",
            "Loss in iteration no. 65399 ==> 0.5209182762716004\n",
            "Loss in iteration no. 65400 ==> 0.5209169217870288\n",
            "Loss in iteration no. 65401 ==> 0.520915567316578\n",
            "Loss in iteration no. 65402 ==> 0.5209142128602472\n",
            "Loss in iteration no. 65403 ==> 0.5209128584180366\n",
            "Loss in iteration no. 65404 ==> 0.5209115039899458\n",
            "Loss in iteration no. 65405 ==> 0.5209101495759746\n",
            "Loss in iteration no. 65406 ==> 0.5209087951761229\n",
            "Loss in iteration no. 65407 ==> 0.5209074407903902\n",
            "Loss in iteration no. 65408 ==> 0.5209060864187766\n",
            "Loss in iteration no. 65409 ==> 0.5209047320612816\n",
            "Loss in iteration no. 65410 ==> 0.5209033777179053\n",
            "Loss in iteration no. 65411 ==> 0.5209020233886473\n",
            "Loss in iteration no. 65412 ==> 0.5209006690735073\n",
            "Loss in iteration no. 65413 ==> 0.5208993147724852\n",
            "Loss in iteration no. 65414 ==> 0.5208979604855809\n",
            "Loss in iteration no. 65415 ==> 0.5208966062127938\n",
            "Loss in iteration no. 65416 ==> 0.5208952519541239\n",
            "Loss in iteration no. 65417 ==> 0.5208938977095713\n",
            "Loss in iteration no. 65418 ==> 0.5208925434791352\n",
            "Loss in iteration no. 65419 ==> 0.5208911892628157\n",
            "Loss in iteration no. 65420 ==> 0.5208898350606125\n",
            "Loss in iteration no. 65421 ==> 0.5208884808725255\n",
            "Loss in iteration no. 65422 ==> 0.5208871266985542\n",
            "Loss in iteration no. 65423 ==> 0.5208857725386988\n",
            "Loss in iteration no. 65424 ==> 0.5208844183929587\n",
            "Loss in iteration no. 65425 ==> 0.5208830642613339\n",
            "Loss in iteration no. 65426 ==> 0.5208817101438241\n",
            "Loss in iteration no. 65427 ==> 0.5208803560404294\n",
            "Loss in iteration no. 65428 ==> 0.5208790019511489\n",
            "Loss in iteration no. 65429 ==> 0.5208776478759829\n",
            "Loss in iteration no. 65430 ==> 0.520876293814931\n",
            "Loss in iteration no. 65431 ==> 0.5208749397679932\n",
            "Loss in iteration no. 65432 ==> 0.5208735857351687\n",
            "Loss in iteration no. 65433 ==> 0.5208722317164579\n",
            "Loss in iteration no. 65434 ==> 0.5208708777118604\n",
            "Loss in iteration no. 65435 ==> 0.520869523721376\n",
            "Loss in iteration no. 65436 ==> 0.5208681697450044\n",
            "Loss in iteration no. 65437 ==> 0.5208668157827453\n",
            "Loss in iteration no. 65438 ==> 0.5208654618345986\n",
            "Loss in iteration no. 65439 ==> 0.5208641079005641\n",
            "Loss in iteration no. 65440 ==> 0.5208627539806416\n",
            "Loss in iteration no. 65441 ==> 0.5208614000748307\n",
            "Loss in iteration no. 65442 ==> 0.5208600461831314\n",
            "Loss in iteration no. 65443 ==> 0.5208586923055435\n",
            "Loss in iteration no. 65444 ==> 0.5208573384420666\n",
            "Loss in iteration no. 65445 ==> 0.5208559845927005\n",
            "Loss in iteration no. 65446 ==> 0.5208546307574451\n",
            "Loss in iteration no. 65447 ==> 0.5208532769363\n",
            "Loss in iteration no. 65448 ==> 0.5208519231292652\n",
            "Loss in iteration no. 65449 ==> 0.5208505693363404\n",
            "Loss in iteration no. 65450 ==> 0.5208492155575253\n",
            "Loss in iteration no. 65451 ==> 0.5208478617928197\n",
            "Loss in iteration no. 65452 ==> 0.5208465080422235\n",
            "Loss in iteration no. 65453 ==> 0.5208451543057363\n",
            "Loss in iteration no. 65454 ==> 0.5208438005833581\n",
            "Loss in iteration no. 65455 ==> 0.5208424468750885\n",
            "Loss in iteration no. 65456 ==> 0.5208410931809274\n",
            "Loss in iteration no. 65457 ==> 0.5208397395008745\n",
            "Loss in iteration no. 65458 ==> 0.5208383858349297\n",
            "Loss in iteration no. 65459 ==> 0.5208370321830925\n",
            "Loss in iteration no. 65460 ==> 0.520835678545363\n",
            "Loss in iteration no. 65461 ==> 0.5208343249217405\n",
            "Loss in iteration no. 65462 ==> 0.5208329713122256\n",
            "Loss in iteration no. 65463 ==> 0.5208316177168175\n",
            "Loss in iteration no. 65464 ==> 0.520830264135516\n",
            "Loss in iteration no. 65465 ==> 0.520828910568321\n",
            "Loss in iteration no. 65466 ==> 0.5208275570152322\n",
            "Loss in iteration no. 65467 ==> 0.5208262034762495\n",
            "Loss in iteration no. 65468 ==> 0.5208248499513727\n",
            "Loss in iteration no. 65469 ==> 0.5208234964406014\n",
            "Loss in iteration no. 65470 ==> 0.5208221429439354\n",
            "Loss in iteration no. 65471 ==> 0.5208207894613747\n",
            "Loss in iteration no. 65472 ==> 0.5208194359929189\n",
            "Loss in iteration no. 65473 ==> 0.5208180825385678\n",
            "Loss in iteration no. 65474 ==> 0.5208167290983212\n",
            "Loss in iteration no. 65475 ==> 0.5208153756721788\n",
            "Loss in iteration no. 65476 ==> 0.5208140222601406\n",
            "Loss in iteration no. 65477 ==> 0.5208126688622062\n",
            "Loss in iteration no. 65478 ==> 0.5208113154783754\n",
            "Loss in iteration no. 65479 ==> 0.5208099621086482\n",
            "Loss in iteration no. 65480 ==> 0.5208086087530239\n",
            "Loss in iteration no. 65481 ==> 0.5208072554115026\n",
            "Loss in iteration no. 65482 ==> 0.5208059020840843\n",
            "Loss in iteration no. 65483 ==> 0.5208045487707682\n",
            "Loss in iteration no. 65484 ==> 0.5208031954715546\n",
            "Loss in iteration no. 65485 ==> 0.520801842186443\n",
            "Loss in iteration no. 65486 ==> 0.5208004889154335\n",
            "Loss in iteration no. 65487 ==> 0.5207991356585255\n",
            "Loss in iteration no. 65488 ==> 0.5207977824157191\n",
            "Loss in iteration no. 65489 ==> 0.5207964291870137\n",
            "Loss in iteration no. 65490 ==> 0.5207950759724093\n",
            "Loss in iteration no. 65491 ==> 0.5207937227719058\n",
            "Loss in iteration no. 65492 ==> 0.5207923695855028\n",
            "Loss in iteration no. 65493 ==> 0.5207910164132001\n",
            "Loss in iteration no. 65494 ==> 0.5207896632549975\n",
            "Loss in iteration no. 65495 ==> 0.5207883101108951\n",
            "Loss in iteration no. 65496 ==> 0.5207869569808921\n",
            "Loss in iteration no. 65497 ==> 0.5207856038649885\n",
            "Loss in iteration no. 65498 ==> 0.5207842507631845\n",
            "Loss in iteration no. 65499 ==> 0.5207828976754793\n",
            "Loss in iteration no. 65500 ==> 0.5207815446018729\n",
            "Loss in iteration no. 65501 ==> 0.5207801915423651\n",
            "Loss in iteration no. 65502 ==> 0.5207788384969558\n",
            "Loss in iteration no. 65503 ==> 0.5207774854656445\n",
            "Loss in iteration no. 65504 ==> 0.5207761324484311\n",
            "Loss in iteration no. 65505 ==> 0.5207747794453156\n",
            "Loss in iteration no. 65506 ==> 0.5207734264562975\n",
            "Loss in iteration no. 65507 ==> 0.5207720734813767\n",
            "Loss in iteration no. 65508 ==> 0.5207707205205531\n",
            "Loss in iteration no. 65509 ==> 0.5207693675738262\n",
            "Loss in iteration no. 65510 ==> 0.5207680146411958\n",
            "Loss in iteration no. 65511 ==> 0.5207666617226621\n",
            "Loss in iteration no. 65512 ==> 0.5207653088182242\n",
            "Loss in iteration no. 65513 ==> 0.5207639559278825\n",
            "Loss in iteration no. 65514 ==> 0.5207626030516366\n",
            "Loss in iteration no. 65515 ==> 0.520761250189486\n",
            "Loss in iteration no. 65516 ==> 0.5207598973414309\n",
            "Loss in iteration no. 65517 ==> 0.520758544507471\n",
            "Loss in iteration no. 65518 ==> 0.5207571916876056\n",
            "Loss in iteration no. 65519 ==> 0.5207558388818353\n",
            "Loss in iteration no. 65520 ==> 0.5207544860901593\n",
            "Loss in iteration no. 65521 ==> 0.5207531333125772\n",
            "Loss in iteration no. 65522 ==> 0.5207517805490895\n",
            "Loss in iteration no. 65523 ==> 0.5207504277996954\n",
            "Loss in iteration no. 65524 ==> 0.5207490750643948\n",
            "Loss in iteration no. 65525 ==> 0.5207477223431879\n",
            "Loss in iteration no. 65526 ==> 0.5207463696360738\n",
            "Loss in iteration no. 65527 ==> 0.5207450169430525\n",
            "Loss in iteration no. 65528 ==> 0.5207436642641241\n",
            "Loss in iteration no. 65529 ==> 0.5207423115992882\n",
            "Loss in iteration no. 65530 ==> 0.5207409589485444\n",
            "Loss in iteration no. 65531 ==> 0.5207396063118926\n",
            "Loss in iteration no. 65532 ==> 0.5207382536893329\n",
            "Loss in iteration no. 65533 ==> 0.5207369010808646\n",
            "Loss in iteration no. 65534 ==> 0.5207355484864876\n",
            "Loss in iteration no. 65535 ==> 0.520734195906202\n",
            "Loss in iteration no. 65536 ==> 0.5207328433400071\n",
            "Loss in iteration no. 65537 ==> 0.5207314907879029\n",
            "Loss in iteration no. 65538 ==> 0.5207301382498893\n",
            "Loss in iteration no. 65539 ==> 0.520728785725966\n",
            "Loss in iteration no. 65540 ==> 0.5207274332161327\n",
            "Loss in iteration no. 65541 ==> 0.5207260807203894\n",
            "Loss in iteration no. 65542 ==> 0.5207247282387356\n",
            "Loss in iteration no. 65543 ==> 0.5207233757711712\n",
            "Loss in iteration no. 65544 ==> 0.5207220233176961\n",
            "Loss in iteration no. 65545 ==> 0.5207206708783098\n",
            "Loss in iteration no. 65546 ==> 0.5207193184530123\n",
            "Loss in iteration no. 65547 ==> 0.5207179660418036\n",
            "Loss in iteration no. 65548 ==> 0.5207166136446828\n",
            "Loss in iteration no. 65549 ==> 0.5207152612616504\n",
            "Loss in iteration no. 65550 ==> 0.5207139088927057\n",
            "Loss in iteration no. 65551 ==> 0.5207125565378488\n",
            "Loss in iteration no. 65552 ==> 0.5207112041970792\n",
            "Loss in iteration no. 65553 ==> 0.5207098518703969\n",
            "Loss in iteration no. 65554 ==> 0.5207084995578016\n",
            "Loss in iteration no. 65555 ==> 0.520707147259293\n",
            "Loss in iteration no. 65556 ==> 0.520705794974871\n",
            "Loss in iteration no. 65557 ==> 0.5207044427045355\n",
            "Loss in iteration no. 65558 ==> 0.5207030904482861\n",
            "Loss in iteration no. 65559 ==> 0.5207017382061225\n",
            "Loss in iteration no. 65560 ==> 0.5207003859780445\n",
            "Loss in iteration no. 65561 ==> 0.5206990337640522\n",
            "Loss in iteration no. 65562 ==> 0.5206976815641449\n",
            "Loss in iteration no. 65563 ==> 0.520696329378323\n",
            "Loss in iteration no. 65564 ==> 0.5206949772065856\n",
            "Loss in iteration no. 65565 ==> 0.520693625048933\n",
            "Loss in iteration no. 65566 ==> 0.5206922729053647\n",
            "Loss in iteration no. 65567 ==> 0.5206909207758806\n",
            "Loss in iteration no. 65568 ==> 0.5206895686604804\n",
            "Loss in iteration no. 65569 ==> 0.5206882165591639\n",
            "Loss in iteration no. 65570 ==> 0.5206868644719309\n",
            "Loss in iteration no. 65571 ==> 0.5206855123987812\n",
            "Loss in iteration no. 65572 ==> 0.5206841603397148\n",
            "Loss in iteration no. 65573 ==> 0.520682808294731\n",
            "Loss in iteration no. 65574 ==> 0.52068145626383\n",
            "Loss in iteration no. 65575 ==> 0.5206801042470112\n",
            "Loss in iteration no. 65576 ==> 0.5206787522442747\n",
            "Loss in iteration no. 65577 ==> 0.52067740025562\n",
            "Loss in iteration no. 65578 ==> 0.5206760482810474\n",
            "Loss in iteration no. 65579 ==> 0.5206746963205563\n",
            "Loss in iteration no. 65580 ==> 0.5206733443741463\n",
            "Loss in iteration no. 65581 ==> 0.5206719924418176\n",
            "Loss in iteration no. 65582 ==> 0.5206706405235697\n",
            "Loss in iteration no. 65583 ==> 0.5206692886194024\n",
            "Loss in iteration no. 65584 ==> 0.5206679367293157\n",
            "Loss in iteration no. 65585 ==> 0.5206665848533091\n",
            "Loss in iteration no. 65586 ==> 0.5206652329913827\n",
            "Loss in iteration no. 65587 ==> 0.5206638811435358\n",
            "Loss in iteration no. 65588 ==> 0.5206625293097688\n",
            "Loss in iteration no. 65589 ==> 0.5206611774900809\n",
            "Loss in iteration no. 65590 ==> 0.5206598256844722\n",
            "Loss in iteration no. 65591 ==> 0.5206584738929425\n",
            "Loss in iteration no. 65592 ==> 0.5206571221154915\n",
            "Loss in iteration no. 65593 ==> 0.5206557703521191\n",
            "Loss in iteration no. 65594 ==> 0.5206544186028249\n",
            "Loss in iteration no. 65595 ==> 0.5206530668676085\n",
            "Loss in iteration no. 65596 ==> 0.5206517151464701\n",
            "Loss in iteration no. 65597 ==> 0.5206503634394094\n",
            "Loss in iteration no. 65598 ==> 0.520649011746426\n",
            "Loss in iteration no. 65599 ==> 0.5206476600675198\n",
            "Loss in iteration no. 65600 ==> 0.5206463084026904\n",
            "Loss in iteration no. 65601 ==> 0.520644956751938\n",
            "Loss in iteration no. 65602 ==> 0.520643605115262\n",
            "Loss in iteration no. 65603 ==> 0.5206422534926624\n",
            "Loss in iteration no. 65604 ==> 0.5206409018841387\n",
            "Loss in iteration no. 65605 ==> 0.520639550289691\n",
            "Loss in iteration no. 65606 ==> 0.520638198709319\n",
            "Loss in iteration no. 65607 ==> 0.5206368471430223\n",
            "Loss in iteration no. 65608 ==> 0.5206354955908008\n",
            "Loss in iteration no. 65609 ==> 0.5206341440526543\n",
            "Loss in iteration no. 65610 ==> 0.5206327925285829\n",
            "Loss in iteration no. 65611 ==> 0.5206314410185856\n",
            "Loss in iteration no. 65612 ==> 0.5206300895226628\n",
            "Loss in iteration no. 65613 ==> 0.5206287380408143\n",
            "Loss in iteration no. 65614 ==> 0.5206273865730394\n",
            "Loss in iteration no. 65615 ==> 0.5206260351193384\n",
            "Loss in iteration no. 65616 ==> 0.5206246836797108\n",
            "Loss in iteration no. 65617 ==> 0.5206233322541565\n",
            "Loss in iteration no. 65618 ==> 0.5206219808426751\n",
            "Loss in iteration no. 65619 ==> 0.5206206294452667\n",
            "Loss in iteration no. 65620 ==> 0.5206192780619308\n",
            "Loss in iteration no. 65621 ==> 0.5206179266926672\n",
            "Loss in iteration no. 65622 ==> 0.5206165753374757\n",
            "Loss in iteration no. 65623 ==> 0.5206152239963564\n",
            "Loss in iteration no. 65624 ==> 0.5206138726693086\n",
            "Loss in iteration no. 65625 ==> 0.5206125213563324\n",
            "Loss in iteration no. 65626 ==> 0.5206111700574274\n",
            "Loss in iteration no. 65627 ==> 0.5206098187725936\n",
            "Loss in iteration no. 65628 ==> 0.5206084675018307\n",
            "Loss in iteration no. 65629 ==> 0.5206071162451382\n",
            "Loss in iteration no. 65630 ==> 0.5206057650025162\n",
            "Loss in iteration no. 65631 ==> 0.5206044137739644\n",
            "Loss in iteration no. 65632 ==> 0.5206030625594826\n",
            "Loss in iteration no. 65633 ==> 0.5206017113590705\n",
            "Loss in iteration no. 65634 ==> 0.5206003601727281\n",
            "Loss in iteration no. 65635 ==> 0.5205990090004547\n",
            "Loss in iteration no. 65636 ==> 0.5205976578422506\n",
            "Loss in iteration no. 65637 ==> 0.5205963066981156\n",
            "Loss in iteration no. 65638 ==> 0.520594955568049\n",
            "Loss in iteration no. 65639 ==> 0.5205936044520508\n",
            "Loss in iteration no. 65640 ==> 0.5205922533501212\n",
            "Loss in iteration no. 65641 ==> 0.5205909022622592\n",
            "Loss in iteration no. 65642 ==> 0.5205895511884652\n",
            "Loss in iteration no. 65643 ==> 0.5205882001287386\n",
            "Loss in iteration no. 65644 ==> 0.5205868490830796\n",
            "Loss in iteration no. 65645 ==> 0.5205854980514876\n",
            "Loss in iteration no. 65646 ==> 0.5205841470339626\n",
            "Loss in iteration no. 65647 ==> 0.5205827960305043\n",
            "Loss in iteration no. 65648 ==> 0.5205814450411124\n",
            "Loss in iteration no. 65649 ==> 0.5205800940657869\n",
            "Loss in iteration no. 65650 ==> 0.5205787431045273\n",
            "Loss in iteration no. 65651 ==> 0.5205773921573337\n",
            "Loss in iteration no. 65652 ==> 0.5205760412242054\n",
            "Loss in iteration no. 65653 ==> 0.5205746903051428\n",
            "Loss in iteration no. 65654 ==> 0.5205733394001453\n",
            "Loss in iteration no. 65655 ==> 0.5205719885092127\n",
            "Loss in iteration no. 65656 ==> 0.5205706376323449\n",
            "Loss in iteration no. 65657 ==> 0.5205692867695416\n",
            "Loss in iteration no. 65658 ==> 0.5205679359208026\n",
            "Loss in iteration no. 65659 ==> 0.5205665850861276\n",
            "Loss in iteration no. 65660 ==> 0.5205652342655166\n",
            "Loss in iteration no. 65661 ==> 0.5205638834589693\n",
            "Loss in iteration no. 65662 ==> 0.5205625326664854\n",
            "Loss in iteration no. 65663 ==> 0.5205611818880648\n",
            "Loss in iteration no. 65664 ==> 0.520559831123707\n",
            "Loss in iteration no. 65665 ==> 0.520558480373412\n",
            "Loss in iteration no. 65666 ==> 0.5205571296371797\n",
            "Loss in iteration no. 65667 ==> 0.5205557789150096\n",
            "Loss in iteration no. 65668 ==> 0.5205544282069018\n",
            "Loss in iteration no. 65669 ==> 0.5205530775128557\n",
            "Loss in iteration no. 65670 ==> 0.5205517268328714\n",
            "Loss in iteration no. 65671 ==> 0.5205503761669488\n",
            "Loss in iteration no. 65672 ==> 0.520549025515087\n",
            "Loss in iteration no. 65673 ==> 0.5205476748772865\n",
            "Loss in iteration no. 65674 ==> 0.5205463242535467\n",
            "Loss in iteration no. 65675 ==> 0.5205449736438678\n",
            "Loss in iteration no. 65676 ==> 0.5205436230482489\n",
            "Loss in iteration no. 65677 ==> 0.5205422724666905\n",
            "Loss in iteration no. 65678 ==> 0.5205409218991919\n",
            "Loss in iteration no. 65679 ==> 0.5205395713457529\n",
            "Loss in iteration no. 65680 ==> 0.5205382208063735\n",
            "Loss in iteration no. 65681 ==> 0.5205368702810534\n",
            "Loss in iteration no. 65682 ==> 0.5205355197697925\n",
            "Loss in iteration no. 65683 ==> 0.5205341692725904\n",
            "Loss in iteration no. 65684 ==> 0.5205328187894469\n",
            "Loss in iteration no. 65685 ==> 0.5205314683203617\n",
            "Loss in iteration no. 65686 ==> 0.5205301178653349\n",
            "Loss in iteration no. 65687 ==> 0.520528767424366\n",
            "Loss in iteration no. 65688 ==> 0.520527416997455\n",
            "Loss in iteration no. 65689 ==> 0.5205260665846014\n",
            "Loss in iteration no. 65690 ==> 0.5205247161858051\n",
            "Loss in iteration no. 65691 ==> 0.5205233658010662\n",
            "Loss in iteration no. 65692 ==> 0.5205220154303838\n",
            "Loss in iteration no. 65693 ==> 0.5205206650737583\n",
            "Loss in iteration no. 65694 ==> 0.5205193147311893\n",
            "Loss in iteration no. 65695 ==> 0.5205179644026765\n",
            "Loss in iteration no. 65696 ==> 0.5205166140882197\n",
            "Loss in iteration no. 65697 ==> 0.5205152637878188\n",
            "Loss in iteration no. 65698 ==> 0.5205139135014732\n",
            "Loss in iteration no. 65699 ==> 0.5205125632291834\n",
            "Loss in iteration no. 65700 ==> 0.5205112129709485\n",
            "Loss in iteration no. 65701 ==> 0.5205098627267686\n",
            "Loss in iteration no. 65702 ==> 0.5205085124966434\n",
            "Loss in iteration no. 65703 ==> 0.5205071622805726\n",
            "Loss in iteration no. 65704 ==> 0.5205058120785563\n",
            "Loss in iteration no. 65705 ==> 0.520504461890594\n",
            "Loss in iteration no. 65706 ==> 0.5205031117166854\n",
            "Loss in iteration no. 65707 ==> 0.5205017615568305\n",
            "Loss in iteration no. 65708 ==> 0.5205004114110292\n",
            "Loss in iteration no. 65709 ==> 0.5204990612792809\n",
            "Loss in iteration no. 65710 ==> 0.5204977111615856\n",
            "Loss in iteration no. 65711 ==> 0.5204963610579431\n",
            "Loss in iteration no. 65712 ==> 0.5204950109683532\n",
            "Loss in iteration no. 65713 ==> 0.5204936608928155\n",
            "Loss in iteration no. 65714 ==> 0.5204923108313299\n",
            "Loss in iteration no. 65715 ==> 0.5204909607838965\n",
            "Loss in iteration no. 65716 ==> 0.5204896107505145\n",
            "Loss in iteration no. 65717 ==> 0.5204882607311838\n",
            "Loss in iteration no. 65718 ==> 0.5204869107259046\n",
            "Loss in iteration no. 65719 ==> 0.5204855607346764\n",
            "Loss in iteration no. 65720 ==> 0.520484210757499\n",
            "Loss in iteration no. 65721 ==> 0.5204828607943721\n",
            "Loss in iteration no. 65722 ==> 0.5204815108452956\n",
            "Loss in iteration no. 65723 ==> 0.5204801609102693\n",
            "Loss in iteration no. 65724 ==> 0.5204788109892929\n",
            "Loss in iteration no. 65725 ==> 0.5204774610823661\n",
            "Loss in iteration no. 65726 ==> 0.520476111189489\n",
            "Loss in iteration no. 65727 ==> 0.5204747613106611\n",
            "Loss in iteration no. 65728 ==> 0.5204734114458822\n",
            "Loss in iteration no. 65729 ==> 0.5204720615951522\n",
            "Loss in iteration no. 65730 ==> 0.5204707117584708\n",
            "Loss in iteration no. 65731 ==> 0.5204693619358378\n",
            "Loss in iteration no. 65732 ==> 0.520468012127253\n",
            "Loss in iteration no. 65733 ==> 0.5204666623327162\n",
            "Loss in iteration no. 65734 ==> 0.5204653125522272\n",
            "Loss in iteration no. 65735 ==> 0.5204639627857857\n",
            "Loss in iteration no. 65736 ==> 0.5204626130333915\n",
            "Loss in iteration no. 65737 ==> 0.5204612632950443\n",
            "Loss in iteration no. 65738 ==> 0.5204599135707442\n",
            "Loss in iteration no. 65739 ==> 0.5204585638604906\n",
            "Loss in iteration no. 65740 ==> 0.5204572141642836\n",
            "Loss in iteration no. 65741 ==> 0.5204558644821227\n",
            "Loss in iteration no. 65742 ==> 0.520454514814008\n",
            "Loss in iteration no. 65743 ==> 0.5204531651599388\n",
            "Loss in iteration no. 65744 ==> 0.5204518155199154\n",
            "Loss in iteration no. 65745 ==> 0.5204504658939372\n",
            "Loss in iteration no. 65746 ==> 0.5204491162820043\n",
            "Loss in iteration no. 65747 ==> 0.5204477666841163\n",
            "Loss in iteration no. 65748 ==> 0.520446417100273\n",
            "Loss in iteration no. 65749 ==> 0.5204450675304741\n",
            "Loss in iteration no. 65750 ==> 0.5204437179747196\n",
            "Loss in iteration no. 65751 ==> 0.5204423684330091\n",
            "Loss in iteration no. 65752 ==> 0.5204410189053423\n",
            "Loss in iteration no. 65753 ==> 0.5204396693917195\n",
            "Loss in iteration no. 65754 ==> 0.5204383198921398\n",
            "Loss in iteration no. 65755 ==> 0.5204369704066035\n",
            "Loss in iteration no. 65756 ==> 0.52043562093511\n",
            "Loss in iteration no. 65757 ==> 0.5204342714776592\n",
            "Loss in iteration no. 65758 ==> 0.5204329220342511\n",
            "Loss in iteration no. 65759 ==> 0.5204315726048853\n",
            "Loss in iteration no. 65760 ==> 0.5204302231895614\n",
            "Loss in iteration no. 65761 ==> 0.5204288737882796\n",
            "Loss in iteration no. 65762 ==> 0.5204275244010395\n",
            "Loss in iteration no. 65763 ==> 0.5204261750278407\n",
            "Loss in iteration no. 65764 ==> 0.5204248256686831\n",
            "Loss in iteration no. 65765 ==> 0.5204234763235666\n",
            "Loss in iteration no. 65766 ==> 0.520422126992491\n",
            "Loss in iteration no. 65767 ==> 0.5204207776754558\n",
            "Loss in iteration no. 65768 ==> 0.520419428372461\n",
            "Loss in iteration no. 65769 ==> 0.5204180790835065\n",
            "Loss in iteration no. 65770 ==> 0.5204167298085918\n",
            "Loss in iteration no. 65771 ==> 0.5204153805477169\n",
            "Loss in iteration no. 65772 ==> 0.5204140313008814\n",
            "Loss in iteration no. 65773 ==> 0.520412682068085\n",
            "Loss in iteration no. 65774 ==> 0.520411332849328\n",
            "Loss in iteration no. 65775 ==> 0.5204099836446096\n",
            "Loss in iteration no. 65776 ==> 0.5204086344539299\n",
            "Loss in iteration no. 65777 ==> 0.5204072852772885\n",
            "Loss in iteration no. 65778 ==> 0.5204059361146854\n",
            "Loss in iteration no. 65779 ==> 0.5204045869661204\n",
            "Loss in iteration no. 65780 ==> 0.520403237831593\n",
            "Loss in iteration no. 65781 ==> 0.5204018887111032\n",
            "Loss in iteration no. 65782 ==> 0.5204005396046506\n",
            "Loss in iteration no. 65783 ==> 0.5203991905122352\n",
            "Loss in iteration no. 65784 ==> 0.5203978414338567\n",
            "Loss in iteration no. 65785 ==> 0.5203964923695147\n",
            "Loss in iteration no. 65786 ==> 0.5203951433192093\n",
            "Loss in iteration no. 65787 ==> 0.5203937942829401\n",
            "Loss in iteration no. 65788 ==> 0.5203924452607069\n",
            "Loss in iteration no. 65789 ==> 0.5203910962525097\n",
            "Loss in iteration no. 65790 ==> 0.5203897472583476\n",
            "Loss in iteration no. 65791 ==> 0.5203883982782213\n",
            "Loss in iteration no. 65792 ==> 0.5203870493121299\n",
            "Loss in iteration no. 65793 ==> 0.5203857003600737\n",
            "Loss in iteration no. 65794 ==> 0.520384351422052\n",
            "Loss in iteration no. 65795 ==> 0.5203830024980648\n",
            "Loss in iteration no. 65796 ==> 0.5203816535881121\n",
            "Loss in iteration no. 65797 ==> 0.5203803046921931\n",
            "Loss in iteration no. 65798 ==> 0.5203789558103082\n",
            "Loss in iteration no. 65799 ==> 0.5203776069424568\n",
            "Loss in iteration no. 65800 ==> 0.5203762580886389\n",
            "Loss in iteration no. 65801 ==> 0.5203749092488541\n",
            "Loss in iteration no. 65802 ==> 0.5203735604231023\n",
            "Loss in iteration no. 65803 ==> 0.5203722116113834\n",
            "Loss in iteration no. 65804 ==> 0.5203708628136967\n",
            "Loss in iteration no. 65805 ==> 0.5203695140300426\n",
            "Loss in iteration no. 65806 ==> 0.5203681652604206\n",
            "Loss in iteration no. 65807 ==> 0.5203668165048304\n",
            "Loss in iteration no. 65808 ==> 0.520365467763272\n",
            "Loss in iteration no. 65809 ==> 0.520364119035745\n",
            "Loss in iteration no. 65810 ==> 0.5203627703222491\n",
            "Loss in iteration no. 65811 ==> 0.5203614216227842\n",
            "Loss in iteration no. 65812 ==> 0.5203600729373503\n",
            "Loss in iteration no. 65813 ==> 0.5203587242659468\n",
            "Loss in iteration no. 65814 ==> 0.5203573756085738\n",
            "Loss in iteration no. 65815 ==> 0.5203560269652309\n",
            "Loss in iteration no. 65816 ==> 0.520354678335918\n",
            "Loss in iteration no. 65817 ==> 0.5203533297206347\n",
            "Loss in iteration no. 65818 ==> 0.5203519811193809\n",
            "Loss in iteration no. 65819 ==> 0.5203506325321564\n",
            "Loss in iteration no. 65820 ==> 0.5203492839589612\n",
            "Loss in iteration no. 65821 ==> 0.5203479353997945\n",
            "Loss in iteration no. 65822 ==> 0.5203465868546565\n",
            "Loss in iteration no. 65823 ==> 0.5203452383235471\n",
            "Loss in iteration no. 65824 ==> 0.5203438898064657\n",
            "Loss in iteration no. 65825 ==> 0.5203425413034124\n",
            "Loss in iteration no. 65826 ==> 0.520341192814387\n",
            "Loss in iteration no. 65827 ==> 0.5203398443393887\n",
            "Loss in iteration no. 65828 ==> 0.5203384958784181\n",
            "Loss in iteration no. 65829 ==> 0.5203371474314745\n",
            "Loss in iteration no. 65830 ==> 0.5203357989985578\n",
            "Loss in iteration no. 65831 ==> 0.5203344505796678\n",
            "Loss in iteration no. 65832 ==> 0.5203331021748041\n",
            "Loss in iteration no. 65833 ==> 0.5203317537839668\n",
            "Loss in iteration no. 65834 ==> 0.5203304054071556\n",
            "Loss in iteration no. 65835 ==> 0.5203290570443702\n",
            "Loss in iteration no. 65836 ==> 0.5203277086956102\n",
            "Loss in iteration no. 65837 ==> 0.5203263603608757\n",
            "Loss in iteration no. 65838 ==> 0.5203250120401662\n",
            "Loss in iteration no. 65839 ==> 0.5203236637334819\n",
            "Loss in iteration no. 65840 ==> 0.5203223154408221\n",
            "Loss in iteration no. 65841 ==> 0.5203209671621869\n",
            "Loss in iteration no. 65842 ==> 0.5203196188975758\n",
            "Loss in iteration no. 65843 ==> 0.5203182706469892\n",
            "Loss in iteration no. 65844 ==> 0.5203169224104262\n",
            "Loss in iteration no. 65845 ==> 0.5203155741878868\n",
            "Loss in iteration no. 65846 ==> 0.5203142259793709\n",
            "Loss in iteration no. 65847 ==> 0.5203128777848782\n",
            "Loss in iteration no. 65848 ==> 0.5203115296044084\n",
            "Loss in iteration no. 65849 ==> 0.5203101814379615\n",
            "Loss in iteration no. 65850 ==> 0.5203088332855371\n",
            "Loss in iteration no. 65851 ==> 0.5203074851471351\n",
            "Loss in iteration no. 65852 ==> 0.5203061370227551\n",
            "Loss in iteration no. 65853 ==> 0.5203047889123971\n",
            "Loss in iteration no. 65854 ==> 0.5203034408160606\n",
            "Loss in iteration no. 65855 ==> 0.5203020927337456\n",
            "Loss in iteration no. 65856 ==> 0.5203007446654521\n",
            "Loss in iteration no. 65857 ==> 0.5202993966111794\n",
            "Loss in iteration no. 65858 ==> 0.5202980485709275\n",
            "Loss in iteration no. 65859 ==> 0.5202967005446963\n",
            "Loss in iteration no. 65860 ==> 0.5202953525324855\n",
            "Loss in iteration no. 65861 ==> 0.520294004534295\n",
            "Loss in iteration no. 65862 ==> 0.5202926565501242\n",
            "Loss in iteration no. 65863 ==> 0.5202913085799733\n",
            "Loss in iteration no. 65864 ==> 0.5202899606238418\n",
            "Loss in iteration no. 65865 ==> 0.5202886126817295\n",
            "Loss in iteration no. 65866 ==> 0.5202872647536366\n",
            "Loss in iteration no. 65867 ==> 0.5202859168395623\n",
            "Loss in iteration no. 65868 ==> 0.5202845689395068\n",
            "Loss in iteration no. 65869 ==> 0.5202832210534697\n",
            "Loss in iteration no. 65870 ==> 0.5202818731814506\n",
            "Loss in iteration no. 65871 ==> 0.5202805253234498\n",
            "Loss in iteration no. 65872 ==> 0.5202791774794667\n",
            "Loss in iteration no. 65873 ==> 0.5202778296495011\n",
            "Loss in iteration no. 65874 ==> 0.5202764818335529\n",
            "Loss in iteration no. 65875 ==> 0.5202751340316217\n",
            "Loss in iteration no. 65876 ==> 0.5202737862437076\n",
            "Loss in iteration no. 65877 ==> 0.5202724384698102\n",
            "Loss in iteration no. 65878 ==> 0.520271090709929\n",
            "Loss in iteration no. 65879 ==> 0.5202697429640644\n",
            "Loss in iteration no. 65880 ==> 0.5202683952322157\n",
            "Loss in iteration no. 65881 ==> 0.5202670475143828\n",
            "Loss in iteration no. 65882 ==> 0.5202656998105656\n",
            "Loss in iteration no. 65883 ==> 0.5202643521207636\n",
            "Loss in iteration no. 65884 ==> 0.5202630044449771\n",
            "Loss in iteration no. 65885 ==> 0.5202616567832052\n",
            "Loss in iteration no. 65886 ==> 0.5202603091354483\n",
            "Loss in iteration no. 65887 ==> 0.5202589615017058\n",
            "Loss in iteration no. 65888 ==> 0.5202576138819778\n",
            "Loss in iteration no. 65889 ==> 0.5202562662762638\n",
            "Loss in iteration no. 65890 ==> 0.5202549186845635\n",
            "Loss in iteration no. 65891 ==> 0.520253571106877\n",
            "Loss in iteration no. 65892 ==> 0.5202522235432039\n",
            "Loss in iteration no. 65893 ==> 0.5202508759935441\n",
            "Loss in iteration no. 65894 ==> 0.5202495284578973\n",
            "Loss in iteration no. 65895 ==> 0.5202481809362633\n",
            "Loss in iteration no. 65896 ==> 0.520246833428642\n",
            "Loss in iteration no. 65897 ==> 0.5202454859350328\n",
            "Loss in iteration no. 65898 ==> 0.5202441384554358\n",
            "Loss in iteration no. 65899 ==> 0.5202427909898509\n",
            "Loss in iteration no. 65900 ==> 0.5202414435382775\n",
            "Loss in iteration no. 65901 ==> 0.5202400961007156\n",
            "Loss in iteration no. 65902 ==> 0.5202387486771652\n",
            "Loss in iteration no. 65903 ==> 0.5202374012676256\n",
            "Loss in iteration no. 65904 ==> 0.520236053872097\n",
            "Loss in iteration no. 65905 ==> 0.5202347064905791\n",
            "Loss in iteration no. 65906 ==> 0.5202333591230716\n",
            "Loss in iteration no. 65907 ==> 0.5202320117695742\n",
            "Loss in iteration no. 65908 ==> 0.5202306644300868\n",
            "Loss in iteration no. 65909 ==> 0.5202293171046092\n",
            "Loss in iteration no. 65910 ==> 0.520227969793141\n",
            "Loss in iteration no. 65911 ==> 0.5202266224956822\n",
            "Loss in iteration no. 65912 ==> 0.5202252752122325\n",
            "Loss in iteration no. 65913 ==> 0.5202239279427917\n",
            "Loss in iteration no. 65914 ==> 0.5202225806873596\n",
            "Loss in iteration no. 65915 ==> 0.520221233445936\n",
            "Loss in iteration no. 65916 ==> 0.5202198862185207\n",
            "Loss in iteration no. 65917 ==> 0.5202185390051133\n",
            "Loss in iteration no. 65918 ==> 0.5202171918057136\n",
            "Loss in iteration no. 65919 ==> 0.5202158446203217\n",
            "Loss in iteration no. 65920 ==> 0.5202144974489371\n",
            "Loss in iteration no. 65921 ==> 0.5202131502915598\n",
            "Loss in iteration no. 65922 ==> 0.5202118031481893\n",
            "Loss in iteration no. 65923 ==> 0.5202104560188255\n",
            "Loss in iteration no. 65924 ==> 0.5202091089034683\n",
            "Loss in iteration no. 65925 ==> 0.5202077618021174\n",
            "Loss in iteration no. 65926 ==> 0.5202064147147725\n",
            "Loss in iteration no. 65927 ==> 0.5202050676414335\n",
            "Loss in iteration no. 65928 ==> 0.5202037205821001\n",
            "Loss in iteration no. 65929 ==> 0.5202023735367722\n",
            "Loss in iteration no. 65930 ==> 0.5202010265054495\n",
            "Loss in iteration no. 65931 ==> 0.5201996794881318\n",
            "Loss in iteration no. 65932 ==> 0.520198332484819\n",
            "Loss in iteration no. 65933 ==> 0.5201969854955105\n",
            "Loss in iteration no. 65934 ==> 0.5201956385202064\n",
            "Loss in iteration no. 65935 ==> 0.5201942915589064\n",
            "Loss in iteration no. 65936 ==> 0.5201929446116105\n",
            "Loss in iteration no. 65937 ==> 0.5201915976783181\n",
            "Loss in iteration no. 65938 ==> 0.5201902507590295\n",
            "Loss in iteration no. 65939 ==> 0.5201889038537438\n",
            "Loss in iteration no. 65940 ==> 0.5201875569624613\n",
            "Loss in iteration no. 65941 ==> 0.5201862100851816\n",
            "Loss in iteration no. 65942 ==> 0.5201848632219046\n",
            "Loss in iteration no. 65943 ==> 0.5201835163726299\n",
            "Loss in iteration no. 65944 ==> 0.5201821695373575\n",
            "Loss in iteration no. 65945 ==> 0.5201808227160869\n",
            "Loss in iteration no. 65946 ==> 0.5201794759088183\n",
            "Loss in iteration no. 65947 ==> 0.5201781291155508\n",
            "Loss in iteration no. 65948 ==> 0.5201767823362851\n",
            "Loss in iteration no. 65949 ==> 0.5201754355710202\n",
            "Loss in iteration no. 65950 ==> 0.5201740888197562\n",
            "Loss in iteration no. 65951 ==> 0.520172742082493\n",
            "Loss in iteration no. 65952 ==> 0.5201713953592302\n",
            "Loss in iteration no. 65953 ==> 0.5201700486499676\n",
            "Loss in iteration no. 65954 ==> 0.5201687019547049\n",
            "Loss in iteration no. 65955 ==> 0.5201673552734423\n",
            "Loss in iteration no. 65956 ==> 0.5201660086061791\n",
            "Loss in iteration no. 65957 ==> 0.5201646619529151\n",
            "Loss in iteration no. 65958 ==> 0.5201633153136506\n",
            "Loss in iteration no. 65959 ==> 0.5201619686883848\n",
            "Loss in iteration no. 65960 ==> 0.5201606220771177\n",
            "Loss in iteration no. 65961 ==> 0.5201592754798493\n",
            "Loss in iteration no. 65962 ==> 0.520157928896579\n",
            "Loss in iteration no. 65963 ==> 0.5201565823273067\n",
            "Loss in iteration no. 65964 ==> 0.5201552357720326\n",
            "Loss in iteration no. 65965 ==> 0.5201538892307559\n",
            "Loss in iteration no. 65966 ==> 0.5201525427034764\n",
            "Loss in iteration no. 65967 ==> 0.5201511961901945\n",
            "Loss in iteration no. 65968 ==> 0.5201498496909094\n",
            "Loss in iteration no. 65969 ==> 0.5201485032056211\n",
            "Loss in iteration no. 65970 ==> 0.5201471567343293\n",
            "Loss in iteration no. 65971 ==> 0.520145810277034\n",
            "Loss in iteration no. 65972 ==> 0.5201444638337346\n",
            "Loss in iteration no. 65973 ==> 0.5201431174044312\n",
            "Loss in iteration no. 65974 ==> 0.5201417709891236\n",
            "Loss in iteration no. 65975 ==> 0.5201404245878113\n",
            "Loss in iteration no. 65976 ==> 0.5201390782004943\n",
            "Loss in iteration no. 65977 ==> 0.5201377318271724\n",
            "Loss in iteration no. 65978 ==> 0.5201363854678454\n",
            "Loss in iteration no. 65979 ==> 0.5201350391225128\n",
            "Loss in iteration no. 65980 ==> 0.5201336927911746\n",
            "Loss in iteration no. 65981 ==> 0.5201323464738309\n",
            "Loss in iteration no. 65982 ==> 0.5201310001704809\n",
            "Loss in iteration no. 65983 ==> 0.5201296538811248\n",
            "Loss in iteration no. 65984 ==> 0.5201283076057619\n",
            "Loss in iteration no. 65985 ==> 0.5201269613443925\n",
            "Loss in iteration no. 65986 ==> 0.5201256150970163\n",
            "Loss in iteration no. 65987 ==> 0.5201242688636328\n",
            "Loss in iteration no. 65988 ==> 0.5201229226442421\n",
            "Loss in iteration no. 65989 ==> 0.5201215764388437\n",
            "Loss in iteration no. 65990 ==> 0.5201202302474376\n",
            "Loss in iteration no. 65991 ==> 0.5201188840700235\n",
            "Loss in iteration no. 65992 ==> 0.5201175379066012\n",
            "Loss in iteration no. 65993 ==> 0.5201161917571705\n",
            "Loss in iteration no. 65994 ==> 0.5201148456217313\n",
            "Loss in iteration no. 65995 ==> 0.5201134995002831\n",
            "Loss in iteration no. 65996 ==> 0.5201121533928259\n",
            "Loss in iteration no. 65997 ==> 0.5201108072993591\n",
            "Loss in iteration no. 65998 ==> 0.5201094612198831\n",
            "Loss in iteration no. 65999 ==> 0.5201081151543973\n",
            "Loss in iteration no. 66000 ==> 0.5201067691029018\n",
            "Loss in iteration no. 66001 ==> 0.5201054230653959\n",
            "Loss in iteration no. 66002 ==> 0.5201040770418796\n",
            "Loss in iteration no. 66003 ==> 0.5201027310323527\n",
            "Loss in iteration no. 66004 ==> 0.5201013850368151\n",
            "Loss in iteration no. 66005 ==> 0.5201000390552665\n",
            "Loss in iteration no. 66006 ==> 0.5200986930877066\n",
            "Loss in iteration no. 66007 ==> 0.5200973471341356\n",
            "Loss in iteration no. 66008 ==> 0.5200960011945526\n",
            "Loss in iteration no. 66009 ==> 0.5200946552689577\n",
            "Loss in iteration no. 66010 ==> 0.5200933093573508\n",
            "Loss in iteration no. 66011 ==> 0.5200919634597315\n",
            "Loss in iteration no. 66012 ==> 0.5200906175760998\n",
            "Loss in iteration no. 66013 ==> 0.5200892717064551\n",
            "Loss in iteration no. 66014 ==> 0.5200879258507978\n",
            "Loss in iteration no. 66015 ==> 0.5200865800091271\n",
            "Loss in iteration no. 66016 ==> 0.520085234181443\n",
            "Loss in iteration no. 66017 ==> 0.5200838883677453\n",
            "Loss in iteration no. 66018 ==> 0.5200825425680339\n",
            "Loss in iteration no. 66019 ==> 0.5200811967823085\n",
            "Loss in iteration no. 66020 ==> 0.5200798510105686\n",
            "Loss in iteration no. 66021 ==> 0.5200785052528144\n",
            "Loss in iteration no. 66022 ==> 0.5200771595090453\n",
            "Loss in iteration no. 66023 ==> 0.5200758137792617\n",
            "Loss in iteration no. 66024 ==> 0.5200744680634627\n",
            "Loss in iteration no. 66025 ==> 0.5200731223616483\n",
            "Loss in iteration no. 66026 ==> 0.5200717766738185\n",
            "Loss in iteration no. 66027 ==> 0.5200704309999729\n",
            "Loss in iteration no. 66028 ==> 0.5200690853401114\n",
            "Loss in iteration no. 66029 ==> 0.5200677396942335\n",
            "Loss in iteration no. 66030 ==> 0.5200663940623392\n",
            "Loss in iteration no. 66031 ==> 0.5200650484444284\n",
            "Loss in iteration no. 66032 ==> 0.5200637028405006\n",
            "Loss in iteration no. 66033 ==> 0.520062357250556\n",
            "Loss in iteration no. 66034 ==> 0.5200610116745938\n",
            "Loss in iteration no. 66035 ==> 0.5200596661126143\n",
            "Loss in iteration no. 66036 ==> 0.5200583205646171\n",
            "Loss in iteration no. 66037 ==> 0.5200569750306019\n",
            "Loss in iteration no. 66038 ==> 0.5200556295105686\n",
            "Loss in iteration no. 66039 ==> 0.5200542840045169\n",
            "Loss in iteration no. 66040 ==> 0.5200529385124465\n",
            "Loss in iteration no. 66041 ==> 0.5200515930343573\n",
            "Loss in iteration no. 66042 ==> 0.5200502475702495\n",
            "Loss in iteration no. 66043 ==> 0.5200489021201221\n",
            "Loss in iteration no. 66044 ==> 0.5200475566839755\n",
            "Loss in iteration no. 66045 ==> 0.5200462112618089\n",
            "Loss in iteration no. 66046 ==> 0.5200448658536226\n",
            "Loss in iteration no. 66047 ==> 0.5200435204594163\n",
            "Loss in iteration no. 66048 ==> 0.5200421750791896\n",
            "Loss in iteration no. 66049 ==> 0.5200408297129424\n",
            "Loss in iteration no. 66050 ==> 0.5200394843606745\n",
            "Loss in iteration no. 66051 ==> 0.5200381390223856\n",
            "Loss in iteration no. 66052 ==> 0.5200367936980757\n",
            "Loss in iteration no. 66053 ==> 0.5200354483877442\n",
            "Loss in iteration no. 66054 ==> 0.5200341030913912\n",
            "Loss in iteration no. 66055 ==> 0.5200327578090164\n",
            "Loss in iteration no. 66056 ==> 0.5200314125406194\n",
            "Loss in iteration no. 66057 ==> 0.5200300672862004\n",
            "Loss in iteration no. 66058 ==> 0.5200287220457588\n",
            "Loss in iteration no. 66059 ==> 0.5200273768192943\n",
            "Loss in iteration no. 66060 ==> 0.5200260316068073\n",
            "Loss in iteration no. 66061 ==> 0.5200246864082969\n",
            "Loss in iteration no. 66062 ==> 0.5200233412237634\n",
            "Loss in iteration no. 66063 ==> 0.5200219960532062\n",
            "Loss in iteration no. 66064 ==> 0.5200206508966254\n",
            "Loss in iteration no. 66065 ==> 0.5200193057540204\n",
            "Loss in iteration no. 66066 ==> 0.5200179606253914\n",
            "Loss in iteration no. 66067 ==> 0.5200166155107379\n",
            "Loss in iteration no. 66068 ==> 0.5200152704100598\n",
            "Loss in iteration no. 66069 ==> 0.5200139253233568\n",
            "Loss in iteration no. 66070 ==> 0.5200125802506289\n",
            "Loss in iteration no. 66071 ==> 0.5200112351918755\n",
            "Loss in iteration no. 66072 ==> 0.5200098901470968\n",
            "Loss in iteration no. 66073 ==> 0.5200085451162924\n",
            "Loss in iteration no. 66074 ==> 0.5200072000994619\n",
            "Loss in iteration no. 66075 ==> 0.5200058550966054\n",
            "Loss in iteration no. 66076 ==> 0.5200045101077226\n",
            "Loss in iteration no. 66077 ==> 0.5200031651328132\n",
            "Loss in iteration no. 66078 ==> 0.5200018201718769\n",
            "Loss in iteration no. 66079 ==> 0.5200004752249137\n",
            "Loss in iteration no. 66080 ==> 0.5199991302919235\n",
            "Loss in iteration no. 66081 ==> 0.5199977853729055\n",
            "Loss in iteration no. 66082 ==> 0.5199964404678601\n",
            "Loss in iteration no. 66083 ==> 0.5199950955767866\n",
            "Loss in iteration no. 66084 ==> 0.5199937506996852\n",
            "Loss in iteration no. 66085 ==> 0.5199924058365555\n",
            "Loss in iteration no. 66086 ==> 0.5199910609873972\n",
            "Loss in iteration no. 66087 ==> 0.5199897161522103\n",
            "Loss in iteration no. 66088 ==> 0.5199883713309944\n",
            "Loss in iteration no. 66089 ==> 0.5199870265237494\n",
            "Loss in iteration no. 66090 ==> 0.5199856817304751\n",
            "Loss in iteration no. 66091 ==> 0.5199843369511711\n",
            "Loss in iteration no. 66092 ==> 0.5199829921858372\n",
            "Loss in iteration no. 66093 ==> 0.5199816474344734\n",
            "Loss in iteration no. 66094 ==> 0.5199803026970794\n",
            "Loss in iteration no. 66095 ==> 0.5199789579736549\n",
            "Loss in iteration no. 66096 ==> 0.5199776132641998\n",
            "Loss in iteration no. 66097 ==> 0.5199762685687138\n",
            "Loss in iteration no. 66098 ==> 0.5199749238871966\n",
            "Loss in iteration no. 66099 ==> 0.5199735792196482\n",
            "Loss in iteration no. 66100 ==> 0.5199722345660681\n",
            "Loss in iteration no. 66101 ==> 0.5199708899264565\n",
            "Loss in iteration no. 66102 ==> 0.5199695453008127\n",
            "Loss in iteration no. 66103 ==> 0.5199682006891371\n",
            "Loss in iteration no. 66104 ==> 0.5199668560914287\n",
            "Loss in iteration no. 66105 ==> 0.5199655115076878\n",
            "Loss in iteration no. 66106 ==> 0.5199641669379141\n",
            "Loss in iteration no. 66107 ==> 0.5199628223821074\n",
            "Loss in iteration no. 66108 ==> 0.5199614778402675\n",
            "Loss in iteration no. 66109 ==> 0.5199601333123941\n",
            "Loss in iteration no. 66110 ==> 0.519958788798487\n",
            "Loss in iteration no. 66111 ==> 0.5199574442985461\n",
            "Loss in iteration no. 66112 ==> 0.519956099812571\n",
            "Loss in iteration no. 66113 ==> 0.5199547553405615\n",
            "Loss in iteration no. 66114 ==> 0.5199534108825173\n",
            "Loss in iteration no. 66115 ==> 0.5199520664384387\n",
            "Loss in iteration no. 66116 ==> 0.5199507220083249\n",
            "Loss in iteration no. 66117 ==> 0.519949377592176\n",
            "Loss in iteration no. 66118 ==> 0.5199480331899917\n",
            "Loss in iteration no. 66119 ==> 0.5199466888017718\n",
            "Loss in iteration no. 66120 ==> 0.5199453444275159\n",
            "Loss in iteration no. 66121 ==> 0.5199440000672241\n",
            "Loss in iteration no. 66122 ==> 0.519942655720896\n",
            "Loss in iteration no. 66123 ==> 0.5199413113885313\n",
            "Loss in iteration no. 66124 ==> 0.5199399670701299\n",
            "Loss in iteration no. 66125 ==> 0.5199386227656918\n",
            "Loss in iteration no. 66126 ==> 0.5199372784752164\n",
            "Loss in iteration no. 66127 ==> 0.5199359341987038\n",
            "Loss in iteration no. 66128 ==> 0.5199345899361535\n",
            "Loss in iteration no. 66129 ==> 0.5199332456875654\n",
            "Loss in iteration no. 66130 ==> 0.5199319014529394\n",
            "Loss in iteration no. 66131 ==> 0.5199305572322752\n",
            "Loss in iteration no. 66132 ==> 0.5199292130255725\n",
            "Loss in iteration no. 66133 ==> 0.519927868832831\n",
            "Loss in iteration no. 66134 ==> 0.519926524654051\n",
            "Loss in iteration no. 66135 ==> 0.5199251804892316\n",
            "Loss in iteration no. 66136 ==> 0.5199238363383731\n",
            "Loss in iteration no. 66137 ==> 0.5199224922014751\n",
            "Loss in iteration no. 66138 ==> 0.5199211480785373\n",
            "Loss in iteration no. 66139 ==> 0.5199198039695597\n",
            "Loss in iteration no. 66140 ==> 0.5199184598745418\n",
            "Loss in iteration no. 66141 ==> 0.5199171157934838\n",
            "Loss in iteration no. 66142 ==> 0.5199157717263848\n",
            "Loss in iteration no. 66143 ==> 0.5199144276732452\n",
            "Loss in iteration no. 66144 ==> 0.5199130836340646\n",
            "Loss in iteration no. 66145 ==> 0.5199117396088428\n",
            "Loss in iteration no. 66146 ==> 0.5199103955975796\n",
            "Loss in iteration no. 66147 ==> 0.5199090516002746\n",
            "Loss in iteration no. 66148 ==> 0.5199077076169278\n",
            "Loss in iteration no. 66149 ==> 0.519906363647539\n",
            "Loss in iteration no. 66150 ==> 0.5199050196921078\n",
            "Loss in iteration no. 66151 ==> 0.519903675750634\n",
            "Loss in iteration no. 66152 ==> 0.5199023318231176\n",
            "Loss in iteration no. 66153 ==> 0.5199009879095582\n",
            "Loss in iteration no. 66154 ==> 0.5198996440099557\n",
            "Loss in iteration no. 66155 ==> 0.5198983001243098\n",
            "Loss in iteration no. 66156 ==> 0.5198969562526202\n",
            "Loss in iteration no. 66157 ==> 0.5198956123948868\n",
            "Loss in iteration no. 66158 ==> 0.5198942685511094\n",
            "Loss in iteration no. 66159 ==> 0.5198929247212879\n",
            "Loss in iteration no. 66160 ==> 0.5198915809054218\n",
            "Loss in iteration no. 66161 ==> 0.5198902371035111\n",
            "Loss in iteration no. 66162 ==> 0.5198888933155553\n",
            "Loss in iteration no. 66163 ==> 0.5198875495415546\n",
            "Loss in iteration no. 66164 ==> 0.5198862057815086\n",
            "Loss in iteration no. 66165 ==> 0.519884862035417\n",
            "Loss in iteration no. 66166 ==> 0.5198835183032795\n",
            "Loss in iteration no. 66167 ==> 0.5198821745850963\n",
            "Loss in iteration no. 66168 ==> 0.5198808308808668\n",
            "Loss in iteration no. 66169 ==> 0.519879487190591\n",
            "Loss in iteration no. 66170 ==> 0.5198781435142684\n",
            "Loss in iteration no. 66171 ==> 0.519876799851899\n",
            "Loss in iteration no. 66172 ==> 0.5198754562034826\n",
            "Loss in iteration no. 66173 ==> 0.5198741125690192\n",
            "Loss in iteration no. 66174 ==> 0.519872768948508\n",
            "Loss in iteration no. 66175 ==> 0.5198714253419491\n",
            "Loss in iteration no. 66176 ==> 0.5198700817493426\n",
            "Loss in iteration no. 66177 ==> 0.5198687381706875\n",
            "Loss in iteration no. 66178 ==> 0.5198673946059845\n",
            "Loss in iteration no. 66179 ==> 0.5198660510552329\n",
            "Loss in iteration no. 66180 ==> 0.5198647075184324\n",
            "Loss in iteration no. 66181 ==> 0.5198633639955829\n",
            "Loss in iteration no. 66182 ==> 0.5198620204866843\n",
            "Loss in iteration no. 66183 ==> 0.5198606769917362\n",
            "Loss in iteration no. 66184 ==> 0.5198593335107385\n",
            "Loss in iteration no. 66185 ==> 0.5198579900436912\n",
            "Loss in iteration no. 66186 ==> 0.5198566465905934\n",
            "Loss in iteration no. 66187 ==> 0.5198553031514458\n",
            "Loss in iteration no. 66188 ==> 0.5198539597262474\n",
            "Loss in iteration no. 66189 ==> 0.5198526163149984\n",
            "Loss in iteration no. 66190 ==> 0.5198512729176983\n",
            "Loss in iteration no. 66191 ==> 0.5198499295343473\n",
            "Loss in iteration no. 66192 ==> 0.5198485861649448\n",
            "Loss in iteration no. 66193 ==> 0.5198472428094909\n",
            "Loss in iteration no. 66194 ==> 0.5198458994679851\n",
            "Loss in iteration no. 66195 ==> 0.5198445561404273\n",
            "Loss in iteration no. 66196 ==> 0.5198432128268174\n",
            "Loss in iteration no. 66197 ==> 0.519841869527155\n",
            "Loss in iteration no. 66198 ==> 0.5198405262414401\n",
            "Loss in iteration no. 66199 ==> 0.5198391829696722\n",
            "Loss in iteration no. 66200 ==> 0.5198378397118512\n",
            "Loss in iteration no. 66201 ==> 0.5198364964679771\n",
            "Loss in iteration no. 66202 ==> 0.5198351532380493\n",
            "Loss in iteration no. 66203 ==> 0.5198338100220679\n",
            "Loss in iteration no. 66204 ==> 0.5198324668200324\n",
            "Loss in iteration no. 66205 ==> 0.5198311236319431\n",
            "Loss in iteration no. 66206 ==> 0.519829780457799\n",
            "Loss in iteration no. 66207 ==> 0.5198284372976008\n",
            "Loss in iteration no. 66208 ==> 0.5198270941513473\n",
            "Loss in iteration no. 66209 ==> 0.5198257510190392\n",
            "Loss in iteration no. 66210 ==> 0.5198244079006757\n",
            "Loss in iteration no. 66211 ==> 0.5198230647962567\n",
            "Loss in iteration no. 66212 ==> 0.5198217217057822\n",
            "Loss in iteration no. 66213 ==> 0.5198203786292519\n",
            "Loss in iteration no. 66214 ==> 0.5198190355666653\n",
            "Loss in iteration no. 66215 ==> 0.5198176925180226\n",
            "Loss in iteration no. 66216 ==> 0.5198163494833232\n",
            "Loss in iteration no. 66217 ==> 0.5198150064625673\n",
            "Loss in iteration no. 66218 ==> 0.5198136634557543\n",
            "Loss in iteration no. 66219 ==> 0.5198123204628842\n",
            "Loss in iteration no. 66220 ==> 0.5198109774839567\n",
            "Loss in iteration no. 66221 ==> 0.5198096345189717\n",
            "Loss in iteration no. 66222 ==> 0.5198082915679287\n",
            "Loss in iteration no. 66223 ==> 0.519806948630828\n",
            "Loss in iteration no. 66224 ==> 0.5198056057076686\n",
            "Loss in iteration no. 66225 ==> 0.519804262798451\n",
            "Loss in iteration no. 66226 ==> 0.5198029199031748\n",
            "Loss in iteration no. 66227 ==> 0.5198015770218398\n",
            "Loss in iteration no. 66228 ==> 0.5198002341544457\n",
            "Loss in iteration no. 66229 ==> 0.5197988913009922\n",
            "Loss in iteration no. 66230 ==> 0.5197975484614791\n",
            "Loss in iteration no. 66231 ==> 0.5197962056359063\n",
            "Loss in iteration no. 66232 ==> 0.5197948628242737\n",
            "Loss in iteration no. 66233 ==> 0.5197935200265809\n",
            "Loss in iteration no. 66234 ==> 0.5197921772428277\n",
            "Loss in iteration no. 66235 ==> 0.5197908344730137\n",
            "Loss in iteration no. 66236 ==> 0.519789491717139\n",
            "Loss in iteration no. 66237 ==> 0.5197881489752033\n",
            "Loss in iteration no. 66238 ==> 0.5197868062472065\n",
            "Loss in iteration no. 66239 ==> 0.519785463533148\n",
            "Loss in iteration no. 66240 ==> 0.5197841208330279\n",
            "Loss in iteration no. 66241 ==> 0.519782778146846\n",
            "Loss in iteration no. 66242 ==> 0.519781435474602\n",
            "Loss in iteration no. 66243 ==> 0.5197800928162958\n",
            "Loss in iteration no. 66244 ==> 0.5197787501719268\n",
            "Loss in iteration no. 66245 ==> 0.5197774075414952\n",
            "Loss in iteration no. 66246 ==> 0.5197760649250006\n",
            "Loss in iteration no. 66247 ==> 0.5197747223224427\n",
            "Loss in iteration no. 66248 ==> 0.5197733797338216\n",
            "Loss in iteration no. 66249 ==> 0.519772037159137\n",
            "Loss in iteration no. 66250 ==> 0.5197706945983883\n",
            "Loss in iteration no. 66251 ==> 0.5197693520515757\n",
            "Loss in iteration no. 66252 ==> 0.5197680095186987\n",
            "Loss in iteration no. 66253 ==> 0.5197666669997574\n",
            "Loss in iteration no. 66254 ==> 0.5197653244947514\n",
            "Loss in iteration no. 66255 ==> 0.5197639820036805\n",
            "Loss in iteration no. 66256 ==> 0.5197626395265444\n",
            "Loss in iteration no. 66257 ==> 0.5197612970633432\n",
            "Loss in iteration no. 66258 ==> 0.5197599546140763\n",
            "Loss in iteration no. 66259 ==> 0.5197586121787438\n",
            "Loss in iteration no. 66260 ==> 0.519757269757345\n",
            "Loss in iteration no. 66261 ==> 0.5197559273498803\n",
            "Loss in iteration no. 66262 ==> 0.5197545849563492\n",
            "Loss in iteration no. 66263 ==> 0.5197532425767513\n",
            "Loss in iteration no. 66264 ==> 0.5197519002110866\n",
            "Loss in iteration no. 66265 ==> 0.519750557859355\n",
            "Loss in iteration no. 66266 ==> 0.5197492155215562\n",
            "Loss in iteration no. 66267 ==> 0.5197478731976897\n",
            "Loss in iteration no. 66268 ==> 0.5197465308877556\n",
            "Loss in iteration no. 66269 ==> 0.5197451885917537\n",
            "Loss in iteration no. 66270 ==> 0.5197438463096835\n",
            "Loss in iteration no. 66271 ==> 0.519742504041545\n",
            "Loss in iteration no. 66272 ==> 0.5197411617873381\n",
            "Loss in iteration no. 66273 ==> 0.5197398195470623\n",
            "Loss in iteration no. 66274 ==> 0.5197384773207175\n",
            "Loss in iteration no. 66275 ==> 0.5197371351083038\n",
            "Loss in iteration no. 66276 ==> 0.5197357929098204\n",
            "Loss in iteration no. 66277 ==> 0.5197344507252675\n",
            "Loss in iteration no. 66278 ==> 0.5197331085546447\n",
            "Loss in iteration no. 66279 ==> 0.5197317663979518\n",
            "Loss in iteration no. 66280 ==> 0.5197304242551888\n",
            "Loss in iteration no. 66281 ==> 0.5197290821263553\n",
            "Loss in iteration no. 66282 ==> 0.519727740011451\n",
            "Loss in iteration no. 66283 ==> 0.5197263979104758\n",
            "Loss in iteration no. 66284 ==> 0.5197250558234294\n",
            "Loss in iteration no. 66285 ==> 0.519723713750312\n",
            "Loss in iteration no. 66286 ==> 0.5197223716911227\n",
            "Loss in iteration no. 66287 ==> 0.5197210296458618\n",
            "Loss in iteration no. 66288 ==> 0.5197196876145289\n",
            "Loss in iteration no. 66289 ==> 0.5197183455971237\n",
            "Loss in iteration no. 66290 ==> 0.519717003593646\n",
            "Loss in iteration no. 66291 ==> 0.519715661604096\n",
            "Loss in iteration no. 66292 ==> 0.5197143196284729\n",
            "Loss in iteration no. 66293 ==> 0.5197129776667768\n",
            "Loss in iteration no. 66294 ==> 0.5197116357190077\n",
            "Loss in iteration no. 66295 ==> 0.5197102937851648\n",
            "Loss in iteration no. 66296 ==> 0.5197089518652481\n",
            "Loss in iteration no. 66297 ==> 0.5197076099592577\n",
            "Loss in iteration no. 66298 ==> 0.5197062680671932\n",
            "Loss in iteration no. 66299 ==> 0.5197049261890543\n",
            "Loss in iteration no. 66300 ==> 0.5197035843248409\n",
            "Loss in iteration no. 66301 ==> 0.5197022424745525\n",
            "Loss in iteration no. 66302 ==> 0.5197009006381894\n",
            "Loss in iteration no. 66303 ==> 0.5196995588157508\n",
            "Loss in iteration no. 66304 ==> 0.5196982170072371\n",
            "Loss in iteration no. 66305 ==> 0.5196968752126476\n",
            "Loss in iteration no. 66306 ==> 0.5196955334319823\n",
            "Loss in iteration no. 66307 ==> 0.5196941916652409\n",
            "Loss in iteration no. 66308 ==> 0.5196928499124231\n",
            "Loss in iteration no. 66309 ==> 0.519691508173529\n",
            "Loss in iteration no. 66310 ==> 0.5196901664485581\n",
            "Loss in iteration no. 66311 ==> 0.5196888247375104\n",
            "Loss in iteration no. 66312 ==> 0.5196874830403856\n",
            "Loss in iteration no. 66313 ==> 0.5196861413571833\n",
            "Loss in iteration no. 66314 ==> 0.5196847996879034\n",
            "Loss in iteration no. 66315 ==> 0.5196834580325458\n",
            "Loss in iteration no. 66316 ==> 0.5196821163911103\n",
            "Loss in iteration no. 66317 ==> 0.5196807747635964\n",
            "Loss in iteration no. 66318 ==> 0.5196794331500042\n",
            "Loss in iteration no. 66319 ==> 0.5196780915503333\n",
            "Loss in iteration no. 66320 ==> 0.5196767499645836\n",
            "Loss in iteration no. 66321 ==> 0.5196754083927548\n",
            "Loss in iteration no. 66322 ==> 0.5196740668348467\n",
            "Loss in iteration no. 66323 ==> 0.5196727252908593\n",
            "Loss in iteration no. 66324 ==> 0.519671383760792\n",
            "Loss in iteration no. 66325 ==> 0.5196700422446447\n",
            "Loss in iteration no. 66326 ==> 0.5196687007424176\n",
            "Loss in iteration no. 66327 ==> 0.5196673592541098\n",
            "Loss in iteration no. 66328 ==> 0.5196660177797215\n",
            "Loss in iteration no. 66329 ==> 0.5196646763192526\n",
            "Loss in iteration no. 66330 ==> 0.5196633348727026\n",
            "Loss in iteration no. 66331 ==> 0.5196619934400714\n",
            "Loss in iteration no. 66332 ==> 0.5196606520213587\n",
            "Loss in iteration no. 66333 ==> 0.5196593106165645\n",
            "Loss in iteration no. 66334 ==> 0.5196579692256883\n",
            "Loss in iteration no. 66335 ==> 0.5196566278487301\n",
            "Loss in iteration no. 66336 ==> 0.5196552864856895\n",
            "Loss in iteration no. 66337 ==> 0.5196539451365665\n",
            "Loss in iteration no. 66338 ==> 0.519652603801361\n",
            "Loss in iteration no. 66339 ==> 0.5196512624800723\n",
            "Loss in iteration no. 66340 ==> 0.5196499211727006\n",
            "Loss in iteration no. 66341 ==> 0.5196485798792454\n",
            "Loss in iteration no. 66342 ==> 0.5196472385997066\n",
            "Loss in iteration no. 66343 ==> 0.5196458973340842\n",
            "Loss in iteration no. 66344 ==> 0.5196445560823777\n",
            "Loss in iteration no. 66345 ==> 0.519643214844587\n",
            "Loss in iteration no. 66346 ==> 0.5196418736207119\n",
            "Loss in iteration no. 66347 ==> 0.5196405324107521\n",
            "Loss in iteration no. 66348 ==> 0.5196391912147076\n",
            "Loss in iteration no. 66349 ==> 0.5196378500325779\n",
            "Loss in iteration no. 66350 ==> 0.519636508864363\n",
            "Loss in iteration no. 66351 ==> 0.5196351677100625\n",
            "Loss in iteration no. 66352 ==> 0.5196338265696764\n",
            "Loss in iteration no. 66353 ==> 0.5196324854432042\n",
            "Loss in iteration no. 66354 ==> 0.5196311443306459\n",
            "Loss in iteration no. 66355 ==> 0.5196298032320014\n",
            "Loss in iteration no. 66356 ==> 0.5196284621472702\n",
            "Loss in iteration no. 66357 ==> 0.5196271210764521\n",
            "Loss in iteration no. 66358 ==> 0.5196257800195473\n",
            "Loss in iteration no. 66359 ==> 0.519624438976555\n",
            "Loss in iteration no. 66360 ==> 0.5196230979474754\n",
            "Loss in iteration no. 66361 ==> 0.5196217569323083\n",
            "Loss in iteration no. 66362 ==> 0.5196204159310531\n",
            "Loss in iteration no. 66363 ==> 0.5196190749437101\n",
            "Loss in iteration no. 66364 ==> 0.5196177339702786\n",
            "Loss in iteration no. 66365 ==> 0.5196163930107586\n",
            "Loss in iteration no. 66366 ==> 0.5196150520651498\n",
            "Loss in iteration no. 66367 ==> 0.5196137111334523\n",
            "Loss in iteration no. 66368 ==> 0.5196123702156656\n",
            "Loss in iteration no. 66369 ==> 0.5196110293117894\n",
            "Loss in iteration no. 66370 ==> 0.5196096884218239\n",
            "Loss in iteration no. 66371 ==> 0.5196083475457682\n",
            "Loss in iteration no. 66372 ==> 0.5196070066836229\n",
            "Loss in iteration no. 66373 ==> 0.5196056658353871\n",
            "Loss in iteration no. 66374 ==> 0.519604325001061\n",
            "Loss in iteration no. 66375 ==> 0.5196029841806444\n",
            "Loss in iteration no. 66376 ==> 0.5196016433741368\n",
            "Loss in iteration no. 66377 ==> 0.5196003025815381\n",
            "Loss in iteration no. 66378 ==> 0.5195989618028483\n",
            "Loss in iteration no. 66379 ==> 0.5195976210380667\n",
            "Loss in iteration no. 66380 ==> 0.5195962802871936\n",
            "Loss in iteration no. 66381 ==> 0.5195949395502285\n",
            "Loss in iteration no. 66382 ==> 0.5195935988271713\n",
            "Loss in iteration no. 66383 ==> 0.5195922581180218\n",
            "Loss in iteration no. 66384 ==> 0.5195909174227795\n",
            "Loss in iteration no. 66385 ==> 0.5195895767414446\n",
            "Loss in iteration no. 66386 ==> 0.5195882360740165\n",
            "Loss in iteration no. 66387 ==> 0.5195868954204955\n",
            "Loss in iteration no. 66388 ==> 0.5195855547808808\n",
            "Loss in iteration no. 66389 ==> 0.5195842141551728\n",
            "Loss in iteration no. 66390 ==> 0.5195828735433706\n",
            "Loss in iteration no. 66391 ==> 0.5195815329454744\n",
            "Loss in iteration no. 66392 ==> 0.519580192361484\n",
            "Loss in iteration no. 66393 ==> 0.5195788517913991\n",
            "Loss in iteration no. 66394 ==> 0.5195775112352193\n",
            "Loss in iteration no. 66395 ==> 0.5195761706929447\n",
            "Loss in iteration no. 66396 ==> 0.5195748301645751\n",
            "Loss in iteration no. 66397 ==> 0.51957348965011\n",
            "Loss in iteration no. 66398 ==> 0.5195721491495494\n",
            "Loss in iteration no. 66399 ==> 0.5195708086628928\n",
            "Loss in iteration no. 66400 ==> 0.5195694681901405\n",
            "Loss in iteration no. 66401 ==> 0.5195681277312918\n",
            "Loss in iteration no. 66402 ==> 0.5195667872863469\n",
            "Loss in iteration no. 66403 ==> 0.5195654468553051\n",
            "Loss in iteration no. 66404 ==> 0.5195641064381665\n",
            "Loss in iteration no. 66405 ==> 0.5195627660349309\n",
            "Loss in iteration no. 66406 ==> 0.519561425645598\n",
            "Loss in iteration no. 66407 ==> 0.5195600852701676\n",
            "Loss in iteration no. 66408 ==> 0.5195587449086396\n",
            "Loss in iteration no. 66409 ==> 0.5195574045610134\n",
            "Loss in iteration no. 66410 ==> 0.5195560642272893\n",
            "Loss in iteration no. 66411 ==> 0.5195547239074667\n",
            "Loss in iteration no. 66412 ==> 0.5195533836015456\n",
            "Loss in iteration no. 66413 ==> 0.5195520433095258\n",
            "Loss in iteration no. 66414 ==> 0.5195507030314069\n",
            "Loss in iteration no. 66415 ==> 0.519549362767189\n",
            "Loss in iteration no. 66416 ==> 0.5195480225168713\n",
            "Loss in iteration no. 66417 ==> 0.5195466822804542\n",
            "Loss in iteration no. 66418 ==> 0.5195453420579371\n",
            "Loss in iteration no. 66419 ==> 0.5195440018493201\n",
            "Loss in iteration no. 66420 ==> 0.5195426616546028\n",
            "Loss in iteration no. 66421 ==> 0.519541321473785\n",
            "Loss in iteration no. 66422 ==> 0.5195399813068663\n",
            "Loss in iteration no. 66423 ==> 0.5195386411538471\n",
            "Loss in iteration no. 66424 ==> 0.5195373010147264\n",
            "Loss in iteration no. 66425 ==> 0.5195359608895044\n",
            "Loss in iteration no. 66426 ==> 0.5195346207781809\n",
            "Loss in iteration no. 66427 ==> 0.5195332806807557\n",
            "Loss in iteration no. 66428 ==> 0.5195319405972283\n",
            "Loss in iteration no. 66429 ==> 0.519530600527599\n",
            "Loss in iteration no. 66430 ==> 0.519529260471867\n",
            "Loss in iteration no. 66431 ==> 0.5195279204300325\n",
            "Loss in iteration no. 66432 ==> 0.5195265804020952\n",
            "Loss in iteration no. 66433 ==> 0.5195252403880547\n",
            "Loss in iteration no. 66434 ==> 0.519523900387911\n",
            "Loss in iteration no. 66435 ==> 0.5195225604016637\n",
            "Loss in iteration no. 66436 ==> 0.5195212204293127\n",
            "Loss in iteration no. 66437 ==> 0.5195198804708578\n",
            "Loss in iteration no. 66438 ==> 0.5195185405262991\n",
            "Loss in iteration no. 66439 ==> 0.5195172005956358\n",
            "Loss in iteration no. 66440 ==> 0.5195158606788678\n",
            "Loss in iteration no. 66441 ==> 0.5195145207759952\n",
            "Loss in iteration no. 66442 ==> 0.5195131808870176\n",
            "Loss in iteration no. 66443 ==> 0.5195118410119347\n",
            "Loss in iteration no. 66444 ==> 0.5195105011507465\n",
            "Loss in iteration no. 66445 ==> 0.5195091613034527\n",
            "Loss in iteration no. 66446 ==> 0.5195078214700529\n",
            "Loss in iteration no. 66447 ==> 0.5195064816505472\n",
            "Loss in iteration no. 66448 ==> 0.5195051418449351\n",
            "Loss in iteration no. 66449 ==> 0.5195038020532167\n",
            "Loss in iteration no. 66450 ==> 0.5195024622753914\n",
            "Loss in iteration no. 66451 ==> 0.5195011225114592\n",
            "Loss in iteration no. 66452 ==> 0.51949978276142\n",
            "Loss in iteration no. 66453 ==> 0.5194984430252735\n",
            "Loss in iteration no. 66454 ==> 0.5194971033030192\n",
            "Loss in iteration no. 66455 ==> 0.5194957635946573\n",
            "Loss in iteration no. 66456 ==> 0.5194944239001874\n",
            "Loss in iteration no. 66457 ==> 0.5194930842196095\n",
            "Loss in iteration no. 66458 ==> 0.5194917445529228\n",
            "Loss in iteration no. 66459 ==> 0.5194904049001277\n",
            "Loss in iteration no. 66460 ==> 0.5194890652612237\n",
            "Loss in iteration no. 66461 ==> 0.5194877256362108\n",
            "Loss in iteration no. 66462 ==> 0.5194863860250886\n",
            "Loss in iteration no. 66463 ==> 0.5194850464278568\n",
            "Loss in iteration no. 66464 ==> 0.5194837068445153\n",
            "Loss in iteration no. 66465 ==> 0.5194823672750639\n",
            "Loss in iteration no. 66466 ==> 0.5194810277195024\n",
            "Loss in iteration no. 66467 ==> 0.5194796881778306\n",
            "Loss in iteration no. 66468 ==> 0.5194783486500484\n",
            "Loss in iteration no. 66469 ==> 0.5194770091361552\n",
            "Loss in iteration no. 66470 ==> 0.5194756696361511\n",
            "Loss in iteration no. 66471 ==> 0.5194743301500359\n",
            "Loss in iteration no. 66472 ==> 0.5194729906778092\n",
            "Loss in iteration no. 66473 ==> 0.5194716512194708\n",
            "Loss in iteration no. 66474 ==> 0.5194703117750208\n",
            "Loss in iteration no. 66475 ==> 0.5194689723444587\n",
            "Loss in iteration no. 66476 ==> 0.5194676329277842\n",
            "Loss in iteration no. 66477 ==> 0.5194662935249973\n",
            "Loss in iteration no. 66478 ==> 0.5194649541360978\n",
            "Loss in iteration no. 66479 ==> 0.5194636147610854\n",
            "Loss in iteration no. 66480 ==> 0.5194622753999597\n",
            "Loss in iteration no. 66481 ==> 0.5194609360527207\n",
            "Loss in iteration no. 66482 ==> 0.5194595967193684\n",
            "Loss in iteration no. 66483 ==> 0.5194582573999021\n",
            "Loss in iteration no. 66484 ==> 0.5194569180943219\n",
            "Loss in iteration no. 66485 ==> 0.5194555788026276\n",
            "Loss in iteration no. 66486 ==> 0.519454239524819\n",
            "Loss in iteration no. 66487 ==> 0.5194529002608956\n",
            "Loss in iteration no. 66488 ==> 0.5194515610108574\n",
            "Loss in iteration no. 66489 ==> 0.5194502217747041\n",
            "Loss in iteration no. 66490 ==> 0.5194488825524357\n",
            "Loss in iteration no. 66491 ==> 0.5194475433440519\n",
            "Loss in iteration no. 66492 ==> 0.5194462041495522\n",
            "Loss in iteration no. 66493 ==> 0.5194448649689366\n",
            "Loss in iteration no. 66494 ==> 0.5194435258022051\n",
            "Loss in iteration no. 66495 ==> 0.5194421866493572\n",
            "Loss in iteration no. 66496 ==> 0.5194408475103927\n",
            "Loss in iteration no. 66497 ==> 0.5194395083853115\n",
            "Loss in iteration no. 66498 ==> 0.5194381692741135\n",
            "Loss in iteration no. 66499 ==> 0.5194368301767981\n",
            "Loss in iteration no. 66500 ==> 0.5194354910933653\n",
            "Loss in iteration no. 66501 ==> 0.519434152023815\n",
            "Loss in iteration no. 66502 ==> 0.519432812968147\n",
            "Loss in iteration no. 66503 ==> 0.5194314739263608\n",
            "Loss in iteration no. 66504 ==> 0.5194301348984565\n",
            "Loss in iteration no. 66505 ==> 0.5194287958844335\n",
            "Loss in iteration no. 66506 ==> 0.5194274568842921\n",
            "Loss in iteration no. 66507 ==> 0.5194261178980317\n",
            "Loss in iteration no. 66508 ==> 0.5194247789256522\n",
            "Loss in iteration no. 66509 ==> 0.5194234399671535\n",
            "Loss in iteration no. 66510 ==> 0.5194221010225352\n",
            "Loss in iteration no. 66511 ==> 0.5194207620917971\n",
            "Loss in iteration no. 66512 ==> 0.5194194231749392\n",
            "Loss in iteration no. 66513 ==> 0.5194180842719609\n",
            "Loss in iteration no. 66514 ==> 0.5194167453828625\n",
            "Loss in iteration no. 66515 ==> 0.5194154065076433\n",
            "Loss in iteration no. 66516 ==> 0.5194140676463034\n",
            "Loss in iteration no. 66517 ==> 0.5194127287988425\n",
            "Loss in iteration no. 66518 ==> 0.5194113899652604\n",
            "Loss in iteration no. 66519 ==> 0.5194100511455566\n",
            "Loss in iteration no. 66520 ==> 0.5194087123397314\n",
            "Loss in iteration no. 66521 ==> 0.5194073735477844\n",
            "Loss in iteration no. 66522 ==> 0.519406034769715\n",
            "Loss in iteration no. 66523 ==> 0.5194046960055236\n",
            "Loss in iteration no. 66524 ==> 0.5194033572552095\n",
            "Loss in iteration no. 66525 ==> 0.5194020185187728\n",
            "Loss in iteration no. 66526 ==> 0.5194006797962131\n",
            "Loss in iteration no. 66527 ==> 0.5193993410875302\n",
            "Loss in iteration no. 66528 ==> 0.519398002392724\n",
            "Loss in iteration no. 66529 ==> 0.5193966637117942\n",
            "Loss in iteration no. 66530 ==> 0.5193953250447407\n",
            "Loss in iteration no. 66531 ==> 0.5193939863915631\n",
            "Loss in iteration no. 66532 ==> 0.5193926477522611\n",
            "Loss in iteration no. 66533 ==> 0.519391309126835\n",
            "Loss in iteration no. 66534 ==> 0.5193899705152841\n",
            "Loss in iteration no. 66535 ==> 0.5193886319176084\n",
            "Loss in iteration no. 66536 ==> 0.5193872933338076\n",
            "Loss in iteration no. 66537 ==> 0.5193859547638815\n",
            "Loss in iteration no. 66538 ==> 0.5193846162078299\n",
            "Loss in iteration no. 66539 ==> 0.5193832776656526\n",
            "Loss in iteration no. 66540 ==> 0.5193819391373493\n",
            "Loss in iteration no. 66541 ==> 0.51938060062292\n",
            "Loss in iteration no. 66542 ==> 0.5193792621223642\n",
            "Loss in iteration no. 66543 ==> 0.5193779236356819\n",
            "Loss in iteration no. 66544 ==> 0.5193765851628729\n",
            "Loss in iteration no. 66545 ==> 0.5193752467039368\n",
            "Loss in iteration no. 66546 ==> 0.5193739082588734\n",
            "Loss in iteration no. 66547 ==> 0.5193725698276828\n",
            "Loss in iteration no. 66548 ==> 0.5193712314103645\n",
            "Loss in iteration no. 66549 ==> 0.5193698930069183\n",
            "Loss in iteration no. 66550 ==> 0.519368554617344\n",
            "Loss in iteration no. 66551 ==> 0.5193672162416415\n",
            "Loss in iteration no. 66552 ==> 0.5193658778798105\n",
            "Loss in iteration no. 66553 ==> 0.5193645395318508\n",
            "Loss in iteration no. 66554 ==> 0.5193632011977621\n",
            "Loss in iteration no. 66555 ==> 0.5193618628775444\n",
            "Loss in iteration no. 66556 ==> 0.5193605245711972\n",
            "Loss in iteration no. 66557 ==> 0.5193591862787205\n",
            "Loss in iteration no. 66558 ==> 0.5193578480001142\n",
            "Loss in iteration no. 66559 ==> 0.5193565097353778\n",
            "Loss in iteration no. 66560 ==> 0.5193551714845113\n",
            "Loss in iteration no. 66561 ==> 0.5193538332475143\n",
            "Loss in iteration no. 66562 ==> 0.5193524950243866\n",
            "Loss in iteration no. 66563 ==> 0.5193511568151282\n",
            "Loss in iteration no. 66564 ==> 0.5193498186197386\n",
            "Loss in iteration no. 66565 ==> 0.5193484804382179\n",
            "Loss in iteration no. 66566 ==> 0.5193471422705658\n",
            "Loss in iteration no. 66567 ==> 0.5193458041167818\n",
            "Loss in iteration no. 66568 ==> 0.519344465976866\n",
            "Loss in iteration no. 66569 ==> 0.519343127850818\n",
            "Loss in iteration no. 66570 ==> 0.5193417897386378\n",
            "Loss in iteration no. 66571 ==> 0.519340451640325\n",
            "Loss in iteration no. 66572 ==> 0.5193391135558795\n",
            "Loss in iteration no. 66573 ==> 0.519337775485301\n",
            "Loss in iteration no. 66574 ==> 0.5193364374285893\n",
            "Loss in iteration no. 66575 ==> 0.5193350993857441\n",
            "Loss in iteration no. 66576 ==> 0.5193337613567656\n",
            "Loss in iteration no. 66577 ==> 0.5193324233416529\n",
            "Loss in iteration no. 66578 ==> 0.5193310853404064\n",
            "Loss in iteration no. 66579 ==> 0.5193297473530256\n",
            "Loss in iteration no. 66580 ==> 0.5193284093795103\n",
            "Loss in iteration no. 66581 ==> 0.5193270714198603\n",
            "Loss in iteration no. 66582 ==> 0.5193257334740756\n",
            "Loss in iteration no. 66583 ==> 0.5193243955421556\n",
            "Loss in iteration no. 66584 ==> 0.5193230576241004\n",
            "Loss in iteration no. 66585 ==> 0.5193217197199097\n",
            "Loss in iteration no. 66586 ==> 0.5193203818295832\n",
            "Loss in iteration no. 66587 ==> 0.5193190439531207\n",
            "Loss in iteration no. 66588 ==> 0.5193177060905222\n",
            "Loss in iteration no. 66589 ==> 0.5193163682417872\n",
            "Loss in iteration no. 66590 ==> 0.5193150304069156\n",
            "Loss in iteration no. 66591 ==> 0.5193136925859072\n",
            "Loss in iteration no. 66592 ==> 0.5193123547787619\n",
            "Loss in iteration no. 66593 ==> 0.5193110169854793\n",
            "Loss in iteration no. 66594 ==> 0.5193096792060591\n",
            "Loss in iteration no. 66595 ==> 0.5193083414405014\n",
            "Loss in iteration no. 66596 ==> 0.5193070036888058\n",
            "Loss in iteration no. 66597 ==> 0.519305665950972\n",
            "Loss in iteration no. 66598 ==> 0.5193043282270001\n",
            "Loss in iteration no. 66599 ==> 0.5193029905168897\n",
            "Loss in iteration no. 66600 ==> 0.5193016528206404\n",
            "Loss in iteration no. 66601 ==> 0.5193003151382523\n",
            "Loss in iteration no. 66602 ==> 0.519298977469725\n",
            "Loss in iteration no. 66603 ==> 0.5192976398150583\n",
            "Loss in iteration no. 66604 ==> 0.5192963021742522\n",
            "Loss in iteration no. 66605 ==> 0.5192949645473061\n",
            "Loss in iteration no. 66606 ==> 0.51929362693422\n",
            "Loss in iteration no. 66607 ==> 0.5192922893349937\n",
            "Loss in iteration no. 66608 ==> 0.5192909517496271\n",
            "Loss in iteration no. 66609 ==> 0.5192896141781198\n",
            "Loss in iteration no. 66610 ==> 0.5192882766204716\n",
            "Loss in iteration no. 66611 ==> 0.5192869390766824\n",
            "Loss in iteration no. 66612 ==> 0.5192856015467519\n",
            "Loss in iteration no. 66613 ==> 0.5192842640306798\n",
            "Loss in iteration no. 66614 ==> 0.5192829265284662\n",
            "Loss in iteration no. 66615 ==> 0.5192815890401105\n",
            "Loss in iteration no. 66616 ==> 0.5192802515656129\n",
            "Loss in iteration no. 66617 ==> 0.5192789141049726\n",
            "Loss in iteration no. 66618 ==> 0.5192775766581901\n",
            "Loss in iteration no. 66619 ==> 0.5192762392252647\n",
            "Loss in iteration no. 66620 ==> 0.5192749018061963\n",
            "Loss in iteration no. 66621 ==> 0.5192735644009845\n",
            "Loss in iteration no. 66622 ==> 0.5192722270096295\n",
            "Loss in iteration no. 66623 ==> 0.519270889632131\n",
            "Loss in iteration no. 66624 ==> 0.5192695522684885\n",
            "Loss in iteration no. 66625 ==> 0.5192682149187019\n",
            "Loss in iteration no. 66626 ==> 0.519266877582771\n",
            "Loss in iteration no. 66627 ==> 0.5192655402606959\n",
            "Loss in iteration no. 66628 ==> 0.5192642029524759\n",
            "Loss in iteration no. 66629 ==> 0.519262865658111\n",
            "Loss in iteration no. 66630 ==> 0.5192615283776011\n",
            "Loss in iteration no. 66631 ==> 0.5192601911109457\n",
            "Loss in iteration no. 66632 ==> 0.5192588538581449\n",
            "Loss in iteration no. 66633 ==> 0.5192575166191984\n",
            "Loss in iteration no. 66634 ==> 0.5192561793941058\n",
            "Loss in iteration no. 66635 ==> 0.519254842182867\n",
            "Loss in iteration no. 66636 ==> 0.5192535049854818\n",
            "Loss in iteration no. 66637 ==> 0.5192521678019502\n",
            "Loss in iteration no. 66638 ==> 0.5192508306322716\n",
            "Loss in iteration no. 66639 ==> 0.519249493476446\n",
            "Loss in iteration no. 66640 ==> 0.5192481563344732\n",
            "Loss in iteration no. 66641 ==> 0.5192468192063528\n",
            "Loss in iteration no. 66642 ==> 0.5192454820920849\n",
            "Loss in iteration no. 66643 ==> 0.5192441449916692\n",
            "Loss in iteration no. 66644 ==> 0.519242807905105\n",
            "Loss in iteration no. 66645 ==> 0.519241470832393\n",
            "Loss in iteration no. 66646 ==> 0.5192401337735322\n",
            "Loss in iteration no. 66647 ==> 0.5192387967285227\n",
            "Loss in iteration no. 66648 ==> 0.5192374596973642\n",
            "Loss in iteration no. 66649 ==> 0.5192361226800567\n",
            "Loss in iteration no. 66650 ==> 0.5192347856765998\n",
            "Loss in iteration no. 66651 ==> 0.5192334486869932\n",
            "Loss in iteration no. 66652 ==> 0.5192321117112367\n",
            "Loss in iteration no. 66653 ==> 0.5192307747493303\n",
            "Loss in iteration no. 66654 ==> 0.5192294378012738\n",
            "Loss in iteration no. 66655 ==> 0.5192281008670668\n",
            "Loss in iteration no. 66656 ==> 0.5192267639467092\n",
            "Loss in iteration no. 66657 ==> 0.5192254270402006\n",
            "Loss in iteration no. 66658 ==> 0.5192240901475411\n",
            "Loss in iteration no. 66659 ==> 0.51922275326873\n",
            "Loss in iteration no. 66660 ==> 0.5192214164037677\n",
            "Loss in iteration no. 66661 ==> 0.5192200795526536\n",
            "Loss in iteration no. 66662 ==> 0.5192187427153875\n",
            "Loss in iteration no. 66663 ==> 0.5192174058919694\n",
            "Loss in iteration no. 66664 ==> 0.5192160690823987\n",
            "Loss in iteration no. 66665 ==> 0.5192147322866757\n",
            "Loss in iteration no. 66666 ==> 0.5192133955047998\n",
            "Loss in iteration no. 66667 ==> 0.5192120587367709\n",
            "Loss in iteration no. 66668 ==> 0.5192107219825888\n",
            "Loss in iteration no. 66669 ==> 0.5192093852422534\n",
            "Loss in iteration no. 66670 ==> 0.5192080485157643\n",
            "Loss in iteration no. 66671 ==> 0.5192067118031213\n",
            "Loss in iteration no. 66672 ==> 0.5192053751043243\n",
            "Loss in iteration no. 66673 ==> 0.519204038419373\n",
            "Loss in iteration no. 66674 ==> 0.5192027017482672\n",
            "Loss in iteration no. 66675 ==> 0.5192013650910068\n",
            "Loss in iteration no. 66676 ==> 0.5192000284475915\n",
            "Loss in iteration no. 66677 ==> 0.519198691818021\n",
            "Loss in iteration no. 66678 ==> 0.5191973552022952\n",
            "Loss in iteration no. 66679 ==> 0.5191960186004139\n",
            "Loss in iteration no. 66680 ==> 0.5191946820123768\n",
            "Loss in iteration no. 66681 ==> 0.5191933454381836\n",
            "Loss in iteration no. 66682 ==> 0.5191920088778345\n",
            "Loss in iteration no. 66683 ==> 0.5191906723313287\n",
            "Loss in iteration no. 66684 ==> 0.5191893357986664\n",
            "Loss in iteration no. 66685 ==> 0.5191879992798475\n",
            "Loss in iteration no. 66686 ==> 0.5191866627748714\n",
            "Loss in iteration no. 66687 ==> 0.5191853262837379\n",
            "Loss in iteration no. 66688 ==> 0.5191839898064471\n",
            "Loss in iteration no. 66689 ==> 0.5191826533429986\n",
            "Loss in iteration no. 66690 ==> 0.5191813168933923\n",
            "Loss in iteration no. 66691 ==> 0.5191799804576278\n",
            "Loss in iteration no. 66692 ==> 0.519178644035705\n",
            "Loss in iteration no. 66693 ==> 0.5191773076276238\n",
            "Loss in iteration no. 66694 ==> 0.5191759712333838\n",
            "Loss in iteration no. 66695 ==> 0.5191746348529849\n",
            "Loss in iteration no. 66696 ==> 0.5191732984864267\n",
            "Loss in iteration no. 66697 ==> 0.5191719621337091\n",
            "Loss in iteration no. 66698 ==> 0.5191706257948321\n",
            "Loss in iteration no. 66699 ==> 0.5191692894697952\n",
            "Loss in iteration no. 66700 ==> 0.5191679531585983\n",
            "Loss in iteration no. 66701 ==> 0.5191666168612412\n",
            "Loss in iteration no. 66702 ==> 0.5191652805777237\n",
            "Loss in iteration no. 66703 ==> 0.5191639443080454\n",
            "Loss in iteration no. 66704 ==> 0.5191626080522065\n",
            "Loss in iteration no. 66705 ==> 0.5191612718102062\n",
            "Loss in iteration no. 66706 ==> 0.5191599355820449\n",
            "Loss in iteration no. 66707 ==> 0.5191585993677219\n",
            "Loss in iteration no. 66708 ==> 0.5191572631672373\n",
            "Loss in iteration no. 66709 ==> 0.5191559269805908\n",
            "Loss in iteration no. 66710 ==> 0.5191545908077821\n",
            "Loss in iteration no. 66711 ==> 0.5191532546488111\n",
            "Loss in iteration no. 66712 ==> 0.5191519185036776\n",
            "Loss in iteration no. 66713 ==> 0.519150582372381\n",
            "Loss in iteration no. 66714 ==> 0.5191492462549218\n",
            "Loss in iteration no. 66715 ==> 0.5191479101512992\n",
            "Loss in iteration no. 66716 ==> 0.5191465740615132\n",
            "Loss in iteration no. 66717 ==> 0.5191452379855636\n",
            "Loss in iteration no. 66718 ==> 0.5191439019234504\n",
            "Loss in iteration no. 66719 ==> 0.5191425658751729\n",
            "Loss in iteration no. 66720 ==> 0.519141229840731\n",
            "Loss in iteration no. 66721 ==> 0.5191398938201248\n",
            "Loss in iteration no. 66722 ==> 0.5191385578133539\n",
            "Loss in iteration no. 66723 ==> 0.5191372218204182\n",
            "Loss in iteration no. 66724 ==> 0.5191358858413174\n",
            "Loss in iteration no. 66725 ==> 0.519134549876051\n",
            "Loss in iteration no. 66726 ==> 0.5191332139246194\n",
            "Loss in iteration no. 66727 ==> 0.5191318779870219\n",
            "Loss in iteration no. 66728 ==> 0.5191305420632584\n",
            "Loss in iteration no. 66729 ==> 0.5191292061533288\n",
            "Loss in iteration no. 66730 ==> 0.5191278702572328\n",
            "Loss in iteration no. 66731 ==> 0.5191265343749701\n",
            "Loss in iteration no. 66732 ==> 0.5191251985065407\n",
            "Loss in iteration no. 66733 ==> 0.5191238626519444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loss in iteration no. 91791 ==> 0.48950576046300603\n",
            "Loss in iteration no. 91792 ==> 0.48950471527285294\n",
            "Loss in iteration no. 91793 ==> 0.4895036700924154\n",
            "Loss in iteration no. 91794 ==> 0.48950262492169333\n",
            "Loss in iteration no. 91795 ==> 0.4895015797606864\n",
            "Loss in iteration no. 91796 ==> 0.4895005346093945\n",
            "Loss in iteration no. 91797 ==> 0.48949948946781774\n",
            "Loss in iteration no. 91798 ==> 0.4894984443359559\n",
            "Loss in iteration no. 91799 ==> 0.4894973992138086\n",
            "Loss in iteration no. 91800 ==> 0.48949635410137593\n",
            "Loss in iteration no. 91801 ==> 0.4894953089986578\n",
            "Loss in iteration no. 91802 ==> 0.48949426390565404\n",
            "Loss in iteration no. 91803 ==> 0.48949321882236446\n",
            "Loss in iteration no. 91804 ==> 0.4894921737487889\n",
            "Loss in iteration no. 91805 ==> 0.4894911286849275\n",
            "Loss in iteration no. 91806 ==> 0.4894900836307797\n",
            "Loss in iteration no. 91807 ==> 0.48948903858634585\n",
            "Loss in iteration no. 91808 ==> 0.48948799355162537\n",
            "Loss in iteration no. 91809 ==> 0.4894869485266185\n",
            "Loss in iteration no. 91810 ==> 0.4894859035113249\n",
            "Loss in iteration no. 91811 ==> 0.4894848585057446\n",
            "Loss in iteration no. 91812 ==> 0.4894838135098772\n",
            "Loss in iteration no. 91813 ==> 0.4894827685237228\n",
            "Loss in iteration no. 91814 ==> 0.4894817235472813\n",
            "Loss in iteration no. 91815 ==> 0.4894806785805524\n",
            "Loss in iteration no. 91816 ==> 0.48947963362353614\n",
            "Loss in iteration no. 91817 ==> 0.48947858867623234\n",
            "Loss in iteration no. 91818 ==> 0.4894775437386409\n",
            "Loss in iteration no. 91819 ==> 0.48947649881076144\n",
            "Loss in iteration no. 91820 ==> 0.4894754538925942\n",
            "Loss in iteration no. 91821 ==> 0.4894744089841388\n",
            "Loss in iteration no. 91822 ==> 0.4894733640853952\n",
            "Loss in iteration no. 91823 ==> 0.4894723191963633\n",
            "Loss in iteration no. 91824 ==> 0.489471274317043\n",
            "Loss in iteration no. 91825 ==> 0.48947022944743407\n",
            "Loss in iteration no. 91826 ==> 0.48946918458753647\n",
            "Loss in iteration no. 91827 ==> 0.48946813973735\n",
            "Loss in iteration no. 91828 ==> 0.4894670948968746\n",
            "Loss in iteration no. 91829 ==> 0.4894660500661101\n",
            "Loss in iteration no. 91830 ==> 0.4894650052450563\n",
            "Loss in iteration no. 91831 ==> 0.4894639604337133\n",
            "Loss in iteration no. 91832 ==> 0.48946291563208083\n",
            "Loss in iteration no. 91833 ==> 0.48946187084015863\n",
            "Loss in iteration no. 91834 ==> 0.4894608260579468\n",
            "Loss in iteration no. 91835 ==> 0.4894597812854451\n",
            "Loss in iteration no. 91836 ==> 0.48945873652265337\n",
            "Loss in iteration no. 91837 ==> 0.4894576917695716\n",
            "Loss in iteration no. 91838 ==> 0.48945664702619956\n",
            "Loss in iteration no. 91839 ==> 0.48945560229253715\n",
            "Loss in iteration no. 91840 ==> 0.4894545575685842\n",
            "Loss in iteration no. 91841 ==> 0.4894535128543408\n",
            "Loss in iteration no. 91842 ==> 0.48945246814980653\n",
            "Loss in iteration no. 91843 ==> 0.48945142345498144\n",
            "Loss in iteration no. 91844 ==> 0.48945037876986525\n",
            "Loss in iteration no. 91845 ==> 0.4894493340944581\n",
            "Loss in iteration no. 91846 ==> 0.4894482894287597\n",
            "Loss in iteration no. 91847 ==> 0.48944724477276985\n",
            "Loss in iteration no. 91848 ==> 0.4894462001264885\n",
            "Loss in iteration no. 91849 ==> 0.4894451554899155\n",
            "Loss in iteration no. 91850 ==> 0.4894441108630506\n",
            "Loss in iteration no. 91851 ==> 0.489443066245894\n",
            "Loss in iteration no. 91852 ==> 0.48944202163844536\n",
            "Loss in iteration no. 91853 ==> 0.48944097704070455\n",
            "Loss in iteration no. 91854 ==> 0.48943993245267153\n",
            "Loss in iteration no. 91855 ==> 0.4894388878743461\n",
            "Loss in iteration no. 91856 ==> 0.4894378433057281\n",
            "Loss in iteration no. 91857 ==> 0.4894367987468174\n",
            "Loss in iteration no. 91858 ==> 0.48943575419761404\n",
            "Loss in iteration no. 91859 ==> 0.4894347096581177\n",
            "Loss in iteration no. 91860 ==> 0.4894336651283283\n",
            "Loss in iteration no. 91861 ==> 0.4894326206082458\n",
            "Loss in iteration no. 91862 ==> 0.4894315760978699\n",
            "Loss in iteration no. 91863 ==> 0.4894305315972008\n",
            "Loss in iteration no. 91864 ==> 0.48942948710623796\n",
            "Loss in iteration no. 91865 ==> 0.4894284426249816\n",
            "Loss in iteration no. 91866 ==> 0.4894273981534314\n",
            "Loss in iteration no. 91867 ==> 0.48942635369158727\n",
            "Loss in iteration no. 91868 ==> 0.4894253092394491\n",
            "Loss in iteration no. 91869 ==> 0.4894242647970166\n",
            "Loss in iteration no. 91870 ==> 0.48942322036429003\n",
            "Loss in iteration no. 91871 ==> 0.48942217594126897\n",
            "Loss in iteration no. 91872 ==> 0.4894211315279532\n",
            "Loss in iteration no. 91873 ==> 0.4894200871243429\n",
            "Loss in iteration no. 91874 ==> 0.4894190427304377\n",
            "Loss in iteration no. 91875 ==> 0.4894179983462376\n",
            "Loss in iteration no. 91876 ==> 0.4894169539717425\n",
            "Loss in iteration no. 91877 ==> 0.489415909606952\n",
            "Loss in iteration no. 91878 ==> 0.48941486525186645\n",
            "Loss in iteration no. 91879 ==> 0.4894138209064853\n",
            "Loss in iteration no. 91880 ==> 0.4894127765708085\n",
            "Loss in iteration no. 91881 ==> 0.4894117322448362\n",
            "Loss in iteration no. 91882 ==> 0.48941068792856784\n",
            "Loss in iteration no. 91883 ==> 0.4894096436220036\n",
            "Loss in iteration no. 91884 ==> 0.48940859932514336\n",
            "Loss in iteration no. 91885 ==> 0.48940755503798694\n",
            "Loss in iteration no. 91886 ==> 0.48940651076053404\n",
            "Loss in iteration no. 91887 ==> 0.4894054664927847\n",
            "Loss in iteration no. 91888 ==> 0.4894044222347388\n",
            "Loss in iteration no. 91889 ==> 0.48940337798639616\n",
            "Loss in iteration no. 91890 ==> 0.4894023337477568\n",
            "Loss in iteration no. 91891 ==> 0.48940128951882034\n",
            "Loss in iteration no. 91892 ==> 0.4894002452995868\n",
            "Loss in iteration no. 91893 ==> 0.48939920109005597\n",
            "Loss in iteration no. 91894 ==> 0.4893981568902279\n",
            "Loss in iteration no. 91895 ==> 0.4893971127001023\n",
            "Loss in iteration no. 91896 ==> 0.48939606851967904\n",
            "Loss in iteration no. 91897 ==> 0.4893950243489581\n",
            "Loss in iteration no. 91898 ==> 0.48939398018793934\n",
            "Loss in iteration no. 91899 ==> 0.48939293603662254\n",
            "Loss in iteration no. 91900 ==> 0.4893918918950075\n",
            "Loss in iteration no. 91901 ==> 0.48939084776309444\n",
            "Loss in iteration no. 91902 ==> 0.4893898036408829\n",
            "Loss in iteration no. 91903 ==> 0.48938875952837285\n",
            "Loss in iteration no. 91904 ==> 0.48938771542556414\n",
            "Loss in iteration no. 91905 ==> 0.48938667133245667\n",
            "Loss in iteration no. 91906 ==> 0.4893856272490505\n",
            "Loss in iteration no. 91907 ==> 0.4893845831753451\n",
            "Loss in iteration no. 91908 ==> 0.48938353911134064\n",
            "Loss in iteration no. 91909 ==> 0.48938249505703696\n",
            "Loss in iteration no. 91910 ==> 0.48938145101243385\n",
            "Loss in iteration no. 91911 ==> 0.4893804069775312\n",
            "Loss in iteration no. 91912 ==> 0.489379362952329\n",
            "Loss in iteration no. 91913 ==> 0.48937831893682693\n",
            "Loss in iteration no. 91914 ==> 0.48937727493102495\n",
            "Loss in iteration no. 91915 ==> 0.48937623093492316\n",
            "Loss in iteration no. 91916 ==> 0.489375186948521\n",
            "Loss in iteration no. 91917 ==> 0.4893741429718186\n",
            "Loss in iteration no. 91918 ==> 0.48937309900481574\n",
            "Loss in iteration no. 91919 ==> 0.48937205504751236\n",
            "Loss in iteration no. 91920 ==> 0.48937101109990844\n",
            "Loss in iteration no. 91921 ==> 0.48936996716200365\n",
            "Loss in iteration no. 91922 ==> 0.489368923233798\n",
            "Loss in iteration no. 91923 ==> 0.48936787931529124\n",
            "Loss in iteration no. 91924 ==> 0.48936683540648335\n",
            "Loss in iteration no. 91925 ==> 0.4893657915073742\n",
            "Loss in iteration no. 91926 ==> 0.48936474761796367\n",
            "Loss in iteration no. 91927 ==> 0.48936370373825144\n",
            "Loss in iteration no. 91928 ==> 0.4893626598682376\n",
            "Loss in iteration no. 91929 ==> 0.48936161600792205\n",
            "Loss in iteration no. 91930 ==> 0.48936057215730444\n",
            "Loss in iteration no. 91931 ==> 0.48935952831638474\n",
            "Loss in iteration no. 91932 ==> 0.48935848448516295\n",
            "Loss in iteration no. 91933 ==> 0.48935744066363884\n",
            "Loss in iteration no. 91934 ==> 0.48935639685181226\n",
            "Loss in iteration no. 91935 ==> 0.4893553530496832\n",
            "Loss in iteration no. 91936 ==> 0.48935430925725126\n",
            "Loss in iteration no. 91937 ==> 0.4893532654745167\n",
            "Loss in iteration no. 91938 ==> 0.48935222170147924\n",
            "Loss in iteration no. 91939 ==> 0.4893511779381385\n",
            "Loss in iteration no. 91940 ==> 0.48935013418449463\n",
            "Loss in iteration no. 91941 ==> 0.4893490904405474\n",
            "Loss in iteration no. 91942 ==> 0.4893480467062968\n",
            "Loss in iteration no. 91943 ==> 0.4893470029817425\n",
            "Loss in iteration no. 91944 ==> 0.48934595926688457\n",
            "Loss in iteration no. 91945 ==> 0.4893449155617229\n",
            "Loss in iteration no. 91946 ==> 0.48934387186625705\n",
            "Loss in iteration no. 91947 ==> 0.4893428281804873\n",
            "Loss in iteration no. 91948 ==> 0.48934178450441324\n",
            "Loss in iteration no. 91949 ==> 0.48934074083803497\n",
            "Loss in iteration no. 91950 ==> 0.48933969718135195\n",
            "Loss in iteration no. 91951 ==> 0.4893386535343645\n",
            "Loss in iteration no. 91952 ==> 0.4893376098970723\n",
            "Loss in iteration no. 91953 ==> 0.48933656626947536\n",
            "Loss in iteration no. 91954 ==> 0.4893355226515734\n",
            "Loss in iteration no. 91955 ==> 0.4893344790433663\n",
            "Loss in iteration no. 91956 ==> 0.4893334354448539\n",
            "Loss in iteration no. 91957 ==> 0.4893323918560362\n",
            "Loss in iteration no. 91958 ==> 0.48933134827691305\n",
            "Loss in iteration no. 91959 ==> 0.48933030470748423\n",
            "Loss in iteration no. 91960 ==> 0.4893292611477496\n",
            "Loss in iteration no. 91961 ==> 0.4893282175977092\n",
            "Loss in iteration no. 91962 ==> 0.48932717405736276\n",
            "Loss in iteration no. 91963 ==> 0.48932613052671026\n",
            "Loss in iteration no. 91964 ==> 0.48932508700575156\n",
            "Loss in iteration no. 91965 ==> 0.4893240434944865\n",
            "Loss in iteration no. 91966 ==> 0.48932299999291473\n",
            "Loss in iteration no. 91967 ==> 0.4893219565010364\n",
            "Loss in iteration no. 91968 ==> 0.4893209130188514\n",
            "Loss in iteration no. 91969 ==> 0.48931986954635953\n",
            "Loss in iteration no. 91970 ==> 0.4893188260835606\n",
            "Loss in iteration no. 91971 ==> 0.4893177826304544\n",
            "Loss in iteration no. 91972 ==> 0.48931673918704116\n",
            "Loss in iteration no. 91973 ==> 0.48931569575332046\n",
            "Loss in iteration no. 91974 ==> 0.4893146523292922\n",
            "Loss in iteration no. 91975 ==> 0.48931360891495634\n",
            "Loss in iteration no. 91976 ==> 0.4893125655103127\n",
            "Loss in iteration no. 91977 ==> 0.48931152211536116\n",
            "Loss in iteration no. 91978 ==> 0.48931047873010153\n",
            "Loss in iteration no. 91979 ==> 0.48930943535453375\n",
            "Loss in iteration no. 91980 ==> 0.48930839198865783\n",
            "Loss in iteration no. 91981 ==> 0.48930734863247327\n",
            "Loss in iteration no. 91982 ==> 0.48930630528598046\n",
            "Loss in iteration no. 91983 ==> 0.4893052619491788\n",
            "Loss in iteration no. 91984 ==> 0.4893042186220683\n",
            "Loss in iteration no. 91985 ==> 0.4893031753046491\n",
            "Loss in iteration no. 91986 ==> 0.4893021319969208\n",
            "Loss in iteration no. 91987 ==> 0.4893010886988832\n",
            "Loss in iteration no. 91988 ==> 0.48930004541053634\n",
            "Loss in iteration no. 91989 ==> 0.48929900213188016\n",
            "Loss in iteration no. 91990 ==> 0.4892979588629144\n",
            "Loss in iteration no. 91991 ==> 0.48929691560363897\n",
            "Loss in iteration no. 91992 ==> 0.48929587235405364\n",
            "Loss in iteration no. 91993 ==> 0.4892948291141584\n",
            "Loss in iteration no. 91994 ==> 0.48929378588395306\n",
            "Loss in iteration no. 91995 ==> 0.4892927426634378\n",
            "Loss in iteration no. 91996 ==> 0.48929169945261203\n",
            "Loss in iteration no. 91997 ==> 0.4892906562514759\n",
            "Loss in iteration no. 91998 ==> 0.4892896130600291\n",
            "Loss in iteration no. 91999 ==> 0.48928856987827174\n",
            "Loss in iteration no. 92000 ==> 0.4892875267062034\n",
            "Loss in iteration no. 92001 ==> 0.48928648354382415\n",
            "Loss in iteration no. 92002 ==> 0.489285440391134\n",
            "Loss in iteration no. 92003 ==> 0.4892843972481325\n",
            "Loss in iteration no. 92004 ==> 0.4892833541148197\n",
            "Loss in iteration no. 92005 ==> 0.48928231099119557\n",
            "Loss in iteration no. 92006 ==> 0.4892812678772597\n",
            "Loss in iteration no. 92007 ==> 0.4892802247730121\n",
            "Loss in iteration no. 92008 ==> 0.4892791816784529\n",
            "Loss in iteration no. 92009 ==> 0.4892781385935814\n",
            "Loss in iteration no. 92010 ==> 0.48927709551839804\n",
            "Loss in iteration no. 92011 ==> 0.48927605245290245\n",
            "Loss in iteration no. 92012 ==> 0.48927500939709456\n",
            "Loss in iteration no. 92013 ==> 0.48927396635097403\n",
            "Loss in iteration no. 92014 ==> 0.4892729233145411\n",
            "Loss in iteration no. 92015 ==> 0.48927188028779534\n",
            "Loss in iteration no. 92016 ==> 0.4892708372707368\n",
            "Loss in iteration no. 92017 ==> 0.48926979426336525\n",
            "Loss in iteration no. 92018 ==> 0.4892687512656806\n",
            "Loss in iteration no. 92019 ==> 0.4892677082776826\n",
            "Loss in iteration no. 92020 ==> 0.48926666529937146\n",
            "Loss in iteration no. 92021 ==> 0.4892656223307468\n",
            "Loss in iteration no. 92022 ==> 0.48926457937180845\n",
            "Loss in iteration no. 92023 ==> 0.48926353642255643\n",
            "Loss in iteration no. 92024 ==> 0.4892624934829905\n",
            "Loss in iteration no. 92025 ==> 0.48926145055311054\n",
            "Loss in iteration no. 92026 ==> 0.48926040763291656\n",
            "Loss in iteration no. 92027 ==> 0.4892593647224083\n",
            "Loss in iteration no. 92028 ==> 0.48925832182158563\n",
            "Loss in iteration no. 92029 ==> 0.48925727893044846\n",
            "Loss in iteration no. 92030 ==> 0.4892562360489967\n",
            "Loss in iteration no. 92031 ==> 0.4892551931772302\n",
            "Loss in iteration no. 92032 ==> 0.4892541503151489\n",
            "Loss in iteration no. 92033 ==> 0.4892531074627524\n",
            "Loss in iteration no. 92034 ==> 0.489252064620041\n",
            "Loss in iteration no. 92035 ==> 0.48925102178701413\n",
            "Loss in iteration no. 92036 ==> 0.48924997896367206\n",
            "Loss in iteration no. 92037 ==> 0.4892489361500144\n",
            "Loss in iteration no. 92038 ==> 0.48924789334604113\n",
            "Loss in iteration no. 92039 ==> 0.48924685055175193\n",
            "Loss in iteration no. 92040 ==> 0.4892458077671471\n",
            "Loss in iteration no. 92041 ==> 0.4892447649922261\n",
            "Loss in iteration no. 92042 ==> 0.48924372222698903\n",
            "Loss in iteration no. 92043 ==> 0.4892426794714355\n",
            "Loss in iteration no. 92044 ==> 0.48924163672556575\n",
            "Loss in iteration no. 92045 ==> 0.4892405939893794\n",
            "Loss in iteration no. 92046 ==> 0.4892395512628765\n",
            "Loss in iteration no. 92047 ==> 0.48923850854605677\n",
            "Loss in iteration no. 92048 ==> 0.48923746583892014\n",
            "Loss in iteration no. 92049 ==> 0.48923642314146637\n",
            "Loss in iteration no. 92050 ==> 0.48923538045369563\n",
            "Loss in iteration no. 92051 ==> 0.4892343377756075\n",
            "Loss in iteration no. 92052 ==> 0.48923329510720204\n",
            "Loss in iteration no. 92053 ==> 0.48923225244847884\n",
            "Loss in iteration no. 92054 ==> 0.4892312097994382\n",
            "Loss in iteration no. 92055 ==> 0.48923016716007967\n",
            "Loss in iteration no. 92056 ==> 0.4892291245304032\n",
            "Loss in iteration no. 92057 ==> 0.48922808191040873\n",
            "Loss in iteration no. 92058 ==> 0.48922703930009614\n",
            "Loss in iteration no. 92059 ==> 0.4892259966994651\n",
            "Loss in iteration no. 92060 ==> 0.4892249541085157\n",
            "Loss in iteration no. 92061 ==> 0.4892239115272478\n",
            "Loss in iteration no. 92062 ==> 0.4892228689556611\n",
            "Loss in iteration no. 92063 ==> 0.4892218263937557\n",
            "Loss in iteration no. 92064 ==> 0.4892207838415313\n",
            "Loss in iteration no. 92065 ==> 0.48921974129898793\n",
            "Loss in iteration no. 92066 ==> 0.48921869876612534\n",
            "Loss in iteration no. 92067 ==> 0.4892176562429434\n",
            "Loss in iteration no. 92068 ==> 0.4892166137294422\n",
            "Loss in iteration no. 92069 ==> 0.4892155712256211\n",
            "Loss in iteration no. 92070 ==> 0.4892145287314805\n",
            "Loss in iteration no. 92071 ==> 0.4892134862470201\n",
            "Loss in iteration no. 92072 ==> 0.48921244377223977\n",
            "Loss in iteration no. 92073 ==> 0.4892114013071393\n",
            "Loss in iteration no. 92074 ==> 0.4892103588517186\n",
            "Loss in iteration no. 92075 ==> 0.48920931640597765\n",
            "Loss in iteration no. 92076 ==> 0.4892082739699162\n",
            "Loss in iteration no. 92077 ==> 0.4892072315435342\n",
            "Loss in iteration no. 92078 ==> 0.48920618912683145\n",
            "Loss in iteration no. 92079 ==> 0.48920514671980797\n",
            "Loss in iteration no. 92080 ==> 0.48920410432246336\n",
            "Loss in iteration no. 92081 ==> 0.4892030619347979\n",
            "Loss in iteration no. 92082 ==> 0.48920201955681103\n",
            "Loss in iteration no. 92083 ==> 0.4892009771885028\n",
            "Loss in iteration no. 92084 ==> 0.48919993482987334\n",
            "Loss in iteration no. 92085 ==> 0.489198892480922\n",
            "Loss in iteration no. 92086 ==> 0.4891978501416491\n",
            "Loss in iteration no. 92087 ==> 0.4891968078120543\n",
            "Loss in iteration no. 92088 ==> 0.4891957654921376\n",
            "Loss in iteration no. 92089 ==> 0.48919472318189866\n",
            "Loss in iteration no. 92090 ==> 0.48919368088133763\n",
            "Loss in iteration no. 92091 ==> 0.48919263859045414\n",
            "Loss in iteration no. 92092 ==> 0.4891915963092483\n",
            "Loss in iteration no. 92093 ==> 0.4891905540377198\n",
            "Loss in iteration no. 92094 ==> 0.48918951177586845\n",
            "Loss in iteration no. 92095 ==> 0.4891884695236944\n",
            "Loss in iteration no. 92096 ==> 0.4891874272811973\n",
            "Loss in iteration no. 92097 ==> 0.48918638504837697\n",
            "Loss in iteration no. 92098 ==> 0.48918534282523357\n",
            "Loss in iteration no. 92099 ==> 0.4891843006117667\n",
            "Loss in iteration no. 92100 ==> 0.48918325840797644\n",
            "Loss in iteration no. 92101 ==> 0.4891822162138626\n",
            "Loss in iteration no. 92102 ==> 0.4891811740294248\n",
            "Loss in iteration no. 92103 ==> 0.48918013185466336\n",
            "Loss in iteration no. 92104 ==> 0.48917908968957774\n",
            "Loss in iteration no. 92105 ==> 0.48917804753416805\n",
            "Loss in iteration no. 92106 ==> 0.48917700538843417\n",
            "Loss in iteration no. 92107 ==> 0.48917596325237583\n",
            "Loss in iteration no. 92108 ==> 0.489174921125993\n",
            "Loss in iteration no. 92109 ==> 0.4891738790092855\n",
            "Loss in iteration no. 92110 ==> 0.48917283690225327\n",
            "Loss in iteration no. 92111 ==> 0.4891717948048962\n",
            "Loss in iteration no. 92112 ==> 0.489170752717214\n",
            "Loss in iteration no. 92113 ==> 0.48916971063920683\n",
            "Loss in iteration no. 92114 ==> 0.4891686685708742\n",
            "Loss in iteration no. 92115 ==> 0.48916762651221635\n",
            "Loss in iteration no. 92116 ==> 0.48916658446323297\n",
            "Loss in iteration no. 92117 ==> 0.48916554242392385\n",
            "Loss in iteration no. 92118 ==> 0.48916450039428894\n",
            "Loss in iteration no. 92119 ==> 0.4891634583743283\n",
            "Loss in iteration no. 92120 ==> 0.4891624163640414\n",
            "Loss in iteration no. 92121 ==> 0.48916137436342855\n",
            "Loss in iteration no. 92122 ==> 0.4891603323724893\n",
            "Loss in iteration no. 92123 ==> 0.48915929039122363\n",
            "Loss in iteration no. 92124 ==> 0.4891582484196316\n",
            "Loss in iteration no. 92125 ==> 0.48915720645771277\n",
            "Loss in iteration no. 92126 ==> 0.4891561645054672\n",
            "Loss in iteration no. 92127 ==> 0.4891551225628946\n",
            "Loss in iteration no. 92128 ==> 0.48915408062999516\n",
            "Loss in iteration no. 92129 ==> 0.4891530387067684\n",
            "Loss in iteration no. 92130 ==> 0.48915199679321436\n",
            "Loss in iteration no. 92131 ==> 0.48915095488933297\n",
            "Loss in iteration no. 92132 ==> 0.48914991299512395\n",
            "Loss in iteration no. 92133 ==> 0.4891488711105873\n",
            "Loss in iteration no. 92134 ==> 0.4891478292357228\n",
            "Loss in iteration no. 92135 ==> 0.4891467873705305\n",
            "Loss in iteration no. 92136 ==> 0.48914574551501017\n",
            "Loss in iteration no. 92137 ==> 0.4891447036691616\n",
            "Loss in iteration no. 92138 ==> 0.4891436618329847\n",
            "Loss in iteration no. 92139 ==> 0.4891426200064793\n",
            "Loss in iteration no. 92140 ==> 0.48914157818964543\n",
            "Loss in iteration no. 92141 ==> 0.4891405363824829\n",
            "Loss in iteration no. 92142 ==> 0.4891394945849915\n",
            "Loss in iteration no. 92143 ==> 0.48913845279717105\n",
            "Loss in iteration no. 92144 ==> 0.48913741101902175\n",
            "Loss in iteration no. 92145 ==> 0.48913636925054316\n",
            "Loss in iteration no. 92146 ==> 0.4891353274917352\n",
            "Loss in iteration no. 92147 ==> 0.489134285742598\n",
            "Loss in iteration no. 92148 ==> 0.4891332440031312\n",
            "Loss in iteration no. 92149 ==> 0.48913220227333454\n",
            "Loss in iteration no. 92150 ==> 0.489131160553208\n",
            "Loss in iteration no. 92151 ==> 0.4891301188427517\n",
            "Loss in iteration no. 92152 ==> 0.48912907714196524\n",
            "Loss in iteration no. 92153 ==> 0.48912803545084865\n",
            "Loss in iteration no. 92154 ==> 0.48912699376940155\n",
            "Loss in iteration no. 92155 ==> 0.48912595209762416\n",
            "Loss in iteration no. 92156 ==> 0.48912491043551615\n",
            "Loss in iteration no. 92157 ==> 0.48912386878307745\n",
            "Loss in iteration no. 92158 ==> 0.48912282714030786\n",
            "Loss in iteration no. 92159 ==> 0.48912178550720736\n",
            "Loss in iteration no. 92160 ==> 0.4891207438837757\n",
            "Loss in iteration no. 92161 ==> 0.48911970227001283\n",
            "Loss in iteration no. 92162 ==> 0.4891186606659187\n",
            "Loss in iteration no. 92163 ==> 0.4891176190714931\n",
            "Loss in iteration no. 92164 ==> 0.4891165774867358\n",
            "Loss in iteration no. 92165 ==> 0.4891155359116469\n",
            "Loss in iteration no. 92166 ==> 0.4891144943462261\n",
            "Loss in iteration no. 92167 ==> 0.48911345279047336\n",
            "Loss in iteration no. 92168 ==> 0.4891124112443884\n",
            "Loss in iteration no. 92169 ==> 0.4891113697079714\n",
            "Loss in iteration no. 92170 ==> 0.4891103281812219\n",
            "Loss in iteration no. 92171 ==> 0.48910928666413994\n",
            "Loss in iteration no. 92172 ==> 0.48910824515672535\n",
            "Loss in iteration no. 92173 ==> 0.48910720365897814\n",
            "Loss in iteration no. 92174 ==> 0.489106162170898\n",
            "Loss in iteration no. 92175 ==> 0.4891051206924848\n",
            "Loss in iteration no. 92176 ==> 0.48910407922373866\n",
            "Loss in iteration no. 92177 ==> 0.4891030377646592\n",
            "Loss in iteration no. 92178 ==> 0.4891019963152464\n",
            "Loss in iteration no. 92179 ==> 0.4891009548755\n",
            "Loss in iteration no. 92180 ==> 0.4890999134454201\n",
            "Loss in iteration no. 92181 ==> 0.48909887202500635\n",
            "Loss in iteration no. 92182 ==> 0.48909783061425877\n",
            "Loss in iteration no. 92183 ==> 0.48909678921317723\n",
            "Loss in iteration no. 92184 ==> 0.48909574782176163\n",
            "Loss in iteration no. 92185 ==> 0.48909470644001163\n",
            "Loss in iteration no. 92186 ==> 0.4890936650679273\n",
            "Loss in iteration no. 92187 ==> 0.4890926237055085\n",
            "Loss in iteration no. 92188 ==> 0.48909158235275507\n",
            "Loss in iteration no. 92189 ==> 0.48909054100966687\n",
            "Loss in iteration no. 92190 ==> 0.4890894996762437\n",
            "Loss in iteration no. 92191 ==> 0.48908845835248566\n",
            "Loss in iteration no. 92192 ==> 0.4890874170383925\n",
            "Loss in iteration no. 92193 ==> 0.4890863757339639\n",
            "Loss in iteration no. 92194 ==> 0.48908533443920005\n",
            "Loss in iteration no. 92195 ==> 0.48908429315410074\n",
            "Loss in iteration no. 92196 ==> 0.4890832518786657\n",
            "Loss in iteration no. 92197 ==> 0.4890822106128948\n",
            "Loss in iteration no. 92198 ==> 0.4890811693567882\n",
            "Loss in iteration no. 92199 ==> 0.48908012811034546\n",
            "Loss in iteration no. 92200 ==> 0.48907908687356655\n",
            "Loss in iteration no. 92201 ==> 0.48907804564645146\n",
            "Loss in iteration no. 92202 ==> 0.4890770044289998\n",
            "Loss in iteration no. 92203 ==> 0.4890759632212118\n",
            "Loss in iteration no. 92204 ==> 0.4890749220230871\n",
            "Loss in iteration no. 92205 ==> 0.4890738808346255\n",
            "Loss in iteration no. 92206 ==> 0.4890728396558271\n",
            "Loss in iteration no. 92207 ==> 0.48907179848669174\n",
            "Loss in iteration no. 92208 ==> 0.48907075732721916\n",
            "Loss in iteration no. 92209 ==> 0.48906971617740924\n",
            "Loss in iteration no. 92210 ==> 0.4890686750372621\n",
            "Loss in iteration no. 92211 ==> 0.48906763390677727\n",
            "Loss in iteration no. 92212 ==> 0.48906659278595466\n",
            "Loss in iteration no. 92213 ==> 0.48906555167479443\n",
            "Loss in iteration no. 92214 ==> 0.48906451057329625\n",
            "Loss in iteration no. 92215 ==> 0.48906346948146\n",
            "Loss in iteration no. 92216 ==> 0.4890624283992856\n",
            "Loss in iteration no. 92217 ==> 0.4890613873267729\n",
            "Loss in iteration no. 92218 ==> 0.4890603462639217\n",
            "Loss in iteration no. 92219 ==> 0.48905930521073204\n",
            "Loss in iteration no. 92220 ==> 0.4890582641672036\n",
            "Loss in iteration no. 92221 ==> 0.4890572231333365\n",
            "Loss in iteration no. 92222 ==> 0.48905618210913043\n",
            "Loss in iteration no. 92223 ==> 0.4890551410945853\n",
            "Loss in iteration no. 92224 ==> 0.489054100089701\n",
            "Loss in iteration no. 92225 ==> 0.4890530590944774\n",
            "Loss in iteration no. 92226 ==> 0.48905201810891424\n",
            "Loss in iteration no. 92227 ==> 0.48905097713301166\n",
            "Loss in iteration no. 92228 ==> 0.4890499361667693\n",
            "Loss in iteration no. 92229 ==> 0.4890488952101873\n",
            "Loss in iteration no. 92230 ==> 0.4890478542632652\n",
            "Loss in iteration no. 92231 ==> 0.489046813326003\n",
            "Loss in iteration no. 92232 ==> 0.48904577239840075\n",
            "Loss in iteration no. 92233 ==> 0.48904473148045824\n",
            "Loss in iteration no. 92234 ==> 0.48904369057217506\n",
            "Loss in iteration no. 92235 ==> 0.4890426496735513\n",
            "Loss in iteration no. 92236 ==> 0.4890416087845871\n",
            "Loss in iteration no. 92237 ==> 0.48904056790528194\n",
            "Loss in iteration no. 92238 ==> 0.48903952703563575\n",
            "Loss in iteration no. 92239 ==> 0.4890384861756486\n",
            "Loss in iteration no. 92240 ==> 0.48903744532532023\n",
            "Loss in iteration no. 92241 ==> 0.4890364044846505\n",
            "Loss in iteration no. 92242 ==> 0.48903536365363937\n",
            "Loss in iteration no. 92243 ==> 0.48903432283228654\n",
            "Loss in iteration no. 92244 ==> 0.4890332820205921\n",
            "Loss in iteration no. 92245 ==> 0.4890322412185558\n",
            "Loss in iteration no. 92246 ==> 0.4890312004261776\n",
            "Loss in iteration no. 92247 ==> 0.4890301596434572\n",
            "Loss in iteration no. 92248 ==> 0.4890291188703947\n",
            "Loss in iteration no. 92249 ==> 0.4890280781069898\n",
            "Loss in iteration no. 92250 ==> 0.4890270373532424\n",
            "Loss in iteration no. 92251 ==> 0.48902599660915247\n",
            "Loss in iteration no. 92252 ==> 0.48902495587471984\n",
            "Loss in iteration no. 92253 ==> 0.48902391514994425\n",
            "Loss in iteration no. 92254 ==> 0.48902287443482567\n",
            "Loss in iteration no. 92255 ==> 0.48902183372936414\n",
            "Loss in iteration no. 92256 ==> 0.48902079303355944\n",
            "Loss in iteration no. 92257 ==> 0.48901975234741124\n",
            "Loss in iteration no. 92258 ==> 0.4890187116709196\n",
            "Loss in iteration no. 92259 ==> 0.48901767100408433\n",
            "Loss in iteration no. 92260 ==> 0.4890166303469053\n",
            "Loss in iteration no. 92261 ==> 0.4890155896993825\n",
            "Loss in iteration no. 92262 ==> 0.4890145490615157\n",
            "Loss in iteration no. 92263 ==> 0.4890135084333048\n",
            "Loss in iteration no. 92264 ==> 0.4890124678147498\n",
            "Loss in iteration no. 92265 ==> 0.4890114272058502\n",
            "Loss in iteration no. 92266 ==> 0.48901038660660623\n",
            "Loss in iteration no. 92267 ==> 0.4890093460170176\n",
            "Loss in iteration no. 92268 ==> 0.4890083054370844\n",
            "Loss in iteration no. 92269 ==> 0.4890072648668061\n",
            "Loss in iteration no. 92270 ==> 0.4890062243061829\n",
            "Loss in iteration no. 92271 ==> 0.48900518375521457\n",
            "Loss in iteration no. 92272 ==> 0.489004143213901\n",
            "Loss in iteration no. 92273 ==> 0.4890031026822421\n",
            "Loss in iteration no. 92274 ==> 0.48900206216023767\n",
            "Loss in iteration no. 92275 ==> 0.4890010216478876\n",
            "Loss in iteration no. 92276 ==> 0.48899998114519183\n",
            "Loss in iteration no. 92277 ==> 0.48899894065215016\n",
            "Loss in iteration no. 92278 ==> 0.48899790016876254\n",
            "Loss in iteration no. 92279 ==> 0.4889968596950287\n",
            "Loss in iteration no. 92280 ==> 0.48899581923094865\n",
            "Loss in iteration no. 92281 ==> 0.48899477877652225\n",
            "Loss in iteration no. 92282 ==> 0.4889937383317492\n",
            "Loss in iteration no. 92283 ==> 0.4889926978966297\n",
            "Loss in iteration no. 92284 ==> 0.48899165747116335\n",
            "Loss in iteration no. 92285 ==> 0.4889906170553502\n",
            "Loss in iteration no. 92286 ==> 0.48898957664918996\n",
            "Loss in iteration no. 92287 ==> 0.4889885362526826\n",
            "Loss in iteration no. 92288 ==> 0.48898749586582796\n",
            "Loss in iteration no. 92289 ==> 0.48898645548862596\n",
            "Loss in iteration no. 92290 ==> 0.48898541512107646\n",
            "Loss in iteration no. 92291 ==> 0.48898437476317924\n",
            "Loss in iteration no. 92292 ==> 0.4889833344149343\n",
            "Loss in iteration no. 92293 ==> 0.4889822940763415\n",
            "Loss in iteration no. 92294 ==> 0.48898125374740053\n",
            "Loss in iteration no. 92295 ==> 0.4889802134281116\n",
            "Loss in iteration no. 92296 ==> 0.4889791731184743\n",
            "Loss in iteration no. 92297 ==> 0.4889781328184886\n",
            "Loss in iteration no. 92298 ==> 0.4889770925281544\n",
            "Loss in iteration no. 92299 ==> 0.4889760522474716\n",
            "Loss in iteration no. 92300 ==> 0.4889750119764399\n",
            "Loss in iteration no. 92301 ==> 0.48897397171505946\n",
            "Loss in iteration no. 92302 ==> 0.4889729314633299\n",
            "Loss in iteration no. 92303 ==> 0.4889718912212511\n",
            "Loss in iteration no. 92304 ==> 0.4889708509888232\n",
            "Loss in iteration no. 92305 ==> 0.48896981076604573\n",
            "Loss in iteration no. 92306 ==> 0.4889687705529187\n",
            "Loss in iteration no. 92307 ==> 0.48896773034944213\n",
            "Loss in iteration no. 92308 ==> 0.4889666901556157\n",
            "Loss in iteration no. 92309 ==> 0.4889656499714394\n",
            "Loss in iteration no. 92310 ==> 0.4889646097969131\n",
            "Loss in iteration no. 92311 ==> 0.4889635696320365\n",
            "Loss in iteration no. 92312 ==> 0.4889625294768098\n",
            "Loss in iteration no. 92313 ==> 0.48896148933123246\n",
            "Loss in iteration no. 92314 ==> 0.48896044919530474\n",
            "Loss in iteration no. 92315 ==> 0.4889594090690263\n",
            "Loss in iteration no. 92316 ==> 0.48895836895239697\n",
            "Loss in iteration no. 92317 ==> 0.48895732884541687\n",
            "Loss in iteration no. 92318 ==> 0.48895628874808555\n",
            "Loss in iteration no. 92319 ==> 0.4889552486604033\n",
            "Loss in iteration no. 92320 ==> 0.4889542085823695\n",
            "Loss in iteration no. 92321 ==> 0.48895316851398435\n",
            "Loss in iteration no. 92322 ==> 0.48895212845524766\n",
            "Loss in iteration no. 92323 ==> 0.48895108840615925\n",
            "Loss in iteration no. 92324 ==> 0.4889500483667192\n",
            "Loss in iteration no. 92325 ==> 0.48894900833692706\n",
            "Loss in iteration no. 92326 ==> 0.48894796831678294\n",
            "Loss in iteration no. 92327 ==> 0.4889469283062866\n",
            "Loss in iteration no. 92328 ==> 0.488945888305438\n",
            "Loss in iteration no. 92329 ==> 0.4889448483142369\n",
            "Loss in iteration no. 92330 ==> 0.48894380833268325\n",
            "Loss in iteration no. 92331 ==> 0.48894276836077694\n",
            "Loss in iteration no. 92332 ==> 0.48894172839851774\n",
            "Loss in iteration no. 92333 ==> 0.48894068844590566\n",
            "Loss in iteration no. 92334 ==> 0.4889396485029405\n",
            "Loss in iteration no. 92335 ==> 0.488938608569622\n",
            "Loss in iteration no. 92336 ==> 0.4889375686459504\n",
            "Loss in iteration no. 92337 ==> 0.4889365287319253\n",
            "Loss in iteration no. 92338 ==> 0.48893548882754667\n",
            "Loss in iteration no. 92339 ==> 0.48893444893281424\n",
            "Loss in iteration no. 92340 ==> 0.488933409047728\n",
            "Loss in iteration no. 92341 ==> 0.4889323691722879\n",
            "Loss in iteration no. 92342 ==> 0.4889313293064936\n",
            "Loss in iteration no. 92343 ==> 0.4889302894503451\n",
            "Loss in iteration no. 92344 ==> 0.4889292496038423\n",
            "Loss in iteration no. 92345 ==> 0.48892820976698514\n",
            "Loss in iteration no. 92346 ==> 0.48892716993977337\n",
            "Loss in iteration no. 92347 ==> 0.48892613012220676\n",
            "Loss in iteration no. 92348 ==> 0.4889250903142855\n",
            "Loss in iteration no. 92349 ==> 0.4889240505160092\n",
            "Loss in iteration no. 92350 ==> 0.48892301072737776\n",
            "Loss in iteration no. 92351 ==> 0.4889219709483911\n",
            "Loss in iteration no. 92352 ==> 0.4889209311790492\n",
            "Loss in iteration no. 92353 ==> 0.4889198914193518\n",
            "Loss in iteration no. 92354 ==> 0.48891885166929877\n",
            "Loss in iteration no. 92355 ==> 0.4889178119288901\n",
            "Loss in iteration no. 92356 ==> 0.4889167721981256\n",
            "Loss in iteration no. 92357 ==> 0.4889157324770049\n",
            "Loss in iteration no. 92358 ==> 0.4889146927655284\n",
            "Loss in iteration no. 92359 ==> 0.48891365306369555\n",
            "Loss in iteration no. 92360 ==> 0.48891261337150643\n",
            "Loss in iteration no. 92361 ==> 0.48891157368896077\n",
            "Loss in iteration no. 92362 ==> 0.4889105340160584\n",
            "Loss in iteration no. 92363 ==> 0.48890949435279957\n",
            "Loss in iteration no. 92364 ==> 0.48890845469918365\n",
            "Loss in iteration no. 92365 ==> 0.4889074150552109\n",
            "Loss in iteration no. 92366 ==> 0.488906375420881\n",
            "Loss in iteration no. 92367 ==> 0.4889053357961939\n",
            "Loss in iteration no. 92368 ==> 0.48890429618114944\n",
            "Loss in iteration no. 92369 ==> 0.4889032565757474\n",
            "Loss in iteration no. 92370 ==> 0.48890221697998787\n",
            "Loss in iteration no. 92371 ==> 0.4889011773938705\n",
            "Loss in iteration no. 92372 ==> 0.4889001378173954\n",
            "Loss in iteration no. 92373 ==> 0.4888990982505622\n",
            "Loss in iteration no. 92374 ==> 0.48889805869337094\n",
            "Loss in iteration no. 92375 ==> 0.48889701914582145\n",
            "Loss in iteration no. 92376 ==> 0.48889597960791353\n",
            "Loss in iteration no. 92377 ==> 0.4888949400796472\n",
            "Loss in iteration no. 92378 ==> 0.4888939005610223\n",
            "Loss in iteration no. 92379 ==> 0.48889286105203855\n",
            "Loss in iteration no. 92380 ==> 0.4888918215526959\n",
            "Loss in iteration no. 92381 ==> 0.4888907820629944\n",
            "Loss in iteration no. 92382 ==> 0.48888974258293366\n",
            "Loss in iteration no. 92383 ==> 0.48888870311251376\n",
            "Loss in iteration no. 92384 ==> 0.4888876636517345\n",
            "Loss in iteration no. 92385 ==> 0.4888866242005957\n",
            "Loss in iteration no. 92386 ==> 0.4888855847590973\n",
            "Loss in iteration no. 92387 ==> 0.4888845453272392\n",
            "Loss in iteration no. 92388 ==> 0.48888350590502117\n",
            "Loss in iteration no. 92389 ==> 0.48888246649244305\n",
            "Loss in iteration no. 92390 ==> 0.4888814270895048\n",
            "Loss in iteration no. 92391 ==> 0.4888803876962065\n",
            "Loss in iteration no. 92392 ==> 0.48887934831254765\n",
            "Loss in iteration no. 92393 ==> 0.48887830893852835\n",
            "Loss in iteration no. 92394 ==> 0.48887726957414845\n",
            "Loss in iteration no. 92395 ==> 0.4888762302194078\n",
            "Loss in iteration no. 92396 ==> 0.4888751908743062\n",
            "Loss in iteration no. 92397 ==> 0.48887415153884356\n",
            "Loss in iteration no. 92398 ==> 0.4888731122130199\n",
            "Loss in iteration no. 92399 ==> 0.4888720728968349\n",
            "Loss in iteration no. 92400 ==> 0.48887103359028844\n",
            "Loss in iteration no. 92401 ==> 0.4888699942933806\n",
            "Loss in iteration no. 92402 ==> 0.48886895500611105\n",
            "Loss in iteration no. 92403 ==> 0.4888679157284798\n",
            "Loss in iteration no. 92404 ==> 0.48886687646048665\n",
            "Loss in iteration no. 92405 ==> 0.4888658372021315\n",
            "Loss in iteration no. 92406 ==> 0.48886479795341414\n",
            "Loss in iteration no. 92407 ==> 0.48886375871433446\n",
            "Loss in iteration no. 92408 ==> 0.4888627194848924\n",
            "Loss in iteration no. 92409 ==> 0.4888616802650879\n",
            "Loss in iteration no. 92410 ==> 0.48886064105492083\n",
            "Loss in iteration no. 92411 ==> 0.4888596018543908\n",
            "Loss in iteration no. 92412 ==> 0.48885856266349803\n",
            "Loss in iteration no. 92413 ==> 0.48885752348224226\n",
            "Loss in iteration no. 92414 ==> 0.4888564843106232\n",
            "Loss in iteration no. 92415 ==> 0.48885544514864093\n",
            "Loss in iteration no. 92416 ==> 0.4888544059962952\n",
            "Loss in iteration no. 92417 ==> 0.488853366853586\n",
            "Loss in iteration no. 92418 ==> 0.4888523277205132\n",
            "Loss in iteration no. 92419 ==> 0.4888512885970765\n",
            "Loss in iteration no. 92420 ==> 0.48885024948327593\n",
            "Loss in iteration no. 92421 ==> 0.48884921037911144\n",
            "Loss in iteration no. 92422 ==> 0.4888481712845826\n",
            "Loss in iteration no. 92423 ==> 0.48884713219968967\n",
            "Loss in iteration no. 92424 ==> 0.48884609312443217\n",
            "Loss in iteration no. 92425 ==> 0.4888450540588102\n",
            "Loss in iteration no. 92426 ==> 0.48884401500282354\n",
            "Loss in iteration no. 92427 ==> 0.4888429759564722\n",
            "Loss in iteration no. 92428 ==> 0.4888419369197558\n",
            "Loss in iteration no. 92429 ==> 0.4888408978926745\n",
            "Loss in iteration no. 92430 ==> 0.4888398588752279\n",
            "Loss in iteration no. 92431 ==> 0.48883881986741606\n",
            "Loss in iteration no. 92432 ==> 0.4888377808692389\n",
            "Loss in iteration no. 92433 ==> 0.48883674188069604\n",
            "Loss in iteration no. 92434 ==> 0.4888357029017876\n",
            "Loss in iteration no. 92435 ==> 0.4888346639325133\n",
            "Loss in iteration no. 92436 ==> 0.48883362497287314\n",
            "Loss in iteration no. 92437 ==> 0.48883258602286694\n",
            "Loss in iteration no. 92438 ==> 0.48883154708249443\n",
            "Loss in iteration no. 92439 ==> 0.4888305081517559\n",
            "Loss in iteration no. 92440 ==> 0.48882946923065074\n",
            "Loss in iteration no. 92441 ==> 0.488828430319179\n",
            "Loss in iteration no. 92442 ==> 0.4888273914173408\n",
            "Loss in iteration no. 92443 ==> 0.4888263525251356\n",
            "Loss in iteration no. 92444 ==> 0.4888253136425636\n",
            "Loss in iteration no. 92445 ==> 0.4888242747696245\n",
            "Loss in iteration no. 92446 ==> 0.4888232359063182\n",
            "Loss in iteration no. 92447 ==> 0.48882219705264457\n",
            "Loss in iteration no. 92448 ==> 0.4888211582086035\n",
            "Loss in iteration no. 92449 ==> 0.488820119374195\n",
            "Loss in iteration no. 92450 ==> 0.48881908054941875\n",
            "Loss in iteration no. 92451 ==> 0.4888180417342746\n",
            "Loss in iteration no. 92452 ==> 0.4888170029287626\n",
            "Loss in iteration no. 92453 ==> 0.4888159641328826\n",
            "Loss in iteration no. 92454 ==> 0.48881492534663434\n",
            "Loss in iteration no. 92455 ==> 0.4888138865700177\n",
            "Loss in iteration no. 92456 ==> 0.48881284780303275\n",
            "Loss in iteration no. 92457 ==> 0.4888118090456791\n",
            "Loss in iteration no. 92458 ==> 0.48881077029795694\n",
            "Loss in iteration no. 92459 ==> 0.4888097315598659\n",
            "Loss in iteration no. 92460 ==> 0.48880869283140577\n",
            "Loss in iteration no. 92461 ==> 0.48880765411257676\n",
            "Loss in iteration no. 92462 ==> 0.4888066154033785\n",
            "Loss in iteration no. 92463 ==> 0.48880557670381075\n",
            "Loss in iteration no. 92464 ==> 0.48880453801387375\n",
            "Loss in iteration no. 92465 ==> 0.48880349933356726\n",
            "Loss in iteration no. 92466 ==> 0.48880246066289085\n",
            "Loss in iteration no. 92467 ==> 0.48880142200184473\n",
            "Loss in iteration no. 92468 ==> 0.48880038335042864\n",
            "Loss in iteration no. 92469 ==> 0.48879934470864256\n",
            "Loss in iteration no. 92470 ==> 0.4887983060764862\n",
            "Loss in iteration no. 92471 ==> 0.4887972674539595\n",
            "Loss in iteration no. 92472 ==> 0.4887962288410624\n",
            "Loss in iteration no. 92473 ==> 0.4887951902377947\n",
            "Loss in iteration no. 92474 ==> 0.48879415164415624\n",
            "Loss in iteration no. 92475 ==> 0.48879311306014706\n",
            "Loss in iteration no. 92476 ==> 0.4887920744857669\n",
            "Loss in iteration no. 92477 ==> 0.48879103592101564\n",
            "Loss in iteration no. 92478 ==> 0.48878999736589324\n",
            "Loss in iteration no. 92479 ==> 0.48878895882039936\n",
            "Loss in iteration no. 92480 ==> 0.48878792028453405\n",
            "Loss in iteration no. 92481 ==> 0.48878688175829715\n",
            "Loss in iteration no. 92482 ==> 0.48878584324168867\n",
            "Loss in iteration no. 92483 ==> 0.48878480473470837\n",
            "Loss in iteration no. 92484 ==> 0.4887837662373559\n",
            "Loss in iteration no. 92485 ==> 0.4887827277496315\n",
            "Loss in iteration no. 92486 ==> 0.4887816892715349\n",
            "Loss in iteration no. 92487 ==> 0.488780650803066\n",
            "Loss in iteration no. 92488 ==> 0.4887796123442244\n",
            "Loss in iteration no. 92489 ==> 0.4887785738950104\n",
            "Loss in iteration no. 92490 ==> 0.4887775354554238\n",
            "Loss in iteration no. 92491 ==> 0.48877649702546405\n",
            "Loss in iteration no. 92492 ==> 0.48877545860513155\n",
            "Loss in iteration no. 92493 ==> 0.4887744201944259\n",
            "Loss in iteration no. 92494 ==> 0.488773381793347\n",
            "Loss in iteration no. 92495 ==> 0.4887723434018948\n",
            "Loss in iteration no. 92496 ==> 0.48877130502006916\n",
            "Loss in iteration no. 92497 ==> 0.4887702666478699\n",
            "Loss in iteration no. 92498 ==> 0.4887692282852968\n",
            "Loss in iteration no. 92499 ==> 0.48876818993235\n",
            "Loss in iteration no. 92500 ==> 0.4887671515890293\n",
            "Loss in iteration no. 92501 ==> 0.48876611325533426\n",
            "Loss in iteration no. 92502 ==> 0.48876507493126514\n",
            "Loss in iteration no. 92503 ==> 0.4887640366168216\n",
            "Loss in iteration no. 92504 ==> 0.4887629983120037\n",
            "Loss in iteration no. 92505 ==> 0.48876196001681105\n",
            "Loss in iteration no. 92506 ==> 0.48876092173124375\n",
            "Loss in iteration no. 92507 ==> 0.4887598834553017\n",
            "Loss in iteration no. 92508 ==> 0.48875884518898455\n",
            "Loss in iteration no. 92509 ==> 0.48875780693229226\n",
            "Loss in iteration no. 92510 ==> 0.48875676868522483\n",
            "Loss in iteration no. 92511 ==> 0.488755730447782\n",
            "Loss in iteration no. 92512 ==> 0.48875469221996365\n",
            "Loss in iteration no. 92513 ==> 0.48875365400176984\n",
            "Loss in iteration no. 92514 ==> 0.4887526157932003\n",
            "Loss in iteration no. 92515 ==> 0.4887515775942547\n",
            "Loss in iteration no. 92516 ==> 0.4887505394049332\n",
            "Loss in iteration no. 92517 ==> 0.48874950122523564\n",
            "Loss in iteration no. 92518 ==> 0.48874846305516173\n",
            "Loss in iteration no. 92519 ==> 0.4887474248947117\n",
            "Loss in iteration no. 92520 ==> 0.4887463867438849\n",
            "Loss in iteration no. 92521 ==> 0.48874534860268154\n",
            "Loss in iteration no. 92522 ==> 0.4887443104711016\n",
            "Loss in iteration no. 92523 ==> 0.48874327234914466\n",
            "Loss in iteration no. 92524 ==> 0.48874223423681085\n",
            "Loss in iteration no. 92525 ==> 0.4887411961340998\n",
            "Loss in iteration no. 92526 ==> 0.4887401580410115\n",
            "Loss in iteration no. 92527 ==> 0.4887391199575459\n",
            "Loss in iteration no. 92528 ==> 0.4887380818837029\n",
            "Loss in iteration no. 92529 ==> 0.4887370438194821\n",
            "Loss in iteration no. 92530 ==> 0.48873600576488363\n",
            "Loss in iteration no. 92531 ==> 0.4887349677199073\n",
            "Loss in iteration no. 92532 ==> 0.488733929684553\n",
            "Loss in iteration no. 92533 ==> 0.48873289165882056\n",
            "Loss in iteration no. 92534 ==> 0.4887318536427099\n",
            "Loss in iteration no. 92535 ==> 0.4887308156362208\n",
            "Loss in iteration no. 92536 ==> 0.48872977763935316\n",
            "Loss in iteration no. 92537 ==> 0.48872873965210706\n",
            "Loss in iteration no. 92538 ==> 0.48872770167448204\n",
            "Loss in iteration no. 92539 ==> 0.48872666370647827\n",
            "Loss in iteration no. 92540 ==> 0.48872562574809547\n",
            "Loss in iteration no. 92541 ==> 0.4887245877993336\n",
            "Loss in iteration no. 92542 ==> 0.4887235498601923\n",
            "Loss in iteration no. 92543 ==> 0.4887225119306718\n",
            "Loss in iteration no. 92544 ==> 0.4887214740107717\n",
            "Loss in iteration no. 92545 ==> 0.488720436100492\n",
            "Loss in iteration no. 92546 ==> 0.48871939819983257\n",
            "Loss in iteration no. 92547 ==> 0.4887183603087932\n",
            "Loss in iteration no. 92548 ==> 0.4887173224273737\n",
            "Loss in iteration no. 92549 ==> 0.48871628455557437\n",
            "Loss in iteration no. 92550 ==> 0.48871524669339456\n",
            "Loss in iteration no. 92551 ==> 0.48871420884083444\n",
            "Loss in iteration no. 92552 ==> 0.48871317099789385\n",
            "Loss in iteration no. 92553 ==> 0.48871213316457257\n",
            "Loss in iteration no. 92554 ==> 0.48871109534087065\n",
            "Loss in iteration no. 92555 ==> 0.48871005752678764\n",
            "Loss in iteration no. 92556 ==> 0.4887090197223237\n",
            "Loss in iteration no. 92557 ==> 0.4887079819274787\n",
            "Loss in iteration no. 92558 ==> 0.48870694414225235\n",
            "Loss in iteration no. 92559 ==> 0.4887059063666446\n",
            "Loss in iteration no. 92560 ==> 0.4887048686006553\n",
            "Loss in iteration no. 92561 ==> 0.48870383084428454\n",
            "Loss in iteration no. 92562 ==> 0.48870279309753184\n",
            "Loss in iteration no. 92563 ==> 0.4887017553603974\n",
            "Loss in iteration no. 92564 ==> 0.48870071763288087\n",
            "Loss in iteration no. 92565 ==> 0.4886996799149822\n",
            "Loss in iteration no. 92566 ==> 0.4886986422067013\n",
            "Loss in iteration no. 92567 ==> 0.488697604508038\n",
            "Loss in iteration no. 92568 ==> 0.4886965668189921\n",
            "Loss in iteration no. 92569 ==> 0.4886955291395635\n",
            "Loss in iteration no. 92570 ==> 0.48869449146975225\n",
            "Loss in iteration no. 92571 ==> 0.48869345380955814\n",
            "Loss in iteration no. 92572 ==> 0.4886924161589809\n",
            "Loss in iteration no. 92573 ==> 0.4886913785180205\n",
            "Loss in iteration no. 92574 ==> 0.48869034088667707\n",
            "Loss in iteration no. 92575 ==> 0.4886893032649501\n",
            "Loss in iteration no. 92576 ==> 0.4886882656528395\n",
            "Loss in iteration no. 92577 ==> 0.48868722805034537\n",
            "Loss in iteration no. 92578 ==> 0.4886861904574674\n",
            "Loss in iteration no. 92579 ==> 0.48868515287420566\n",
            "Loss in iteration no. 92580 ==> 0.48868411530055966\n",
            "Loss in iteration no. 92581 ==> 0.48868307773652964\n",
            "Loss in iteration no. 92582 ==> 0.48868204018211536\n",
            "Loss in iteration no. 92583 ==> 0.4886810026373166\n",
            "Loss in iteration no. 92584 ==> 0.4886799651021334\n",
            "Loss in iteration no. 92585 ==> 0.4886789275765655\n",
            "Loss in iteration no. 92586 ==> 0.4886778900606129\n",
            "Loss in iteration no. 92587 ==> 0.48867685255427534\n",
            "Loss in iteration no. 92588 ==> 0.4886758150575528\n",
            "Loss in iteration no. 92589 ==> 0.48867477757044503\n",
            "Loss in iteration no. 92590 ==> 0.488673740092952\n",
            "Loss in iteration no. 92591 ==> 0.48867270262507356\n",
            "Loss in iteration no. 92592 ==> 0.4886716651668095\n",
            "Loss in iteration no. 92593 ==> 0.48867062771815994\n",
            "Loss in iteration no. 92594 ==> 0.4886695902791245\n",
            "Loss in iteration no. 92595 ==> 0.4886685528497032\n",
            "Loss in iteration no. 92596 ==> 0.4886675154298959\n",
            "Loss in iteration no. 92597 ==> 0.4886664780197023\n",
            "Loss in iteration no. 92598 ==> 0.4886654406191226\n",
            "Loss in iteration no. 92599 ==> 0.48866440322815635\n",
            "Loss in iteration no. 92600 ==> 0.48866336584680353\n",
            "Loss in iteration no. 92601 ==> 0.48866232847506413\n",
            "Loss in iteration no. 92602 ==> 0.48866129111293793\n",
            "Loss in iteration no. 92603 ==> 0.4886602537604249\n",
            "Loss in iteration no. 92604 ==> 0.48865921641752474\n",
            "Loss in iteration no. 92605 ==> 0.4886581790842373\n",
            "Loss in iteration no. 92606 ==> 0.4886571417605629\n",
            "Loss in iteration no. 92607 ==> 0.48865610444650076\n",
            "Loss in iteration no. 92608 ==> 0.4886550671420513\n",
            "Loss in iteration no. 92609 ==> 0.488654029847214\n",
            "Loss in iteration no. 92610 ==> 0.48865299256198896\n",
            "Loss in iteration no. 92611 ==> 0.48865195528637606\n",
            "Loss in iteration no. 92612 ==> 0.4886509180203751\n",
            "Loss in iteration no. 92613 ==> 0.48864988076398597\n",
            "Loss in iteration no. 92614 ==> 0.48864884351720855\n",
            "Loss in iteration no. 92615 ==> 0.48864780628004256\n",
            "Loss in iteration no. 92616 ==> 0.4886467690524883\n",
            "Loss in iteration no. 92617 ==> 0.4886457318345453\n",
            "Loss in iteration no. 92618 ==> 0.4886446946262134\n",
            "Loss in iteration no. 92619 ==> 0.48864365742749255\n",
            "Loss in iteration no. 92620 ==> 0.48864262023838284\n",
            "Loss in iteration no. 92621 ==> 0.4886415830588837\n",
            "Loss in iteration no. 92622 ==> 0.4886405458889956\n",
            "Loss in iteration no. 92623 ==> 0.4886395087287177\n",
            "Loss in iteration no. 92624 ==> 0.48863847157805046\n",
            "Loss in iteration no. 92625 ==> 0.4886374344369936\n",
            "Loss in iteration no. 92626 ==> 0.4886363973055467\n",
            "Loss in iteration no. 92627 ==> 0.4886353601837101\n",
            "Loss in iteration no. 92628 ==> 0.4886343230714834\n",
            "Loss in iteration no. 92629 ==> 0.48863328596886646\n",
            "Loss in iteration no. 92630 ==> 0.4886322488758593\n",
            "Loss in iteration no. 92631 ==> 0.4886312117924616\n",
            "Loss in iteration no. 92632 ==> 0.48863017471867354\n",
            "Loss in iteration no. 92633 ==> 0.48862913765449467\n",
            "Loss in iteration no. 92634 ==> 0.488628100599925\n",
            "Loss in iteration no. 92635 ==> 0.4886270635549644\n",
            "Loss in iteration no. 92636 ==> 0.4886260265196128\n",
            "Loss in iteration no. 92637 ==> 0.4886249894938699\n",
            "Loss in iteration no. 92638 ==> 0.4886239524777358\n",
            "Loss in iteration no. 92639 ==> 0.48862291547121023\n",
            "Loss in iteration no. 92640 ==> 0.48862187847429317\n",
            "Loss in iteration no. 92641 ==> 0.48862084148698426\n",
            "Loss in iteration no. 92642 ==> 0.4886198045092838\n",
            "Loss in iteration no. 92643 ==> 0.48861876754119127\n",
            "Loss in iteration no. 92644 ==> 0.4886177305827067\n",
            "Loss in iteration no. 92645 ==> 0.4886166936338299\n",
            "Loss in iteration no. 92646 ==> 0.48861565669456075\n",
            "Loss in iteration no. 92647 ==> 0.4886146197648992\n",
            "Loss in iteration no. 92648 ==> 0.48861358284484513\n",
            "Loss in iteration no. 92649 ==> 0.48861254593439857\n",
            "Loss in iteration no. 92650 ==> 0.4886115090335589\n",
            "Loss in iteration no. 92651 ==> 0.4886104721423264\n",
            "Loss in iteration no. 92652 ==> 0.4886094352607008\n",
            "Loss in iteration no. 92653 ==> 0.48860839838868214\n",
            "Loss in iteration no. 92654 ==> 0.48860736152627005\n",
            "Loss in iteration no. 92655 ==> 0.48860632467346454\n",
            "Loss in iteration no. 92656 ==> 0.4886052878302655\n",
            "Loss in iteration no. 92657 ==> 0.4886042509966728\n",
            "Loss in iteration no. 92658 ==> 0.48860321417268615\n",
            "Loss in iteration no. 92659 ==> 0.4886021773583058\n",
            "Loss in iteration no. 92660 ==> 0.48860114055353115\n",
            "Loss in iteration no. 92661 ==> 0.4886001037583624\n",
            "Loss in iteration no. 92662 ==> 0.48859906697279937\n",
            "Loss in iteration no. 92663 ==> 0.4885980301968419\n",
            "Loss in iteration no. 92664 ==> 0.4885969934304899\n",
            "Loss in iteration no. 92665 ==> 0.48859595667374306\n",
            "Loss in iteration no. 92666 ==> 0.4885949199266014\n",
            "Loss in iteration no. 92667 ==> 0.48859388318906494\n",
            "Loss in iteration no. 92668 ==> 0.4885928464611334\n",
            "Loss in iteration no. 92669 ==> 0.48859180974280664\n",
            "Loss in iteration no. 92670 ==> 0.48859077303408455\n",
            "Loss in iteration no. 92671 ==> 0.48858973633496694\n",
            "Loss in iteration no. 92672 ==> 0.48858869964545376\n",
            "Loss in iteration no. 92673 ==> 0.4885876629655451\n",
            "Loss in iteration no. 92674 ==> 0.4885866262952405\n",
            "Loss in iteration no. 92675 ==> 0.48858558963453985\n",
            "Loss in iteration no. 92676 ==> 0.4885845529834432\n",
            "Loss in iteration no. 92677 ==> 0.4885835163419505\n",
            "Loss in iteration no. 92678 ==> 0.4885824797100613\n",
            "Loss in iteration no. 92679 ==> 0.4885814430877756\n",
            "Loss in iteration no. 92680 ==> 0.4885804064750935\n",
            "Loss in iteration no. 92681 ==> 0.48857936987201467\n",
            "Loss in iteration no. 92682 ==> 0.48857833327853895\n",
            "Loss in iteration no. 92683 ==> 0.4885772966946664\n",
            "Loss in iteration no. 92684 ==> 0.4885762601203967\n",
            "Loss in iteration no. 92685 ==> 0.48857522355572974\n",
            "Loss in iteration no. 92686 ==> 0.48857418700066546\n",
            "Loss in iteration no. 92687 ==> 0.4885731504552039\n",
            "Loss in iteration no. 92688 ==> 0.4885721139193446\n",
            "Loss in iteration no. 92689 ==> 0.4885710773930877\n",
            "Loss in iteration no. 92690 ==> 0.4885700408764329\n",
            "Loss in iteration no. 92691 ==> 0.48856900436938017\n",
            "Loss in iteration no. 92692 ==> 0.48856796787192935\n",
            "Loss in iteration no. 92693 ==> 0.4885669313840803\n",
            "Loss in iteration no. 92694 ==> 0.4885658949058331\n",
            "Loss in iteration no. 92695 ==> 0.4885648584371872\n",
            "Loss in iteration no. 92696 ==> 0.4885638219781429\n",
            "Loss in iteration no. 92697 ==> 0.4885627855286998\n",
            "Loss in iteration no. 92698 ==> 0.48856174908885797\n",
            "Loss in iteration no. 92699 ==> 0.48856071265861717\n",
            "Loss in iteration no. 92700 ==> 0.4885596762379772\n",
            "Loss in iteration no. 92701 ==> 0.4885586398269381\n",
            "Loss in iteration no. 92702 ==> 0.48855760342549975\n",
            "Loss in iteration no. 92703 ==> 0.4885565670336618\n",
            "Loss in iteration no. 92704 ==> 0.4885555306514243\n",
            "Loss in iteration no. 92705 ==> 0.48855449427878717\n",
            "Loss in iteration no. 92706 ==> 0.48855345791575006\n",
            "Loss in iteration no. 92707 ==> 0.4885524215623131\n",
            "Loss in iteration no. 92708 ==> 0.4885513852184762\n",
            "Loss in iteration no. 92709 ==> 0.4885503488842389\n",
            "Loss in iteration no. 92710 ==> 0.4885493125596013\n",
            "Loss in iteration no. 92711 ==> 0.48854827624456326\n",
            "Loss in iteration no. 92712 ==> 0.48854723993912463\n",
            "Loss in iteration no. 92713 ==> 0.4885462036432854\n",
            "Loss in iteration no. 92714 ==> 0.4885451673570452\n",
            "Loss in iteration no. 92715 ==> 0.48854413108040406\n",
            "Loss in iteration no. 92716 ==> 0.4885430948133619\n",
            "Loss in iteration no. 92717 ==> 0.48854205855591853\n",
            "Loss in iteration no. 92718 ==> 0.4885410223080737\n",
            "Loss in iteration no. 92719 ==> 0.48853998606982757\n",
            "Loss in iteration no. 92720 ==> 0.4885389498411798\n",
            "Loss in iteration no. 92721 ==> 0.48853791362213034\n",
            "Loss in iteration no. 92722 ==> 0.488536877412679\n",
            "Loss in iteration no. 92723 ==> 0.4885358412128257\n",
            "Loss in iteration no. 92724 ==> 0.4885348050225703\n",
            "Loss in iteration no. 92725 ==> 0.48853376884191285\n",
            "Loss in iteration no. 92726 ==> 0.4885327326708528\n",
            "Loss in iteration no. 92727 ==> 0.48853169650939055\n",
            "Loss in iteration no. 92728 ==> 0.4885306603575255\n",
            "Loss in iteration no. 92729 ==> 0.4885296242152579\n",
            "Loss in iteration no. 92730 ==> 0.4885285880825873\n",
            "Loss in iteration no. 92731 ==> 0.4885275519595139\n",
            "Loss in iteration no. 92732 ==> 0.4885265158460374\n",
            "Loss in iteration no. 92733 ==> 0.4885254797421577\n",
            "Loss in iteration no. 92734 ==> 0.48852444364787456\n",
            "Loss in iteration no. 92735 ==> 0.4885234075631879\n",
            "Loss in iteration no. 92736 ==> 0.48852237148809785\n",
            "Loss in iteration no. 92737 ==> 0.4885213354226041\n",
            "Loss in iteration no. 92738 ==> 0.48852029936670627\n",
            "Loss in iteration no. 92739 ==> 0.4885192633204045\n",
            "Loss in iteration no. 92740 ==> 0.48851822728369887\n",
            "Loss in iteration no. 92741 ==> 0.48851719125658893\n",
            "Loss in iteration no. 92742 ==> 0.48851615523907466\n",
            "Loss in iteration no. 92743 ==> 0.4885151192311559\n",
            "Loss in iteration no. 92744 ==> 0.4885140832328325\n",
            "Loss in iteration no. 92745 ==> 0.4885130472441045\n",
            "Loss in iteration no. 92746 ==> 0.4885120112649715\n",
            "Loss in iteration no. 92747 ==> 0.4885109752954337\n",
            "Loss in iteration no. 92748 ==> 0.48850993933549075\n",
            "Loss in iteration no. 92749 ==> 0.4885089033851426\n",
            "Loss in iteration no. 92750 ==> 0.4885078674443891\n",
            "Loss in iteration no. 92751 ==> 0.48850683151323004\n",
            "Loss in iteration no. 92752 ==> 0.4885057955916655\n",
            "Loss in iteration no. 92753 ==> 0.4885047596796953\n",
            "Loss in iteration no. 92754 ==> 0.4885037237773191\n",
            "Loss in iteration no. 92755 ==> 0.4885026878845371\n",
            "Loss in iteration no. 92756 ==> 0.4885016520013489\n",
            "Loss in iteration no. 92757 ==> 0.4885006161277545\n",
            "Loss in iteration no. 92758 ==> 0.48849958026375384\n",
            "Loss in iteration no. 92759 ==> 0.4884985444093465\n",
            "Loss in iteration no. 92760 ==> 0.4884975085645327\n",
            "Loss in iteration no. 92761 ==> 0.4884964727293122\n",
            "Loss in iteration no. 92762 ==> 0.48849543690368485\n",
            "Loss in iteration no. 92763 ==> 0.4884944010876506\n",
            "Loss in iteration no. 92764 ==> 0.48849336528120924\n",
            "Loss in iteration no. 92765 ==> 0.4884923294843605\n",
            "Loss in iteration no. 92766 ==> 0.48849129369710453\n",
            "Loss in iteration no. 92767 ==> 0.48849025791944106\n",
            "Loss in iteration no. 92768 ==> 0.48848922215137\n",
            "Loss in iteration no. 92769 ==> 0.48848818639289127\n",
            "Loss in iteration no. 92770 ==> 0.4884871506440047\n",
            "Loss in iteration no. 92771 ==> 0.48848611490471017\n",
            "Loss in iteration no. 92772 ==> 0.48848507917500744\n",
            "Loss in iteration no. 92773 ==> 0.4884840434548966\n",
            "Loss in iteration no. 92774 ==> 0.4884830077443774\n",
            "Loss in iteration no. 92775 ==> 0.4884819720434497\n",
            "Loss in iteration no. 92776 ==> 0.48848093635211337\n",
            "Loss in iteration no. 92777 ==> 0.4884799006703684\n",
            "Loss in iteration no. 92778 ==> 0.4884788649982146\n",
            "Loss in iteration no. 92779 ==> 0.4884778293356517\n",
            "Loss in iteration no. 92780 ==> 0.48847679368267977\n",
            "Loss in iteration no. 92781 ==> 0.48847575803929877\n",
            "Loss in iteration no. 92782 ==> 0.48847472240550827\n",
            "Loss in iteration no. 92783 ==> 0.48847368678130826\n",
            "Loss in iteration no. 92784 ==> 0.4884726511666987\n",
            "Loss in iteration no. 92785 ==> 0.48847161556167956\n",
            "Loss in iteration no. 92786 ==> 0.4884705799662504\n",
            "Loss in iteration no. 92787 ==> 0.48846954438041124\n",
            "Loss in iteration no. 92788 ==> 0.4884685088041621\n",
            "Loss in iteration no. 92789 ==> 0.4884674732375027\n",
            "Loss in iteration no. 92790 ==> 0.4884664376804329\n",
            "Loss in iteration no. 92791 ==> 0.4884654021329527\n",
            "Loss in iteration no. 92792 ==> 0.4884643665950619\n",
            "Loss in iteration no. 92793 ==> 0.4884633310667604\n",
            "Loss in iteration no. 92794 ==> 0.48846229554804804\n",
            "Loss in iteration no. 92795 ==> 0.48846126003892465\n",
            "Loss in iteration no. 92796 ==> 0.48846022453939025\n",
            "Loss in iteration no. 92797 ==> 0.48845918904944463\n",
            "Loss in iteration no. 92798 ==> 0.48845815356908756\n",
            "Loss in iteration no. 92799 ==> 0.488457118098319\n",
            "Loss in iteration no. 92800 ==> 0.488456082637139\n",
            "Loss in iteration no. 92801 ==> 0.48845504718554716\n",
            "Loss in iteration no. 92802 ==> 0.48845401174354347\n",
            "Loss in iteration no. 92803 ==> 0.48845297631112794\n",
            "Loss in iteration no. 92804 ==> 0.4884519408883002\n",
            "Loss in iteration no. 92805 ==> 0.4884509054750603\n",
            "Loss in iteration no. 92806 ==> 0.48844987007140805\n",
            "Loss in iteration no. 92807 ==> 0.4884488346773432\n",
            "Loss in iteration no. 92808 ==> 0.48844779929286586\n",
            "Loss in iteration no. 92809 ==> 0.4884467639179758\n",
            "Loss in iteration no. 92810 ==> 0.4884457285526728\n",
            "Loss in iteration no. 92811 ==> 0.4884446931969569\n",
            "Loss in iteration no. 92812 ==> 0.4884436578508279\n",
            "Loss in iteration no. 92813 ==> 0.4884426225142857\n",
            "Loss in iteration no. 92814 ==> 0.48844158718733005\n",
            "Loss in iteration no. 92815 ==> 0.48844055186996105\n",
            "Loss in iteration no. 92816 ==> 0.48843951656217843\n",
            "Loss in iteration no. 92817 ==> 0.48843848126398204\n",
            "Loss in iteration no. 92818 ==> 0.48843744597537186\n",
            "Loss in iteration no. 92819 ==> 0.48843641069634774\n",
            "Loss in iteration no. 92820 ==> 0.4884353754269094\n",
            "Loss in iteration no. 92821 ==> 0.48843434016705695\n",
            "Loss in iteration no. 92822 ==> 0.48843330491679\n",
            "Loss in iteration no. 92823 ==> 0.48843226967610875\n",
            "Loss in iteration no. 92824 ==> 0.48843123444501285\n",
            "Loss in iteration no. 92825 ==> 0.48843019922350217\n",
            "Loss in iteration no. 92826 ==> 0.48842916401157666\n",
            "Loss in iteration no. 92827 ==> 0.4884281288092362\n",
            "Loss in iteration no. 92828 ==> 0.4884270936164807\n",
            "Loss in iteration no. 92829 ==> 0.4884260584333097\n",
            "Loss in iteration no. 92830 ==> 0.48842502325972376\n",
            "Loss in iteration no. 92831 ==> 0.48842398809572213\n",
            "Loss in iteration no. 92832 ==> 0.4884229529413049\n",
            "Loss in iteration no. 92833 ==> 0.488421917796472\n",
            "Loss in iteration no. 92834 ==> 0.48842088266122313\n",
            "Loss in iteration no. 92835 ==> 0.48841984753555845\n",
            "Loss in iteration no. 92836 ==> 0.48841881241947765\n",
            "Loss in iteration no. 92837 ==> 0.4884177773129805\n",
            "Loss in iteration no. 92838 ==> 0.48841674221606707\n",
            "Loss in iteration no. 92839 ==> 0.48841570712873716\n",
            "Loss in iteration no. 92840 ==> 0.4884146720509907\n",
            "Loss in iteration no. 92841 ==> 0.48841363698282747\n",
            "Loss in iteration no. 92842 ==> 0.4884126019242474\n",
            "Loss in iteration no. 92843 ==> 0.48841156687525034\n",
            "Loss in iteration no. 92844 ==> 0.4884105318358362\n",
            "Loss in iteration no. 92845 ==> 0.4884094968060049\n",
            "Loss in iteration no. 92846 ==> 0.4884084617857561\n",
            "Loss in iteration no. 92847 ==> 0.48840742677508997\n",
            "Loss in iteration no. 92848 ==> 0.4884063917740061\n",
            "Loss in iteration no. 92849 ==> 0.4884053567825047\n",
            "Loss in iteration no. 92850 ==> 0.4884043218005853\n",
            "Loss in iteration no. 92851 ==> 0.488403286828248\n",
            "Loss in iteration no. 92852 ==> 0.4884022518654926\n",
            "Loss in iteration no. 92853 ==> 0.48840121691231897\n",
            "Loss in iteration no. 92854 ==> 0.4884001819687269\n",
            "Loss in iteration no. 92855 ==> 0.48839914703471654\n",
            "Loss in iteration no. 92856 ==> 0.48839811211028744\n",
            "Loss in iteration no. 92857 ==> 0.4883970771954396\n",
            "Loss in iteration no. 92858 ==> 0.4883960422901731\n",
            "Loss in iteration no. 92859 ==> 0.48839500739448755\n",
            "Loss in iteration no. 92860 ==> 0.4883939725083827\n",
            "Loss in iteration no. 92861 ==> 0.48839293763185876\n",
            "Loss in iteration no. 92862 ==> 0.48839190276491556\n",
            "Loss in iteration no. 92863 ==> 0.4883908679075527\n",
            "Loss in iteration no. 92864 ==> 0.4883898330597704\n",
            "Loss in iteration no. 92865 ==> 0.48838879822156844\n",
            "Loss in iteration no. 92866 ==> 0.4883877633929465\n",
            "Loss in iteration no. 92867 ==> 0.48838672857390447\n",
            "Loss in iteration no. 92868 ==> 0.4883856937644426\n",
            "Loss in iteration no. 92869 ==> 0.4883846589645603\n",
            "Loss in iteration no. 92870 ==> 0.48838362417425785\n",
            "Loss in iteration no. 92871 ==> 0.4883825893935348\n",
            "Loss in iteration no. 92872 ==> 0.48838155462239125\n",
            "Loss in iteration no. 92873 ==> 0.48838051986082687\n",
            "Loss in iteration no. 92874 ==> 0.48837948510884166\n",
            "Loss in iteration no. 92875 ==> 0.48837845036643546\n",
            "Loss in iteration no. 92876 ==> 0.4883774156336082\n",
            "Loss in iteration no. 92877 ==> 0.4883763809103598\n",
            "Loss in iteration no. 92878 ==> 0.48837534619669\n",
            "Loss in iteration no. 92879 ==> 0.4883743114925986\n",
            "Loss in iteration no. 92880 ==> 0.48837327679808573\n",
            "Loss in iteration no. 92881 ==> 0.4883722421131511\n",
            "Loss in iteration no. 92882 ==> 0.4883712074377947\n",
            "Loss in iteration no. 92883 ==> 0.4883701727720162\n",
            "Loss in iteration no. 92884 ==> 0.4883691381158157\n",
            "Loss in iteration no. 92885 ==> 0.48836810346919296\n",
            "Loss in iteration no. 92886 ==> 0.48836706883214787\n",
            "Loss in iteration no. 92887 ==> 0.4883660342046804\n",
            "Loss in iteration no. 92888 ==> 0.4883649995867902\n",
            "Loss in iteration no. 92889 ==> 0.48836396497847734\n",
            "Loss in iteration no. 92890 ==> 0.4883629303797416\n",
            "Loss in iteration no. 92891 ==> 0.48836189579058287\n",
            "Loss in iteration no. 92892 ==> 0.4883608612110011\n",
            "Loss in iteration no. 92893 ==> 0.48835982664099614\n",
            "Loss in iteration no. 92894 ==> 0.4883587920805677\n",
            "Loss in iteration no. 92895 ==> 0.48835775752971594\n",
            "Loss in iteration no. 92896 ==> 0.4883567229884406\n",
            "Loss in iteration no. 92897 ==> 0.48835568845674143\n",
            "Loss in iteration no. 92898 ==> 0.48835465393461847\n",
            "Loss in iteration no. 92899 ==> 0.4883536194220715\n",
            "Loss in iteration no. 92900 ==> 0.48835258491910055\n",
            "Loss in iteration no. 92901 ==> 0.48835155042570527\n",
            "Loss in iteration no. 92902 ==> 0.48835051594188555\n",
            "Loss in iteration no. 92903 ==> 0.4883494814676415\n",
            "Loss in iteration no. 92904 ==> 0.48834844700297286\n",
            "Loss in iteration no. 92905 ==> 0.4883474125478795\n",
            "Loss in iteration no. 92906 ==> 0.4883463781023613\n",
            "Loss in iteration no. 92907 ==> 0.48834534366641813\n",
            "Loss in iteration no. 92908 ==> 0.48834430924004973\n",
            "Loss in iteration no. 92909 ==> 0.4883432748232564\n",
            "Loss in iteration no. 92910 ==> 0.4883422404160375\n",
            "Loss in iteration no. 92911 ==> 0.48834120601839326\n",
            "Loss in iteration no. 92912 ==> 0.4883401716303233\n",
            "Loss in iteration no. 92913 ==> 0.4883391372518277\n",
            "Loss in iteration no. 92914 ==> 0.4883381028829062\n",
            "Loss in iteration no. 92915 ==> 0.4883370685235588\n",
            "Loss in iteration no. 92916 ==> 0.48833603417378524\n",
            "Loss in iteration no. 92917 ==> 0.48833499983358564\n",
            "Loss in iteration no. 92918 ==> 0.48833396550295954\n",
            "Loss in iteration no. 92919 ==> 0.4883329311819069\n",
            "Loss in iteration no. 92920 ==> 0.4883318968704278\n",
            "Loss in iteration no. 92921 ==> 0.4883308625685221\n",
            "Loss in iteration no. 92922 ==> 0.48832982827618937\n",
            "Loss in iteration no. 92923 ==> 0.48832879399342954\n",
            "Loss in iteration no. 92924 ==> 0.48832775972024295\n",
            "Loss in iteration no. 92925 ==> 0.48832672545662903\n",
            "Loss in iteration no. 92926 ==> 0.4883256912025877\n",
            "Loss in iteration no. 92927 ==> 0.48832465695811883\n",
            "Loss in iteration no. 92928 ==> 0.48832362272322244\n",
            "Loss in iteration no. 92929 ==> 0.4883225884978985\n",
            "Loss in iteration no. 92930 ==> 0.4883215542821467\n",
            "Loss in iteration no. 92931 ==> 0.48832052007596677\n",
            "Loss in iteration no. 92932 ==> 0.48831948587935886\n",
            "Loss in iteration no. 92933 ==> 0.48831845169232263\n",
            "Loss in iteration no. 92934 ==> 0.4883174175148582\n",
            "Loss in iteration no. 92935 ==> 0.4883163833469652\n",
            "Loss in iteration no. 92936 ==> 0.4883153491886437\n",
            "Loss in iteration no. 92937 ==> 0.4883143150398934\n",
            "Loss in iteration no. 92938 ==> 0.4883132809007143\n",
            "Loss in iteration no. 92939 ==> 0.4883122467711062\n",
            "Loss in iteration no. 92940 ==> 0.4883112126510692\n",
            "Loss in iteration no. 92941 ==> 0.4883101785406028\n",
            "Loss in iteration no. 92942 ==> 0.48830914443970713\n",
            "Loss in iteration no. 92943 ==> 0.48830811034838195\n",
            "Loss in iteration no. 92944 ==> 0.48830707626662717\n",
            "Loss in iteration no. 92945 ==> 0.4883060421944428\n",
            "Loss in iteration no. 92946 ==> 0.4883050081318285\n",
            "Loss in iteration no. 92947 ==> 0.48830397407878434\n",
            "Loss in iteration no. 92948 ==> 0.48830294003531\n",
            "Loss in iteration no. 92949 ==> 0.48830190600140544\n",
            "Loss in iteration no. 92950 ==> 0.4883008719770706\n",
            "Loss in iteration no. 92951 ==> 0.4882998379623052\n",
            "Loss in iteration no. 92952 ==> 0.4882988039571093\n",
            "Loss in iteration no. 92953 ==> 0.4882977699614827\n",
            "Loss in iteration no. 92954 ==> 0.4882967359754252\n",
            "Loss in iteration no. 92955 ==> 0.48829570199893685\n",
            "Loss in iteration no. 92956 ==> 0.4882946680320174\n",
            "Loss in iteration no. 92957 ==> 0.48829363407466664\n",
            "Loss in iteration no. 92958 ==> 0.4882926001268847\n",
            "Loss in iteration no. 92959 ==> 0.4882915661886712\n",
            "Loss in iteration no. 92960 ==> 0.48829053226002617\n",
            "Loss in iteration no. 92961 ==> 0.4882894983409493\n",
            "Loss in iteration no. 92962 ==> 0.4882884644314407\n",
            "Loss in iteration no. 92963 ==> 0.48828743053150025\n",
            "Loss in iteration no. 92964 ==> 0.48828639664112755\n",
            "Loss in iteration no. 92965 ==> 0.4882853627603227\n",
            "Loss in iteration no. 92966 ==> 0.4882843288890856\n",
            "Loss in iteration no. 92967 ==> 0.48828329502741596\n",
            "Loss in iteration no. 92968 ==> 0.48828226117531376\n",
            "Loss in iteration no. 92969 ==> 0.4882812273327788\n",
            "Loss in iteration no. 92970 ==> 0.48828019349981117\n",
            "Loss in iteration no. 92971 ==> 0.4882791596764104\n",
            "Loss in iteration no. 92972 ==> 0.48827812586257663\n",
            "Loss in iteration no. 92973 ==> 0.48827709205830966\n",
            "Loss in iteration no. 92974 ==> 0.4882760582636094\n",
            "Loss in iteration no. 92975 ==> 0.48827502447847565\n",
            "Loss in iteration no. 92976 ==> 0.4882739907029084\n",
            "Loss in iteration no. 92977 ==> 0.48827295693690737\n",
            "Loss in iteration no. 92978 ==> 0.48827192318047247\n",
            "Loss in iteration no. 92979 ==> 0.4882708894336037\n",
            "Loss in iteration no. 92980 ==> 0.4882698556963009\n",
            "Loss in iteration no. 92981 ==> 0.48826882196856375\n",
            "Loss in iteration no. 92982 ==> 0.4882677882503923\n",
            "Loss in iteration no. 92983 ==> 0.4882667545417864\n",
            "Loss in iteration no. 92984 ==> 0.4882657208427461\n",
            "Loss in iteration no. 92985 ==> 0.488264687153271\n",
            "Loss in iteration no. 92986 ==> 0.488263653473361\n",
            "Loss in iteration no. 92987 ==> 0.48826261980301605\n",
            "Loss in iteration no. 92988 ==> 0.48826158614223614\n",
            "Loss in iteration no. 92989 ==> 0.488260552491021\n",
            "Loss in iteration no. 92990 ==> 0.4882595188493705\n",
            "Loss in iteration no. 92991 ==> 0.48825848521728465\n",
            "Loss in iteration no. 92992 ==> 0.48825745159476314\n",
            "Loss in iteration no. 92993 ==> 0.48825641798180597\n",
            "Loss in iteration no. 92994 ==> 0.4882553843784129\n",
            "Loss in iteration no. 92995 ==> 0.488254350784584\n",
            "Loss in iteration no. 92996 ==> 0.48825331720031895\n",
            "Loss in iteration no. 92997 ==> 0.48825228362561773\n",
            "Loss in iteration no. 92998 ==> 0.48825125006048015\n",
            "Loss in iteration no. 92999 ==> 0.48825021650490613\n",
            "Loss in iteration no. 93000 ==> 0.48824918295889563\n",
            "Loss in iteration no. 93001 ==> 0.4882481494224484\n",
            "Loss in iteration no. 93002 ==> 0.4882471158955644\n",
            "Loss in iteration no. 93003 ==> 0.4882460823782433\n",
            "Loss in iteration no. 93004 ==> 0.48824504887048525\n",
            "Loss in iteration no. 93005 ==> 0.48824401537229\n",
            "Loss in iteration no. 93006 ==> 0.48824298188365733\n",
            "Loss in iteration no. 93007 ==> 0.48824194840458734\n",
            "Loss in iteration no. 93008 ==> 0.4882409149350798\n",
            "Loss in iteration no. 93009 ==> 0.4882398814751344\n",
            "Loss in iteration no. 93010 ==> 0.4882388480247513\n",
            "Loss in iteration no. 93011 ==> 0.4882378145839304\n",
            "Loss in iteration no. 93012 ==> 0.4882367811526712\n",
            "Loss in iteration no. 93013 ==> 0.48823574773097406\n",
            "Loss in iteration no. 93014 ==> 0.4882347143188384\n",
            "Loss in iteration no. 93015 ==> 0.48823368091626435\n",
            "Loss in iteration no. 93016 ==> 0.48823264752325174\n",
            "Loss in iteration no. 93017 ==> 0.48823161413980043\n",
            "Loss in iteration no. 93018 ==> 0.48823058076591036\n",
            "Loss in iteration no. 93019 ==> 0.48822954740158137\n",
            "Loss in iteration no. 93020 ==> 0.48822851404681333\n",
            "Loss in iteration no. 93021 ==> 0.488227480701606\n",
            "Loss in iteration no. 93022 ==> 0.48822644736595944\n",
            "Loss in iteration no. 93023 ==> 0.48822541403987335\n",
            "Loss in iteration no. 93024 ==> 0.48822438072334784\n",
            "Loss in iteration no. 93025 ==> 0.4882233474163825\n",
            "Loss in iteration no. 93026 ==> 0.4882223141189775\n",
            "Loss in iteration no. 93027 ==> 0.4882212808311324\n",
            "Loss in iteration no. 93028 ==> 0.48822024755284743\n",
            "Loss in iteration no. 93029 ==> 0.4882192142841221\n",
            "Loss in iteration no. 93030 ==> 0.4882181810249567\n",
            "Loss in iteration no. 93031 ==> 0.48821714777535064\n",
            "Loss in iteration no. 93032 ==> 0.4882161145353041\n",
            "Loss in iteration no. 93033 ==> 0.48821508130481683\n",
            "Loss in iteration no. 93034 ==> 0.4882140480838889\n",
            "Loss in iteration no. 93035 ==> 0.4882130148725199\n",
            "Loss in iteration no. 93036 ==> 0.48821198167070984\n",
            "Loss in iteration no. 93037 ==> 0.4882109484784587\n",
            "Loss in iteration no. 93038 ==> 0.48820991529576624\n",
            "Loss in iteration no. 93039 ==> 0.48820888212263236\n",
            "Loss in iteration no. 93040 ==> 0.48820784895905694\n",
            "Loss in iteration no. 93041 ==> 0.4882068158050397\n",
            "Loss in iteration no. 93042 ==> 0.4882057826605808\n",
            "Loss in iteration no. 93043 ==> 0.48820474952568\n",
            "Loss in iteration no. 93044 ==> 0.48820371640033694\n",
            "Loss in iteration no. 93045 ==> 0.4882026832845519\n",
            "Loss in iteration no. 93046 ==> 0.48820165017832445\n",
            "Loss in iteration no. 93047 ==> 0.4882006170816547\n",
            "Loss in iteration no. 93048 ==> 0.4881995839945424\n",
            "Loss in iteration no. 93049 ==> 0.48819855091698733\n",
            "Loss in iteration no. 93050 ==> 0.48819751784898946\n",
            "Loss in iteration no. 93051 ==> 0.4881964847905488\n",
            "Loss in iteration no. 93052 ==> 0.4881954517416649\n",
            "Loss in iteration no. 93053 ==> 0.48819441870233793\n",
            "Loss in iteration no. 93054 ==> 0.4881933856725676\n",
            "Loss in iteration no. 93055 ==> 0.488192352652354\n",
            "Loss in iteration no. 93056 ==> 0.4881913196416967\n",
            "Loss in iteration no. 93057 ==> 0.4881902866405959\n",
            "Loss in iteration no. 93058 ==> 0.48818925364905114\n",
            "Loss in iteration no. 93059 ==> 0.48818822066706263\n",
            "Loss in iteration no. 93060 ==> 0.48818718769463\n",
            "Loss in iteration no. 93061 ==> 0.4881861547317532\n",
            "Loss in iteration no. 93062 ==> 0.488185121778432\n",
            "Loss in iteration no. 93063 ==> 0.48818408883466646\n",
            "Loss in iteration no. 93064 ==> 0.4881830559004564\n",
            "Loss in iteration no. 93065 ==> 0.48818202297580165\n",
            "Loss in iteration no. 93066 ==> 0.4881809900607021\n",
            "Loss in iteration no. 93067 ==> 0.48817995715515766\n",
            "Loss in iteration no. 93068 ==> 0.4881789242591682\n",
            "Loss in iteration no. 93069 ==> 0.48817789137273354\n",
            "Loss in iteration no. 93070 ==> 0.48817685849585357\n",
            "Loss in iteration no. 93071 ==> 0.4881758256285283\n",
            "Loss in iteration no. 93072 ==> 0.48817479277075737\n",
            "Loss in iteration no. 93073 ==> 0.4881737599225409\n",
            "Loss in iteration no. 93074 ==> 0.48817272708387854\n",
            "Loss in iteration no. 93075 ==> 0.48817169425477047\n",
            "Loss in iteration no. 93076 ==> 0.4881706614352161\n",
            "Loss in iteration no. 93077 ==> 0.48816962862521573\n",
            "Loss in iteration no. 93078 ==> 0.4881685958247689\n",
            "Loss in iteration no. 93079 ==> 0.4881675630338758\n",
            "Loss in iteration no. 93080 ==> 0.48816653025253626\n",
            "Loss in iteration no. 93081 ==> 0.48816549748074994\n",
            "Loss in iteration no. 93082 ==> 0.4881644647185168\n",
            "Loss in iteration no. 93083 ==> 0.48816343196583684\n",
            "Loss in iteration no. 93084 ==> 0.4881623992227098\n",
            "Loss in iteration no. 93085 ==> 0.48816136648913566\n",
            "Loss in iteration no. 93086 ==> 0.4881603337651142\n",
            "Loss in iteration no. 93087 ==> 0.4881593010506454\n",
            "Loss in iteration no. 93088 ==> 0.488158268345729\n",
            "Loss in iteration no. 93089 ==> 0.4881572356503649\n",
            "Loss in iteration no. 93090 ==> 0.48815620296455303\n",
            "Loss in iteration no. 93091 ==> 0.48815517028829336\n",
            "Loss in iteration no. 93092 ==> 0.4881541376215857\n",
            "Loss in iteration no. 93093 ==> 0.48815310496442976\n",
            "Loss in iteration no. 93094 ==> 0.4881520723168256\n",
            "Loss in iteration no. 93095 ==> 0.48815103967877305\n",
            "Loss in iteration no. 93096 ==> 0.488150007050272\n",
            "Loss in iteration no. 93097 ==> 0.48814897443132227\n",
            "Loss in iteration no. 93098 ==> 0.4881479418219237\n",
            "Loss in iteration no. 93099 ==> 0.48814690922207626\n",
            "Loss in iteration no. 93100 ==> 0.48814587663178\n",
            "Loss in iteration no. 93101 ==> 0.4881448440510344\n",
            "Loss in iteration no. 93102 ==> 0.4881438114798395\n",
            "Loss in iteration no. 93103 ==> 0.4881427789181953\n",
            "Loss in iteration no. 93104 ==> 0.48814174636610147\n",
            "Loss in iteration no. 93105 ==> 0.4881407138235582\n",
            "Loss in iteration no. 93106 ==> 0.48813968129056495\n",
            "Loss in iteration no. 93107 ==> 0.48813864876712193\n",
            "Loss in iteration no. 93108 ==> 0.4881376162532289\n",
            "Loss in iteration no. 93109 ==> 0.4881365837488857\n",
            "Loss in iteration no. 93110 ==> 0.48813555125409225\n",
            "Loss in iteration no. 93111 ==> 0.4881345187688484\n",
            "Loss in iteration no. 93112 ==> 0.488133486293154\n",
            "Loss in iteration no. 93113 ==> 0.48813245382700904\n",
            "Loss in iteration no. 93114 ==> 0.4881314213704131\n",
            "Loss in iteration no. 93115 ==> 0.48813038892336647\n",
            "Loss in iteration no. 93116 ==> 0.4881293564858689\n",
            "Loss in iteration no. 93117 ==> 0.48812832405792\n",
            "Loss in iteration no. 93118 ==> 0.48812729163951996\n",
            "Loss in iteration no. 93119 ==> 0.4881262592306686\n",
            "Loss in iteration no. 93120 ==> 0.48812522683136556\n",
            "Loss in iteration no. 93121 ==> 0.488124194441611\n",
            "Loss in iteration no. 93122 ==> 0.48812316206140466\n",
            "Loss in iteration no. 93123 ==> 0.4881221296907465\n",
            "Loss in iteration no. 93124 ==> 0.48812109732963616\n",
            "Loss in iteration no. 93125 ==> 0.48812006497807375\n",
            "Loss in iteration no. 93126 ==> 0.48811903263605916\n",
            "Loss in iteration no. 93127 ==> 0.48811800030359215\n",
            "Loss in iteration no. 93128 ==> 0.4881169679806726\n",
            "Loss in iteration no. 93129 ==> 0.4881159356673005\n",
            "Loss in iteration no. 93130 ==> 0.4881149033634756\n",
            "Loss in iteration no. 93131 ==> 0.48811387106919785\n",
            "Loss in iteration no. 93132 ==> 0.48811283878446704\n",
            "Loss in iteration no. 93133 ==> 0.4881118065092832\n",
            "Loss in iteration no. 93134 ==> 0.488110774243646\n",
            "Loss in iteration no. 93135 ==> 0.4881097419875555\n",
            "Loss in iteration no. 93136 ==> 0.48810870974101156\n",
            "Loss in iteration no. 93137 ==> 0.48810767750401396\n",
            "Loss in iteration no. 93138 ==> 0.48810664527656256\n",
            "Loss in iteration no. 93139 ==> 0.4881056130586572\n",
            "Loss in iteration no. 93140 ==> 0.48810458085029795\n",
            "Loss in iteration no. 93141 ==> 0.48810354865148464\n",
            "Loss in iteration no. 93142 ==> 0.48810251646221703\n",
            "Loss in iteration no. 93143 ==> 0.48810148428249506\n",
            "Loss in iteration no. 93144 ==> 0.48810045211231845\n",
            "Loss in iteration no. 93145 ==> 0.48809941995168743\n",
            "Loss in iteration no. 93146 ==> 0.4880983878006015\n",
            "Loss in iteration no. 93147 ==> 0.48809735565906087\n",
            "Loss in iteration no. 93148 ==> 0.48809632352706517\n",
            "Loss in iteration no. 93149 ==> 0.4880952914046144\n",
            "Loss in iteration no. 93150 ==> 0.48809425929170835\n",
            "Loss in iteration no. 93151 ==> 0.48809322718834697\n",
            "Loss in iteration no. 93152 ==> 0.48809219509453006\n",
            "Loss in iteration no. 93153 ==> 0.4880911630102575\n",
            "Loss in iteration no. 93154 ==> 0.4880901309355293\n",
            "Loss in iteration no. 93155 ==> 0.48808909887034524\n",
            "Loss in iteration no. 93156 ==> 0.4880880668147051\n",
            "Loss in iteration no. 93157 ==> 0.48808703476860893\n",
            "Loss in iteration no. 93158 ==> 0.48808600273205643\n",
            "Loss in iteration no. 93159 ==> 0.48808497070504775\n",
            "Loss in iteration no. 93160 ==> 0.48808393868758243\n",
            "Loss in iteration no. 93161 ==> 0.4880829066796606\n",
            "Loss in iteration no. 93162 ==> 0.48808187468128195\n",
            "Loss in iteration no. 93163 ==> 0.4880808426924465\n",
            "Loss in iteration no. 93164 ==> 0.48807981071315404\n",
            "Loss in iteration no. 93165 ==> 0.4880787787434045\n",
            "Loss in iteration no. 93166 ==> 0.48807774678319776\n",
            "Loss in iteration no. 93167 ==> 0.4880767148325336\n",
            "Loss in iteration no. 93168 ==> 0.488075682891412\n",
            "Loss in iteration no. 93169 ==> 0.48807465095983277\n",
            "Loss in iteration no. 93170 ==> 0.48807361903779584\n",
            "Loss in iteration no. 93171 ==> 0.4880725871253011\n",
            "Loss in iteration no. 93172 ==> 0.4880715552223483\n",
            "Loss in iteration no. 93173 ==> 0.4880705233289376\n",
            "Loss in iteration no. 93174 ==> 0.48806949144506845\n",
            "Loss in iteration no. 93175 ==> 0.4880684595707411\n",
            "Loss in iteration no. 93176 ==> 0.4880674277059552\n",
            "Loss in iteration no. 93177 ==> 0.48806639585071065\n",
            "Loss in iteration no. 93178 ==> 0.48806536400500755\n",
            "Loss in iteration no. 93179 ==> 0.4880643321688455\n",
            "Loss in iteration no. 93180 ==> 0.4880633003422245\n",
            "Loss in iteration no. 93181 ==> 0.48806226852514434\n",
            "Loss in iteration no. 93182 ==> 0.48806123671760504\n",
            "Loss in iteration no. 93183 ==> 0.4880602049196064\n",
            "Loss in iteration no. 93184 ==> 0.4880591731311483\n",
            "Loss in iteration no. 93185 ==> 0.4880581413522306\n",
            "Loss in iteration no. 93186 ==> 0.4880571095828532\n",
            "Loss in iteration no. 93187 ==> 0.48805607782301585\n",
            "Loss in iteration no. 93188 ==> 0.48805504607271866\n",
            "Loss in iteration no. 93189 ==> 0.48805401433196144\n",
            "Loss in iteration no. 93190 ==> 0.488052982600744\n",
            "Loss in iteration no. 93191 ==> 0.48805195087906605\n",
            "Loss in iteration no. 93192 ==> 0.48805091916692783\n",
            "Loss in iteration no. 93193 ==> 0.48804988746432887\n",
            "Loss in iteration no. 93194 ==> 0.4880488557712692\n",
            "Loss in iteration no. 93195 ==> 0.4880478240877489\n",
            "Loss in iteration no. 93196 ==> 0.48804679241376747\n",
            "Loss in iteration no. 93197 ==> 0.488045760749325\n",
            "Loss in iteration no. 93198 ==> 0.4880447290944215\n",
            "Loss in iteration no. 93199 ==> 0.4880436974490565\n",
            "Loss in iteration no. 93200 ==> 0.4880426658132299\n",
            "Loss in iteration no. 93201 ==> 0.488041634186942\n",
            "Loss in iteration no. 93202 ==> 0.48804060257019233\n",
            "Loss in iteration no. 93203 ==> 0.48803957096298073\n",
            "Loss in iteration no. 93204 ==> 0.4880385393653073\n",
            "Loss in iteration no. 93205 ==> 0.4880375077771717\n",
            "Loss in iteration no. 93206 ==> 0.4880364761985741\n",
            "Loss in iteration no. 93207 ==> 0.4880354446295138\n",
            "Loss in iteration no. 93208 ==> 0.4880344130699915\n",
            "Loss in iteration no. 93209 ==> 0.48803338152000636\n",
            "Loss in iteration no. 93210 ==> 0.4880323499795585\n",
            "Loss in iteration no. 93211 ==> 0.48803131844864794\n",
            "Loss in iteration no. 93212 ==> 0.4880302869272745\n",
            "Loss in iteration no. 93213 ==> 0.4880292554154378\n",
            "Loss in iteration no. 93214 ==> 0.488028223913138\n",
            "Loss in iteration no. 93215 ==> 0.48802719242037496\n",
            "Loss in iteration no. 93216 ==> 0.48802616093714835\n",
            "Loss in iteration no. 93217 ==> 0.48802512946345833\n",
            "Loss in iteration no. 93218 ==> 0.4880240979993046\n",
            "Loss in iteration no. 93219 ==> 0.4880230665446869\n",
            "Loss in iteration no. 93220 ==> 0.48802203509960534\n",
            "Loss in iteration no. 93221 ==> 0.48802100366405976\n",
            "Loss in iteration no. 93222 ==> 0.48801997223805\n",
            "Loss in iteration no. 93223 ==> 0.48801894082157593\n",
            "Loss in iteration no. 93224 ==> 0.48801790941463735\n",
            "Loss in iteration no. 93225 ==> 0.4880168780172343\n",
            "Loss in iteration no. 93226 ==> 0.4880158466293665\n",
            "Loss in iteration no. 93227 ==> 0.488014815251034\n",
            "Loss in iteration no. 93228 ==> 0.48801378388223654\n",
            "Loss in iteration no. 93229 ==> 0.488012752522974\n",
            "Loss in iteration no. 93230 ==> 0.4880117211732464\n",
            "Loss in iteration no. 93231 ==> 0.4880106898330533\n",
            "Loss in iteration no. 93232 ==> 0.48800965850239486\n",
            "Loss in iteration no. 93233 ==> 0.48800862718127086\n",
            "Loss in iteration no. 93234 ==> 0.48800759586968123\n",
            "Loss in iteration no. 93235 ==> 0.48800656456762576\n",
            "Loss in iteration no. 93236 ==> 0.48800553327510443\n",
            "Loss in iteration no. 93237 ==> 0.48800450199211703\n",
            "Loss in iteration no. 93238 ==> 0.48800347071866335\n",
            "Loss in iteration no. 93239 ==> 0.4880024394547435\n",
            "Loss in iteration no. 93240 ==> 0.4880014082003572\n",
            "Loss in iteration no. 93241 ==> 0.48800037695550436\n",
            "Loss in iteration no. 93242 ==> 0.48799934572018483\n",
            "Loss in iteration no. 93243 ==> 0.4879983144943985\n",
            "Loss in iteration no. 93244 ==> 0.4879972832781453\n",
            "Loss in iteration no. 93245 ==> 0.48799625207142505\n",
            "Loss in iteration no. 93246 ==> 0.48799522087423775\n",
            "Loss in iteration no. 93247 ==> 0.4879941896865829\n",
            "Loss in iteration no. 93248 ==> 0.4879931585084608\n",
            "Loss in iteration no. 93249 ==> 0.48799212733987124\n",
            "Loss in iteration no. 93250 ==> 0.487991096180814\n",
            "Loss in iteration no. 93251 ==> 0.4879900650312889\n",
            "Loss in iteration no. 93252 ==> 0.4879890338912959\n",
            "Loss in iteration no. 93253 ==> 0.4879880027608348\n",
            "Loss in iteration no. 93254 ==> 0.48798697163990573\n",
            "Loss in iteration no. 93255 ==> 0.4879859405285082\n",
            "Loss in iteration no. 93256 ==> 0.48798490942664224\n",
            "Loss in iteration no. 93257 ==> 0.48798387833430795\n",
            "Loss in iteration no. 93258 ==> 0.487982847251505\n",
            "Loss in iteration no. 93259 ==> 0.48798181617823316\n",
            "Loss in iteration no. 93260 ==> 0.4879807851144924\n",
            "Loss in iteration no. 93261 ==> 0.48797975406028277\n",
            "Loss in iteration no. 93262 ==> 0.48797872301560385\n",
            "Loss in iteration no. 93263 ==> 0.48797769198045565\n",
            "Loss in iteration no. 93264 ==> 0.48797666095483816\n",
            "Loss in iteration no. 93265 ==> 0.4879756299387511\n",
            "Loss in iteration no. 93266 ==> 0.4879745989321944\n",
            "Loss in iteration no. 93267 ==> 0.4879735679351678\n",
            "Loss in iteration no. 93268 ==> 0.48797253694767156\n",
            "Loss in iteration no. 93269 ==> 0.48797150596970523\n",
            "Loss in iteration no. 93270 ==> 0.48797047500126856\n",
            "Loss in iteration no. 93271 ==> 0.48796944404236187\n",
            "Loss in iteration no. 93272 ==> 0.4879684130929846\n",
            "Loss in iteration no. 93273 ==> 0.48796738215313695\n",
            "Loss in iteration no. 93274 ==> 0.4879663512228187\n",
            "Loss in iteration no. 93275 ==> 0.48796532030202955\n",
            "Loss in iteration no. 93276 ==> 0.4879642893907696\n",
            "Loss in iteration no. 93277 ==> 0.4879632584890387\n",
            "Loss in iteration no. 93278 ==> 0.4879622275968365\n",
            "Loss in iteration no. 93279 ==> 0.4879611967141632\n",
            "Loss in iteration no. 93280 ==> 0.4879601658410185\n",
            "Loss in iteration no. 93281 ==> 0.4879591349774022\n",
            "Loss in iteration no. 93282 ==> 0.48795810412331425\n",
            "Loss in iteration no. 93283 ==> 0.4879570732787547\n",
            "Loss in iteration no. 93284 ==> 0.4879560424437232\n",
            "Loss in iteration no. 93285 ==> 0.48795501161821964\n",
            "Loss in iteration no. 93286 ==> 0.48795398080224406\n",
            "Loss in iteration no. 93287 ==> 0.4879529499957962\n",
            "Loss in iteration no. 93288 ==> 0.4879519191988759\n",
            "Loss in iteration no. 93289 ==> 0.4879508884114832\n",
            "Loss in iteration no. 93290 ==> 0.4879498576336178\n",
            "Loss in iteration no. 93291 ==> 0.48794882686527974\n",
            "Loss in iteration no. 93292 ==> 0.48794779610646877\n",
            "Loss in iteration no. 93293 ==> 0.4879467653571849\n",
            "Loss in iteration no. 93294 ==> 0.48794573461742774\n",
            "Loss in iteration no. 93295 ==> 0.48794470388719735\n",
            "Loss in iteration no. 93296 ==> 0.48794367316649384\n",
            "Loss in iteration no. 93297 ==> 0.48794264245531666\n",
            "Loss in iteration no. 93298 ==> 0.4879416117536658\n",
            "Loss in iteration no. 93299 ==> 0.48794058106154126\n",
            "Loss in iteration no. 93300 ==> 0.487939550378943\n",
            "Loss in iteration no. 93301 ==> 0.4879385197058706\n",
            "Loss in iteration no. 93302 ==> 0.48793748904232404\n",
            "Loss in iteration no. 93303 ==> 0.48793645838830346\n",
            "Loss in iteration no. 93304 ==> 0.4879354277438083\n",
            "Loss in iteration no. 93305 ==> 0.48793439710883885\n",
            "Loss in iteration no. 93306 ==> 0.48793336648339475\n",
            "Loss in iteration no. 93307 ==> 0.48793233586747586\n",
            "Loss in iteration no. 93308 ==> 0.487931305261082\n",
            "Loss in iteration no. 93309 ==> 0.48793027466421335\n",
            "Loss in iteration no. 93310 ==> 0.48792924407686955\n",
            "Loss in iteration no. 93311 ==> 0.4879282134990505\n",
            "Loss in iteration no. 93312 ==> 0.4879271829307562\n",
            "Loss in iteration no. 93313 ==> 0.48792615237198633\n",
            "Loss in iteration no. 93314 ==> 0.48792512182274084\n",
            "Loss in iteration no. 93315 ==> 0.4879240912830197\n",
            "Loss in iteration no. 93316 ==> 0.48792306075282277\n",
            "Loss in iteration no. 93317 ==> 0.4879220302321497\n",
            "Loss in iteration no. 93318 ==> 0.4879209997210008\n",
            "Loss in iteration no. 93319 ==> 0.48791996921937547\n",
            "Loss in iteration no. 93320 ==> 0.4879189387272739\n",
            "Loss in iteration no. 93321 ==> 0.48791790824469566\n",
            "Loss in iteration no. 93322 ==> 0.48791687777164117\n",
            "Loss in iteration no. 93323 ==> 0.4879158473081098\n",
            "Loss in iteration no. 93324 ==> 0.4879148168541016\n",
            "Loss in iteration no. 93325 ==> 0.48791378640961636\n",
            "Loss in iteration no. 93326 ==> 0.48791275597465406\n",
            "Loss in iteration no. 93327 ==> 0.48791172554921475\n",
            "Loss in iteration no. 93328 ==> 0.487910695133298\n",
            "Loss in iteration no. 93329 ==> 0.4879096647269036\n",
            "Loss in iteration no. 93330 ==> 0.4879086343300319\n",
            "Loss in iteration no. 93331 ==> 0.48790760394268234\n",
            "Loss in iteration no. 93332 ==> 0.487906573564855\n",
            "Loss in iteration no. 93333 ==> 0.48790554319654966\n",
            "Loss in iteration no. 93334 ==> 0.4879045128377663\n",
            "Loss in iteration no. 93335 ==> 0.4879034824885048\n",
            "Loss in iteration no. 93336 ==> 0.48790245214876493\n",
            "Loss in iteration no. 93337 ==> 0.4879014218185466\n",
            "Loss in iteration no. 93338 ==> 0.4879003914978497\n",
            "Loss in iteration no. 93339 ==> 0.4878993611866741\n",
            "Loss in iteration no. 93340 ==> 0.4878983308850196\n",
            "Loss in iteration no. 93341 ==> 0.48789730059288633\n",
            "Loss in iteration no. 93342 ==> 0.4878962703102739\n",
            "Loss in iteration no. 93343 ==> 0.48789524003718227\n",
            "Loss in iteration no. 93344 ==> 0.48789420977361136\n",
            "Loss in iteration no. 93345 ==> 0.48789317951956096\n",
            "Loss in iteration no. 93346 ==> 0.48789214927503116\n",
            "Loss in iteration no. 93347 ==> 0.48789111904002147\n",
            "Loss in iteration no. 93348 ==> 0.4878900888145321\n",
            "Loss in iteration no. 93349 ==> 0.4878890585985628\n",
            "Loss in iteration no. 93350 ==> 0.4878880283921134\n",
            "Loss in iteration no. 93351 ==> 0.48788699819518383\n",
            "Loss in iteration no. 93352 ==> 0.4878859680077739\n",
            "Loss in iteration no. 93353 ==> 0.4878849378298837\n",
            "Loss in iteration no. 93354 ==> 0.48788390766151274\n",
            "Loss in iteration no. 93355 ==> 0.48788287750266124\n",
            "Loss in iteration no. 93356 ==> 0.48788184735332885\n",
            "Loss in iteration no. 93357 ==> 0.48788081721351567\n",
            "Loss in iteration no. 93358 ==> 0.4878797870832214\n",
            "Loss in iteration no. 93359 ==> 0.48787875696244587\n",
            "Loss in iteration no. 93360 ==> 0.48787772685118913\n",
            "Loss in iteration no. 93361 ==> 0.4878766967494509\n",
            "Loss in iteration no. 93362 ==> 0.48787566665723114\n",
            "Loss in iteration no. 93363 ==> 0.4878746365745298\n",
            "Loss in iteration no. 93364 ==> 0.4878736065013467\n",
            "Loss in iteration no. 93365 ==> 0.48787257643768145\n",
            "Loss in iteration no. 93366 ==> 0.4878715463835343\n",
            "Loss in iteration no. 93367 ==> 0.4878705163389051\n",
            "Loss in iteration no. 93368 ==> 0.48786948630379356\n",
            "Loss in iteration no. 93369 ==> 0.4878684562781996\n",
            "Loss in iteration no. 93370 ==> 0.48786742626212304\n",
            "Loss in iteration no. 93371 ==> 0.4878663962555637\n",
            "Loss in iteration no. 93372 ==> 0.4878653662585219\n",
            "Loss in iteration no. 93373 ==> 0.48786433627099707\n",
            "Loss in iteration no. 93374 ==> 0.4878633062929892\n",
            "Loss in iteration no. 93375 ==> 0.48786227632449813\n",
            "Loss in iteration no. 93376 ==> 0.4878612463655238\n",
            "Loss in iteration no. 93377 ==> 0.4878602164160661\n",
            "Loss in iteration no. 93378 ==> 0.4878591864761248\n",
            "Loss in iteration no. 93379 ==> 0.4878581565456999\n",
            "Loss in iteration no. 93380 ==> 0.48785712662479125\n",
            "Loss in iteration no. 93381 ==> 0.4878560967133988\n",
            "Loss in iteration no. 93382 ==> 0.4878550668115222\n",
            "Loss in iteration no. 93383 ==> 0.48785403691916146\n",
            "Loss in iteration no. 93384 ==> 0.48785300703631634\n",
            "Loss in iteration no. 93385 ==> 0.48785197716298706\n",
            "Loss in iteration no. 93386 ==> 0.48785094729917317\n",
            "Loss in iteration no. 93387 ==> 0.48784991744487466\n",
            "Loss in iteration no. 93388 ==> 0.48784888760009143\n",
            "Loss in iteration no. 93389 ==> 0.48784785776482315\n",
            "Loss in iteration no. 93390 ==> 0.4878468279390701\n",
            "Loss in iteration no. 93391 ==> 0.48784579812283174\n",
            "Loss in iteration no. 93392 ==> 0.4878447683161081\n",
            "Loss in iteration no. 93393 ==> 0.48784373851889923\n",
            "Loss in iteration no. 93394 ==> 0.4878427087312048\n",
            "Loss in iteration no. 93395 ==> 0.48784167895302477\n",
            "Loss in iteration no. 93396 ==> 0.4878406491843589\n",
            "Loss in iteration no. 93397 ==> 0.48783961942520715\n",
            "Loss in iteration no. 93398 ==> 0.4878385896755695\n",
            "Loss in iteration no. 93399 ==> 0.4878375599354456\n",
            "Loss in iteration no. 93400 ==> 0.4878365302048356\n",
            "Loss in iteration no. 93401 ==> 0.48783550048373914\n",
            "Loss in iteration no. 93402 ==> 0.4878344707721563\n",
            "Loss in iteration no. 93403 ==> 0.4878334410700867\n",
            "Loss in iteration no. 93404 ==> 0.48783241137753036\n",
            "Loss in iteration no. 93405 ==> 0.4878313816944872\n",
            "Loss in iteration no. 93406 ==> 0.48783035202095704\n",
            "Loss in iteration no. 93407 ==> 0.4878293223569397\n",
            "Loss in iteration no. 93408 ==> 0.4878282927024353\n",
            "Loss in iteration no. 93409 ==> 0.48782726305744345\n",
            "Loss in iteration no. 93410 ==> 0.4878262334219642\n",
            "Loss in iteration no. 93411 ==> 0.4878252037959972\n",
            "Loss in iteration no. 93412 ==> 0.4878241741795425\n",
            "Loss in iteration no. 93413 ==> 0.48782314457259995\n",
            "Loss in iteration no. 93414 ==> 0.4878221149751694\n",
            "Loss in iteration no. 93415 ==> 0.48782108538725083\n",
            "Loss in iteration no. 93416 ==> 0.487820055808844\n",
            "Loss in iteration no. 93417 ==> 0.48781902623994877\n",
            "Loss in iteration no. 93418 ==> 0.4878179966805651\n",
            "Loss in iteration no. 93419 ==> 0.48781696713069284\n",
            "Loss in iteration no. 93420 ==> 0.4878159375903318\n",
            "Loss in iteration no. 93421 ==> 0.4878149080594821\n",
            "Loss in iteration no. 93422 ==> 0.4878138785381432\n",
            "Loss in iteration no. 93423 ==> 0.4878128490263153\n",
            "Loss in iteration no. 93424 ==> 0.4878118195239982\n",
            "Loss in iteration no. 93425 ==> 0.4878107900311918\n",
            "Loss in iteration no. 93426 ==> 0.4878097605478958\n",
            "Loss in iteration no. 93427 ==> 0.4878087310741104\n",
            "Loss in iteration no. 93428 ==> 0.4878077016098351\n",
            "Loss in iteration no. 93429 ==> 0.48780667215507006\n",
            "Loss in iteration no. 93430 ==> 0.48780564270981513\n",
            "Loss in iteration no. 93431 ==> 0.48780461327407\n",
            "Loss in iteration no. 93432 ==> 0.4878035838478348\n",
            "Loss in iteration no. 93433 ==> 0.48780255443110915\n",
            "Loss in iteration no. 93434 ==> 0.4878015250238931\n",
            "Loss in iteration no. 93435 ==> 0.4878004956261864\n",
            "Loss in iteration no. 93436 ==> 0.4877994662379891\n",
            "Loss in iteration no. 93437 ==> 0.4877984368593009\n",
            "Loss in iteration no. 93438 ==> 0.4877974074901218\n",
            "Loss in iteration no. 93439 ==> 0.48779637813045157\n",
            "Loss in iteration no. 93440 ==> 0.4877953487802902\n",
            "Loss in iteration no. 93441 ==> 0.4877943194396376\n",
            "Loss in iteration no. 93442 ==> 0.4877932901084933\n",
            "Loss in iteration no. 93443 ==> 0.48779226078685767\n",
            "Loss in iteration no. 93444 ==> 0.4877912314747303\n",
            "Loss in iteration no. 93445 ==> 0.48779020217211105\n",
            "Loss in iteration no. 93446 ==> 0.48778917287899987\n",
            "Loss in iteration no. 93447 ==> 0.4877881435953967\n",
            "Loss in iteration no. 93448 ==> 0.48778711432130134\n",
            "Loss in iteration no. 93449 ==> 0.4877860850567136\n",
            "Loss in iteration no. 93450 ==> 0.4877850558016334\n",
            "Loss in iteration no. 93451 ==> 0.4877840265560608\n",
            "Loss in iteration no. 93452 ==> 0.48778299731999536\n",
            "Loss in iteration no. 93453 ==> 0.4877819680934372\n",
            "Loss in iteration no. 93454 ==> 0.4877809388763862\n",
            "Loss in iteration no. 93455 ==> 0.48777990966884194\n",
            "Loss in iteration no. 93456 ==> 0.4877788804708046\n",
            "Loss in iteration no. 93457 ==> 0.48777785128227397\n",
            "Loss in iteration no. 93458 ==> 0.48777682210324996\n",
            "Loss in iteration no. 93459 ==> 0.48777579293373247\n",
            "Loss in iteration no. 93460 ==> 0.4877747637737211\n",
            "Loss in iteration no. 93461 ==> 0.48777373462321605\n",
            "Loss in iteration no. 93462 ==> 0.48777270548221713\n",
            "Loss in iteration no. 93463 ==> 0.48777167635072416\n",
            "Loss in iteration no. 93464 ==> 0.48777064722873703\n",
            "Loss in iteration no. 93465 ==> 0.4877696181162556\n",
            "Loss in iteration no. 93466 ==> 0.48776858901327974\n",
            "Loss in iteration no. 93467 ==> 0.4877675599198093\n",
            "Loss in iteration no. 93468 ==> 0.48776653083584426\n",
            "Loss in iteration no. 93469 ==> 0.4877655017613844\n",
            "Loss in iteration no. 93470 ==> 0.48776447269642964\n",
            "Loss in iteration no. 93471 ==> 0.48776344364097995\n",
            "Loss in iteration no. 93472 ==> 0.487762414595035\n",
            "Loss in iteration no. 93473 ==> 0.48776138555859483\n",
            "Loss in iteration no. 93474 ==> 0.4877603565316593\n",
            "Loss in iteration no. 93475 ==> 0.4877593275142282\n",
            "Loss in iteration no. 93476 ==> 0.4877582985063014\n",
            "Loss in iteration no. 93477 ==> 0.48775726950787884\n",
            "Loss in iteration no. 93478 ==> 0.4877562405189605\n",
            "Loss in iteration no. 93479 ==> 0.4877552115395461\n",
            "Loss in iteration no. 93480 ==> 0.48775418256963554\n",
            "Loss in iteration no. 93481 ==> 0.4877531536092286\n",
            "Loss in iteration no. 93482 ==> 0.4877521246583254\n",
            "Loss in iteration no. 93483 ==> 0.48775109571692576\n",
            "Loss in iteration no. 93484 ==> 0.48775006678502936\n",
            "Loss in iteration no. 93485 ==> 0.48774903786263624\n",
            "Loss in iteration no. 93486 ==> 0.48774800894974624\n",
            "Loss in iteration no. 93487 ==> 0.4877469800463593\n",
            "Loss in iteration no. 93488 ==> 0.4877459511524751\n",
            "Loss in iteration no. 93489 ==> 0.48774492226809374\n",
            "Loss in iteration no. 93490 ==> 0.48774389339321506\n",
            "Loss in iteration no. 93491 ==> 0.48774286452783866\n",
            "Loss in iteration no. 93492 ==> 0.48774183567196483\n",
            "Loss in iteration no. 93493 ==> 0.4877408068255932\n",
            "Loss in iteration no. 93494 ==> 0.48773977798872364\n",
            "Loss in iteration no. 93495 ==> 0.48773874916135623\n",
            "Loss in iteration no. 93496 ==> 0.4877377203434906\n",
            "Loss in iteration no. 93497 ==> 0.4877366915351267\n",
            "Loss in iteration no. 93498 ==> 0.4877356627362645\n",
            "Loss in iteration no. 93499 ==> 0.4877346339469037\n",
            "Loss in iteration no. 93500 ==> 0.4877336051670444\n",
            "Loss in iteration no. 93501 ==> 0.48773257639668643\n",
            "Loss in iteration no. 93502 ==> 0.48773154763582954\n",
            "Loss in iteration no. 93503 ==> 0.4877305188844737\n",
            "Loss in iteration no. 93504 ==> 0.48772949014261857\n",
            "Loss in iteration no. 93505 ==> 0.48772846141026444\n",
            "Loss in iteration no. 93506 ==> 0.4877274326874108\n",
            "Loss in iteration no. 93507 ==> 0.4877264039740578\n",
            "Loss in iteration no. 93508 ==> 0.48772537527020515\n",
            "Loss in iteration no. 93509 ==> 0.48772434657585273\n",
            "Loss in iteration no. 93510 ==> 0.4877233178910006\n",
            "Loss in iteration no. 93511 ==> 0.4877222892156483\n",
            "Loss in iteration no. 93512 ==> 0.48772126054979603\n",
            "Loss in iteration no. 93513 ==> 0.48772023189344355\n",
            "Loss in iteration no. 93514 ==> 0.4877192032465907\n",
            "Loss in iteration no. 93515 ==> 0.48771817460923733\n",
            "Loss in iteration no. 93516 ==> 0.48771714598138355\n",
            "Loss in iteration no. 93517 ==> 0.4877161173630289\n",
            "Loss in iteration no. 93518 ==> 0.4877150887541735\n",
            "Loss in iteration no. 93519 ==> 0.48771406015481694\n",
            "Loss in iteration no. 93520 ==> 0.48771303156495965\n",
            "Loss in iteration no. 93521 ==> 0.48771200298460093\n",
            "Loss in iteration no. 93522 ==> 0.4877109744137409\n",
            "Loss in iteration no. 93523 ==> 0.4877099458523794\n",
            "Loss in iteration no. 93524 ==> 0.4877089173005164\n",
            "Loss in iteration no. 93525 ==> 0.4877078887581518\n",
            "Loss in iteration no. 93526 ==> 0.4877068602252852\n",
            "Loss in iteration no. 93527 ==> 0.48770583170191667\n",
            "Loss in iteration no. 93528 ==> 0.487704803188046\n",
            "Loss in iteration no. 93529 ==> 0.4877037746836734\n",
            "Loss in iteration no. 93530 ==> 0.4877027461887982\n",
            "Loss in iteration no. 93531 ==> 0.4877017177034207\n",
            "Loss in iteration no. 93532 ==> 0.48770068922754056\n",
            "Loss in iteration no. 93533 ==> 0.48769966076115784\n",
            "Loss in iteration no. 93534 ==> 0.4876986323042723\n",
            "Loss in iteration no. 93535 ==> 0.4876976038568837\n",
            "Loss in iteration no. 93536 ==> 0.48769657541899214\n",
            "Loss in iteration no. 93537 ==> 0.48769554699059736\n",
            "Loss in iteration no. 93538 ==> 0.4876945185716994\n",
            "Loss in iteration no. 93539 ==> 0.4876934901622979\n",
            "Loss in iteration no. 93540 ==> 0.48769246176239284\n",
            "Loss in iteration no. 93541 ==> 0.4876914333719841\n",
            "Loss in iteration no. 93542 ==> 0.4876904049910716\n",
            "Loss in iteration no. 93543 ==> 0.48768937661965517\n",
            "Loss in iteration no. 93544 ==> 0.4876883482577347\n",
            "Loss in iteration no. 93545 ==> 0.48768731990531\n",
            "Loss in iteration no. 93546 ==> 0.4876862915623811\n",
            "Loss in iteration no. 93547 ==> 0.48768526322894773\n",
            "Loss in iteration no. 93548 ==> 0.4876842349050099\n",
            "Loss in iteration no. 93549 ==> 0.48768320659056735\n",
            "Loss in iteration no. 93550 ==> 0.48768217828562\n",
            "Loss in iteration no. 93551 ==> 0.4876811499901677\n",
            "Loss in iteration no. 93552 ==> 0.48768012170421043\n",
            "Loss in iteration no. 93553 ==> 0.48767909342774796\n",
            "Loss in iteration no. 93554 ==> 0.4876780651607803\n",
            "Loss in iteration no. 93555 ==> 0.48767703690330727\n",
            "Loss in iteration no. 93556 ==> 0.48767600865532856\n",
            "Loss in iteration no. 93557 ==> 0.4876749804168443\n",
            "Loss in iteration no. 93558 ==> 0.48767395218785425\n",
            "Loss in iteration no. 93559 ==> 0.4876729239683583\n",
            "Loss in iteration no. 93560 ==> 0.48767189575835634\n",
            "Loss in iteration no. 93561 ==> 0.48767086755784816\n",
            "Loss in iteration no. 93562 ==> 0.48766983936683367\n",
            "Loss in iteration no. 93563 ==> 0.48766881118531297\n",
            "Loss in iteration no. 93564 ==> 0.48766778301328567\n",
            "Loss in iteration no. 93565 ==> 0.4876667548507518\n",
            "Loss in iteration no. 93566 ==> 0.4876657266977111\n",
            "Loss in iteration no. 93567 ==> 0.4876646985541635\n",
            "Loss in iteration no. 93568 ==> 0.4876636704201089\n",
            "Loss in iteration no. 93569 ==> 0.48766264229554723\n",
            "Loss in iteration no. 93570 ==> 0.48766161418047826\n",
            "Loss in iteration no. 93571 ==> 0.487660586074902\n",
            "Loss in iteration no. 93572 ==> 0.48765955797881805\n",
            "Loss in iteration no. 93573 ==> 0.4876585298922267\n",
            "Loss in iteration no. 93574 ==> 0.4876575018151274\n",
            "Loss in iteration no. 93575 ==> 0.48765647374752025\n",
            "Loss in iteration no. 93576 ==> 0.4876554456894053\n",
            "Loss in iteration no. 93577 ==> 0.4876544176407821\n",
            "Loss in iteration no. 93578 ==> 0.4876533896016506\n",
            "Loss in iteration no. 93579 ==> 0.48765236157201086\n",
            "Loss in iteration no. 93580 ==> 0.4876513335518626\n",
            "Loss in iteration no. 93581 ==> 0.48765030554120575\n",
            "Loss in iteration no. 93582 ==> 0.48764927754004\n",
            "Loss in iteration no. 93583 ==> 0.48764824954836555\n",
            "Loss in iteration no. 93584 ==> 0.48764722156618207\n",
            "Loss in iteration no. 93585 ==> 0.4876461935934895\n",
            "Loss in iteration no. 93586 ==> 0.4876451656302877\n",
            "Loss in iteration no. 93587 ==> 0.4876441376765766\n",
            "Loss in iteration no. 93588 ==> 0.487643109732356\n",
            "Loss in iteration no. 93589 ==> 0.4876420817976258\n",
            "Loss in iteration no. 93590 ==> 0.48764105387238593\n",
            "Loss in iteration no. 93591 ==> 0.4876400259566361\n",
            "Loss in iteration no. 93592 ==> 0.4876389980503763\n",
            "Loss in iteration no. 93593 ==> 0.4876379701536065\n",
            "Loss in iteration no. 93594 ==> 0.4876369422663264\n",
            "Loss in iteration no. 93595 ==> 0.487635914388536\n",
            "Loss in iteration no. 93596 ==> 0.48763488652023523\n",
            "Loss in iteration no. 93597 ==> 0.4876338586614238\n",
            "Loss in iteration no. 93598 ==> 0.4876328308121017\n",
            "Loss in iteration no. 93599 ==> 0.4876318029722686\n",
            "Loss in iteration no. 93600 ==> 0.48763077514192466\n",
            "Loss in iteration no. 93601 ==> 0.48762974732106973\n",
            "Loss in iteration no. 93602 ==> 0.48762871950970343\n",
            "Loss in iteration no. 93603 ==> 0.487627691707826\n",
            "Loss in iteration no. 93604 ==> 0.487626663915437\n",
            "Loss in iteration no. 93605 ==> 0.48762563613253646\n",
            "Loss in iteration no. 93606 ==> 0.4876246083591242\n",
            "Loss in iteration no. 93607 ==> 0.4876235805952001\n",
            "Loss in iteration no. 93608 ==> 0.48762255284076417\n",
            "Loss in iteration no. 93609 ==> 0.4876215250958161\n",
            "Loss in iteration no. 93610 ==> 0.4876204973603559\n",
            "Loss in iteration no. 93611 ==> 0.4876194696343834\n",
            "Loss in iteration no. 93612 ==> 0.48761844191789827\n",
            "Loss in iteration no. 93613 ==> 0.4876174142109007\n",
            "Loss in iteration no. 93614 ==> 0.48761638651339045\n",
            "Loss in iteration no. 93615 ==> 0.48761535882536744\n",
            "Loss in iteration no. 93616 ==> 0.4876143311468315\n",
            "Loss in iteration no. 93617 ==> 0.4876133034777825\n",
            "Loss in iteration no. 93618 ==> 0.48761227581822025\n",
            "Loss in iteration no. 93619 ==> 0.4876112481681448\n",
            "Loss in iteration no. 93620 ==> 0.487610220527556\n",
            "Loss in iteration no. 93621 ==> 0.4876091928964535\n",
            "Loss in iteration no. 93622 ==> 0.4876081652748373\n",
            "Loss in iteration no. 93623 ==> 0.4876071376627075\n",
            "Loss in iteration no. 93624 ==> 0.4876061100600637\n",
            "Loss in iteration no. 93625 ==> 0.48760508246690576\n",
            "Loss in iteration no. 93626 ==> 0.4876040548832338\n",
            "Loss in iteration no. 93627 ==> 0.4876030273090474\n",
            "Loss in iteration no. 93628 ==> 0.48760199974434676\n",
            "Loss in iteration no. 93629 ==> 0.48760097218913157\n",
            "Loss in iteration no. 93630 ==> 0.4875999446434017\n",
            "Loss in iteration no. 93631 ==> 0.487598917107157\n",
            "Loss in iteration no. 93632 ==> 0.48759788958039757\n",
            "Loss in iteration no. 93633 ==> 0.48759686206312297\n",
            "Loss in iteration no. 93634 ==> 0.4875958345553332\n",
            "Loss in iteration no. 93635 ==> 0.4875948070570282\n",
            "Loss in iteration no. 93636 ==> 0.48759377956820776\n",
            "Loss in iteration no. 93637 ==> 0.48759275208887193\n",
            "Loss in iteration no. 93638 ==> 0.4875917246190204\n",
            "Loss in iteration no. 93639 ==> 0.487590697158653\n",
            "Loss in iteration no. 93640 ==> 0.4875896697077699\n",
            "Loss in iteration no. 93641 ==> 0.4875886422663707\n",
            "Loss in iteration no. 93642 ==> 0.48758761483445534\n",
            "Loss in iteration no. 93643 ==> 0.4875865874120238\n",
            "Loss in iteration no. 93644 ==> 0.4875855599990758\n",
            "Loss in iteration no. 93645 ==> 0.4875845325956113\n",
            "Loss in iteration no. 93646 ==> 0.4875835052016303\n",
            "Loss in iteration no. 93647 ==> 0.48758247781713254\n",
            "Loss in iteration no. 93648 ==> 0.4875814504421177\n",
            "Loss in iteration no. 93649 ==> 0.4875804230765861\n",
            "Loss in iteration no. 93650 ==> 0.4875793957205374\n",
            "Loss in iteration no. 93651 ==> 0.4875783683739712\n",
            "Loss in iteration no. 93652 ==> 0.4875773410368878\n",
            "Loss in iteration no. 93653 ==> 0.4875763137092868\n",
            "Loss in iteration no. 93654 ==> 0.4875752863911683\n",
            "Loss in iteration no. 93655 ==> 0.4875742590825321\n",
            "Loss in iteration no. 93656 ==> 0.487573231783378\n",
            "Loss in iteration no. 93657 ==> 0.487572204493706\n",
            "Loss in iteration no. 93658 ==> 0.48757117721351567\n",
            "Loss in iteration no. 93659 ==> 0.4875701499428073\n",
            "Loss in iteration no. 93660 ==> 0.4875691226815806\n",
            "Loss in iteration no. 93661 ==> 0.48756809542983537\n",
            "Loss in iteration no. 93662 ==> 0.4875670681875714\n",
            "Loss in iteration no. 93663 ==> 0.48756604095478895\n",
            "Loss in iteration no. 93664 ==> 0.4875650137314876\n",
            "Loss in iteration no. 93665 ==> 0.48756398651766725\n",
            "Loss in iteration no. 93666 ==> 0.48756295931332777\n",
            "Loss in iteration no. 93667 ==> 0.4875619321184691\n",
            "Loss in iteration no. 93668 ==> 0.4875609049330911\n",
            "Loss in iteration no. 93669 ==> 0.4875598777571937\n",
            "Loss in iteration no. 93670 ==> 0.4875588505907767\n",
            "Loss in iteration no. 93671 ==> 0.48755782343383997\n",
            "Loss in iteration no. 93672 ==> 0.4875567962863833\n",
            "Loss in iteration no. 93673 ==> 0.4875557691484068\n",
            "Loss in iteration no. 93674 ==> 0.4875547420199103\n",
            "Loss in iteration no. 93675 ==> 0.48755371490089355\n",
            "Loss in iteration no. 93676 ==> 0.4875526877913564\n",
            "Loss in iteration no. 93677 ==> 0.48755166069129885\n",
            "Loss in iteration no. 93678 ==> 0.48755063360072076\n",
            "Loss in iteration no. 93679 ==> 0.48754960651962187\n",
            "Loss in iteration no. 93680 ==> 0.4875485794480024\n",
            "Loss in iteration no. 93681 ==> 0.4875475523858618\n",
            "Loss in iteration no. 93682 ==> 0.4875465253332002\n",
            "Loss in iteration no. 93683 ==> 0.4875454982900173\n",
            "Loss in iteration no. 93684 ==> 0.4875444712563132\n",
            "Loss in iteration no. 93685 ==> 0.4875434442320877\n",
            "Loss in iteration no. 93686 ==> 0.4875424172173406\n",
            "Loss in iteration no. 93687 ==> 0.4875413902120718\n",
            "Loss in iteration no. 93688 ==> 0.48754036321628136\n",
            "Loss in iteration no. 93689 ==> 0.48753933622996887\n",
            "Loss in iteration no. 93690 ==> 0.48753830925313435\n",
            "Loss in iteration no. 93691 ==> 0.48753728228577764\n",
            "Loss in iteration no. 93692 ==> 0.4875362553278987\n",
            "Loss in iteration no. 93693 ==> 0.4875352283794973\n",
            "Loss in iteration no. 93694 ==> 0.4875342014405733\n",
            "Loss in iteration no. 93695 ==> 0.48753317451112677\n",
            "Loss in iteration no. 93696 ==> 0.4875321475911575\n",
            "Loss in iteration no. 93697 ==> 0.4875311206806652\n",
            "Loss in iteration no. 93698 ==> 0.48753009377964984\n",
            "Loss in iteration no. 93699 ==> 0.4875290668881115\n",
            "Loss in iteration no. 93700 ==> 0.4875280400060497\n",
            "Loss in iteration no. 93701 ==> 0.4875270131334645\n",
            "Loss in iteration no. 93702 ==> 0.4875259862703559\n",
            "Loss in iteration no. 93703 ==> 0.4875249594167237\n",
            "Loss in iteration no. 93704 ==> 0.4875239325725676\n",
            "Loss in iteration no. 93705 ==> 0.48752290573788765\n",
            "Loss in iteration no. 93706 ==> 0.4875218789126836\n",
            "Loss in iteration no. 93707 ==> 0.48752085209695556\n",
            "Loss in iteration no. 93708 ==> 0.48751982529070326\n",
            "Loss in iteration no. 93709 ==> 0.4875187984939265\n",
            "Loss in iteration no. 93710 ==> 0.48751777170662525\n",
            "Loss in iteration no. 93711 ==> 0.4875167449287993\n",
            "Loss in iteration no. 93712 ==> 0.4875157181604487\n",
            "Loss in iteration no. 93713 ==> 0.4875146914015732\n",
            "Loss in iteration no. 93714 ==> 0.4875136646521727\n",
            "Loss in iteration no. 93715 ==> 0.4875126379122471\n",
            "Loss in iteration no. 93716 ==> 0.4875116111817962\n",
            "Loss in iteration no. 93717 ==> 0.4875105844608199\n",
            "Loss in iteration no. 93718 ==> 0.48750955774931837\n",
            "Loss in iteration no. 93719 ==> 0.48750853104729086\n",
            "Loss in iteration no. 93720 ==> 0.48750750435473783\n",
            "Loss in iteration no. 93721 ==> 0.4875064776716589\n",
            "Loss in iteration no. 93722 ==> 0.48750545099805404\n",
            "Loss in iteration no. 93723 ==> 0.48750442433392294\n",
            "Loss in iteration no. 93724 ==> 0.4875033976792657\n",
            "Loss in iteration no. 93725 ==> 0.48750237103408217\n",
            "Loss in iteration no. 93726 ==> 0.4875013443983721\n",
            "Loss in iteration no. 93727 ==> 0.48750031777213537\n",
            "Loss in iteration no. 93728 ==> 0.487499291155372\n",
            "Loss in iteration no. 93729 ==> 0.4874982645480817\n",
            "Loss in iteration no. 93730 ==> 0.4874972379502645\n",
            "Loss in iteration no. 93731 ==> 0.48749621136192023\n",
            "Loss in iteration no. 93732 ==> 0.48749518478304865\n",
            "Loss in iteration no. 93733 ==> 0.48749415821364983\n",
            "Loss in iteration no. 93734 ==> 0.48749313165372343\n",
            "Loss in iteration no. 93735 ==> 0.4874921051032696\n",
            "Loss in iteration no. 93736 ==> 0.487491078562288\n",
            "Loss in iteration no. 93737 ==> 0.4874900520307786\n",
            "Loss in iteration no. 93738 ==> 0.48748902550874124\n",
            "Loss in iteration no. 93739 ==> 0.48748799899617573\n",
            "Loss in iteration no. 93740 ==> 0.4874869724930821\n",
            "Loss in iteration no. 93741 ==> 0.48748594599946005\n",
            "Loss in iteration no. 93742 ==> 0.48748491951530976\n",
            "Loss in iteration no. 93743 ==> 0.4874838930406307\n",
            "Loss in iteration no. 93744 ==> 0.4874828665754231\n",
            "Loss in iteration no. 93745 ==> 0.4874818401196866\n",
            "Loss in iteration no. 93746 ==> 0.48748081367342116\n",
            "Loss in iteration no. 93747 ==> 0.4874797872366267\n",
            "Loss in iteration no. 93748 ==> 0.48747876080930297\n",
            "Loss in iteration no. 93749 ==> 0.4874777343914501\n",
            "Loss in iteration no. 93750 ==> 0.48747670798306775\n",
            "Loss in iteration no. 93751 ==> 0.4874756815841557\n",
            "Loss in iteration no. 93752 ==> 0.4874746551947142\n",
            "Loss in iteration no. 93753 ==> 0.4874736288147427\n",
            "Loss in iteration no. 93754 ==> 0.4874726024442414\n",
            "Loss in iteration no. 93755 ==> 0.48747157608321\n",
            "Loss in iteration no. 93756 ==> 0.48747054973164844\n",
            "Loss in iteration no. 93757 ==> 0.48746952338955657\n",
            "Loss in iteration no. 93758 ==> 0.4874684970569344\n",
            "Loss in iteration no. 93759 ==> 0.48746747073378155\n",
            "Loss in iteration no. 93760 ==> 0.48746644442009823\n",
            "Loss in iteration no. 93761 ==> 0.487465418115884\n",
            "Loss in iteration no. 93762 ==> 0.4874643918211388\n",
            "Loss in iteration no. 93763 ==> 0.4874633655358627\n",
            "Loss in iteration no. 93764 ==> 0.48746233926005555\n",
            "Loss in iteration no. 93765 ==> 0.487461312993717\n",
            "Loss in iteration no. 93766 ==> 0.48746028673684694\n",
            "Loss in iteration no. 93767 ==> 0.48745926048944554\n",
            "Loss in iteration no. 93768 ==> 0.4874582342515124\n",
            "Loss in iteration no. 93769 ==> 0.48745720802304743\n",
            "Loss in iteration no. 93770 ==> 0.4874561818040507\n",
            "Loss in iteration no. 93771 ==> 0.4874551555945219\n",
            "Loss in iteration no. 93772 ==> 0.4874541293944611\n",
            "Loss in iteration no. 93773 ==> 0.48745310320386787\n",
            "Loss in iteration no. 93774 ==> 0.4874520770227423\n",
            "Loss in iteration no. 93775 ==> 0.48745105085108414\n",
            "Loss in iteration no. 93776 ==> 0.48745002468889365\n",
            "Loss in iteration no. 93777 ==> 0.48744899853617013\n",
            "Loss in iteration no. 93778 ==> 0.4874479723929138\n",
            "Loss in iteration no. 93779 ==> 0.48744694625912455\n",
            "Loss in iteration no. 93780 ==> 0.4874459201348022\n",
            "Loss in iteration no. 93781 ==> 0.48744489401994656\n",
            "Loss in iteration no. 93782 ==> 0.4874438679145576\n",
            "Loss in iteration no. 93783 ==> 0.48744284181863506\n",
            "Loss in iteration no. 93784 ==> 0.487441815732179\n",
            "Loss in iteration no. 93785 ==> 0.4874407896551892\n",
            "Loss in iteration no. 93786 ==> 0.4874397635876654\n",
            "Loss in iteration no. 93787 ==> 0.4874387375296078\n",
            "Loss in iteration no. 93788 ==> 0.48743771148101606\n",
            "Loss in iteration no. 93789 ==> 0.4874366854418901\n",
            "Loss in iteration no. 93790 ==> 0.4874356594122297\n",
            "Loss in iteration no. 93791 ==> 0.487434633392035\n",
            "Loss in iteration no. 93792 ==> 0.48743360738130553\n",
            "Loss in iteration no. 93793 ==> 0.4874325813800414\n",
            "Loss in iteration no. 93794 ==> 0.48743155538824257\n",
            "Loss in iteration no. 93795 ==> 0.48743052940590864\n",
            "Loss in iteration no. 93796 ==> 0.4874295034330396\n",
            "Loss in iteration no. 93797 ==> 0.48742847746963547\n",
            "Loss in iteration no. 93798 ==> 0.487427451515696\n",
            "Loss in iteration no. 93799 ==> 0.48742642557122096\n",
            "Loss in iteration no. 93800 ==> 0.48742539963621045\n",
            "Loss in iteration no. 93801 ==> 0.4874243737106642\n",
            "Loss in iteration no. 93802 ==> 0.4874233477945822\n",
            "Loss in iteration no. 93803 ==> 0.4874223218879642\n",
            "Loss in iteration no. 93804 ==> 0.4874212959908101\n",
            "Loss in iteration no. 93805 ==> 0.48742027010311983\n",
            "Loss in iteration no. 93806 ==> 0.4874192442248933\n",
            "Loss in iteration no. 93807 ==> 0.48741821835613025\n",
            "Loss in iteration no. 93808 ==> 0.48741719249683074\n",
            "Loss in iteration no. 93809 ==> 0.4874161666469945\n",
            "Loss in iteration no. 93810 ==> 0.48741514080662146\n",
            "Loss in iteration no. 93811 ==> 0.48741411497571147\n",
            "Loss in iteration no. 93812 ==> 0.4874130891542645\n",
            "Loss in iteration no. 93813 ==> 0.4874120633422802\n",
            "Loss in iteration no. 93814 ==> 0.4874110375397588\n",
            "Loss in iteration no. 93815 ==> 0.4874100117466999\n",
            "Loss in iteration no. 93816 ==> 0.4874089859631034\n",
            "Loss in iteration no. 93817 ==> 0.48740796018896926\n",
            "Loss in iteration no. 93818 ==> 0.4874069344242974\n",
            "Loss in iteration no. 93819 ==> 0.4874059086690877\n",
            "Loss in iteration no. 93820 ==> 0.4874048829233398\n",
            "Loss in iteration no. 93821 ==> 0.48740385718705376\n",
            "Loss in iteration no. 93822 ==> 0.48740283146022956\n",
            "Loss in iteration no. 93823 ==> 0.48740180574286696\n",
            "Loss in iteration no. 93824 ==> 0.48740078003496573\n",
            "Loss in iteration no. 93825 ==> 0.48739975433652594\n",
            "Loss in iteration no. 93826 ==> 0.48739872864754724\n",
            "Loss in iteration no. 93827 ==> 0.4873977029680298\n",
            "Loss in iteration no. 93828 ==> 0.4873966772979733\n",
            "Loss in iteration no. 93829 ==> 0.4873956516373777\n",
            "Loss in iteration no. 93830 ==> 0.48739462598624267\n",
            "Loss in iteration no. 93831 ==> 0.4873936003445685\n",
            "Loss in iteration no. 93832 ==> 0.4873925747123547\n",
            "Loss in iteration no. 93833 ==> 0.4873915490896012\n",
            "Loss in iteration no. 93834 ==> 0.487390523476308\n",
            "Loss in iteration no. 93835 ==> 0.4873894978724751\n",
            "Loss in iteration no. 93836 ==> 0.48738847227810195\n",
            "Loss in iteration no. 93837 ==> 0.48738744669318873\n",
            "Loss in iteration no. 93838 ==> 0.48738642111773534\n",
            "Loss in iteration no. 93839 ==> 0.48738539555174165\n",
            "Loss in iteration no. 93840 ==> 0.48738436999520734\n",
            "Loss in iteration no. 93841 ==> 0.48738334444813247\n",
            "Loss in iteration no. 93842 ==> 0.4873823189105169\n",
            "Loss in iteration no. 93843 ==> 0.48738129338236047\n",
            "Loss in iteration no. 93844 ==> 0.48738026786366295\n",
            "Loss in iteration no. 93845 ==> 0.4873792423544244\n",
            "Loss in iteration no. 93846 ==> 0.48737821685464466\n",
            "Loss in iteration no. 93847 ==> 0.4873771913643236\n",
            "Loss in iteration no. 93848 ==> 0.4873761658834609\n",
            "Loss in iteration no. 93849 ==> 0.4873751404120568\n",
            "Loss in iteration no. 93850 ==> 0.4873741149501109\n",
            "Loss in iteration no. 93851 ==> 0.48737308949762315\n",
            "Loss in iteration no. 93852 ==> 0.4873720640545935\n",
            "Loss in iteration no. 93853 ==> 0.4873710386210217\n",
            "Loss in iteration no. 93854 ==> 0.48737001319690765\n",
            "Loss in iteration no. 93855 ==> 0.48736898778225146\n",
            "Loss in iteration no. 93856 ==> 0.4873679623770526\n",
            "Loss in iteration no. 93857 ==> 0.4873669369813113\n",
            "Loss in iteration no. 93858 ==> 0.48736591159502723\n",
            "Loss in iteration no. 93859 ==> 0.4873648862182004\n",
            "Loss in iteration no. 93860 ==> 0.4873638608508305\n",
            "Loss in iteration no. 93861 ==> 0.48736283549291765\n",
            "Loss in iteration no. 93862 ==> 0.4873618101444616\n",
            "Loss in iteration no. 93863 ==> 0.48736078480546213\n",
            "Loss in iteration no. 93864 ==> 0.48735975947591936\n",
            "Loss in iteration no. 93865 ==> 0.48735873415583303\n",
            "Loss in iteration no. 93866 ==> 0.487357708845203\n",
            "Loss in iteration no. 93867 ==> 0.48735668354402906\n",
            "Loss in iteration no. 93868 ==> 0.48735565825231125\n",
            "Loss in iteration no. 93869 ==> 0.48735463297004944\n",
            "Loss in iteration no. 93870 ==> 0.48735360769724356\n",
            "Loss in iteration no. 93871 ==> 0.48735258243389323\n",
            "Loss in iteration no. 93872 ==> 0.4873515571799985\n",
            "Loss in iteration no. 93873 ==> 0.4873505319355593\n",
            "Loss in iteration no. 93874 ==> 0.48734950670057536\n",
            "Loss in iteration no. 93875 ==> 0.4873484814750468\n",
            "Loss in iteration no. 93876 ==> 0.487347456258973\n",
            "Loss in iteration no. 93877 ==> 0.4873464310523545\n",
            "Loss in iteration no. 93878 ==> 0.48734540585519065\n",
            "Loss in iteration no. 93879 ==> 0.48734438066748165\n",
            "Loss in iteration no. 93880 ==> 0.48734335548922714\n",
            "Loss in iteration no. 93881 ==> 0.4873423303204271\n",
            "Loss in iteration no. 93882 ==> 0.48734130516108154\n",
            "Loss in iteration no. 93883 ==> 0.48734028001119006\n",
            "Loss in iteration no. 93884 ==> 0.48733925487075275\n",
            "Loss in iteration no. 93885 ==> 0.4873382297397695\n",
            "Loss in iteration no. 93886 ==> 0.48733720461824015\n",
            "Loss in iteration no. 93887 ==> 0.4873361795061644\n",
            "Loss in iteration no. 93888 ==> 0.48733515440354236\n",
            "Loss in iteration no. 93889 ==> 0.4873341293103738\n",
            "Loss in iteration no. 93890 ==> 0.4873331042266586\n",
            "Loss in iteration no. 93891 ==> 0.4873320791523966\n",
            "Loss in iteration no. 93892 ==> 0.48733105408758776\n",
            "Loss in iteration no. 93893 ==> 0.48733002903223205\n",
            "Loss in iteration no. 93894 ==> 0.48732900398632906\n",
            "Loss in iteration no. 93895 ==> 0.48732797894987895\n",
            "Loss in iteration no. 93896 ==> 0.4873269539228815\n",
            "Loss in iteration no. 93897 ==> 0.48732592890533644\n",
            "Loss in iteration no. 93898 ==> 0.48732490389724376\n",
            "Loss in iteration no. 93899 ==> 0.4873238788986034\n",
            "Loss in iteration no. 93900 ==> 0.48732285390941527\n",
            "Loss in iteration no. 93901 ==> 0.48732182892967907\n",
            "Loss in iteration no. 93902 ==> 0.4873208039593948\n",
            "Loss in iteration no. 93903 ==> 0.4873197789985624\n",
            "Loss in iteration no. 93904 ==> 0.48731875404718145\n",
            "Loss in iteration no. 93905 ==> 0.4873177291052522\n",
            "Loss in iteration no. 93906 ==> 0.4873167041727744\n",
            "Loss in iteration no. 93907 ==> 0.4873156792497478\n",
            "Loss in iteration no. 93908 ==> 0.48731465433617227\n",
            "Loss in iteration no. 93909 ==> 0.4873136294320479\n",
            "Loss in iteration no. 93910 ==> 0.4873126045373744\n",
            "Loss in iteration no. 93911 ==> 0.48731157965215177\n",
            "Loss in iteration no. 93912 ==> 0.4873105547763798\n",
            "Loss in iteration no. 93913 ==> 0.4873095299100583\n",
            "Loss in iteration no. 93914 ==> 0.4873085050531874\n",
            "Loss in iteration no. 93915 ==> 0.48730748020576664\n",
            "Loss in iteration no. 93916 ==> 0.4873064553677961\n",
            "Loss in iteration no. 93917 ==> 0.4873054305392756\n",
            "Loss in iteration no. 93918 ==> 0.48730440572020517\n",
            "Loss in iteration no. 93919 ==> 0.48730338091058445\n",
            "Loss in iteration no. 93920 ==> 0.4873023561104135\n",
            "Loss in iteration no. 93921 ==> 0.48730133131969205\n",
            "Loss in iteration no. 93922 ==> 0.4873003065384201\n",
            "Loss in iteration no. 93923 ==> 0.48729928176659737\n",
            "Loss in iteration no. 93924 ==> 0.4872982570042239\n",
            "Loss in iteration no. 93925 ==> 0.4872972322512997\n",
            "Loss in iteration no. 93926 ==> 0.48729620750782426\n",
            "Loss in iteration no. 93927 ==> 0.4872951827737976\n",
            "Loss in iteration no. 93928 ==> 0.48729415804921977\n",
            "Loss in iteration no. 93929 ==> 0.48729313333409063\n",
            "Loss in iteration no. 93930 ==> 0.4872921086284098\n",
            "Loss in iteration no. 93931 ==> 0.48729108393217735\n",
            "Loss in iteration no. 93932 ==> 0.4872900592453929\n",
            "Loss in iteration no. 93933 ==> 0.4872890345680569\n",
            "Loss in iteration no. 93934 ==> 0.48728800990016874\n",
            "Loss in iteration no. 93935 ==> 0.4872869852417284\n",
            "Loss in iteration no. 93936 ==> 0.487285960592736\n",
            "Loss in iteration no. 93937 ==> 0.487284935953191\n",
            "Loss in iteration no. 93938 ==> 0.4872839113230935\n",
            "Loss in iteration no. 93939 ==> 0.48728288670244346\n",
            "Loss in iteration no. 93940 ==> 0.4872818620912405\n",
            "Loss in iteration no. 93941 ==> 0.48728083748948486\n",
            "Loss in iteration no. 93942 ==> 0.48727981289717615\n",
            "Loss in iteration no. 93943 ==> 0.4872787883143142\n",
            "Loss in iteration no. 93944 ==> 0.4872777637408992\n",
            "Loss in iteration no. 93945 ==> 0.48727673917693065\n",
            "Loss in iteration no. 93946 ==> 0.48727571462240876\n",
            "Loss in iteration no. 93947 ==> 0.4872746900773331\n",
            "Loss in iteration no. 93948 ==> 0.48727366554170376\n",
            "Loss in iteration no. 93949 ==> 0.4872726410155206\n",
            "Loss in iteration no. 93950 ==> 0.4872716164987835\n",
            "Loss in iteration no. 93951 ==> 0.48727059199149214\n",
            "Loss in iteration no. 93952 ==> 0.48726956749364664\n",
            "Loss in iteration no. 93953 ==> 0.4872685430052468\n",
            "Loss in iteration no. 93954 ==> 0.4872675185262925\n",
            "Loss in iteration no. 93955 ==> 0.4872664940567836\n",
            "Loss in iteration no. 93956 ==> 0.48726546959671996\n",
            "Loss in iteration no. 93957 ==> 0.4872644451461014\n",
            "Loss in iteration no. 93958 ==> 0.48726342070492806\n",
            "Loss in iteration no. 93959 ==> 0.48726239627319945\n",
            "Loss in iteration no. 93960 ==> 0.48726137185091584\n",
            "Loss in iteration no. 93961 ==> 0.48726034743807667\n",
            "Loss in iteration no. 93962 ==> 0.48725932303468217\n",
            "Loss in iteration no. 93963 ==> 0.4872582986407321\n",
            "Loss in iteration no. 93964 ==> 0.4872572742562263\n",
            "Loss in iteration no. 93965 ==> 0.48725624988116456\n",
            "Loss in iteration no. 93966 ==> 0.48725522551554706\n",
            "Loss in iteration no. 93967 ==> 0.48725420115937346\n",
            "Loss in iteration no. 93968 ==> 0.48725317681264363\n",
            "Loss in iteration no. 93969 ==> 0.4872521524753575\n",
            "Loss in iteration no. 93970 ==> 0.487251128147515\n",
            "Loss in iteration no. 93971 ==> 0.4872501038291158\n",
            "Loss in iteration no. 93972 ==> 0.48724907952015994\n",
            "Loss in iteration no. 93973 ==> 0.48724805522064735\n",
            "Loss in iteration no. 93974 ==> 0.4872470309305779\n",
            "Loss in iteration no. 93975 ==> 0.4872460066499514\n",
            "Loss in iteration no. 93976 ==> 0.4872449823787677\n",
            "Loss in iteration no. 93977 ==> 0.4872439581170266\n",
            "Loss in iteration no. 93978 ==> 0.4872429338647281\n",
            "Loss in iteration no. 93979 ==> 0.4872419096218721\n",
            "Loss in iteration no. 93980 ==> 0.48724088538845856\n",
            "Loss in iteration no. 93981 ==> 0.48723986116448703\n",
            "Loss in iteration no. 93982 ==> 0.48723883694995784\n",
            "Loss in iteration no. 93983 ==> 0.4872378127448705\n",
            "Loss in iteration no. 93984 ==> 0.487236788549225\n",
            "Loss in iteration no. 93985 ==> 0.4872357643630213\n",
            "Loss in iteration no. 93986 ==> 0.48723474018625895\n",
            "Loss in iteration no. 93987 ==> 0.4872337160189384\n",
            "Loss in iteration no. 93988 ==> 0.4872326918610591\n",
            "Loss in iteration no. 93989 ==> 0.48723166771262094\n",
            "Loss in iteration no. 93990 ==> 0.487230643573624\n",
            "Loss in iteration no. 93991 ==> 0.48722961944406795\n",
            "Loss in iteration no. 93992 ==> 0.48722859532395285\n",
            "Loss in iteration no. 93993 ==> 0.48722757121327853\n",
            "Loss in iteration no. 93994 ==> 0.48722654711204477\n",
            "Loss in iteration no. 93995 ==> 0.4872255230202517\n",
            "Loss in iteration no. 93996 ==> 0.4872244989378988\n",
            "Loss in iteration no. 93997 ==> 0.4872234748649862\n",
            "Loss in iteration no. 93998 ==> 0.4872224508015137\n",
            "Loss in iteration no. 93999 ==> 0.48722142674748137\n",
            "Loss in iteration no. 94000 ==> 0.4872204027028888\n",
            "Loss in iteration no. 94001 ==> 0.4872193786677361\n",
            "Loss in iteration no. 94002 ==> 0.48721835464202284\n",
            "Loss in iteration no. 94003 ==> 0.48721733062574935\n",
            "Loss in iteration no. 94004 ==> 0.48721630661891513\n",
            "Loss in iteration no. 94005 ==> 0.48721528262152014\n",
            "Loss in iteration no. 94006 ==> 0.48721425863356443\n",
            "Loss in iteration no. 94007 ==> 0.4872132346550478\n",
            "Loss in iteration no. 94008 ==> 0.48721221068596987\n",
            "Loss in iteration no. 94009 ==> 0.4872111867263309\n",
            "Loss in iteration no. 94010 ==> 0.4872101627761305\n",
            "Loss in iteration no. 94011 ==> 0.4872091388353687\n",
            "Loss in iteration no. 94012 ==> 0.4872081149040453\n",
            "Loss in iteration no. 94013 ==> 0.48720709098216025\n",
            "Loss in iteration no. 94014 ==> 0.4872060670697133\n",
            "Loss in iteration no. 94015 ==> 0.48720504316670443\n",
            "Loss in iteration no. 94016 ==> 0.48720401927313356\n",
            "Loss in iteration no. 94017 ==> 0.48720299538900047\n",
            "Loss in iteration no. 94018 ==> 0.487201971514305\n",
            "Loss in iteration no. 94019 ==> 0.4872009476490471\n",
            "Loss in iteration no. 94020 ==> 0.48719992379322674\n",
            "Loss in iteration no. 94021 ==> 0.4871988999468436\n",
            "Loss in iteration no. 94022 ==> 0.48719787610989773\n",
            "Loss in iteration no. 94023 ==> 0.4871968522823889\n",
            "Loss in iteration no. 94024 ==> 0.48719582846431714\n",
            "Loss in iteration no. 94025 ==> 0.48719480465568193\n",
            "Loss in iteration no. 94026 ==> 0.4871937808564836\n",
            "Loss in iteration no. 94027 ==> 0.48719275706672194\n",
            "Loss in iteration no. 94028 ==> 0.48719173328639653\n",
            "Loss in iteration no. 94029 ==> 0.4871907095155077\n",
            "Loss in iteration no. 94030 ==> 0.487189685754055\n",
            "Loss in iteration no. 94031 ==> 0.4871886620020384\n",
            "Loss in iteration no. 94032 ==> 0.48718763825945766\n",
            "Loss in iteration no. 94033 ==> 0.48718661452631296\n",
            "Loss in iteration no. 94034 ==> 0.48718559080260393\n",
            "Loss in iteration no. 94035 ==> 0.48718456708833047\n",
            "Loss in iteration no. 94036 ==> 0.48718354338349246\n",
            "Loss in iteration no. 94037 ==> 0.4871825196880898\n",
            "Loss in iteration no. 94038 ==> 0.4871814960021224\n",
            "Loss in iteration no. 94039 ==> 0.4871804723255902\n",
            "Loss in iteration no. 94040 ==> 0.487179448658493\n",
            "Loss in iteration no. 94041 ==> 0.48717842500083053\n",
            "Loss in iteration no. 94042 ==> 0.48717740135260285\n",
            "Loss in iteration no. 94043 ==> 0.48717637771380995\n",
            "Loss in iteration no. 94044 ==> 0.4871753540844514\n",
            "Loss in iteration no. 94045 ==> 0.4871743304645273\n",
            "Loss in iteration no. 94046 ==> 0.4871733068540374\n",
            "Loss in iteration no. 94047 ==> 0.48717228325298173\n",
            "Loss in iteration no. 94048 ==> 0.48717125966136005\n",
            "Loss in iteration no. 94049 ==> 0.4871702360791722\n",
            "Loss in iteration no. 94050 ==> 0.48716921250641815\n",
            "Loss in iteration no. 94051 ==> 0.48716818894309777\n",
            "Loss in iteration no. 94052 ==> 0.48716716538921095\n",
            "Loss in iteration no. 94053 ==> 0.48716614184475754\n",
            "Loss in iteration no. 94054 ==> 0.48716511830973735\n",
            "Loss in iteration no. 94055 ==> 0.48716409478415035\n",
            "Loss in iteration no. 94056 ==> 0.4871630712679962\n",
            "Loss in iteration no. 94057 ==> 0.48716204776127525\n",
            "Loss in iteration no. 94058 ==> 0.487161024263987\n",
            "Loss in iteration no. 94059 ==> 0.48716000077613136\n",
            "Loss in iteration no. 94060 ==> 0.4871589772977083\n",
            "Loss in iteration no. 94061 ==> 0.48715795382871774\n",
            "Loss in iteration no. 94062 ==> 0.4871569303691593\n",
            "Loss in iteration no. 94063 ==> 0.4871559069190332\n",
            "Loss in iteration no. 94064 ==> 0.48715488347833924\n",
            "Loss in iteration no. 94065 ==> 0.48715386004707695\n",
            "Loss in iteration no. 94066 ==> 0.4871528366252467\n",
            "Loss in iteration no. 94067 ==> 0.487151813212848\n",
            "Loss in iteration no. 94068 ==> 0.4871507898098811\n",
            "Loss in iteration no. 94069 ==> 0.4871497664163454\n",
            "Loss in iteration no. 94070 ==> 0.48714874303224104\n",
            "Loss in iteration no. 94071 ==> 0.487147719657568\n",
            "Loss in iteration no. 94072 ==> 0.48714669629232604\n",
            "Loss in iteration no. 94073 ==> 0.4871456729365149\n",
            "Loss in iteration no. 94074 ==> 0.48714464959013465\n",
            "Loss in iteration no. 94075 ==> 0.48714362625318514\n",
            "Loss in iteration no. 94076 ==> 0.48714260292566625\n",
            "Loss in iteration no. 94077 ==> 0.4871415796075778\n",
            "Loss in iteration no. 94078 ==> 0.48714055629891967\n",
            "Loss in iteration no. 94079 ==> 0.48713953299969187\n",
            "Loss in iteration no. 94080 ==> 0.48713850970989403\n",
            "Loss in iteration no. 94081 ==> 0.4871374864295263\n",
            "Loss in iteration no. 94082 ==> 0.4871364631585883\n",
            "Loss in iteration no. 94083 ==> 0.4871354398970802\n",
            "Loss in iteration no. 94084 ==> 0.48713441664500157\n",
            "Loss in iteration no. 94085 ==> 0.48713339340235257\n",
            "Loss in iteration no. 94086 ==> 0.4871323701691327\n",
            "Loss in iteration no. 94087 ==> 0.4871313469453422\n",
            "Loss in iteration no. 94088 ==> 0.4871303237309809\n",
            "Loss in iteration no. 94089 ==> 0.48712930052604864\n",
            "Loss in iteration no. 94090 ==> 0.4871282773305451\n",
            "Loss in iteration no. 94091 ==> 0.4871272541444704\n",
            "Loss in iteration no. 94092 ==> 0.4871262309678243\n",
            "Loss in iteration no. 94093 ==> 0.48712520780060675\n",
            "Loss in iteration no. 94094 ==> 0.4871241846428176\n",
            "Loss in iteration no. 94095 ==> 0.48712316149445667\n",
            "Loss in iteration no. 94096 ==> 0.48712213835552387\n",
            "Loss in iteration no. 94097 ==> 0.4871211152260192\n",
            "Loss in iteration no. 94098 ==> 0.48712009210594237\n",
            "Loss in iteration no. 94099 ==> 0.4871190689952933\n",
            "Loss in iteration no. 94100 ==> 0.48711804589407187\n",
            "Loss in iteration no. 94101 ==> 0.487117022802278\n",
            "Loss in iteration no. 94102 ==> 0.48711599971991154\n",
            "Loss in iteration no. 94103 ==> 0.48711497664697234\n",
            "Loss in iteration no. 94104 ==> 0.4871139535834604\n",
            "Loss in iteration no. 94105 ==> 0.4871129305293754\n",
            "Loss in iteration no. 94106 ==> 0.48711190748471744\n",
            "Loss in iteration no. 94107 ==> 0.4871108844494863\n",
            "Loss in iteration no. 94108 ==> 0.4871098614236816\n",
            "Loss in iteration no. 94109 ==> 0.4871088384073037\n",
            "Loss in iteration no. 94110 ==> 0.48710781540035214\n",
            "Loss in iteration no. 94111 ==> 0.4871067924028269\n",
            "Loss in iteration no. 94112 ==> 0.48710576941472783\n",
            "Loss in iteration no. 94113 ==> 0.48710474643605484\n",
            "Loss in iteration no. 94114 ==> 0.48710372346680786\n",
            "Loss in iteration no. 94115 ==> 0.4871027005069866\n",
            "Loss in iteration no. 94116 ==> 0.48710167755659106\n",
            "Loss in iteration no. 94117 ==> 0.4871006546156212\n",
            "Loss in iteration no. 94118 ==> 0.48709963168407666\n",
            "Loss in iteration no. 94119 ==> 0.48709860876195754\n",
            "Loss in iteration no. 94120 ==> 0.4870975858492635\n",
            "Loss in iteration no. 94121 ==> 0.4870965629459947\n",
            "Loss in iteration no. 94122 ==> 0.487095540052151\n",
            "Loss in iteration no. 94123 ==> 0.48709451716773194\n",
            "Loss in iteration no. 94124 ==> 0.4870934942927376\n",
            "Loss in iteration no. 94125 ==> 0.4870924714271679\n",
            "Loss in iteration no. 94126 ==> 0.4870914485710227\n",
            "Loss in iteration no. 94127 ==> 0.48709042572430183\n",
            "Loss in iteration no. 94128 ==> 0.48708940288700525\n",
            "Loss in iteration no. 94129 ==> 0.4870883800591327\n",
            "Loss in iteration no. 94130 ==> 0.48708735724068414\n",
            "Loss in iteration no. 94131 ==> 0.48708633443165955\n",
            "Loss in iteration no. 94132 ==> 0.4870853116320586\n",
            "Loss in iteration no. 94133 ==> 0.4870842888418813\n",
            "Loss in iteration no. 94134 ==> 0.4870832660611275\n",
            "Loss in iteration no. 94135 ==> 0.4870822432897971\n",
            "Loss in iteration no. 94136 ==> 0.48708122052789\n",
            "Loss in iteration no. 94137 ==> 0.48708019777540607\n",
            "Loss in iteration no. 94138 ==> 0.487079175032345\n",
            "Loss in iteration no. 94139 ==> 0.4870781522987069\n",
            "Loss in iteration no. 94140 ==> 0.48707712957449145\n",
            "Loss in iteration no. 94141 ==> 0.4870761068596989\n",
            "Loss in iteration no. 94142 ==> 0.48707508415432876\n",
            "Loss in iteration no. 94143 ==> 0.487074061458381\n",
            "Loss in iteration no. 94144 ==> 0.4870730387718555\n",
            "Loss in iteration no. 94145 ==> 0.4870720160947522\n",
            "Loss in iteration no. 94146 ==> 0.48707099342707094\n",
            "Loss in iteration no. 94147 ==> 0.4870699707688116\n",
            "Loss in iteration no. 94148 ==> 0.48706894811997387\n",
            "Loss in iteration no. 94149 ==> 0.48706792548055805\n",
            "Loss in iteration no. 94150 ==> 0.48706690285056375\n",
            "Loss in iteration no. 94151 ==> 0.48706588022999076\n",
            "Loss in iteration no. 94152 ==> 0.4870648576188391\n",
            "Loss in iteration no. 94153 ==> 0.4870638350171087\n",
            "Loss in iteration no. 94154 ==> 0.48706281242479926\n",
            "Loss in iteration no. 94155 ==> 0.4870617898419108\n",
            "Loss in iteration no. 94156 ==> 0.4870607672684431\n",
            "Loss in iteration no. 94157 ==> 0.48705974470439617\n",
            "Loss in iteration no. 94158 ==> 0.4870587221497699\n",
            "Loss in iteration no. 94159 ==> 0.4870576996045639\n",
            "Loss in iteration no. 94160 ==> 0.48705667706877837\n",
            "Loss in iteration no. 94161 ==> 0.487055654542413\n",
            "Loss in iteration no. 94162 ==> 0.4870546320254677\n",
            "Loss in iteration no. 94163 ==> 0.48705360951794235\n",
            "Loss in iteration no. 94164 ==> 0.4870525870198369\n",
            "Loss in iteration no. 94165 ==> 0.48705156453115095\n",
            "Loss in iteration no. 94166 ==> 0.4870505420518847\n",
            "Loss in iteration no. 94167 ==> 0.48704951958203807\n",
            "Loss in iteration no. 94168 ==> 0.48704849712161064\n",
            "Loss in iteration no. 94169 ==> 0.4870474746706026\n",
            "Loss in iteration no. 94170 ==> 0.48704645222901344\n",
            "Loss in iteration no. 94171 ==> 0.48704542979684345\n",
            "Loss in iteration no. 94172 ==> 0.48704440737409227\n",
            "Loss in iteration no. 94173 ==> 0.48704338496075966\n",
            "Loss in iteration no. 94174 ==> 0.48704236255684585\n",
            "Loss in iteration no. 94175 ==> 0.48704134016235057\n",
            "Loss in iteration no. 94176 ==> 0.4870403177772735\n",
            "Loss in iteration no. 94177 ==> 0.4870392954016149\n",
            "Loss in iteration no. 94178 ==> 0.48703827303537434\n",
            "Loss in iteration no. 94179 ==> 0.48703725067855164\n",
            "Loss in iteration no. 94180 ==> 0.4870362283311469\n",
            "Loss in iteration no. 94181 ==> 0.48703520599316\n",
            "Loss in iteration no. 94182 ==> 0.48703418366459067\n",
            "Loss in iteration no. 94183 ==> 0.4870331613454389\n",
            "Loss in iteration no. 94184 ==> 0.4870321390357045\n",
            "Loss in iteration no. 94185 ==> 0.4870311167353874\n",
            "Loss in iteration no. 94186 ==> 0.4870300944444875\n",
            "Loss in iteration no. 94187 ==> 0.48702907216300456\n",
            "Loss in iteration no. 94188 ==> 0.48702804989093856\n",
            "Loss in iteration no. 94189 ==> 0.48702702762828926\n",
            "Loss in iteration no. 94190 ==> 0.48702600537505675\n",
            "Loss in iteration no. 94191 ==> 0.4870249831312407\n",
            "Loss in iteration no. 94192 ==> 0.4870239608968411\n",
            "Loss in iteration no. 94193 ==> 0.48702293867185764\n",
            "Loss in iteration no. 94194 ==> 0.4870219164562906\n",
            "Loss in iteration no. 94195 ==> 0.48702089425013956\n",
            "Loss in iteration no. 94196 ==> 0.4870198720534044\n",
            "Loss in iteration no. 94197 ==> 0.48701884986608507\n",
            "Loss in iteration no. 94198 ==> 0.48701782768818147\n",
            "Loss in iteration no. 94199 ==> 0.4870168055196934\n",
            "Loss in iteration no. 94200 ==> 0.48701578336062074\n",
            "Loss in iteration no. 94201 ==> 0.48701476121096343\n",
            "Loss in iteration no. 94202 ==> 0.48701373907072126\n",
            "Loss in iteration no. 94203 ==> 0.48701271693989423\n",
            "Loss in iteration no. 94204 ==> 0.4870116948184822\n",
            "Loss in iteration no. 94205 ==> 0.48701067270648496\n",
            "Loss in iteration no. 94206 ==> 0.4870096506039024\n",
            "Loss in iteration no. 94207 ==> 0.4870086285107344\n",
            "Loss in iteration no. 94208 ==> 0.487007606426981\n",
            "Loss in iteration no. 94209 ==> 0.4870065843526417\n",
            "Loss in iteration no. 94210 ==> 0.4870055622877169\n",
            "Loss in iteration no. 94211 ==> 0.48700454023220613\n",
            "Loss in iteration no. 94212 ==> 0.4870035181861092\n",
            "Loss in iteration no. 94213 ==> 0.4870024961494262\n",
            "Loss in iteration no. 94214 ==> 0.48700147412215716\n",
            "Loss in iteration no. 94215 ==> 0.48700045210430143\n",
            "Loss in iteration no. 94216 ==> 0.48699943009585933\n",
            "Loss in iteration no. 94217 ==> 0.4869984080968306\n",
            "Loss in iteration no. 94218 ==> 0.486997386107215\n",
            "Loss in iteration no. 94219 ==> 0.4869963641270126\n",
            "Loss in iteration no. 94220 ==> 0.48699534215622325\n",
            "Loss in iteration no. 94221 ==> 0.48699432019484673\n",
            "Loss in iteration no. 94222 ==> 0.486993298242883\n",
            "Loss in iteration no. 94223 ==> 0.4869922763003319\n",
            "Loss in iteration no. 94224 ==> 0.48699125436719337\n",
            "Loss in iteration no. 94225 ==> 0.48699023244346706\n",
            "Loss in iteration no. 94226 ==> 0.4869892105291532\n",
            "Loss in iteration no. 94227 ==> 0.4869881886242515\n",
            "Loss in iteration no. 94228 ==> 0.4869871667287617\n",
            "Loss in iteration no. 94229 ==> 0.4869861448426838\n",
            "Loss in iteration no. 94230 ==> 0.48698512296601787\n",
            "Loss in iteration no. 94231 ==> 0.48698410109876344\n",
            "Loss in iteration no. 94232 ==> 0.4869830792409205\n",
            "Loss in iteration no. 94233 ==> 0.48698205739248906\n",
            "Loss in iteration no. 94234 ==> 0.486981035553469\n",
            "Loss in iteration no. 94235 ==> 0.4869800137238601\n",
            "Loss in iteration no. 94236 ==> 0.48697899190366206\n",
            "Loss in iteration no. 94237 ==> 0.4869779700928751\n",
            "Loss in iteration no. 94238 ==> 0.48697694829149896\n",
            "Loss in iteration no. 94239 ==> 0.4869759264995334\n",
            "Loss in iteration no. 94240 ==> 0.4869749047169786\n",
            "Loss in iteration no. 94241 ==> 0.4869738829438341\n",
            "Loss in iteration no. 94242 ==> 0.4869728611800999\n",
            "Loss in iteration no. 94243 ==> 0.486971839425776\n",
            "Loss in iteration no. 94244 ==> 0.48697081768086203\n",
            "Loss in iteration no. 94245 ==> 0.4869697959453581\n",
            "Loss in iteration no. 94246 ==> 0.4869687742192641\n",
            "Loss in iteration no. 94247 ==> 0.4869677525025797\n",
            "Loss in iteration no. 94248 ==> 0.48696673079530495\n",
            "Loss in iteration no. 94249 ==> 0.4869657090974396\n",
            "Loss in iteration no. 94250 ==> 0.48696468740898363\n",
            "Loss in iteration no. 94251 ==> 0.4869636657299368\n",
            "Loss in iteration no. 94252 ==> 0.48696264406029927\n",
            "Loss in iteration no. 94253 ==> 0.4869616224000705\n",
            "Loss in iteration no. 94254 ==> 0.48696060074925074\n",
            "Loss in iteration no. 94255 ==> 0.4869595791078396\n",
            "Loss in iteration no. 94256 ==> 0.4869585574758373\n",
            "Loss in iteration no. 94257 ==> 0.4869575358532431\n",
            "Loss in iteration no. 94258 ==> 0.48695651424005754\n",
            "Loss in iteration no. 94259 ==> 0.48695549263628024\n",
            "Loss in iteration no. 94260 ==> 0.486954471041911\n",
            "Loss in iteration no. 94261 ==> 0.48695344945694974\n",
            "Loss in iteration no. 94262 ==> 0.4869524278813963\n",
            "Loss in iteration no. 94263 ==> 0.48695140631525086\n",
            "Loss in iteration no. 94264 ==> 0.48695038475851293\n",
            "Loss in iteration no. 94265 ==> 0.48694936321118243\n",
            "Loss in iteration no. 94266 ==> 0.48694834167325945\n",
            "Loss in iteration no. 94267 ==> 0.4869473201447436\n",
            "Loss in iteration no. 94268 ==> 0.4869462986256351\n",
            "Loss in iteration no. 94269 ==> 0.4869452771159335\n",
            "Loss in iteration no. 94270 ==> 0.4869442556156388\n",
            "Loss in iteration no. 94271 ==> 0.48694323412475093\n",
            "Loss in iteration no. 94272 ==> 0.48694221264326965\n",
            "Loss in iteration no. 94273 ==> 0.4869411911711951\n",
            "Loss in iteration no. 94274 ==> 0.4869401697085269\n",
            "Loss in iteration no. 94275 ==> 0.48693914825526485\n",
            "Loss in iteration no. 94276 ==> 0.486938126811409\n",
            "Loss in iteration no. 94277 ==> 0.4869371053769592\n",
            "Loss in iteration no. 94278 ==> 0.4869360839519155\n",
            "Loss in iteration no. 94279 ==> 0.48693506253627755\n",
            "Loss in iteration no. 94280 ==> 0.4869340411300453\n",
            "Loss in iteration no. 94281 ==> 0.4869330197332185\n",
            "Loss in iteration no. 94282 ==> 0.48693199834579726\n",
            "Loss in iteration no. 94283 ==> 0.4869309769677813\n",
            "Loss in iteration no. 94284 ==> 0.48692995559917057\n",
            "Loss in iteration no. 94285 ==> 0.4869289342399648\n",
            "Loss in iteration no. 94286 ==> 0.48692791289016407\n",
            "Loss in iteration no. 94287 ==> 0.48692689154976815\n",
            "Loss in iteration no. 94288 ==> 0.48692587021877703\n",
            "Loss in iteration no. 94289 ==> 0.48692484889719045\n",
            "Loss in iteration no. 94290 ==> 0.4869238275850083\n",
            "Loss in iteration no. 94291 ==> 0.4869228062822305\n",
            "Loss in iteration no. 94292 ==> 0.486921784988857\n",
            "Loss in iteration no. 94293 ==> 0.4869207637048877\n",
            "Loss in iteration no. 94294 ==> 0.4869197424303222\n",
            "Loss in iteration no. 94295 ==> 0.4869187211651606\n",
            "Loss in iteration no. 94296 ==> 0.48691769990940287\n",
            "Loss in iteration no. 94297 ==> 0.48691667866304844\n",
            "Loss in iteration no. 94298 ==> 0.4869156574260978\n",
            "Loss in iteration no. 94299 ==> 0.48691463619855047\n",
            "Loss in iteration no. 94300 ==> 0.4869136149804064\n",
            "Loss in iteration no. 94301 ==> 0.4869125937716653\n",
            "Loss in iteration no. 94302 ==> 0.48691157257232737\n",
            "Loss in iteration no. 94303 ==> 0.4869105513823923\n",
            "Loss in iteration no. 94304 ==> 0.48690953020186\n",
            "Loss in iteration no. 94305 ==> 0.48690850903073024\n",
            "Loss in iteration no. 94306 ==> 0.4869074878690032\n",
            "Loss in iteration no. 94307 ==> 0.4869064667166785\n",
            "Loss in iteration no. 94308 ==> 0.48690544557375603\n",
            "Loss in iteration no. 94309 ==> 0.48690442444023563\n",
            "Loss in iteration no. 94310 ==> 0.4869034033161174\n",
            "Loss in iteration no. 94311 ==> 0.48690238220140103\n",
            "Loss in iteration no. 94312 ==> 0.48690136109608634\n",
            "Loss in iteration no. 94313 ==> 0.4869003400001735\n",
            "Loss in iteration no. 94314 ==> 0.4868993189136621\n",
            "Loss in iteration no. 94315 ==> 0.4868982978365522\n",
            "Loss in iteration no. 94316 ==> 0.48689727676884365\n",
            "Loss in iteration no. 94317 ==> 0.48689625571053613\n",
            "Loss in iteration no. 94318 ==> 0.48689523466162976\n",
            "Loss in iteration no. 94319 ==> 0.4868942136221243\n",
            "Loss in iteration no. 94320 ==> 0.4868931925920197\n",
            "Loss in iteration no. 94321 ==> 0.48689217157131565\n",
            "Loss in iteration no. 94322 ==> 0.4868911505600123\n",
            "Loss in iteration no. 94323 ==> 0.48689012955810945\n",
            "Loss in iteration no. 94324 ==> 0.4868891085656069\n",
            "Loss in iteration no. 94325 ==> 0.4868880875825045\n",
            "Loss in iteration no. 94326 ==> 0.48688706660880215\n",
            "Loss in iteration no. 94327 ==> 0.48688604564449983\n",
            "Loss in iteration no. 94328 ==> 0.48688502468959727\n",
            "Loss in iteration no. 94329 ==> 0.48688400374409463\n",
            "Loss in iteration no. 94330 ==> 0.4868829828079914\n",
            "Loss in iteration no. 94331 ==> 0.48688196188128763\n",
            "Loss in iteration no. 94332 ==> 0.4868809409639833\n",
            "Loss in iteration no. 94333 ==> 0.4868799200560783\n",
            "Loss in iteration no. 94334 ==> 0.4868788991575722\n",
            "Loss in iteration no. 94335 ==> 0.4868778782684652\n",
            "Loss in iteration no. 94336 ==> 0.48687685738875713\n",
            "Loss in iteration no. 94337 ==> 0.48687583651844785\n",
            "Loss in iteration no. 94338 ==> 0.4868748156575371\n",
            "Loss in iteration no. 94339 ==> 0.4868737948060247\n",
            "Loss in iteration no. 94340 ==> 0.48687277396391093\n",
            "Loss in iteration no. 94341 ==> 0.4868717531311953\n",
            "Loss in iteration no. 94342 ==> 0.48687073230787786\n",
            "Loss in iteration no. 94343 ==> 0.48686971149395836\n",
            "Loss in iteration no. 94344 ==> 0.4868686906894368\n",
            "Loss in iteration no. 94345 ==> 0.486867669894313\n",
            "Loss in iteration no. 94346 ==> 0.4868666491085868\n",
            "Loss in iteration no. 94347 ==> 0.4868656283322582\n",
            "Loss in iteration no. 94348 ==> 0.486864607565327\n",
            "Loss in iteration no. 94349 ==> 0.4868635868077931\n",
            "Loss in iteration no. 94350 ==> 0.48686256605965644\n",
            "Loss in iteration no. 94351 ==> 0.4868615453209167\n",
            "Loss in iteration no. 94352 ==> 0.48686052459157386\n",
            "Loss in iteration no. 94353 ==> 0.48685950387162796\n",
            "Loss in iteration no. 94354 ==> 0.4868584831610786\n",
            "Loss in iteration no. 94355 ==> 0.4868574624599259\n",
            "Loss in iteration no. 94356 ==> 0.48685644176816945\n",
            "Loss in iteration no. 94357 ==> 0.4868554210858096\n",
            "Loss in iteration no. 94358 ==> 0.4868544004128457\n",
            "Loss in iteration no. 94359 ==> 0.48685337974927795\n",
            "Loss in iteration no. 94360 ==> 0.4868523590951061\n",
            "Loss in iteration no. 94361 ==> 0.4868513384503302\n",
            "Loss in iteration no. 94362 ==> 0.4868503178149499\n",
            "Loss in iteration no. 94363 ==> 0.4868492971889652\n",
            "Loss in iteration no. 94364 ==> 0.48684827657237595\n",
            "Loss in iteration no. 94365 ==> 0.48684725596518214\n",
            "Loss in iteration no. 94366 ==> 0.48684623536738336\n",
            "Loss in iteration no. 94367 ==> 0.4868452147789799\n",
            "Loss in iteration no. 94368 ==> 0.48684419419997127\n",
            "Loss in iteration no. 94369 ==> 0.4868431736303575\n",
            "Loss in iteration no. 94370 ==> 0.48684215307013845\n",
            "Loss in iteration no. 94371 ==> 0.4868411325193141\n",
            "Loss in iteration no. 94372 ==> 0.48684011197788424\n",
            "Loss in iteration no. 94373 ==> 0.4868390914458486\n",
            "Loss in iteration no. 94374 ==> 0.4868380709232073\n",
            "Loss in iteration no. 94375 ==> 0.4868370504099601\n",
            "Loss in iteration no. 94376 ==> 0.48683602990610686\n",
            "Loss in iteration no. 94377 ==> 0.48683500941164753\n",
            "Loss in iteration no. 94378 ==> 0.4868339889265821\n",
            "Loss in iteration no. 94379 ==> 0.4868329684509102\n",
            "Loss in iteration no. 94380 ==> 0.48683194798463175\n",
            "Loss in iteration no. 94381 ==> 0.48683092752774676\n",
            "Loss in iteration no. 94382 ==> 0.486829907080255\n",
            "Loss in iteration no. 94383 ==> 0.48682888664215634\n",
            "Loss in iteration no. 94384 ==> 0.4868278662134508\n",
            "Loss in iteration no. 94385 ==> 0.4868268457941382\n",
            "Loss in iteration no. 94386 ==> 0.4868258253842183\n",
            "Loss in iteration no. 94387 ==> 0.4868248049836912\n",
            "Loss in iteration no. 94388 ==> 0.4868237845925565\n",
            "Loss in iteration no. 94389 ==> 0.48682276421081416\n",
            "Loss in iteration no. 94390 ==> 0.4868217438384642\n",
            "Loss in iteration no. 94391 ==> 0.4868207234755065\n",
            "Loss in iteration no. 94392 ==> 0.4868197031219408\n",
            "Loss in iteration no. 94393 ==> 0.486818682777767\n",
            "Loss in iteration no. 94394 ==> 0.486817662442985\n",
            "Loss in iteration no. 94395 ==> 0.4868166421175948\n",
            "Loss in iteration no. 94396 ==> 0.4868156218015961\n",
            "Loss in iteration no. 94397 ==> 0.4868146014949889\n",
            "Loss in iteration no. 94398 ==> 0.48681358119777285\n",
            "Loss in iteration no. 94399 ==> 0.4868125609099481\n",
            "Loss in iteration no. 94400 ==> 0.4868115406315145\n",
            "Loss in iteration no. 94401 ==> 0.4868105203624718\n",
            "Loss in iteration no. 94402 ==> 0.4868095001028198\n",
            "Loss in iteration no. 94403 ==> 0.4868084798525587\n",
            "Loss in iteration no. 94404 ==> 0.48680745961168825\n",
            "Loss in iteration no. 94405 ==> 0.4868064393802082\n",
            "Loss in iteration no. 94406 ==> 0.4868054191581185\n",
            "Loss in iteration no. 94407 ==> 0.48680439894541894\n",
            "Loss in iteration no. 94408 ==> 0.48680337874210955\n",
            "Loss in iteration no. 94409 ==> 0.4868023585481902\n",
            "Loss in iteration no. 94410 ==> 0.48680133836366063\n",
            "Loss in iteration no. 94411 ==> 0.4868003181885209\n",
            "Loss in iteration no. 94412 ==> 0.4867992980227706\n",
            "Loss in iteration no. 94413 ==> 0.4867982778664101\n",
            "Loss in iteration no. 94414 ==> 0.4867972577194387\n",
            "Loss in iteration no. 94415 ==> 0.4867962375818568\n",
            "Loss in iteration no. 94416 ==> 0.4867952174536639\n",
            "Loss in iteration no. 94417 ==> 0.48679419733486\n",
            "Loss in iteration no. 94418 ==> 0.48679317722544513\n",
            "Loss in iteration no. 94419 ==> 0.48679215712541885\n",
            "Loss in iteration no. 94420 ==> 0.48679113703478133\n",
            "Loss in iteration no. 94421 ==> 0.4867901169535323\n",
            "Loss in iteration no. 94422 ==> 0.48678909688167166\n",
            "Loss in iteration no. 94423 ==> 0.48678807681919933\n",
            "Loss in iteration no. 94424 ==> 0.48678705676611517\n",
            "Loss in iteration no. 94425 ==> 0.48678603672241916\n",
            "Loss in iteration no. 94426 ==> 0.4867850166881109\n",
            "Loss in iteration no. 94427 ==> 0.48678399666319055\n",
            "Loss in iteration no. 94428 ==> 0.48678297664765774\n",
            "Loss in iteration no. 94429 ==> 0.48678195664151264\n",
            "Loss in iteration no. 94430 ==> 0.48678093664475486\n",
            "Loss in iteration no. 94431 ==> 0.4867799166573844\n",
            "Loss in iteration no. 94432 ==> 0.48677889667940133\n",
            "Loss in iteration no. 94433 ==> 0.48677787671080514\n",
            "Loss in iteration no. 94434 ==> 0.48677685675159593\n",
            "Loss in iteration no. 94435 ==> 0.4867758368017735\n",
            "Loss in iteration no. 94436 ==> 0.48677481686133783\n",
            "Loss in iteration no. 94437 ==> 0.48677379693028877\n",
            "Loss in iteration no. 94438 ==> 0.48677277700862615\n",
            "Loss in iteration no. 94439 ==> 0.4867717570963499\n",
            "Loss in iteration no. 94440 ==> 0.48677073719345987\n",
            "Loss in iteration no. 94441 ==> 0.4867697172999558\n",
            "Loss in iteration no. 94442 ==> 0.4867686974158379\n",
            "Loss in iteration no. 94443 ==> 0.4867676775411057\n",
            "Loss in iteration no. 94444 ==> 0.4867666576757594\n",
            "Loss in iteration no. 94445 ==> 0.48676563781979854\n",
            "Loss in iteration no. 94446 ==> 0.48676461797322323\n",
            "Loss in iteration no. 94447 ==> 0.4867635981360333\n",
            "Loss in iteration no. 94448 ==> 0.48676257830822867\n",
            "Loss in iteration no. 94449 ==> 0.4867615584898092\n",
            "Loss in iteration no. 94450 ==> 0.4867605386807746\n",
            "Loss in iteration no. 94451 ==> 0.48675951888112495\n",
            "Loss in iteration no. 94452 ==> 0.48675849909086\n",
            "Loss in iteration no. 94453 ==> 0.4867574793099797\n",
            "Loss in iteration no. 94454 ==> 0.4867564595384839\n",
            "Loss in iteration no. 94455 ==> 0.4867554397763727\n",
            "Loss in iteration no. 94456 ==> 0.4867544200236456\n",
            "Loss in iteration no. 94457 ==> 0.48675340028030273\n",
            "Loss in iteration no. 94458 ==> 0.48675238054634384\n",
            "Loss in iteration no. 94459 ==> 0.4867513608217688\n",
            "Loss in iteration no. 94460 ==> 0.48675034110657767\n",
            "Loss in iteration no. 94461 ==> 0.48674932140077015\n",
            "Loss in iteration no. 94462 ==> 0.4867483017043462\n",
            "Loss in iteration no. 94463 ==> 0.48674728201730566\n",
            "Loss in iteration no. 94464 ==> 0.48674626233964846\n",
            "Loss in iteration no. 94465 ==> 0.4867452426713743\n",
            "Loss in iteration no. 94466 ==> 0.48674422301248343\n",
            "Loss in iteration no. 94467 ==> 0.4867432033629754\n",
            "Loss in iteration no. 94468 ==> 0.4867421837228501\n",
            "Loss in iteration no. 94469 ==> 0.48674116409210766\n",
            "Loss in iteration no. 94470 ==> 0.48674014447074765\n",
            "Loss in iteration no. 94471 ==> 0.48673912485877013\n",
            "Loss in iteration no. 94472 ==> 0.48673810525617495\n",
            "Loss in iteration no. 94473 ==> 0.486737085662962\n",
            "Loss in iteration no. 94474 ==> 0.486736066079131\n",
            "Loss in iteration no. 94475 ==> 0.48673504650468224\n",
            "Loss in iteration no. 94476 ==> 0.4867340269396152\n",
            "Loss in iteration no. 94477 ==> 0.4867330073839298\n",
            "Loss in iteration no. 94478 ==> 0.48673198783762617\n",
            "Loss in iteration no. 94479 ==> 0.4867309683007038\n",
            "Loss in iteration no. 94480 ==> 0.4867299487731628\n",
            "Loss in iteration no. 94481 ==> 0.4867289292550033\n",
            "Loss in iteration no. 94482 ==> 0.48672790974622476\n",
            "Loss in iteration no. 94483 ==> 0.48672689024682725\n",
            "Loss in iteration no. 94484 ==> 0.4867258707568106\n",
            "Loss in iteration no. 94485 ==> 0.48672485127617476\n",
            "Loss in iteration no. 94486 ==> 0.4867238318049194\n",
            "Loss in iteration no. 94487 ==> 0.48672281234304465\n",
            "Loss in iteration no. 94488 ==> 0.48672179289055034\n",
            "Loss in iteration no. 94489 ==> 0.4867207734474362\n",
            "Loss in iteration no. 94490 ==> 0.4867197540137024\n",
            "Loss in iteration no. 94491 ==> 0.48671873458934833\n",
            "Loss in iteration no. 94492 ==> 0.4867177151743744\n",
            "Loss in iteration no. 94493 ==> 0.48671669576878\n",
            "Loss in iteration no. 94494 ==> 0.4867156763725655\n",
            "Loss in iteration no. 94495 ==> 0.4867146569857304\n",
            "Loss in iteration no. 94496 ==> 0.4867136376082749\n",
            "Loss in iteration no. 94497 ==> 0.4867126182401986\n",
            "Loss in iteration no. 94498 ==> 0.48671159888150134\n",
            "Loss in iteration no. 94499 ==> 0.4867105795321833\n",
            "Loss in iteration no. 94500 ==> 0.4867095601922442\n",
            "Loss in iteration no. 94501 ==> 0.48670854086168386\n",
            "Loss in iteration no. 94502 ==> 0.4867075215405023\n",
            "Loss in iteration no. 94503 ==> 0.486706502228699\n",
            "Loss in iteration no. 94504 ==> 0.4867054829262744\n",
            "Loss in iteration no. 94505 ==> 0.48670446363322817\n",
            "Loss in iteration no. 94506 ==> 0.48670344434956003\n",
            "Loss in iteration no. 94507 ==> 0.4867024250752699\n",
            "Loss in iteration no. 94508 ==> 0.4867014058103578\n",
            "Loss in iteration no. 94509 ==> 0.48670038655482367\n",
            "Loss in iteration no. 94510 ==> 0.48669936730866725\n",
            "Loss in iteration no. 94511 ==> 0.4866983480718882\n",
            "Loss in iteration no. 94512 ==> 0.4866973288444869\n",
            "Loss in iteration no. 94513 ==> 0.4866963096264628\n",
            "Loss in iteration no. 94514 ==> 0.486695290417816\n",
            "Loss in iteration no. 94515 ==> 0.48669427121854625\n",
            "Loss in iteration no. 94516 ==> 0.48669325202865354\n",
            "Loss in iteration no. 94517 ==> 0.4866922328481376\n",
            "Loss in iteration no. 94518 ==> 0.48669121367699847\n",
            "Loss in iteration no. 94519 ==> 0.48669019451523604\n",
            "Loss in iteration no. 94520 ==> 0.48668917536285006\n",
            "Loss in iteration no. 94521 ==> 0.4866881562198405\n",
            "Loss in iteration no. 94522 ==> 0.4866871370862071\n",
            "Loss in iteration no. 94523 ==> 0.48668611796194994\n",
            "Loss in iteration no. 94524 ==> 0.4866850988470688\n",
            "Loss in iteration no. 94525 ==> 0.48668407974156347\n",
            "Loss in iteration no. 94526 ==> 0.486683060645434\n",
            "Loss in iteration no. 94527 ==> 0.4866820415586802\n",
            "Loss in iteration no. 94528 ==> 0.4866810224813019\n",
            "Loss in iteration no. 94529 ==> 0.486680003413299\n",
            "Loss in iteration no. 94530 ==> 0.48667898435467133\n",
            "Loss in iteration no. 94531 ==> 0.48667796530541896\n",
            "Loss in iteration no. 94532 ==> 0.4866769462655416\n",
            "Loss in iteration no. 94533 ==> 0.48667592723503905\n",
            "Loss in iteration no. 94534 ==> 0.48667490821391146\n",
            "Loss in iteration no. 94535 ==> 0.4866738892021586\n",
            "Loss in iteration no. 94536 ==> 0.4866728701997801\n",
            "Loss in iteration no. 94537 ==> 0.48667185120677614\n",
            "Loss in iteration no. 94538 ==> 0.4866708322231466\n",
            "Loss in iteration no. 94539 ==> 0.48666981324889114\n",
            "Loss in iteration no. 94540 ==> 0.48666879428400966\n",
            "Loss in iteration no. 94541 ==> 0.4866677753285023\n",
            "Loss in iteration no. 94542 ==> 0.4866667563823688\n",
            "Loss in iteration no. 94543 ==> 0.486665737445609\n",
            "Loss in iteration no. 94544 ==> 0.4866647185182228\n",
            "Loss in iteration no. 94545 ==> 0.48666369960021\n",
            "Loss in iteration no. 94546 ==> 0.48666268069157054\n",
            "Loss in iteration no. 94547 ==> 0.48666166179230436\n",
            "Loss in iteration no. 94548 ==> 0.4866606429024113\n",
            "Loss in iteration no. 94549 ==> 0.4866596240218912\n",
            "Loss in iteration no. 94550 ==> 0.486658605150744\n",
            "Loss in iteration no. 94551 ==> 0.48665758628896955\n",
            "Loss in iteration no. 94552 ==> 0.4866565674365676\n",
            "Loss in iteration no. 94553 ==> 0.4866555485935384\n",
            "Loss in iteration no. 94554 ==> 0.48665452975988127\n",
            "Loss in iteration no. 94555 ==> 0.48665351093559667\n",
            "Loss in iteration no. 94556 ==> 0.48665249212068407\n",
            "Loss in iteration no. 94557 ==> 0.48665147331514347\n",
            "Loss in iteration no. 94558 ==> 0.4866504545189749\n",
            "Loss in iteration no. 94559 ==> 0.48664943573217795\n",
            "Loss in iteration no. 94560 ==> 0.48664841695475275\n",
            "Loss in iteration no. 94561 ==> 0.48664739818669905\n",
            "Loss in iteration no. 94562 ==> 0.4866463794280168\n",
            "Loss in iteration no. 94563 ==> 0.48664536067870573\n",
            "Loss in iteration no. 94564 ==> 0.4866443419387659\n",
            "Loss in iteration no. 94565 ==> 0.48664332320819714\n",
            "Loss in iteration no. 94566 ==> 0.4866423044869994\n",
            "Loss in iteration no. 94567 ==> 0.48664128577517224\n",
            "Loss in iteration no. 94568 ==> 0.48664026707271596\n",
            "Loss in iteration no. 94569 ==> 0.4866392483796301\n",
            "Loss in iteration no. 94570 ==> 0.4866382296959148\n",
            "Loss in iteration no. 94571 ==> 0.48663721102156965\n",
            "Loss in iteration no. 94572 ==> 0.4866361923565949\n",
            "Loss in iteration no. 94573 ==> 0.48663517370099013\n",
            "Loss in iteration no. 94574 ==> 0.48663415505475544\n",
            "Loss in iteration no. 94575 ==> 0.48663313641789047\n",
            "Loss in iteration no. 94576 ==> 0.48663211779039517\n",
            "Loss in iteration no. 94577 ==> 0.4866310991722695\n",
            "Loss in iteration no. 94578 ==> 0.4866300805635132\n",
            "Loss in iteration no. 94579 ==> 0.48662906196412636\n",
            "Loss in iteration no. 94580 ==> 0.48662804337410887\n",
            "Loss in iteration no. 94581 ==> 0.48662702479346037\n",
            "Loss in iteration no. 94582 ==> 0.48662600622218083\n",
            "Loss in iteration no. 94583 ==> 0.4866249876602701\n",
            "Loss in iteration no. 94584 ==> 0.48662396910772826\n",
            "Loss in iteration no. 94585 ==> 0.486622950564555\n",
            "Loss in iteration no. 94586 ==> 0.48662193203075016\n",
            "Loss in iteration no. 94587 ==> 0.48662091350631387\n",
            "Loss in iteration no. 94588 ==> 0.48661989499124564\n",
            "Loss in iteration no. 94589 ==> 0.48661887648554564\n",
            "Loss in iteration no. 94590 ==> 0.48661785798921364\n",
            "Loss in iteration no. 94591 ==> 0.4866168395022496\n",
            "Loss in iteration no. 94592 ==> 0.48661582102465323\n",
            "Loss in iteration no. 94593 ==> 0.4866148025564246\n",
            "Loss in iteration no. 94594 ==> 0.48661378409756345\n",
            "Loss in iteration no. 94595 ==> 0.4866127656480698\n",
            "Loss in iteration no. 94596 ==> 0.4866117472079433\n",
            "Loss in iteration no. 94597 ==> 0.48661072877718414\n",
            "Loss in iteration no. 94598 ==> 0.4866097103557918\n",
            "Loss in iteration no. 94599 ==> 0.48660869194376655\n",
            "Loss in iteration no. 94600 ==> 0.48660767354110807\n",
            "Loss in iteration no. 94601 ==> 0.4866066551478163\n",
            "Loss in iteration no. 94602 ==> 0.48660563676389107\n",
            "Loss in iteration no. 94603 ==> 0.48660461838933233\n",
            "Loss in iteration no. 94604 ==> 0.4866036000241398\n",
            "Loss in iteration no. 94605 ==> 0.4866025816683136\n",
            "Loss in iteration no. 94606 ==> 0.48660156332185334\n",
            "Loss in iteration no. 94607 ==> 0.48660054498475913\n",
            "Loss in iteration no. 94608 ==> 0.4865995266570307\n",
            "Loss in iteration no. 94609 ==> 0.48659850833866813\n",
            "Loss in iteration no. 94610 ==> 0.48659749002967095\n",
            "Loss in iteration no. 94611 ==> 0.4865964717300394\n",
            "Loss in iteration no. 94612 ==> 0.48659545343977306\n",
            "Loss in iteration no. 94613 ==> 0.486594435158872\n",
            "Loss in iteration no. 94614 ==> 0.4865934168873361\n",
            "Loss in iteration no. 94615 ==> 0.4865923986251652\n",
            "Loss in iteration no. 94616 ==> 0.48659138037235905\n",
            "Loss in iteration no. 94617 ==> 0.48659036212891776\n",
            "Loss in iteration no. 94618 ==> 0.48658934389484104\n",
            "Loss in iteration no. 94619 ==> 0.4865883256701289\n",
            "Loss in iteration no. 94620 ==> 0.486587307454781\n",
            "Loss in iteration no. 94621 ==> 0.48658628924879754\n",
            "Loss in iteration no. 94622 ==> 0.4865852710521781\n",
            "Loss in iteration no. 94623 ==> 0.48658425286492274\n",
            "Loss in iteration no. 94624 ==> 0.4865832346870312\n",
            "Loss in iteration no. 94625 ==> 0.48658221651850353\n",
            "Loss in iteration no. 94626 ==> 0.4865811983593395\n",
            "Loss in iteration no. 94627 ==> 0.4865801802095389\n",
            "Loss in iteration no. 94628 ==> 0.4865791620691018\n",
            "Loss in iteration no. 94629 ==> 0.486578143938028\n",
            "Loss in iteration no. 94630 ==> 0.4865771258163173\n",
            "Loss in iteration no. 94631 ==> 0.4865761077039698\n",
            "Loss in iteration no. 94632 ==> 0.486575089600985\n",
            "Loss in iteration no. 94633 ==> 0.48657407150736315\n",
            "Loss in iteration no. 94634 ==> 0.486573053423104\n",
            "Loss in iteration no. 94635 ==> 0.48657203534820737\n",
            "Loss in iteration no. 94636 ==> 0.4865710172826732\n",
            "Loss in iteration no. 94637 ==> 0.4865699992265014\n",
            "Loss in iteration no. 94638 ==> 0.4865689811796917\n",
            "Loss in iteration no. 94639 ==> 0.4865679631422442\n",
            "Loss in iteration no. 94640 ==> 0.48656694511415866\n",
            "Loss in iteration no. 94641 ==> 0.48656592709543484\n",
            "Loss in iteration no. 94642 ==> 0.48656490908607275\n",
            "Loss in iteration no. 94643 ==> 0.4865638910860724\n",
            "Loss in iteration no. 94644 ==> 0.4865628730954334\n",
            "Loss in iteration no. 94645 ==> 0.4865618551141557\n",
            "Loss in iteration no. 94646 ==> 0.48656083714223936\n",
            "Loss in iteration no. 94647 ==> 0.4865598191796841\n",
            "Loss in iteration no. 94648 ==> 0.4865588012264898\n",
            "Loss in iteration no. 94649 ==> 0.4865577832826564\n",
            "Loss in iteration no. 94650 ==> 0.48655676534818365\n",
            "Loss in iteration no. 94651 ==> 0.4865557474230717\n",
            "Loss in iteration no. 94652 ==> 0.4865547295073202\n",
            "Loss in iteration no. 94653 ==> 0.48655371160092903\n",
            "Loss in iteration no. 94654 ==> 0.4865526937038982\n",
            "Loss in iteration no. 94655 ==> 0.48655167581622744\n",
            "Loss in iteration no. 94656 ==> 0.48655065793791674\n",
            "Loss in iteration no. 94657 ==> 0.48654964006896595\n",
            "Loss in iteration no. 94658 ==> 0.48654862220937495\n",
            "Loss in iteration no. 94659 ==> 0.4865476043591436\n",
            "Loss in iteration no. 94660 ==> 0.4865465865182718\n",
            "Loss in iteration no. 94661 ==> 0.48654556868675936\n",
            "Loss in iteration no. 94662 ==> 0.48654455086460624\n",
            "Loss in iteration no. 94663 ==> 0.4865435330518123\n",
            "Loss in iteration no. 94664 ==> 0.4865425152483775\n",
            "Loss in iteration no. 94665 ==> 0.4865414974543015\n",
            "Loss in iteration no. 94666 ==> 0.4865404796695844\n",
            "Loss in iteration no. 94667 ==> 0.486539461894226\n",
            "Loss in iteration no. 94668 ==> 0.48653844412822617\n",
            "Loss in iteration no. 94669 ==> 0.4865374263715847\n",
            "Loss in iteration no. 94670 ==> 0.48653640862430164\n",
            "Loss in iteration no. 94671 ==> 0.4865353908863767\n",
            "Loss in iteration no. 94672 ==> 0.48653437315780995\n",
            "Loss in iteration no. 94673 ==> 0.4865333554386011\n",
            "Loss in iteration no. 94674 ==> 0.48653233772875015\n",
            "Loss in iteration no. 94675 ==> 0.48653132002825683\n",
            "Loss in iteration no. 94676 ==> 0.48653030233712113\n",
            "Loss in iteration no. 94677 ==> 0.48652928465534306\n",
            "Loss in iteration no. 94678 ==> 0.4865282669829222\n",
            "Loss in iteration no. 94679 ==> 0.4865272493198586\n",
            "Loss in iteration no. 94680 ==> 0.4865262316661521\n",
            "Loss in iteration no. 94681 ==> 0.4865252140218027\n",
            "Loss in iteration no. 94682 ==> 0.48652419638681016\n",
            "Loss in iteration no. 94683 ==> 0.48652317876117435\n",
            "Loss in iteration no. 94684 ==> 0.4865221611448951\n",
            "Loss in iteration no. 94685 ==> 0.4865211435379725\n",
            "Loss in iteration no. 94686 ==> 0.4865201259404061\n",
            "Loss in iteration no. 94687 ==> 0.4865191083521962\n",
            "Loss in iteration no. 94688 ==> 0.4865180907733423\n",
            "Loss in iteration no. 94689 ==> 0.4865170732038444\n",
            "Loss in iteration no. 94690 ==> 0.48651605564370254\n",
            "Loss in iteration no. 94691 ==> 0.48651503809291635\n",
            "Loss in iteration no. 94692 ==> 0.4865140205514858\n",
            "Loss in iteration no. 94693 ==> 0.48651300301941103\n",
            "Loss in iteration no. 94694 ==> 0.48651198549669145\n",
            "Loss in iteration no. 94695 ==> 0.48651096798332727\n",
            "Loss in iteration no. 94696 ==> 0.48650995047931817\n",
            "Loss in iteration no. 94697 ==> 0.48650893298466424\n",
            "Loss in iteration no. 94698 ==> 0.4865079154993653\n",
            "Loss in iteration no. 94699 ==> 0.486506898023421\n",
            "Loss in iteration no. 94700 ==> 0.48650588055683164\n",
            "Loss in iteration no. 94701 ==> 0.48650486309959673\n",
            "Loss in iteration no. 94702 ==> 0.4865038456517162\n",
            "Loss in iteration no. 94703 ==> 0.48650282821319013\n",
            "Loss in iteration no. 94704 ==> 0.48650181078401816\n",
            "Loss in iteration no. 94705 ==> 0.4865007933642004\n",
            "Loss in iteration no. 94706 ==> 0.48649977595373656\n",
            "Loss in iteration no. 94707 ==> 0.48649875855262653\n",
            "Loss in iteration no. 94708 ==> 0.48649774116087025\n",
            "Loss in iteration no. 94709 ==> 0.48649672377846764\n",
            "Loss in iteration no. 94710 ==> 0.4864957064054184\n",
            "Loss in iteration no. 94711 ==> 0.48649468904172266\n",
            "Loss in iteration no. 94712 ==> 0.48649367168738017\n",
            "Loss in iteration no. 94713 ==> 0.48649265434239075\n",
            "Loss in iteration no. 94714 ==> 0.48649163700675435\n",
            "Loss in iteration no. 94715 ==> 0.48649061968047086\n",
            "Loss in iteration no. 94716 ==> 0.48648960236354005\n",
            "Loss in iteration no. 94717 ==> 0.4864885850559618\n",
            "Loss in iteration no. 94718 ==> 0.4864875677577363\n",
            "Loss in iteration no. 94719 ==> 0.48648655046886313\n",
            "Loss in iteration no. 94720 ==> 0.4864855331893422\n",
            "Loss in iteration no. 94721 ==> 0.48648451591917347\n",
            "Loss in iteration no. 94722 ==> 0.4864834986583567\n",
            "Loss in iteration no. 94723 ==> 0.48648248140689193\n",
            "Loss in iteration no. 94724 ==> 0.486481464164779\n",
            "Loss in iteration no. 94725 ==> 0.4864804469320176\n",
            "Loss in iteration no. 94726 ==> 0.48647942970860775\n",
            "Loss in iteration no. 94727 ==> 0.4864784124945495\n",
            "Loss in iteration no. 94728 ==> 0.48647739528984246\n",
            "Loss in iteration no. 94729 ==> 0.48647637809448663\n",
            "Loss in iteration no. 94730 ==> 0.4864753609084818\n",
            "Loss in iteration no. 94731 ==> 0.4864743437318281\n",
            "Loss in iteration no. 94732 ==> 0.4864733265645251\n",
            "Loss in iteration no. 94733 ==> 0.4864723094065728\n",
            "Loss in iteration no. 94734 ==> 0.4864712922579711\n",
            "Loss in iteration no. 94735 ==> 0.48647027511871993\n",
            "Loss in iteration no. 94736 ==> 0.48646925798881907\n",
            "Loss in iteration no. 94737 ==> 0.4864682408682684\n",
            "Loss in iteration no. 94738 ==> 0.4864672237570678\n",
            "Loss in iteration no. 94739 ==> 0.48646620665521717\n",
            "Loss in iteration no. 94740 ==> 0.4864651895627165\n",
            "Loss in iteration no. 94741 ==> 0.48646417247956564\n",
            "Loss in iteration no. 94742 ==> 0.4864631554057643\n",
            "Loss in iteration no. 94743 ==> 0.4864621383413124\n",
            "Loss in iteration no. 94744 ==> 0.48646112128620994\n",
            "Loss in iteration no. 94745 ==> 0.48646010424045677\n",
            "Loss in iteration no. 94746 ==> 0.4864590872040527\n",
            "Loss in iteration no. 94747 ==> 0.4864580701769976\n",
            "Loss in iteration no. 94748 ==> 0.4864570531592915\n",
            "Loss in iteration no. 94749 ==> 0.4864560361509341\n",
            "Loss in iteration no. 94750 ==> 0.4864550191519253\n",
            "Loss in iteration no. 94751 ==> 0.4864540021622651\n",
            "Loss in iteration no. 94752 ==> 0.4864529851819534\n",
            "Loss in iteration no. 94753 ==> 0.4864519682109899\n",
            "Loss in iteration no. 94754 ==> 0.48645095124937454\n",
            "Loss in iteration no. 94755 ==> 0.48644993429710737\n",
            "Loss in iteration no. 94756 ==> 0.486448917354188\n",
            "Loss in iteration no. 94757 ==> 0.4864479004206165\n",
            "Loss in iteration no. 94758 ==> 0.48644688349639265\n",
            "Loss in iteration no. 94759 ==> 0.4864458665815164\n",
            "Loss in iteration no. 94760 ==> 0.48644484967598745\n",
            "Loss in iteration no. 94761 ==> 0.48644383277980596\n",
            "Loss in iteration no. 94762 ==> 0.4864428158929716\n",
            "Loss in iteration no. 94763 ==> 0.48644179901548446\n",
            "Loss in iteration no. 94764 ==> 0.4864407821473442\n",
            "Loss in iteration no. 94765 ==> 0.4864397652885507\n",
            "Loss in iteration no. 94766 ==> 0.486438748439104\n",
            "Loss in iteration no. 94767 ==> 0.48643773159900383\n",
            "Loss in iteration no. 94768 ==> 0.48643671476825023\n",
            "Loss in iteration no. 94769 ==> 0.48643569794684316\n",
            "Loss in iteration no. 94770 ==> 0.48643468113478194\n",
            "Loss in iteration no. 94771 ==> 0.486433664332067\n",
            "Loss in iteration no. 94772 ==> 0.48643264753869814\n",
            "Loss in iteration no. 94773 ==> 0.48643163075467516\n",
            "Loss in iteration no. 94774 ==> 0.4864306139799979\n",
            "Loss in iteration no. 94775 ==> 0.4864295972146661\n",
            "Loss in iteration no. 94776 ==> 0.48642858045868004\n",
            "Loss in iteration no. 94777 ==> 0.4864275637120392\n",
            "Loss in iteration no. 94778 ==> 0.48642654697474386\n",
            "Loss in iteration no. 94779 ==> 0.4864255302467936\n",
            "Loss in iteration no. 94780 ==> 0.4864245135281882\n",
            "Loss in iteration no. 94781 ==> 0.4864234968189277\n",
            "Loss in iteration no. 94782 ==> 0.4864224801190122\n",
            "Loss in iteration no. 94783 ==> 0.4864214634284413\n",
            "Loss in iteration no. 94784 ==> 0.48642044674721485\n",
            "Loss in iteration no. 94785 ==> 0.48641943007533284\n",
            "Loss in iteration no. 94786 ==> 0.48641841341279524\n",
            "Loss in iteration no. 94787 ==> 0.4864173967596017\n",
            "Loss in iteration no. 94788 ==> 0.4864163801157523\n",
            "Loss in iteration no. 94789 ==> 0.48641536348124687\n",
            "Loss in iteration no. 94790 ==> 0.4864143468560852\n",
            "Loss in iteration no. 94791 ==> 0.4864133302402671\n",
            "Loss in iteration no. 94792 ==> 0.4864123136337927\n",
            "Loss in iteration no. 94793 ==> 0.4864112970366619\n",
            "Loss in iteration no. 94794 ==> 0.48641028044887424\n",
            "Loss in iteration no. 94795 ==> 0.4864092638704299\n",
            "Loss in iteration no. 94796 ==> 0.48640824730132864\n",
            "Loss in iteration no. 94797 ==> 0.4864072307415704\n",
            "Loss in iteration no. 94798 ==> 0.4864062141911549\n",
            "Loss in iteration no. 94799 ==> 0.48640519765008217\n",
            "Loss in iteration no. 94800 ==> 0.48640418111835204\n",
            "Loss in iteration no. 94801 ==> 0.4864031645959645\n",
            "Loss in iteration no. 94802 ==> 0.4864021480829193\n",
            "Loss in iteration no. 94803 ==> 0.48640113157921633\n",
            "Loss in iteration no. 94804 ==> 0.4864001150848555\n",
            "Loss in iteration no. 94805 ==> 0.4863990985998366\n",
            "Loss in iteration no. 94806 ==> 0.48639808212415964\n",
            "Loss in iteration no. 94807 ==> 0.4863970656578245\n",
            "Loss in iteration no. 94808 ==> 0.48639604920083107\n",
            "Loss in iteration no. 94809 ==> 0.48639503275317897\n",
            "Loss in iteration no. 94810 ==> 0.48639401631486834\n",
            "Loss in iteration no. 94811 ==> 0.486392999885899\n",
            "Loss in iteration no. 94812 ==> 0.48639198346627094\n",
            "Loss in iteration no. 94813 ==> 0.4863909670559839\n",
            "Loss in iteration no. 94814 ==> 0.48638995065503765\n",
            "Loss in iteration no. 94815 ==> 0.4863889342634323\n",
            "Loss in iteration no. 94816 ==> 0.48638791788116764\n",
            "Loss in iteration no. 94817 ==> 0.48638690150824354\n",
            "Loss in iteration no. 94818 ==> 0.4863858851446598\n",
            "Loss in iteration no. 94819 ==> 0.4863848687904164\n",
            "Loss in iteration no. 94820 ==> 0.48638385244551313\n",
            "Loss in iteration no. 94821 ==> 0.4863828361099502\n",
            "Loss in iteration no. 94822 ==> 0.4863818197837271\n",
            "Loss in iteration no. 94823 ==> 0.4863808034668438\n",
            "Loss in iteration no. 94824 ==> 0.4863797871593001\n",
            "Loss in iteration no. 94825 ==> 0.48637877086109615\n",
            "Loss in iteration no. 94826 ==> 0.48637775457223165\n",
            "Loss in iteration no. 94827 ==> 0.48637673829270645\n",
            "Loss in iteration no. 94828 ==> 0.48637572202252066\n",
            "Loss in iteration no. 94829 ==> 0.4863747057616738\n",
            "Loss in iteration no. 94830 ==> 0.4863736895101659\n",
            "Loss in iteration no. 94831 ==> 0.486372673267997\n",
            "Loss in iteration no. 94832 ==> 0.48637165703516677\n",
            "Loss in iteration no. 94833 ==> 0.48637064081167525\n",
            "Loss in iteration no. 94834 ==> 0.48636962459752214\n",
            "Loss in iteration no. 94835 ==> 0.4863686083927075\n",
            "Loss in iteration no. 94836 ==> 0.48636759219723114\n",
            "Loss in iteration no. 94837 ==> 0.4863665760110928\n",
            "Loss in iteration no. 94838 ==> 0.48636555983429264\n",
            "Loss in iteration no. 94839 ==> 0.48636454366683024\n",
            "Loss in iteration no. 94840 ==> 0.4863635275087059\n",
            "Loss in iteration no. 94841 ==> 0.4863625113599189\n",
            "Loss in iteration no. 94842 ==> 0.48636149522046956\n",
            "Loss in iteration no. 94843 ==> 0.4863604790903576\n",
            "Loss in iteration no. 94844 ==> 0.4863594629695831\n",
            "Loss in iteration no. 94845 ==> 0.48635844685814567\n",
            "Loss in iteration no. 94846 ==> 0.4863574307560453\n",
            "Loss in iteration no. 94847 ==> 0.4863564146632819\n",
            "Loss in iteration no. 94848 ==> 0.4863553985798554\n",
            "Loss in iteration no. 94849 ==> 0.4863543825057654\n",
            "Loss in iteration no. 94850 ==> 0.4863533664410121\n",
            "Loss in iteration no. 94851 ==> 0.4863523503855952\n",
            "Loss in iteration no. 94852 ==> 0.4863513343395147\n",
            "Loss in iteration no. 94853 ==> 0.4863503183027706\n",
            "Loss in iteration no. 94854 ==> 0.48634930227536227\n",
            "Loss in iteration no. 94855 ==> 0.48634828625729\n",
            "Loss in iteration no. 94856 ==> 0.4863472702485536\n",
            "Loss in iteration no. 94857 ==> 0.4863462542491529\n",
            "Loss in iteration no. 94858 ==> 0.486345238259088\n",
            "Loss in iteration no. 94859 ==> 0.4863442222783584\n",
            "Loss in iteration no. 94860 ==> 0.4863432063069642\n",
            "Loss in iteration no. 94861 ==> 0.4863421903449053\n",
            "Loss in iteration no. 94862 ==> 0.4863411743921816\n",
            "Loss in iteration no. 94863 ==> 0.48634015844879286\n",
            "Loss in iteration no. 94864 ==> 0.4863391425147389\n",
            "Loss in iteration no. 94865 ==> 0.48633812659001974\n",
            "Loss in iteration no. 94866 ==> 0.48633711067463536\n",
            "Loss in iteration no. 94867 ==> 0.4863360947685855\n",
            "Loss in iteration no. 94868 ==> 0.48633507887186994\n",
            "Loss in iteration no. 94869 ==> 0.4863340629844887\n",
            "Loss in iteration no. 94870 ==> 0.4863330471064416\n",
            "Loss in iteration no. 94871 ==> 0.48633203123772867\n",
            "Loss in iteration no. 94872 ==> 0.48633101537834944\n",
            "Loss in iteration no. 94873 ==> 0.4863299995283042\n",
            "Loss in iteration no. 94874 ==> 0.48632898368759264\n",
            "Loss in iteration no. 94875 ==> 0.48632796785621457\n",
            "Loss in iteration no. 94876 ==> 0.48632695203417\n",
            "Loss in iteration no. 94877 ==> 0.48632593622145864\n",
            "Loss in iteration no. 94878 ==> 0.4863249204180806\n",
            "Loss in iteration no. 94879 ==> 0.4863239046240356\n",
            "Loss in iteration no. 94880 ==> 0.48632288883932356\n",
            "Loss in iteration no. 94881 ==> 0.4863218730639444\n",
            "Loss in iteration no. 94882 ==> 0.486320857297898\n",
            "Loss in iteration no. 94883 ==> 0.486319841541184\n",
            "Loss in iteration no. 94884 ==> 0.48631882579380264\n",
            "Loss in iteration no. 94885 ==> 0.48631781005575353\n",
            "Loss in iteration no. 94886 ==> 0.48631679432703684\n",
            "Loss in iteration no. 94887 ==> 0.48631577860765207\n",
            "Loss in iteration no. 94888 ==> 0.4863147628975994\n",
            "Loss in iteration no. 94889 ==> 0.4863137471968786\n",
            "Loss in iteration no. 94890 ==> 0.48631273150548954\n",
            "Loss in iteration no. 94891 ==> 0.4863117158234321\n",
            "Loss in iteration no. 94892 ==> 0.4863107001507062\n",
            "Loss in iteration no. 94893 ==> 0.4863096844873117\n",
            "Loss in iteration no. 94894 ==> 0.4863086688332484\n",
            "Loss in iteration no. 94895 ==> 0.4863076531885163\n",
            "Loss in iteration no. 94896 ==> 0.48630663755311515\n",
            "Loss in iteration no. 94897 ==> 0.48630562192704513\n",
            "Loss in iteration no. 94898 ==> 0.48630460631030575\n",
            "Loss in iteration no. 94899 ==> 0.4863035907028971\n",
            "Loss in iteration no. 94900 ==> 0.4863025751048189\n",
            "Loss in iteration no. 94901 ==> 0.4863015595160711\n",
            "Loss in iteration no. 94902 ==> 0.48630054393665373\n",
            "Loss in iteration no. 94903 ==> 0.48629952836656654\n",
            "Loss in iteration no. 94904 ==> 0.4862985128058093\n",
            "Loss in iteration no. 94905 ==> 0.4862974972543822\n",
            "Loss in iteration no. 94906 ==> 0.48629648171228484\n",
            "Loss in iteration no. 94907 ==> 0.48629546617951713\n",
            "Loss in iteration no. 94908 ==> 0.486294450656079\n",
            "Loss in iteration no. 94909 ==> 0.48629343514197043\n",
            "Loss in iteration no. 94910 ==> 0.48629241963719116\n",
            "Loss in iteration no. 94911 ==> 0.48629140414174105\n",
            "Loss in iteration no. 94912 ==> 0.48629038865562013\n",
            "Loss in iteration no. 94913 ==> 0.4862893731788282\n",
            "Loss in iteration no. 94914 ==> 0.4862883577113651\n",
            "Loss in iteration no. 94915 ==> 0.4862873422532307\n",
            "Loss in iteration no. 94916 ==> 0.486286326804425\n",
            "Loss in iteration no. 94917 ==> 0.4862853113649478\n",
            "Loss in iteration no. 94918 ==> 0.4862842959347989\n",
            "Loss in iteration no. 94919 ==> 0.4862832805139783\n",
            "Loss in iteration no. 94920 ==> 0.48628226510248584\n",
            "Loss in iteration no. 94921 ==> 0.4862812497003213\n",
            "Loss in iteration no. 94922 ==> 0.4862802343074848\n",
            "Loss in iteration no. 94923 ==> 0.48627921892397613\n",
            "Loss in iteration no. 94924 ==> 0.48627820354979495\n",
            "Loss in iteration no. 94925 ==> 0.48627718818494137\n",
            "Loss in iteration no. 94926 ==> 0.48627617282941515\n",
            "Loss in iteration no. 94927 ==> 0.4862751574832163\n",
            "Loss in iteration no. 94928 ==> 0.4862741421463447\n",
            "Loss in iteration no. 94929 ==> 0.48627312681880003\n",
            "Loss in iteration no. 94930 ==> 0.4862721115005823\n",
            "Loss in iteration no. 94931 ==> 0.4862710961916914\n",
            "Loss in iteration no. 94932 ==> 0.4862700808921272\n",
            "Loss in iteration no. 94933 ==> 0.4862690656018896\n",
            "Loss in iteration no. 94934 ==> 0.48626805032097836\n",
            "Loss in iteration no. 94935 ==> 0.48626703504939367\n",
            "Loss in iteration no. 94936 ==> 0.486266019787135\n",
            "Loss in iteration no. 94937 ==> 0.4862650045342025\n",
            "Loss in iteration no. 94938 ==> 0.4862639892905959\n",
            "Loss in iteration no. 94939 ==> 0.4862629740563152\n",
            "Loss in iteration no. 94940 ==> 0.48626195883136014\n",
            "Loss in iteration no. 94941 ==> 0.4862609436157308\n",
            "Loss in iteration no. 94942 ==> 0.48625992840942694\n",
            "Loss in iteration no. 94943 ==> 0.4862589132124485\n",
            "Loss in iteration no. 94944 ==> 0.4862578980247952\n",
            "Loss in iteration no. 94945 ==> 0.48625688284646706\n",
            "Loss in iteration no. 94946 ==> 0.48625586767746387\n",
            "Loss in iteration no. 94947 ==> 0.48625485251778566\n",
            "Loss in iteration no. 94948 ==> 0.48625383736743216\n",
            "Loss in iteration no. 94949 ==> 0.48625282222640326\n",
            "Loss in iteration no. 94950 ==> 0.48625180709469895\n",
            "Loss in iteration no. 94951 ==> 0.48625079197231913\n",
            "Loss in iteration no. 94952 ==> 0.4862497768592634\n",
            "Loss in iteration no. 94953 ==> 0.486248761755532\n",
            "Loss in iteration no. 94954 ==> 0.4862477466611245\n",
            "Loss in iteration no. 94955 ==> 0.48624673157604115\n",
            "Loss in iteration no. 94956 ==> 0.4862457165002814\n",
            "Loss in iteration no. 94957 ==> 0.4862447014338454\n",
            "Loss in iteration no. 94958 ==> 0.486243686376733\n",
            "Loss in iteration no. 94959 ==> 0.48624267132894394\n",
            "Loss in iteration no. 94960 ==> 0.4862416562904782\n",
            "Loss in iteration no. 94961 ==> 0.4862406412613358\n",
            "Loss in iteration no. 94962 ==> 0.4862396262415164\n",
            "Loss in iteration no. 94963 ==> 0.48623861123102\n",
            "Loss in iteration no. 94964 ==> 0.48623759622984636\n",
            "Loss in iteration no. 94965 ==> 0.4862365812379955\n",
            "Loss in iteration no. 94966 ==> 0.4862355662554672\n",
            "Loss in iteration no. 94967 ==> 0.4862345512822615\n",
            "Loss in iteration no. 94968 ==> 0.48623353631837796\n",
            "Loss in iteration no. 94969 ==> 0.4862325213638168\n",
            "Loss in iteration no. 94970 ==> 0.48623150641857765\n",
            "Loss in iteration no. 94971 ==> 0.4862304914826605\n",
            "Loss in iteration no. 94972 ==> 0.48622947655606535\n",
            "Loss in iteration no. 94973 ==> 0.48622846163879185\n",
            "Loss in iteration no. 94974 ==> 0.4862274467308401\n",
            "Loss in iteration no. 94975 ==> 0.4862264318322098\n",
            "Loss in iteration no. 94976 ==> 0.48622541694290083\n",
            "Loss in iteration no. 94977 ==> 0.48622440206291323\n",
            "Loss in iteration no. 94978 ==> 0.4862233871922467\n",
            "Loss in iteration no. 94979 ==> 0.48622237233090126\n",
            "Loss in iteration no. 94980 ==> 0.48622135747887674\n",
            "Loss in iteration no. 94981 ==> 0.48622034263617303\n",
            "Loss in iteration no. 94982 ==> 0.4862193278027899\n",
            "Loss in iteration no. 94983 ==> 0.48621831297872736\n",
            "Loss in iteration no. 94984 ==> 0.48621729816398523\n",
            "Loss in iteration no. 94985 ==> 0.4862162833585635\n",
            "Loss in iteration no. 94986 ==> 0.4862152685624619\n",
            "Loss in iteration no. 94987 ==> 0.4862142537756803\n",
            "Loss in iteration no. 94988 ==> 0.4862132389982189\n",
            "Loss in iteration no. 94989 ==> 0.4862122242300771\n",
            "Loss in iteration no. 94990 ==> 0.48621120947125496\n",
            "Loss in iteration no. 94991 ==> 0.4862101947217526\n",
            "Loss in iteration no. 94992 ==> 0.48620917998156965\n",
            "Loss in iteration no. 94993 ==> 0.4862081652507061\n",
            "Loss in iteration no. 94994 ==> 0.4862071505291616\n",
            "Loss in iteration no. 94995 ==> 0.48620613581693634\n",
            "Loss in iteration no. 94996 ==> 0.4862051211140301\n",
            "Loss in iteration no. 94997 ==> 0.4862041064204426\n",
            "Loss in iteration no. 94998 ==> 0.4862030917361738\n",
            "Loss in iteration no. 94999 ==> 0.4862020770612238\n",
            "Loss in iteration no. 95000 ==> 0.48620106239559224\n",
            "Loss in iteration no. 95001 ==> 0.48620004773927905\n",
            "Loss in iteration no. 95002 ==> 0.4861990330922843\n",
            "Loss in iteration no. 95003 ==> 0.4861980184546075\n",
            "Loss in iteration no. 95004 ==> 0.48619700382624875\n",
            "Loss in iteration no. 95005 ==> 0.48619598920720786\n",
            "Loss in iteration no. 95006 ==> 0.4861949745974849\n",
            "Loss in iteration no. 95007 ==> 0.4861939599970795\n",
            "Loss in iteration no. 95008 ==> 0.4861929454059916\n",
            "Loss in iteration no. 95009 ==> 0.48619193082422124\n",
            "Loss in iteration no. 95010 ==> 0.48619091625176813\n",
            "Loss in iteration no. 95011 ==> 0.48618990168863224\n",
            "Loss in iteration no. 95012 ==> 0.48618888713481334\n",
            "Loss in iteration no. 95013 ==> 0.4861878725903115\n",
            "Loss in iteration no. 95014 ==> 0.48618685805512635\n",
            "Loss in iteration no. 95015 ==> 0.486185843529258\n",
            "Loss in iteration no. 95016 ==> 0.4861848290127062\n",
            "Loss in iteration no. 95017 ==> 0.48618381450547077\n",
            "Loss in iteration no. 95018 ==> 0.48618280000755176\n",
            "Loss in iteration no. 95019 ==> 0.486181785518949\n",
            "Loss in iteration no. 95020 ==> 0.48618077103966223\n",
            "Loss in iteration no. 95021 ==> 0.4861797565696916\n",
            "Loss in iteration no. 95022 ==> 0.4861787421090368\n",
            "Loss in iteration no. 95023 ==> 0.4861777276576976\n",
            "Loss in iteration no. 95024 ==> 0.48617671321567413\n",
            "Loss in iteration no. 95025 ==> 0.4861756987829662\n",
            "Loss in iteration no. 95026 ==> 0.48617468435957356\n",
            "Loss in iteration no. 95027 ==> 0.4861736699454962\n",
            "Loss in iteration no. 95028 ==> 0.48617265554073397\n",
            "Loss in iteration no. 95029 ==> 0.4861716411452868\n",
            "Loss in iteration no. 95030 ==> 0.4861706267591544\n",
            "Loss in iteration no. 95031 ==> 0.4861696123823369\n",
            "Loss in iteration no. 95032 ==> 0.4861685980148341\n",
            "Loss in iteration no. 95033 ==> 0.4861675836566457\n",
            "Loss in iteration no. 95034 ==> 0.4861665693077718\n",
            "Loss in iteration no. 95035 ==> 0.4861655549682122\n",
            "Loss in iteration no. 95036 ==> 0.48616454063796677\n",
            "Loss in iteration no. 95037 ==> 0.48616352631703535\n",
            "Loss in iteration no. 95038 ==> 0.4861625120054179\n",
            "Loss in iteration no. 95039 ==> 0.48616149770311423\n",
            "Loss in iteration no. 95040 ==> 0.48616048341012424\n",
            "Loss in iteration no. 95041 ==> 0.486159469126448\n",
            "Loss in iteration no. 95042 ==> 0.4861584548520849\n",
            "Loss in iteration no. 95043 ==> 0.4861574405870354\n",
            "Loss in iteration no. 95044 ==> 0.4861564263312991\n",
            "Loss in iteration no. 95045 ==> 0.4861554120848758\n",
            "Loss in iteration no. 95046 ==> 0.4861543978477655\n",
            "Loss in iteration no. 95047 ==> 0.48615338361996796\n",
            "Loss in iteration no. 95048 ==> 0.48615236940148326\n",
            "Loss in iteration no. 95049 ==> 0.48615135519231123\n",
            "Loss in iteration no. 95050 ==> 0.48615034099245164\n",
            "Loss in iteration no. 95051 ==> 0.4861493268019043\n",
            "Loss in iteration no. 95052 ==> 0.48614831262066943\n",
            "Loss in iteration no. 95053 ==> 0.4861472984487465\n",
            "Loss in iteration no. 95054 ==> 0.48614628428613577\n",
            "Loss in iteration no. 95055 ==> 0.4861452701328367\n",
            "Loss in iteration no. 95056 ==> 0.48614425598884964\n",
            "Loss in iteration no. 95057 ==> 0.486143241854174\n",
            "Loss in iteration no. 95058 ==> 0.4861422277288101\n",
            "Loss in iteration no. 95059 ==> 0.48614121361275753\n",
            "Loss in iteration no. 95060 ==> 0.48614019950601617\n",
            "Loss in iteration no. 95061 ==> 0.4861391854085861\n",
            "Loss in iteration no. 95062 ==> 0.48613817132046705\n",
            "Loss in iteration no. 95063 ==> 0.4861371572416589\n",
            "Loss in iteration no. 95064 ==> 0.48613614317216153\n",
            "Loss in iteration no. 95065 ==> 0.4861351291119749\n",
            "Loss in iteration no. 95066 ==> 0.48613411506109877\n",
            "Loss in iteration no. 95067 ==> 0.4861331010195332\n",
            "Loss in iteration no. 95068 ==> 0.48613208698727783\n",
            "Loss in iteration no. 95069 ==> 0.4861310729643328\n",
            "Loss in iteration no. 95070 ==> 0.4861300589506978\n",
            "Loss in iteration no. 95071 ==> 0.4861290449463728\n",
            "Loss in iteration no. 95072 ==> 0.48612803095135754\n",
            "Loss in iteration no. 95073 ==> 0.48612701696565214\n",
            "Loss in iteration no. 95074 ==> 0.4861260029892563\n",
            "Loss in iteration no. 95075 ==> 0.4861249890221699\n",
            "Loss in iteration no. 95076 ==> 0.486123975064393\n",
            "Loss in iteration no. 95077 ==> 0.4861229611159251\n",
            "Loss in iteration no. 95078 ==> 0.4861219471767665\n",
            "Loss in iteration no. 95079 ==> 0.48612093324691696\n",
            "Loss in iteration no. 95080 ==> 0.4861199193263763\n",
            "Loss in iteration no. 95081 ==> 0.48611890541514424\n",
            "Loss in iteration no. 95082 ==> 0.48611789151322093\n",
            "Loss in iteration no. 95083 ==> 0.48611687762060624\n",
            "Loss in iteration no. 95084 ==> 0.48611586373729987\n",
            "Loss in iteration no. 95085 ==> 0.4861148498633018\n",
            "Loss in iteration no. 95086 ==> 0.48611383599861174\n",
            "Loss in iteration no. 95087 ==> 0.48611282214323\n",
            "Loss in iteration no. 95088 ==> 0.48611180829715606\n",
            "Loss in iteration no. 95089 ==> 0.4861107944603898\n",
            "Loss in iteration no. 95090 ==> 0.48610978063293137\n",
            "Loss in iteration no. 95091 ==> 0.4861087668147806\n",
            "Loss in iteration no. 95092 ==> 0.48610775300593706\n",
            "Loss in iteration no. 95093 ==> 0.4861067392064009\n",
            "Loss in iteration no. 95094 ==> 0.4861057254161721\n",
            "Loss in iteration no. 95095 ==> 0.4861047116352502\n",
            "Loss in iteration no. 95096 ==> 0.4861036978636353\n",
            "Loss in iteration no. 95097 ==> 0.4861026841013273\n",
            "Loss in iteration no. 95098 ==> 0.48610167034832585\n",
            "Loss in iteration no. 95099 ==> 0.4861006566046312\n",
            "Loss in iteration no. 95100 ==> 0.48609964287024304\n",
            "Loss in iteration no. 95101 ==> 0.4860986291451613\n",
            "Loss in iteration no. 95102 ==> 0.48609761542938557\n",
            "Loss in iteration no. 95103 ==> 0.48609660172291613\n",
            "Loss in iteration no. 95104 ==> 0.4860955880257527\n",
            "Loss in iteration no. 95105 ==> 0.48609457433789505\n",
            "Loss in iteration no. 95106 ==> 0.4860935606593431\n",
            "Loss in iteration no. 95107 ==> 0.4860925469900971\n",
            "Loss in iteration no. 95108 ==> 0.4860915333301564\n",
            "Loss in iteration no. 95109 ==> 0.48609051967952116\n",
            "Loss in iteration no. 95110 ==> 0.48608950603819123\n",
            "Loss in iteration no. 95111 ==> 0.48608849240616625\n",
            "Loss in iteration no. 95112 ==> 0.48608747878344655\n",
            "Loss in iteration no. 95113 ==> 0.48608646517003173\n",
            "Loss in iteration no. 95114 ==> 0.48608545156592164\n",
            "Loss in iteration no. 95115 ==> 0.48608443797111645\n",
            "Loss in iteration no. 95116 ==> 0.4860834243856154\n",
            "Loss in iteration no. 95117 ==> 0.48608241080941916\n",
            "Loss in iteration no. 95118 ==> 0.4860813972425271\n",
            "Loss in iteration no. 95119 ==> 0.4860803836849393\n",
            "Loss in iteration no. 95120 ==> 0.48607937013665564\n",
            "Loss in iteration no. 95121 ==> 0.48607835659767573\n",
            "Loss in iteration no. 95122 ==> 0.48607734306799993\n",
            "Loss in iteration no. 95123 ==> 0.48607632954762764\n",
            "Loss in iteration no. 95124 ==> 0.48607531603655907\n",
            "Loss in iteration no. 95125 ==> 0.4860743025347938\n",
            "Loss in iteration no. 95126 ==> 0.48607328904233205\n",
            "Loss in iteration no. 95127 ==> 0.4860722755591736\n",
            "Loss in iteration no. 95128 ==> 0.48607126208531803\n",
            "Loss in iteration no. 95129 ==> 0.48607024862076564\n",
            "Loss in iteration no. 95130 ==> 0.4860692351655162\n",
            "Loss in iteration no. 95131 ==> 0.4860682217195694\n",
            "Loss in iteration no. 95132 ==> 0.4860672082829253\n",
            "Loss in iteration no. 95133 ==> 0.48606619485558356\n",
            "Loss in iteration no. 95134 ==> 0.4860651814375445\n",
            "Loss in iteration no. 95135 ==> 0.48606416802880753\n",
            "Loss in iteration no. 95136 ==> 0.48606315462937283\n",
            "Loss in iteration no. 95137 ==> 0.48606214123923996\n",
            "Loss in iteration no. 95138 ==> 0.4860611278584093\n",
            "Loss in iteration no. 95139 ==> 0.48606011448688025\n",
            "Loss in iteration no. 95140 ==> 0.4860591011246529\n",
            "Loss in iteration no. 95141 ==> 0.48605808777172715\n",
            "Loss in iteration no. 95142 ==> 0.486057074428103\n",
            "Loss in iteration no. 95143 ==> 0.4860560610937799\n",
            "Loss in iteration no. 95144 ==> 0.4860550477687581\n",
            "Loss in iteration no. 95145 ==> 0.4860540344530374\n",
            "Loss in iteration no. 95146 ==> 0.48605302114661775\n",
            "Loss in iteration no. 95147 ==> 0.4860520078494987\n",
            "Loss in iteration no. 95148 ==> 0.4860509945616805\n",
            "Loss in iteration no. 95149 ==> 0.486049981283163\n",
            "Loss in iteration no. 95150 ==> 0.4860489680139458\n",
            "Loss in iteration no. 95151 ==> 0.4860479547540291\n",
            "Loss in iteration no. 95152 ==> 0.48604694150341254\n",
            "Loss in iteration no. 95153 ==> 0.4860459282620962\n",
            "Loss in iteration no. 95154 ==> 0.48604491503007985\n",
            "Loss in iteration no. 95155 ==> 0.48604390180736345\n",
            "Loss in iteration no. 95156 ==> 0.4860428885939467\n",
            "Loss in iteration no. 95157 ==> 0.48604187538982957\n",
            "Loss in iteration no. 95158 ==> 0.4860408621950119\n",
            "Loss in iteration no. 95159 ==> 0.48603984900949376\n",
            "Loss in iteration no. 95160 ==> 0.4860388358332749\n",
            "Loss in iteration no. 95161 ==> 0.4860378226663552\n",
            "Loss in iteration no. 95162 ==> 0.48603680950873446\n",
            "Loss in iteration no. 95163 ==> 0.4860357963604127\n",
            "Loss in iteration no. 95164 ==> 0.48603478322138965\n",
            "Loss in iteration no. 95165 ==> 0.48603377009166543\n",
            "Loss in iteration no. 95166 ==> 0.4860327569712397\n",
            "Loss in iteration no. 95167 ==> 0.48603174386011244\n",
            "Loss in iteration no. 95168 ==> 0.4860307307582834\n",
            "Loss in iteration no. 95169 ==> 0.4860297176657527\n",
            "Loss in iteration no. 95170 ==> 0.48602870458252007\n",
            "Loss in iteration no. 95171 ==> 0.48602769150858527\n",
            "Loss in iteration no. 95172 ==> 0.48602667844394837\n",
            "Loss in iteration no. 95173 ==> 0.4860256653886093\n",
            "Loss in iteration no. 95174 ==> 0.48602465234256775\n",
            "Loss in iteration no. 95175 ==> 0.4860236393058236\n",
            "Loss in iteration no. 95176 ==> 0.4860226262783768\n",
            "Loss in iteration no. 95177 ==> 0.48602161326022747\n",
            "Loss in iteration no. 95178 ==> 0.48602060025137506\n",
            "Loss in iteration no. 95179 ==> 0.4860195872518197\n",
            "Loss in iteration no. 95180 ==> 0.4860185742615613\n",
            "Loss in iteration no. 95181 ==> 0.4860175612805996\n",
            "Loss in iteration no. 95182 ==> 0.4860165483089344\n",
            "Loss in iteration no. 95183 ==> 0.486015535346566\n",
            "Loss in iteration no. 95184 ==> 0.4860145223934938\n",
            "Loss in iteration no. 95185 ==> 0.4860135094497179\n",
            "Loss in iteration no. 95186 ==> 0.48601249651523826\n",
            "Loss in iteration no. 95187 ==> 0.4860114835900545\n",
            "Loss in iteration no. 95188 ==> 0.4860104706741669\n",
            "Loss in iteration no. 95189 ==> 0.48600945776757487\n",
            "Loss in iteration no. 95190 ==> 0.4860084448702786\n",
            "Loss in iteration no. 95191 ==> 0.48600743198227797\n",
            "Loss in iteration no. 95192 ==> 0.48600641910357273\n",
            "Loss in iteration no. 95193 ==> 0.4860054062341628\n",
            "Loss in iteration no. 95194 ==> 0.486004393374048\n",
            "Loss in iteration no. 95195 ==> 0.48600338052322845\n",
            "Loss in iteration no. 95196 ==> 0.48600236768170374\n",
            "Loss in iteration no. 95197 ==> 0.48600135484947393\n",
            "Loss in iteration no. 95198 ==> 0.48600034202653886\n",
            "Loss in iteration no. 95199 ==> 0.48599932921289835\n",
            "Loss in iteration no. 95200 ==> 0.4859983164085523\n",
            "Loss in iteration no. 95201 ==> 0.4859973036135007\n",
            "Loss in iteration no. 95202 ==> 0.4859962908277432\n",
            "Loss in iteration no. 95203 ==> 0.4859952780512799\n",
            "Loss in iteration no. 95204 ==> 0.4859942652841106\n",
            "Loss in iteration no. 95205 ==> 0.4859932525262353\n",
            "Loss in iteration no. 95206 ==> 0.48599223977765366\n",
            "Loss in iteration no. 95207 ==> 0.4859912270383655\n",
            "Loss in iteration no. 95208 ==> 0.4859902143083711\n",
            "Loss in iteration no. 95209 ==> 0.48598920158767006\n",
            "Loss in iteration no. 95210 ==> 0.4859881888762622\n",
            "Loss in iteration no. 95211 ==> 0.48598717617414766\n",
            "Loss in iteration no. 95212 ==> 0.485986163481326\n",
            "Loss in iteration no. 95213 ==> 0.48598515079779736\n",
            "Loss in iteration no. 95214 ==> 0.4859841381235615\n",
            "Loss in iteration no. 95215 ==> 0.4859831254586185\n",
            "Loss in iteration no. 95216 ==> 0.4859821128029677\n",
            "Loss in iteration no. 95217 ==> 0.4859811001566096\n",
            "Loss in iteration no. 95218 ==> 0.48598008751954386\n",
            "Loss in iteration no. 95219 ==> 0.4859790748917701\n",
            "Loss in iteration no. 95220 ==> 0.48597806227328855\n",
            "Loss in iteration no. 95221 ==> 0.4859770496640991\n",
            "Loss in iteration no. 95222 ==> 0.4859760370642014\n",
            "Loss in iteration no. 95223 ==> 0.4859750244735953\n",
            "Loss in iteration no. 95224 ==> 0.48597401189228095\n",
            "Loss in iteration no. 95225 ==> 0.485972999320258\n",
            "Loss in iteration no. 95226 ==> 0.4859719867575265\n",
            "Loss in iteration no. 95227 ==> 0.4859709742040862\n",
            "Loss in iteration no. 95228 ==> 0.485969961659937\n",
            "Loss in iteration no. 95229 ==> 0.48596894912507876\n",
            "Loss in iteration no. 95230 ==> 0.4859679365995116\n",
            "Loss in iteration no. 95231 ==> 0.4859669240832351\n",
            "Loss in iteration no. 95232 ==> 0.4859659115762492\n",
            "Loss in iteration no. 95233 ==> 0.4859648990785539\n",
            "Loss in iteration no. 95234 ==> 0.48596388659014883\n",
            "Loss in iteration no. 95235 ==> 0.4859628741110342\n",
            "Loss in iteration no. 95236 ==> 0.48596186164120975\n",
            "Loss in iteration no. 95237 ==> 0.48596084918067534\n",
            "Loss in iteration no. 95238 ==> 0.4859598367294308\n",
            "Loss in iteration no. 95239 ==> 0.48595882428747617\n",
            "Loss in iteration no. 95240 ==> 0.4859578118548112\n",
            "Loss in iteration no. 95241 ==> 0.48595679943143577\n",
            "Loss in iteration no. 95242 ==> 0.48595578701734976\n",
            "Loss in iteration no. 95243 ==> 0.48595477461255315\n",
            "Loss in iteration no. 95244 ==> 0.48595376221704567\n",
            "Loss in iteration no. 95245 ==> 0.4859527498308272\n",
            "Loss in iteration no. 95246 ==> 0.4859517374538979\n",
            "Loss in iteration no. 95247 ==> 0.48595072508625736\n",
            "Loss in iteration no. 95248 ==> 0.4859497127279055\n",
            "Loss in iteration no. 95249 ==> 0.4859487003788423\n",
            "Loss in iteration no. 95250 ==> 0.4859476880390676\n",
            "Loss in iteration no. 95251 ==> 0.48594667570858135\n",
            "Loss in iteration no. 95252 ==> 0.4859456633873833\n",
            "Loss in iteration no. 95253 ==> 0.4859446510754732\n",
            "Loss in iteration no. 95254 ==> 0.48594363877285135\n",
            "Loss in iteration no. 95255 ==> 0.48594262647951736\n",
            "Loss in iteration no. 95256 ==> 0.4859416141954709\n",
            "Loss in iteration no. 95257 ==> 0.48594060192071237\n",
            "Loss in iteration no. 95258 ==> 0.48593958965524126\n",
            "Loss in iteration no. 95259 ==> 0.4859385773990576\n",
            "Loss in iteration no. 95260 ==> 0.48593756515216124\n",
            "Loss in iteration no. 95261 ==> 0.48593655291455196\n",
            "Loss in iteration no. 95262 ==> 0.48593554068622985\n",
            "Loss in iteration no. 95263 ==> 0.48593452846719454\n",
            "Loss in iteration no. 95264 ==> 0.4859335162574461\n",
            "Loss in iteration no. 95265 ==> 0.48593250405698435\n",
            "Loss in iteration no. 95266 ==> 0.48593149186580936\n",
            "Loss in iteration no. 95267 ==> 0.48593047968392056\n",
            "Loss in iteration no. 95268 ==> 0.48592946751131816\n",
            "Loss in iteration no. 95269 ==> 0.48592845534800194\n",
            "Loss in iteration no. 95270 ==> 0.48592744319397196\n",
            "Loss in iteration no. 95271 ==> 0.4859264310492278\n",
            "Loss in iteration no. 95272 ==> 0.4859254189137697\n",
            "Loss in iteration no. 95273 ==> 0.4859244067875972\n",
            "Loss in iteration no. 95274 ==> 0.48592339467071033\n",
            "Loss in iteration no. 95275 ==> 0.4859223825631089\n",
            "Loss in iteration no. 95276 ==> 0.48592137046479295\n",
            "Loss in iteration no. 95277 ==> 0.48592035837576214\n",
            "Loss in iteration no. 95278 ==> 0.4859193462960165\n",
            "Loss in iteration no. 95279 ==> 0.4859183342255559\n",
            "Loss in iteration no. 95280 ==> 0.48591732216438027\n",
            "Loss in iteration no. 95281 ==> 0.4859163101124895\n",
            "Loss in iteration no. 95282 ==> 0.4859152980698831\n",
            "Loss in iteration no. 95283 ==> 0.4859142860365614\n",
            "Loss in iteration no. 95284 ==> 0.4859132740125241\n",
            "Loss in iteration no. 95285 ==> 0.485912261997771\n",
            "Loss in iteration no. 95286 ==> 0.4859112499923022\n",
            "Loss in iteration no. 95287 ==> 0.4859102379961173\n",
            "Loss in iteration no. 95288 ==> 0.4859092260092166\n",
            "Loss in iteration no. 95289 ==> 0.4859082140315995\n",
            "Loss in iteration no. 95290 ==> 0.48590720206326626\n",
            "Loss in iteration no. 95291 ==> 0.4859061901042165\n",
            "Loss in iteration no. 95292 ==> 0.4859051781544503\n",
            "Loss in iteration no. 95293 ==> 0.48590416621396737\n",
            "Loss in iteration no. 95294 ==> 0.4859031542827676\n",
            "Loss in iteration no. 95295 ==> 0.48590214236085105\n",
            "Loss in iteration no. 95296 ==> 0.4859011304482173\n",
            "Loss in iteration no. 95297 ==> 0.4859001185448666\n",
            "Loss in iteration no. 95298 ==> 0.48589910665079866\n",
            "Loss in iteration no. 95299 ==> 0.48589809476601326\n",
            "Loss in iteration no. 95300 ==> 0.4858970828905103\n",
            "Loss in iteration no. 95301 ==> 0.4858960710242898\n",
            "Loss in iteration no. 95302 ==> 0.4858950591673516\n",
            "Loss in iteration no. 95303 ==> 0.4858940473196954\n",
            "Loss in iteration no. 95304 ==> 0.4858930354813213\n",
            "Loss in iteration no. 95305 ==> 0.48589202365222917\n",
            "Loss in iteration no. 95306 ==> 0.4858910118324188\n",
            "Loss in iteration no. 95307 ==> 0.48589000002189014\n",
            "Loss in iteration no. 95308 ==> 0.48588898822064297\n",
            "Loss in iteration no. 95309 ==> 0.4858879764286772\n",
            "Loss in iteration no. 95310 ==> 0.48588696464599274\n",
            "Loss in iteration no. 95311 ==> 0.48588595287258945\n",
            "Loss in iteration no. 95312 ==> 0.48588494110846725\n",
            "Loss in iteration no. 95313 ==> 0.485883929353626\n",
            "Loss in iteration no. 95314 ==> 0.48588291760806557\n",
            "Loss in iteration no. 95315 ==> 0.48588190587178576\n",
            "Loss in iteration no. 95316 ==> 0.48588089414478663\n",
            "Loss in iteration no. 95317 ==> 0.48587988242706803\n",
            "Loss in iteration no. 95318 ==> 0.48587887071862973\n",
            "Loss in iteration no. 95319 ==> 0.48587785901947167\n",
            "Loss in iteration no. 95320 ==> 0.4858768473295937\n",
            "Loss in iteration no. 95321 ==> 0.48587583564899567\n",
            "Loss in iteration no. 95322 ==> 0.48587482397767756\n",
            "Loss in iteration no. 95323 ==> 0.48587381231563925\n",
            "Loss in iteration no. 95324 ==> 0.4858728006628805\n",
            "Loss in iteration no. 95325 ==> 0.48587178901940126\n",
            "Loss in iteration no. 95326 ==> 0.4858707773852014\n",
            "Loss in iteration no. 95327 ==> 0.48586976576028085\n",
            "Loss in iteration no. 95328 ==> 0.4858687541446393\n",
            "Loss in iteration no. 95329 ==> 0.485867742538277\n",
            "Loss in iteration no. 95330 ==> 0.4858667309411936\n",
            "Loss in iteration no. 95331 ==> 0.4858657193533889\n",
            "Loss in iteration no. 95332 ==> 0.48586470777486296\n",
            "Loss in iteration no. 95333 ==> 0.48586369620561537\n",
            "Loss in iteration no. 95334 ==> 0.4858626846456465\n",
            "Loss in iteration no. 95335 ==> 0.4858616730949558\n",
            "Loss in iteration no. 95336 ==> 0.48586066155354335\n",
            "Loss in iteration no. 95337 ==> 0.48585965002140885\n",
            "Loss in iteration no. 95338 ==> 0.48585863849855243\n",
            "Loss in iteration no. 95339 ==> 0.4858576269849738\n",
            "Loss in iteration no. 95340 ==> 0.4858566154806728\n",
            "Loss in iteration no. 95341 ==> 0.4858556039856496\n",
            "Loss in iteration no. 95342 ==> 0.48585459249990376\n",
            "Loss in iteration no. 95343 ==> 0.4858535810234353\n",
            "Loss in iteration no. 95344 ==> 0.48585256955624384\n",
            "Loss in iteration no. 95345 ==> 0.4858515580983298\n",
            "Loss in iteration no. 95346 ==> 0.4858505466496926\n",
            "Loss in iteration no. 95347 ==> 0.4858495352103325\n",
            "Loss in iteration no. 95348 ==> 0.48584852378024895\n",
            "Loss in iteration no. 95349 ==> 0.48584751235944207\n",
            "Loss in iteration no. 95350 ==> 0.4858465009479119\n",
            "Loss in iteration no. 95351 ==> 0.48584548954565787\n",
            "Loss in iteration no. 95352 ==> 0.4858444781526803\n",
            "Loss in iteration no. 95353 ==> 0.4858434667689787\n",
            "Loss in iteration no. 95354 ==> 0.4858424553945534\n",
            "Loss in iteration no. 95355 ==> 0.48584144402940377\n",
            "Loss in iteration no. 95356 ==> 0.4858404326735302\n",
            "Loss in iteration no. 95357 ==> 0.485839421326932\n",
            "Loss in iteration no. 95358 ==> 0.4858384099896096\n",
            "Loss in iteration no. 95359 ==> 0.4858373986615626\n",
            "Loss in iteration no. 95360 ==> 0.48583638734279083\n",
            "Loss in iteration no. 95361 ==> 0.4858353760332943\n",
            "Loss in iteration no. 95362 ==> 0.485834364733073\n",
            "Loss in iteration no. 95363 ==> 0.48583335344212647\n",
            "Loss in iteration no. 95364 ==> 0.48583234216045496\n",
            "Loss in iteration no. 95365 ==> 0.4858313308880581\n",
            "Loss in iteration no. 95366 ==> 0.4858303196249358\n",
            "Loss in iteration no. 95367 ==> 0.48582930837108795\n",
            "Loss in iteration no. 95368 ==> 0.4858282971265145\n",
            "Loss in iteration no. 95369 ==> 0.4858272858912154\n",
            "Loss in iteration no. 95370 ==> 0.48582627466519035\n",
            "Loss in iteration no. 95371 ==> 0.48582526344843935\n",
            "Loss in iteration no. 95372 ==> 0.48582425224096226\n",
            "Loss in iteration no. 95373 ==> 0.485823241042759\n",
            "Loss in iteration no. 95374 ==> 0.4858222298538292\n",
            "Loss in iteration no. 95375 ==> 0.485821218674173\n",
            "Loss in iteration no. 95376 ==> 0.48582020750379024\n",
            "Loss in iteration no. 95377 ==> 0.4858191963426808\n",
            "Loss in iteration no. 95378 ==> 0.4858181851908446\n",
            "Loss in iteration no. 95379 ==> 0.4858171740482813\n",
            "Loss in iteration no. 95380 ==> 0.485816162914991\n",
            "Loss in iteration no. 95381 ==> 0.48581515179097345\n",
            "Loss in iteration no. 95382 ==> 0.4858141406762287\n",
            "Loss in iteration no. 95383 ==> 0.48581312957075645\n",
            "Loss in iteration no. 95384 ==> 0.48581211847455674\n",
            "Loss in iteration no. 95385 ==> 0.4858111073876293\n",
            "Loss in iteration no. 95386 ==> 0.48581009630997396\n",
            "Loss in iteration no. 95387 ==> 0.4858090852415909\n",
            "Loss in iteration no. 95388 ==> 0.48580807418247973\n",
            "Loss in iteration no. 95389 ==> 0.48580706313264044\n",
            "Loss in iteration no. 95390 ==> 0.48580605209207284\n",
            "Loss in iteration no. 95391 ==> 0.48580504106077693\n",
            "Loss in iteration no. 95392 ==> 0.4858040300387525\n",
            "Loss in iteration no. 95393 ==> 0.4858030190259995\n",
            "Loss in iteration no. 95394 ==> 0.4858020080225176\n",
            "Loss in iteration no. 95395 ==> 0.48580099702830704\n",
            "Loss in iteration no. 95396 ==> 0.4857999860433673\n",
            "Loss in iteration no. 95397 ==> 0.4857989750676986\n",
            "Loss in iteration no. 95398 ==> 0.4857979641013007\n",
            "Loss in iteration no. 95399 ==> 0.4857969531441735\n",
            "Loss in iteration no. 95400 ==> 0.48579594219631667\n",
            "Loss in iteration no. 95401 ==> 0.4857949312577305\n",
            "Loss in iteration no. 95402 ==> 0.48579392032841434\n",
            "Loss in iteration no. 95403 ==> 0.48579290940836856\n",
            "Loss in iteration no. 95404 ==> 0.48579189849759274\n",
            "Loss in iteration no. 95405 ==> 0.4857908875960869\n",
            "Loss in iteration no. 95406 ==> 0.485789876703851\n",
            "Loss in iteration no. 95407 ==> 0.48578886582088465\n",
            "Loss in iteration no. 95408 ==> 0.485787854947188\n",
            "Loss in iteration no. 95409 ==> 0.48578684408276085\n",
            "Loss in iteration no. 95410 ==> 0.48578583322760294\n",
            "Loss in iteration no. 95411 ==> 0.4857848223817142\n",
            "Loss in iteration no. 95412 ==> 0.4857838115450947\n",
            "Loss in iteration no. 95413 ==> 0.4857828007177442\n",
            "Loss in iteration no. 95414 ==> 0.4857817898996625\n",
            "Loss in iteration no. 95415 ==> 0.4857807790908495\n",
            "Loss in iteration no. 95416 ==> 0.48577976829130526\n",
            "Loss in iteration no. 95417 ==> 0.48577875750102945\n",
            "Loss in iteration no. 95418 ==> 0.48577774672002205\n",
            "Loss in iteration no. 95419 ==> 0.48577673594828286\n",
            "Loss in iteration no. 95420 ==> 0.48577572518581197\n",
            "Loss in iteration no. 95421 ==> 0.48577471443260906\n",
            "Loss in iteration no. 95422 ==> 0.485773703688674\n",
            "Loss in iteration no. 95423 ==> 0.48577269295400677\n",
            "Loss in iteration no. 95424 ==> 0.4857716822286073\n",
            "Loss in iteration no. 95425 ==> 0.48577067151247527\n",
            "Loss in iteration no. 95426 ==> 0.4857696608056108\n",
            "Loss in iteration no. 95427 ==> 0.4857686501080135\n",
            "Loss in iteration no. 95428 ==> 0.48576763941968343\n",
            "Loss in iteration no. 95429 ==> 0.48576662874062054\n",
            "Loss in iteration no. 95430 ==> 0.4857656180708246\n",
            "Loss in iteration no. 95431 ==> 0.4857646074102953\n",
            "Loss in iteration no. 95432 ==> 0.485763596759033\n",
            "Loss in iteration no. 95433 ==> 0.4857625861170372\n",
            "Loss in iteration no. 95434 ==> 0.4857615754843078\n",
            "Loss in iteration no. 95435 ==> 0.4857605648608448\n",
            "Loss in iteration no. 95436 ==> 0.485759554246648\n",
            "Loss in iteration no. 95437 ==> 0.48575854364171756\n",
            "Loss in iteration no. 95438 ==> 0.48575753304605285\n",
            "Loss in iteration no. 95439 ==> 0.4857565224596541\n",
            "Loss in iteration no. 95440 ==> 0.4857555118825211\n",
            "Loss in iteration no. 95441 ==> 0.48575450131465375\n",
            "Loss in iteration no. 95442 ==> 0.485753490756052\n",
            "Loss in iteration no. 95443 ==> 0.48575248020671574\n",
            "Loss in iteration no. 95444 ==> 0.4857514696666446\n",
            "Loss in iteration no. 95445 ==> 0.4857504591358386\n",
            "Loss in iteration no. 95446 ==> 0.4857494486142977\n",
            "Loss in iteration no. 95447 ==> 0.48574843810202184\n",
            "Loss in iteration no. 95448 ==> 0.4857474275990107\n",
            "Loss in iteration no. 95449 ==> 0.48574641710526417\n",
            "Loss in iteration no. 95450 ==> 0.4857454066207823\n",
            "Loss in iteration no. 95451 ==> 0.48574439614556486\n",
            "Loss in iteration no. 95452 ==> 0.4857433856796118\n",
            "Loss in iteration no. 95453 ==> 0.48574237522292285\n",
            "Loss in iteration no. 95454 ==> 0.4857413647754981\n",
            "Loss in iteration no. 95455 ==> 0.48574035433733737\n",
            "Loss in iteration no. 95456 ==> 0.48573934390844037\n",
            "Loss in iteration no. 95457 ==> 0.48573833348880713\n",
            "Loss in iteration no. 95458 ==> 0.48573732307843764\n",
            "Loss in iteration no. 95459 ==> 0.4857363126773315\n",
            "Loss in iteration no. 95460 ==> 0.48573530228548883\n",
            "Loss in iteration no. 95461 ==> 0.48573429190290934\n",
            "Loss in iteration no. 95462 ==> 0.48573328152959294\n",
            "Loss in iteration no. 95463 ==> 0.48573227116553963\n",
            "Loss in iteration no. 95464 ==> 0.48573126081074924\n",
            "Loss in iteration no. 95465 ==> 0.4857302504652216\n",
            "Loss in iteration no. 95466 ==> 0.4857292401289566\n",
            "Loss in iteration no. 95467 ==> 0.4857282298019541\n",
            "Loss in iteration no. 95468 ==> 0.48572721948421416\n",
            "Loss in iteration no. 95469 ==> 0.4857262091757365\n",
            "Loss in iteration no. 95470 ==> 0.48572519887652105\n",
            "Loss in iteration no. 95471 ==> 0.4857241885865675\n",
            "Loss in iteration no. 95472 ==> 0.485723178305876\n",
            "Loss in iteration no. 95473 ==> 0.4857221680344464\n",
            "Loss in iteration no. 95474 ==> 0.4857211577722784\n",
            "Loss in iteration no. 95475 ==> 0.485720147519372\n",
            "Loss in iteration no. 95476 ==> 0.4857191372757271\n",
            "Loss in iteration no. 95477 ==> 0.48571812704134354\n",
            "Loss in iteration no. 95478 ==> 0.48571711681622115\n",
            "Loss in iteration no. 95479 ==> 0.4857161066003599\n",
            "Loss in iteration no. 95480 ==> 0.48571509639375965\n",
            "Loss in iteration no. 95481 ==> 0.48571408619642026\n",
            "Loss in iteration no. 95482 ==> 0.4857130760083417\n",
            "Loss in iteration no. 95483 ==> 0.4857120658295238\n",
            "Loss in iteration no. 95484 ==> 0.4857110556599663\n",
            "Loss in iteration no. 95485 ==> 0.4857100454996692\n",
            "Loss in iteration no. 95486 ==> 0.4857090353486324\n",
            "Loss in iteration no. 95487 ==> 0.4857080252068557\n",
            "Loss in iteration no. 95488 ==> 0.4857070150743392\n",
            "Loss in iteration no. 95489 ==> 0.4857060049510824\n",
            "Loss in iteration no. 95490 ==> 0.48570499483708557\n",
            "Loss in iteration no. 95491 ==> 0.48570398473234844\n",
            "Loss in iteration no. 95492 ==> 0.4857029746368707\n",
            "Loss in iteration no. 95493 ==> 0.4857019645506525\n",
            "Loss in iteration no. 95494 ==> 0.4857009544736936\n",
            "Loss in iteration no. 95495 ==> 0.4856999444059939\n",
            "Loss in iteration no. 95496 ==> 0.48569893434755335\n",
            "Loss in iteration no. 95497 ==> 0.48569792429837166\n",
            "Loss in iteration no. 95498 ==> 0.48569691425844885\n",
            "Loss in iteration no. 95499 ==> 0.4856959042277847\n",
            "Loss in iteration no. 95500 ==> 0.48569489420637935\n",
            "Loss in iteration no. 95501 ==> 0.4856938841942323\n",
            "Loss in iteration no. 95502 ==> 0.4856928741913437\n",
            "Loss in iteration no. 95503 ==> 0.4856918641977133\n",
            "Loss in iteration no. 95504 ==> 0.4856908542133411\n",
            "Loss in iteration no. 95505 ==> 0.4856898442382268\n",
            "Loss in iteration no. 95506 ==> 0.4856888342723705\n",
            "Loss in iteration no. 95507 ==> 0.4856878243157719\n",
            "Loss in iteration no. 95508 ==> 0.4856868143684309\n",
            "Loss in iteration no. 95509 ==> 0.4856858044303476\n",
            "Loss in iteration no. 95510 ==> 0.4856847945015215\n",
            "Loss in iteration no. 95511 ==> 0.4856837845819529\n",
            "Loss in iteration no. 95512 ==> 0.48568277467164134\n",
            "Loss in iteration no. 95513 ==> 0.48568176477058694\n",
            "Loss in iteration no. 95514 ==> 0.4856807548787894\n",
            "Loss in iteration no. 95515 ==> 0.48567974499624866\n",
            "Loss in iteration no. 95516 ==> 0.4856787351229647\n",
            "Loss in iteration no. 95517 ==> 0.4856777252589372\n",
            "Loss in iteration no. 95518 ==> 0.48567671540416624\n",
            "Loss in iteration no. 95519 ==> 0.48567570555865164\n",
            "Loss in iteration no. 95520 ==> 0.4856746957223932\n",
            "Loss in iteration no. 95521 ==> 0.48567368589539084\n",
            "Loss in iteration no. 95522 ==> 0.48567267607764447\n",
            "Loss in iteration no. 95523 ==> 0.48567166626915403\n",
            "Loss in iteration no. 95524 ==> 0.48567065646991925\n",
            "Loss in iteration no. 95525 ==> 0.48566964667994017\n",
            "Loss in iteration no. 95526 ==> 0.48566863689921663\n",
            "Loss in iteration no. 95527 ==> 0.4856676271277483\n",
            "Loss in iteration no. 95528 ==> 0.48566661736553535\n",
            "Loss in iteration no. 95529 ==> 0.48566560761257754\n",
            "Loss in iteration no. 95530 ==> 0.4856645978688748\n",
            "Loss in iteration no. 95531 ==> 0.48566358813442695\n",
            "Loss in iteration no. 95532 ==> 0.4856625784092338\n",
            "Loss in iteration no. 95533 ==> 0.48566156869329546\n",
            "Loss in iteration no. 95534 ==> 0.4856605589866115\n",
            "Loss in iteration no. 95535 ==> 0.48565954928918204\n",
            "Loss in iteration no. 95536 ==> 0.485658539601007\n",
            "Loss in iteration no. 95537 ==> 0.485657529922086\n",
            "Loss in iteration no. 95538 ==> 0.48565652025241907\n",
            "Loss in iteration no. 95539 ==> 0.4856555105920062\n",
            "Loss in iteration no. 95540 ==> 0.48565450094084717\n",
            "Loss in iteration no. 95541 ==> 0.4856534912989418\n",
            "Loss in iteration no. 95542 ==> 0.48565248166629\n",
            "Loss in iteration no. 95543 ==> 0.4856514720428917\n",
            "Loss in iteration no. 95544 ==> 0.4856504624287468\n",
            "Loss in iteration no. 95545 ==> 0.48564945282385513\n",
            "Loss in iteration no. 95546 ==> 0.48564844322821665\n",
            "Loss in iteration no. 95547 ==> 0.48564743364183105\n",
            "Loss in iteration no. 95548 ==> 0.4856464240646984\n",
            "Loss in iteration no. 95549 ==> 0.4856454144968184\n",
            "Loss in iteration no. 95550 ==> 0.4856444049381912\n",
            "Loss in iteration no. 95551 ==> 0.48564339538881646\n",
            "Loss in iteration no. 95552 ==> 0.485642385848694\n",
            "Loss in iteration no. 95553 ==> 0.48564137631782395\n",
            "Loss in iteration no. 95554 ==> 0.48564036679620615\n",
            "Loss in iteration no. 95555 ==> 0.4856393572838403\n",
            "Loss in iteration no. 95556 ==> 0.48563834778072634\n",
            "Loss in iteration no. 95557 ==> 0.4856373382868643\n",
            "Loss in iteration no. 95558 ==> 0.48563632880225377\n",
            "Loss in iteration no. 95559 ==> 0.4856353193268951\n",
            "Loss in iteration no. 95560 ==> 0.48563430986078754\n",
            "Loss in iteration no. 95561 ==> 0.48563330040393154\n",
            "Loss in iteration no. 95562 ==> 0.48563229095632665\n",
            "Loss in iteration no. 95563 ==> 0.48563128151797286\n",
            "Loss in iteration no. 95564 ==> 0.4856302720888702\n",
            "Loss in iteration no. 95565 ==> 0.48562926266901824\n",
            "Loss in iteration no. 95566 ==> 0.4856282532584171\n",
            "Loss in iteration no. 95567 ==> 0.4856272438570665\n",
            "Loss in iteration no. 95568 ==> 0.48562623446496633\n",
            "Loss in iteration no. 95569 ==> 0.48562522508211675\n",
            "Loss in iteration no. 95570 ==> 0.4856242157085173\n",
            "Loss in iteration no. 95571 ==> 0.485623206344168\n",
            "Loss in iteration no. 95572 ==> 0.4856221969890687\n",
            "Loss in iteration no. 95573 ==> 0.4856211876432194\n",
            "Loss in iteration no. 95574 ==> 0.48562017830661974\n",
            "Loss in iteration no. 95575 ==> 0.4856191689792698\n",
            "Loss in iteration no. 95576 ==> 0.4856181596611694\n",
            "Loss in iteration no. 95577 ==> 0.4856171503523185\n",
            "Loss in iteration no. 95578 ==> 0.48561614105271683\n",
            "Loss in iteration no. 95579 ==> 0.4856151317623645\n",
            "Loss in iteration no. 95580 ==> 0.4856141224812611\n",
            "Loss in iteration no. 95581 ==> 0.48561311320940653\n",
            "Loss in iteration no. 95582 ==> 0.48561210394680093\n",
            "Loss in iteration no. 95583 ==> 0.4856110946934441\n",
            "Loss in iteration no. 95584 ==> 0.4856100854493358\n",
            "Loss in iteration no. 95585 ==> 0.4856090762144759\n",
            "Loss in iteration no. 95586 ==> 0.48560806698886444\n",
            "Loss in iteration no. 95587 ==> 0.48560705777250124\n",
            "Loss in iteration no. 95588 ==> 0.4856060485653862\n",
            "Loss in iteration no. 95589 ==> 0.48560503936751903\n",
            "Loss in iteration no. 95590 ==> 0.4856040301788998\n",
            "Loss in iteration no. 95591 ==> 0.4856030209995283\n",
            "Loss in iteration no. 95592 ==> 0.48560201182940455\n",
            "Loss in iteration no. 95593 ==> 0.4856010026685282\n",
            "Loss in iteration no. 95594 ==> 0.4855999935168992\n",
            "Loss in iteration no. 95595 ==> 0.48559898437451754\n",
            "Loss in iteration no. 95596 ==> 0.485597975241383\n",
            "Loss in iteration no. 95597 ==> 0.48559696611749564\n",
            "Loss in iteration no. 95598 ==> 0.4855959570028551\n",
            "Loss in iteration no. 95599 ==> 0.4855949478974614\n",
            "Loss in iteration no. 95600 ==> 0.4855939388013144\n",
            "Loss in iteration no. 95601 ==> 0.485592929714414\n",
            "Loss in iteration no. 95602 ==> 0.4855919206367599\n",
            "Loss in iteration no. 95603 ==> 0.48559091156835227\n",
            "Loss in iteration no. 95604 ==> 0.4855899025091908\n",
            "Loss in iteration no. 95605 ==> 0.4855888934592754\n",
            "Loss in iteration no. 95606 ==> 0.48558788441860606\n",
            "Loss in iteration no. 95607 ==> 0.48558687538718254\n",
            "Loss in iteration no. 95608 ==> 0.4855858663650047\n",
            "Loss in iteration no. 95609 ==> 0.48558485735207246\n",
            "Loss in iteration no. 95610 ==> 0.48558384834838575\n",
            "Loss in iteration no. 95611 ==> 0.48558283935394436\n",
            "Loss in iteration no. 95612 ==> 0.4855818303687483\n",
            "Loss in iteration no. 95613 ==> 0.4855808213927974\n",
            "Loss in iteration no. 95614 ==> 0.4855798124260915\n",
            "Loss in iteration no. 95615 ==> 0.4855788034686305\n",
            "Loss in iteration no. 95616 ==> 0.48557779452041433\n",
            "Loss in iteration no. 95617 ==> 0.4855767855814428\n",
            "Loss in iteration no. 95618 ==> 0.48557577665171575\n",
            "Loss in iteration no. 95619 ==> 0.48557476773123315\n",
            "Loss in iteration no. 95620 ==> 0.48557375881999487\n",
            "Loss in iteration no. 95621 ==> 0.4855727499180007\n",
            "Loss in iteration no. 95622 ==> 0.48557174102525075\n",
            "Loss in iteration no. 95623 ==> 0.4855707321417447\n",
            "Loss in iteration no. 95624 ==> 0.48556972326748243\n",
            "Loss in iteration no. 95625 ==> 0.4855687144024639\n",
            "Loss in iteration no. 95626 ==> 0.4855677055466888\n",
            "Loss in iteration no. 95627 ==> 0.4855666967001575\n",
            "Loss in iteration no. 95628 ==> 0.48556568786286924\n",
            "Loss in iteration no. 95629 ==> 0.4855646790348243\n",
            "Loss in iteration no. 95630 ==> 0.4855636702160226\n",
            "Loss in iteration no. 95631 ==> 0.48556266140646376\n",
            "Loss in iteration no. 95632 ==> 0.48556165260614803\n",
            "Loss in iteration no. 95633 ==> 0.4855606438150748\n",
            "Loss in iteration no. 95634 ==> 0.48555963503324434\n",
            "Loss in iteration no. 95635 ==> 0.48555862626065627\n",
            "Loss in iteration no. 95636 ==> 0.4855576174973107\n",
            "Loss in iteration no. 95637 ==> 0.4855566087432074\n",
            "Loss in iteration no. 95638 ==> 0.4855555999983463\n",
            "Loss in iteration no. 95639 ==> 0.48555459126272726\n",
            "Loss in iteration no. 95640 ==> 0.48555358253635\n",
            "Loss in iteration no. 95641 ==> 0.4855525738192146\n",
            "Loss in iteration no. 95642 ==> 0.48555156511132097\n",
            "Loss in iteration no. 95643 ==> 0.4855505564126689\n",
            "Loss in iteration no. 95644 ==> 0.4855495477232582\n",
            "Loss in iteration no. 95645 ==> 0.485548539043089\n",
            "Loss in iteration no. 95646 ==> 0.48554753037216086\n",
            "Loss in iteration no. 95647 ==> 0.4855465217104738\n",
            "Loss in iteration no. 95648 ==> 0.4855455130580278\n",
            "Loss in iteration no. 95649 ==> 0.4855445044148226\n",
            "Loss in iteration no. 95650 ==> 0.4855434957808581\n",
            "Loss in iteration no. 95651 ==> 0.48554248715613424\n",
            "Loss in iteration no. 95652 ==> 0.4855414785406509\n",
            "Loss in iteration no. 95653 ==> 0.48554046993440797\n",
            "Loss in iteration no. 95654 ==> 0.48553946133740533\n",
            "Loss in iteration no. 95655 ==> 0.4855384527496428\n",
            "Loss in iteration no. 95656 ==> 0.48553744417112016\n",
            "Loss in iteration no. 95657 ==> 0.48553643560183757\n",
            "Loss in iteration no. 95658 ==> 0.4855354270417946\n",
            "Loss in iteration no. 95659 ==> 0.4855344184909915\n",
            "Loss in iteration no. 95660 ==> 0.4855334099494279\n",
            "Loss in iteration no. 95661 ==> 0.48553240141710374\n",
            "Loss in iteration no. 95662 ==> 0.4855313928940188\n",
            "Loss in iteration no. 95663 ==> 0.48553038438017304\n",
            "Loss in iteration no. 95664 ==> 0.4855293758755664\n",
            "Loss in iteration no. 95665 ==> 0.48552836738019883\n",
            "Loss in iteration no. 95666 ==> 0.48552735889406984\n",
            "Loss in iteration no. 95667 ==> 0.48552635041717973\n",
            "Loss in iteration no. 95668 ==> 0.4855253419495282\n",
            "Loss in iteration no. 95669 ==> 0.48552433349111507\n",
            "Loss in iteration no. 95670 ==> 0.48552332504194035\n",
            "Loss in iteration no. 95671 ==> 0.4855223166020039\n",
            "Loss in iteration no. 95672 ==> 0.48552130817130557\n",
            "Loss in iteration no. 95673 ==> 0.48552029974984523\n",
            "Loss in iteration no. 95674 ==> 0.4855192913376227\n",
            "Loss in iteration no. 95675 ==> 0.48551828293463806\n",
            "Loss in iteration no. 95676 ==> 0.4855172745408909\n",
            "Loss in iteration no. 95677 ==> 0.4855162661563814\n",
            "Loss in iteration no. 95678 ==> 0.48551525778110916\n",
            "Loss in iteration no. 95679 ==> 0.48551424941507443\n",
            "Loss in iteration no. 95680 ==> 0.4855132410582768\n",
            "Loss in iteration no. 95681 ==> 0.4855122327107161\n",
            "Loss in iteration no. 95682 ==> 0.4855112243723923\n",
            "Loss in iteration no. 95683 ==> 0.4855102160433054\n",
            "Loss in iteration no. 95684 ==> 0.48550920772345524\n",
            "Loss in iteration no. 95685 ==> 0.4855081994128416\n",
            "Loss in iteration no. 95686 ==> 0.48550719111146445\n",
            "Loss in iteration no. 95687 ==> 0.4855061828193237\n",
            "Loss in iteration no. 95688 ==> 0.48550517453641884\n",
            "Loss in iteration no. 95689 ==> 0.48550416626275045\n",
            "Loss in iteration no. 95690 ==> 0.48550315799831784\n",
            "Loss in iteration no. 95691 ==> 0.48550214974312106\n",
            "Loss in iteration no. 95692 ==> 0.4855011414971602\n",
            "Loss in iteration no. 95693 ==> 0.4855001332604349\n",
            "Loss in iteration no. 95694 ==> 0.48549912503294496\n",
            "Loss in iteration no. 95695 ==> 0.48549811681469063\n",
            "Loss in iteration no. 95696 ==> 0.48549710860567136\n",
            "Loss in iteration no. 95697 ==> 0.4854961004058874\n",
            "Loss in iteration no. 95698 ==> 0.4854950922153384\n",
            "Loss in iteration no. 95699 ==> 0.4854940840340243\n",
            "Loss in iteration no. 95700 ==> 0.485493075861945\n",
            "Loss in iteration no. 95701 ==> 0.4854920676991004\n",
            "Loss in iteration no. 95702 ==> 0.48549105954549016\n",
            "Loss in iteration no. 95703 ==> 0.48549005140111456\n",
            "Loss in iteration no. 95704 ==> 0.4854890432659733\n",
            "Loss in iteration no. 95705 ==> 0.48548803514006605\n",
            "Loss in iteration no. 95706 ==> 0.4854870270233931\n",
            "Loss in iteration no. 95707 ==> 0.48548601891595394\n",
            "Loss in iteration no. 95708 ==> 0.4854850108177487\n",
            "Loss in iteration no. 95709 ==> 0.4854840027287772\n",
            "Loss in iteration no. 95710 ==> 0.48548299464903916\n",
            "Loss in iteration no. 95711 ==> 0.48548198657853475\n",
            "Loss in iteration no. 95712 ==> 0.48548097851726363\n",
            "Loss in iteration no. 95713 ==> 0.48547997046522573\n",
            "Loss in iteration no. 95714 ==> 0.485478962422421\n",
            "Loss in iteration no. 95715 ==> 0.4854779543888493\n",
            "Loss in iteration no. 95716 ==> 0.4854769463645105\n",
            "Loss in iteration no. 95717 ==> 0.4854759383494043\n",
            "Loss in iteration no. 95718 ==> 0.48547493034353095\n",
            "Loss in iteration no. 95719 ==> 0.4854739223468901\n",
            "Loss in iteration no. 95720 ==> 0.4854729143594816\n",
            "Loss in iteration no. 95721 ==> 0.48547190638130544\n",
            "Loss in iteration no. 95722 ==> 0.4854708984123615\n",
            "Loss in iteration no. 95723 ==> 0.48546989045264954\n",
            "Loss in iteration no. 95724 ==> 0.4854688825021696\n",
            "Loss in iteration no. 95725 ==> 0.4854678745609213\n",
            "Loss in iteration no. 95726 ==> 0.48546686662890476\n",
            "Loss in iteration no. 95727 ==> 0.4854658587061198\n",
            "Loss in iteration no. 95728 ==> 0.48546485079256635\n",
            "Loss in iteration no. 95729 ==> 0.4854638428882444\n",
            "Loss in iteration no. 95730 ==> 0.48546283499315346\n",
            "Loss in iteration no. 95731 ==> 0.4854618271072937\n",
            "Loss in iteration no. 95732 ==> 0.4854608192306649\n",
            "Loss in iteration no. 95733 ==> 0.485459811363267\n",
            "Loss in iteration no. 95734 ==> 0.4854588035050998\n",
            "Loss in iteration no. 95735 ==> 0.48545779565616326\n",
            "Loss in iteration no. 95736 ==> 0.48545678781645724\n",
            "Loss in iteration no. 95737 ==> 0.48545577998598155\n",
            "Loss in iteration no. 95738 ==> 0.48545477216473626\n",
            "Loss in iteration no. 95739 ==> 0.48545376435272103\n",
            "Loss in iteration no. 95740 ==> 0.4854527565499358\n",
            "Loss in iteration no. 95741 ==> 0.48545174875638064\n",
            "Loss in iteration no. 95742 ==> 0.4854507409720551\n",
            "Loss in iteration no. 95743 ==> 0.4854497331969594\n",
            "Loss in iteration no. 95744 ==> 0.48544872543109324\n",
            "Loss in iteration no. 95745 ==> 0.48544771767445644\n",
            "Loss in iteration no. 95746 ==> 0.4854467099270491\n",
            "Loss in iteration no. 95747 ==> 0.4854457021888708\n",
            "Loss in iteration no. 95748 ==> 0.4854446944599216\n",
            "Loss in iteration no. 95749 ==> 0.4854436867402014\n",
            "Loss in iteration no. 95750 ==> 0.4854426790297101\n",
            "Loss in iteration no. 95751 ==> 0.4854416713284474\n",
            "Loss in iteration no. 95752 ==> 0.48544066363641347\n",
            "Loss in iteration no. 95753 ==> 0.485439655953608\n",
            "Loss in iteration no. 95754 ==> 0.48543864828003075\n",
            "Loss in iteration no. 95755 ==> 0.485437640615682\n",
            "Loss in iteration no. 95756 ==> 0.48543663296056117\n",
            "Loss in iteration no. 95757 ==> 0.4854356253146685\n",
            "Loss in iteration no. 95758 ==> 0.48543461767800367\n",
            "Loss in iteration no. 95759 ==> 0.4854336100505666\n",
            "Loss in iteration no. 95760 ==> 0.4854326024323572\n",
            "Loss in iteration no. 95761 ==> 0.48543159482337533\n",
            "Loss in iteration no. 95762 ==> 0.485430587223621\n",
            "Loss in iteration no. 95763 ==> 0.4854295796330939\n",
            "Loss in iteration no. 95764 ==> 0.48542857205179407\n",
            "Loss in iteration no. 95765 ==> 0.48542756447972113\n",
            "Loss in iteration no. 95766 ==> 0.48542655691687525\n",
            "Loss in iteration no. 95767 ==> 0.48542554936325616\n",
            "Loss in iteration no. 95768 ==> 0.48542454181886385\n",
            "Loss in iteration no. 95769 ==> 0.485423534283698\n",
            "Loss in iteration no. 95770 ==> 0.48542252675775877\n",
            "Loss in iteration no. 95771 ==> 0.48542151924104576\n",
            "Loss in iteration no. 95772 ==> 0.48542051173355905\n",
            "Loss in iteration no. 95773 ==> 0.48541950423529856\n",
            "Loss in iteration no. 95774 ==> 0.48541849674626397\n",
            "Loss in iteration no. 95775 ==> 0.4854174892664552\n",
            "Loss in iteration no. 95776 ==> 0.4854164817958723\n",
            "Loss in iteration no. 95777 ==> 0.485415474334515\n",
            "Loss in iteration no. 95778 ==> 0.4854144668823832\n",
            "Loss in iteration no. 95779 ==> 0.48541345943947684\n",
            "Loss in iteration no. 95780 ==> 0.48541245200579575\n",
            "Loss in iteration no. 95781 ==> 0.4854114445813399\n",
            "Loss in iteration no. 95782 ==> 0.48541043716610904\n",
            "Loss in iteration no. 95783 ==> 0.485409429760103\n",
            "Loss in iteration no. 95784 ==> 0.48540842236332193\n",
            "Loss in iteration no. 95785 ==> 0.48540741497576556\n",
            "Loss in iteration no. 95786 ==> 0.48540640759743364\n",
            "Loss in iteration no. 95787 ==> 0.48540540022832623\n",
            "Loss in iteration no. 95788 ==> 0.48540439286844317\n",
            "Loss in iteration no. 95789 ==> 0.48540338551778434\n",
            "Loss in iteration no. 95790 ==> 0.48540237817634957\n",
            "Loss in iteration no. 95791 ==> 0.4854013708441388\n",
            "Loss in iteration no. 95792 ==> 0.4854003635211519\n",
            "Loss in iteration no. 95793 ==> 0.48539935620738883\n",
            "Loss in iteration no. 95794 ==> 0.4853983489028492\n",
            "Loss in iteration no. 95795 ==> 0.4853973416075332\n",
            "Loss in iteration no. 95796 ==> 0.4853963343214405\n",
            "Loss in iteration no. 95797 ==> 0.48539532704457117\n",
            "Loss in iteration no. 95798 ==> 0.48539431977692504\n",
            "Loss in iteration no. 95799 ==> 0.4853933125185018\n",
            "Loss in iteration no. 95800 ==> 0.4853923052693015\n",
            "Loss in iteration no. 95801 ==> 0.485391298029324\n",
            "Loss in iteration no. 95802 ==> 0.48539029079856927\n",
            "Loss in iteration no. 95803 ==> 0.48538928357703715\n",
            "Loss in iteration no. 95804 ==> 0.4853882763647272\n",
            "Loss in iteration no. 95805 ==> 0.4853872691616397\n",
            "Loss in iteration no. 95806 ==> 0.48538626196777446\n",
            "Loss in iteration no. 95807 ==> 0.4853852547831312\n",
            "Loss in iteration no. 95808 ==> 0.48538424760771004\n",
            "Loss in iteration no. 95809 ==> 0.4853832404415106\n",
            "Loss in iteration no. 95810 ==> 0.485382233284533\n",
            "Loss in iteration no. 95811 ==> 0.48538122613677687\n",
            "Loss in iteration no. 95812 ==> 0.4853802189982423\n",
            "Loss in iteration no. 95813 ==> 0.4853792118689291\n",
            "Loss in iteration no. 95814 ==> 0.4853782047488372\n",
            "Loss in iteration no. 95815 ==> 0.48537719763796633\n",
            "Loss in iteration no. 95816 ==> 0.48537619053631664\n",
            "Loss in iteration no. 95817 ==> 0.48537518344388764\n",
            "Loss in iteration no. 95818 ==> 0.4853741763606796\n",
            "Loss in iteration no. 95819 ==> 0.4853731692866921\n",
            "Loss in iteration no. 95820 ==> 0.4853721622219252\n",
            "Loss in iteration no. 95821 ==> 0.4853711551663787\n",
            "Loss in iteration no. 95822 ==> 0.4853701481200525\n",
            "Loss in iteration no. 95823 ==> 0.48536914108294654\n",
            "Loss in iteration no. 95824 ==> 0.4853681340550606\n",
            "Loss in iteration no. 95825 ==> 0.4853671270363945\n",
            "Loss in iteration no. 95826 ==> 0.48536612002694834\n",
            "Loss in iteration no. 95827 ==> 0.48536511302672186\n",
            "Loss in iteration no. 95828 ==> 0.485364106035715\n",
            "Loss in iteration no. 95829 ==> 0.48536309905392766\n",
            "Loss in iteration no. 95830 ==> 0.48536209208135955\n",
            "Loss in iteration no. 95831 ==> 0.48536108511801085\n",
            "Loss in iteration no. 95832 ==> 0.48536007816388105\n",
            "Loss in iteration no. 95833 ==> 0.4853590712189705\n",
            "Loss in iteration no. 95834 ==> 0.48535806428327866\n",
            "Loss in iteration no. 95835 ==> 0.48535705735680557\n",
            "Loss in iteration no. 95836 ==> 0.48535605043955116\n",
            "Loss in iteration no. 95837 ==> 0.4853550435315153\n",
            "Loss in iteration no. 95838 ==> 0.4853540366326977\n",
            "Loss in iteration no. 95839 ==> 0.4853530297430985\n",
            "Loss in iteration no. 95840 ==> 0.4853520228627175\n",
            "Loss in iteration no. 95841 ==> 0.48535101599155456\n",
            "Loss in iteration no. 95842 ==> 0.4853500091296095\n",
            "Loss in iteration no. 95843 ==> 0.4853490022768822\n",
            "Loss in iteration no. 95844 ==> 0.4853479954333728\n",
            "Loss in iteration no. 95845 ==> 0.48534698859908076\n",
            "Loss in iteration no. 95846 ==> 0.48534598177400623\n",
            "Loss in iteration no. 95847 ==> 0.4853449749581492\n",
            "Loss in iteration no. 95848 ==> 0.4853439681515092\n",
            "Loss in iteration no. 95849 ==> 0.4853429613540864\n",
            "Loss in iteration no. 95850 ==> 0.4853419545658805\n",
            "Loss in iteration no. 95851 ==> 0.48534094778689163\n",
            "Loss in iteration no. 95852 ==> 0.4853399410171193\n",
            "Loss in iteration no. 95853 ==> 0.4853389342565636\n",
            "Loss in iteration no. 95854 ==> 0.4853379275052246\n",
            "Loss in iteration no. 95855 ==> 0.48533692076310175\n",
            "Loss in iteration no. 95856 ==> 0.4853359140301953\n",
            "Loss in iteration no. 95857 ==> 0.485334907306505\n",
            "Loss in iteration no. 95858 ==> 0.48533390059203074\n",
            "Loss in iteration no. 95859 ==> 0.4853328938867724\n",
            "Loss in iteration no. 95860 ==> 0.48533188719072984\n",
            "Loss in iteration no. 95861 ==> 0.48533088050390294\n",
            "Loss in iteration no. 95862 ==> 0.4853298738262917\n",
            "Loss in iteration no. 95863 ==> 0.4853288671578958\n",
            "Loss in iteration no. 95864 ==> 0.4853278604987152\n",
            "Loss in iteration no. 95865 ==> 0.4853268538487499\n",
            "Loss in iteration no. 95866 ==> 0.48532584720799965\n",
            "Loss in iteration no. 95867 ==> 0.48532484057646436\n",
            "Loss in iteration no. 95868 ==> 0.48532383395414397\n",
            "Loss in iteration no. 95869 ==> 0.48532282734103815\n",
            "Loss in iteration no. 95870 ==> 0.48532182073714714\n",
            "Loss in iteration no. 95871 ==> 0.48532081414247047\n",
            "Loss in iteration no. 95872 ==> 0.4853198075570082\n",
            "Loss in iteration no. 95873 ==> 0.48531880098076036\n",
            "Loss in iteration no. 95874 ==> 0.4853177944137265\n",
            "Loss in iteration no. 95875 ==> 0.4853167878559066\n",
            "Loss in iteration no. 95876 ==> 0.48531578130730063\n",
            "Loss in iteration no. 95877 ==> 0.4853147747679085\n",
            "Loss in iteration no. 95878 ==> 0.4853137682377301\n",
            "Loss in iteration no. 95879 ==> 0.4853127617167652\n",
            "Loss in iteration no. 95880 ==> 0.48531175520501374\n",
            "Loss in iteration no. 95881 ==> 0.4853107487024755\n",
            "Loss in iteration no. 95882 ==> 0.48530974220915035\n",
            "Loss in iteration no. 95883 ==> 0.48530873572503846\n",
            "Loss in iteration no. 95884 ==> 0.48530772925013954\n",
            "Loss in iteration no. 95885 ==> 0.4853067227844534\n",
            "Loss in iteration no. 95886 ==> 0.48530571632798003\n",
            "Loss in iteration no. 95887 ==> 0.48530470988071905\n",
            "Loss in iteration no. 95888 ==> 0.4853037034426708\n",
            "Loss in iteration no. 95889 ==> 0.48530269701383477\n",
            "Loss in iteration no. 95890 ==> 0.485301690594211\n",
            "Loss in iteration no. 95891 ==> 0.4853006841837994\n",
            "Loss in iteration no. 95892 ==> 0.48529967778259986\n",
            "Loss in iteration no. 95893 ==> 0.4852986713906121\n",
            "Loss in iteration no. 95894 ==> 0.4852976650078361\n",
            "Loss in iteration no. 95895 ==> 0.48529665863427185\n",
            "Loss in iteration no. 95896 ==> 0.4852956522699191\n",
            "Loss in iteration no. 95897 ==> 0.4852946459147776\n",
            "Loss in iteration no. 95898 ==> 0.4852936395688476\n",
            "Loss in iteration no. 95899 ==> 0.4852926332321286\n",
            "Loss in iteration no. 95900 ==> 0.48529162690462085\n",
            "Loss in iteration no. 95901 ==> 0.4852906205863239\n",
            "Loss in iteration no. 95902 ==> 0.4852896142772378\n",
            "Loss in iteration no. 95903 ==> 0.4852886079773624\n",
            "Loss in iteration no. 95904 ==> 0.48528760168669766\n",
            "Loss in iteration no. 95905 ==> 0.48528659540524327\n",
            "Loss in iteration no. 95906 ==> 0.4852855891329992\n",
            "Loss in iteration no. 95907 ==> 0.4852845828699656\n",
            "Loss in iteration no. 95908 ==> 0.4852835766161419\n",
            "Loss in iteration no. 95909 ==> 0.48528257037152817\n",
            "Loss in iteration no. 95910 ==> 0.48528156413612444\n",
            "Loss in iteration no. 95911 ==> 0.48528055790993047\n",
            "Loss in iteration no. 95912 ==> 0.48527955169294607\n",
            "Loss in iteration no. 95913 ==> 0.4852785454851711\n",
            "Loss in iteration no. 95914 ==> 0.4852775392866056\n",
            "Loss in iteration no. 95915 ==> 0.48527653309724944\n",
            "Loss in iteration no. 95916 ==> 0.48527552691710235\n",
            "Loss in iteration no. 95917 ==> 0.4852745207461644\n",
            "Loss in iteration no. 95918 ==> 0.4852735145844353\n",
            "Loss in iteration no. 95919 ==> 0.48527250843191516\n",
            "Loss in iteration no. 95920 ==> 0.48527150228860344\n",
            "Loss in iteration no. 95921 ==> 0.48527049615450046\n",
            "Loss in iteration no. 95922 ==> 0.485269490029606\n",
            "Loss in iteration no. 95923 ==> 0.48526848391391975\n",
            "Loss in iteration no. 95924 ==> 0.48526747780744184\n",
            "Loss in iteration no. 95925 ==> 0.48526647171017184\n",
            "Loss in iteration no. 95926 ==> 0.4852654656221099\n",
            "Loss in iteration no. 95927 ==> 0.48526445954325587\n",
            "Loss in iteration no. 95928 ==> 0.48526345347360955\n",
            "Loss in iteration no. 95929 ==> 0.48526244741317087\n",
            "Loss in iteration no. 95930 ==> 0.4852614413619397\n",
            "Loss in iteration no. 95931 ==> 0.48526043531991575\n",
            "Loss in iteration no. 95932 ==> 0.48525942928709925\n",
            "Loss in iteration no. 95933 ==> 0.48525842326348984\n",
            "Loss in iteration no. 95934 ==> 0.4852574172490875\n",
            "Loss in iteration no. 95935 ==> 0.48525641124389207\n",
            "Loss in iteration no. 95936 ==> 0.4852554052479034\n",
            "Loss in iteration no. 95937 ==> 0.48525439926112135\n",
            "Loss in iteration no. 95938 ==> 0.48525339328354594\n",
            "Loss in iteration no. 95939 ==> 0.48525238731517695\n",
            "Loss in iteration no. 95940 ==> 0.4852513813560143\n",
            "Loss in iteration no. 95941 ==> 0.48525037540605775\n",
            "Loss in iteration no. 95942 ==> 0.48524936946530745\n",
            "Loss in iteration no. 95943 ==> 0.4852483635337631\n",
            "Loss in iteration no. 95944 ==> 0.48524735761142446\n",
            "Loss in iteration no. 95945 ==> 0.4852463516982916\n",
            "Loss in iteration no. 95946 ==> 0.48524534579436435\n",
            "Loss in iteration no. 95947 ==> 0.48524433989964266\n",
            "Loss in iteration no. 95948 ==> 0.4852433340141263\n",
            "Loss in iteration no. 95949 ==> 0.4852423281378152\n",
            "Loss in iteration no. 95950 ==> 0.48524132227070915\n",
            "Loss in iteration no. 95951 ==> 0.48524031641280824\n",
            "Loss in iteration no. 95952 ==> 0.48523931056411224\n",
            "Loss in iteration no. 95953 ==> 0.48523830472462093\n",
            "Loss in iteration no. 95954 ==> 0.4852372988943343\n",
            "Loss in iteration no. 95955 ==> 0.48523629307325233\n",
            "Loss in iteration no. 95956 ==> 0.4852352872613746\n",
            "Loss in iteration no. 95957 ==> 0.48523428145870134\n",
            "Loss in iteration no. 95958 ==> 0.4852332756652322\n",
            "Loss in iteration no. 95959 ==> 0.48523226988096707\n",
            "Loss in iteration no. 95960 ==> 0.48523126410590595\n",
            "Loss in iteration no. 95961 ==> 0.4852302583400487\n",
            "Loss in iteration no. 95962 ==> 0.48522925258339517\n",
            "Loss in iteration no. 95963 ==> 0.48522824683594523\n",
            "Loss in iteration no. 95964 ==> 0.48522724109769877\n",
            "Loss in iteration no. 95965 ==> 0.4852262353686556\n",
            "Loss in iteration no. 95966 ==> 0.48522522964881576\n",
            "Loss in iteration no. 95967 ==> 0.485224223938179\n",
            "Loss in iteration no. 95968 ==> 0.48522321823674525\n",
            "Loss in iteration no. 95969 ==> 0.4852222125445145\n",
            "Loss in iteration no. 95970 ==> 0.48522120686148634\n",
            "Loss in iteration no. 95971 ==> 0.48522020118766085\n",
            "Loss in iteration no. 95972 ==> 0.485219195523038\n",
            "Loss in iteration no. 95973 ==> 0.48521818986761744\n",
            "Loss in iteration no. 95974 ==> 0.48521718422139926\n",
            "Loss in iteration no. 95975 ==> 0.48521617858438326\n",
            "Loss in iteration no. 95976 ==> 0.4852151729565693\n",
            "Loss in iteration no. 95977 ==> 0.48521416733795736\n",
            "Loss in iteration no. 95978 ==> 0.48521316172854717\n",
            "Loss in iteration no. 95979 ==> 0.48521215612833873\n",
            "Loss in iteration no. 95980 ==> 0.4852111505373318\n",
            "Loss in iteration no. 95981 ==> 0.48521014495552645\n",
            "Loss in iteration no. 95982 ==> 0.4852091393829223\n",
            "Loss in iteration no. 95983 ==> 0.4852081338195196\n",
            "Loss in iteration no. 95984 ==> 0.48520712826531776\n",
            "Loss in iteration no. 95985 ==> 0.48520612272031705\n",
            "Loss in iteration no. 95986 ==> 0.48520511718451725\n",
            "Loss in iteration no. 95987 ==> 0.48520411165791816\n",
            "Loss in iteration no. 95988 ==> 0.48520310614051976\n",
            "Loss in iteration no. 95989 ==> 0.4852021006323217\n",
            "Loss in iteration no. 95990 ==> 0.48520109513332427\n",
            "Loss in iteration no. 95991 ==> 0.48520008964352707\n",
            "Loss in iteration no. 95992 ==> 0.4851990841629299\n",
            "Loss in iteration no. 95993 ==> 0.4851980786915329\n",
            "Loss in iteration no. 95994 ==> 0.4851970732293359\n",
            "Loss in iteration no. 95995 ==> 0.4851960677763386\n",
            "Loss in iteration no. 95996 ==> 0.48519506233254106\n",
            "Loss in iteration no. 95997 ==> 0.48519405689794304\n",
            "Loss in iteration no. 95998 ==> 0.4851930514725445\n",
            "Loss in iteration no. 95999 ==> 0.48519204605634525\n",
            "Loss in iteration no. 96000 ==> 0.4851910406493453\n",
            "Loss in iteration no. 96001 ==> 0.48519003525154447\n",
            "Loss in iteration no. 96002 ==> 0.4851890298629426\n",
            "Loss in iteration no. 96003 ==> 0.4851880244835394\n",
            "Loss in iteration no. 96004 ==> 0.4851870191133353\n",
            "Loss in iteration no. 96005 ==> 0.48518601375232967\n",
            "Loss in iteration no. 96006 ==> 0.4851850084005225\n",
            "Loss in iteration no. 96007 ==> 0.48518400305791376\n",
            "Loss in iteration no. 96008 ==> 0.48518299772450335\n",
            "Loss in iteration no. 96009 ==> 0.485181992400291\n",
            "Loss in iteration no. 96010 ==> 0.48518098708527674\n",
            "Loss in iteration no. 96011 ==> 0.4851799817794604\n",
            "Loss in iteration no. 96012 ==> 0.48517897648284186\n",
            "Loss in iteration no. 96013 ==> 0.48517797119542094\n",
            "Loss in iteration no. 96014 ==> 0.4851769659171978\n",
            "Loss in iteration no. 96015 ==> 0.4851759606481718\n",
            "Loss in iteration no. 96016 ==> 0.4851749553883433\n",
            "Loss in iteration no. 96017 ==> 0.48517395013771203\n",
            "Loss in iteration no. 96018 ==> 0.4851729448962779\n",
            "Loss in iteration no. 96019 ==> 0.4851719396640406\n",
            "Loss in iteration no. 96020 ==> 0.48517093444100023\n",
            "Loss in iteration no. 96021 ==> 0.4851699292271566\n",
            "Loss in iteration no. 96022 ==> 0.4851689240225096\n",
            "Loss in iteration no. 96023 ==> 0.48516791882705906\n",
            "Loss in iteration no. 96024 ==> 0.485166913640805\n",
            "Loss in iteration no. 96025 ==> 0.4851659084637471\n",
            "Loss in iteration no. 96026 ==> 0.48516490329588535\n",
            "Loss in iteration no. 96027 ==> 0.48516389813721966\n",
            "Loss in iteration no. 96028 ==> 0.4851628929877499\n",
            "Loss in iteration no. 96029 ==> 0.485161887847476\n",
            "Loss in iteration no. 96030 ==> 0.48516088271639773\n",
            "Loss in iteration no. 96031 ==> 0.4851598775945149\n",
            "Loss in iteration no. 96032 ==> 0.4851588724818277\n",
            "Loss in iteration no. 96033 ==> 0.48515786737833566\n",
            "Loss in iteration no. 96034 ==> 0.48515686228403887\n",
            "Loss in iteration no. 96035 ==> 0.4851558571989371\n",
            "Loss in iteration no. 96036 ==> 0.4851548521230305\n",
            "Loss in iteration no. 96037 ==> 0.48515384705631853\n",
            "Loss in iteration no. 96038 ==> 0.4851528419988014\n",
            "Loss in iteration no. 96039 ==> 0.4851518369504789\n",
            "Loss in iteration no. 96040 ==> 0.4851508319113509\n",
            "Loss in iteration no. 96041 ==> 0.48514982688141717\n",
            "Loss in iteration no. 96042 ==> 0.4851488218606778\n",
            "Loss in iteration no. 96043 ==> 0.4851478168491325\n",
            "Loss in iteration no. 96044 ==> 0.48514681184678116\n",
            "Loss in iteration no. 96045 ==> 0.48514580685362385\n",
            "Loss in iteration no. 96046 ==> 0.4851448018696603\n",
            "Loss in iteration no. 96047 ==> 0.48514379689489046\n",
            "Loss in iteration no. 96048 ==> 0.4851427919293141\n",
            "Loss in iteration no. 96049 ==> 0.4851417869729312\n",
            "Loss in iteration no. 96050 ==> 0.4851407820257416\n",
            "Loss in iteration no. 96051 ==> 0.4851397770877451\n",
            "Loss in iteration no. 96052 ==> 0.4851387721589418\n",
            "Loss in iteration no. 96053 ==> 0.4851377672393313\n",
            "Loss in iteration no. 96054 ==> 0.48513676232891384\n",
            "Loss in iteration no. 96055 ==> 0.485135757427689\n",
            "Loss in iteration no. 96056 ==> 0.4851347525356567\n",
            "Loss in iteration no. 96057 ==> 0.48513374765281697\n",
            "Loss in iteration no. 96058 ==> 0.48513274277916973\n",
            "Loss in iteration no. 96059 ==> 0.48513173791471453\n",
            "Loss in iteration no. 96060 ==> 0.48513073305945165\n",
            "Loss in iteration no. 96061 ==> 0.48512972821338063\n",
            "Loss in iteration no. 96062 ==> 0.48512872337650154\n",
            "Loss in iteration no. 96063 ==> 0.48512771854881426\n",
            "Loss in iteration no. 96064 ==> 0.4851267137303185\n",
            "Loss in iteration no. 96065 ==> 0.48512570892101436\n",
            "Loss in iteration no. 96066 ==> 0.48512470412090164\n",
            "Loss in iteration no. 96067 ==> 0.48512369932998034\n",
            "Loss in iteration no. 96068 ==> 0.4851226945482502\n",
            "Loss in iteration no. 96069 ==> 0.48512168977571096\n",
            "Loss in iteration no. 96070 ==> 0.48512068501236283\n",
            "Loss in iteration no. 96071 ==> 0.48511968025820545\n",
            "Loss in iteration no. 96072 ==> 0.48511867551323884\n",
            "Loss in iteration no. 96073 ==> 0.48511767077746276\n",
            "Loss in iteration no. 96074 ==> 0.4851166660508773\n",
            "Loss in iteration no. 96075 ==> 0.48511566133348194\n",
            "Loss in iteration no. 96076 ==> 0.48511465662527703\n",
            "Loss in iteration no. 96077 ==> 0.4851136519262623\n",
            "Loss in iteration no. 96078 ==> 0.4851126472364373\n",
            "Loss in iteration no. 96079 ==> 0.48511164255580236\n",
            "Loss in iteration no. 96080 ==> 0.4851106378843573\n",
            "Loss in iteration no. 96081 ==> 0.4851096332221017\n",
            "Loss in iteration no. 96082 ==> 0.4851086285690357\n",
            "Loss in iteration no. 96083 ==> 0.4851076239251591\n",
            "Loss in iteration no. 96084 ==> 0.48510661929047183\n",
            "Loss in iteration no. 96085 ==> 0.4851056146649737\n",
            "Loss in iteration no. 96086 ==> 0.4851046100486645\n",
            "Loss in iteration no. 96087 ==> 0.4851036054415445\n",
            "Loss in iteration no. 96088 ==> 0.48510260084361323\n",
            "Loss in iteration no. 96089 ==> 0.4851015962548707\n",
            "Loss in iteration no. 96090 ==> 0.4851005916753167\n",
            "Loss in iteration no. 96091 ==> 0.48509958710495105\n",
            "Loss in iteration no. 96092 ==> 0.48509858254377397\n",
            "Loss in iteration no. 96093 ==> 0.4850975779917851\n",
            "Loss in iteration no. 96094 ==> 0.48509657344898427\n",
            "Loss in iteration no. 96095 ==> 0.48509556891537137\n",
            "Loss in iteration no. 96096 ==> 0.4850945643909464\n",
            "Loss in iteration no. 96097 ==> 0.48509355987570923\n",
            "Loss in iteration no. 96098 ==> 0.48509255536965973\n",
            "Loss in iteration no. 96099 ==> 0.4850915508727977\n",
            "Loss in iteration no. 96100 ==> 0.48509054638512306\n",
            "Loss in iteration no. 96101 ==> 0.4850895419066357\n",
            "Loss in iteration no. 96102 ==> 0.4850885374373355\n",
            "Loss in iteration no. 96103 ==> 0.4850875329772224\n",
            "Loss in iteration no. 96104 ==> 0.48508652852629625\n",
            "Loss in iteration no. 96105 ==> 0.4850855240845569\n",
            "Loss in iteration no. 96106 ==> 0.48508451965200433\n",
            "Loss in iteration no. 96107 ==> 0.48508351522863824\n",
            "Loss in iteration no. 96108 ==> 0.4850825108144585\n",
            "Loss in iteration no. 96109 ==> 0.4850815064094654\n",
            "Loss in iteration no. 96110 ==> 0.4850805020136582\n",
            "Loss in iteration no. 96111 ==> 0.4850794976270373\n",
            "Loss in iteration no. 96112 ==> 0.4850784932496025\n",
            "Loss in iteration no. 96113 ==> 0.4850774888813533\n",
            "Loss in iteration no. 96114 ==> 0.48507648452228996\n",
            "Loss in iteration no. 96115 ==> 0.4850754801724123\n",
            "Loss in iteration no. 96116 ==> 0.4850744758317202\n",
            "Loss in iteration no. 96117 ==> 0.4850734715002134\n",
            "Loss in iteration no. 96118 ==> 0.48507246717789193\n",
            "Loss in iteration no. 96119 ==> 0.4850714628647556\n",
            "Loss in iteration no. 96120 ==> 0.4850704585608045\n",
            "Loss in iteration no. 96121 ==> 0.4850694542660381\n",
            "Loss in iteration no. 96122 ==> 0.4850684499804565\n",
            "Loss in iteration no. 96123 ==> 0.4850674457040597\n",
            "Loss in iteration no. 96124 ==> 0.4850664414368475\n",
            "Loss in iteration no. 96125 ==> 0.4850654371788197\n",
            "Loss in iteration no. 96126 ==> 0.48506443292997614\n",
            "Loss in iteration no. 96127 ==> 0.48506342869031693\n",
            "Loss in iteration no. 96128 ==> 0.48506242445984177\n",
            "Loss in iteration no. 96129 ==> 0.4850614202385506\n",
            "Loss in iteration no. 96130 ==> 0.4850604160264434\n",
            "Loss in iteration no. 96131 ==> 0.4850594118235198\n",
            "Loss in iteration no. 96132 ==> 0.4850584076297798\n",
            "Loss in iteration no. 96133 ==> 0.4850574034452236\n",
            "Loss in iteration no. 96134 ==> 0.48505639926985045\n",
            "Loss in iteration no. 96135 ==> 0.48505539510366075\n",
            "Loss in iteration no. 96136 ==> 0.4850543909466542\n",
            "Loss in iteration no. 96137 ==> 0.4850533867988306\n",
            "Loss in iteration no. 96138 ==> 0.4850523826601901\n",
            "Loss in iteration no. 96139 ==> 0.48505137853073216\n",
            "Loss in iteration no. 96140 ==> 0.4850503744104572\n",
            "Loss in iteration no. 96141 ==> 0.4850493702993646\n",
            "Loss in iteration no. 96142 ==> 0.48504836619745445\n",
            "Loss in iteration no. 96143 ==> 0.4850473621047267\n",
            "Loss in iteration no. 96144 ==> 0.48504635802118123\n",
            "Loss in iteration no. 96145 ==> 0.4850453539468177\n",
            "Loss in iteration no. 96146 ==> 0.48504434988163625\n",
            "Loss in iteration no. 96147 ==> 0.4850433458256367\n",
            "Loss in iteration no. 96148 ==> 0.48504234177881883\n",
            "Loss in iteration no. 96149 ==> 0.4850413377411826\n",
            "Loss in iteration no. 96150 ==> 0.48504033371272776\n",
            "Loss in iteration no. 96151 ==> 0.4850393296934544\n",
            "Loss in iteration no. 96152 ==> 0.4850383256833624\n",
            "Loss in iteration no. 96153 ==> 0.48503732168245145\n",
            "Loss in iteration no. 96154 ==> 0.48503631769072153\n",
            "Loss in iteration no. 96155 ==> 0.4850353137081726\n",
            "Loss in iteration no. 96156 ==> 0.48503430973480444\n",
            "Loss in iteration no. 96157 ==> 0.48503330577061693\n",
            "Loss in iteration no. 96158 ==> 0.48503230181561\n",
            "Loss in iteration no. 96159 ==> 0.4850312978697836\n",
            "Loss in iteration no. 96160 ==> 0.48503029393313746\n",
            "Loss in iteration no. 96161 ==> 0.48502929000567147\n",
            "Loss in iteration no. 96162 ==> 0.48502828608738563\n",
            "Loss in iteration no. 96163 ==> 0.4850272821782799\n",
            "Loss in iteration no. 96164 ==> 0.4850262782783537\n",
            "Loss in iteration no. 96165 ==> 0.48502527438760745\n",
            "Loss in iteration no. 96166 ==> 0.4850242705060408\n",
            "Loss in iteration no. 96167 ==> 0.48502326663365364\n",
            "Loss in iteration no. 96168 ==> 0.48502226277044586\n",
            "Loss in iteration no. 96169 ==> 0.48502125891641734\n",
            "Loss in iteration no. 96170 ==> 0.485020255071568\n",
            "Loss in iteration no. 96171 ==> 0.48501925123589773\n",
            "Loss in iteration no. 96172 ==> 0.48501824740940624\n",
            "Loss in iteration no. 96173 ==> 0.48501724359209364\n",
            "Loss in iteration no. 96174 ==> 0.4850162397839597\n",
            "Loss in iteration no. 96175 ==> 0.4850152359850044\n",
            "Loss in iteration no. 96176 ==> 0.48501423219522743\n",
            "Loss in iteration no. 96177 ==> 0.48501322841462874\n",
            "Loss in iteration no. 96178 ==> 0.4850122246432083\n",
            "Loss in iteration no. 96179 ==> 0.485011220880966\n",
            "Loss in iteration no. 96180 ==> 0.48501021712790165\n",
            "Loss in iteration no. 96181 ==> 0.48500921338401515\n",
            "Loss in iteration no. 96182 ==> 0.4850082096493064\n",
            "Loss in iteration no. 96183 ==> 0.4850072059237753\n",
            "Loss in iteration no. 96184 ==> 0.48500620220742163\n",
            "Loss in iteration no. 96185 ==> 0.4850051985002453\n",
            "Loss in iteration no. 96186 ==> 0.48500419480224627\n",
            "Loss in iteration no. 96187 ==> 0.4850031911134245\n",
            "Loss in iteration no. 96188 ==> 0.4850021874337796\n",
            "Loss in iteration no. 96189 ==> 0.48500118376331175\n",
            "Loss in iteration no. 96190 ==> 0.48500018010202045\n",
            "Loss in iteration no. 96191 ==> 0.4849991764499061\n",
            "Loss in iteration no. 96192 ==> 0.4849981728069681\n",
            "Loss in iteration no. 96193 ==> 0.4849971691732067\n",
            "Loss in iteration no. 96194 ==> 0.48499616554862157\n",
            "Loss in iteration no. 96195 ==> 0.48499516193321257\n",
            "Loss in iteration no. 96196 ==> 0.48499415832697973\n",
            "Loss in iteration no. 96197 ==> 0.4849931547299228\n",
            "Loss in iteration no. 96198 ==> 0.48499215114204175\n",
            "Loss in iteration no. 96199 ==> 0.4849911475633365\n",
            "Loss in iteration no. 96200 ==> 0.4849901439938067\n",
            "Loss in iteration no. 96201 ==> 0.4849891404334525\n",
            "Loss in iteration no. 96202 ==> 0.48498813688227366\n",
            "Loss in iteration no. 96203 ==> 0.48498713334027\n",
            "Loss in iteration no. 96204 ==> 0.48498612980744155\n",
            "Loss in iteration no. 96205 ==> 0.48498512628378815\n",
            "Loss in iteration no. 96206 ==> 0.48498412276930963\n",
            "Loss in iteration no. 96207 ==> 0.4849831192640059\n",
            "Loss in iteration no. 96208 ==> 0.4849821157678769\n",
            "Loss in iteration no. 96209 ==> 0.48498111228092244\n",
            "Loss in iteration no. 96210 ==> 0.48498010880314235\n",
            "Loss in iteration no. 96211 ==> 0.48497910533453653\n",
            "Loss in iteration no. 96212 ==> 0.4849781018751051\n",
            "Loss in iteration no. 96213 ==> 0.4849770984248475\n",
            "Loss in iteration no. 96214 ==> 0.4849760949837641\n",
            "Loss in iteration no. 96215 ==> 0.4849750915518544\n",
            "Loss in iteration no. 96216 ==> 0.4849740881291185\n",
            "Loss in iteration no. 96217 ==> 0.48497308471555617\n",
            "Loss in iteration no. 96218 ==> 0.48497208131116726\n",
            "Loss in iteration no. 96219 ==> 0.48497107791595184\n",
            "Loss in iteration no. 96220 ==> 0.48497007452990964\n",
            "Loss in iteration no. 96221 ==> 0.4849690711530405\n",
            "Loss in iteration no. 96222 ==> 0.4849680677853445\n",
            "Loss in iteration no. 96223 ==> 0.48496706442682136\n",
            "Loss in iteration no. 96224 ==> 0.48496606107747103\n",
            "Loss in iteration no. 96225 ==> 0.4849650577372934\n",
            "Loss in iteration no. 96226 ==> 0.4849640544062882\n",
            "Loss in iteration no. 96227 ==> 0.4849630510844554\n",
            "Loss in iteration no. 96228 ==> 0.48496204777179514\n",
            "Loss in iteration no. 96229 ==> 0.48496104446830696\n",
            "Loss in iteration no. 96230 ==> 0.4849600411739909\n",
            "Loss in iteration no. 96231 ==> 0.48495903788884653\n",
            "Loss in iteration no. 96232 ==> 0.4849580346128743\n",
            "Loss in iteration no. 96233 ==> 0.4849570313460737\n",
            "Loss in iteration no. 96234 ==> 0.4849560280884446\n",
            "Loss in iteration no. 96235 ==> 0.48495502483998715\n",
            "Loss in iteration no. 96236 ==> 0.4849540216007011\n",
            "Loss in iteration no. 96237 ==> 0.48495301837058613\n",
            "Loss in iteration no. 96238 ==> 0.4849520151496424\n",
            "Loss in iteration no. 96239 ==> 0.48495101193786977\n",
            "Loss in iteration no. 96240 ==> 0.48495000873526783\n",
            "Loss in iteration no. 96241 ==> 0.48494900554183684\n",
            "Loss in iteration no. 96242 ==> 0.4849480023575765\n",
            "Loss in iteration no. 96243 ==> 0.4849469991824867\n",
            "Loss in iteration no. 96244 ==> 0.4849459960165673\n",
            "Loss in iteration no. 96245 ==> 0.4849449928598181\n",
            "Loss in iteration no. 96246 ==> 0.4849439897122393\n",
            "Loss in iteration no. 96247 ==> 0.4849429865738305\n",
            "Loss in iteration no. 96248 ==> 0.48494198344459166\n",
            "Loss in iteration no. 96249 ==> 0.4849409803245226\n",
            "Loss in iteration no. 96250 ==> 0.48493997721362325\n",
            "Loss in iteration no. 96251 ==> 0.4849389741118935\n",
            "Loss in iteration no. 96252 ==> 0.4849379710193334\n",
            "Loss in iteration no. 96253 ==> 0.4849369679359426\n",
            "Loss in iteration no. 96254 ==> 0.484935964861721\n",
            "Loss in iteration no. 96255 ==> 0.4849349617966686\n",
            "Loss in iteration no. 96256 ==> 0.4849339587407851\n",
            "Loss in iteration no. 96257 ==> 0.4849329556940707\n",
            "Loss in iteration no. 96258 ==> 0.48493195265652483\n",
            "Loss in iteration no. 96259 ==> 0.4849309496281478\n",
            "Loss in iteration no. 96260 ==> 0.48492994660893923\n",
            "Loss in iteration no. 96261 ==> 0.48492894359889915\n",
            "Loss in iteration no. 96262 ==> 0.4849279405980273\n",
            "Loss in iteration no. 96263 ==> 0.4849269376063237\n",
            "Loss in iteration no. 96264 ==> 0.48492593462378825\n",
            "Loss in iteration no. 96265 ==> 0.48492493165042055\n",
            "Loss in iteration no. 96266 ==> 0.48492392868622086\n",
            "Loss in iteration no. 96267 ==> 0.48492292573118884\n",
            "Loss in iteration no. 96268 ==> 0.4849219227853245\n",
            "Loss in iteration no. 96269 ==> 0.4849209198486275\n",
            "Loss in iteration no. 96270 ==> 0.4849199169210979\n",
            "Loss in iteration no. 96271 ==> 0.4849189140027357\n",
            "Loss in iteration no. 96272 ==> 0.4849179110935405\n",
            "Loss in iteration no. 96273 ==> 0.4849169081935123\n",
            "Loss in iteration no. 96274 ==> 0.484915905302651\n",
            "Loss in iteration no. 96275 ==> 0.48491490242095653\n",
            "Loss in iteration no. 96276 ==> 0.4849138995484288\n",
            "Loss in iteration no. 96277 ==> 0.4849128966850674\n",
            "Loss in iteration no. 96278 ==> 0.48491189383087263\n",
            "Loss in iteration no. 96279 ==> 0.48491089098584406\n",
            "Loss in iteration no. 96280 ==> 0.48490988814998176\n",
            "Loss in iteration no. 96281 ==> 0.4849088853232854\n",
            "Loss in iteration no. 96282 ==> 0.4849078825057551\n",
            "Loss in iteration no. 96283 ==> 0.4849068796973906\n",
            "Loss in iteration no. 96284 ==> 0.4849058768981919\n",
            "Loss in iteration no. 96285 ==> 0.48490487410815875\n",
            "Loss in iteration no. 96286 ==> 0.48490387132729107\n",
            "Loss in iteration no. 96287 ==> 0.48490286855558873\n",
            "Loss in iteration no. 96288 ==> 0.4849018657930518\n",
            "Loss in iteration no. 96289 ==> 0.4849008630396799\n",
            "Loss in iteration no. 96290 ==> 0.48489986029547294\n",
            "Loss in iteration no. 96291 ==> 0.48489885756043094\n",
            "Loss in iteration no. 96292 ==> 0.48489785483455367\n",
            "Loss in iteration no. 96293 ==> 0.48489685211784106\n",
            "Loss in iteration no. 96294 ==> 0.48489584941029307\n",
            "Loss in iteration no. 96295 ==> 0.48489484671190947\n",
            "Loss in iteration no. 96296 ==> 0.48489384402269026\n",
            "Loss in iteration no. 96297 ==> 0.4848928413426351\n",
            "Loss in iteration no. 96298 ==> 0.48489183867174407\n",
            "Loss in iteration no. 96299 ==> 0.48489083601001703\n",
            "Loss in iteration no. 96300 ==> 0.4848898333574539\n",
            "Loss in iteration no. 96301 ==> 0.4848888307140543\n",
            "Loss in iteration no. 96302 ==> 0.4848878280798184\n",
            "Loss in iteration no. 96303 ==> 0.48488682545474593\n",
            "Loss in iteration no. 96304 ==> 0.48488582283883697\n",
            "Loss in iteration no. 96305 ==> 0.4848848202320911\n",
            "Loss in iteration no. 96306 ==> 0.4848838176345085\n",
            "Loss in iteration no. 96307 ==> 0.4848828150460889\n",
            "Loss in iteration no. 96308 ==> 0.484881812466832\n",
            "Loss in iteration no. 96309 ==> 0.4848808098967381\n",
            "Loss in iteration no. 96310 ==> 0.48487980733580677\n",
            "Loss in iteration no. 96311 ==> 0.484878804784038\n",
            "Loss in iteration no. 96312 ==> 0.48487780224143173\n",
            "Loss in iteration no. 96313 ==> 0.4848767997079877\n",
            "Loss in iteration no. 96314 ==> 0.4848757971837058\n",
            "Loss in iteration no. 96315 ==> 0.484874794668586\n",
            "Loss in iteration no. 96316 ==> 0.48487379216262827\n",
            "Loss in iteration no. 96317 ==> 0.4848727896658323\n",
            "Loss in iteration no. 96318 ==> 0.484871787178198\n",
            "Loss in iteration no. 96319 ==> 0.4848707846997254\n",
            "Loss in iteration no. 96320 ==> 0.4848697822304141\n",
            "Loss in iteration no. 96321 ==> 0.4848687797702644\n",
            "Loss in iteration no. 96322 ==> 0.48486777731927583\n",
            "Loss in iteration no. 96323 ==> 0.4848667748774485\n",
            "Loss in iteration no. 96324 ==> 0.484865772444782\n",
            "Loss in iteration no. 96325 ==> 0.48486477002127654\n",
            "Loss in iteration no. 96326 ==> 0.48486376760693184\n",
            "Loss in iteration no. 96327 ==> 0.4848627652017478\n",
            "Loss in iteration no. 96328 ==> 0.4848617628057243\n",
            "Loss in iteration no. 96329 ==> 0.4848607604188612\n",
            "Loss in iteration no. 96330 ==> 0.4848597580411584\n",
            "Loss in iteration no. 96331 ==> 0.4848587556726159\n",
            "Loss in iteration no. 96332 ==> 0.4848577533132334\n",
            "Loss in iteration no. 96333 ==> 0.48485675096301084\n",
            "Loss in iteration no. 96334 ==> 0.4848557486219482\n",
            "Loss in iteration no. 96335 ==> 0.48485474629004516\n",
            "Loss in iteration no. 96336 ==> 0.48485374396730174\n",
            "Loss in iteration no. 96337 ==> 0.48485274165371806\n",
            "Loss in iteration no. 96338 ==> 0.48485173934929343\n",
            "Loss in iteration no. 96339 ==> 0.48485073705402815\n",
            "Loss in iteration no. 96340 ==> 0.484849734767922\n",
            "Loss in iteration no. 96341 ==> 0.4848487324909749\n",
            "Loss in iteration no. 96342 ==> 0.48484773022318656\n",
            "Loss in iteration no. 96343 ==> 0.4848467279645572\n",
            "Loss in iteration no. 96344 ==> 0.4848457257150865\n",
            "Loss in iteration no. 96345 ==> 0.48484472347477425\n",
            "Loss in iteration no. 96346 ==> 0.4848437212436204\n",
            "Loss in iteration no. 96347 ==> 0.48484271902162496\n",
            "Loss in iteration no. 96348 ==> 0.4848417168087877\n",
            "Loss in iteration no. 96349 ==> 0.4848407146051084\n",
            "Loss in iteration no. 96350 ==> 0.48483971241058715\n",
            "Loss in iteration no. 96351 ==> 0.4848387102252238\n",
            "Loss in iteration no. 96352 ==> 0.48483770804901816\n",
            "Loss in iteration no. 96353 ==> 0.4848367058819699\n",
            "Loss in iteration no. 96354 ==> 0.4848357037240794\n",
            "Loss in iteration no. 96355 ==> 0.4848347015753462\n",
            "Loss in iteration no. 96356 ==> 0.4848336994357702\n",
            "Loss in iteration no. 96357 ==> 0.4848326973053514\n",
            "Loss in iteration no. 96358 ==> 0.4848316951840896\n",
            "Loss in iteration no. 96359 ==> 0.4848306930719847\n",
            "Loss in iteration no. 96360 ==> 0.48482969096903655\n",
            "Loss in iteration no. 96361 ==> 0.48482868887524505\n",
            "Loss in iteration no. 96362 ==> 0.48482768679061017\n",
            "Loss in iteration no. 96363 ==> 0.48482668471513163\n",
            "Loss in iteration no. 96364 ==> 0.48482568264880954\n",
            "Loss in iteration no. 96365 ==> 0.4848246805916436\n",
            "Loss in iteration no. 96366 ==> 0.48482367854363373\n",
            "Loss in iteration no. 96367 ==> 0.48482267650477967\n",
            "Loss in iteration no. 96368 ==> 0.4848216744750816\n",
            "Loss in iteration no. 96369 ==> 0.4848206724545393\n",
            "Loss in iteration no. 96370 ==> 0.48481967044315244\n",
            "Loss in iteration no. 96371 ==> 0.4848186684409212\n",
            "Loss in iteration no. 96372 ==> 0.48481766644784535\n",
            "Loss in iteration no. 96373 ==> 0.48481666446392474\n",
            "Loss in iteration no. 96374 ==> 0.48481566248915925\n",
            "Loss in iteration no. 96375 ==> 0.4848146605235487\n",
            "Loss in iteration no. 96376 ==> 0.4848136585670932\n",
            "Loss in iteration no. 96377 ==> 0.4848126566197924\n",
            "Loss in iteration no. 96378 ==> 0.48481165468164633\n",
            "Loss in iteration no. 96379 ==> 0.4848106527526546\n",
            "Loss in iteration no. 96380 ==> 0.4848096508328176\n",
            "Loss in iteration no. 96381 ==> 0.4848086489221347\n",
            "Loss in iteration no. 96382 ==> 0.48480764702060614\n",
            "Loss in iteration no. 96383 ==> 0.48480664512823163\n",
            "Loss in iteration no. 96384 ==> 0.4848056432450111\n",
            "Loss in iteration no. 96385 ==> 0.48480464137094426\n",
            "Loss in iteration no. 96386 ==> 0.4848036395060313\n",
            "Loss in iteration no. 96387 ==> 0.484802637650272\n",
            "Loss in iteration no. 96388 ==> 0.48480163580366603\n",
            "Loss in iteration no. 96389 ==> 0.48480063396621353\n",
            "Loss in iteration no. 96390 ==> 0.4847996321379143\n",
            "Loss in iteration no. 96391 ==> 0.4847986303187682\n",
            "Loss in iteration no. 96392 ==> 0.4847976285087751\n",
            "Loss in iteration no. 96393 ==> 0.4847966267079349\n",
            "Loss in iteration no. 96394 ==> 0.48479562491624745\n",
            "Loss in iteration no. 96395 ==> 0.4847946231337127\n",
            "Loss in iteration no. 96396 ==> 0.48479362136033055\n",
            "Loss in iteration no. 96397 ==> 0.48479261959610087\n",
            "Loss in iteration no. 96398 ==> 0.4847916178410234\n",
            "Loss in iteration no. 96399 ==> 0.4847906160950982\n",
            "Loss in iteration no. 96400 ==> 0.4847896143583251\n",
            "Loss in iteration no. 96401 ==> 0.48478861263070394\n",
            "Loss in iteration no. 96402 ==> 0.4847876109122347\n",
            "Loss in iteration no. 96403 ==> 0.48478660920291716\n",
            "Loss in iteration no. 96404 ==> 0.48478560750275124\n",
            "Loss in iteration no. 96405 ==> 0.48478460581173666\n",
            "Loss in iteration no. 96406 ==> 0.4847836041298736\n",
            "Loss in iteration no. 96407 ==> 0.48478260245716176\n",
            "Loss in iteration no. 96408 ==> 0.4847816007936011\n",
            "Loss in iteration no. 96409 ==> 0.48478059913919147\n",
            "Loss in iteration no. 96410 ==> 0.4847795974939326\n",
            "Loss in iteration no. 96411 ==> 0.4847785958578248\n",
            "Loss in iteration no. 96412 ==> 0.48477759423086747\n",
            "Loss in iteration no. 96413 ==> 0.48477659261306083\n",
            "Loss in iteration no. 96414 ==> 0.4847755910044046\n",
            "Loss in iteration no. 96415 ==> 0.48477458940489865\n",
            "Loss in iteration no. 96416 ==> 0.48477358781454294\n",
            "Loss in iteration no. 96417 ==> 0.48477258623333724\n",
            "Loss in iteration no. 96418 ==> 0.48477158466128156\n",
            "Loss in iteration no. 96419 ==> 0.48477058309837573\n",
            "Loss in iteration no. 96420 ==> 0.48476958154461963\n",
            "Loss in iteration no. 96421 ==> 0.48476858000001305\n",
            "Loss in iteration no. 96422 ==> 0.4847675784645562\n",
            "Loss in iteration no. 96423 ==> 0.48476657693824865\n",
            "Loss in iteration no. 96424 ==> 0.4847655754210903\n",
            "Loss in iteration no. 96425 ==> 0.48476457391308114\n",
            "Loss in iteration no. 96426 ==> 0.4847635724142209\n",
            "Loss in iteration no. 96427 ==> 0.48476257092450975\n",
            "Loss in iteration no. 96428 ==> 0.4847615694439474\n",
            "Loss in iteration no. 96429 ==> 0.48476056797253353\n",
            "Loss in iteration no. 96430 ==> 0.48475956651026836\n",
            "Loss in iteration no. 96431 ==> 0.48475856505715165\n",
            "Loss in iteration no. 96432 ==> 0.48475756361318323\n",
            "Loss in iteration no. 96433 ==> 0.484756562178363\n",
            "Loss in iteration no. 96434 ==> 0.48475556075269094\n",
            "Loss in iteration no. 96435 ==> 0.48475455933616673\n",
            "Loss in iteration no. 96436 ==> 0.4847535579287905\n",
            "Loss in iteration no. 96437 ==> 0.484752556530562\n",
            "Loss in iteration no. 96438 ==> 0.48475155514148105\n",
            "Loss in iteration no. 96439 ==> 0.4847505537615477\n",
            "Loss in iteration no. 96440 ==> 0.4847495523907618\n",
            "Loss in iteration no. 96441 ==> 0.4847485510291229\n",
            "Loss in iteration no. 96442 ==> 0.4847475496766314\n",
            "Loss in iteration no. 96443 ==> 0.48474654833328673\n",
            "Loss in iteration no. 96444 ==> 0.4847455469990892\n",
            "Loss in iteration no. 96445 ==> 0.4847445456740384\n",
            "Loss in iteration no. 96446 ==> 0.48474354435813416\n",
            "Loss in iteration no. 96447 ==> 0.4847425430513766\n",
            "Loss in iteration no. 96448 ==> 0.4847415417537655\n",
            "Loss in iteration no. 96449 ==> 0.48474054046530074\n",
            "Loss in iteration no. 96450 ==> 0.48473953918598206\n",
            "Loss in iteration no. 96451 ==> 0.4847385379158096\n",
            "Loss in iteration no. 96452 ==> 0.48473753665478314\n",
            "Loss in iteration no. 96453 ==> 0.4847365354029025\n",
            "Loss in iteration no. 96454 ==> 0.4847355341601676\n",
            "Loss in iteration no. 96455 ==> 0.48473453292657837\n",
            "Loss in iteration no. 96456 ==> 0.48473353170213457\n",
            "Loss in iteration no. 96457 ==> 0.4847325304868363\n",
            "Loss in iteration no. 96458 ==> 0.48473152928068314\n",
            "Loss in iteration no. 96459 ==> 0.4847305280836752\n",
            "Loss in iteration no. 96460 ==> 0.48472952689581233\n",
            "Loss in iteration no. 96461 ==> 0.48472852571709446\n",
            "Loss in iteration no. 96462 ==> 0.48472752454752127\n",
            "Loss in iteration no. 96463 ==> 0.4847265233870928\n",
            "Loss in iteration no. 96464 ==> 0.4847255222358089\n",
            "Loss in iteration no. 96465 ==> 0.4847245210936694\n",
            "Loss in iteration no. 96466 ==> 0.48472351996067436\n",
            "Loss in iteration no. 96467 ==> 0.4847225188368235\n",
            "Loss in iteration no. 96468 ==> 0.48472151772211675\n",
            "Loss in iteration no. 96469 ==> 0.48472051661655396\n",
            "Loss in iteration no. 96470 ==> 0.4847195155201351\n",
            "Loss in iteration no. 96471 ==> 0.48471851443285996\n",
            "Loss in iteration no. 96472 ==> 0.48471751335472846\n",
            "Loss in iteration no. 96473 ==> 0.48471651228574036\n",
            "Loss in iteration no. 96474 ==> 0.4847155112258958\n",
            "Loss in iteration no. 96475 ==> 0.48471451017519446\n",
            "Loss in iteration no. 96476 ==> 0.4847135091336363\n",
            "Loss in iteration no. 96477 ==> 0.48471250810122113\n",
            "Loss in iteration no. 96478 ==> 0.484711507077949\n",
            "Loss in iteration no. 96479 ==> 0.48471050606381966\n",
            "Loss in iteration no. 96480 ==> 0.48470950505883303\n",
            "Loss in iteration no. 96481 ==> 0.4847085040629889\n",
            "Loss in iteration no. 96482 ==> 0.48470750307628724\n",
            "Loss in iteration no. 96483 ==> 0.48470650209872806\n",
            "Loss in iteration no. 96484 ==> 0.48470550113031097\n",
            "Loss in iteration no. 96485 ==> 0.48470450017103595\n",
            "Loss in iteration no. 96486 ==> 0.484703499220903\n",
            "Loss in iteration no. 96487 ==> 0.4847024982799119\n",
            "Loss in iteration no. 96488 ==> 0.48470149734806256\n",
            "Loss in iteration no. 96489 ==> 0.48470049642535495\n",
            "Loss in iteration no. 96490 ==> 0.4846994955117888\n",
            "Loss in iteration no. 96491 ==> 0.4846984946073641\n",
            "Loss in iteration no. 96492 ==> 0.4846974937120805\n",
            "Loss in iteration no. 96493 ==> 0.48469649282593824\n",
            "Loss in iteration no. 96494 ==> 0.4846954919489371\n",
            "Loss in iteration no. 96495 ==> 0.4846944910810767\n",
            "Loss in iteration no. 96496 ==> 0.48469349022235725\n",
            "Loss in iteration no. 96497 ==> 0.4846924893727786\n",
            "Loss in iteration no. 96498 ==> 0.4846914885323403\n",
            "Loss in iteration no. 96499 ==> 0.4846904877010426\n",
            "Loss in iteration no. 96500 ==> 0.4846894868788852\n",
            "Loss in iteration no. 96501 ==> 0.484688486065868\n",
            "Loss in iteration no. 96502 ==> 0.484687485261991\n",
            "Loss in iteration no. 96503 ==> 0.4846864844672541\n",
            "Loss in iteration no. 96504 ==> 0.4846854836816569\n",
            "Loss in iteration no. 96505 ==> 0.4846844829051995\n",
            "Loss in iteration no. 96506 ==> 0.4846834821378818\n",
            "Loss in iteration no. 96507 ==> 0.4846824813797037\n",
            "Loss in iteration no. 96508 ==> 0.4846814806306648\n",
            "Loss in iteration no. 96509 ==> 0.4846804798907653\n",
            "Loss in iteration no. 96510 ==> 0.48467947916000503\n",
            "Loss in iteration no. 96511 ==> 0.4846784784383838\n",
            "Loss in iteration no. 96512 ==> 0.4846774777259015\n",
            "Loss in iteration no. 96513 ==> 0.48467647702255795\n",
            "Loss in iteration no. 96514 ==> 0.4846754763283532\n",
            "Loss in iteration no. 96515 ==> 0.48467447564328703\n",
            "Loss in iteration no. 96516 ==> 0.4846734749673594\n",
            "Loss in iteration no. 96517 ==> 0.4846724743005701\n",
            "Loss in iteration no. 96518 ==> 0.48467147364291896\n",
            "Loss in iteration no. 96519 ==> 0.48467047299440597\n",
            "Loss in iteration no. 96520 ==> 0.48466947235503105\n",
            "Loss in iteration no. 96521 ==> 0.48466847172479394\n",
            "Loss in iteration no. 96522 ==> 0.48466747110369457\n",
            "Loss in iteration no. 96523 ==> 0.48466647049173306\n",
            "Loss in iteration no. 96524 ==> 0.48466546988890896\n",
            "Loss in iteration no. 96525 ==> 0.48466446929522217\n",
            "Loss in iteration no. 96526 ==> 0.48466346871067284\n",
            "Loss in iteration no. 96527 ==> 0.4846624681352606\n",
            "Loss in iteration no. 96528 ==> 0.4846614675689854\n",
            "Loss in iteration no. 96529 ==> 0.48466046701184734\n",
            "Loss in iteration no. 96530 ==> 0.484659466463846\n",
            "Loss in iteration no. 96531 ==> 0.4846584659249813\n",
            "Loss in iteration no. 96532 ==> 0.4846574653952534\n",
            "Loss in iteration no. 96533 ==> 0.4846564648746618\n",
            "Loss in iteration no. 96534 ==> 0.48465546436320667\n",
            "Loss in iteration no. 96535 ==> 0.48465446386088773\n",
            "Loss in iteration no. 96536 ==> 0.48465346336770493\n",
            "Loss in iteration no. 96537 ==> 0.48465246288365804\n",
            "Loss in iteration no. 96538 ==> 0.48465146240874735\n",
            "Loss in iteration no. 96539 ==> 0.48465046194297223\n",
            "Loss in iteration no. 96540 ==> 0.48464946148633276\n",
            "Loss in iteration no. 96541 ==> 0.48464846103882886\n",
            "Loss in iteration no. 96542 ==> 0.4846474606004604\n",
            "Loss in iteration no. 96543 ==> 0.4846464601712272\n",
            "Loss in iteration no. 96544 ==> 0.48464545975112927\n",
            "Loss in iteration no. 96545 ==> 0.48464445934016637\n",
            "Loss in iteration no. 96546 ==> 0.48464345893833854\n",
            "Loss in iteration no. 96547 ==> 0.48464245854564547\n",
            "Loss in iteration no. 96548 ==> 0.4846414581620871\n",
            "Loss in iteration no. 96549 ==> 0.48464045778766335\n",
            "Loss in iteration no. 96550 ==> 0.48463945742237413\n",
            "Loss in iteration no. 96551 ==> 0.4846384570662193\n",
            "Loss in iteration no. 96552 ==> 0.4846374567191986\n",
            "Loss in iteration no. 96553 ==> 0.4846364563813122\n",
            "Loss in iteration no. 96554 ==> 0.48463545605255975\n",
            "Loss in iteration no. 96555 ==> 0.4846344557329411\n",
            "Loss in iteration no. 96556 ==> 0.48463345542245645\n",
            "Loss in iteration no. 96557 ==> 0.4846324551211053\n",
            "Loss in iteration no. 96558 ==> 0.4846314548288878\n",
            "Loss in iteration no. 96559 ==> 0.4846304545458037\n",
            "Loss in iteration no. 96560 ==> 0.4846294542718529\n",
            "Loss in iteration no. 96561 ==> 0.48462845400703536\n",
            "Loss in iteration no. 96562 ==> 0.4846274537513509\n",
            "Loss in iteration no. 96563 ==> 0.4846264535047995\n",
            "Loss in iteration no. 96564 ==> 0.48462545326738066\n",
            "Loss in iteration no. 96565 ==> 0.48462445303909485\n",
            "Loss in iteration no. 96566 ==> 0.4846234528199414\n",
            "Loss in iteration no. 96567 ==> 0.4846224526099207\n",
            "Loss in iteration no. 96568 ==> 0.4846214524090324\n",
            "Loss in iteration no. 96569 ==> 0.4846204522172761\n",
            "Loss in iteration no. 96570 ==> 0.4846194520346521\n",
            "Loss in iteration no. 96571 ==> 0.48461845186116015\n",
            "Loss in iteration no. 96572 ==> 0.48461745169680015\n",
            "Loss in iteration no. 96573 ==> 0.4846164515415719\n",
            "Loss in iteration no. 96574 ==> 0.48461545139547535\n",
            "Loss in iteration no. 96575 ==> 0.4846144512585103\n",
            "Loss in iteration no. 96576 ==> 0.4846134511306768\n",
            "Loss in iteration no. 96577 ==> 0.48461245101197453\n",
            "Loss in iteration no. 96578 ==> 0.48461145090240354\n",
            "Loss in iteration no. 96579 ==> 0.48461045080196363\n",
            "Loss in iteration no. 96580 ==> 0.48460945071065475\n",
            "Loss in iteration no. 96581 ==> 0.4846084506284766\n",
            "Loss in iteration no. 96582 ==> 0.4846074505554293\n",
            "Loss in iteration no. 96583 ==> 0.48460645049151263\n",
            "Loss in iteration no. 96584 ==> 0.4846054504367265\n",
            "Loss in iteration no. 96585 ==> 0.4846044503910706\n",
            "Loss in iteration no. 96586 ==> 0.48460345035454516\n",
            "Loss in iteration no. 96587 ==> 0.48460245032714966\n",
            "Loss in iteration no. 96588 ==> 0.48460145030888435\n",
            "Loss in iteration no. 96589 ==> 0.484600450299749\n",
            "Loss in iteration no. 96590 ==> 0.4845994502997434\n",
            "Loss in iteration no. 96591 ==> 0.48459845030886756\n",
            "Loss in iteration no. 96592 ==> 0.48459745032712126\n",
            "Loss in iteration no. 96593 ==> 0.4845964503545043\n",
            "Loss in iteration no. 96594 ==> 0.48459545039101676\n",
            "Loss in iteration no. 96595 ==> 0.48459445043665844\n",
            "Loss in iteration no. 96596 ==> 0.4845934504914292\n",
            "Loss in iteration no. 96597 ==> 0.48459245055532907\n",
            "Loss in iteration no. 96598 ==> 0.48459145062835784\n",
            "Loss in iteration no. 96599 ==> 0.4845904507105152\n",
            "Loss in iteration no. 96600 ==> 0.48458945080180127\n",
            "Loss in iteration no. 96601 ==> 0.4845884509022158\n",
            "Loss in iteration no. 96602 ==> 0.4845874510117588\n",
            "Loss in iteration no. 96603 ==> 0.48458645113043003\n",
            "Loss in iteration no. 96604 ==> 0.4845854512582295\n",
            "Loss in iteration no. 96605 ==> 0.48458445139515705\n",
            "Loss in iteration no. 96606 ==> 0.48458345154121246\n",
            "Loss in iteration no. 96607 ==> 0.48458245169639563\n",
            "Loss in iteration no. 96608 ==> 0.48458145186070667\n",
            "Loss in iteration no. 96609 ==> 0.48458045203414507\n",
            "Loss in iteration no. 96610 ==> 0.48457945221671106\n",
            "Loss in iteration no. 96611 ==> 0.48457845240840447\n",
            "Loss in iteration no. 96612 ==> 0.4845774526092251\n",
            "Loss in iteration no. 96613 ==> 0.4845764528191728\n",
            "Loss in iteration no. 96614 ==> 0.4845754530382475\n",
            "Loss in iteration no. 96615 ==> 0.48457445326644905\n",
            "Loss in iteration no. 96616 ==> 0.4845734535037774\n",
            "Loss in iteration no. 96617 ==> 0.48457245375023245\n",
            "Loss in iteration no. 96618 ==> 0.4845714540058139\n",
            "Loss in iteration no. 96619 ==> 0.48457045427052187\n",
            "Loss in iteration no. 96620 ==> 0.48456945454435607\n",
            "Loss in iteration no. 96621 ==> 0.4845684548273165\n",
            "Loss in iteration no. 96622 ==> 0.484567455119403\n",
            "Loss in iteration no. 96623 ==> 0.4845664554206154\n",
            "Loss in iteration no. 96624 ==> 0.4845654557309538\n",
            "Loss in iteration no. 96625 ==> 0.48456445605041765\n",
            "Loss in iteration no. 96626 ==> 0.4845634563790073\n",
            "Loss in iteration no. 96627 ==> 0.4845624567167223\n",
            "Loss in iteration no. 96628 ==> 0.48456145706356274\n",
            "Loss in iteration no. 96629 ==> 0.48456045741952825\n",
            "Loss in iteration no. 96630 ==> 0.4845594577846191\n",
            "Loss in iteration no. 96631 ==> 0.48455845815883486\n",
            "Loss in iteration no. 96632 ==> 0.4845574585421756\n",
            "Loss in iteration no. 96633 ==> 0.48455645893464105\n",
            "Loss in iteration no. 96634 ==> 0.4845554593362312\n",
            "Loss in iteration no. 96635 ==> 0.48455445974694583\n",
            "Loss in iteration no. 96636 ==> 0.48455346016678497\n",
            "Loss in iteration no. 96637 ==> 0.48455246059574836\n",
            "Loss in iteration no. 96638 ==> 0.4845514610338359\n",
            "Loss in iteration no. 96639 ==> 0.4845504614810476\n",
            "Loss in iteration no. 96640 ==> 0.4845494619373833\n",
            "Loss in iteration no. 96641 ==> 0.48454846240284266\n",
            "Loss in iteration no. 96642 ==> 0.48454746287742595\n",
            "Loss in iteration no. 96643 ==> 0.4845464633611328\n",
            "Loss in iteration no. 96644 ==> 0.484545463853963\n",
            "Loss in iteration no. 96645 ==> 0.4845444643559168\n",
            "Loss in iteration no. 96646 ==> 0.4845434648669936\n",
            "Loss in iteration no. 96647 ==> 0.48454246538719364\n",
            "Loss in iteration no. 96648 ==> 0.4845414659165168\n",
            "Loss in iteration no. 96649 ==> 0.48454046645496274\n",
            "Loss in iteration no. 96650 ==> 0.48453946700253153\n",
            "Loss in iteration no. 96651 ==> 0.48453846755922303\n",
            "Loss in iteration no. 96652 ==> 0.484537468125037\n",
            "Loss in iteration no. 96653 ==> 0.48453646869997347\n",
            "Loss in iteration no. 96654 ==> 0.48453546928403224\n",
            "Loss in iteration no. 96655 ==> 0.48453446987721316\n",
            "Loss in iteration no. 96656 ==> 0.4845334704795163\n",
            "Loss in iteration no. 96657 ==> 0.48453247109094116\n",
            "Loss in iteration no. 96658 ==> 0.48453147171148814\n",
            "Loss in iteration no. 96659 ==> 0.48453047234115676\n",
            "Loss in iteration no. 96660 ==> 0.4845294729799469\n",
            "Loss in iteration no. 96661 ==> 0.4845284736278587\n",
            "Loss in iteration no. 96662 ==> 0.4845274742848919\n",
            "Loss in iteration no. 96663 ==> 0.48452647495104634\n",
            "Loss in iteration no. 96664 ==> 0.4845254756263218\n",
            "Loss in iteration no. 96665 ==> 0.4845244763107184\n",
            "Loss in iteration no. 96666 ==> 0.4845234770042359\n",
            "Loss in iteration no. 96667 ==> 0.4845224777068742\n",
            "Loss in iteration no. 96668 ==> 0.4845214784186332\n",
            "Loss in iteration no. 96669 ==> 0.4845204791395128\n",
            "Loss in iteration no. 96670 ==> 0.48451947986951277\n",
            "Loss in iteration no. 96671 ==> 0.4845184806086331\n",
            "Loss in iteration no. 96672 ==> 0.4845174813568736\n",
            "Loss in iteration no. 96673 ==> 0.4845164821142343\n",
            "Loss in iteration no. 96674 ==> 0.48451548288071494\n",
            "Loss in iteration no. 96675 ==> 0.48451448365631544\n",
            "Loss in iteration no. 96676 ==> 0.48451348444103565\n",
            "Loss in iteration no. 96677 ==> 0.48451248523487556\n",
            "Loss in iteration no. 96678 ==> 0.4845114860378349\n",
            "Loss in iteration no. 96679 ==> 0.48451048684991377\n",
            "Loss in iteration no. 96680 ==> 0.48450948767111185\n",
            "Loss in iteration no. 96681 ==> 0.4845084885014291\n",
            "Loss in iteration no. 96682 ==> 0.48450748934086546\n",
            "Loss in iteration no. 96683 ==> 0.48450649018942066\n",
            "Loss in iteration no. 96684 ==> 0.48450549104709467\n",
            "Loss in iteration no. 96685 ==> 0.4845044919138874\n",
            "Loss in iteration no. 96686 ==> 0.48450349278979876\n",
            "Loss in iteration no. 96687 ==> 0.4845024936748285\n",
            "Loss in iteration no. 96688 ==> 0.4845014945689767\n",
            "Loss in iteration no. 96689 ==> 0.484500495472243\n",
            "Loss in iteration no. 96690 ==> 0.4844994963846276\n",
            "Loss in iteration no. 96691 ==> 0.4844984973061299\n",
            "Loss in iteration no. 96692 ==> 0.48449749823675026\n",
            "Loss in iteration no. 96693 ==> 0.4844964991764884\n",
            "Loss in iteration no. 96694 ==> 0.4844955001253442\n",
            "Loss in iteration no. 96695 ==> 0.48449450108331743\n",
            "Loss in iteration no. 96696 ==> 0.4844935020504082\n",
            "Loss in iteration no. 96697 ==> 0.48449250302661623\n",
            "Loss in iteration no. 96698 ==> 0.48449150401194135\n",
            "Loss in iteration no. 96699 ==> 0.4844905050063836\n",
            "Loss in iteration no. 96700 ==> 0.4844895060099427\n",
            "Loss in iteration no. 96701 ==> 0.4844885070226188\n",
            "Loss in iteration no. 96702 ==> 0.4844875080444115\n",
            "Loss in iteration no. 96703 ==> 0.48448650907532076\n",
            "Loss in iteration no. 96704 ==> 0.4844855101153466\n",
            "Loss in iteration no. 96705 ==> 0.48448451116448865\n",
            "Loss in iteration no. 96706 ==> 0.4844835122227472\n",
            "Loss in iteration no. 96707 ==> 0.48448251329012176\n",
            "Loss in iteration no. 96708 ==> 0.48448151436661224\n",
            "Loss in iteration no. 96709 ==> 0.48448051545221865\n",
            "Loss in iteration no. 96710 ==> 0.4844795165469409\n",
            "Loss in iteration no. 96711 ==> 0.4844785176507786\n",
            "Loss in iteration no. 96712 ==> 0.4844775187637321\n",
            "Loss in iteration no. 96713 ==> 0.48447651988580087\n",
            "Loss in iteration no. 96714 ==> 0.48447552101698504\n",
            "Loss in iteration no. 96715 ==> 0.4844745221572843\n",
            "Loss in iteration no. 96716 ==> 0.4844735233066988\n",
            "Loss in iteration no. 96717 ==> 0.4844725244652281\n",
            "Loss in iteration no. 96718 ==> 0.4844715256328724\n",
            "Loss in iteration no. 96719 ==> 0.4844705268096313\n",
            "Loss in iteration no. 96720 ==> 0.48446952799550486\n",
            "Loss in iteration no. 96721 ==> 0.4844685291904929\n",
            "Loss in iteration no. 96722 ==> 0.4844675303945953\n",
            "Loss in iteration no. 96723 ==> 0.48446653160781206\n",
            "Loss in iteration no. 96724 ==> 0.4844655328301428\n",
            "Loss in iteration no. 96725 ==> 0.4844645340615876\n",
            "Loss in iteration no. 96726 ==> 0.4844635353021464\n",
            "Loss in iteration no. 96727 ==> 0.4844625365518189\n",
            "Loss in iteration no. 96728 ==> 0.48446153781060514\n",
            "Loss in iteration no. 96729 ==> 0.48446053907850484\n",
            "Loss in iteration no. 96730 ==> 0.484459540355518\n",
            "Loss in iteration no. 96731 ==> 0.4844585416416446\n",
            "Loss in iteration no. 96732 ==> 0.48445754293688437\n",
            "Loss in iteration no. 96733 ==> 0.48445654424123724\n",
            "Loss in iteration no. 96734 ==> 0.484455545554703\n",
            "Loss in iteration no. 96735 ==> 0.48445454687728173\n",
            "Loss in iteration no. 96736 ==> 0.48445354820897313\n",
            "Loss in iteration no. 96737 ==> 0.4844525495497771\n",
            "Loss in iteration no. 96738 ==> 0.48445155089969355\n",
            "Loss in iteration no. 96739 ==> 0.4844505522587226\n",
            "Loss in iteration no. 96740 ==> 0.4844495536268637\n",
            "Loss in iteration no. 96741 ==> 0.4844485550041171\n",
            "Loss in iteration no. 96742 ==> 0.48444755639048254\n",
            "Loss in iteration no. 96743 ==> 0.4844465577859598\n",
            "Loss in iteration no. 96744 ==> 0.48444555919054894\n",
            "Loss in iteration no. 96745 ==> 0.48444456060424973\n",
            "Loss in iteration no. 96746 ==> 0.48444356202706207\n",
            "Loss in iteration no. 96747 ==> 0.48444256345898595\n",
            "Loss in iteration no. 96748 ==> 0.48444156490002116\n",
            "Loss in iteration no. 96749 ==> 0.4844405663501675\n",
            "Loss in iteration no. 96750 ==> 0.48443956780942515\n",
            "Loss in iteration no. 96751 ==> 0.4844385692777935\n",
            "Loss in iteration no. 96752 ==> 0.484437570755273\n",
            "Loss in iteration no. 96753 ==> 0.4844365722418631\n",
            "Loss in iteration no. 96754 ==> 0.48443557373756385\n",
            "Loss in iteration no. 96755 ==> 0.4844345752423751\n",
            "Loss in iteration no. 96756 ==> 0.4844335767562968\n",
            "Loss in iteration no. 96757 ==> 0.4844325782793288\n",
            "Loss in iteration no. 96758 ==> 0.48443157981147095\n",
            "Loss in iteration no. 96759 ==> 0.4844305813527231\n",
            "Loss in iteration no. 96760 ==> 0.48442958290308524\n",
            "Loss in iteration no. 96761 ==> 0.4844285844625572\n",
            "Loss in iteration no. 96762 ==> 0.484427586031139\n",
            "Loss in iteration no. 96763 ==> 0.48442658760883006\n",
            "Loss in iteration no. 96764 ==> 0.4844255891956309\n",
            "Loss in iteration no. 96765 ==> 0.48442459079154093\n",
            "Loss in iteration no. 96766 ==> 0.4844235923965603\n",
            "Loss in iteration no. 96767 ==> 0.48442259401068877\n",
            "Loss in iteration no. 96768 ==> 0.4844215956339262\n",
            "Loss in iteration no. 96769 ==> 0.48442059726627246\n",
            "Loss in iteration no. 96770 ==> 0.4844195989077276\n",
            "Loss in iteration no. 96771 ==> 0.48441860055829145\n",
            "Loss in iteration no. 96772 ==> 0.48441760221796376\n",
            "Loss in iteration no. 96773 ==> 0.4844166038867444\n",
            "Loss in iteration no. 96774 ==> 0.4844156055646335\n",
            "Loss in iteration no. 96775 ==> 0.48441460725163066\n",
            "Loss in iteration no. 96776 ==> 0.484413608947736\n",
            "Loss in iteration no. 96777 ==> 0.4844126106529492\n",
            "Loss in iteration no. 96778 ==> 0.4844116123672703\n",
            "Loss in iteration no. 96779 ==> 0.48441061409069913\n",
            "Loss in iteration no. 96780 ==> 0.48440961582323555\n",
            "Loss in iteration no. 96781 ==> 0.48440861756487946\n",
            "Loss in iteration no. 96782 ==> 0.48440761931563076\n",
            "Loss in iteration no. 96783 ==> 0.4844066210754893\n",
            "Loss in iteration no. 96784 ==> 0.48440562284445493\n",
            "Loss in iteration no. 96785 ==> 0.48440462462252754\n",
            "Loss in iteration no. 96786 ==> 0.4844036264097072\n",
            "Loss in iteration no. 96787 ==> 0.4844026282059936\n",
            "Loss in iteration no. 96788 ==> 0.4844016300113867\n",
            "Loss in iteration no. 96789 ==> 0.4844006318258864\n",
            "Loss in iteration no. 96790 ==> 0.48439963364949234\n",
            "Loss in iteration no. 96791 ==> 0.4843986354822047\n",
            "Loss in iteration no. 96792 ==> 0.4843976373240232\n",
            "Loss in iteration no. 96793 ==> 0.484396639174948\n",
            "Loss in iteration no. 96794 ==> 0.4843956410349785\n",
            "Loss in iteration no. 96795 ==> 0.4843946429041151\n",
            "Loss in iteration no. 96796 ==> 0.4843936447823573\n",
            "Loss in iteration no. 96797 ==> 0.4843926466697052\n",
            "Loss in iteration no. 96798 ==> 0.48439164856615846\n",
            "Loss in iteration no. 96799 ==> 0.48439065047171725\n",
            "Loss in iteration no. 96800 ==> 0.4843896523863813\n",
            "Loss in iteration no. 96801 ==> 0.48438865431015043\n",
            "Loss in iteration no. 96802 ==> 0.48438765624302466\n",
            "Loss in iteration no. 96803 ==> 0.4843866581850038\n",
            "Loss in iteration no. 96804 ==> 0.48438566013608764\n",
            "Loss in iteration no. 96805 ==> 0.48438466209627634\n",
            "Loss in iteration no. 96806 ==> 0.48438366406556954\n",
            "Loss in iteration no. 96807 ==> 0.4843826660439671\n",
            "Loss in iteration no. 96808 ==> 0.4843816680314691\n",
            "Loss in iteration no. 96809 ==> 0.48438067002807533\n",
            "Loss in iteration no. 96810 ==> 0.4843796720337857\n",
            "Loss in iteration no. 96811 ==> 0.48437867404859997\n",
            "Loss in iteration no. 96812 ==> 0.48437767607251814\n",
            "Loss in iteration no. 96813 ==> 0.4843766781055401\n",
            "Loss in iteration no. 96814 ==> 0.4843756801476657\n",
            "Loss in iteration no. 96815 ==> 0.48437468219889485\n",
            "Loss in iteration no. 96816 ==> 0.4843736842592274\n",
            "Loss in iteration no. 96817 ==> 0.48437268632866304\n",
            "Loss in iteration no. 96818 ==> 0.484371688407202\n",
            "Loss in iteration no. 96819 ==> 0.4843706904948441\n",
            "Loss in iteration no. 96820 ==> 0.48436969259158913\n",
            "Loss in iteration no. 96821 ==> 0.4843686946974368\n",
            "Loss in iteration no. 96822 ==> 0.4843676968123873\n",
            "Loss in iteration no. 96823 ==> 0.4843666989364404\n",
            "Loss in iteration no. 96824 ==> 0.484365701069596\n",
            "Loss in iteration no. 96825 ==> 0.48436470321185393\n",
            "Loss in iteration no. 96826 ==> 0.484363705363214\n",
            "Loss in iteration no. 96827 ==> 0.48436270752367633\n",
            "Loss in iteration no. 96828 ==> 0.4843617096932406\n",
            "Loss in iteration no. 96829 ==> 0.4843607118719067\n",
            "Loss in iteration no. 96830 ==> 0.48435971405967476\n",
            "Loss in iteration no. 96831 ==> 0.48435871625654436\n",
            "Loss in iteration no. 96832 ==> 0.4843577184625156\n",
            "Loss in iteration no. 96833 ==> 0.48435672067758795\n",
            "Loss in iteration no. 96834 ==> 0.484355722901762\n",
            "Loss in iteration no. 96835 ==> 0.484354725135037\n",
            "Loss in iteration no. 96836 ==> 0.48435372737741317\n",
            "Loss in iteration no. 96837 ==> 0.4843527296288902\n",
            "Loss in iteration no. 96838 ==> 0.4843517318894682\n",
            "Loss in iteration no. 96839 ==> 0.484350734159147\n",
            "Loss in iteration no. 96840 ==> 0.48434973643792617\n",
            "Loss in iteration no. 96841 ==> 0.4843487387258059\n",
            "Loss in iteration no. 96842 ==> 0.484347741022786\n",
            "Loss in iteration no. 96843 ==> 0.4843467433288664\n",
            "Loss in iteration no. 96844 ==> 0.48434574564404703\n",
            "Loss in iteration no. 96845 ==> 0.48434474796832755\n",
            "Loss in iteration no. 96846 ==> 0.48434375030170806\n",
            "Loss in iteration no. 96847 ==> 0.4843427526441883\n",
            "Loss in iteration no. 96848 ==> 0.4843417549957683\n",
            "Loss in iteration no. 96849 ==> 0.48434075735644777\n",
            "Loss in iteration no. 96850 ==> 0.4843397597262268\n",
            "Loss in iteration no. 96851 ==> 0.484338762105105\n",
            "Loss in iteration no. 96852 ==> 0.48433776449308247\n",
            "Loss in iteration no. 96853 ==> 0.4843367668901591\n",
            "Loss in iteration no. 96854 ==> 0.48433576929633465\n",
            "Loss in iteration no. 96855 ==> 0.48433477171160905\n",
            "Loss in iteration no. 96856 ==> 0.48433377413598216\n",
            "Loss in iteration no. 96857 ==> 0.48433277656945395\n",
            "Loss in iteration no. 96858 ==> 0.48433177901202434\n",
            "Loss in iteration no. 96859 ==> 0.48433078146369307\n",
            "Loss in iteration no. 96860 ==> 0.48432978392445997\n",
            "Loss in iteration no. 96861 ==> 0.4843287863943251\n",
            "Loss in iteration no. 96862 ==> 0.4843277888732882\n",
            "Loss in iteration no. 96863 ==> 0.48432679136134943\n",
            "Loss in iteration no. 96864 ==> 0.4843257938585083\n",
            "Loss in iteration no. 96865 ==> 0.484324796364765\n",
            "Loss in iteration no. 96866 ==> 0.4843237988801191\n",
            "Loss in iteration no. 96867 ==> 0.48432280140457085\n",
            "Loss in iteration no. 96868 ==> 0.48432180393811974\n",
            "Loss in iteration no. 96869 ==> 0.4843208064807659\n",
            "Loss in iteration no. 96870 ==> 0.4843198090325093\n",
            "Loss in iteration no. 96871 ==> 0.4843188115933496\n",
            "Loss in iteration no. 96872 ==> 0.48431781416328706\n",
            "Loss in iteration no. 96873 ==> 0.48431681674232085\n",
            "Loss in iteration no. 96874 ==> 0.4843158193304515\n",
            "Loss in iteration no. 96875 ==> 0.4843148219276788\n",
            "Loss in iteration no. 96876 ==> 0.4843138245340023\n",
            "Loss in iteration no. 96877 ==> 0.4843128271494222\n",
            "Loss in iteration no. 96878 ==> 0.4843118297739381\n",
            "Loss in iteration no. 96879 ==> 0.48431083240755035\n",
            "Loss in iteration no. 96880 ==> 0.48430983505025843\n",
            "Loss in iteration no. 96881 ==> 0.48430883770206223\n",
            "Loss in iteration no. 96882 ==> 0.4843078403629619\n",
            "Loss in iteration no. 96883 ==> 0.4843068430329571\n",
            "Loss in iteration no. 96884 ==> 0.4843058457120477\n",
            "Loss in iteration no. 96885 ==> 0.4843048484002338\n",
            "Loss in iteration no. 96886 ==> 0.48430385109751506\n",
            "Loss in iteration no. 96887 ==> 0.48430285380389165\n",
            "Loss in iteration no. 96888 ==> 0.484301856519363\n",
            "Loss in iteration no. 96889 ==> 0.4843008592439295\n",
            "Loss in iteration no. 96890 ==> 0.48429986197759056\n",
            "Loss in iteration no. 96891 ==> 0.48429886472034633\n",
            "Loss in iteration no. 96892 ==> 0.48429786747219666\n",
            "Loss in iteration no. 96893 ==> 0.4842968702331415\n",
            "Loss in iteration no. 96894 ==> 0.48429587300318067\n",
            "Loss in iteration no. 96895 ==> 0.48429487578231395\n",
            "Loss in iteration no. 96896 ==> 0.48429387857054135\n",
            "Loss in iteration no. 96897 ==> 0.4842928813678627\n",
            "Loss in iteration no. 96898 ==> 0.48429188417427793\n",
            "Loss in iteration no. 96899 ==> 0.48429088698978684\n",
            "Loss in iteration no. 96900 ==> 0.4842898898143894\n",
            "Loss in iteration no. 96901 ==> 0.48428889264808556\n",
            "Loss in iteration no. 96902 ==> 0.484287895490875\n",
            "Loss in iteration no. 96903 ==> 0.48428689834275773\n",
            "Loss in iteration no. 96904 ==> 0.48428590120373355\n",
            "Loss in iteration no. 96905 ==> 0.4842849040738026\n",
            "Loss in iteration no. 96906 ==> 0.48428390695296436\n",
            "Loss in iteration no. 96907 ==> 0.484282909841219\n",
            "Loss in iteration no. 96908 ==> 0.48428191273856636\n",
            "Loss in iteration no. 96909 ==> 0.4842809156450062\n",
            "Loss in iteration no. 96910 ==> 0.4842799185605386\n",
            "Loss in iteration no. 96911 ==> 0.4842789214851632\n",
            "Loss in iteration no. 96912 ==> 0.48427792441888023\n",
            "Loss in iteration no. 96913 ==> 0.48427692736168915\n",
            "Loss in iteration no. 96914 ==> 0.4842759303135903\n",
            "Loss in iteration no. 96915 ==> 0.48427493327458315\n",
            "Loss in iteration no. 96916 ==> 0.4842739362446678\n",
            "Loss in iteration no. 96917 ==> 0.48427293922384396\n",
            "Loss in iteration no. 96918 ==> 0.48427194221211184\n",
            "Loss in iteration no. 96919 ==> 0.48427094520947117\n",
            "Loss in iteration no. 96920 ==> 0.4842699482159217\n",
            "Loss in iteration no. 96921 ==> 0.48426895123146324\n",
            "Loss in iteration no. 96922 ==> 0.48426795425609603\n",
            "Loss in iteration no. 96923 ==> 0.4842669572898197\n",
            "Loss in iteration no. 96924 ==> 0.48426596033263425\n",
            "Loss in iteration no. 96925 ==> 0.48426496338453945\n",
            "Loss in iteration no. 96926 ==> 0.48426396644553515\n",
            "Loss in iteration no. 96927 ==> 0.4842629695156215\n",
            "Loss in iteration no. 96928 ==> 0.48426197259479814\n",
            "Loss in iteration no. 96929 ==> 0.48426097568306503\n",
            "Loss in iteration no. 96930 ==> 0.48425997878042204\n",
            "Loss in iteration no. 96931 ==> 0.48425898188686906\n",
            "Loss in iteration no. 96932 ==> 0.484257985002406\n",
            "Loss in iteration no. 96933 ==> 0.4842569881270327\n",
            "Loss in iteration no. 96934 ==> 0.48425599126074914\n",
            "Loss in iteration no. 96935 ==> 0.4842549944035549\n",
            "Loss in iteration no. 96936 ==> 0.4842539975554503\n",
            "Loss in iteration no. 96937 ==> 0.48425300071643507\n",
            "Loss in iteration no. 96938 ==> 0.48425200388650874\n",
            "Loss in iteration no. 96939 ==> 0.4842510070656717\n",
            "Loss in iteration no. 96940 ==> 0.4842500102539236\n",
            "Loss in iteration no. 96941 ==> 0.48424901345126437\n",
            "Loss in iteration no. 96942 ==> 0.4842480166576938\n",
            "Loss in iteration no. 96943 ==> 0.48424701987321184\n",
            "Loss in iteration no. 96944 ==> 0.4842460230978184\n",
            "Loss in iteration no. 96945 ==> 0.48424502633151345\n",
            "Loss in iteration no. 96946 ==> 0.4842440295742966\n",
            "Loss in iteration no. 96947 ==> 0.48424303282616804\n",
            "Loss in iteration no. 96948 ==> 0.48424203608712746\n",
            "Loss in iteration no. 96949 ==> 0.48424103935717466\n",
            "Loss in iteration no. 96950 ==> 0.4842400426363098\n",
            "Loss in iteration no. 96951 ==> 0.48423904592453265\n",
            "Loss in iteration no. 96952 ==> 0.4842380492218431\n",
            "Loss in iteration no. 96953 ==> 0.48423705252824084\n",
            "Loss in iteration no. 96954 ==> 0.48423605584372603\n",
            "Loss in iteration no. 96955 ==> 0.48423505916829845\n",
            "Loss in iteration no. 96956 ==> 0.48423406250195794\n",
            "Loss in iteration no. 96957 ==> 0.4842330658447043\n",
            "Loss in iteration no. 96958 ==> 0.4842320691965378\n",
            "Loss in iteration no. 96959 ==> 0.4842310725574578\n",
            "Loss in iteration no. 96960 ==> 0.4842300759274644\n",
            "Loss in iteration no. 96961 ==> 0.4842290793065577\n",
            "Loss in iteration no. 96962 ==> 0.48422808269473744\n",
            "Loss in iteration no. 96963 ==> 0.4842270860920033\n",
            "Loss in iteration no. 96964 ==> 0.48422608949835544\n",
            "Loss in iteration no. 96965 ==> 0.4842250929137937\n",
            "Loss in iteration no. 96966 ==> 0.4842240963383177\n",
            "Loss in iteration no. 96967 ==> 0.48422309977192773\n",
            "Loss in iteration no. 96968 ==> 0.4842221032146234\n",
            "Loss in iteration no. 96969 ==> 0.4842211066664045\n",
            "Loss in iteration no. 96970 ==> 0.48422011012727134\n",
            "Loss in iteration no. 96971 ==> 0.48421911359722325\n",
            "Loss in iteration no. 96972 ==> 0.48421811707626067\n",
            "Loss in iteration no. 96973 ==> 0.484217120564383\n",
            "Loss in iteration no. 96974 ==> 0.4842161240615905\n",
            "Loss in iteration no. 96975 ==> 0.4842151275678829\n",
            "Loss in iteration no. 96976 ==> 0.48421413108325984\n",
            "Loss in iteration no. 96977 ==> 0.4842131346077217\n",
            "Loss in iteration no. 96978 ==> 0.484212138141268\n",
            "Loss in iteration no. 96979 ==> 0.4842111416838987\n",
            "Loss in iteration no. 96980 ==> 0.4842101452356137\n",
            "Loss in iteration no. 96981 ==> 0.484209148796413\n",
            "Loss in iteration no. 96982 ==> 0.48420815236629633\n",
            "Loss in iteration no. 96983 ==> 0.48420715594526353\n",
            "Loss in iteration no. 96984 ==> 0.48420615953331475\n",
            "Loss in iteration no. 96985 ==> 0.48420516313044953\n",
            "Loss in iteration no. 96986 ==> 0.4842041667366681\n",
            "Loss in iteration no. 96987 ==> 0.4842031703519701\n",
            "Loss in iteration no. 96988 ==> 0.4842021739763554\n",
            "Loss in iteration no. 96989 ==> 0.48420117760982395\n",
            "Loss in iteration no. 96990 ==> 0.48420018125237574\n",
            "Loss in iteration no. 96991 ==> 0.48419918490401054\n",
            "Loss in iteration no. 96992 ==> 0.4841981885647283\n",
            "Loss in iteration no. 96993 ==> 0.48419719223452884\n",
            "Loss in iteration no. 96994 ==> 0.4841961959134119\n",
            "Loss in iteration no. 96995 ==> 0.4841951996013777\n",
            "Loss in iteration no. 96996 ==> 0.48419420329842583\n",
            "Loss in iteration no. 96997 ==> 0.4841932070045564\n",
            "Loss in iteration no. 96998 ==> 0.4841922107197692\n",
            "Loss in iteration no. 96999 ==> 0.48419121444406427\n",
            "Loss in iteration no. 97000 ==> 0.484190218177441\n",
            "Loss in iteration no. 97001 ==> 0.4841892219198997\n",
            "Loss in iteration no. 97002 ==> 0.48418822567144026\n",
            "Loss in iteration no. 97003 ==> 0.4841872294320623\n",
            "Loss in iteration no. 97004 ==> 0.48418623320176596\n",
            "Loss in iteration no. 97005 ==> 0.48418523698055105\n",
            "Loss in iteration no. 97006 ==> 0.48418424076841743\n",
            "Loss in iteration no. 97007 ==> 0.4841832445653649\n",
            "Loss in iteration no. 97008 ==> 0.48418224837139345\n",
            "Loss in iteration no. 97009 ==> 0.4841812521865029\n",
            "Loss in iteration no. 97010 ==> 0.48418025601069326\n",
            "Loss in iteration no. 97011 ==> 0.48417925984396437\n",
            "Loss in iteration no. 97012 ==> 0.4841782636863159\n",
            "Loss in iteration no. 97013 ==> 0.4841772675377481\n",
            "Loss in iteration no. 97014 ==> 0.4841762713982605\n",
            "Loss in iteration no. 97015 ==> 0.48417527526785314\n",
            "Loss in iteration no. 97016 ==> 0.48417427914652605\n",
            "Loss in iteration no. 97017 ==> 0.4841732830342789\n",
            "Loss in iteration no. 97018 ==> 0.4841722869311116\n",
            "Loss in iteration no. 97019 ==> 0.48417129083702415\n",
            "Loss in iteration no. 97020 ==> 0.4841702947520164\n",
            "Loss in iteration no. 97021 ==> 0.48416929867608816\n",
            "Loss in iteration no. 97022 ==> 0.48416830260923915\n",
            "Loss in iteration no. 97023 ==> 0.4841673065514696\n",
            "Loss in iteration no. 97024 ==> 0.4841663105027793\n",
            "Loss in iteration no. 97025 ==> 0.4841653144631681\n",
            "Loss in iteration no. 97026 ==> 0.4841643184326358\n",
            "Loss in iteration no. 97027 ==> 0.48416332241118226\n",
            "Loss in iteration no. 97028 ==> 0.4841623263988077\n",
            "Loss in iteration no. 97029 ==> 0.4841613303955115\n",
            "Loss in iteration no. 97030 ==> 0.48416033440129397\n",
            "Loss in iteration no. 97031 ==> 0.4841593384161547\n",
            "Loss in iteration no. 97032 ==> 0.48415834244009387\n",
            "Loss in iteration no. 97033 ==> 0.484157346473111\n",
            "Loss in iteration no. 97034 ==> 0.4841563505152063\n",
            "Loss in iteration no. 97035 ==> 0.4841553545663794\n",
            "Loss in iteration no. 97036 ==> 0.4841543586266303\n",
            "Loss in iteration no. 97037 ==> 0.48415336269595904\n",
            "Loss in iteration no. 97038 ==> 0.48415236677436535\n",
            "Loss in iteration no. 97039 ==> 0.48415137086184895\n",
            "Loss in iteration no. 97040 ==> 0.4841503749584099\n",
            "Loss in iteration no. 97041 ==> 0.48414937906404826\n",
            "Loss in iteration no. 97042 ==> 0.4841483831787636\n",
            "Loss in iteration no. 97043 ==> 0.484147387302556\n",
            "Loss in iteration no. 97044 ==> 0.48414639143542515\n",
            "Loss in iteration no. 97045 ==> 0.4841453955773712\n",
            "Loss in iteration no. 97046 ==> 0.4841443997283938\n",
            "Loss in iteration no. 97047 ==> 0.4841434038884929\n",
            "Loss in iteration no. 97048 ==> 0.4841424080576685\n",
            "Loss in iteration no. 97049 ==> 0.48414141223592033\n",
            "Loss in iteration no. 97050 ==> 0.48414041642324845\n",
            "Loss in iteration no. 97051 ==> 0.4841394206196525\n",
            "Loss in iteration no. 97052 ==> 0.4841384248251325\n",
            "Loss in iteration no. 97053 ==> 0.48413742903968837\n",
            "Loss in iteration no. 97054 ==> 0.4841364332633199\n",
            "Loss in iteration no. 97055 ==> 0.48413543749602705\n",
            "Loss in iteration no. 97056 ==> 0.48413444173780973\n",
            "Loss in iteration no. 97057 ==> 0.4841334459886677\n",
            "Loss in iteration no. 97058 ==> 0.4841324502486011\n",
            "Loss in iteration no. 97059 ==> 0.48413145451760947\n",
            "Loss in iteration no. 97060 ==> 0.4841304587956929\n",
            "Loss in iteration no. 97061 ==> 0.48412946308285115\n",
            "Loss in iteration no. 97062 ==> 0.48412846737908427\n",
            "Loss in iteration no. 97063 ==> 0.484127471684392\n",
            "Loss in iteration no. 97064 ==> 0.4841264759987743\n",
            "Loss in iteration no. 97065 ==> 0.484125480322231\n",
            "Loss in iteration no. 97066 ==> 0.48412448465476227\n",
            "Loss in iteration no. 97067 ==> 0.4841234889963674\n",
            "Loss in iteration no. 97068 ==> 0.4841224933470467\n",
            "Loss in iteration no. 97069 ==> 0.48412149770680013\n",
            "Loss in iteration no. 97070 ==> 0.48412050207562723\n",
            "Loss in iteration no. 97071 ==> 0.4841195064535282\n",
            "Loss in iteration no. 97072 ==> 0.4841185108405028\n",
            "Loss in iteration no. 97073 ==> 0.48411751523655083\n",
            "Loss in iteration no. 97074 ==> 0.48411651964167224\n",
            "Loss in iteration no. 97075 ==> 0.484115524055867\n",
            "Loss in iteration no. 97076 ==> 0.4841145284791349\n",
            "Loss in iteration no. 97077 ==> 0.4841135329114758\n",
            "Loss in iteration no. 97078 ==> 0.48411253735288956\n",
            "Loss in iteration no. 97079 ==> 0.4841115418033763\n",
            "Loss in iteration no. 97080 ==> 0.4841105462629356\n",
            "Loss in iteration no. 97081 ==> 0.48410955073156764\n",
            "Loss in iteration no. 97082 ==> 0.484108555209272\n",
            "Loss in iteration no. 97083 ==> 0.48410755969604874\n",
            "Loss in iteration no. 97084 ==> 0.4841065641918976\n",
            "Loss in iteration no. 97085 ==> 0.4841055686968188\n",
            "Loss in iteration no. 97086 ==> 0.4841045732108118\n",
            "Loss in iteration no. 97087 ==> 0.4841035777338768\n",
            "Loss in iteration no. 97088 ==> 0.4841025822660136\n",
            "Loss in iteration no. 97089 ==> 0.484101586807222\n",
            "Loss in iteration no. 97090 ==> 0.48410059135750194\n",
            "Loss in iteration no. 97091 ==> 0.48409959591685314\n",
            "Loss in iteration no. 97092 ==> 0.4840986004852758\n",
            "Loss in iteration no. 97093 ==> 0.4840976050627697\n",
            "Loss in iteration no. 97094 ==> 0.4840966096493346\n",
            "Loss in iteration no. 97095 ==> 0.48409561424497044\n",
            "Loss in iteration no. 97096 ==> 0.48409461884967714\n",
            "Loss in iteration no. 97097 ==> 0.4840936234634545\n",
            "Loss in iteration no. 97098 ==> 0.48409262808630255\n",
            "Loss in iteration no. 97099 ==> 0.48409163271822103\n",
            "Loss in iteration no. 97100 ==> 0.48409063735920993\n",
            "Loss in iteration no. 97101 ==> 0.484089642009269\n",
            "Loss in iteration no. 97102 ==> 0.48408864666839824\n",
            "Loss in iteration no. 97103 ==> 0.4840876513365976\n",
            "Loss in iteration no. 97104 ==> 0.4840866560138668\n",
            "Loss in iteration no. 97105 ==> 0.48408566070020576\n",
            "Loss in iteration no. 97106 ==> 0.4840846653956145\n",
            "Loss in iteration no. 97107 ==> 0.4840836701000928\n",
            "Loss in iteration no. 97108 ==> 0.4840826748136405\n",
            "Loss in iteration no. 97109 ==> 0.48408167953625736\n",
            "Loss in iteration no. 97110 ==> 0.4840806842679436\n",
            "Loss in iteration no. 97111 ==> 0.48407968900869897\n",
            "Loss in iteration no. 97112 ==> 0.4840786937585233\n",
            "Loss in iteration no. 97113 ==> 0.48407769851741644\n",
            "Loss in iteration no. 97114 ==> 0.4840767032853784\n",
            "Loss in iteration no. 97115 ==> 0.484075708062409\n",
            "Loss in iteration no. 97116 ==> 0.484074712848508\n",
            "Loss in iteration no. 97117 ==> 0.4840737176436755\n",
            "Loss in iteration no. 97118 ==> 0.4840727224479112\n",
            "Loss in iteration no. 97119 ==> 0.4840717272612152\n",
            "Loss in iteration no. 97120 ==> 0.48407073208358714\n",
            "Loss in iteration no. 97121 ==> 0.48406973691502697\n",
            "Loss in iteration no. 97122 ==> 0.4840687417555348\n",
            "Loss in iteration no. 97123 ==> 0.4840677466051103\n",
            "Loss in iteration no. 97124 ==> 0.4840667514637533\n",
            "Loss in iteration no. 97125 ==> 0.48406575633146376\n",
            "Loss in iteration no. 97126 ==> 0.48406476120824166\n",
            "Loss in iteration no. 97127 ==> 0.48406376609408674\n",
            "Loss in iteration no. 97128 ==> 0.48406277098899897\n",
            "Loss in iteration no. 97129 ==> 0.4840617758929782\n",
            "Loss in iteration no. 97130 ==> 0.48406078080602427\n",
            "Loss in iteration no. 97131 ==> 0.4840597857281372\n",
            "Loss in iteration no. 97132 ==> 0.48405879065931684\n",
            "Loss in iteration no. 97133 ==> 0.4840577955995629\n",
            "Loss in iteration no. 97134 ==> 0.4840568005488754\n",
            "Loss in iteration no. 97135 ==> 0.48405580550725436\n",
            "Loss in iteration no. 97136 ==> 0.4840548104746995\n",
            "Loss in iteration no. 97137 ==> 0.4840538154512105\n",
            "Loss in iteration no. 97138 ==> 0.48405282043678755\n",
            "Loss in iteration no. 97139 ==> 0.4840518254314306\n",
            "Loss in iteration no. 97140 ==> 0.4840508304351393\n",
            "Loss in iteration no. 97141 ==> 0.48404983544791363\n",
            "Loss in iteration no. 97142 ==> 0.4840488404697534\n",
            "Loss in iteration no. 97143 ==> 0.4840478455006586\n",
            "Loss in iteration no. 97144 ==> 0.4840468505406291\n",
            "Loss in iteration no. 97145 ==> 0.4840458555896647\n",
            "Loss in iteration no. 97146 ==> 0.48404486064776536\n",
            "Loss in iteration no. 97147 ==> 0.4840438657149309\n",
            "Loss in iteration no. 97148 ==> 0.4840428707911613\n",
            "Loss in iteration no. 97149 ==> 0.4840418758764564\n",
            "Loss in iteration no. 97150 ==> 0.48404088097081616\n",
            "Loss in iteration no. 97151 ==> 0.48403988607424014\n",
            "Loss in iteration no. 97152 ==> 0.4840388911867287\n",
            "Loss in iteration no. 97153 ==> 0.4840378963082813\n",
            "Loss in iteration no. 97154 ==> 0.48403690143889805\n",
            "Loss in iteration no. 97155 ==> 0.484035906578579\n",
            "Loss in iteration no. 97156 ==> 0.4840349117273236\n",
            "Loss in iteration no. 97157 ==> 0.484033916885132\n",
            "Loss in iteration no. 97158 ==> 0.4840329220520041\n",
            "Loss in iteration no. 97159 ==> 0.4840319272279397\n",
            "Loss in iteration no. 97160 ==> 0.48403093241293876\n",
            "Loss in iteration no. 97161 ==> 0.48402993760700114\n",
            "Loss in iteration no. 97162 ==> 0.48402894281012654\n",
            "Loss in iteration no. 97163 ==> 0.48402794802231525\n",
            "Loss in iteration no. 97164 ==> 0.48402695324356665\n",
            "Loss in iteration no. 97165 ==> 0.48402595847388097\n",
            "Loss in iteration no. 97166 ==> 0.4840249637132581\n",
            "Loss in iteration no. 97167 ==> 0.4840239689616978\n",
            "Loss in iteration no. 97168 ==> 0.48402297421919993\n",
            "Loss in iteration no. 97169 ==> 0.48402197948576453\n",
            "Loss in iteration no. 97170 ==> 0.4840209847613913\n",
            "Loss in iteration no. 97171 ==> 0.4840199900460802\n",
            "Loss in iteration no. 97172 ==> 0.4840189953398313\n",
            "Loss in iteration no. 97173 ==> 0.4840180006426441\n",
            "Loss in iteration no. 97174 ==> 0.4840170059545188\n",
            "Loss in iteration no. 97175 ==> 0.4840160112754552\n",
            "Loss in iteration no. 97176 ==> 0.48401501660545304\n",
            "Loss in iteration no. 97177 ==> 0.48401402194451243\n",
            "Loss in iteration no. 97178 ==> 0.48401302729263307\n",
            "Loss in iteration no. 97179 ==> 0.48401203264981507\n",
            "Loss in iteration no. 97180 ==> 0.48401103801605805\n",
            "Loss in iteration no. 97181 ==> 0.48401004339136194\n",
            "Loss in iteration no. 97182 ==> 0.48400904877572676\n",
            "Loss in iteration no. 97183 ==> 0.4840080541691524\n",
            "Loss in iteration no. 97184 ==> 0.4840070595716386\n",
            "Loss in iteration no. 97185 ==> 0.48400606498318544\n",
            "Loss in iteration no. 97186 ==> 0.4840050704037925\n",
            "Loss in iteration no. 97187 ==> 0.48400407583346\n",
            "Loss in iteration no. 97188 ==> 0.4840030812721875\n",
            "Loss in iteration no. 97189 ==> 0.48400208671997524\n",
            "Loss in iteration no. 97190 ==> 0.4840010921768228\n",
            "Loss in iteration no. 97191 ==> 0.4840000976427302\n",
            "Loss in iteration no. 97192 ==> 0.4839991031176973\n",
            "Loss in iteration no. 97193 ==> 0.48399810860172404\n",
            "Loss in iteration no. 97194 ==> 0.4839971140948103\n",
            "Loss in iteration no. 97195 ==> 0.4839961195969558\n",
            "Loss in iteration no. 97196 ==> 0.48399512510816056\n",
            "Loss in iteration no. 97197 ==> 0.4839941306284245\n",
            "Loss in iteration no. 97198 ==> 0.48399313615774736\n",
            "Loss in iteration no. 97199 ==> 0.48399214169612936\n",
            "Loss in iteration no. 97200 ==> 0.4839911472435698\n",
            "Loss in iteration no. 97201 ==> 0.48399015280006913\n",
            "Loss in iteration no. 97202 ==> 0.483989158365627\n",
            "Loss in iteration no. 97203 ==> 0.4839881639402433\n",
            "Loss in iteration no. 97204 ==> 0.4839871695239179\n",
            "Loss in iteration no. 97205 ==> 0.48398617511665065\n",
            "Loss in iteration no. 97206 ==> 0.4839851807184416\n",
            "Loss in iteration no. 97207 ==> 0.48398418632929036\n",
            "Loss in iteration no. 97208 ==> 0.48398319194919714\n",
            "Loss in iteration no. 97209 ==> 0.4839821975781615\n",
            "Loss in iteration no. 97210 ==> 0.4839812032161835\n",
            "Loss in iteration no. 97211 ==> 0.4839802088632631\n",
            "Loss in iteration no. 97212 ==> 0.48397921451940007\n",
            "Loss in iteration no. 97213 ==> 0.48397822018459424\n",
            "Loss in iteration no. 97214 ==> 0.4839772258588456\n",
            "Loss in iteration no. 97215 ==> 0.48397623154215413\n",
            "Loss in iteration no. 97216 ==> 0.48397523723451946\n",
            "Loss in iteration no. 97217 ==> 0.4839742429359416\n",
            "Loss in iteration no. 97218 ==> 0.48397324864642044\n",
            "Loss in iteration no. 97219 ==> 0.4839722543659559\n",
            "Loss in iteration no. 97220 ==> 0.48397126009454783\n",
            "Loss in iteration no. 97221 ==> 0.483970265832196\n",
            "Loss in iteration no. 97222 ==> 0.4839692715789005\n",
            "Loss in iteration no. 97223 ==> 0.48396827733466125\n",
            "Loss in iteration no. 97224 ==> 0.48396728309947773\n",
            "Loss in iteration no. 97225 ==> 0.48396628887335025\n",
            "Loss in iteration no. 97226 ==> 0.4839652946562786\n",
            "Loss in iteration no. 97227 ==> 0.48396430044826244\n",
            "Loss in iteration no. 97228 ==> 0.48396330624930195\n",
            "Loss in iteration no. 97229 ==> 0.4839623120593968\n",
            "Loss in iteration no. 97230 ==> 0.48396131787854696\n",
            "Loss in iteration no. 97231 ==> 0.48396032370675235\n",
            "Loss in iteration no. 97232 ==> 0.4839593295440128\n",
            "Loss in iteration no. 97233 ==> 0.4839583353903282\n",
            "Loss in iteration no. 97234 ==> 0.4839573412456984\n",
            "Loss in iteration no. 97235 ==> 0.4839563471101235\n",
            "Loss in iteration no. 97236 ==> 0.483955352983603\n",
            "Loss in iteration no. 97237 ==> 0.4839543588661372\n",
            "Loss in iteration no. 97238 ==> 0.48395336475772555\n",
            "Loss in iteration no. 97239 ==> 0.4839523706583684\n",
            "Loss in iteration no. 97240 ==> 0.4839513765680652\n",
            "Loss in iteration no. 97241 ==> 0.48395038248681604\n",
            "Loss in iteration no. 97242 ==> 0.48394938841462093\n",
            "Loss in iteration no. 97243 ==> 0.4839483943514795\n",
            "Loss in iteration no. 97244 ==> 0.4839474002973919\n",
            "Loss in iteration no. 97245 ==> 0.48394640625235785\n",
            "Loss in iteration no. 97246 ==> 0.48394541221637716\n",
            "Loss in iteration no. 97247 ==> 0.48394441818944983\n",
            "Loss in iteration no. 97248 ==> 0.4839434241715757\n",
            "Loss in iteration no. 97249 ==> 0.48394243016275484\n",
            "Loss in iteration no. 97250 ==> 0.4839414361629867\n",
            "Loss in iteration no. 97251 ==> 0.48394044217227167\n",
            "Loss in iteration no. 97252 ==> 0.4839394481906093\n",
            "Loss in iteration no. 97253 ==> 0.4839384542179997\n",
            "Loss in iteration no. 97254 ==> 0.48393746025444245\n",
            "Loss in iteration no. 97255 ==> 0.48393646629993764\n",
            "Loss in iteration no. 97256 ==> 0.48393547235448514\n",
            "Loss in iteration no. 97257 ==> 0.4839344784180849\n",
            "Loss in iteration no. 97258 ==> 0.48393348449073675\n",
            "Loss in iteration no. 97259 ==> 0.4839324905724404\n",
            "Loss in iteration no. 97260 ==> 0.48393149666319596\n",
            "Loss in iteration no. 97261 ==> 0.4839305027630032\n",
            "Loss in iteration no. 97262 ==> 0.48392950887186215\n",
            "Loss in iteration no. 97263 ==> 0.4839285149897724\n",
            "Loss in iteration no. 97264 ==> 0.48392752111673415\n",
            "Loss in iteration no. 97265 ==> 0.4839265272527472\n",
            "Loss in iteration no. 97266 ==> 0.48392553339781136\n",
            "Loss in iteration no. 97267 ==> 0.4839245395519265\n",
            "Loss in iteration no. 97268 ==> 0.4839235457150925\n",
            "Loss in iteration no. 97269 ==> 0.48392255188730937\n",
            "Loss in iteration no. 97270 ==> 0.483921558068577\n",
            "Loss in iteration no. 97271 ==> 0.4839205642588951\n",
            "Loss in iteration no. 97272 ==> 0.48391957045826367\n",
            "Loss in iteration no. 97273 ==> 0.4839185766666825\n",
            "Loss in iteration no. 97274 ==> 0.4839175828841516\n",
            "Loss in iteration no. 97275 ==> 0.4839165891106708\n",
            "Loss in iteration no. 97276 ==> 0.4839155953462399\n",
            "Loss in iteration no. 97277 ==> 0.483914601590859\n",
            "Loss in iteration no. 97278 ==> 0.48391360784452775\n",
            "Loss in iteration no. 97279 ==> 0.4839126141072461\n",
            "Loss in iteration no. 97280 ==> 0.48391162037901414\n",
            "Loss in iteration no. 97281 ==> 0.48391062665983153\n",
            "Loss in iteration no. 97282 ==> 0.4839096329496982\n",
            "Loss in iteration no. 97283 ==> 0.483908639248614\n",
            "Loss in iteration no. 97284 ==> 0.4839076455565788\n",
            "Loss in iteration no. 97285 ==> 0.4839066518735927\n",
            "Loss in iteration no. 97286 ==> 0.48390565819965525\n",
            "Loss in iteration no. 97287 ==> 0.4839046645347666\n",
            "Loss in iteration no. 97288 ==> 0.4839036708789265\n",
            "Loss in iteration no. 97289 ==> 0.483902677232135\n",
            "Loss in iteration no. 97290 ==> 0.48390168359439184\n",
            "Loss in iteration no. 97291 ==> 0.48390068996569685\n",
            "Loss in iteration no. 97292 ==> 0.48389969634605007\n",
            "Loss in iteration no. 97293 ==> 0.4838987027354512\n",
            "Loss in iteration no. 97294 ==> 0.48389770913390034\n",
            "Loss in iteration no. 97295 ==> 0.48389671554139724\n",
            "Loss in iteration no. 97296 ==> 0.48389572195794184\n",
            "Loss in iteration no. 97297 ==> 0.4838947283835339\n",
            "Loss in iteration no. 97298 ==> 0.48389373481817344\n",
            "Loss in iteration no. 97299 ==> 0.4838927412618602\n",
            "Loss in iteration no. 97300 ==> 0.48389174771459437\n",
            "Loss in iteration no. 97301 ==> 0.48389075417637556\n",
            "Loss in iteration no. 97302 ==> 0.4838897606472036\n",
            "Loss in iteration no. 97303 ==> 0.4838887671270786\n",
            "Loss in iteration no. 97304 ==> 0.4838877736160004\n",
            "Loss in iteration no. 97305 ==> 0.48388678011396885\n",
            "Loss in iteration no. 97306 ==> 0.4838857866209837\n",
            "Loss in iteration no. 97307 ==> 0.48388479313704497\n",
            "Loss in iteration no. 97308 ==> 0.4838837996621526\n",
            "Loss in iteration no. 97309 ==> 0.48388280619630625\n",
            "Loss in iteration no. 97310 ==> 0.48388181273950603\n",
            "Loss in iteration no. 97311 ==> 0.4838808192917518\n",
            "Loss in iteration no. 97312 ==> 0.4838798258530434\n",
            "Loss in iteration no. 97313 ==> 0.48387883242338064\n",
            "Loss in iteration no. 97314 ==> 0.48387783900276343\n",
            "Loss in iteration no. 97315 ==> 0.4838768455911917\n",
            "Loss in iteration no. 97316 ==> 0.48387585218866547\n",
            "Loss in iteration no. 97317 ==> 0.4838748587951844\n",
            "Loss in iteration no. 97318 ==> 0.48387386541074845\n",
            "Loss in iteration no. 97319 ==> 0.4838728720353574\n",
            "Loss in iteration no. 97320 ==> 0.48387187866901143\n",
            "Loss in iteration no. 97321 ==> 0.48387088531171013\n",
            "Loss in iteration no. 97322 ==> 0.4838698919634536\n",
            "Loss in iteration no. 97323 ==> 0.48386889862424154\n",
            "Loss in iteration no. 97324 ==> 0.48386790529407386\n",
            "Loss in iteration no. 97325 ==> 0.4838669119729505\n",
            "Loss in iteration no. 97326 ==> 0.4838659186608715\n",
            "Loss in iteration no. 97327 ==> 0.48386492535783643\n",
            "Loss in iteration no. 97328 ==> 0.4838639320638454\n",
            "Loss in iteration no. 97329 ==> 0.48386293877889813\n",
            "Loss in iteration no. 97330 ==> 0.4838619455029948\n",
            "Loss in iteration no. 97331 ==> 0.4838609522361349\n",
            "Loss in iteration no. 97332 ==> 0.48385995897831857\n",
            "Loss in iteration no. 97333 ==> 0.4838589657295457\n",
            "Loss in iteration no. 97334 ==> 0.483857972489816\n",
            "Loss in iteration no. 97335 ==> 0.4838569792591295\n",
            "Loss in iteration no. 97336 ==> 0.4838559860374861\n",
            "Loss in iteration no. 97337 ==> 0.4838549928248856\n",
            "Loss in iteration no. 97338 ==> 0.4838539996213279\n",
            "Loss in iteration no. 97339 ==> 0.48385300642681284\n",
            "Loss in iteration no. 97340 ==> 0.4838520132413404\n",
            "Loss in iteration no. 97341 ==> 0.48385102006491043\n",
            "Loss in iteration no. 97342 ==> 0.48385002689752293\n",
            "Loss in iteration no. 97343 ==> 0.48384903373917754\n",
            "Loss in iteration no. 97344 ==> 0.4838480405898744\n",
            "Loss in iteration no. 97345 ==> 0.48384704744961304\n",
            "Loss in iteration no. 97346 ==> 0.4838460543183938\n",
            "Loss in iteration no. 97347 ==> 0.48384506119621606\n",
            "Loss in iteration no. 97348 ==> 0.4838440680830802\n",
            "Loss in iteration no. 97349 ==> 0.4838430749789859\n",
            "Loss in iteration no. 97350 ==> 0.48384208188393296\n",
            "Loss in iteration no. 97351 ==> 0.48384108879792137\n",
            "Loss in iteration no. 97352 ==> 0.48384009572095094\n",
            "Loss in iteration no. 97353 ==> 0.4838391026530216\n",
            "Loss in iteration no. 97354 ==> 0.4838381095941333\n",
            "Loss in iteration no. 97355 ==> 0.48383711654428574\n",
            "Loss in iteration no. 97356 ==> 0.48383612350347893\n",
            "Loss in iteration no. 97357 ==> 0.4838351304717128\n",
            "Loss in iteration no. 97358 ==> 0.4838341374489871\n",
            "Loss in iteration no. 97359 ==> 0.4838331444353018\n",
            "Loss in iteration no. 97360 ==> 0.4838321514306568\n",
            "Loss in iteration no. 97361 ==> 0.4838311584350519\n",
            "Loss in iteration no. 97362 ==> 0.48383016544848717\n",
            "Loss in iteration no. 97363 ==> 0.48382917247096235\n",
            "Loss in iteration no. 97364 ==> 0.48382817950247725\n",
            "Loss in iteration no. 97365 ==> 0.48382718654303186\n",
            "Loss in iteration no. 97366 ==> 0.4838261935926262\n",
            "Loss in iteration no. 97367 ==> 0.4838252006512599\n",
            "Loss in iteration no. 97368 ==> 0.4838242077189328\n",
            "Loss in iteration no. 97369 ==> 0.4838232147956451\n",
            "Loss in iteration no. 97370 ==> 0.4838222218813965\n",
            "Loss in iteration no. 97371 ==> 0.48382122897618685\n",
            "Loss in iteration no. 97372 ==> 0.4838202360800161\n",
            "Loss in iteration no. 97373 ==> 0.48381924319288416\n",
            "Loss in iteration no. 97374 ==> 0.48381825031479087\n",
            "Loss in iteration no. 97375 ==> 0.4838172574457362\n",
            "Loss in iteration no. 97376 ==> 0.48381626458571975\n",
            "Loss in iteration no. 97377 ==> 0.4838152717347417\n",
            "Loss in iteration no. 97378 ==> 0.483814278892802\n",
            "Loss in iteration no. 97379 ==> 0.48381328605990015\n",
            "Loss in iteration no. 97380 ==> 0.4838122932360364\n",
            "Loss in iteration no. 97381 ==> 0.4838113004212104\n",
            "Loss in iteration no. 97382 ==> 0.48381030761542226\n",
            "Loss in iteration no. 97383 ==> 0.4838093148186716\n",
            "Loss in iteration no. 97384 ==> 0.4838083220309585\n",
            "Loss in iteration no. 97385 ==> 0.48380732925228287\n",
            "Loss in iteration no. 97386 ==> 0.48380633648264443\n",
            "Loss in iteration no. 97387 ==> 0.4838053437220432\n",
            "Loss in iteration no. 97388 ==> 0.4838043509704789\n",
            "Loss in iteration no. 97389 ==> 0.4838033582279516\n",
            "Loss in iteration no. 97390 ==> 0.4838023654944611\n",
            "Loss in iteration no. 97391 ==> 0.4838013727700073\n",
            "Loss in iteration no. 97392 ==> 0.4838003800545901\n",
            "Loss in iteration no. 97393 ==> 0.48379938734820926\n",
            "Loss in iteration no. 97394 ==> 0.48379839465086494\n",
            "Loss in iteration no. 97395 ==> 0.4837974019625568\n",
            "Loss in iteration no. 97396 ==> 0.4837964092832846\n",
            "Loss in iteration no. 97397 ==> 0.4837954166130486\n",
            "Loss in iteration no. 97398 ==> 0.4837944239518484\n",
            "Loss in iteration no. 97399 ==> 0.48379343129968405\n",
            "Loss in iteration no. 97400 ==> 0.48379243865655525\n",
            "Loss in iteration no. 97401 ==> 0.483791446022462\n",
            "Loss in iteration no. 97402 ==> 0.48379045339740423\n",
            "Loss in iteration no. 97403 ==> 0.48378946078138163\n",
            "Loss in iteration no. 97404 ==> 0.48378846817439436\n",
            "Loss in iteration no. 97405 ==> 0.4837874755764422\n",
            "Loss in iteration no. 97406 ==> 0.4837864829875249\n",
            "Loss in iteration no. 97407 ==> 0.48378549040764257\n",
            "Loss in iteration no. 97408 ==> 0.4837844978367949\n",
            "Loss in iteration no. 97409 ==> 0.4837835052749818\n",
            "Loss in iteration no. 97410 ==> 0.4837825127222032\n",
            "Loss in iteration no. 97411 ==> 0.483781520178459\n",
            "Loss in iteration no. 97412 ==> 0.4837805276437491\n",
            "Loss in iteration no. 97413 ==> 0.4837795351180733\n",
            "Loss in iteration no. 97414 ==> 0.4837785426014317\n",
            "Loss in iteration no. 97415 ==> 0.4837775500938239\n",
            "Loss in iteration no. 97416 ==> 0.48377655759524996\n",
            "Loss in iteration no. 97417 ==> 0.4837755651057095\n",
            "Loss in iteration no. 97418 ==> 0.4837745726252028\n",
            "Loss in iteration no. 97419 ==> 0.4837735801537296\n",
            "Loss in iteration no. 97420 ==> 0.48377258769128967\n",
            "Loss in iteration no. 97421 ==> 0.483771595237883\n",
            "Loss in iteration no. 97422 ==> 0.4837706027935094\n",
            "Loss in iteration no. 97423 ==> 0.48376961035816884\n",
            "Loss in iteration no. 97424 ==> 0.48376861793186116\n",
            "Loss in iteration no. 97425 ==> 0.4837676255145863\n",
            "Loss in iteration no. 97426 ==> 0.483766633106344\n",
            "Loss in iteration no. 97427 ==> 0.4837656407071342\n",
            "Loss in iteration no. 97428 ==> 0.48376464831695704\n",
            "Loss in iteration no. 97429 ==> 0.48376365593581205\n",
            "Loss in iteration no. 97430 ==> 0.48376266356369924\n",
            "Loss in iteration no. 97431 ==> 0.48376167120061847\n",
            "Loss in iteration no. 97432 ==> 0.48376067884656965\n",
            "Loss in iteration no. 97433 ==> 0.4837596865015528\n",
            "Loss in iteration no. 97434 ==> 0.48375869416556766\n",
            "Loss in iteration no. 97435 ==> 0.4837577018386141\n",
            "Loss in iteration no. 97436 ==> 0.48375670952069194\n",
            "Loss in iteration no. 97437 ==> 0.4837557172118014\n",
            "Loss in iteration no. 97438 ==> 0.4837547249119419\n",
            "Loss in iteration no. 97439 ==> 0.4837537326211137\n",
            "Loss in iteration no. 97440 ==> 0.4837527403393165\n",
            "Loss in iteration no. 97441 ==> 0.4837517480665502\n",
            "Loss in iteration no. 97442 ==> 0.4837507558028147\n",
            "Loss in iteration no. 97443 ==> 0.4837497635481099\n",
            "Loss in iteration no. 97444 ==> 0.4837487713024357\n",
            "Loss in iteration no. 97445 ==> 0.48374777906579197\n",
            "Loss in iteration no. 97446 ==> 0.4837467868381785\n",
            "Loss in iteration no. 97447 ==> 0.4837457946195954\n",
            "Loss in iteration no. 97448 ==> 0.4837448024100423\n",
            "Loss in iteration no. 97449 ==> 0.4837438102095193\n",
            "Loss in iteration no. 97450 ==> 0.4837428180180261\n",
            "Loss in iteration no. 97451 ==> 0.48374182583556274\n",
            "Loss in iteration no. 97452 ==> 0.4837408336621289\n",
            "Loss in iteration no. 97453 ==> 0.4837398414977247\n",
            "Loss in iteration no. 97454 ==> 0.4837388493423499\n",
            "Loss in iteration no. 97455 ==> 0.48373785719600443\n",
            "Loss in iteration no. 97456 ==> 0.4837368650586882\n",
            "Loss in iteration no. 97457 ==> 0.48373587293040093\n",
            "Loss in iteration no. 97458 ==> 0.4837348808111427\n",
            "Loss in iteration no. 97459 ==> 0.4837338887009134\n",
            "Loss in iteration no. 97460 ==> 0.48373289659971264\n",
            "Loss in iteration no. 97461 ==> 0.4837319045075406\n",
            "Loss in iteration no. 97462 ==> 0.4837309124243971\n",
            "Loss in iteration no. 97463 ==> 0.4837299203502819\n",
            "Loss in iteration no. 97464 ==> 0.48372892828519504\n",
            "Loss in iteration no. 97465 ==> 0.48372793622913624\n",
            "Loss in iteration no. 97466 ==> 0.48372694418210566\n",
            "Loss in iteration no. 97467 ==> 0.4837259521441029\n",
            "Loss in iteration no. 97468 ==> 0.48372496011512794\n",
            "Loss in iteration no. 97469 ==> 0.48372396809518065\n",
            "Loss in iteration no. 97470 ==> 0.483722976084261\n",
            "Loss in iteration no. 97471 ==> 0.4837219840823688\n",
            "Loss in iteration no. 97472 ==> 0.4837209920895039\n",
            "Loss in iteration no. 97473 ==> 0.48372000010566635\n",
            "Loss in iteration no. 97474 ==> 0.4837190081308558\n",
            "Loss in iteration no. 97475 ==> 0.4837180161650722\n",
            "Loss in iteration no. 97476 ==> 0.4837170242083156\n",
            "Loss in iteration no. 97477 ==> 0.4837160322605856\n",
            "Loss in iteration no. 97478 ==> 0.48371504032188256\n",
            "Loss in iteration no. 97479 ==> 0.48371404839220583\n",
            "Loss in iteration no. 97480 ==> 0.4837130564715556\n",
            "Loss in iteration no. 97481 ==> 0.4837120645599316\n",
            "Loss in iteration no. 97482 ==> 0.48371107265733404\n",
            "Loss in iteration no. 97483 ==> 0.48371008076376226\n",
            "Loss in iteration no. 97484 ==> 0.4837090888792166\n",
            "Loss in iteration no. 97485 ==> 0.4837080970036968\n",
            "Loss in iteration no. 97486 ==> 0.48370710513720266\n",
            "Loss in iteration no. 97487 ==> 0.4837061132797341\n",
            "Loss in iteration no. 97488 ==> 0.4837051214312913\n",
            "Loss in iteration no. 97489 ==> 0.4837041295918737\n",
            "Loss in iteration no. 97490 ==> 0.48370313776148144\n",
            "Loss in iteration no. 97491 ==> 0.48370214594011424\n",
            "Loss in iteration no. 97492 ==> 0.48370115412777215\n",
            "Loss in iteration no. 97493 ==> 0.483700162324455\n",
            "Loss in iteration no. 97494 ==> 0.48369917053016265\n",
            "Loss in iteration no. 97495 ==> 0.4836981787448949\n",
            "Loss in iteration no. 97496 ==> 0.48369718696865177\n",
            "Loss in iteration no. 97497 ==> 0.4836961952014332\n",
            "Loss in iteration no. 97498 ==> 0.4836952034432389\n",
            "Loss in iteration no. 97499 ==> 0.48369421169406884\n",
            "Loss in iteration no. 97500 ==> 0.48369321995392295\n",
            "Loss in iteration no. 97501 ==> 0.48369222822280106\n",
            "Loss in iteration no. 97502 ==> 0.48369123650070317\n",
            "Loss in iteration no. 97503 ==> 0.4836902447876288\n",
            "Loss in iteration no. 97504 ==> 0.48368925308357824\n",
            "Loss in iteration no. 97505 ==> 0.4836882613885512\n",
            "Loss in iteration no. 97506 ==> 0.4836872697025476\n",
            "Loss in iteration no. 97507 ==> 0.48368627802556724\n",
            "Loss in iteration no. 97508 ==> 0.4836852863576101\n",
            "Loss in iteration no. 97509 ==> 0.4836842946986762\n",
            "Loss in iteration no. 97510 ==> 0.48368330304876517\n",
            "Loss in iteration no. 97511 ==> 0.483682311407877\n",
            "Loss in iteration no. 97512 ==> 0.4836813197760115\n",
            "Loss in iteration no. 97513 ==> 0.4836803281531687\n",
            "Loss in iteration no. 97514 ==> 0.48367933653934836\n",
            "Loss in iteration no. 97515 ==> 0.4836783449345505\n",
            "Loss in iteration no. 97516 ==> 0.4836773533387749\n",
            "Loss in iteration no. 97517 ==> 0.48367636175202133\n",
            "Loss in iteration no. 97518 ==> 0.4836753701742899\n",
            "Loss in iteration no. 97519 ==> 0.48367437860558044\n",
            "Loss in iteration no. 97520 ==> 0.48367338704589274\n",
            "Loss in iteration no. 97521 ==> 0.4836723954952267\n",
            "Loss in iteration no. 97522 ==> 0.4836714039535824\n",
            "Loss in iteration no. 97523 ==> 0.4836704124209594\n",
            "Loss in iteration no. 97524 ==> 0.48366942089735787\n",
            "Loss in iteration no. 97525 ==> 0.4836684293827774\n",
            "Loss in iteration no. 97526 ==> 0.4836674378772184\n",
            "Loss in iteration no. 97527 ==> 0.4836664463806801\n",
            "Loss in iteration no. 97528 ==> 0.48366545489316276\n",
            "Loss in iteration no. 97529 ==> 0.4836644634146663\n",
            "Loss in iteration no. 97530 ==> 0.4836634719451903\n",
            "Loss in iteration no. 97531 ==> 0.48366248048473515\n",
            "Loss in iteration no. 97532 ==> 0.48366148903330014\n",
            "Loss in iteration no. 97533 ==> 0.48366049759088564\n",
            "Loss in iteration no. 97534 ==> 0.48365950615749137\n",
            "Loss in iteration no. 97535 ==> 0.48365851473311716\n",
            "Loss in iteration no. 97536 ==> 0.4836575233177628\n",
            "Loss in iteration no. 97537 ==> 0.48365653191142843\n",
            "Loss in iteration no. 97538 ==> 0.48365554051411375\n",
            "Loss in iteration no. 97539 ==> 0.4836545491258187\n",
            "Loss in iteration no. 97540 ==> 0.4836535577465431\n",
            "Loss in iteration no. 97541 ==> 0.48365256637628695\n",
            "Loss in iteration no. 97542 ==> 0.4836515750150502\n",
            "Loss in iteration no. 97543 ==> 0.4836505836628325\n",
            "Loss in iteration no. 97544 ==> 0.4836495923196339\n",
            "Loss in iteration no. 97545 ==> 0.48364860098545415\n",
            "Loss in iteration no. 97546 ==> 0.4836476096602932\n",
            "Loss in iteration no. 97547 ==> 0.48364661834415107\n",
            "Loss in iteration no. 97548 ==> 0.48364562703702757\n",
            "Loss in iteration no. 97549 ==> 0.4836446357389223\n",
            "Loss in iteration no. 97550 ==> 0.48364364444983565\n",
            "Loss in iteration no. 97551 ==> 0.4836426531697672\n",
            "Loss in iteration no. 97552 ==> 0.4836416618987168\n",
            "Loss in iteration no. 97553 ==> 0.48364067063668453\n",
            "Loss in iteration no. 97554 ==> 0.4836396793836701\n",
            "Loss in iteration no. 97555 ==> 0.48363868813967326\n",
            "Loss in iteration no. 97556 ==> 0.48363769690469427\n",
            "Loss in iteration no. 97557 ==> 0.48363670567873296\n",
            "Loss in iteration no. 97558 ==> 0.4836357144617889\n",
            "Loss in iteration no. 97559 ==> 0.4836347232538623\n",
            "Loss in iteration no. 97560 ==> 0.48363373205495286\n",
            "Loss in iteration no. 97561 ==> 0.48363274086506036\n",
            "Loss in iteration no. 97562 ==> 0.48363174968418515\n",
            "Loss in iteration no. 97563 ==> 0.48363075851232656\n",
            "Loss in iteration no. 97564 ==> 0.48362976734948493\n",
            "Loss in iteration no. 97565 ==> 0.48362877619565964\n",
            "Loss in iteration no. 97566 ==> 0.4836277850508511\n",
            "Loss in iteration no. 97567 ==> 0.48362679391505886\n",
            "Loss in iteration no. 97568 ==> 0.483625802788283\n",
            "Loss in iteration no. 97569 ==> 0.4836248116705232\n",
            "Loss in iteration no. 97570 ==> 0.4836238205617795\n",
            "Loss in iteration no. 97571 ==> 0.4836228294620518\n",
            "Loss in iteration no. 97572 ==> 0.48362183837134004\n",
            "Loss in iteration no. 97573 ==> 0.4836208472896438\n",
            "Loss in iteration no. 97574 ==> 0.48361985621696313\n",
            "Loss in iteration no. 97575 ==> 0.483618865153298\n",
            "Loss in iteration no. 97576 ==> 0.48361787409864837\n",
            "Loss in iteration no. 97577 ==> 0.4836168830530138\n",
            "Loss in iteration no. 97578 ==> 0.48361589201639454\n",
            "Loss in iteration no. 97579 ==> 0.4836149009887903\n",
            "Loss in iteration no. 97580 ==> 0.48361390997020076\n",
            "Loss in iteration no. 97581 ==> 0.4836129189606262\n",
            "Loss in iteration no. 97582 ==> 0.4836119279600662\n",
            "Loss in iteration no. 97583 ==> 0.48361093696852087\n",
            "Loss in iteration no. 97584 ==> 0.4836099459859899\n",
            "Loss in iteration no. 97585 ==> 0.4836089550124734\n",
            "Loss in iteration no. 97586 ==> 0.48360796404797096\n",
            "Loss in iteration no. 97587 ==> 0.4836069730924827\n",
            "Loss in iteration no. 97588 ==> 0.48360598214600836\n",
            "Loss in iteration no. 97589 ==> 0.483604991208548\n",
            "Loss in iteration no. 97590 ==> 0.48360400028010125\n",
            "Loss in iteration no. 97591 ==> 0.4836030093606684\n",
            "Loss in iteration no. 97592 ==> 0.48360201845024875\n",
            "Loss in iteration no. 97593 ==> 0.48360102754884277\n",
            "Loss in iteration no. 97594 ==> 0.48360003665644996\n",
            "Loss in iteration no. 97595 ==> 0.4835990457730703\n",
            "Loss in iteration no. 97596 ==> 0.48359805489870394\n",
            "Loss in iteration no. 97597 ==> 0.48359706403335034\n",
            "Loss in iteration no. 97598 ==> 0.4835960731770096\n",
            "Loss in iteration no. 97599 ==> 0.48359508232968146\n",
            "Loss in iteration no. 97600 ==> 0.48359409149136623\n",
            "Loss in iteration no. 97601 ==> 0.48359310066206324\n",
            "Loss in iteration no. 97602 ==> 0.48359210984177275\n",
            "Loss in iteration no. 97603 ==> 0.4835911190304945\n",
            "Loss in iteration no. 97604 ==> 0.4835901282282283\n",
            "Loss in iteration no. 97605 ==> 0.4835891374349743\n",
            "Loss in iteration no. 97606 ==> 0.483588146650732\n",
            "Loss in iteration no. 97607 ==> 0.48358715587550166\n",
            "Loss in iteration no. 97608 ==> 0.4835861651092831\n",
            "Loss in iteration no. 97609 ==> 0.483585174352076\n",
            "Loss in iteration no. 97610 ==> 0.4835841836038803\n",
            "Loss in iteration no. 97611 ==> 0.4835831928646959\n",
            "Loss in iteration no. 97612 ==> 0.4835822021345229\n",
            "Loss in iteration no. 97613 ==> 0.483581211413361\n",
            "Loss in iteration no. 97614 ==> 0.48358022070120993\n",
            "Loss in iteration no. 97615 ==> 0.4835792299980698\n",
            "Loss in iteration no. 97616 ==> 0.48357823930394056\n",
            "Loss in iteration no. 97617 ==> 0.48357724861882184\n",
            "Loss in iteration no. 97618 ==> 0.4835762579427137\n",
            "Loss in iteration no. 97619 ==> 0.483575267275616\n",
            "Loss in iteration no. 97620 ==> 0.4835742766175285\n",
            "Loss in iteration no. 97621 ==> 0.4835732859684514\n",
            "Loss in iteration no. 97622 ==> 0.4835722953283842\n",
            "Loss in iteration no. 97623 ==> 0.48357130469732695\n",
            "Loss in iteration no. 97624 ==> 0.48357031407527973\n",
            "Loss in iteration no. 97625 ==> 0.4835693234622421\n",
            "Loss in iteration no. 97626 ==> 0.4835683328582141\n",
            "Loss in iteration no. 97627 ==> 0.48356734226319564\n",
            "Loss in iteration no. 97628 ==> 0.4835663516771865\n",
            "Loss in iteration no. 97629 ==> 0.4835653611001868\n",
            "Loss in iteration no. 97630 ==> 0.4835643705321961\n",
            "Loss in iteration no. 97631 ==> 0.4835633799732144\n",
            "Loss in iteration no. 97632 ==> 0.48356238942324176\n",
            "Loss in iteration no. 97633 ==> 0.48356139888227795\n",
            "Loss in iteration no. 97634 ==> 0.4835604083503227\n",
            "Loss in iteration no. 97635 ==> 0.48355941782737605\n",
            "Loss in iteration no. 97636 ==> 0.483558427313438\n",
            "Loss in iteration no. 97637 ==> 0.48355743680850827\n",
            "Loss in iteration no. 97638 ==> 0.48355644631258665\n",
            "Loss in iteration no. 97639 ==> 0.4835554558256733\n",
            "Loss in iteration no. 97640 ==> 0.48355446534776797\n",
            "Loss in iteration no. 97641 ==> 0.48355347487887035\n",
            "Loss in iteration no. 97642 ==> 0.48355248441898063\n",
            "Loss in iteration no. 97643 ==> 0.48355149396809854\n",
            "Loss in iteration no. 97644 ==> 0.483550503526224\n",
            "Loss in iteration no. 97645 ==> 0.4835495130933569\n",
            "Loss in iteration no. 97646 ==> 0.48354852266949716\n",
            "Loss in iteration no. 97647 ==> 0.48354753225464453\n",
            "Loss in iteration no. 97648 ==> 0.48354654184879914\n",
            "Loss in iteration no. 97649 ==> 0.4835455514519605\n",
            "Loss in iteration no. 97650 ==> 0.4835445610641289\n",
            "Loss in iteration no. 97651 ==> 0.4835435706853039\n",
            "Loss in iteration no. 97652 ==> 0.48354258031548575\n",
            "Loss in iteration no. 97653 ==> 0.4835415899546739\n",
            "Loss in iteration no. 97654 ==> 0.48354059960286855\n",
            "Loss in iteration no. 97655 ==> 0.4835396092600695\n",
            "Loss in iteration no. 97656 ==> 0.4835386189262766\n",
            "Loss in iteration no. 97657 ==> 0.48353762860148963\n",
            "Loss in iteration no. 97658 ==> 0.48353663828570875\n",
            "Loss in iteration no. 97659 ==> 0.4835356479789336\n",
            "Loss in iteration no. 97660 ==> 0.48353465768116427\n",
            "Loss in iteration no. 97661 ==> 0.4835336673924005\n",
            "Loss in iteration no. 97662 ==> 0.48353267711264214\n",
            "Loss in iteration no. 97663 ==> 0.4835316868418892\n",
            "Loss in iteration no. 97664 ==> 0.4835306965801414\n",
            "Loss in iteration no. 97665 ==> 0.48352970632739894\n",
            "Loss in iteration no. 97666 ==> 0.48352871608366144\n",
            "Loss in iteration no. 97667 ==> 0.4835277258489287\n",
            "Loss in iteration no. 97668 ==> 0.4835267356232008\n",
            "Loss in iteration no. 97669 ==> 0.4835257454064775\n",
            "Loss in iteration no. 97670 ==> 0.483524755198759\n",
            "Loss in iteration no. 97671 ==> 0.4835237650000448\n",
            "Loss in iteration no. 97672 ==> 0.48352277481033495\n",
            "Loss in iteration no. 97673 ==> 0.4835217846296293\n",
            "Loss in iteration no. 97674 ==> 0.4835207944579278\n",
            "Loss in iteration no. 97675 ==> 0.4835198042952303\n",
            "Loss in iteration no. 97676 ==> 0.4835188141415365\n",
            "Loss in iteration no. 97677 ==> 0.4835178239968466\n",
            "Loss in iteration no. 97678 ==> 0.48351683386116034\n",
            "Loss in iteration no. 97679 ==> 0.4835158437344776\n",
            "Loss in iteration no. 97680 ==> 0.48351485361679825\n",
            "Loss in iteration no. 97681 ==> 0.48351386350812225\n",
            "Loss in iteration no. 97682 ==> 0.4835128734084493\n",
            "Loss in iteration no. 97683 ==> 0.4835118833177794\n",
            "Loss in iteration no. 97684 ==> 0.48351089323611257\n",
            "Loss in iteration no. 97685 ==> 0.48350990316344866\n",
            "Loss in iteration no. 97686 ==> 0.4835089130997872\n",
            "Loss in iteration no. 97687 ==> 0.4835079230451286\n",
            "Loss in iteration no. 97688 ==> 0.4835069329994724\n",
            "Loss in iteration no. 97689 ==> 0.4835059429628185\n",
            "Loss in iteration no. 97690 ==> 0.483504952935167\n",
            "Loss in iteration no. 97691 ==> 0.48350396291651765\n",
            "Loss in iteration no. 97692 ==> 0.4835029729068703\n",
            "Loss in iteration no. 97693 ==> 0.48350198290622476\n",
            "Loss in iteration no. 97694 ==> 0.4835009929145812\n",
            "Loss in iteration no. 97695 ==> 0.48350000293193923\n",
            "Loss in iteration no. 97696 ==> 0.4834990129582988\n",
            "Loss in iteration no. 97697 ==> 0.48349802299365985\n",
            "Loss in iteration no. 97698 ==> 0.4834970330380221\n",
            "Loss in iteration no. 97699 ==> 0.48349604309138594\n",
            "Loss in iteration no. 97700 ==> 0.48349505315375063\n",
            "Loss in iteration no. 97701 ==> 0.4834940632251163\n",
            "Loss in iteration no. 97702 ==> 0.4834930733054829\n",
            "Loss in iteration no. 97703 ==> 0.4834920833948504\n",
            "Loss in iteration no. 97704 ==> 0.48349109349321834\n",
            "Loss in iteration no. 97705 ==> 0.48349010360058703\n",
            "Loss in iteration no. 97706 ==> 0.483489113716956\n",
            "Loss in iteration no. 97707 ==> 0.48348812384232526\n",
            "Loss in iteration no. 97708 ==> 0.48348713397669485\n",
            "Loss in iteration no. 97709 ==> 0.4834861441200644\n",
            "Loss in iteration no. 97710 ==> 0.48348515427243394\n",
            "Loss in iteration no. 97711 ==> 0.48348416443380343\n",
            "Loss in iteration no. 97712 ==> 0.48348317460417256\n",
            "Loss in iteration no. 97713 ==> 0.4834821847835414\n",
            "Loss in iteration no. 97714 ==> 0.48348119497190967\n",
            "Loss in iteration no. 97715 ==> 0.48348020516927726\n",
            "Loss in iteration no. 97716 ==> 0.4834792153756442\n",
            "Loss in iteration no. 97717 ==> 0.4834782255910103\n",
            "Loss in iteration no. 97718 ==> 0.4834772358153755\n",
            "Loss in iteration no. 97719 ==> 0.48347624604873957\n",
            "Loss in iteration no. 97720 ==> 0.4834752562911025\n",
            "Loss in iteration no. 97721 ==> 0.4834742665424641\n",
            "Loss in iteration no. 97722 ==> 0.4834732768028243\n",
            "Loss in iteration no. 97723 ==> 0.48347228707218287\n",
            "Loss in iteration no. 97724 ==> 0.48347129735053995\n",
            "Loss in iteration no. 97725 ==> 0.4834703076378952\n",
            "Loss in iteration no. 97726 ==> 0.48346931793424863\n",
            "Loss in iteration no. 97727 ==> 0.4834683282396\n",
            "Loss in iteration no. 97728 ==> 0.4834673385539493\n",
            "Loss in iteration no. 97729 ==> 0.4834663488772964\n",
            "Loss in iteration no. 97730 ==> 0.48346535920964107\n",
            "Loss in iteration no. 97731 ==> 0.48346436955098343\n",
            "Loss in iteration no. 97732 ==> 0.4834633799013232\n",
            "Loss in iteration no. 97733 ==> 0.48346239026066024\n",
            "Loss in iteration no. 97734 ==> 0.48346140062899456\n",
            "Loss in iteration no. 97735 ==> 0.48346041100632603\n",
            "Loss in iteration no. 97736 ==> 0.4834594213926543\n",
            "Loss in iteration no. 97737 ==> 0.48345843178797954\n",
            "Loss in iteration no. 97738 ==> 0.4834574421923015\n",
            "Loss in iteration no. 97739 ==> 0.48345645260562015\n",
            "Loss in iteration no. 97740 ==> 0.48345546302793535\n",
            "Loss in iteration no. 97741 ==> 0.4834544734592469\n",
            "Loss in iteration no. 97742 ==> 0.4834534838995547\n",
            "Loss in iteration no. 97743 ==> 0.4834524943488588\n",
            "Loss in iteration no. 97744 ==> 0.48345150480715876\n",
            "Loss in iteration no. 97745 ==> 0.48345051527445476\n",
            "Loss in iteration no. 97746 ==> 0.48344952575074673\n",
            "Loss in iteration no. 97747 ==> 0.4834485362360343\n",
            "Loss in iteration no. 97748 ==> 0.4834475467303174\n",
            "Loss in iteration no. 97749 ==> 0.48344655723359614\n",
            "Loss in iteration no. 97750 ==> 0.48344556774587016\n",
            "Loss in iteration no. 97751 ==> 0.48344457826713944\n",
            "Loss in iteration no. 97752 ==> 0.4834435887974039\n",
            "Loss in iteration no. 97753 ==> 0.4834425993366634\n",
            "Loss in iteration no. 97754 ==> 0.48344160988491774\n",
            "Loss in iteration no. 97755 ==> 0.48344062044216707\n",
            "Loss in iteration no. 97756 ==> 0.4834396310084108\n",
            "Loss in iteration no. 97757 ==> 0.4834386415836493\n",
            "Loss in iteration no. 97758 ==> 0.48343765216788226\n",
            "Loss in iteration no. 97759 ==> 0.4834366627611094\n",
            "Loss in iteration no. 97760 ==> 0.48343567336333093\n",
            "Loss in iteration no. 97761 ==> 0.48343468397454653\n",
            "Loss in iteration no. 97762 ==> 0.4834336945947561\n",
            "Loss in iteration no. 97763 ==> 0.48343270522395954\n",
            "Loss in iteration no. 97764 ==> 0.4834317158621567\n",
            "Loss in iteration no. 97765 ==> 0.4834307265093476\n",
            "Loss in iteration no. 97766 ==> 0.4834297371655321\n",
            "Loss in iteration no. 97767 ==> 0.4834287478307099\n",
            "Loss in iteration no. 97768 ==> 0.483427758504881\n",
            "Loss in iteration no. 97769 ==> 0.4834267691880455\n",
            "Loss in iteration no. 97770 ==> 0.48342577988020285\n",
            "Loss in iteration no. 97771 ==> 0.4834247905813533\n",
            "Loss in iteration no. 97772 ==> 0.48342380129149637\n",
            "Loss in iteration no. 97773 ==> 0.48342281201063253\n",
            "Loss in iteration no. 97774 ==> 0.4834218227387611\n",
            "Loss in iteration no. 97775 ==> 0.4834208334758823\n",
            "Loss in iteration no. 97776 ==> 0.4834198442219957\n",
            "Loss in iteration no. 97777 ==> 0.4834188549771014\n",
            "Loss in iteration no. 97778 ==> 0.48341786574119944\n",
            "Loss in iteration no. 97779 ==> 0.4834168765142894\n",
            "Loss in iteration no. 97780 ==> 0.48341588729637136\n",
            "Loss in iteration no. 97781 ==> 0.4834148980874451\n",
            "Loss in iteration no. 97782 ==> 0.48341390888751057\n",
            "Loss in iteration no. 97783 ==> 0.4834129196965675\n",
            "Loss in iteration no. 97784 ==> 0.48341193051461606\n",
            "Loss in iteration no. 97785 ==> 0.48341094134165585\n",
            "Loss in iteration no. 97786 ==> 0.4834099521776869\n",
            "Loss in iteration no. 97787 ==> 0.4834089630227093\n",
            "Loss in iteration no. 97788 ==> 0.48340797387672246\n",
            "Loss in iteration no. 97789 ==> 0.4834069847397267\n",
            "Loss in iteration no. 97790 ==> 0.4834059956117216\n",
            "Loss in iteration no. 97791 ==> 0.4834050064927072\n",
            "Loss in iteration no. 97792 ==> 0.4834040173826833\n",
            "Loss in iteration no. 97793 ==> 0.48340302828164994\n",
            "Loss in iteration no. 97794 ==> 0.48340203918960684\n",
            "Loss in iteration no. 97795 ==> 0.48340105010655404\n",
            "Loss in iteration no. 97796 ==> 0.48340006103249133\n",
            "Loss in iteration no. 97797 ==> 0.4833990719674185\n",
            "Loss in iteration no. 97798 ==> 0.4833980829113356\n",
            "Loss in iteration no. 97799 ==> 0.4833970938642425\n",
            "Loss in iteration no. 97800 ==> 0.4833961048261389\n",
            "Loss in iteration no. 97801 ==> 0.48339511579702504\n",
            "Loss in iteration no. 97802 ==> 0.48339412677690036\n",
            "Loss in iteration no. 97803 ==> 0.48339313776576504\n",
            "Loss in iteration no. 97804 ==> 0.483392148763619\n",
            "Loss in iteration no. 97805 ==> 0.48339115977046193\n",
            "Loss in iteration no. 97806 ==> 0.48339017078629387\n",
            "Loss in iteration no. 97807 ==> 0.4833891818111147\n",
            "Loss in iteration no. 97808 ==> 0.4833881928449242\n",
            "Loss in iteration no. 97809 ==> 0.4833872038877222\n",
            "Loss in iteration no. 97810 ==> 0.48338621493950884\n",
            "Loss in iteration no. 97811 ==> 0.4833852260002837\n",
            "Loss in iteration no. 97812 ==> 0.483384237070047\n",
            "Loss in iteration no. 97813 ==> 0.4833832481487983\n",
            "Loss in iteration no. 97814 ==> 0.48338225923653766\n",
            "Loss in iteration no. 97815 ==> 0.48338127033326506\n",
            "Loss in iteration no. 97816 ==> 0.48338028143898015\n",
            "Loss in iteration no. 97817 ==> 0.48337929255368306\n",
            "Loss in iteration no. 97818 ==> 0.4833783036773734\n",
            "Loss in iteration no. 97819 ==> 0.4833773148100512\n",
            "Loss in iteration no. 97820 ==> 0.4833763259517164\n",
            "Loss in iteration no. 97821 ==> 0.48337533710236885\n",
            "Loss in iteration no. 97822 ==> 0.4833743482620085\n",
            "Loss in iteration no. 97823 ==> 0.48337335943063503\n",
            "Loss in iteration no. 97824 ==> 0.48337237060824845\n",
            "Loss in iteration no. 97825 ==> 0.48337138179484873\n",
            "Loss in iteration no. 97826 ==> 0.48337039299043555\n",
            "Loss in iteration no. 97827 ==> 0.4833694041950089\n",
            "Loss in iteration no. 97828 ==> 0.4833684154085688\n",
            "Loss in iteration no. 97829 ==> 0.48336742663111504\n",
            "Loss in iteration no. 97830 ==> 0.4833664378626473\n",
            "Loss in iteration no. 97831 ==> 0.48336544910316576\n",
            "Loss in iteration no. 97832 ==> 0.4833644603526702\n",
            "Loss in iteration no. 97833 ==> 0.4833634716111606\n",
            "Loss in iteration no. 97834 ==> 0.4833624828786366\n",
            "Loss in iteration no. 97835 ==> 0.48336149415509827\n",
            "Loss in iteration no. 97836 ==> 0.4833605054405453\n",
            "Loss in iteration no. 97837 ==> 0.483359516734978\n",
            "Loss in iteration no. 97838 ==> 0.48335852803839585\n",
            "Loss in iteration no. 97839 ==> 0.4833575393507989\n",
            "Loss in iteration no. 97840 ==> 0.4833565506721869\n",
            "Loss in iteration no. 97841 ==> 0.4833555620025599\n",
            "Loss in iteration no. 97842 ==> 0.4833545733419177\n",
            "Loss in iteration no. 97843 ==> 0.48335358469026035\n",
            "Loss in iteration no. 97844 ==> 0.48335259604758746\n",
            "Loss in iteration no. 97845 ==> 0.48335160741389904\n",
            "Loss in iteration no. 97846 ==> 0.4833506187891951\n",
            "Loss in iteration no. 97847 ==> 0.4833496301734753\n",
            "Loss in iteration no. 97848 ==> 0.4833486415667397\n",
            "Loss in iteration no. 97849 ==> 0.4833476529689882\n",
            "Loss in iteration no. 97850 ==> 0.48334666438022045\n",
            "Loss in iteration no. 97851 ==> 0.48334567580043664\n",
            "Loss in iteration no. 97852 ==> 0.48334468722963636\n",
            "Loss in iteration no. 97853 ==> 0.48334369866781973\n",
            "Loss in iteration no. 97854 ==> 0.48334271011498664\n",
            "Loss in iteration no. 97855 ==> 0.4833417215711368\n",
            "Loss in iteration no. 97856 ==> 0.4833407330362701\n",
            "Loss in iteration no. 97857 ==> 0.4833397445103866\n",
            "Loss in iteration no. 97858 ==> 0.4833387559934861\n",
            "Loss in iteration no. 97859 ==> 0.4833377674855685\n",
            "Loss in iteration no. 97860 ==> 0.48333677898663363\n",
            "Loss in iteration no. 97861 ==> 0.48333579049668135\n",
            "Loss in iteration no. 97862 ==> 0.48333480201571166\n",
            "Loss in iteration no. 97863 ==> 0.48333381354372434\n",
            "Loss in iteration no. 97864 ==> 0.48333282508071945\n",
            "Loss in iteration no. 97865 ==> 0.48333183662669654\n",
            "Loss in iteration no. 97866 ==> 0.48333084818165595\n",
            "Loss in iteration no. 97867 ==> 0.4833298597455972\n",
            "Loss in iteration no. 97868 ==> 0.48332887131852026\n",
            "Loss in iteration no. 97869 ==> 0.4833278829004251\n",
            "Loss in iteration no. 97870 ==> 0.4833268944913117\n",
            "Loss in iteration no. 97871 ==> 0.48332590609117954\n",
            "Loss in iteration no. 97872 ==> 0.4833249177000289\n",
            "Loss in iteration no. 97873 ==> 0.48332392931785967\n",
            "Loss in iteration no. 97874 ==> 0.48332294094467143\n",
            "Loss in iteration no. 97875 ==> 0.4833219525804641\n",
            "Loss in iteration no. 97876 ==> 0.48332096422523796\n",
            "Loss in iteration no. 97877 ==> 0.48331997587899256\n",
            "Loss in iteration no. 97878 ==> 0.4833189875417279\n",
            "Loss in iteration no. 97879 ==> 0.4833179992134438\n",
            "Loss in iteration no. 97880 ==> 0.4833170108941401\n",
            "Loss in iteration no. 97881 ==> 0.48331602258381684\n",
            "Loss in iteration no. 97882 ==> 0.4833150342824738\n",
            "Loss in iteration no. 97883 ==> 0.4833140459901109\n",
            "Loss in iteration no. 97884 ==> 0.483313057706728\n",
            "Loss in iteration no. 97885 ==> 0.483312069432325\n",
            "Loss in iteration no. 97886 ==> 0.4833110811669019\n",
            "Loss in iteration no. 97887 ==> 0.48331009291045834\n",
            "Loss in iteration no. 97888 ==> 0.48330910466299437\n",
            "Loss in iteration no. 97889 ==> 0.4833081164245097\n",
            "Loss in iteration no. 97890 ==> 0.4833071281950046\n",
            "Loss in iteration no. 97891 ==> 0.48330613997447863\n",
            "Loss in iteration no. 97892 ==> 0.4833051517629317\n",
            "Loss in iteration no. 97893 ==> 0.4833041635603638\n",
            "Loss in iteration no. 97894 ==> 0.4833031753667748\n",
            "Loss in iteration no. 97895 ==> 0.4833021871821646\n",
            "Loss in iteration no. 97896 ==> 0.48330119900653296\n",
            "Loss in iteration no. 97897 ==> 0.4833002108398799\n",
            "Loss in iteration no. 97898 ==> 0.4832992226822052\n",
            "Loss in iteration no. 97899 ==> 0.48329823453350873\n",
            "Loss in iteration no. 97900 ==> 0.48329724639379057\n",
            "Loss in iteration no. 97901 ==> 0.48329625826305045\n",
            "Loss in iteration no. 97902 ==> 0.4832952701412883\n",
            "Loss in iteration no. 97903 ==> 0.483294282028504\n",
            "Loss in iteration no. 97904 ==> 0.4832932939246972\n",
            "Loss in iteration no. 97905 ==> 0.4832923058298684\n",
            "Loss in iteration no. 97906 ==> 0.4832913177440168\n",
            "Loss in iteration no. 97907 ==> 0.48329032966714275\n",
            "Loss in iteration no. 97908 ==> 0.4832893415992459\n",
            "Loss in iteration no. 97909 ==> 0.48328835354032623\n",
            "Loss in iteration no. 97910 ==> 0.48328736549038365\n",
            "Loss in iteration no. 97911 ==> 0.4832863774494179\n",
            "Loss in iteration no. 97912 ==> 0.48328538941742893\n",
            "Loss in iteration no. 97913 ==> 0.4832844013944166\n",
            "Loss in iteration no. 97914 ==> 0.4832834133803811\n",
            "Loss in iteration no. 97915 ==> 0.4832824253753219\n",
            "Loss in iteration no. 97916 ==> 0.48328143737923895\n",
            "Loss in iteration no. 97917 ==> 0.48328044939213255\n",
            "Loss in iteration no. 97918 ==> 0.48327946141400213\n",
            "Loss in iteration no. 97919 ==> 0.4832784734448476\n",
            "Loss in iteration no. 97920 ==> 0.48327748548466914\n",
            "Loss in iteration no. 97921 ==> 0.4832764975334663\n",
            "Loss in iteration no. 97922 ==> 0.4832755095912393\n",
            "Loss in iteration no. 97923 ==> 0.4832745216579877\n",
            "Loss in iteration no. 97924 ==> 0.4832735337337117\n",
            "Loss in iteration no. 97925 ==> 0.4832725458184109\n",
            "Loss in iteration no. 97926 ==> 0.48327155791208537\n",
            "Loss in iteration no. 97927 ==> 0.48327057001473483\n",
            "Loss in iteration no. 97928 ==> 0.48326958212635934\n",
            "Loss in iteration no. 97929 ==> 0.4832685942469587\n",
            "Loss in iteration no. 97930 ==> 0.4832676063765328\n",
            "Loss in iteration no. 97931 ==> 0.48326661851508157\n",
            "Loss in iteration no. 97932 ==> 0.483265630662605\n",
            "Loss in iteration no. 97933 ==> 0.48326464281910264\n",
            "Loss in iteration no. 97934 ==> 0.4832636549845746\n",
            "Loss in iteration no. 97935 ==> 0.4832626671590208\n",
            "Loss in iteration no. 97936 ==> 0.483261679342441\n",
            "Loss in iteration no. 97937 ==> 0.4832606915348352\n",
            "Loss in iteration no. 97938 ==> 0.48325970373620325\n",
            "Loss in iteration no. 97939 ==> 0.48325871594654496\n",
            "Loss in iteration no. 97940 ==> 0.4832577281658603\n",
            "Loss in iteration no. 97941 ==> 0.4832567403941491\n",
            "Loss in iteration no. 97942 ==> 0.48325575263141146\n",
            "Loss in iteration no. 97943 ==> 0.48325476487764685\n",
            "Loss in iteration no. 97944 ==> 0.48325377713285556\n",
            "Loss in iteration no. 97945 ==> 0.4832527893970373\n",
            "Loss in iteration no. 97946 ==> 0.48325180167019177\n",
            "Loss in iteration no. 97947 ==> 0.48325081395231934\n",
            "Loss in iteration no. 97948 ==> 0.48324982624341933\n",
            "Loss in iteration no. 97949 ==> 0.48324883854349204\n",
            "Loss in iteration no. 97950 ==> 0.4832478508525372\n",
            "Loss in iteration no. 97951 ==> 0.48324686317055465\n",
            "Loss in iteration no. 97952 ==> 0.4832458754975445\n",
            "Loss in iteration no. 97953 ==> 0.48324488783350633\n",
            "Loss in iteration no. 97954 ==> 0.4832439001784402\n",
            "Loss in iteration no. 97955 ==> 0.4832429125323461\n",
            "Loss in iteration no. 97956 ==> 0.48324192489522355\n",
            "Loss in iteration no. 97957 ==> 0.4832409372670728\n",
            "Loss in iteration no. 97958 ==> 0.4832399496478936\n",
            "Loss in iteration no. 97959 ==> 0.4832389620376857\n",
            "Loss in iteration no. 97960 ==> 0.4832379744364492\n",
            "Loss in iteration no. 97961 ==> 0.4832369868441839\n",
            "Loss in iteration no. 97962 ==> 0.48323599926088967\n",
            "Loss in iteration no. 97963 ==> 0.4832350116865665\n",
            "Loss in iteration no. 97964 ==> 0.4832340241212141\n",
            "Loss in iteration no. 97965 ==> 0.4832330365648326\n",
            "Loss in iteration no. 97966 ==> 0.4832320490174216\n",
            "Loss in iteration no. 97967 ==> 0.4832310614789811\n",
            "Loss in iteration no. 97968 ==> 0.48323007394951106\n",
            "Loss in iteration no. 97969 ==> 0.4832290864290114\n",
            "Loss in iteration no. 97970 ==> 0.4832280989174817\n",
            "Loss in iteration no. 97971 ==> 0.48322711141492225\n",
            "Loss in iteration no. 97972 ==> 0.4832261239213327\n",
            "Loss in iteration no. 97973 ==> 0.4832251364367131\n",
            "Loss in iteration no. 97974 ==> 0.483224148961063\n",
            "Loss in iteration no. 97975 ==> 0.4832231614943826\n",
            "Loss in iteration no. 97976 ==> 0.4832221740366717\n",
            "Loss in iteration no. 97977 ==> 0.4832211865879303\n",
            "Loss in iteration no. 97978 ==> 0.4832201991481579\n",
            "Loss in iteration no. 97979 ==> 0.4832192117173549\n",
            "Loss in iteration no. 97980 ==> 0.4832182242955208\n",
            "Loss in iteration no. 97981 ==> 0.4832172368826555\n",
            "Loss in iteration no. 97982 ==> 0.4832162494787593\n",
            "Loss in iteration no. 97983 ==> 0.4832152620838316\n",
            "Loss in iteration no. 97984 ==> 0.48321427469787254\n",
            "Loss in iteration no. 97985 ==> 0.4832132873208819\n",
            "Loss in iteration no. 97986 ==> 0.4832122999528597\n",
            "Loss in iteration no. 97987 ==> 0.48321131259380556\n",
            "Loss in iteration no. 97988 ==> 0.4832103252437197\n",
            "Loss in iteration no. 97989 ==> 0.48320933790260184\n",
            "Loss in iteration no. 97990 ==> 0.4832083505704517\n",
            "Loss in iteration no. 97991 ==> 0.4832073632472696\n",
            "Loss in iteration no. 97992 ==> 0.48320637593305504\n",
            "Loss in iteration no. 97993 ==> 0.48320538862780804\n",
            "Loss in iteration no. 97994 ==> 0.48320440133152837\n",
            "Loss in iteration no. 97995 ==> 0.48320341404421613\n",
            "Loss in iteration no. 97996 ==> 0.4832024267658711\n",
            "Loss in iteration no. 97997 ==> 0.48320143949649313\n",
            "Loss in iteration no. 97998 ==> 0.4832004522360822\n",
            "Loss in iteration no. 97999 ==> 0.48319946498463806\n",
            "Loss in iteration no. 98000 ==> 0.4831984777421607\n",
            "Loss in iteration no. 98001 ==> 0.4831974905086499\n",
            "Loss in iteration no. 98002 ==> 0.48319650328410574\n",
            "Loss in iteration no. 98003 ==> 0.4831955160685279\n",
            "Loss in iteration no. 98004 ==> 0.4831945288619164\n",
            "Loss in iteration no. 98005 ==> 0.4831935416642711\n",
            "Loss in iteration no. 98006 ==> 0.4831925544755918\n",
            "Loss in iteration no. 98007 ==> 0.4831915672958784\n",
            "Loss in iteration no. 98008 ==> 0.48319058012513094\n",
            "Loss in iteration no. 98009 ==> 0.48318959296334923\n",
            "Loss in iteration no. 98010 ==> 0.4831886058105331\n",
            "Loss in iteration no. 98011 ==> 0.4831876186666825\n",
            "Loss in iteration no. 98012 ==> 0.4831866315317971\n",
            "Loss in iteration no. 98013 ==> 0.483185644405877\n",
            "Loss in iteration no. 98014 ==> 0.48318465728892224\n",
            "Loss in iteration no. 98015 ==> 0.4831836701809324\n",
            "Loss in iteration no. 98016 ==> 0.4831826830819074\n",
            "Loss in iteration no. 98017 ==> 0.48318169599184746\n",
            "Loss in iteration no. 98018 ==> 0.48318070891075193\n",
            "Loss in iteration no. 98019 ==> 0.48317972183862107\n",
            "Loss in iteration no. 98020 ==> 0.48317873477545475\n",
            "Loss in iteration no. 98021 ==> 0.4831777477212527\n",
            "Loss in iteration no. 98022 ==> 0.48317676067601495\n",
            "Loss in iteration no. 98023 ==> 0.48317577363974124\n",
            "Loss in iteration no. 98024 ==> 0.48317478661243163\n",
            "Loss in iteration no. 98025 ==> 0.4831737995940858\n",
            "Loss in iteration no. 98026 ==> 0.48317281258470385\n",
            "Loss in iteration no. 98027 ==> 0.4831718255842856\n",
            "Loss in iteration no. 98028 ==> 0.4831708385928307\n",
            "Loss in iteration no. 98029 ==> 0.4831698516103395\n",
            "Loss in iteration no. 98030 ==> 0.48316886463681147\n",
            "Loss in iteration no. 98031 ==> 0.48316787767224667\n",
            "Loss in iteration no. 98032 ==> 0.483166890716645\n",
            "Loss in iteration no. 98033 ==> 0.4831659037700063\n",
            "Loss in iteration no. 98034 ==> 0.4831649168323305\n",
            "Loss in iteration no. 98035 ==> 0.48316392990361734\n",
            "Loss in iteration no. 98036 ==> 0.4831629429838668\n",
            "Loss in iteration no. 98037 ==> 0.483161956073079\n",
            "Loss in iteration no. 98038 ==> 0.4831609691712534\n",
            "Loss in iteration no. 98039 ==> 0.4831599822783902\n",
            "Loss in iteration no. 98040 ==> 0.4831589953944891\n",
            "Loss in iteration no. 98041 ==> 0.4831580085195501\n",
            "Loss in iteration no. 98042 ==> 0.48315702165357305\n",
            "Loss in iteration no. 98043 ==> 0.48315603479655783\n",
            "Loss in iteration no. 98044 ==> 0.4831550479485044\n",
            "Loss in iteration no. 98045 ==> 0.4831540611094126\n",
            "Loss in iteration no. 98046 ==> 0.4831530742792823\n",
            "Loss in iteration no. 98047 ==> 0.4831520874581131\n",
            "Loss in iteration no. 98048 ==> 0.4831511006459054\n",
            "Loss in iteration no. 98049 ==> 0.4831501138426589\n",
            "Loss in iteration no. 98050 ==> 0.4831491270483734\n",
            "Loss in iteration no. 98051 ==> 0.4831481402630488\n",
            "Loss in iteration no. 98052 ==> 0.4831471534866851\n",
            "Loss in iteration no. 98053 ==> 0.48314616671928184\n",
            "Loss in iteration no. 98054 ==> 0.48314517996083944\n",
            "Loss in iteration no. 98055 ==> 0.4831441932113574\n",
            "Loss in iteration no. 98056 ==> 0.48314320647083564\n",
            "Loss in iteration no. 98057 ==> 0.4831422197392742\n",
            "Loss in iteration no. 98058 ==> 0.48314123301667283\n",
            "Loss in iteration no. 98059 ==> 0.4831402463030316\n",
            "Loss in iteration no. 98060 ==> 0.48313925959835025\n",
            "Loss in iteration no. 98061 ==> 0.4831382729026287\n",
            "Loss in iteration no. 98062 ==> 0.4831372862158666\n",
            "Loss in iteration no. 98063 ==> 0.48313629953806414\n",
            "Loss in iteration no. 98064 ==> 0.4831353128692213\n",
            "Loss in iteration no. 98065 ==> 0.4831343262093376\n",
            "Loss in iteration no. 98066 ==> 0.48313333955841326\n",
            "Loss in iteration no. 98067 ==> 0.48313235291644785\n",
            "Loss in iteration no. 98068 ==> 0.4831313662834416\n",
            "Loss in iteration no. 98069 ==> 0.4831303796593941\n",
            "Loss in iteration no. 98070 ==> 0.4831293930443054\n",
            "Loss in iteration no. 98071 ==> 0.48312840643817534\n",
            "Loss in iteration no. 98072 ==> 0.48312741984100377\n",
            "Loss in iteration no. 98073 ==> 0.48312643325279064\n",
            "Loss in iteration no. 98074 ==> 0.48312544667353585\n",
            "Loss in iteration no. 98075 ==> 0.48312446010323923\n",
            "Loss in iteration no. 98076 ==> 0.48312347354190066\n",
            "Loss in iteration no. 98077 ==> 0.48312248698952004\n",
            "Loss in iteration no. 98078 ==> 0.4831215004460973\n",
            "Loss in iteration no. 98079 ==> 0.4831205139116323\n",
            "Loss in iteration no. 98080 ==> 0.4831195273861248\n",
            "Loss in iteration no. 98081 ==> 0.4831185408695749\n",
            "Loss in iteration no. 98082 ==> 0.4831175543619824\n",
            "Loss in iteration no. 98083 ==> 0.4831165678633471\n",
            "Loss in iteration no. 98084 ==> 0.48311558137366906\n",
            "Loss in iteration no. 98085 ==> 0.483114594892948\n",
            "Loss in iteration no. 98086 ==> 0.4831136084211839\n",
            "Loss in iteration no. 98087 ==> 0.48311262195837656\n",
            "Loss in iteration no. 98088 ==> 0.48311163550452585\n",
            "Loss in iteration no. 98089 ==> 0.4831106490596319\n",
            "Loss in iteration no. 98090 ==> 0.4831096626236945\n",
            "Loss in iteration no. 98091 ==> 0.48310867619671327\n",
            "Loss in iteration no. 98092 ==> 0.4831076897786883\n",
            "Loss in iteration no. 98093 ==> 0.4831067033696196\n",
            "Loss in iteration no. 98094 ==> 0.4831057169695067\n",
            "Loss in iteration no. 98095 ==> 0.48310473057834996\n",
            "Loss in iteration no. 98096 ==> 0.48310374419614877\n",
            "Loss in iteration no. 98097 ==> 0.4831027578229034\n",
            "Loss in iteration no. 98098 ==> 0.48310177145861355\n",
            "Loss in iteration no. 98099 ==> 0.48310078510327914\n",
            "Loss in iteration no. 98100 ==> 0.4830997987569001\n",
            "Loss in iteration no. 98101 ==> 0.4830988124194762\n",
            "Loss in iteration no. 98102 ==> 0.48309782609100754\n",
            "Loss in iteration no. 98103 ==> 0.4830968397714938\n",
            "Loss in iteration no. 98104 ==> 0.4830958534609348\n",
            "Loss in iteration no. 98105 ==> 0.48309486715933075\n",
            "Loss in iteration no. 98106 ==> 0.4830938808666813\n",
            "Loss in iteration no. 98107 ==> 0.4830928945829863\n",
            "Loss in iteration no. 98108 ==> 0.48309190830824594\n",
            "Loss in iteration no. 98109 ==> 0.4830909220424596\n",
            "Loss in iteration no. 98110 ==> 0.48308993578562776\n",
            "Loss in iteration no. 98111 ==> 0.4830889495377498\n",
            "Loss in iteration no. 98112 ==> 0.48308796329882586\n",
            "Loss in iteration no. 98113 ==> 0.4830869770688557\n",
            "Loss in iteration no. 98114 ==> 0.48308599084783943\n",
            "Loss in iteration no. 98115 ==> 0.4830850046357767\n",
            "Loss in iteration no. 98116 ==> 0.48308401843266746\n",
            "Loss in iteration no. 98117 ==> 0.4830830322385115\n",
            "Loss in iteration no. 98118 ==> 0.48308204605330896\n",
            "Loss in iteration no. 98119 ==> 0.4830810598770596\n",
            "Loss in iteration no. 98120 ==> 0.4830800737097632\n",
            "Loss in iteration no. 98121 ==> 0.4830790875514199\n",
            "Loss in iteration no. 98122 ==> 0.48307810140202934\n",
            "Loss in iteration no. 98123 ==> 0.48307711526159147\n",
            "Loss in iteration no. 98124 ==> 0.4830761291301061\n",
            "Loss in iteration no. 98125 ==> 0.4830751430075734\n",
            "Loss in iteration no. 98126 ==> 0.483074156893993\n",
            "Loss in iteration no. 98127 ==> 0.48307317078936485\n",
            "Loss in iteration no. 98128 ==> 0.4830721846936888\n",
            "Loss in iteration no. 98129 ==> 0.48307119860696485\n",
            "Loss in iteration no. 98130 ==> 0.4830702125291928\n",
            "Loss in iteration no. 98131 ==> 0.4830692264603724\n",
            "Loss in iteration no. 98132 ==> 0.4830682404005039\n",
            "Loss in iteration no. 98133 ==> 0.48306725434958686\n",
            "Loss in iteration no. 98134 ==> 0.48306626830762134\n",
            "Loss in iteration no. 98135 ==> 0.48306528227460704\n",
            "Loss in iteration no. 98136 ==> 0.4830642962505441\n",
            "Loss in iteration no. 98137 ==> 0.4830633102354322\n",
            "Loss in iteration no. 98138 ==> 0.4830623242292713\n",
            "Loss in iteration no. 98139 ==> 0.4830613382320614\n",
            "Loss in iteration no. 98140 ==> 0.4830603522438021\n",
            "Loss in iteration no. 98141 ==> 0.48305936626449353\n",
            "Loss in iteration no. 98142 ==> 0.4830583802941356\n",
            "Loss in iteration no. 98143 ==> 0.48305739433272793\n",
            "Loss in iteration no. 98144 ==> 0.4830564083802707\n",
            "Loss in iteration no. 98145 ==> 0.48305542243676364\n",
            "Loss in iteration no. 98146 ==> 0.48305443650220675\n",
            "Loss in iteration no. 98147 ==> 0.4830534505765997\n",
            "Loss in iteration no. 98148 ==> 0.48305246465994256\n",
            "Loss in iteration no. 98149 ==> 0.4830514787522352\n",
            "Loss in iteration no. 98150 ==> 0.48305049285347745\n",
            "Loss in iteration no. 98151 ==> 0.4830495069636692\n",
            "Loss in iteration no. 98152 ==> 0.4830485210828103\n",
            "Loss in iteration no. 98153 ==> 0.4830475352109009\n",
            "Loss in iteration no. 98154 ==> 0.4830465493479405\n",
            "Loss in iteration no. 98155 ==> 0.4830455634939292\n",
            "Loss in iteration no. 98156 ==> 0.4830445776488669\n",
            "Loss in iteration no. 98157 ==> 0.48304359181275336\n",
            "Loss in iteration no. 98158 ==> 0.4830426059855885\n",
            "Loss in iteration no. 98159 ==> 0.48304162016737234\n",
            "Loss in iteration no. 98160 ==> 0.48304063435810474\n",
            "Loss in iteration no. 98161 ==> 0.4830396485577854\n",
            "Loss in iteration no. 98162 ==> 0.4830386627664143\n",
            "Loss in iteration no. 98163 ==> 0.48303767698399147\n",
            "Loss in iteration no. 98164 ==> 0.4830366912105166\n",
            "Loss in iteration no. 98165 ==> 0.4830357054459896\n",
            "Loss in iteration no. 98166 ==> 0.4830347196904105\n",
            "Loss in iteration no. 98167 ==> 0.4830337339437791\n",
            "Loss in iteration no. 98168 ==> 0.4830327482060953\n",
            "Loss in iteration no. 98169 ==> 0.48303176247735896\n",
            "Loss in iteration no. 98170 ==> 0.4830307767575699\n",
            "Loss in iteration no. 98171 ==> 0.48302979104672816\n",
            "Loss in iteration no. 98172 ==> 0.4830288053448335\n",
            "Loss in iteration no. 98173 ==> 0.48302781965188596\n",
            "Loss in iteration no. 98174 ==> 0.4830268339678851\n",
            "Loss in iteration no. 98175 ==> 0.48302584829283124\n",
            "Loss in iteration no. 98176 ==> 0.4830248626267239\n",
            "Loss in iteration no. 98177 ==> 0.4830238769695633\n",
            "Loss in iteration no. 98178 ==> 0.4830228913213489\n",
            "Loss in iteration no. 98179 ==> 0.48302190568208103\n",
            "Loss in iteration no. 98180 ==> 0.4830209200517593\n",
            "Loss in iteration no. 98181 ==> 0.4830199344303837\n",
            "Loss in iteration no. 98182 ==> 0.483018948817954\n",
            "Loss in iteration no. 98183 ==> 0.4830179632144702\n",
            "Loss in iteration no. 98184 ==> 0.48301697761993223\n",
            "Loss in iteration no. 98185 ==> 0.48301599203434\n",
            "Loss in iteration no. 98186 ==> 0.483015006457693\n",
            "Loss in iteration no. 98187 ==> 0.4830140208899916\n",
            "Loss in iteration no. 98188 ==> 0.4830130353312356\n",
            "Loss in iteration no. 98189 ==> 0.4830120497814246\n",
            "Loss in iteration no. 98190 ==> 0.4830110642405588\n",
            "Loss in iteration no. 98191 ==> 0.48301007870863777\n",
            "Loss in iteration no. 98192 ==> 0.4830090931856618\n",
            "Loss in iteration no. 98193 ==> 0.48300810767163055\n",
            "Loss in iteration no. 98194 ==> 0.4830071221665439\n",
            "Loss in iteration no. 98195 ==> 0.48300613667040165\n",
            "Loss in iteration no. 98196 ==> 0.4830051511832039\n",
            "Loss in iteration no. 98197 ==> 0.4830041657049504\n",
            "Loss in iteration no. 98198 ==> 0.4830031802356411\n",
            "Loss in iteration no. 98199 ==> 0.4830021947752758\n",
            "Loss in iteration no. 98200 ==> 0.4830012093238545\n",
            "Loss in iteration no. 98201 ==> 0.483000223881377\n",
            "Loss in iteration no. 98202 ==> 0.48299923844784315\n",
            "Loss in iteration no. 98203 ==> 0.48299825302325294\n",
            "Loss in iteration no. 98204 ==> 0.48299726760760625\n",
            "Loss in iteration no. 98205 ==> 0.4829962822009029\n",
            "Loss in iteration no. 98206 ==> 0.4829952968031428\n",
            "Loss in iteration no. 98207 ==> 0.4829943114143258\n",
            "Loss in iteration no. 98208 ==> 0.48299332603445194\n",
            "Loss in iteration no. 98209 ==> 0.4829923406635209\n",
            "Loss in iteration no. 98210 ==> 0.48299135530153264\n",
            "Loss in iteration no. 98211 ==> 0.48299036994848715\n",
            "Loss in iteration no. 98212 ==> 0.4829893846043841\n",
            "Loss in iteration no. 98213 ==> 0.4829883992692237\n",
            "Loss in iteration no. 98214 ==> 0.4829874139430055\n",
            "Loss in iteration no. 98215 ==> 0.48298642862572955\n",
            "Loss in iteration no. 98216 ==> 0.4829854433173958\n",
            "Loss in iteration no. 98217 ==> 0.48298445801800394\n",
            "Loss in iteration no. 98218 ==> 0.482983472727554\n",
            "Loss in iteration no. 98219 ==> 0.48298248744604577\n",
            "Loss in iteration no. 98220 ==> 0.4829815021734794\n",
            "Loss in iteration no. 98221 ==> 0.48298051690985433\n",
            "Loss in iteration no. 98222 ==> 0.4829795316551709\n",
            "Loss in iteration no. 98223 ==> 0.48297854640942867\n",
            "Loss in iteration no. 98224 ==> 0.48297756117262775\n",
            "Loss in iteration no. 98225 ==> 0.4829765759447677\n",
            "Loss in iteration no. 98226 ==> 0.4829755907258489\n",
            "Loss in iteration no. 98227 ==> 0.4829746055158708\n",
            "Loss in iteration no. 98228 ==> 0.4829736203148336\n",
            "Loss in iteration no. 98229 ==> 0.4829726351227369\n",
            "Loss in iteration no. 98230 ==> 0.48297164993958075\n",
            "Loss in iteration no. 98231 ==> 0.482970664765365\n",
            "Loss in iteration no. 98232 ==> 0.48296967960008963\n",
            "Loss in iteration no. 98233 ==> 0.4829686944437543\n",
            "Loss in iteration no. 98234 ==> 0.482967709296359\n",
            "Loss in iteration no. 98235 ==> 0.4829667241579038\n",
            "Loss in iteration no. 98236 ==> 0.4829657390283885\n",
            "Loss in iteration no. 98237 ==> 0.48296475390781285\n",
            "Loss in iteration no. 98238 ==> 0.48296376879617675\n",
            "Loss in iteration no. 98239 ==> 0.48296278369348017\n",
            "Loss in iteration no. 98240 ==> 0.48296179859972305\n",
            "Loss in iteration no. 98241 ==> 0.48296081351490505\n",
            "Loss in iteration no. 98242 ==> 0.48295982843902635\n",
            "Loss in iteration no. 98243 ==> 0.4829588433720866\n",
            "Loss in iteration no. 98244 ==> 0.4829578583140859\n",
            "Loss in iteration no. 98245 ==> 0.4829568732650239\n",
            "Loss in iteration no. 98246 ==> 0.48295588822490065\n",
            "Loss in iteration no. 98247 ==> 0.482954903193716\n",
            "Loss in iteration no. 98248 ==> 0.4829539181714698\n",
            "Loss in iteration no. 98249 ==> 0.4829529331581619\n",
            "Loss in iteration no. 98250 ==> 0.48295194815379233\n",
            "Loss in iteration no. 98251 ==> 0.4829509631583609\n",
            "Loss in iteration no. 98252 ==> 0.4829499781718674\n",
            "Loss in iteration no. 98253 ==> 0.48294899319431195\n",
            "Loss in iteration no. 98254 ==> 0.4829480082256942\n",
            "Loss in iteration no. 98255 ==> 0.4829470232660142\n",
            "Loss in iteration no. 98256 ==> 0.4829460383152716\n",
            "Loss in iteration no. 98257 ==> 0.48294505337346655\n",
            "Loss in iteration no. 98258 ==> 0.48294406844059895\n",
            "Loss in iteration no. 98259 ==> 0.4829430835166684\n",
            "Loss in iteration no. 98260 ==> 0.48294209860167503\n",
            "Loss in iteration no. 98261 ==> 0.48294111369561865\n",
            "Loss in iteration no. 98262 ==> 0.4829401287984991\n",
            "Loss in iteration no. 98263 ==> 0.4829391439103165\n",
            "Loss in iteration no. 98264 ==> 0.48293815903107046\n",
            "Loss in iteration no. 98265 ==> 0.4829371741607609\n",
            "Loss in iteration no. 98266 ==> 0.48293618929938775\n",
            "Loss in iteration no. 98267 ==> 0.48293520444695104\n",
            "Loss in iteration no. 98268 ==> 0.48293421960345045\n",
            "Loss in iteration no. 98269 ==> 0.48293323476888583\n",
            "Loss in iteration no. 98270 ==> 0.4829322499432574\n",
            "Loss in iteration no. 98271 ==> 0.4829312651265647\n",
            "Loss in iteration no. 98272 ==> 0.48293028031880775\n",
            "Loss in iteration no. 98273 ==> 0.4829292955199865\n",
            "Loss in iteration no. 98274 ==> 0.4829283107301007\n",
            "Loss in iteration no. 98275 ==> 0.4829273259491503\n",
            "Loss in iteration no. 98276 ==> 0.48292634117713523\n",
            "Loss in iteration no. 98277 ==> 0.4829253564140553\n",
            "Loss in iteration no. 98278 ==> 0.4829243716599104\n",
            "Loss in iteration no. 98279 ==> 0.48292338691470055\n",
            "Loss in iteration no. 98280 ==> 0.48292240217842547\n",
            "Loss in iteration no. 98281 ==> 0.4829214174510852\n",
            "Loss in iteration no. 98282 ==> 0.48292043273267937\n",
            "Loss in iteration no. 98283 ==> 0.48291944802320813\n",
            "Loss in iteration no. 98284 ==> 0.4829184633226713\n",
            "Loss in iteration no. 98285 ==> 0.4829174786310686\n",
            "Loss in iteration no. 98286 ==> 0.48291649394840036\n",
            "Loss in iteration no. 98287 ==> 0.48291550927466587\n",
            "Loss in iteration no. 98288 ==> 0.48291452460986545\n",
            "Loss in iteration no. 98289 ==> 0.48291353995399877\n",
            "Loss in iteration no. 98290 ==> 0.4829125553070658\n",
            "Loss in iteration no. 98291 ==> 0.48291157066906637\n",
            "Loss in iteration no. 98292 ==> 0.4829105860400004\n",
            "Loss in iteration no. 98293 ==> 0.4829096014198679\n",
            "Loss in iteration no. 98294 ==> 0.4829086168086684\n",
            "Loss in iteration no. 98295 ==> 0.4829076322064023\n",
            "Loss in iteration no. 98296 ==> 0.4829066476130693\n",
            "Loss in iteration no. 98297 ==> 0.48290566302866883\n",
            "Loss in iteration no. 98298 ==> 0.4829046784532014\n",
            "Loss in iteration no. 98299 ==> 0.48290369388666665\n",
            "Loss in iteration no. 98300 ==> 0.4829027093290643\n",
            "Loss in iteration no. 98301 ==> 0.4829017247803945\n",
            "Loss in iteration no. 98302 ==> 0.4829007402406571\n",
            "Loss in iteration no. 98303 ==> 0.48289975570985183\n",
            "Loss in iteration no. 98304 ==> 0.48289877118797875\n",
            "Loss in iteration no. 98305 ==> 0.48289778667503747\n",
            "Loss in iteration no. 98306 ==> 0.4828968021710283\n",
            "Loss in iteration no. 98307 ==> 0.4828958176759508\n",
            "Loss in iteration no. 98308 ==> 0.4828948331898049\n",
            "Loss in iteration no. 98309 ==> 0.48289384871259056\n",
            "Loss in iteration no. 98310 ==> 0.48289286424430783\n",
            "Loss in iteration no. 98311 ==> 0.4828918797849563\n",
            "Loss in iteration no. 98312 ==> 0.4828908953345358\n",
            "Loss in iteration no. 98313 ==> 0.4828899108930465\n",
            "Loss in iteration no. 98314 ==> 0.48288892646048814\n",
            "Loss in iteration no. 98315 ==> 0.48288794203686075\n",
            "Loss in iteration no. 98316 ==> 0.48288695762216405\n",
            "Loss in iteration no. 98317 ==> 0.48288597321639787\n",
            "Loss in iteration no. 98318 ==> 0.4828849888195623\n",
            "Loss in iteration no. 98319 ==> 0.48288400443165713\n",
            "Loss in iteration no. 98320 ==> 0.4828830200526822\n",
            "Loss in iteration no. 98321 ==> 0.48288203568263754\n",
            "Loss in iteration no. 98322 ==> 0.4828810513215228\n",
            "Loss in iteration no. 98323 ==> 0.48288006696933805\n",
            "Loss in iteration no. 98324 ==> 0.4828790826260832\n",
            "Loss in iteration no. 98325 ==> 0.48287809829175804\n",
            "Loss in iteration no. 98326 ==> 0.48287711396636246\n",
            "Loss in iteration no. 98327 ==> 0.48287612964989657\n",
            "Loss in iteration no. 98328 ==> 0.48287514534235976\n",
            "Loss in iteration no. 98329 ==> 0.4828741610437524\n",
            "Loss in iteration no. 98330 ==> 0.48287317675407415\n",
            "Loss in iteration no. 98331 ==> 0.48287219247332486\n",
            "Loss in iteration no. 98332 ==> 0.4828712082015047\n",
            "Loss in iteration no. 98333 ==> 0.4828702239386131\n",
            "Loss in iteration no. 98334 ==> 0.4828692396846504\n",
            "Loss in iteration no. 98335 ==> 0.4828682554396161\n",
            "Loss in iteration no. 98336 ==> 0.48286727120351036\n",
            "Loss in iteration no. 98337 ==> 0.4828662869763331\n",
            "Loss in iteration no. 98338 ==> 0.4828653027580838\n",
            "Loss in iteration no. 98339 ==> 0.48286431854876294\n",
            "Loss in iteration no. 98340 ==> 0.48286333434836987\n",
            "Loss in iteration no. 98341 ==> 0.4828623501569048\n",
            "Loss in iteration no. 98342 ==> 0.48286136597436746\n",
            "Loss in iteration no. 98343 ==> 0.4828603818007578\n",
            "Loss in iteration no. 98344 ==> 0.4828593976360758\n",
            "Loss in iteration no. 98345 ==> 0.48285841348032116\n",
            "Loss in iteration no. 98346 ==> 0.4828574293334939\n",
            "Loss in iteration no. 98347 ==> 0.48285644519559373\n",
            "Loss in iteration no. 98348 ==> 0.4828554610666209\n",
            "Loss in iteration no. 98349 ==> 0.48285447694657496\n",
            "Loss in iteration no. 98350 ==> 0.48285349283545587\n",
            "Loss in iteration no. 98351 ==> 0.4828525087332636\n",
            "Loss in iteration no. 98352 ==> 0.4828515246399978\n",
            "Loss in iteration no. 98353 ==> 0.48285054055565874\n",
            "Loss in iteration no. 98354 ==> 0.48284955648024597\n",
            "Loss in iteration no. 98355 ==> 0.48284857241375967\n",
            "Loss in iteration no. 98356 ==> 0.4828475883561994\n",
            "Loss in iteration no. 98357 ==> 0.4828466043075653\n",
            "Loss in iteration no. 98358 ==> 0.4828456202678572\n",
            "Loss in iteration no. 98359 ==> 0.4828446362370749\n",
            "Loss in iteration no. 98360 ==> 0.4828436522152184\n",
            "Loss in iteration no. 98361 ==> 0.4828426682022875\n",
            "Loss in iteration no. 98362 ==> 0.4828416841982821\n",
            "Loss in iteration no. 98363 ==> 0.48284070020320213\n",
            "Loss in iteration no. 98364 ==> 0.4828397162170474\n",
            "Loss in iteration no. 98365 ==> 0.482838732239818\n",
            "Loss in iteration no. 98366 ==> 0.4828377482715136\n",
            "Loss in iteration no. 98367 ==> 0.48283676431213396\n",
            "Loss in iteration no. 98368 ==> 0.4828357803616794\n",
            "Loss in iteration no. 98369 ==> 0.4828347964201494\n",
            "Loss in iteration no. 98370 ==> 0.48283381248754403\n",
            "Loss in iteration no. 98371 ==> 0.4828328285638633\n",
            "Loss in iteration no. 98372 ==> 0.48283184464910683\n",
            "Loss in iteration no. 98373 ==> 0.4828308607432746\n",
            "Loss in iteration no. 98374 ==> 0.4828298768463665\n",
            "Loss in iteration no. 98375 ==> 0.4828288929583826\n",
            "Loss in iteration no. 98376 ==> 0.4828279090793225\n",
            "Loss in iteration no. 98377 ==> 0.4828269252091863\n",
            "Loss in iteration no. 98378 ==> 0.48282594134797374\n",
            "Loss in iteration no. 98379 ==> 0.4828249574956848\n",
            "Loss in iteration no. 98380 ==> 0.48282397365231927\n",
            "Loss in iteration no. 98381 ==> 0.4828229898178771\n",
            "Loss in iteration no. 98382 ==> 0.4828220059923582\n",
            "Loss in iteration no. 98383 ==> 0.48282102217576245\n",
            "Loss in iteration no. 98384 ==> 0.4828200383680898\n",
            "Loss in iteration no. 98385 ==> 0.48281905456933993\n",
            "Loss in iteration no. 98386 ==> 0.48281807077951294\n",
            "Loss in iteration no. 98387 ==> 0.48281708699860854\n",
            "Loss in iteration no. 98388 ==> 0.48281610322662677\n",
            "Loss in iteration no. 98389 ==> 0.4828151194635674\n",
            "Loss in iteration no. 98390 ==> 0.48281413570943044\n",
            "Loss in iteration no. 98391 ==> 0.48281315196421565\n",
            "Loss in iteration no. 98392 ==> 0.48281216822792306\n",
            "Loss in iteration no. 98393 ==> 0.48281118450055227\n",
            "Loss in iteration no. 98394 ==> 0.48281020078210357\n",
            "Loss in iteration no. 98395 ==> 0.48280921707257657\n",
            "Loss in iteration no. 98396 ==> 0.48280823337197115\n",
            "Loss in iteration no. 98397 ==> 0.48280724968028743\n",
            "Loss in iteration no. 98398 ==> 0.4828062659975251\n",
            "Loss in iteration no. 98399 ==> 0.48280528232368397\n",
            "Loss in iteration no. 98400 ==> 0.4828042986587642\n",
            "Loss in iteration no. 98401 ==> 0.48280331500276535\n",
            "Loss in iteration no. 98402 ==> 0.48280233135568756\n",
            "Loss in iteration no. 98403 ==> 0.4828013477175306\n",
            "Loss in iteration no. 98404 ==> 0.4828003640882945\n",
            "Loss in iteration no. 98405 ==> 0.482799380467979\n",
            "Loss in iteration no. 98406 ==> 0.4827983968565839\n",
            "Loss in iteration no. 98407 ==> 0.48279741325410935\n",
            "Loss in iteration no. 98408 ==> 0.482796429660555\n",
            "Loss in iteration no. 98409 ==> 0.4827954460759209\n",
            "Loss in iteration no. 98410 ==> 0.4827944625002068\n",
            "Loss in iteration no. 98411 ==> 0.4827934789334128\n",
            "Loss in iteration no. 98412 ==> 0.4827924953755384\n",
            "Loss in iteration no. 98413 ==> 0.482791511826584\n",
            "Loss in iteration no. 98414 ==> 0.48279052828654917\n",
            "Loss in iteration no. 98415 ==> 0.4827895447554337\n",
            "Loss in iteration no. 98416 ==> 0.4827885612332377\n",
            "Loss in iteration no. 98417 ==> 0.48278757771996095\n",
            "Loss in iteration no. 98418 ==> 0.4827865942156033\n",
            "Loss in iteration no. 98419 ==> 0.48278561072016474\n",
            "Loss in iteration no. 98420 ==> 0.4827846272336451\n",
            "Loss in iteration no. 98421 ==> 0.4827836437560443\n",
            "Loss in iteration no. 98422 ==> 0.4827826602873623\n",
            "Loss in iteration no. 98423 ==> 0.48278167682759876\n",
            "Loss in iteration no. 98424 ==> 0.4827806933767537\n",
            "Loss in iteration no. 98425 ==> 0.48277970993482716\n",
            "Loss in iteration no. 98426 ==> 0.4827787265018188\n",
            "Loss in iteration no. 98427 ==> 0.4827777430777285\n",
            "Loss in iteration no. 98428 ==> 0.4827767596625563\n",
            "Loss in iteration no. 98429 ==> 0.48277577625630197\n",
            "Loss in iteration no. 98430 ==> 0.4827747928589655\n",
            "Loss in iteration no. 98431 ==> 0.48277380947054677\n",
            "Loss in iteration no. 98432 ==> 0.48277282609104544\n",
            "Loss in iteration no. 98433 ==> 0.48277184272046164\n",
            "Loss in iteration no. 98434 ==> 0.4827708593587952\n",
            "Loss in iteration no. 98435 ==> 0.4827698760060461\n",
            "Loss in iteration no. 98436 ==> 0.482768892662214\n",
            "Loss in iteration no. 98437 ==> 0.4827679093272989\n",
            "Loss in iteration no. 98438 ==> 0.4827669260013007\n",
            "Loss in iteration no. 98439 ==> 0.48276594268421935\n",
            "Loss in iteration no. 98440 ==> 0.4827649593760546\n",
            "Loss in iteration no. 98441 ==> 0.4827639760768065\n",
            "Loss in iteration no. 98442 ==> 0.48276299278647467\n",
            "Loss in iteration no. 98443 ==> 0.4827620095050592\n",
            "Loss in iteration no. 98444 ==> 0.48276102623256\n",
            "Loss in iteration no. 98445 ==> 0.4827600429689769\n",
            "Loss in iteration no. 98446 ==> 0.4827590597143099\n",
            "Loss in iteration no. 98447 ==> 0.4827580764685586\n",
            "Loss in iteration no. 98448 ==> 0.4827570932317231\n",
            "Loss in iteration no. 98449 ==> 0.4827561100038032\n",
            "Loss in iteration no. 98450 ==> 0.4827551267847989\n",
            "Loss in iteration no. 98451 ==> 0.48275414357470997\n",
            "Loss in iteration no. 98452 ==> 0.48275316037353655\n",
            "Loss in iteration no. 98453 ==> 0.48275217718127805\n",
            "Loss in iteration no. 98454 ==> 0.48275119399793476\n",
            "Loss in iteration no. 98455 ==> 0.4827502108235065\n",
            "Loss in iteration no. 98456 ==> 0.48274922765799294\n",
            "Loss in iteration no. 98457 ==> 0.48274824450139414\n",
            "Loss in iteration no. 98458 ==> 0.4827472613537101\n",
            "Loss in iteration no. 98459 ==> 0.48274627821494037\n",
            "Loss in iteration no. 98460 ==> 0.4827452950850851\n",
            "Loss in iteration no. 98461 ==> 0.48274431196414425\n",
            "Loss in iteration no. 98462 ==> 0.4827433288521175\n",
            "Loss in iteration no. 98463 ==> 0.48274234574900465\n",
            "Loss in iteration no. 98464 ==> 0.48274136265480594\n",
            "Loss in iteration no. 98465 ==> 0.48274037956952104\n",
            "Loss in iteration no. 98466 ==> 0.48273939649314984\n",
            "Loss in iteration no. 98467 ==> 0.4827384134256922\n",
            "Loss in iteration no. 98468 ==> 0.482737430367148\n",
            "Loss in iteration no. 98469 ==> 0.4827364473175174\n",
            "Loss in iteration no. 98470 ==> 0.4827354642767998\n",
            "Loss in iteration no. 98471 ==> 0.4827344812449955\n",
            "Loss in iteration no. 98472 ==> 0.48273349822210426\n",
            "Loss in iteration no. 98473 ==> 0.48273251520812593\n",
            "Loss in iteration no. 98474 ==> 0.4827315322030604\n",
            "Loss in iteration no. 98475 ==> 0.4827305492069076\n",
            "Loss in iteration no. 98476 ==> 0.4827295662196673\n",
            "Loss in iteration no. 98477 ==> 0.4827285832413395\n",
            "Loss in iteration no. 98478 ==> 0.482727600271924\n",
            "Loss in iteration no. 98479 ==> 0.4827266173114209\n",
            "Loss in iteration no. 98480 ==> 0.4827256343598298\n",
            "Loss in iteration no. 98481 ==> 0.48272465141715076\n",
            "Loss in iteration no. 98482 ==> 0.48272366848338366\n",
            "Loss in iteration no. 98483 ==> 0.4827226855585282\n",
            "Loss in iteration no. 98484 ==> 0.4827217026425846\n",
            "Loss in iteration no. 98485 ==> 0.48272071973555253\n",
            "Loss in iteration no. 98486 ==> 0.48271973683743186\n",
            "Loss in iteration no. 98487 ==> 0.48271875394822267\n",
            "Loss in iteration no. 98488 ==> 0.48271777106792446\n",
            "Loss in iteration no. 98489 ==> 0.4827167881965376\n",
            "Loss in iteration no. 98490 ==> 0.4827158053340615\n",
            "Loss in iteration no. 98491 ==> 0.4827148224804965\n",
            "Loss in iteration no. 98492 ==> 0.48271383963584225\n",
            "Loss in iteration no. 98493 ==> 0.48271285680009857\n",
            "Loss in iteration no. 98494 ==> 0.4827118739732653\n",
            "Loss in iteration no. 98495 ==> 0.4827108911553427\n",
            "Loss in iteration no. 98496 ==> 0.4827099083463304\n",
            "Loss in iteration no. 98497 ==> 0.48270892554622813\n",
            "Loss in iteration no. 98498 ==> 0.4827079427550362\n",
            "Loss in iteration no. 98499 ==> 0.48270695997275403\n",
            "Loss in iteration no. 98500 ==> 0.4827059771993818\n",
            "Loss in iteration no. 98501 ==> 0.4827049944349193\n",
            "Loss in iteration no. 98502 ==> 0.4827040116793665\n",
            "Loss in iteration no. 98503 ==> 0.48270302893272327\n",
            "Loss in iteration no. 98504 ==> 0.4827020461949893\n",
            "Loss in iteration no. 98505 ==> 0.48270106346616476\n",
            "Loss in iteration no. 98506 ==> 0.4827000807462493\n",
            "Loss in iteration no. 98507 ==> 0.482699098035243\n",
            "Loss in iteration no. 98508 ==> 0.4826981153331456\n",
            "Loss in iteration no. 98509 ==> 0.4826971326399571\n",
            "Loss in iteration no. 98510 ==> 0.48269614995567733\n",
            "Loss in iteration no. 98511 ==> 0.4826951672803062\n",
            "Loss in iteration no. 98512 ==> 0.4826941846138435\n",
            "Loss in iteration no. 98513 ==> 0.48269320195628934\n",
            "Loss in iteration no. 98514 ==> 0.4826922193076433\n",
            "Loss in iteration no. 98515 ==> 0.4826912366679055\n",
            "Loss in iteration no. 98516 ==> 0.48269025403707566\n",
            "Loss in iteration no. 98517 ==> 0.48268927141515383\n",
            "Loss in iteration no. 98518 ==> 0.4826882888021398\n",
            "Loss in iteration no. 98519 ==> 0.4826873061980335\n",
            "Loss in iteration no. 98520 ==> 0.48268632360283475\n",
            "Loss in iteration no. 98521 ==> 0.4826853410165436\n",
            "Loss in iteration no. 98522 ==> 0.48268435843915974\n",
            "Loss in iteration no. 98523 ==> 0.4826833758706832\n",
            "Loss in iteration no. 98524 ==> 0.4826823933111138\n",
            "Loss in iteration no. 98525 ==> 0.4826814107604514\n",
            "Loss in iteration no. 98526 ==> 0.48268042821869594\n",
            "Loss in iteration no. 98527 ==> 0.48267944568584725\n",
            "Loss in iteration no. 98528 ==> 0.4826784631619053\n",
            "Loss in iteration no. 98529 ==> 0.4826774806468699\n",
            "Loss in iteration no. 98530 ==> 0.482676498140741\n",
            "Loss in iteration no. 98531 ==> 0.48267551564351857\n",
            "Loss in iteration no. 98532 ==> 0.4826745331552022\n",
            "Loss in iteration no. 98533 ==> 0.48267355067579193\n",
            "Loss in iteration no. 98534 ==> 0.4826725682052878\n",
            "Loss in iteration no. 98535 ==> 0.48267158574368957\n",
            "Loss in iteration no. 98536 ==> 0.4826706032909969\n",
            "Loss in iteration no. 98537 ==> 0.48266962084721016\n",
            "Loss in iteration no. 98538 ==> 0.48266863841232893\n",
            "Loss in iteration no. 98539 ==> 0.4826676559863532\n",
            "Loss in iteration no. 98540 ==> 0.48266667356928267\n",
            "Loss in iteration no. 98541 ==> 0.4826656911611175\n",
            "Loss in iteration no. 98542 ==> 0.48266470876185724\n",
            "Loss in iteration no. 98543 ==> 0.4826637263715022\n",
            "Loss in iteration no. 98544 ==> 0.482662743990052\n",
            "Loss in iteration no. 98545 ==> 0.4826617616175064\n",
            "Loss in iteration no. 98546 ==> 0.4826607792538656\n",
            "Loss in iteration no. 98547 ==> 0.4826597968991293\n",
            "Loss in iteration no. 98548 ==> 0.4826588145532974\n",
            "Loss in iteration no. 98549 ==> 0.4826578322163699\n",
            "Loss in iteration no. 98550 ==> 0.48265684988834656\n",
            "Loss in iteration no. 98551 ==> 0.48265586756922735\n",
            "Loss in iteration no. 98552 ==> 0.48265488525901196\n",
            "Loss in iteration no. 98553 ==> 0.48265390295770066\n",
            "Loss in iteration no. 98554 ==> 0.48265292066529303\n",
            "Loss in iteration no. 98555 ==> 0.48265193838178905\n",
            "Loss in iteration no. 98556 ==> 0.48265095610718844\n",
            "Loss in iteration no. 98557 ==> 0.48264997384149144\n",
            "Loss in iteration no. 98558 ==> 0.4826489915846977\n",
            "Loss in iteration no. 98559 ==> 0.482648009336807\n",
            "Loss in iteration no. 98560 ==> 0.4826470270978195\n",
            "Loss in iteration no. 98561 ==> 0.48264604486773494\n",
            "Loss in iteration no. 98562 ==> 0.4826450626465533\n",
            "Loss in iteration no. 98563 ==> 0.48264408043427426\n",
            "Loss in iteration no. 98564 ==> 0.48264309823089796\n",
            "Loss in iteration no. 98565 ==> 0.48264211603642415\n",
            "Loss in iteration no. 98566 ==> 0.4826411338508526\n",
            "Loss in iteration no. 98567 ==> 0.4826401516741834\n",
            "Loss in iteration no. 98568 ==> 0.48263916950641633\n",
            "Loss in iteration no. 98569 ==> 0.48263818734755143\n",
            "Loss in iteration no. 98570 ==> 0.4826372051975884\n",
            "Loss in iteration no. 98571 ==> 0.4826362230565272\n",
            "Loss in iteration no. 98572 ==> 0.48263524092436777\n",
            "Loss in iteration no. 98573 ==> 0.4826342588011098\n",
            "Loss in iteration no. 98574 ==> 0.4826332766867535\n",
            "Loss in iteration no. 98575 ==> 0.48263229458129836\n",
            "Loss in iteration no. 98576 ==> 0.4826313124847446\n",
            "Loss in iteration no. 98577 ==> 0.48263033039709213\n",
            "Loss in iteration no. 98578 ==> 0.4826293483183405\n",
            "Loss in iteration no. 98579 ==> 0.4826283662484898\n",
            "Loss in iteration no. 98580 ==> 0.48262738418754\n",
            "Loss in iteration no. 98581 ==> 0.4826264021354909\n",
            "Loss in iteration no. 98582 ==> 0.48262542009234227\n",
            "Loss in iteration no. 98583 ==> 0.48262443805809424\n",
            "Loss in iteration no. 98584 ==> 0.4826234560327465\n",
            "Loss in iteration no. 98585 ==> 0.482622474016299\n",
            "Loss in iteration no. 98586 ==> 0.48262149200875165\n",
            "Loss in iteration no. 98587 ==> 0.4826205100101043\n",
            "Loss in iteration no. 98588 ==> 0.48261952802035685\n",
            "Loss in iteration no. 98589 ==> 0.4826185460395092\n",
            "Loss in iteration no. 98590 ==> 0.4826175640675612\n",
            "Loss in iteration no. 98591 ==> 0.48261658210451275\n",
            "Loss in iteration no. 98592 ==> 0.48261560015036375\n",
            "Loss in iteration no. 98593 ==> 0.48261461820511425\n",
            "Loss in iteration no. 98594 ==> 0.48261363626876375\n",
            "Loss in iteration no. 98595 ==> 0.48261265434131245\n",
            "Loss in iteration no. 98596 ==> 0.48261167242276026\n",
            "Loss in iteration no. 98597 ==> 0.48261069051310684\n",
            "Loss in iteration no. 98598 ==> 0.4826097086123522\n",
            "Loss in iteration no. 98599 ==> 0.4826087267204963\n",
            "Loss in iteration no. 98600 ==> 0.4826077448375389\n",
            "Loss in iteration no. 98601 ==> 0.4826067629634799\n",
            "Loss in iteration no. 98602 ==> 0.48260578109831925\n",
            "Loss in iteration no. 98603 ==> 0.48260479924205674\n",
            "Loss in iteration no. 98604 ==> 0.48260381739469244\n",
            "Loss in iteration no. 98605 ==> 0.482602835556226\n",
            "Loss in iteration no. 98606 ==> 0.48260185372665754\n",
            "Loss in iteration no. 98607 ==> 0.4826008719059867\n",
            "Loss in iteration no. 98608 ==> 0.4825998900942136\n",
            "Loss in iteration no. 98609 ==> 0.48259890829133806\n",
            "Loss in iteration no. 98610 ==> 0.4825979264973599\n",
            "Loss in iteration no. 98611 ==> 0.4825969447122791\n",
            "Loss in iteration no. 98612 ==> 0.48259596293609547\n",
            "Loss in iteration no. 98613 ==> 0.4825949811688088\n",
            "Loss in iteration no. 98614 ==> 0.4825939994104192\n",
            "Loss in iteration no. 98615 ==> 0.4825930176609263\n",
            "Loss in iteration no. 98616 ==> 0.48259203592033034\n",
            "Loss in iteration no. 98617 ==> 0.4825910541886309\n",
            "Loss in iteration no. 98618 ==> 0.482590072465828\n",
            "Loss in iteration no. 98619 ==> 0.4825890907519215\n",
            "Loss in iteration no. 98620 ==> 0.4825881090469112\n",
            "Loss in iteration no. 98621 ==> 0.48258712735079723\n",
            "Loss in iteration no. 98622 ==> 0.4825861456635792\n",
            "Loss in iteration no. 98623 ==> 0.482585163985257\n",
            "Loss in iteration no. 98624 ==> 0.48258418231583083\n",
            "Loss in iteration no. 98625 ==> 0.4825832006553004\n",
            "Loss in iteration no. 98626 ==> 0.48258221900366555\n",
            "Loss in iteration no. 98627 ==> 0.48258123736092606\n",
            "Loss in iteration no. 98628 ==> 0.4825802557270822\n",
            "Loss in iteration no. 98629 ==> 0.4825792741021333\n",
            "Loss in iteration no. 98630 ==> 0.48257829248607975\n",
            "Loss in iteration no. 98631 ==> 0.48257731087892125\n",
            "Loss in iteration no. 98632 ==> 0.48257632928065763\n",
            "Loss in iteration no. 98633 ==> 0.48257534769128874\n",
            "Loss in iteration no. 98634 ==> 0.48257436611081467\n",
            "Loss in iteration no. 98635 ==> 0.4825733845392352\n",
            "Loss in iteration no. 98636 ==> 0.4825724029765501\n",
            "Loss in iteration no. 98637 ==> 0.4825714214227595\n",
            "Loss in iteration no. 98638 ==> 0.48257043987786297\n",
            "Loss in iteration no. 98639 ==> 0.4825694583418608\n",
            "Loss in iteration no. 98640 ==> 0.48256847681475246\n",
            "Loss in iteration no. 98641 ==> 0.48256749529653814\n",
            "Loss in iteration no. 98642 ==> 0.4825665137872176\n",
            "Loss in iteration no. 98643 ==> 0.4825655322867907\n",
            "Loss in iteration no. 98644 ==> 0.4825645507952575\n",
            "Loss in iteration no. 98645 ==> 0.4825635693126177\n",
            "Loss in iteration no. 98646 ==> 0.48256258783887107\n",
            "Loss in iteration no. 98647 ==> 0.48256160637401785\n",
            "Loss in iteration no. 98648 ==> 0.4825606249180578\n",
            "Loss in iteration no. 98649 ==> 0.4825596434709906\n",
            "Loss in iteration no. 98650 ==> 0.4825586620328164\n",
            "Loss in iteration no. 98651 ==> 0.4825576806035349\n",
            "Loss in iteration no. 98652 ==> 0.4825566991831461\n",
            "Loss in iteration no. 98653 ==> 0.4825557177716499\n",
            "Loss in iteration no. 98654 ==> 0.4825547363690461\n",
            "Loss in iteration no. 98655 ==> 0.48255375497533476\n",
            "Loss in iteration no. 98656 ==> 0.48255277359051557\n",
            "Loss in iteration no. 98657 ==> 0.4825517922145884\n",
            "Loss in iteration no. 98658 ==> 0.48255081084755325\n",
            "Loss in iteration no. 98659 ==> 0.48254982948940994\n",
            "Loss in iteration no. 98660 ==> 0.4825488481401585\n",
            "Loss in iteration no. 98661 ==> 0.48254786679979866\n",
            "Loss in iteration no. 98662 ==> 0.48254688546833036\n",
            "Loss in iteration no. 98663 ==> 0.4825459041457534\n",
            "Loss in iteration no. 98664 ==> 0.48254492283206785\n",
            "Loss in iteration no. 98665 ==> 0.4825439415272735\n",
            "Loss in iteration no. 98666 ==> 0.4825429602313702\n",
            "Loss in iteration no. 98667 ==> 0.482541978944358\n",
            "Loss in iteration no. 98668 ==> 0.4825409976662364\n",
            "Loss in iteration no. 98669 ==> 0.4825400163970058\n",
            "Loss in iteration no. 98670 ==> 0.48253903513666574\n",
            "Loss in iteration no. 98671 ==> 0.4825380538852162\n",
            "Loss in iteration no. 98672 ==> 0.4825370726426571\n",
            "Loss in iteration no. 98673 ==> 0.4825360914089882\n",
            "Loss in iteration no. 98674 ==> 0.4825351101842096\n",
            "Loss in iteration no. 98675 ==> 0.48253412896832104\n",
            "Loss in iteration no. 98676 ==> 0.48253314776132233\n",
            "Loss in iteration no. 98677 ==> 0.4825321665632136\n",
            "Loss in iteration no. 98678 ==> 0.48253118537399453\n",
            "Loss in iteration no. 98679 ==> 0.482530204193665\n",
            "Loss in iteration no. 98680 ==> 0.4825292230222252\n",
            "Loss in iteration no. 98681 ==> 0.48252824185967463\n",
            "Loss in iteration no. 98682 ==> 0.4825272607060134\n",
            "Loss in iteration no. 98683 ==> 0.48252627956124133\n",
            "Loss in iteration no. 98684 ==> 0.48252529842535824\n",
            "Loss in iteration no. 98685 ==> 0.48252431729836415\n",
            "Loss in iteration no. 98686 ==> 0.4825233361802589\n",
            "Loss in iteration no. 98687 ==> 0.4825223550710424\n",
            "Loss in iteration no. 98688 ==> 0.48252137397071443\n",
            "Loss in iteration no. 98689 ==> 0.4825203928792749\n",
            "Loss in iteration no. 98690 ==> 0.4825194117967239\n",
            "Loss in iteration no. 98691 ==> 0.48251843072306116\n",
            "Loss in iteration no. 98692 ==> 0.48251744965828647\n",
            "Loss in iteration no. 98693 ==> 0.48251646860239983\n",
            "Loss in iteration no. 98694 ==> 0.4825154875554011\n",
            "Loss in iteration no. 98695 ==> 0.48251450651729016\n",
            "Loss in iteration no. 98696 ==> 0.4825135254880671\n",
            "Loss in iteration no. 98697 ==> 0.48251254446773145\n",
            "Loss in iteration no. 98698 ==> 0.4825115634562833\n",
            "Loss in iteration no. 98699 ==> 0.4825105824537226\n",
            "Loss in iteration no. 98700 ==> 0.482509601460049\n",
            "Loss in iteration no. 98701 ==> 0.4825086204752626\n",
            "Loss in iteration no. 98702 ==> 0.4825076394993632\n",
            "Loss in iteration no. 98703 ==> 0.4825066585323508\n",
            "Loss in iteration no. 98704 ==> 0.48250567757422513\n",
            "Loss in iteration no. 98705 ==> 0.48250469662498613\n",
            "Loss in iteration no. 98706 ==> 0.4825037156846338\n",
            "Loss in iteration no. 98707 ==> 0.48250273475316785\n",
            "Loss in iteration no. 98708 ==> 0.4825017538305882\n",
            "Loss in iteration no. 98709 ==> 0.48250077291689486\n",
            "Loss in iteration no. 98710 ==> 0.48249979201208754\n",
            "Loss in iteration no. 98711 ==> 0.4824988111161663\n",
            "Loss in iteration no. 98712 ==> 0.48249783022913095\n",
            "Loss in iteration no. 98713 ==> 0.48249684935098136\n",
            "Loss in iteration no. 98714 ==> 0.48249586848171744\n",
            "Loss in iteration no. 98715 ==> 0.4824948876213391\n",
            "Loss in iteration no. 98716 ==> 0.48249390676984616\n",
            "Loss in iteration no. 98717 ==> 0.4824929259272386\n",
            "Loss in iteration no. 98718 ==> 0.48249194509351623\n",
            "Loss in iteration no. 98719 ==> 0.48249096426867893\n",
            "Loss in iteration no. 98720 ==> 0.4824899834527266\n",
            "Loss in iteration no. 98721 ==> 0.4824890026456592\n",
            "Loss in iteration no. 98722 ==> 0.4824880218474765\n",
            "Loss in iteration no. 98723 ==> 0.48248704105817863\n",
            "Loss in iteration no. 98724 ==> 0.48248606027776514\n",
            "Loss in iteration no. 98725 ==> 0.4824850795062361\n",
            "Loss in iteration no. 98726 ==> 0.4824840987435914\n",
            "Loss in iteration no. 98727 ==> 0.4824831179898309\n",
            "Loss in iteration no. 98728 ==> 0.48248213724495453\n",
            "Loss in iteration no. 98729 ==> 0.48248115650896195\n",
            "Loss in iteration no. 98730 ==> 0.4824801757818534\n",
            "Loss in iteration no. 98731 ==> 0.4824791950636285\n",
            "Loss in iteration no. 98732 ==> 0.4824782143542872\n",
            "Loss in iteration no. 98733 ==> 0.48247723365382955\n",
            "Loss in iteration no. 98734 ==> 0.4824762529622554\n",
            "Loss in iteration no. 98735 ==> 0.4824752722795643\n",
            "Loss in iteration no. 98736 ==> 0.4824742916057566\n",
            "Loss in iteration no. 98737 ==> 0.48247331094083185\n",
            "Loss in iteration no. 98738 ==> 0.4824723302847901\n",
            "Loss in iteration no. 98739 ==> 0.48247134963763116\n",
            "Loss in iteration no. 98740 ==> 0.48247036899935497\n",
            "Loss in iteration no. 98741 ==> 0.4824693883699615\n",
            "Loss in iteration no. 98742 ==> 0.4824684077494504\n",
            "Loss in iteration no. 98743 ==> 0.4824674271378217\n",
            "Loss in iteration no. 98744 ==> 0.48246644653507537\n",
            "Loss in iteration no. 98745 ==> 0.4824654659412111\n",
            "Loss in iteration no. 98746 ==> 0.48246448535622893\n",
            "Loss in iteration no. 98747 ==> 0.4824635047801287\n",
            "Loss in iteration no. 98748 ==> 0.48246252421291025\n",
            "Loss in iteration no. 98749 ==> 0.4824615436545736\n",
            "Loss in iteration no. 98750 ==> 0.48246056310511853\n",
            "Loss in iteration no. 98751 ==> 0.48245958256454496\n",
            "Loss in iteration no. 98752 ==> 0.4824586020328527\n",
            "Loss in iteration no. 98753 ==> 0.48245762151004185\n",
            "Loss in iteration no. 98754 ==> 0.482456640996112\n",
            "Loss in iteration no. 98755 ==> 0.48245566049106337\n",
            "Loss in iteration no. 98756 ==> 0.48245467999489555\n",
            "Loss in iteration no. 98757 ==> 0.4824536995076086\n",
            "Loss in iteration no. 98758 ==> 0.48245271902920234\n",
            "Loss in iteration no. 98759 ==> 0.48245173855967655\n",
            "Loss in iteration no. 98760 ==> 0.48245075809903143\n",
            "Loss in iteration no. 98761 ==> 0.4824497776472664\n",
            "Loss in iteration no. 98762 ==> 0.48244879720438183\n",
            "Loss in iteration no. 98763 ==> 0.48244781677037735\n",
            "Loss in iteration no. 98764 ==> 0.48244683634525287\n",
            "Loss in iteration no. 98765 ==> 0.48244585592900835\n",
            "Loss in iteration no. 98766 ==> 0.4824448755216437\n",
            "Loss in iteration no. 98767 ==> 0.4824438951231586\n",
            "Loss in iteration no. 98768 ==> 0.4824429147335531\n",
            "Loss in iteration no. 98769 ==> 0.4824419343528271\n",
            "Loss in iteration no. 98770 ==> 0.4824409539809804\n",
            "Loss in iteration no. 98771 ==> 0.48243997361801305\n",
            "Loss in iteration no. 98772 ==> 0.48243899326392464\n",
            "Loss in iteration no. 98773 ==> 0.4824380129187154\n",
            "Loss in iteration no. 98774 ==> 0.48243703258238496\n",
            "Loss in iteration no. 98775 ==> 0.48243605225493347\n",
            "Loss in iteration no. 98776 ==> 0.4824350719363604\n",
            "Loss in iteration no. 98777 ==> 0.4824340916266661\n",
            "Loss in iteration no. 98778 ==> 0.4824331113258502\n",
            "Loss in iteration no. 98779 ==> 0.48243213103391264\n",
            "Loss in iteration no. 98780 ==> 0.4824311507508533\n",
            "Loss in iteration no. 98781 ==> 0.48243017047667197\n",
            "Loss in iteration no. 98782 ==> 0.4824291902113687\n",
            "Loss in iteration no. 98783 ==> 0.4824282099549433\n",
            "Loss in iteration no. 98784 ==> 0.48242722970739577\n",
            "Loss in iteration no. 98785 ==> 0.48242624946872575\n",
            "Loss in iteration no. 98786 ==> 0.48242526923893336\n",
            "Loss in iteration no. 98787 ==> 0.4824242890180183\n",
            "Loss in iteration no. 98788 ==> 0.48242330880598067\n",
            "Loss in iteration no. 98789 ==> 0.48242232860282025\n",
            "Loss in iteration no. 98790 ==> 0.48242134840853684\n",
            "Loss in iteration no. 98791 ==> 0.48242036822313056\n",
            "Loss in iteration no. 98792 ==> 0.48241938804660106\n",
            "Loss in iteration no. 98793 ==> 0.4824184078789483\n",
            "Loss in iteration no. 98794 ==> 0.4824174277201721\n",
            "Loss in iteration no. 98795 ==> 0.4824164475702725\n",
            "Loss in iteration no. 98796 ==> 0.48241546742924934\n",
            "Loss in iteration no. 98797 ==> 0.48241448729710257\n",
            "Loss in iteration no. 98798 ==> 0.4824135071738319\n",
            "Loss in iteration no. 98799 ==> 0.4824125270594373\n",
            "Loss in iteration no. 98800 ==> 0.48241154695391864\n",
            "Loss in iteration no. 98801 ==> 0.48241056685727585\n",
            "Loss in iteration no. 98802 ==> 0.4824095867695089\n",
            "Loss in iteration no. 98803 ==> 0.48240860669061747\n",
            "Loss in iteration no. 98804 ==> 0.48240762662060155\n",
            "Loss in iteration no. 98805 ==> 0.4824066465594612\n",
            "Loss in iteration no. 98806 ==> 0.4824056665071959\n",
            "Loss in iteration no. 98807 ==> 0.48240468646380597\n",
            "Loss in iteration no. 98808 ==> 0.4824037064292911\n",
            "Loss in iteration no. 98809 ==> 0.48240272640365095\n",
            "Loss in iteration no. 98810 ==> 0.4824017463868859\n",
            "Loss in iteration no. 98811 ==> 0.4824007663789955\n",
            "Loss in iteration no. 98812 ==> 0.48239978637997966\n",
            "Loss in iteration no. 98813 ==> 0.4823988063898383\n",
            "Loss in iteration no. 98814 ==> 0.4823978264085714\n",
            "Loss in iteration no. 98815 ==> 0.4823968464361788\n",
            "Loss in iteration no. 98816 ==> 0.48239586647266036\n",
            "Loss in iteration no. 98817 ==> 0.48239488651801593\n",
            "Loss in iteration no. 98818 ==> 0.4823939065722454\n",
            "Loss in iteration no. 98819 ==> 0.4823929266353487\n",
            "Loss in iteration no. 98820 ==> 0.48239194670732577\n",
            "Loss in iteration no. 98821 ==> 0.48239096678817633\n",
            "Loss in iteration no. 98822 ==> 0.4823899868779006\n",
            "Loss in iteration no. 98823 ==> 0.48238900697649795\n",
            "Loss in iteration no. 98824 ==> 0.48238802708396883\n",
            "Loss in iteration no. 98825 ==> 0.4823870472003127\n",
            "Loss in iteration no. 98826 ==> 0.48238606732552974\n",
            "Loss in iteration no. 98827 ==> 0.48238508745961967\n",
            "Loss in iteration no. 98828 ==> 0.4823841076025823\n",
            "Loss in iteration no. 98829 ==> 0.48238312775441766\n",
            "Loss in iteration no. 98830 ==> 0.4823821479151256\n",
            "Loss in iteration no. 98831 ==> 0.48238116808470627\n",
            "Loss in iteration no. 98832 ==> 0.48238018826315904\n",
            "Loss in iteration no. 98833 ==> 0.48237920845048404\n",
            "Loss in iteration no. 98834 ==> 0.48237822864668134\n",
            "Loss in iteration no. 98835 ==> 0.4823772488517505\n",
            "Loss in iteration no. 98836 ==> 0.48237626906569164\n",
            "Loss in iteration no. 98837 ==> 0.4823752892885046\n",
            "Loss in iteration no. 98838 ==> 0.4823743095201893\n",
            "Loss in iteration no. 98839 ==> 0.4823733297607455\n",
            "Loss in iteration no. 98840 ==> 0.48237235001017303\n",
            "Loss in iteration no. 98841 ==> 0.482371370268472\n",
            "Loss in iteration no. 98842 ==> 0.4823703905356423\n",
            "Loss in iteration no. 98843 ==> 0.4823694108116836\n",
            "Loss in iteration no. 98844 ==> 0.48236843109659605\n",
            "Loss in iteration no. 98845 ==> 0.4823674513903794\n",
            "Loss in iteration no. 98846 ==> 0.48236647169303337\n",
            "Loss in iteration no. 98847 ==> 0.482365492004558\n",
            "Loss in iteration no. 98848 ==> 0.48236451232495337\n",
            "Loss in iteration no. 98849 ==> 0.482363532654219\n",
            "Loss in iteration no. 98850 ==> 0.48236255299235503\n",
            "Loss in iteration no. 98851 ==> 0.48236157333936136\n",
            "Loss in iteration no. 98852 ==> 0.48236059369523776\n",
            "Loss in iteration no. 98853 ==> 0.4823596140599842\n",
            "Loss in iteration no. 98854 ==> 0.4823586344336005\n",
            "Loss in iteration no. 98855 ==> 0.4823576548160864\n",
            "Loss in iteration no. 98856 ==> 0.4823566752074422\n",
            "Loss in iteration no. 98857 ==> 0.4823556956076675\n",
            "Loss in iteration no. 98858 ==> 0.4823547160167622\n",
            "Loss in iteration no. 98859 ==> 0.48235373643472607\n",
            "Loss in iteration no. 98860 ==> 0.4823527568615594\n",
            "Loss in iteration no. 98861 ==> 0.4823517772972617\n",
            "Loss in iteration no. 98862 ==> 0.4823507977418329\n",
            "Loss in iteration no. 98863 ==> 0.4823498181952731\n",
            "Loss in iteration no. 98864 ==> 0.48234883865758194\n",
            "Loss in iteration no. 98865 ==> 0.48234785912875955\n",
            "Loss in iteration no. 98866 ==> 0.4823468796088056\n",
            "Loss in iteration no. 98867 ==> 0.4823459000977202\n",
            "Loss in iteration no. 98868 ==> 0.482344920595503\n",
            "Loss in iteration no. 98869 ==> 0.48234394110215395\n",
            "Loss in iteration no. 98870 ==> 0.4823429616176731\n",
            "Loss in iteration no. 98871 ==> 0.48234198214206014\n",
            "Loss in iteration no. 98872 ==> 0.48234100267531504\n",
            "Loss in iteration no. 98873 ==> 0.4823400232174376\n",
            "Loss in iteration no. 98874 ==> 0.48233904376842796\n",
            "Loss in iteration no. 98875 ==> 0.4823380643282858\n",
            "Loss in iteration no. 98876 ==> 0.48233708489701105\n",
            "Loss in iteration no. 98877 ==> 0.4823361054746035\n",
            "Loss in iteration no. 98878 ==> 0.48233512606106327\n",
            "Loss in iteration no. 98879 ==> 0.4823341466563901\n",
            "Loss in iteration no. 98880 ==> 0.48233316726058384\n",
            "Loss in iteration no. 98881 ==> 0.4823321878736443\n",
            "Loss in iteration no. 98882 ==> 0.4823312084955716\n",
            "Loss in iteration no. 98883 ==> 0.4823302291263655\n",
            "Loss in iteration no. 98884 ==> 0.48232924976602587\n",
            "Loss in iteration no. 98885 ==> 0.4823282704145527\n",
            "Loss in iteration no. 98886 ==> 0.4823272910719459\n",
            "Loss in iteration no. 98887 ==> 0.4823263117382051\n",
            "Loss in iteration no. 98888 ==> 0.4823253324133304\n",
            "Loss in iteration no. 98889 ==> 0.4823243530973217\n",
            "Loss in iteration no. 98890 ==> 0.4823233737901788\n",
            "Loss in iteration no. 98891 ==> 0.4823223944919016\n",
            "Loss in iteration no. 98892 ==> 0.48232141520249\n",
            "Loss in iteration no. 98893 ==> 0.48232043592194396\n",
            "Loss in iteration no. 98894 ==> 0.48231945665026316\n",
            "Loss in iteration no. 98895 ==> 0.48231847738744765\n",
            "Loss in iteration no. 98896 ==> 0.4823174981334976\n",
            "Loss in iteration no. 98897 ==> 0.4823165188884123\n",
            "Loss in iteration no. 98898 ==> 0.48231553965219187\n",
            "Loss in iteration no. 98899 ==> 0.48231456042483656\n",
            "Loss in iteration no. 98900 ==> 0.4823135812063456\n",
            "Loss in iteration no. 98901 ==> 0.48231260199671944\n",
            "Loss in iteration no. 98902 ==> 0.48231162279595763\n",
            "Loss in iteration no. 98903 ==> 0.48231064360406045\n",
            "Loss in iteration no. 98904 ==> 0.48230966442102724\n",
            "Loss in iteration no. 98905 ==> 0.4823086852468584\n",
            "Loss in iteration no. 98906 ==> 0.4823077060815533\n",
            "Loss in iteration no. 98907 ==> 0.48230672692511245\n",
            "Loss in iteration no. 98908 ==> 0.4823057477775352\n",
            "Loss in iteration no. 98909 ==> 0.4823047686388217\n",
            "Loss in iteration no. 98910 ==> 0.4823037895089718\n",
            "Loss in iteration no. 98911 ==> 0.4823028103879854\n",
            "Loss in iteration no. 98912 ==> 0.48230183127586224\n",
            "Loss in iteration no. 98913 ==> 0.4823008521726024\n",
            "Loss in iteration no. 98914 ==> 0.4822998730782057\n",
            "Loss in iteration no. 98915 ==> 0.482298893992672\n",
            "Loss in iteration no. 98916 ==> 0.48229791491600116\n",
            "Loss in iteration no. 98917 ==> 0.4822969358481932\n",
            "Loss in iteration no. 98918 ==> 0.4822959567892478\n",
            "Loss in iteration no. 98919 ==> 0.4822949777391651\n",
            "Loss in iteration no. 98920 ==> 0.48229399869794476\n",
            "Loss in iteration no. 98921 ==> 0.4822930196655869\n",
            "Loss in iteration no. 98922 ==> 0.4822920406420912\n",
            "Loss in iteration no. 98923 ==> 0.4822910616274575\n",
            "Loss in iteration no. 98924 ==> 0.4822900826216859\n",
            "Loss in iteration no. 98925 ==> 0.4822891036247762\n",
            "Loss in iteration no. 98926 ==> 0.4822881246367283\n",
            "Loss in iteration no. 98927 ==> 0.48228714565754194\n",
            "Loss in iteration no. 98928 ==> 0.4822861666872173\n",
            "Loss in iteration no. 98929 ==> 0.48228518772575396\n",
            "Loss in iteration no. 98930 ==> 0.48228420877315215\n",
            "Loss in iteration no. 98931 ==> 0.4822832298294114\n",
            "Loss in iteration no. 98932 ==> 0.4822822508945318\n",
            "Loss in iteration no. 98933 ==> 0.48228127196851317\n",
            "Loss in iteration no. 98934 ==> 0.48228029305135545\n",
            "Loss in iteration no. 98935 ==> 0.48227931414305847\n",
            "Loss in iteration no. 98936 ==> 0.4822783352436222\n",
            "Loss in iteration no. 98937 ==> 0.4822773563530464\n",
            "Loss in iteration no. 98938 ==> 0.482276377471331\n",
            "Loss in iteration no. 98939 ==> 0.48227539859847607\n",
            "Loss in iteration no. 98940 ==> 0.48227441973448126\n",
            "Loss in iteration no. 98941 ==> 0.48227344087934654\n",
            "Loss in iteration no. 98942 ==> 0.4822724620330718\n",
            "Loss in iteration no. 98943 ==> 0.48227148319565705\n",
            "Loss in iteration no. 98944 ==> 0.48227050436710184\n",
            "Loss in iteration no. 98945 ==> 0.4822695255474063\n",
            "Loss in iteration no. 98946 ==> 0.48226854673657055\n",
            "Loss in iteration no. 98947 ==> 0.48226756793459397\n",
            "Loss in iteration no. 98948 ==> 0.4822665891414768\n",
            "Loss in iteration no. 98949 ==> 0.4822656103572188\n",
            "Loss in iteration no. 98950 ==> 0.4822646315818198\n",
            "Loss in iteration no. 98951 ==> 0.48226365281527983\n",
            "Loss in iteration no. 98952 ==> 0.48226267405759865\n",
            "Loss in iteration no. 98953 ==> 0.48226169530877633\n",
            "Loss in iteration no. 98954 ==> 0.48226071656881275\n",
            "Loss in iteration no. 98955 ==> 0.4822597378377075\n",
            "Loss in iteration no. 98956 ==> 0.4822587591154606\n",
            "Loss in iteration no. 98957 ==> 0.48225778040207223\n",
            "Loss in iteration no. 98958 ==> 0.48225680169754187\n",
            "Loss in iteration no. 98959 ==> 0.48225582300186964\n",
            "Loss in iteration no. 98960 ==> 0.48225484431505533\n",
            "Loss in iteration no. 98961 ==> 0.4822538656370989\n",
            "Loss in iteration no. 98962 ==> 0.4822528869680002\n",
            "Loss in iteration no. 98963 ==> 0.48225190830775905\n",
            "Loss in iteration no. 98964 ==> 0.4822509296563755\n",
            "Loss in iteration no. 98965 ==> 0.4822499510138493\n",
            "Loss in iteration no. 98966 ==> 0.48224897238018044\n",
            "Loss in iteration no. 98967 ==> 0.48224799375536875\n",
            "Loss in iteration no. 98968 ==> 0.48224701513941404\n",
            "Loss in iteration no. 98969 ==> 0.4822460365323163\n",
            "Loss in iteration no. 98970 ==> 0.48224505793407535\n",
            "Loss in iteration no. 98971 ==> 0.48224407934469127\n",
            "Loss in iteration no. 98972 ==> 0.4822431007641636\n",
            "Loss in iteration no. 98973 ==> 0.4822421221924927\n",
            "Loss in iteration no. 98974 ==> 0.48224114362967785\n",
            "Loss in iteration no. 98975 ==> 0.48224016507571954\n",
            "Loss in iteration no. 98976 ==> 0.48223918653061737\n",
            "Loss in iteration no. 98977 ==> 0.48223820799437117\n",
            "Loss in iteration no. 98978 ==> 0.48223722946698083\n",
            "Loss in iteration no. 98979 ==> 0.4822362509484463\n",
            "Loss in iteration no. 98980 ==> 0.4822352724387677\n",
            "Loss in iteration no. 98981 ==> 0.4822342939379444\n",
            "Loss in iteration no. 98982 ==> 0.482233315445977\n",
            "Loss in iteration no. 98983 ==> 0.48223233696286455\n",
            "Loss in iteration no. 98984 ==> 0.48223135848860765\n",
            "Loss in iteration no. 98985 ==> 0.48223038002320573\n",
            "Loss in iteration no. 98986 ==> 0.48222940156665894\n",
            "Loss in iteration no. 98987 ==> 0.482228423118967\n",
            "Loss in iteration no. 98988 ==> 0.48222744468012996\n",
            "Loss in iteration no. 98989 ==> 0.4822264662501475\n",
            "Loss in iteration no. 98990 ==> 0.4822254878290197\n",
            "Loss in iteration no. 98991 ==> 0.4822245094167464\n",
            "Loss in iteration no. 98992 ==> 0.4822235310133274\n",
            "Loss in iteration no. 98993 ==> 0.48222255261876273\n",
            "Loss in iteration no. 98994 ==> 0.4822215742330522\n",
            "Loss in iteration no. 98995 ==> 0.48222059585619553\n",
            "Loss in iteration no. 98996 ==> 0.48221961748819303\n",
            "Loss in iteration no. 98997 ==> 0.4822186391290441\n",
            "Loss in iteration no. 98998 ==> 0.4822176607787489\n",
            "Loss in iteration no. 98999 ==> 0.4822166824373073\n",
            "Loss in iteration no. 99000 ==> 0.4822157041047192\n",
            "Loss in iteration no. 99001 ==> 0.4822147257809845\n",
            "Loss in iteration no. 99002 ==> 0.4822137474661029\n",
            "Loss in iteration no. 99003 ==> 0.4822127691600746\n",
            "Loss in iteration no. 99004 ==> 0.48221179086289917\n",
            "Loss in iteration no. 99005 ==> 0.48221081257457665\n",
            "Loss in iteration no. 99006 ==> 0.482209834295107\n",
            "Loss in iteration no. 99007 ==> 0.48220885602448993\n",
            "Loss in iteration no. 99008 ==> 0.4822078777627255\n",
            "Loss in iteration no. 99009 ==> 0.4822068995098136\n",
            "Loss in iteration no. 99010 ==> 0.4822059212657538\n",
            "Loss in iteration no. 99011 ==> 0.4822049430305464\n",
            "Loss in iteration no. 99012 ==> 0.482203964804191\n",
            "Loss in iteration no. 99013 ==> 0.48220298658668775\n",
            "Loss in iteration no. 99014 ==> 0.48220200837803623\n",
            "Loss in iteration no. 99015 ==> 0.4822010301782366\n",
            "Loss in iteration no. 99016 ==> 0.48220005198728877\n",
            "Loss in iteration no. 99017 ==> 0.48219907380519234\n",
            "Loss in iteration no. 99018 ==> 0.48219809563194727\n",
            "Loss in iteration no. 99019 ==> 0.4821971174675538\n",
            "Loss in iteration no. 99020 ==> 0.48219613931201116\n",
            "Loss in iteration no. 99021 ==> 0.48219516116531996\n",
            "Loss in iteration no. 99022 ==> 0.4821941830274795\n",
            "Loss in iteration no. 99023 ==> 0.48219320489849005\n",
            "Loss in iteration no. 99024 ==> 0.48219222677835144\n",
            "Loss in iteration no. 99025 ==> 0.4821912486670633\n",
            "Loss in iteration no. 99026 ==> 0.4821902705646258\n",
            "Loss in iteration no. 99027 ==> 0.48218929247103887\n",
            "Loss in iteration no. 99028 ==> 0.48218831438630205\n",
            "Loss in iteration no. 99029 ==> 0.4821873363104156\n",
            "Loss in iteration no. 99030 ==> 0.4821863582433792\n",
            "Loss in iteration no. 99031 ==> 0.48218538018519264\n",
            "Loss in iteration no. 99032 ==> 0.4821844021358561\n",
            "Loss in iteration no. 99033 ==> 0.48218342409536924\n",
            "Loss in iteration no. 99034 ==> 0.482182446063732\n",
            "Loss in iteration no. 99035 ==> 0.4821814680409444\n",
            "Loss in iteration no. 99036 ==> 0.48218049002700625\n",
            "Loss in iteration no. 99037 ==> 0.4821795120219172\n",
            "Loss in iteration no. 99038 ==> 0.4821785340256775\n",
            "Loss in iteration no. 99039 ==> 0.4821775560382868\n",
            "Loss in iteration no. 99040 ==> 0.4821765780597453\n",
            "Loss in iteration no. 99041 ==> 0.48217560009005245\n",
            "Loss in iteration no. 99042 ==> 0.4821746221292084\n",
            "Loss in iteration no. 99043 ==> 0.4821736441772129\n",
            "Loss in iteration no. 99044 ==> 0.48217266623406607\n",
            "Loss in iteration no. 99045 ==> 0.4821716882997675\n",
            "Loss in iteration no. 99046 ==> 0.48217071037431747\n",
            "Loss in iteration no. 99047 ==> 0.4821697324577153\n",
            "Loss in iteration no. 99048 ==> 0.4821687545499614\n",
            "Loss in iteration no. 99049 ==> 0.4821677766510555\n",
            "Loss in iteration no. 99050 ==> 0.4821667987609973\n",
            "Loss in iteration no. 99051 ==> 0.48216582087978693\n",
            "Loss in iteration no. 99052 ==> 0.48216484300742424\n",
            "Loss in iteration no. 99053 ==> 0.4821638651439089\n",
            "Loss in iteration no. 99054 ==> 0.4821628872892411\n",
            "Loss in iteration no. 99055 ==> 0.4821619094434206\n",
            "Loss in iteration no. 99056 ==> 0.48216093160644724\n",
            "Loss in iteration no. 99057 ==> 0.4821599537783209\n",
            "Loss in iteration no. 99058 ==> 0.4821589759590415\n",
            "Loss in iteration no. 99059 ==> 0.482157998148609\n",
            "Loss in iteration no. 99060 ==> 0.4821570203470231\n",
            "Loss in iteration no. 99061 ==> 0.482156042554284\n",
            "Loss in iteration no. 99062 ==> 0.4821550647703912\n",
            "Loss in iteration no. 99063 ==> 0.48215408699534495\n",
            "Loss in iteration no. 99064 ==> 0.48215310922914495\n",
            "Loss in iteration no. 99065 ==> 0.48215213147179115\n",
            "Loss in iteration no. 99066 ==> 0.4821511537232833\n",
            "Loss in iteration no. 99067 ==> 0.48215017598362153\n",
            "Loss in iteration no. 99068 ==> 0.48214919825280544\n",
            "Loss in iteration no. 99069 ==> 0.4821482205308351\n",
            "Loss in iteration no. 99070 ==> 0.48214724281771043\n",
            "Loss in iteration no. 99071 ==> 0.4821462651134312\n",
            "Loss in iteration no. 99072 ==> 0.48214528741799745\n",
            "Loss in iteration no. 99073 ==> 0.48214430973140887\n",
            "Loss in iteration no. 99074 ==> 0.4821433320536655\n",
            "Loss in iteration no. 99075 ==> 0.48214235438476705\n",
            "Loss in iteration no. 99076 ==> 0.4821413767247137\n",
            "Loss in iteration no. 99077 ==> 0.48214039907350503\n",
            "Loss in iteration no. 99078 ==> 0.48213942143114125\n",
            "Loss in iteration no. 99079 ==> 0.48213844379762183\n",
            "Loss in iteration no. 99080 ==> 0.48213746617294706\n",
            "Loss in iteration no. 99081 ==> 0.48213648855711666\n",
            "Loss in iteration no. 99082 ==> 0.4821355109501305\n",
            "Loss in iteration no. 99083 ==> 0.4821345333519885\n",
            "Loss in iteration no. 99084 ==> 0.4821335557626904\n",
            "Loss in iteration no. 99085 ==> 0.4821325781822364\n",
            "Loss in iteration no. 99086 ==> 0.48213160061062604\n",
            "Loss in iteration no. 99087 ==> 0.48213062304785953\n",
            "Loss in iteration no. 99088 ==> 0.48212964549393655\n",
            "Loss in iteration no. 99089 ==> 0.48212866794885695\n",
            "Loss in iteration no. 99090 ==> 0.48212769041262094\n",
            "Loss in iteration no. 99091 ==> 0.48212671288522785\n",
            "Loss in iteration no. 99092 ==> 0.48212573536667813\n",
            "Loss in iteration no. 99093 ==> 0.48212475785697145\n",
            "Loss in iteration no. 99094 ==> 0.48212378035610765\n",
            "Loss in iteration no. 99095 ==> 0.48212280286408654\n",
            "Loss in iteration no. 99096 ==> 0.48212182538090825\n",
            "Loss in iteration no. 99097 ==> 0.48212084790657245\n",
            "Loss in iteration no. 99098 ==> 0.4821198704410791\n",
            "Loss in iteration no. 99099 ==> 0.48211889298442834\n",
            "Loss in iteration no. 99100 ==> 0.4821179155366196\n",
            "Loss in iteration no. 99101 ==> 0.4821169380976529\n",
            "Loss in iteration no. 99102 ==> 0.4821159606675284\n",
            "Loss in iteration no. 99103 ==> 0.48211498324624574\n",
            "Loss in iteration no. 99104 ==> 0.482114005833805\n",
            "Loss in iteration no. 99105 ==> 0.48211302843020565\n",
            "Loss in iteration no. 99106 ==> 0.4821120510354481\n",
            "Loss in iteration no. 99107 ==> 0.482111073649532\n",
            "Loss in iteration no. 99108 ==> 0.48211009627245716\n",
            "Loss in iteration no. 99109 ==> 0.4821091189042235\n",
            "Loss in iteration no. 99110 ==> 0.48210814154483106\n",
            "Loss in iteration no. 99111 ==> 0.48210716419427957\n",
            "Loss in iteration no. 99112 ==> 0.48210618685256906\n",
            "Loss in iteration no. 99113 ==> 0.48210520951969926\n",
            "Loss in iteration no. 99114 ==> 0.4821042321956701\n",
            "Loss in iteration no. 99115 ==> 0.4821032548804816\n",
            "Loss in iteration no. 99116 ==> 0.4821022775741335\n",
            "Loss in iteration no. 99117 ==> 0.4821013002766257\n",
            "Loss in iteration no. 99118 ==> 0.4821003229879582\n",
            "Loss in iteration no. 99119 ==> 0.48209934570813073\n",
            "Loss in iteration no. 99120 ==> 0.48209836843714327\n",
            "Loss in iteration no. 99121 ==> 0.48209739117499567\n",
            "Loss in iteration no. 99122 ==> 0.48209641392168795\n",
            "Loss in iteration no. 99123 ==> 0.4820954366772197\n",
            "Loss in iteration no. 99124 ==> 0.48209445944159124\n",
            "Loss in iteration no. 99125 ==> 0.4820934822148021\n",
            "Loss in iteration no. 99126 ==> 0.48209250499685224\n",
            "Loss in iteration no. 99127 ==> 0.4820915277877416\n",
            "Loss in iteration no. 99128 ==> 0.48209055058747013\n",
            "Loss in iteration no. 99129 ==> 0.48208957339603775\n",
            "Loss in iteration no. 99130 ==> 0.4820885962134441\n",
            "Loss in iteration no. 99131 ==> 0.48208761903968916\n",
            "Loss in iteration no. 99132 ==> 0.48208664187477307\n",
            "Loss in iteration no. 99133 ==> 0.48208566471869535\n",
            "Loss in iteration no. 99134 ==> 0.4820846875714561\n",
            "Loss in iteration no. 99135 ==> 0.4820837104330552\n",
            "Loss in iteration no. 99136 ==> 0.48208273330349255\n",
            "Loss in iteration no. 99137 ==> 0.4820817561827679\n",
            "Loss in iteration no. 99138 ==> 0.4820807790708812\n",
            "Loss in iteration no. 99139 ==> 0.48207980196783246\n",
            "Loss in iteration no. 99140 ==> 0.4820788248736214\n",
            "Loss in iteration no. 99141 ==> 0.4820778477882481\n",
            "Loss in iteration no. 99142 ==> 0.4820768707117121\n",
            "Loss in iteration no. 99143 ==> 0.48207589364401376\n",
            "Loss in iteration no. 99144 ==> 0.4820749165851526\n",
            "Loss in iteration no. 99145 ==> 0.4820739395351287\n",
            "Loss in iteration no. 99146 ==> 0.4820729624939419\n",
            "Loss in iteration no. 99147 ==> 0.48207198546159197\n",
            "Loss in iteration no. 99148 ==> 0.48207100843807904\n",
            "Loss in iteration no. 99149 ==> 0.48207003142340266\n",
            "Loss in iteration no. 99150 ==> 0.4820690544175631\n",
            "Loss in iteration no. 99151 ==> 0.48206807742056007\n",
            "Loss in iteration no. 99152 ==> 0.4820671004323933\n",
            "Loss in iteration no. 99153 ==> 0.48206612345306293\n",
            "Loss in iteration no. 99154 ==> 0.4820651464825688\n",
            "Loss in iteration no. 99155 ==> 0.48206416952091063\n",
            "Loss in iteration no. 99156 ==> 0.4820631925680885\n",
            "Loss in iteration no. 99157 ==> 0.4820622156241022\n",
            "Loss in iteration no. 99158 ==> 0.4820612386889516\n",
            "Loss in iteration no. 99159 ==> 0.4820602617626366\n",
            "Loss in iteration no. 99160 ==> 0.48205928484515714\n",
            "Loss in iteration no. 99161 ==> 0.4820583079365131\n",
            "Loss in iteration no. 99162 ==> 0.48205733103670445\n",
            "Loss in iteration no. 99163 ==> 0.4820563541457309\n",
            "Loss in iteration no. 99164 ==> 0.4820553772635925\n",
            "Loss in iteration no. 99165 ==> 0.4820544003902889\n",
            "Loss in iteration no. 99166 ==> 0.48205342352582026\n",
            "Loss in iteration no. 99167 ==> 0.4820524466701862\n",
            "Loss in iteration no. 99168 ==> 0.48205146982338687\n",
            "Loss in iteration no. 99169 ==> 0.48205049298542213\n",
            "Loss in iteration no. 99170 ==> 0.4820495161562917\n",
            "Loss in iteration no. 99171 ==> 0.48204853933599556\n",
            "Loss in iteration no. 99172 ==> 0.4820475625245335\n",
            "Loss in iteration no. 99173 ==> 0.4820465857219056\n",
            "Loss in iteration no. 99174 ==> 0.4820456089281116\n",
            "Loss in iteration no. 99175 ==> 0.4820446321431515\n",
            "Loss in iteration no. 99176 ==> 0.4820436553670251\n",
            "Loss in iteration no. 99177 ==> 0.4820426785997323\n",
            "Loss in iteration no. 99178 ==> 0.48204170184127304\n",
            "Loss in iteration no. 99179 ==> 0.4820407250916471\n",
            "Loss in iteration no. 99180 ==> 0.48203974835085445\n",
            "Loss in iteration no. 99181 ==> 0.482038771618895\n",
            "Loss in iteration no. 99182 ==> 0.48203779489576865\n",
            "Loss in iteration no. 99183 ==> 0.48203681818147504\n",
            "Loss in iteration no. 99184 ==> 0.4820358414760144\n",
            "Loss in iteration no. 99185 ==> 0.48203486477938645\n",
            "Loss in iteration no. 99186 ==> 0.4820338880915912\n",
            "Loss in iteration no. 99187 ==> 0.4820329114126283\n",
            "Loss in iteration no. 99188 ==> 0.48203193474249784\n",
            "Loss in iteration no. 99189 ==> 0.48203095808119956\n",
            "Loss in iteration no. 99190 ==> 0.4820299814287335\n",
            "Loss in iteration no. 99191 ==> 0.4820290047850997\n",
            "Loss in iteration no. 99192 ==> 0.48202802815029755\n",
            "Loss in iteration no. 99193 ==> 0.48202705152432734\n",
            "Loss in iteration no. 99194 ==> 0.48202607490718874\n",
            "Loss in iteration no. 99195 ==> 0.48202509829888185\n",
            "Loss in iteration no. 99196 ==> 0.4820241216994064\n",
            "Loss in iteration no. 99197 ==> 0.48202314510876226\n",
            "Loss in iteration no. 99198 ==> 0.4820221685269495\n",
            "Loss in iteration no. 99199 ==> 0.4820211919539677\n",
            "Loss in iteration no. 99200 ==> 0.4820202153898171\n",
            "Loss in iteration no. 99201 ==> 0.4820192388344975\n",
            "Loss in iteration no. 99202 ==> 0.48201826228800865\n",
            "Loss in iteration no. 99203 ==> 0.48201728575035035\n",
            "Loss in iteration no. 99204 ==> 0.48201630922152267\n",
            "Loss in iteration no. 99205 ==> 0.4820153327015255\n",
            "Loss in iteration no. 99206 ==> 0.48201435619035876\n",
            "Loss in iteration no. 99207 ==> 0.48201337968802227\n",
            "Loss in iteration no. 99208 ==> 0.48201240319451594\n",
            "Loss in iteration no. 99209 ==> 0.4820114267098395\n",
            "Loss in iteration no. 99210 ==> 0.48201045023399314\n",
            "Loss in iteration no. 99211 ==> 0.4820094737669765\n",
            "Loss in iteration no. 99212 ==> 0.48200849730878953\n",
            "Loss in iteration no. 99213 ==> 0.48200752085943216\n",
            "Loss in iteration no. 99214 ==> 0.4820065444189043\n",
            "Loss in iteration no. 99215 ==> 0.4820055679872057\n",
            "Loss in iteration no. 99216 ==> 0.4820045915643364\n",
            "Loss in iteration no. 99217 ==> 0.4820036151502962\n",
            "Loss in iteration no. 99218 ==> 0.4820026387450852\n",
            "Loss in iteration no. 99219 ==> 0.48200166234870295\n",
            "Loss in iteration no. 99220 ==> 0.4820006859611495\n",
            "Loss in iteration no. 99221 ==> 0.4819997095824248\n",
            "Loss in iteration no. 99222 ==> 0.4819987332125286\n",
            "Loss in iteration no. 99223 ==> 0.4819977568514609\n",
            "Loss in iteration no. 99224 ==> 0.48199678049922146\n",
            "Loss in iteration no. 99225 ==> 0.48199580415581045\n",
            "Loss in iteration no. 99226 ==> 0.4819948278212275\n",
            "Loss in iteration no. 99227 ==> 0.48199385149547247\n",
            "Loss in iteration no. 99228 ==> 0.4819928751785454\n",
            "Loss in iteration no. 99229 ==> 0.4819918988704461\n",
            "Loss in iteration no. 99230 ==> 0.48199092257117454\n",
            "Loss in iteration no. 99231 ==> 0.48198994628073044\n",
            "Loss in iteration no. 99232 ==> 0.48198896999911384\n",
            "Loss in iteration no. 99233 ==> 0.4819879937263246\n",
            "Loss in iteration no. 99234 ==> 0.48198701746236255\n",
            "Loss in iteration no. 99235 ==> 0.48198604120722777\n",
            "Loss in iteration no. 99236 ==> 0.4819850649609198\n",
            "Loss in iteration no. 99237 ==> 0.48198408872343884\n",
            "Loss in iteration no. 99238 ==> 0.4819831124947847\n",
            "Loss in iteration no. 99239 ==> 0.4819821362749571\n",
            "Loss in iteration no. 99240 ==> 0.48198116006395614\n",
            "Loss in iteration no. 99241 ==> 0.48198018386178165\n",
            "Loss in iteration no. 99242 ==> 0.48197920766843344\n",
            "Loss in iteration no. 99243 ==> 0.48197823148391145\n",
            "Loss in iteration no. 99244 ==> 0.4819772553082157\n",
            "Loss in iteration no. 99245 ==> 0.48197627914134583\n",
            "Loss in iteration no. 99246 ==> 0.48197530298330177\n",
            "Loss in iteration no. 99247 ==> 0.4819743268340836\n",
            "Loss in iteration no. 99248 ==> 0.48197335069369107\n",
            "Loss in iteration no. 99249 ==> 0.48197237456212416\n",
            "Loss in iteration no. 99250 ==> 0.48197139843938264\n",
            "Loss in iteration no. 99251 ==> 0.48197042232546644\n",
            "Loss in iteration no. 99252 ==> 0.4819694462203754\n",
            "Loss in iteration no. 99253 ==> 0.4819684701241096\n",
            "Loss in iteration no. 99254 ==> 0.48196749403666866\n",
            "Loss in iteration no. 99255 ==> 0.4819665179580527\n",
            "Loss in iteration no. 99256 ==> 0.4819655418882615\n",
            "Loss in iteration no. 99257 ==> 0.4819645658272949\n",
            "Loss in iteration no. 99258 ==> 0.48196358977515297\n",
            "Loss in iteration no. 99259 ==> 0.48196261373183535\n",
            "Loss in iteration no. 99260 ==> 0.48196163769734196\n",
            "Loss in iteration no. 99261 ==> 0.481960661671673\n",
            "Loss in iteration no. 99262 ==> 0.4819596856548279\n",
            "Loss in iteration no. 99263 ==> 0.48195870964680704\n",
            "Loss in iteration no. 99264 ==> 0.48195773364761\n",
            "Loss in iteration no. 99265 ==> 0.4819567576572366\n",
            "Loss in iteration no. 99266 ==> 0.4819557816756869\n",
            "Loss in iteration no. 99267 ==> 0.48195480570296073\n",
            "Loss in iteration no. 99268 ==> 0.48195382973905804\n",
            "Loss in iteration no. 99269 ==> 0.4819528537839787\n",
            "Loss in iteration no. 99270 ==> 0.48195187783772253\n",
            "Loss in iteration no. 99271 ==> 0.48195090190028944\n",
            "Loss in iteration no. 99272 ==> 0.48194992597167924\n",
            "Loss in iteration no. 99273 ==> 0.4819489500518921\n",
            "Loss in iteration no. 99274 ==> 0.48194797414092755\n",
            "Loss in iteration no. 99275 ==> 0.48194699823878573\n",
            "Loss in iteration no. 99276 ==> 0.48194602234546646\n",
            "Loss in iteration no. 99277 ==> 0.4819450464609694\n",
            "Loss in iteration no. 99278 ==> 0.48194407058529487\n",
            "Loss in iteration no. 99279 ==> 0.48194309471844254\n",
            "Loss in iteration no. 99280 ==> 0.48194211886041227\n",
            "Loss in iteration no. 99281 ==> 0.4819411430112039\n",
            "Loss in iteration no. 99282 ==> 0.48194016717081734\n",
            "Loss in iteration no. 99283 ==> 0.48193919133925284\n",
            "Loss in iteration no. 99284 ==> 0.4819382155165097\n",
            "Loss in iteration no. 99285 ==> 0.4819372397025883\n",
            "Loss in iteration no. 99286 ==> 0.48193626389748806\n",
            "Loss in iteration no. 99287 ==> 0.4819352881012093\n",
            "Loss in iteration no. 99288 ==> 0.48193431231375167\n",
            "Loss in iteration no. 99289 ==> 0.48193333653511494\n",
            "Loss in iteration no. 99290 ==> 0.48193236076529944\n",
            "Loss in iteration no. 99291 ==> 0.4819313850043047\n",
            "Loss in iteration no. 99292 ==> 0.4819304092521307\n",
            "Loss in iteration no. 99293 ==> 0.48192943350877737\n",
            "Loss in iteration no. 99294 ==> 0.4819284577742447\n",
            "Loss in iteration no. 99295 ==> 0.4819274820485322\n",
            "Loss in iteration no. 99296 ==> 0.4819265063316401\n",
            "Loss in iteration no. 99297 ==> 0.48192553062356824\n",
            "Loss in iteration no. 99298 ==> 0.4819245549243163\n",
            "Loss in iteration no. 99299 ==> 0.48192357923388435\n",
            "Loss in iteration no. 99300 ==> 0.4819226035522724\n",
            "Loss in iteration no. 99301 ==> 0.48192162787948\n",
            "Loss in iteration no. 99302 ==> 0.4819206522155074\n",
            "Loss in iteration no. 99303 ==> 0.4819196765603542\n",
            "Loss in iteration no. 99304 ==> 0.4819187009140205\n",
            "Loss in iteration no. 99305 ==> 0.481917725276506\n",
            "Loss in iteration no. 99306 ==> 0.48191674964781067\n",
            "Loss in iteration no. 99307 ==> 0.48191577402793456\n",
            "Loss in iteration no. 99308 ==> 0.4819147984168773\n",
            "Loss in iteration no. 99309 ==> 0.48191382281463885\n",
            "Loss in iteration no. 99310 ==> 0.48191284722121924\n",
            "Loss in iteration no. 99311 ==> 0.4819118716366182\n",
            "Loss in iteration no. 99312 ==> 0.4819108960608356\n",
            "Loss in iteration no. 99313 ==> 0.48190992049387144\n",
            "Loss in iteration no. 99314 ==> 0.4819089449357255\n",
            "Loss in iteration no. 99315 ==> 0.4819079693863979\n",
            "Loss in iteration no. 99316 ==> 0.4819069938458883\n",
            "Loss in iteration no. 99317 ==> 0.4819060183141966\n",
            "Loss in iteration no. 99318 ==> 0.4819050427913228\n",
            "Loss in iteration no. 99319 ==> 0.4819040672772667\n",
            "Loss in iteration no. 99320 ==> 0.4819030917720282\n",
            "Loss in iteration no. 99321 ==> 0.48190211627560725\n",
            "Loss in iteration no. 99322 ==> 0.4819011407880036\n",
            "Loss in iteration no. 99323 ==> 0.4819001653092172\n",
            "Loss in iteration no. 99324 ==> 0.4818991898392482\n",
            "Loss in iteration no. 99325 ==> 0.48189821437809605\n",
            "Loss in iteration no. 99326 ==> 0.481897238925761\n",
            "Loss in iteration no. 99327 ==> 0.48189626348224257\n",
            "Loss in iteration no. 99328 ==> 0.48189528804754106\n",
            "Loss in iteration no. 99329 ==> 0.481894312621656\n",
            "Loss in iteration no. 99330 ==> 0.4818933372045876\n",
            "Loss in iteration no. 99331 ==> 0.48189236179633554\n",
            "Loss in iteration no. 99332 ==> 0.48189138639689977\n",
            "Loss in iteration no. 99333 ==> 0.4818904110062801\n",
            "Loss in iteration no. 99334 ==> 0.4818894356244765\n",
            "Loss in iteration no. 99335 ==> 0.48188846025148885\n",
            "Loss in iteration no. 99336 ==> 0.4818874848873171\n",
            "Loss in iteration no. 99337 ==> 0.481886509531961\n",
            "Loss in iteration no. 99338 ==> 0.4818855341854205\n",
            "Loss in iteration no. 99339 ==> 0.4818845588476955\n",
            "Loss in iteration no. 99340 ==> 0.48188358351878585\n",
            "Loss in iteration no. 99341 ==> 0.4818826081986914\n",
            "Loss in iteration no. 99342 ==> 0.4818816328874123\n",
            "Loss in iteration no. 99343 ==> 0.4818806575849481\n",
            "Loss in iteration no. 99344 ==> 0.48187968229129896\n",
            "Loss in iteration no. 99345 ==> 0.48187870700646457\n",
            "Loss in iteration no. 99346 ==> 0.48187773173044485\n",
            "Loss in iteration no. 99347 ==> 0.4818767564632398\n",
            "Loss in iteration no. 99348 ==> 0.4818757812048492\n",
            "Loss in iteration no. 99349 ==> 0.481874805955273\n",
            "Loss in iteration no. 99350 ==> 0.4818738307145112\n",
            "Loss in iteration no. 99351 ==> 0.4818728554825633\n",
            "Loss in iteration no. 99352 ==> 0.48187188025942956\n",
            "Loss in iteration no. 99353 ==> 0.48187090504510977\n",
            "Loss in iteration no. 99354 ==> 0.48186992983960375\n",
            "Loss in iteration no. 99355 ==> 0.4818689546429114\n",
            "Loss in iteration no. 99356 ==> 0.4818679794550328\n",
            "Loss in iteration no. 99357 ==> 0.48186700427596746\n",
            "Loss in iteration no. 99358 ==> 0.4818660291057156\n",
            "Loss in iteration no. 99359 ==> 0.4818650539442771\n",
            "Loss in iteration no. 99360 ==> 0.4818640787916517\n",
            "Loss in iteration no. 99361 ==> 0.48186310364783935\n",
            "Loss in iteration no. 99362 ==> 0.4818621285128399\n",
            "Loss in iteration no. 99363 ==> 0.4818611533866532\n",
            "Loss in iteration no. 99364 ==> 0.48186017826927924\n",
            "Loss in iteration no. 99365 ==> 0.48185920316071784\n",
            "Loss in iteration no. 99366 ==> 0.48185822806096895\n",
            "Loss in iteration no. 99367 ==> 0.4818572529700325\n",
            "Loss in iteration no. 99368 ==> 0.4818562778879082\n",
            "Loss in iteration no. 99369 ==> 0.4818553028145961\n",
            "Loss in iteration no. 99370 ==> 0.481854327750096\n",
            "Loss in iteration no. 99371 ==> 0.48185335269440793\n",
            "Loss in iteration no. 99372 ==> 0.4818523776475315\n",
            "Loss in iteration no. 99373 ==> 0.48185140260946685\n",
            "Loss in iteration no. 99374 ==> 0.4818504275802138\n",
            "Loss in iteration no. 99375 ==> 0.48184945255977213\n",
            "Loss in iteration no. 99376 ==> 0.4818484775481419\n",
            "Loss in iteration no. 99377 ==> 0.481847502545323\n",
            "Loss in iteration no. 99378 ==> 0.4818465275513152\n",
            "Loss in iteration no. 99379 ==> 0.4818455525661183\n",
            "Loss in iteration no. 99380 ==> 0.4818445775897325\n",
            "Loss in iteration no. 99381 ==> 0.48184360262215736\n",
            "Loss in iteration no. 99382 ==> 0.481842627663393\n",
            "Loss in iteration no. 99383 ==> 0.48184165271343915\n",
            "Loss in iteration no. 99384 ==> 0.48184067777229583\n",
            "Loss in iteration no. 99385 ==> 0.48183970283996275\n",
            "Loss in iteration no. 99386 ==> 0.48183872791644017\n",
            "Loss in iteration no. 99387 ==> 0.48183775300172754\n",
            "Loss in iteration no. 99388 ==> 0.4818367780958248\n",
            "Loss in iteration no. 99389 ==> 0.4818358031987323\n",
            "Loss in iteration no. 99390 ==> 0.4818348283104494\n",
            "Loss in iteration no. 99391 ==> 0.4818338534309762\n",
            "Loss in iteration no. 99392 ==> 0.48183287856031254\n",
            "Loss in iteration no. 99393 ==> 0.4818319036984584\n",
            "Loss in iteration no. 99394 ==> 0.4818309288454137\n",
            "Loss in iteration no. 99395 ==> 0.48182995400117823\n",
            "Loss in iteration no. 99396 ==> 0.48182897916575174\n",
            "Loss in iteration no. 99397 ==> 0.4818280043391343\n",
            "Loss in iteration no. 99398 ==> 0.4818270295213258\n",
            "Loss in iteration no. 99399 ==> 0.48182605471232615\n",
            "Loss in iteration no. 99400 ==> 0.4818250799121352\n",
            "Loss in iteration no. 99401 ==> 0.48182410512075274\n",
            "Loss in iteration no. 99402 ==> 0.48182313033817875\n",
            "Loss in iteration no. 99403 ==> 0.4818221555644132\n",
            "Loss in iteration no. 99404 ==> 0.48182118079945585\n",
            "Loss in iteration no. 99405 ==> 0.4818202060433065\n",
            "Loss in iteration no. 99406 ==> 0.4818192312959652\n",
            "Loss in iteration no. 99407 ==> 0.48181825655743205\n",
            "Loss in iteration no. 99408 ==> 0.4818172818277064\n",
            "Loss in iteration no. 99409 ==> 0.4818163071067885\n",
            "Loss in iteration no. 99410 ==> 0.48181533239467833\n",
            "Loss in iteration no. 99411 ==> 0.4818143576913755\n",
            "Loss in iteration no. 99412 ==> 0.48181338299688004\n",
            "Loss in iteration no. 99413 ==> 0.48181240831119176\n",
            "Loss in iteration no. 99414 ==> 0.4818114336343106\n",
            "Loss in iteration no. 99415 ==> 0.48181045896623653\n",
            "Loss in iteration no. 99416 ==> 0.4818094843069693\n",
            "Loss in iteration no. 99417 ==> 0.4818085096565088\n",
            "Loss in iteration no. 99418 ==> 0.4818075350148551\n",
            "Loss in iteration no. 99419 ==> 0.4818065603820079\n",
            "Loss in iteration no. 99420 ==> 0.4818055857579671\n",
            "Loss in iteration no. 99421 ==> 0.4818046111427328\n",
            "Loss in iteration no. 99422 ==> 0.4818036365363046\n",
            "Loss in iteration no. 99423 ==> 0.48180266193868254\n",
            "Loss in iteration no. 99424 ==> 0.48180168734986645\n",
            "Loss in iteration no. 99425 ==> 0.48180071276985637\n",
            "Loss in iteration no. 99426 ==> 0.48179973819865196\n",
            "Loss in iteration no. 99427 ==> 0.4817987636362534\n",
            "Loss in iteration no. 99428 ==> 0.4817977890826602\n",
            "Loss in iteration no. 99429 ==> 0.48179681453787254\n",
            "Loss in iteration no. 99430 ==> 0.4817958400018902\n",
            "Loss in iteration no. 99431 ==> 0.4817948654747132\n",
            "Loss in iteration no. 99432 ==> 0.48179389095634106\n",
            "Loss in iteration no. 99433 ==> 0.48179291644677413\n",
            "Loss in iteration no. 99434 ==> 0.48179194194601205\n",
            "Loss in iteration no. 99435 ==> 0.48179096745405475\n",
            "Loss in iteration no. 99436 ==> 0.48178999297090214\n",
            "Loss in iteration no. 99437 ==> 0.48178901849655403\n",
            "Loss in iteration no. 99438 ==> 0.48178804403101044\n",
            "Loss in iteration no. 99439 ==> 0.4817870695742711\n",
            "Loss in iteration no. 99440 ==> 0.4817860951263361\n",
            "Loss in iteration no. 99441 ==> 0.4817851206872051\n",
            "Loss in iteration no. 99442 ==> 0.48178414625687804\n",
            "Loss in iteration no. 99443 ==> 0.48178317183535496\n",
            "Loss in iteration no. 99444 ==> 0.48178219742263567\n",
            "Loss in iteration no. 99445 ==> 0.48178122301872006\n",
            "Loss in iteration no. 99446 ==> 0.48178024862360797\n",
            "Loss in iteration no. 99447 ==> 0.4817792742372994\n",
            "Loss in iteration no. 99448 ==> 0.481778299859794\n",
            "Loss in iteration no. 99449 ==> 0.481777325491092\n",
            "Loss in iteration no. 99450 ==> 0.481776351131193\n",
            "Loss in iteration no. 99451 ==> 0.48177537678009696\n",
            "Loss in iteration no. 99452 ==> 0.48177440243780395\n",
            "Loss in iteration no. 99453 ==> 0.48177342810431356\n",
            "Loss in iteration no. 99454 ==> 0.481772453779626\n",
            "Loss in iteration no. 99455 ==> 0.4817714794637407\n",
            "Loss in iteration no. 99456 ==> 0.4817705051566581\n",
            "Loss in iteration no. 99457 ==> 0.48176953085837787\n",
            "Loss in iteration no. 99458 ==> 0.4817685565688996\n",
            "Loss in iteration no. 99459 ==> 0.4817675822882237\n",
            "Loss in iteration no. 99460 ==> 0.48176660801634974\n",
            "Loss in iteration no. 99461 ==> 0.48176563375327747\n",
            "Loss in iteration no. 99462 ==> 0.48176465949900715\n",
            "Loss in iteration no. 99463 ==> 0.48176368525353835\n",
            "Loss in iteration no. 99464 ==> 0.4817627110168713\n",
            "Loss in iteration no. 99465 ==> 0.4817617367890056\n",
            "Loss in iteration no. 99466 ==> 0.48176076256994116\n",
            "Loss in iteration no. 99467 ==> 0.481759788359678\n",
            "Loss in iteration no. 99468 ==> 0.4817588141582159\n",
            "Loss in iteration no. 99469 ==> 0.4817578399655549\n",
            "Loss in iteration no. 99470 ==> 0.48175686578169463\n",
            "Loss in iteration no. 99471 ==> 0.4817558916066352\n",
            "Loss in iteration no. 99472 ==> 0.48175491744037635\n",
            "Loss in iteration no. 99473 ==> 0.4817539432829182\n",
            "Loss in iteration no. 99474 ==> 0.48175296913426024\n",
            "Loss in iteration no. 99475 ==> 0.4817519949944028\n",
            "Loss in iteration no. 99476 ==> 0.4817510208633456\n",
            "Loss in iteration no. 99477 ==> 0.4817500467410884\n",
            "Loss in iteration no. 99478 ==> 0.4817490726276312\n",
            "Loss in iteration no. 99479 ==> 0.4817480985229738\n",
            "Loss in iteration no. 99480 ==> 0.48174712442711637\n",
            "Loss in iteration no. 99481 ==> 0.48174615034005835\n",
            "Loss in iteration no. 99482 ==> 0.4817451762618001\n",
            "Loss in iteration no. 99483 ==> 0.48174420219234115\n",
            "Loss in iteration no. 99484 ==> 0.4817432281316816\n",
            "Loss in iteration no. 99485 ==> 0.48174225407982113\n",
            "Loss in iteration no. 99486 ==> 0.48174128003676\n",
            "Loss in iteration no. 99487 ==> 0.4817403060024977\n",
            "Loss in iteration no. 99488 ==> 0.48173933197703406\n",
            "Loss in iteration no. 99489 ==> 0.48173835796036946\n",
            "Loss in iteration no. 99490 ==> 0.4817373839525035\n",
            "Loss in iteration no. 99491 ==> 0.481736409953436\n",
            "Loss in iteration no. 99492 ==> 0.481735435963167\n",
            "Loss in iteration no. 99493 ==> 0.48173446198169617\n",
            "Loss in iteration no. 99494 ==> 0.4817334880090237\n",
            "Loss in iteration no. 99495 ==> 0.4817325140451492\n",
            "Loss in iteration no. 99496 ==> 0.4817315400900727\n",
            "Loss in iteration no. 99497 ==> 0.48173056614379417\n",
            "Loss in iteration no. 99498 ==> 0.48172959220631334\n",
            "Loss in iteration no. 99499 ==> 0.48172861827763014\n",
            "Loss in iteration no. 99500 ==> 0.4817276443577446\n",
            "Loss in iteration no. 99501 ==> 0.4817266704466564\n",
            "Loss in iteration no. 99502 ==> 0.4817256965443655\n",
            "Loss in iteration no. 99503 ==> 0.4817247226508718\n",
            "Loss in iteration no. 99504 ==> 0.48172374876617513\n",
            "Loss in iteration no. 99505 ==> 0.4817227748902755\n",
            "Loss in iteration no. 99506 ==> 0.4817218010231727\n",
            "Loss in iteration no. 99507 ==> 0.4817208271648667\n",
            "Loss in iteration no. 99508 ==> 0.4817198533153574\n",
            "Loss in iteration no. 99509 ==> 0.48171887947464453\n",
            "Loss in iteration no. 99510 ==> 0.48171790564272826\n",
            "Loss in iteration no. 99511 ==> 0.4817169318196081\n",
            "Loss in iteration no. 99512 ==> 0.4817159580052843\n",
            "Loss in iteration no. 99513 ==> 0.48171498419975645\n",
            "Loss in iteration no. 99514 ==> 0.4817140104030246\n",
            "Loss in iteration no. 99515 ==> 0.48171303661508874\n",
            "Loss in iteration no. 99516 ==> 0.4817120628359485\n",
            "Loss in iteration no. 99517 ==> 0.48171108906560395\n",
            "Loss in iteration no. 99518 ==> 0.481710115304055\n",
            "Loss in iteration no. 99519 ==> 0.4817091415513015\n",
            "Loss in iteration no. 99520 ==> 0.4817081678073431\n",
            "Loss in iteration no. 99521 ==> 0.4817071940721801\n",
            "Loss in iteration no. 99522 ==> 0.4817062203458121\n",
            "Loss in iteration no. 99523 ==> 0.48170524662823916\n",
            "Loss in iteration no. 99524 ==> 0.4817042729194609\n",
            "Loss in iteration no. 99525 ==> 0.48170329921947747\n",
            "Loss in iteration no. 99526 ==> 0.4817023255282887\n",
            "Loss in iteration no. 99527 ==> 0.4817013518458944\n",
            "Loss in iteration no. 99528 ==> 0.4817003781722946\n",
            "Loss in iteration no. 99529 ==> 0.4816994045074891\n",
            "Loss in iteration no. 99530 ==> 0.4816984308514778\n",
            "Loss in iteration no. 99531 ==> 0.4816974572042606\n",
            "Loss in iteration no. 99532 ==> 0.4816964835658374\n",
            "Loss in iteration no. 99533 ==> 0.481695509936208\n",
            "Loss in iteration no. 99534 ==> 0.4816945363153724\n",
            "Loss in iteration no. 99535 ==> 0.4816935627033304\n",
            "Loss in iteration no. 99536 ==> 0.48169258910008195\n",
            "Loss in iteration no. 99537 ==> 0.4816916155056269\n",
            "Loss in iteration no. 99538 ==> 0.4816906419199652\n",
            "Loss in iteration no. 99539 ==> 0.4816896683430966\n",
            "Loss in iteration no. 99540 ==> 0.48168869477502113\n",
            "Loss in iteration no. 99541 ==> 0.4816877212157386\n",
            "Loss in iteration no. 99542 ==> 0.48168674766524916\n",
            "Loss in iteration no. 99543 ==> 0.4816857741235522\n",
            "Loss in iteration no. 99544 ==> 0.4816848005906479\n",
            "Loss in iteration no. 99545 ==> 0.4816838270665362\n",
            "Loss in iteration no. 99546 ==> 0.4816828535512168\n",
            "Loss in iteration no. 99547 ==> 0.48168188004468987\n",
            "Loss in iteration no. 99548 ==> 0.4816809065469552\n",
            "Loss in iteration no. 99549 ==> 0.4816799330580125\n",
            "Loss in iteration no. 99550 ==> 0.48167895957786167\n",
            "Loss in iteration no. 99551 ==> 0.48167798610650275\n",
            "Loss in iteration no. 99552 ==> 0.4816770126439357\n",
            "Loss in iteration no. 99553 ==> 0.4816760391901602\n",
            "Loss in iteration no. 99554 ==> 0.48167506574517616\n",
            "Loss in iteration no. 99555 ==> 0.4816740923089836\n",
            "Loss in iteration no. 99556 ==> 0.4816731188815823\n",
            "Loss in iteration no. 99557 ==> 0.48167214546297227\n",
            "Loss in iteration no. 99558 ==> 0.4816711720531533\n",
            "Loss in iteration no. 99559 ==> 0.48167019865212535\n",
            "Loss in iteration no. 99560 ==> 0.48166922525988815\n",
            "Loss in iteration no. 99561 ==> 0.48166825187644174\n",
            "Loss in iteration no. 99562 ==> 0.481667278501786\n",
            "Loss in iteration no. 99563 ==> 0.48166630513592074\n",
            "Loss in iteration no. 99564 ==> 0.48166533177884585\n",
            "Loss in iteration no. 99565 ==> 0.4816643584305612\n",
            "Loss in iteration no. 99566 ==> 0.4816633850910669\n",
            "Loss in iteration no. 99567 ==> 0.48166241176036256\n",
            "Loss in iteration no. 99568 ==> 0.48166143843844833\n",
            "Loss in iteration no. 99569 ==> 0.48166046512532396\n",
            "Loss in iteration no. 99570 ==> 0.4816594918209892\n",
            "Loss in iteration no. 99571 ==> 0.4816585185254441\n",
            "Loss in iteration no. 99572 ==> 0.4816575452386886\n",
            "Loss in iteration no. 99573 ==> 0.4816565719607225\n",
            "Loss in iteration no. 99574 ==> 0.48165559869154567\n",
            "Loss in iteration no. 99575 ==> 0.48165462543115795\n",
            "Loss in iteration no. 99576 ==> 0.4816536521795594\n",
            "Loss in iteration no. 99577 ==> 0.48165267893674973\n",
            "Loss in iteration no. 99578 ==> 0.4816517057027291\n",
            "Loss in iteration no. 99579 ==> 0.4816507324774971\n",
            "Loss in iteration no. 99580 ==> 0.4816497592610538\n",
            "Loss in iteration no. 99581 ==> 0.48164878605339884\n",
            "Loss in iteration no. 99582 ==> 0.4816478128545324\n",
            "Loss in iteration no. 99583 ==> 0.4816468396644543\n",
            "Loss in iteration no. 99584 ==> 0.48164586648316426\n",
            "Loss in iteration no. 99585 ==> 0.48164489331066246\n",
            "Loss in iteration no. 99586 ==> 0.4816439201469486\n",
            "Loss in iteration no. 99587 ==> 0.4816429469920225\n",
            "Loss in iteration no. 99588 ==> 0.4816419738458842\n",
            "Loss in iteration no. 99589 ==> 0.4816410007085335\n",
            "Loss in iteration no. 99590 ==> 0.48164002757997043\n",
            "Loss in iteration no. 99591 ==> 0.48163905446019467\n",
            "Loss in iteration no. 99592 ==> 0.4816380813492062\n",
            "Loss in iteration no. 99593 ==> 0.4816371082470048\n",
            "Loss in iteration no. 99594 ==> 0.48163613515359077\n",
            "Loss in iteration no. 99595 ==> 0.4816351620689635\n",
            "Loss in iteration no. 99596 ==> 0.4816341889931232\n",
            "Loss in iteration no. 99597 ==> 0.4816332159260695\n",
            "Loss in iteration no. 99598 ==> 0.4816322428678025\n",
            "Loss in iteration no. 99599 ==> 0.48163126981832205\n",
            "Loss in iteration no. 99600 ==> 0.481630296777628\n",
            "Loss in iteration no. 99601 ==> 0.4816293237457201\n",
            "Loss in iteration no. 99602 ==> 0.48162835072259863\n",
            "Loss in iteration no. 99603 ==> 0.4816273777082632\n",
            "Loss in iteration no. 99604 ==> 0.4816264047027136\n",
            "Loss in iteration no. 99605 ==> 0.4816254317059499\n",
            "Loss in iteration no. 99606 ==> 0.481624458717972\n",
            "Loss in iteration no. 99607 ==> 0.4816234857387797\n",
            "Loss in iteration no. 99608 ==> 0.4816225127683728\n",
            "Loss in iteration no. 99609 ==> 0.4816215398067514\n",
            "Loss in iteration no. 99610 ==> 0.48162056685391536\n",
            "Loss in iteration no. 99611 ==> 0.4816195939098643\n",
            "Loss in iteration no. 99612 ==> 0.4816186209745985\n",
            "Loss in iteration no. 99613 ==> 0.4816176480481177\n",
            "Loss in iteration no. 99614 ==> 0.4816166751304218\n",
            "Loss in iteration no. 99615 ==> 0.4816157022215104\n",
            "Loss in iteration no. 99616 ==> 0.4816147293213837\n",
            "Loss in iteration no. 99617 ==> 0.4816137564300417\n",
            "Loss in iteration no. 99618 ==> 0.4816127835474838\n",
            "Loss in iteration no. 99619 ==> 0.4816118106737104\n",
            "Loss in iteration no. 99620 ==> 0.48161083780872127\n",
            "Loss in iteration no. 99621 ==> 0.48160986495251606\n",
            "Loss in iteration no. 99622 ==> 0.48160889210509483\n",
            "Loss in iteration no. 99623 ==> 0.4816079192664574\n",
            "Loss in iteration no. 99624 ==> 0.4816069464366038\n",
            "Loss in iteration no. 99625 ==> 0.4816059736155339\n",
            "Loss in iteration no. 99626 ==> 0.48160500080324753\n",
            "Loss in iteration no. 99627 ==> 0.48160402799974433\n",
            "Loss in iteration no. 99628 ==> 0.48160305520502456\n",
            "Loss in iteration no. 99629 ==> 0.4816020824190881\n",
            "Loss in iteration no. 99630 ==> 0.4816011096419344\n",
            "Loss in iteration no. 99631 ==> 0.48160013687356396\n",
            "Loss in iteration no. 99632 ==> 0.48159916411397624\n",
            "Loss in iteration no. 99633 ==> 0.4815981913631712\n",
            "Loss in iteration no. 99634 ==> 0.48159721862114896\n",
            "Loss in iteration no. 99635 ==> 0.4815962458879092\n",
            "Loss in iteration no. 99636 ==> 0.48159527316345185\n",
            "Loss in iteration no. 99637 ==> 0.48159430044777674\n",
            "Loss in iteration no. 99638 ==> 0.48159332774088376\n",
            "Loss in iteration no. 99639 ==> 0.4815923550427729\n",
            "Loss in iteration no. 99640 ==> 0.4815913823534441\n",
            "Loss in iteration no. 99641 ==> 0.48159040967289707\n",
            "Loss in iteration no. 99642 ==> 0.48158943700113166\n",
            "Loss in iteration no. 99643 ==> 0.4815884643381481\n",
            "Loss in iteration no. 99644 ==> 0.48158749168394593\n",
            "Loss in iteration no. 99645 ==> 0.48158651903852534\n",
            "Loss in iteration no. 99646 ==> 0.4815855464018858\n",
            "Loss in iteration no. 99647 ==> 0.4815845737740275\n",
            "Loss in iteration no. 99648 ==> 0.4815836011549504\n",
            "Loss in iteration no. 99649 ==> 0.4815826285446542\n",
            "Loss in iteration no. 99650 ==> 0.48158165594313873\n",
            "Loss in iteration no. 99651 ==> 0.4815806833504041\n",
            "Loss in iteration no. 99652 ==> 0.48157971076645006\n",
            "Loss in iteration no. 99653 ==> 0.48157873819127667\n",
            "Loss in iteration no. 99654 ==> 0.4815777656248836\n",
            "Loss in iteration no. 99655 ==> 0.48157679306727075\n",
            "Loss in iteration no. 99656 ==> 0.4815758205184381\n",
            "Loss in iteration no. 99657 ==> 0.4815748479783856\n",
            "Loss in iteration no. 99658 ==> 0.48157387544711316\n",
            "Loss in iteration no. 99659 ==> 0.48157290292462046\n",
            "Loss in iteration no. 99660 ==> 0.4815719304109075\n",
            "Loss in iteration no. 99661 ==> 0.48157095790597415\n",
            "Loss in iteration no. 99662 ==> 0.4815699854098203\n",
            "Loss in iteration no. 99663 ==> 0.4815690129224459\n",
            "Loss in iteration no. 99664 ==> 0.4815680404438508\n",
            "Loss in iteration no. 99665 ==> 0.48156706797403487\n",
            "Loss in iteration no. 99666 ==> 0.48156609551299795\n",
            "Loss in iteration no. 99667 ==> 0.48156512306074006\n",
            "Loss in iteration no. 99668 ==> 0.481564150617261\n",
            "Loss in iteration no. 99669 ==> 0.4815631781825608\n",
            "Loss in iteration no. 99670 ==> 0.4815622057566391\n",
            "Loss in iteration no. 99671 ==> 0.48156123333949585\n",
            "Loss in iteration no. 99672 ==> 0.48156026093113125\n",
            "Loss in iteration no. 99673 ==> 0.4815592885315448\n",
            "Loss in iteration no. 99674 ==> 0.4815583161407365\n",
            "Loss in iteration no. 99675 ==> 0.4815573437587064\n",
            "Loss in iteration no. 99676 ==> 0.48155637138545415\n",
            "Loss in iteration no. 99677 ==> 0.48155539902097977\n",
            "Loss in iteration no. 99678 ==> 0.48155442666528314\n",
            "Loss in iteration no. 99679 ==> 0.48155345431836416\n",
            "Loss in iteration no. 99680 ==> 0.48155248198022255\n",
            "Loss in iteration no. 99681 ==> 0.4815515096508586\n",
            "Loss in iteration no. 99682 ==> 0.48155053733027176\n",
            "Loss in iteration no. 99683 ==> 0.4815495650184622\n",
            "Loss in iteration no. 99684 ==> 0.48154859271542966\n",
            "Loss in iteration no. 99685 ==> 0.4815476204211741\n",
            "Loss in iteration no. 99686 ==> 0.4815466481356955\n",
            "Loss in iteration no. 99687 ==> 0.4815456758589935\n",
            "Loss in iteration no. 99688 ==> 0.4815447035910681\n",
            "Loss in iteration no. 99689 ==> 0.4815437313319194\n",
            "Loss in iteration no. 99690 ==> 0.481542759081547\n",
            "Loss in iteration no. 99691 ==> 0.48154178683995086\n",
            "Loss in iteration no. 99692 ==> 0.481540814607131\n",
            "Loss in iteration no. 99693 ==> 0.4815398423830871\n",
            "Loss in iteration no. 99694 ==> 0.48153887016781927\n",
            "Loss in iteration no. 99695 ==> 0.48153789796132723\n",
            "Loss in iteration no. 99696 ==> 0.48153692576361096\n",
            "Loss in iteration no. 99697 ==> 0.4815359535746703\n",
            "Loss in iteration no. 99698 ==> 0.48153498139450523\n",
            "Loss in iteration no. 99699 ==> 0.4815340092231155\n",
            "Loss in iteration no. 99700 ==> 0.4815330370605011\n",
            "Loss in iteration no. 99701 ==> 0.48153206490666184\n",
            "Loss in iteration no. 99702 ==> 0.4815310927615977\n",
            "Loss in iteration no. 99703 ==> 0.48153012062530853\n",
            "Loss in iteration no. 99704 ==> 0.48152914849779416\n",
            "Loss in iteration no. 99705 ==> 0.4815281763790546\n",
            "Loss in iteration no. 99706 ==> 0.48152720426908974\n",
            "Loss in iteration no. 99707 ==> 0.4815262321678992\n",
            "Loss in iteration no. 99708 ==> 0.4815252600754832\n",
            "Loss in iteration no. 99709 ==> 0.48152428799184155\n",
            "Loss in iteration no. 99710 ==> 0.481523315916974\n",
            "Loss in iteration no. 99711 ==> 0.48152234385088044\n",
            "Loss in iteration no. 99712 ==> 0.481521371793561\n",
            "Loss in iteration no. 99713 ==> 0.48152039974501537\n",
            "Loss in iteration no. 99714 ==> 0.4815194277052435\n",
            "Loss in iteration no. 99715 ==> 0.4815184556742453\n",
            "Loss in iteration no. 99716 ==> 0.4815174836520206\n",
            "Loss in iteration no. 99717 ==> 0.4815165116385693\n",
            "Loss in iteration no. 99718 ==> 0.4815155396338912\n",
            "Loss in iteration no. 99719 ==> 0.48151456763798645\n",
            "Loss in iteration no. 99720 ==> 0.48151359565085466\n",
            "Loss in iteration no. 99721 ==> 0.4815126236724958\n",
            "Loss in iteration no. 99722 ==> 0.4815116517029099\n",
            "Loss in iteration no. 99723 ==> 0.4815106797420968\n",
            "Loss in iteration no. 99724 ==> 0.4815097077900563\n",
            "Loss in iteration no. 99725 ==> 0.4815087358467882\n",
            "Loss in iteration no. 99726 ==> 0.48150776391229266\n",
            "Loss in iteration no. 99727 ==> 0.48150679198656937\n",
            "Loss in iteration no. 99728 ==> 0.4815058200696183\n",
            "Loss in iteration no. 99729 ==> 0.48150484816143924\n",
            "Loss in iteration no. 99730 ==> 0.48150387626203217\n",
            "Loss in iteration no. 99731 ==> 0.48150290437139687\n",
            "Loss in iteration no. 99732 ==> 0.48150193248953344\n",
            "Loss in iteration no. 99733 ==> 0.4815009606164417\n",
            "Loss in iteration no. 99734 ==> 0.4814999887521214\n",
            "Loss in iteration no. 99735 ==> 0.48149901689657254\n",
            "Loss in iteration no. 99736 ==> 0.48149804504979504\n",
            "Loss in iteration no. 99737 ==> 0.4814970732117886\n",
            "Loss in iteration no. 99738 ==> 0.4814961013825533\n",
            "Loss in iteration no. 99739 ==> 0.4814951295620889\n",
            "Loss in iteration no. 99740 ==> 0.4814941577503955\n",
            "Loss in iteration no. 99741 ==> 0.4814931859474728\n",
            "Loss in iteration no. 99742 ==> 0.4814922141533206\n",
            "Loss in iteration no. 99743 ==> 0.4814912423679392\n",
            "Loss in iteration no. 99744 ==> 0.481490270591328\n",
            "Loss in iteration no. 99745 ==> 0.4814892988234872\n",
            "Loss in iteration no. 99746 ==> 0.4814883270644166\n",
            "Loss in iteration no. 99747 ==> 0.481487355314116\n",
            "Loss in iteration no. 99748 ==> 0.48148638357258544\n",
            "Loss in iteration no. 99749 ==> 0.4814854118398247\n",
            "Loss in iteration no. 99750 ==> 0.48148444011583375\n",
            "Loss in iteration no. 99751 ==> 0.4814834684006124\n",
            "Loss in iteration no. 99752 ==> 0.4814824966941606\n",
            "Loss in iteration no. 99753 ==> 0.4814815249964782\n",
            "Loss in iteration no. 99754 ==> 0.48148055330756506\n",
            "Loss in iteration no. 99755 ==> 0.48147958162742127\n",
            "Loss in iteration no. 99756 ==> 0.4814786099560464\n",
            "Loss in iteration no. 99757 ==> 0.4814776382934407\n",
            "Loss in iteration no. 99758 ==> 0.4814766666396037\n",
            "Loss in iteration no. 99759 ==> 0.4814756949945356\n",
            "Loss in iteration no. 99760 ==> 0.48147472335823593\n",
            "Loss in iteration no. 99761 ==> 0.48147375173070506\n",
            "Loss in iteration no. 99762 ==> 0.48147278011194233\n",
            "Loss in iteration no. 99763 ==> 0.481471808501948\n",
            "Loss in iteration no. 99764 ==> 0.48147083690072195\n",
            "Loss in iteration no. 99765 ==> 0.48146986530826397\n",
            "Loss in iteration no. 99766 ==> 0.48146889372457397\n",
            "Loss in iteration no. 99767 ==> 0.48146792214965173\n",
            "Loss in iteration no. 99768 ==> 0.4814669505834974\n",
            "Loss in iteration no. 99769 ==> 0.4814659790261106\n",
            "Loss in iteration no. 99770 ==> 0.48146500747749127\n",
            "Loss in iteration no. 99771 ==> 0.48146403593763953\n",
            "Loss in iteration no. 99772 ==> 0.48146306440655506\n",
            "Loss in iteration no. 99773 ==> 0.48146209288423775\n",
            "Loss in iteration no. 99774 ==> 0.48146112137068753\n",
            "Loss in iteration no. 99775 ==> 0.48146014986590446\n",
            "Loss in iteration no. 99776 ==> 0.48145917836988783\n",
            "Loss in iteration no. 99777 ==> 0.48145820688263835\n",
            "Loss in iteration no. 99778 ==> 0.48145723540415536\n",
            "Loss in iteration no. 99779 ==> 0.48145626393443886\n",
            "Loss in iteration no. 99780 ==> 0.4814552924734889\n",
            "Loss in iteration no. 99781 ==> 0.48145432102130514\n",
            "Loss in iteration no. 99782 ==> 0.4814533495778877\n",
            "Loss in iteration no. 99783 ==> 0.4814523781432364\n",
            "Loss in iteration no. 99784 ==> 0.4814514067173509\n",
            "Loss in iteration no. 99785 ==> 0.48145043530023135\n",
            "Loss in iteration no. 99786 ==> 0.48144946389187765\n",
            "Loss in iteration no. 99787 ==> 0.4814484924922894\n",
            "Loss in iteration no. 99788 ==> 0.48144752110146677\n",
            "Loss in iteration no. 99789 ==> 0.4814465497194097\n",
            "Loss in iteration no. 99790 ==> 0.4814455783461178\n",
            "Loss in iteration no. 99791 ==> 0.4814446069815911\n",
            "Loss in iteration no. 99792 ==> 0.48144363562582965\n",
            "Loss in iteration no. 99793 ==> 0.48144266427883303\n",
            "Loss in iteration no. 99794 ==> 0.48144169294060135\n",
            "Loss in iteration no. 99795 ==> 0.4814407216111344\n",
            "Loss in iteration no. 99796 ==> 0.4814397502904321\n",
            "Loss in iteration no. 99797 ==> 0.48143877897849446\n",
            "Loss in iteration no. 99798 ==> 0.481437807675321\n",
            "Loss in iteration no. 99799 ==> 0.481436836380912\n",
            "Loss in iteration no. 99800 ==> 0.4814358650952673\n",
            "Loss in iteration no. 99801 ==> 0.4814348938183866\n",
            "Loss in iteration no. 99802 ==> 0.48143392255026984\n",
            "Loss in iteration no. 99803 ==> 0.481432951290917\n",
            "Loss in iteration no. 99804 ==> 0.48143198004032794\n",
            "Loss in iteration no. 99805 ==> 0.4814310087985024\n",
            "Loss in iteration no. 99806 ==> 0.48143003756544056\n",
            "Loss in iteration no. 99807 ==> 0.48142906634114224\n",
            "Loss in iteration no. 99808 ==> 0.48142809512560697\n",
            "Loss in iteration no. 99809 ==> 0.48142712391883513\n",
            "Loss in iteration no. 99810 ==> 0.48142615272082634\n",
            "Loss in iteration no. 99811 ==> 0.4814251815315805\n",
            "Loss in iteration no. 99812 ==> 0.4814242103510976\n",
            "Loss in iteration no. 99813 ==> 0.4814232391793774\n",
            "Loss in iteration no. 99814 ==> 0.4814222680164199\n",
            "Loss in iteration no. 99815 ==> 0.4814212968622249\n",
            "Loss in iteration no. 99816 ==> 0.4814203257167923\n",
            "Loss in iteration no. 99817 ==> 0.4814193545801221\n",
            "Loss in iteration no. 99818 ==> 0.48141838345221416\n",
            "Loss in iteration no. 99819 ==> 0.4814174123330683\n",
            "Loss in iteration no. 99820 ==> 0.4814164412226844\n",
            "Loss in iteration no. 99821 ==> 0.4814154701210623\n",
            "Loss in iteration no. 99822 ==> 0.48141449902820205\n",
            "Loss in iteration no. 99823 ==> 0.48141352794410347\n",
            "Loss in iteration no. 99824 ==> 0.4814125568687664\n",
            "Loss in iteration no. 99825 ==> 0.4814115858021908\n",
            "Loss in iteration no. 99826 ==> 0.48141061474437646\n",
            "Loss in iteration no. 99827 ==> 0.4814096436953234\n",
            "Loss in iteration no. 99828 ==> 0.48140867265503146\n",
            "Loss in iteration no. 99829 ==> 0.4814077016235005\n",
            "Loss in iteration no. 99830 ==> 0.48140673060073036\n",
            "Loss in iteration no. 99831 ==> 0.48140575958672105\n",
            "Loss in iteration no. 99832 ==> 0.48140478858147245\n",
            "Loss in iteration no. 99833 ==> 0.48140381758498446\n",
            "Loss in iteration no. 99834 ==> 0.48140284659725663\n",
            "Loss in iteration no. 99835 ==> 0.4814018756182894\n",
            "Loss in iteration no. 99836 ==> 0.4814009046480823\n",
            "Loss in iteration no. 99837 ==> 0.48139993368663525\n",
            "Loss in iteration no. 99838 ==> 0.4813989627339482\n",
            "Loss in iteration no. 99839 ==> 0.48139799179002113\n",
            "Loss in iteration no. 99840 ==> 0.48139702085485375\n",
            "Loss in iteration no. 99841 ==> 0.48139604992844603\n",
            "Loss in iteration no. 99842 ==> 0.481395079010798\n",
            "Loss in iteration no. 99843 ==> 0.4813941081019094\n",
            "Loss in iteration no. 99844 ==> 0.4813931372017801\n",
            "Loss in iteration no. 99845 ==> 0.4813921663104098\n",
            "Loss in iteration no. 99846 ==> 0.48139119542779885\n",
            "Loss in iteration no. 99847 ==> 0.4813902245539468\n",
            "Loss in iteration no. 99848 ==> 0.4813892536888538\n",
            "Loss in iteration no. 99849 ==> 0.48138828283251933\n",
            "Loss in iteration no. 99850 ==> 0.4813873119849437\n",
            "Loss in iteration no. 99851 ==> 0.48138634114612666\n",
            "Loss in iteration no. 99852 ==> 0.48138537031606793\n",
            "Loss in iteration no. 99853 ==> 0.4813843994947677\n",
            "Loss in iteration no. 99854 ==> 0.4813834286822255\n",
            "Loss in iteration no. 99855 ==> 0.4813824578784416\n",
            "Loss in iteration no. 99856 ==> 0.48138148708341555\n",
            "Loss in iteration no. 99857 ==> 0.4813805162971475\n",
            "Loss in iteration no. 99858 ==> 0.4813795455196372\n",
            "Loss in iteration no. 99859 ==> 0.4813785747508846\n",
            "Loss in iteration no. 99860 ==> 0.4813776039908895\n",
            "Loss in iteration no. 99861 ==> 0.4813766332396519\n",
            "Loss in iteration no. 99862 ==> 0.48137566249717173\n",
            "Loss in iteration no. 99863 ==> 0.4813746917634486\n",
            "Loss in iteration no. 99864 ==> 0.4813737210384827\n",
            "Loss in iteration no. 99865 ==> 0.4813727503222738\n",
            "Loss in iteration no. 99866 ==> 0.48137177961482175\n",
            "Loss in iteration no. 99867 ==> 0.4813708089161265\n",
            "Loss in iteration no. 99868 ==> 0.48136983822618795\n",
            "Loss in iteration no. 99869 ==> 0.481368867545006\n",
            "Loss in iteration no. 99870 ==> 0.48136789687258047\n",
            "Loss in iteration no. 99871 ==> 0.48136692620891125\n",
            "Loss in iteration no. 99872 ==> 0.4813659555539983\n",
            "Loss in iteration no. 99873 ==> 0.48136498490784146\n",
            "Loss in iteration no. 99874 ==> 0.4813640142704407\n",
            "Loss in iteration no. 99875 ==> 0.4813630436417958\n",
            "Loss in iteration no. 99876 ==> 0.48136207302190664\n",
            "Loss in iteration no. 99877 ==> 0.48136110241077323\n",
            "Loss in iteration no. 99878 ==> 0.4813601318083953\n",
            "Loss in iteration no. 99879 ==> 0.48135916121477285\n",
            "Loss in iteration no. 99880 ==> 0.4813581906299058\n",
            "Loss in iteration no. 99881 ==> 0.4813572200537939\n",
            "Loss in iteration no. 99882 ==> 0.48135624948643735\n",
            "Loss in iteration no. 99883 ==> 0.4813552789278356\n",
            "Loss in iteration no. 99884 ==> 0.4813543083779888\n",
            "Loss in iteration no. 99885 ==> 0.4813533378368968\n",
            "Loss in iteration no. 99886 ==> 0.4813523673045595\n",
            "Loss in iteration no. 99887 ==> 0.4813513967809767\n",
            "Loss in iteration no. 99888 ==> 0.48135042626614855\n",
            "Loss in iteration no. 99889 ==> 0.48134945576007465\n",
            "Loss in iteration no. 99890 ==> 0.4813484852627549\n",
            "Loss in iteration no. 99891 ==> 0.48134751477418936\n",
            "Loss in iteration no. 99892 ==> 0.48134654429437784\n",
            "Loss in iteration no. 99893 ==> 0.4813455738233202\n",
            "Loss in iteration no. 99894 ==> 0.4813446033610165\n",
            "Loss in iteration no. 99895 ==> 0.48134363290746635\n",
            "Loss in iteration no. 99896 ==> 0.48134266246266977\n",
            "Loss in iteration no. 99897 ==> 0.48134169202662663\n",
            "Loss in iteration no. 99898 ==> 0.4813407215993369\n",
            "Loss in iteration no. 99899 ==> 0.4813397511808004\n",
            "Loss in iteration no. 99900 ==> 0.48133878077101705\n",
            "Loss in iteration no. 99901 ==> 0.4813378103699868\n",
            "Loss in iteration no. 99902 ==> 0.4813368399777094\n",
            "Loss in iteration no. 99903 ==> 0.48133586959418473\n",
            "Loss in iteration no. 99904 ==> 0.4813348992194129\n",
            "Loss in iteration no. 99905 ==> 0.4813339288533935\n",
            "Loss in iteration no. 99906 ==> 0.4813329584961267\n",
            "Loss in iteration no. 99907 ==> 0.4813319881476122\n",
            "Loss in iteration no. 99908 ==> 0.48133101780785\n",
            "Loss in iteration no. 99909 ==> 0.48133004747683983\n",
            "Loss in iteration no. 99910 ==> 0.4813290771545817\n",
            "Loss in iteration no. 99911 ==> 0.4813281068410756\n",
            "Loss in iteration no. 99912 ==> 0.48132713653632125\n",
            "Loss in iteration no. 99913 ==> 0.48132616624031854\n",
            "Loss in iteration no. 99914 ==> 0.4813251959530675\n",
            "Loss in iteration no. 99915 ==> 0.481324225674568\n",
            "Loss in iteration no. 99916 ==> 0.4813232554048197\n",
            "Loss in iteration no. 99917 ==> 0.4813222851438226\n",
            "Loss in iteration no. 99918 ==> 0.4813213148915768\n",
            "Loss in iteration no. 99919 ==> 0.4813203446480821\n",
            "Loss in iteration no. 99920 ==> 0.48131937441333816\n",
            "Loss in iteration no. 99921 ==> 0.4813184041873451\n",
            "Loss in iteration no. 99922 ==> 0.4813174339701027\n",
            "Loss in iteration no. 99923 ==> 0.48131646376161114\n",
            "Loss in iteration no. 99924 ==> 0.4813154935618697\n",
            "Loss in iteration no. 99925 ==> 0.4813145233708788\n",
            "Loss in iteration no. 99926 ==> 0.48131355318863817\n",
            "Loss in iteration no. 99927 ==> 0.4813125830151477\n",
            "Loss in iteration no. 99928 ==> 0.48131161285040713\n",
            "Loss in iteration no. 99929 ==> 0.4813106426944166\n",
            "Loss in iteration no. 99930 ==> 0.48130967254717594\n",
            "Loss in iteration no. 99931 ==> 0.4813087024086849\n",
            "Loss in iteration no. 99932 ==> 0.4813077322789436\n",
            "Loss in iteration no. 99933 ==> 0.4813067621579515\n",
            "Loss in iteration no. 99934 ==> 0.48130579204570906\n",
            "Loss in iteration no. 99935 ==> 0.4813048219422157\n",
            "Loss in iteration no. 99936 ==> 0.48130385184747154\n",
            "Loss in iteration no. 99937 ==> 0.4813028817614765\n",
            "Loss in iteration no. 99938 ==> 0.4813019116842303\n",
            "Loss in iteration no. 99939 ==> 0.481300941615733\n",
            "Loss in iteration no. 99940 ==> 0.48129997155598436\n",
            "Loss in iteration no. 99941 ==> 0.4812990015049843\n",
            "Loss in iteration no. 99942 ==> 0.48129803146273265\n",
            "Loss in iteration no. 99943 ==> 0.4812970614292296\n",
            "Loss in iteration no. 99944 ==> 0.4812960914044747\n",
            "Loss in iteration no. 99945 ==> 0.481295121388468\n",
            "Loss in iteration no. 99946 ==> 0.48129415138120923\n",
            "Loss in iteration no. 99947 ==> 0.4812931813826985\n",
            "Loss in iteration no. 99948 ==> 0.48129221139293554\n",
            "Loss in iteration no. 99949 ==> 0.4812912414119203\n",
            "Loss in iteration no. 99950 ==> 0.4812902714396528\n",
            "Loss in iteration no. 99951 ==> 0.48128930147613264\n",
            "Loss in iteration no. 99952 ==> 0.4812883315213599\n",
            "Loss in iteration no. 99953 ==> 0.48128736157533447\n",
            "Loss in iteration no. 99954 ==> 0.4812863916380563\n",
            "Loss in iteration no. 99955 ==> 0.481285421709525\n",
            "Loss in iteration no. 99956 ==> 0.4812844517897407\n",
            "Loss in iteration no. 99957 ==> 0.48128348187870335\n",
            "Loss in iteration no. 99958 ==> 0.4812825119764126\n",
            "Loss in iteration no. 99959 ==> 0.4812815420828685\n",
            "Loss in iteration no. 99960 ==> 0.48128057219807074\n",
            "Loss in iteration no. 99961 ==> 0.48127960232201966\n",
            "Loss in iteration no. 99962 ==> 0.4812786324547146\n",
            "Loss in iteration no. 99963 ==> 0.48127766259615584\n",
            "Loss in iteration no. 99964 ==> 0.48127669274634316\n",
            "Loss in iteration no. 99965 ==> 0.4812757229052763\n",
            "Loss in iteration no. 99966 ==> 0.48127475307295536\n",
            "Loss in iteration no. 99967 ==> 0.48127378324938025\n",
            "Loss in iteration no. 99968 ==> 0.48127281343455053\n",
            "Loss in iteration no. 99969 ==> 0.4812718436284666\n",
            "Loss in iteration no. 99970 ==> 0.4812708738311278\n",
            "Loss in iteration no. 99971 ==> 0.48126990404253445\n",
            "Loss in iteration no. 99972 ==> 0.4812689342626862\n",
            "Loss in iteration no. 99973 ==> 0.48126796449158304\n",
            "Loss in iteration no. 99974 ==> 0.48126699472922485\n",
            "Loss in iteration no. 99975 ==> 0.4812660249756114\n",
            "Loss in iteration no. 99976 ==> 0.4812650552307427\n",
            "Loss in iteration no. 99977 ==> 0.4812640854946187\n",
            "Loss in iteration no. 99978 ==> 0.4812631157672392\n",
            "Loss in iteration no. 99979 ==> 0.4812621460486042\n",
            "Loss in iteration no. 99980 ==> 0.4812611763387133\n",
            "Loss in iteration no. 99981 ==> 0.48126020663756675\n",
            "Loss in iteration no. 99982 ==> 0.4812592369451641\n",
            "Loss in iteration no. 99983 ==> 0.48125826726150556\n",
            "Loss in iteration no. 99984 ==> 0.48125729758659075\n",
            "Loss in iteration no. 99985 ==> 0.4812563279204197\n",
            "Loss in iteration no. 99986 ==> 0.48125535826299237\n",
            "Loss in iteration no. 99987 ==> 0.4812543886143085\n",
            "Loss in iteration no. 99988 ==> 0.481253418974368\n",
            "Loss in iteration no. 99989 ==> 0.4812524493431708\n",
            "Loss in iteration no. 99990 ==> 0.4812514797207169\n",
            "Loss in iteration no. 99991 ==> 0.48125051010700604\n",
            "Loss in iteration no. 99992 ==> 0.481249540502038\n",
            "Loss in iteration no. 99993 ==> 0.481248570905813\n",
            "Loss in iteration no. 99994 ==> 0.4812476013183305\n",
            "Loss in iteration no. 99995 ==> 0.48124663173959087\n",
            "Loss in iteration no. 99996 ==> 0.48124566216959375\n",
            "Loss in iteration no. 99997 ==> 0.4812446926083389\n",
            "Loss in iteration no. 99998 ==> 0.48124372305582647\n",
            "Loss in iteration no. 99999 ==> 0.4812427535120562\n",
            "Loss in iteration no. 100000 ==> 0.481241783977028\n"
          ]
        }
      ],
      "source": [
        "# Printing out the loss values for each iteration\n",
        "\n",
        "for i,loss in enumerate(model.model_loss):\n",
        "  print(f\"Loss in iteration no. {i+1} ==> {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RCedhQ5Me0w",
        "outputId": "d973217b-c9b4-4586-d880-b36717663763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the Logistic Regression Model ==> 82.61%\n",
            "Number of Correct Predictions ==> 57\n",
            "Number of Wrong Predictions ==> 12\n"
          ]
        }
      ],
      "source": [
        "# Now that we have got all the required results, its time to try\n",
        "# with different hyperparameters set (3 atleast)\n",
        "\n",
        "# SET : 1\n",
        "\n",
        "weights_latest = None\n",
        "model = LogitRegression(learning_rate = 0.002, num_of_iter = 100100)\n",
        "\n",
        "y_train = y_train.squeeze()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "accuracy_vald = np.random.rand()\n",
        "\n",
        "if accuracy_vald > accuracy:\n",
        "  accuracy = accuracy_vald\n",
        "  weights_latest = {\n",
        "      \"weights\" : model.weights.tolist(),\n",
        "      \"bias\" : model.bias\n",
        "  }\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "y_test = y_test.squeeze()\n",
        "prediction_truth_values = (predictions == y_test).astype(int)\n",
        "accuracy = np.mean(prediction_truth_values) * 100\n",
        "\n",
        "print(f\"Accuracy of the Logistic Regression Model ==> {accuracy:.2f}%\")\n",
        "print(f\"Number of Correct Predictions ==> {round((accuracy/100) * 69)}\")\n",
        "print(f\"Number of Wrong Predictions ==> {round(69 - ((accuracy/100) * 69))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZB9ER2m7NFRc",
        "outputId": "7e6e420c-617d-4388-d9d7-a962343ee5b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-3.5691291853744764, -1.403292941762292, -0.3294272472790273, 2.5972898536906484, 2.6568914064444216, 1.9369072141454389, 4.337076708283125]\n"
          ]
        }
      ],
      "source": [
        "print(model.weights.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "id": "bR0zMAJJNh7x",
        "outputId": "f0a39011-775a-4d85-db0b-57f8cdd884a0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "\n",
        "plt.plot(np.arange(model.num_of_iter), model.model_loss)\n",
        "\n",
        "plt.xlabel(\"No. of Iterations\")\n",
        "plt.ylabel(\"Loss Values\")\n",
        "\n",
        "plt.title(\"SET 1 : Loss values w.r.t. no. of iterations\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q57BeJWFNnOE",
        "outputId": "a9fc4df0-51af-4c69-b54a-6412f9ef8d01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Loss in iteration no. 69806 ==> 0.4497615985495821\n",
            "Loss in iteration no. 69807 ==> 0.44976019811762213\n",
            "Loss in iteration no. 69808 ==> 0.44975879770791743\n",
            "Loss in iteration no. 69809 ==> 0.4497573973204674\n",
            "Loss in iteration no. 69810 ==> 0.4497559969552715\n",
            "Loss in iteration no. 69811 ==> 0.4497545966123293\n",
            "Loss in iteration no. 69812 ==> 0.44975319629164034\n",
            "Loss in iteration no. 69813 ==> 0.4497517959932041\n",
            "Loss in iteration no. 69814 ==> 0.44975039571702\n",
            "Loss in iteration no. 69815 ==> 0.4497489954630875\n",
            "Loss in iteration no. 69816 ==> 0.4497475952314063\n",
            "Loss in iteration no. 69817 ==> 0.4497461950219757\n",
            "Loss in iteration no. 69818 ==> 0.44974479483479535\n",
            "Loss in iteration no. 69819 ==> 0.4497433946698646\n",
            "Loss in iteration no. 69820 ==> 0.44974199452718305\n",
            "Loss in iteration no. 69821 ==> 0.4497405944067501\n",
            "Loss in iteration no. 69822 ==> 0.44973919430856546\n",
            "Loss in iteration no. 69823 ==> 0.4497377942326284\n",
            "Loss in iteration no. 69824 ==> 0.44973639417893857\n",
            "Loss in iteration no. 69825 ==> 0.44973499414749535\n",
            "Loss in iteration no. 69826 ==> 0.4497335941382984\n",
            "Loss in iteration no. 69827 ==> 0.449732194151347\n",
            "Loss in iteration no. 69828 ==> 0.44973079418664086\n",
            "Loss in iteration no. 69829 ==> 0.4497293942441793\n",
            "Loss in iteration no. 69830 ==> 0.44972799432396193\n",
            "Loss in iteration no. 69831 ==> 0.4497265944259883\n",
            "Loss in iteration no. 69832 ==> 0.4497251945502576\n",
            "Loss in iteration no. 69833 ==> 0.4497237946967698\n",
            "Loss in iteration no. 69834 ==> 0.44972239486552407\n",
            "Loss in iteration no. 69835 ==> 0.44972099505652\n",
            "Loss in iteration no. 69836 ==> 0.44971959526975713\n",
            "Loss in iteration no. 69837 ==> 0.4497181955052348\n",
            "Loss in iteration no. 69838 ==> 0.44971679576295276\n",
            "Loss in iteration no. 69839 ==> 0.44971539604291033\n",
            "Loss in iteration no. 69840 ==> 0.44971399634510706\n",
            "Loss in iteration no. 69841 ==> 0.44971259666954244\n",
            "Loss in iteration no. 69842 ==> 0.4497111970162159\n",
            "Loss in iteration no. 69843 ==> 0.4497097973851271\n",
            "Loss in iteration no. 69844 ==> 0.4497083977762754\n",
            "Loss in iteration no. 69845 ==> 0.44970699818966037\n",
            "Loss in iteration no. 69846 ==> 0.44970559862528137\n",
            "Loss in iteration no. 69847 ==> 0.4497041990831382\n",
            "Loss in iteration no. 69848 ==> 0.44970279956323006\n",
            "Loss in iteration no. 69849 ==> 0.44970140006555664\n",
            "Loss in iteration no. 69850 ==> 0.44970000059011733\n",
            "Loss in iteration no. 69851 ==> 0.4496986011369117\n",
            "Loss in iteration no. 69852 ==> 0.44969720170593913\n",
            "Loss in iteration no. 69853 ==> 0.44969580229719924\n",
            "Loss in iteration no. 69854 ==> 0.4496944029106915\n",
            "Loss in iteration no. 69855 ==> 0.4496930035464154\n",
            "Loss in iteration no. 69856 ==> 0.44969160420437054\n",
            "Loss in iteration no. 69857 ==> 0.44969020488455613\n",
            "Loss in iteration no. 69858 ==> 0.44968880558697194\n",
            "Loss in iteration no. 69859 ==> 0.44968740631161735\n",
            "Loss in iteration no. 69860 ==> 0.44968600705849193\n",
            "Loss in iteration no. 69861 ==> 0.4496846078275952\n",
            "Loss in iteration no. 69862 ==> 0.4496832086189266\n",
            "Loss in iteration no. 69863 ==> 0.44968180943248554\n",
            "Loss in iteration no. 69864 ==> 0.44968041026827166\n",
            "Loss in iteration no. 69865 ==> 0.4496790111262845\n",
            "Loss in iteration no. 69866 ==> 0.44967761200652334\n",
            "Loss in iteration no. 69867 ==> 0.44967621290898785\n",
            "Loss in iteration no. 69868 ==> 0.44967481383367747\n",
            "Loss in iteration no. 69869 ==> 0.4496734147805918\n",
            "Loss in iteration no. 69870 ==> 0.44967201574973026\n",
            "Loss in iteration no. 69871 ==> 0.44967061674109227\n",
            "Loss in iteration no. 69872 ==> 0.44966921775467744\n",
            "Loss in iteration no. 69873 ==> 0.4496678187904853\n",
            "Loss in iteration no. 69874 ==> 0.4496664198485152\n",
            "Loss in iteration no. 69875 ==> 0.44966502092876676\n",
            "Loss in iteration no. 69876 ==> 0.44966362203123944\n",
            "Loss in iteration no. 69877 ==> 0.44966222315593274\n",
            "Loss in iteration no. 69878 ==> 0.4496608243028462\n",
            "Loss in iteration no. 69879 ==> 0.4496594254719793\n",
            "Loss in iteration no. 69880 ==> 0.44965802666333143\n",
            "Loss in iteration no. 69881 ==> 0.4496566278769024\n",
            "Loss in iteration no. 69882 ==> 0.4496552291126913\n",
            "Loss in iteration no. 69883 ==> 0.4496538303706979\n",
            "Loss in iteration no. 69884 ==> 0.44965243165092156\n",
            "Loss in iteration no. 69885 ==> 0.44965103295336195\n",
            "Loss in iteration no. 69886 ==> 0.44964963427801835\n",
            "Loss in iteration no. 69887 ==> 0.44964823562489054\n",
            "Loss in iteration no. 69888 ==> 0.4496468369939776\n",
            "Loss in iteration no. 69889 ==> 0.44964543838527954\n",
            "Loss in iteration no. 69890 ==> 0.44964403979879547\n",
            "Loss in iteration no. 69891 ==> 0.44964264123452496\n",
            "Loss in iteration no. 69892 ==> 0.4496412426924677\n",
            "Loss in iteration no. 69893 ==> 0.4496398441726231\n",
            "Loss in iteration no. 69894 ==> 0.4496384456749905\n",
            "Loss in iteration no. 69895 ==> 0.4496370471995696\n",
            "Loss in iteration no. 69896 ==> 0.4496356487463598\n",
            "Loss in iteration no. 69897 ==> 0.44963425031536053\n",
            "Loss in iteration no. 69898 ==> 0.4496328519065716\n",
            "Loss in iteration no. 69899 ==> 0.4496314535199922\n",
            "Loss in iteration no. 69900 ==> 0.44963005515562177\n",
            "Loss in iteration no. 69901 ==> 0.4496286568134601\n",
            "Loss in iteration no. 69902 ==> 0.44962725849350654\n",
            "Loss in iteration no. 69903 ==> 0.44962586019576056\n",
            "Loss in iteration no. 69904 ==> 0.44962446192022176\n",
            "Loss in iteration no. 69905 ==> 0.4496230636668895\n",
            "Loss in iteration no. 69906 ==> 0.4496216654357635\n",
            "Loss in iteration no. 69907 ==> 0.449620267226843\n",
            "Loss in iteration no. 69908 ==> 0.4496188690401277\n",
            "Loss in iteration no. 69909 ==> 0.44961747087561693\n",
            "Loss in iteration no. 69910 ==> 0.4496160727333104\n",
            "Loss in iteration no. 69911 ==> 0.4496146746132075\n",
            "Loss in iteration no. 69912 ==> 0.4496132765153075\n",
            "Loss in iteration no. 69913 ==> 0.44961187843961037\n",
            "Loss in iteration no. 69914 ==> 0.44961048038611523\n",
            "Loss in iteration no. 69915 ==> 0.4496090823548218\n",
            "Loss in iteration no. 69916 ==> 0.44960768434572945\n",
            "Loss in iteration no. 69917 ==> 0.44960628635883765\n",
            "Loss in iteration no. 69918 ==> 0.44960488839414603\n",
            "Loss in iteration no. 69919 ==> 0.44960349045165415\n",
            "Loss in iteration no. 69920 ==> 0.4496020925313612\n",
            "Loss in iteration no. 69921 ==> 0.449600694633267\n",
            "Loss in iteration no. 69922 ==> 0.449599296757371\n",
            "Loss in iteration no. 69923 ==> 0.44959789890367235\n",
            "Loss in iteration no. 69924 ==> 0.4495965010721711\n",
            "Loss in iteration no. 69925 ==> 0.4495951032628664\n",
            "Loss in iteration no. 69926 ==> 0.4495937054757577\n",
            "Loss in iteration no. 69927 ==> 0.44959230771084485\n",
            "Loss in iteration no. 69928 ==> 0.4495909099681269\n",
            "Loss in iteration no. 69929 ==> 0.44958951224760374\n",
            "Loss in iteration no. 69930 ==> 0.4495881145492746\n",
            "Loss in iteration no. 69931 ==> 0.4495867168731391\n",
            "Loss in iteration no. 69932 ==> 0.44958531921919687\n",
            "Loss in iteration no. 69933 ==> 0.4495839215874471\n",
            "Loss in iteration no. 69934 ==> 0.4495825239778896\n",
            "Loss in iteration no. 69935 ==> 0.4495811263905236\n",
            "Loss in iteration no. 69936 ==> 0.44957972882534875\n",
            "Loss in iteration no. 69937 ==> 0.4495783312823647\n",
            "Loss in iteration no. 69938 ==> 0.44957693376157054\n",
            "Loss in iteration no. 69939 ==> 0.44957553626296615\n",
            "Loss in iteration no. 69940 ==> 0.4495741387865508\n",
            "Loss in iteration no. 69941 ==> 0.4495727413323242\n",
            "Loss in iteration no. 69942 ==> 0.44957134390028564\n",
            "Loss in iteration no. 69943 ==> 0.4495699464904348\n",
            "Loss in iteration no. 69944 ==> 0.44956854910277105\n",
            "Loss in iteration no. 69945 ==> 0.4495671517372939\n",
            "Loss in iteration no. 69946 ==> 0.4495657543940029\n",
            "Loss in iteration no. 69947 ==> 0.44956435707289755\n",
            "Loss in iteration no. 69948 ==> 0.44956295977397737\n",
            "Loss in iteration no. 69949 ==> 0.44956156249724183\n",
            "Loss in iteration no. 69950 ==> 0.4495601652426903\n",
            "Loss in iteration no. 69951 ==> 0.4495587680103226\n",
            "Loss in iteration no. 69952 ==> 0.44955737080013786\n",
            "Loss in iteration no. 69953 ==> 0.4495559736121359\n",
            "Loss in iteration no. 69954 ==> 0.449554576446316\n",
            "Loss in iteration no. 69955 ==> 0.4495531793026779\n",
            "Loss in iteration no. 69956 ==> 0.4495517821812207\n",
            "Loss in iteration no. 69957 ==> 0.4495503850819442\n",
            "Loss in iteration no. 69958 ==> 0.449548988004848\n",
            "Loss in iteration no. 69959 ==> 0.4495475909499313\n",
            "Loss in iteration no. 69960 ==> 0.4495461939171939\n",
            "Loss in iteration no. 69961 ==> 0.449544796906635\n",
            "Loss in iteration no. 69962 ==> 0.4495433999182544\n",
            "Loss in iteration no. 69963 ==> 0.4495420029520512\n",
            "Loss in iteration no. 69964 ==> 0.4495406060080253\n",
            "Loss in iteration no. 69965 ==> 0.4495392090861762\n",
            "Loss in iteration no. 69966 ==> 0.44953781218650307\n",
            "Loss in iteration no. 69967 ==> 0.44953641530900557\n",
            "Loss in iteration no. 69968 ==> 0.4495350184536832\n",
            "Loss in iteration no. 69969 ==> 0.4495336216205356\n",
            "Loss in iteration no. 69970 ==> 0.4495322248095622\n",
            "Loss in iteration no. 69971 ==> 0.44953082802076233\n",
            "Loss in iteration no. 69972 ==> 0.4495294312541356\n",
            "Loss in iteration no. 69973 ==> 0.4495280345096816\n",
            "Loss in iteration no. 69974 ==> 0.44952663778739976\n",
            "Loss in iteration no. 69975 ==> 0.44952524108728953\n",
            "Loss in iteration no. 69976 ==> 0.4495238444093505\n",
            "Loss in iteration no. 69977 ==> 0.44952244775358224\n",
            "Loss in iteration no. 69978 ==> 0.449521051119984\n",
            "Loss in iteration no. 69979 ==> 0.44951965450855547\n",
            "Loss in iteration no. 69980 ==> 0.449518257919296\n",
            "Loss in iteration no. 69981 ==> 0.44951686135220537\n",
            "Loss in iteration no. 69982 ==> 0.4495154648072829\n",
            "Loss in iteration no. 69983 ==> 0.449514068284528\n",
            "Loss in iteration no. 69984 ==> 0.4495126717839402\n",
            "Loss in iteration no. 69985 ==> 0.44951127530551926\n",
            "Loss in iteration no. 69986 ==> 0.4495098788492644\n",
            "Loss in iteration no. 69987 ==> 0.44950848241517527\n",
            "Loss in iteration no. 69988 ==> 0.4495070860032513\n",
            "Loss in iteration no. 69989 ==> 0.44950568961349197\n",
            "Loss in iteration no. 69990 ==> 0.4495042932458968\n",
            "Loss in iteration no. 69991 ==> 0.4495028969004653\n",
            "Loss in iteration no. 69992 ==> 0.44950150057719707\n",
            "Loss in iteration no. 69993 ==> 0.44950010427609144\n",
            "Loss in iteration no. 69994 ==> 0.4494987079971481\n",
            "Loss in iteration no. 69995 ==> 0.4494973117403663\n",
            "Loss in iteration no. 69996 ==> 0.4494959155057458\n",
            "Loss in iteration no. 69997 ==> 0.44949451929328593\n",
            "Loss in iteration no. 69998 ==> 0.4494931231029863\n",
            "Loss in iteration no. 69999 ==> 0.4494917269348463\n",
            "Loss in iteration no. 70000 ==> 0.4494903307888656\n",
            "Loss in iteration no. 70001 ==> 0.44948893466504347\n",
            "Loss in iteration no. 70002 ==> 0.4494875385633796\n",
            "Loss in iteration no. 70003 ==> 0.4494861424838734\n",
            "Loss in iteration no. 70004 ==> 0.44948474642652453\n",
            "Loss in iteration no. 70005 ==> 0.44948335039133214\n",
            "Loss in iteration no. 70006 ==> 0.449481954378296\n",
            "Loss in iteration no. 70007 ==> 0.4494805583874157\n",
            "Loss in iteration no. 70008 ==> 0.4494791624186905\n",
            "Loss in iteration no. 70009 ==> 0.44947776647212\n",
            "Loss in iteration no. 70010 ==> 0.4494763705477037\n",
            "Loss in iteration no. 70011 ==> 0.44947497464544117\n",
            "Loss in iteration no. 70012 ==> 0.4494735787653319\n",
            "Loss in iteration no. 70013 ==> 0.4494721829073752\n",
            "Loss in iteration no. 70014 ==> 0.44947078707157073\n",
            "Loss in iteration no. 70015 ==> 0.44946939125791807\n",
            "Loss in iteration no. 70016 ==> 0.4494679954664166\n",
            "Loss in iteration no. 70017 ==> 0.44946659969706587\n",
            "Loss in iteration no. 70018 ==> 0.4494652039498653\n",
            "Loss in iteration no. 70019 ==> 0.4494638082248145\n",
            "Loss in iteration no. 70020 ==> 0.44946241252191294\n",
            "Loss in iteration no. 70021 ==> 0.4494610168411599\n",
            "Loss in iteration no. 70022 ==> 0.4494596211825553\n",
            "Loss in iteration no. 70023 ==> 0.4494582255460984\n",
            "Loss in iteration no. 70024 ==> 0.44945682993178865\n",
            "Loss in iteration no. 70025 ==> 0.44945543433962576\n",
            "Loss in iteration no. 70026 ==> 0.4494540387696091\n",
            "Loss in iteration no. 70027 ==> 0.44945264322173817\n",
            "Loss in iteration no. 70028 ==> 0.44945124769601236\n",
            "Loss in iteration no. 70029 ==> 0.4494498521924314\n",
            "Loss in iteration no. 70030 ==> 0.44944845671099454\n",
            "Loss in iteration no. 70031 ==> 0.4494470612517016\n",
            "Loss in iteration no. 70032 ==> 0.44944566581455186\n",
            "Loss in iteration no. 70033 ==> 0.4494442703995448\n",
            "Loss in iteration no. 70034 ==> 0.44944287500668006\n",
            "Loss in iteration no. 70035 ==> 0.44944147963595704\n",
            "Loss in iteration no. 70036 ==> 0.44944008428737536\n",
            "Loss in iteration no. 70037 ==> 0.44943868896093436\n",
            "Loss in iteration no. 70038 ==> 0.44943729365663354\n",
            "Loss in iteration no. 70039 ==> 0.4494358983744727\n",
            "Loss in iteration no. 70040 ==> 0.44943450311445093\n",
            "Loss in iteration no. 70041 ==> 0.4494331078765679\n",
            "Loss in iteration no. 70042 ==> 0.44943171266082327\n",
            "Loss in iteration no. 70043 ==> 0.44943031746721634\n",
            "Loss in iteration no. 70044 ==> 0.4494289222957467\n",
            "Loss in iteration no. 70045 ==> 0.4494275271464139\n",
            "Loss in iteration no. 70046 ==> 0.4494261320192172\n",
            "Loss in iteration no. 70047 ==> 0.4494247369141564\n",
            "Loss in iteration no. 70048 ==> 0.4494233418312309\n",
            "Loss in iteration no. 70049 ==> 0.4494219467704401\n",
            "Loss in iteration no. 70050 ==> 0.4494205517317837\n",
            "Loss in iteration no. 70051 ==> 0.449419156715261\n",
            "Loss in iteration no. 70052 ==> 0.4494177617208715\n",
            "Loss in iteration no. 70053 ==> 0.44941636674861496\n",
            "Loss in iteration no. 70054 ==> 0.44941497179849066\n",
            "Loss in iteration no. 70055 ==> 0.44941357687049815\n",
            "Loss in iteration no. 70056 ==> 0.4494121819646369\n",
            "Loss in iteration no. 70057 ==> 0.44941078708090654\n",
            "Loss in iteration no. 70058 ==> 0.44940939221930637\n",
            "Loss in iteration no. 70059 ==> 0.44940799737983605\n",
            "Loss in iteration no. 70060 ==> 0.44940660256249493\n",
            "Loss in iteration no. 70061 ==> 0.4494052077672828\n",
            "Loss in iteration no. 70062 ==> 0.4494038129941989\n",
            "Loss in iteration no. 70063 ==> 0.4494024182432429\n",
            "Loss in iteration no. 70064 ==> 0.4494010235144142\n",
            "Loss in iteration no. 70065 ==> 0.4493996288077122\n",
            "Loss in iteration no. 70066 ==> 0.4493982341231366\n",
            "Loss in iteration no. 70067 ==> 0.44939683946068676\n",
            "Loss in iteration no. 70068 ==> 0.4493954448203623\n",
            "Loss in iteration no. 70069 ==> 0.4493940502021626\n",
            "Loss in iteration no. 70070 ==> 0.4493926556060874\n",
            "Loss in iteration no. 70071 ==> 0.44939126103213584\n",
            "Loss in iteration no. 70072 ==> 0.4493898664803078\n",
            "Loss in iteration no. 70073 ==> 0.44938847195060244\n",
            "Loss in iteration no. 70074 ==> 0.44938707744301953\n",
            "Loss in iteration no. 70075 ==> 0.4493856829575583\n",
            "Loss in iteration no. 70076 ==> 0.4493842884942186\n",
            "Loss in iteration no. 70077 ==> 0.4493828940529996\n",
            "Loss in iteration no. 70078 ==> 0.44938149963390106\n",
            "Loss in iteration no. 70079 ==> 0.4493801052369224\n",
            "Loss in iteration no. 70080 ==> 0.44937871086206305\n",
            "Loss in iteration no. 70081 ==> 0.4493773165093225\n",
            "Loss in iteration no. 70082 ==> 0.4493759221787003\n",
            "Loss in iteration no. 70083 ==> 0.4493745278701961\n",
            "Loss in iteration no. 70084 ==> 0.44937313358380915\n",
            "Loss in iteration no. 70085 ==> 0.4493717393195391\n",
            "Loss in iteration no. 70086 ==> 0.4493703450773855\n",
            "Loss in iteration no. 70087 ==> 0.44936895085734774\n",
            "Loss in iteration no. 70088 ==> 0.44936755665942524\n",
            "Loss in iteration no. 70089 ==> 0.4493661624836177\n",
            "Loss in iteration no. 70090 ==> 0.4493647683299246\n",
            "Loss in iteration no. 70091 ==> 0.4493633741983453\n",
            "Loss in iteration no. 70092 ==> 0.44936198008887945\n",
            "Loss in iteration no. 70093 ==> 0.44936058600152645\n",
            "Loss in iteration no. 70094 ==> 0.44935919193628593\n",
            "Loss in iteration no. 70095 ==> 0.4493577978931573\n",
            "Loss in iteration no. 70096 ==> 0.44935640387213993\n",
            "Loss in iteration no. 70097 ==> 0.44935500987323357\n",
            "Loss in iteration no. 70098 ==> 0.4493536158964376\n",
            "Loss in iteration no. 70099 ==> 0.4493522219417515\n",
            "Loss in iteration no. 70100 ==> 0.44935082800917486\n",
            "Loss in iteration no. 70101 ==> 0.4493494340987071\n",
            "Loss in iteration no. 70102 ==> 0.44934804021034785\n",
            "Loss in iteration no. 70103 ==> 0.4493466463440964\n",
            "Loss in iteration no. 70104 ==> 0.44934525249995244\n",
            "Loss in iteration no. 70105 ==> 0.4493438586779154\n",
            "Loss in iteration no. 70106 ==> 0.4493424648779848\n",
            "Loss in iteration no. 70107 ==> 0.44934107110016014\n",
            "Loss in iteration no. 70108 ==> 0.44933967734444086\n",
            "Loss in iteration no. 70109 ==> 0.44933828361082656\n",
            "Loss in iteration no. 70110 ==> 0.44933688989931675\n",
            "Loss in iteration no. 70111 ==> 0.44933549620991076\n",
            "Loss in iteration no. 70112 ==> 0.44933410254260836\n",
            "Loss in iteration no. 70113 ==> 0.4493327088974088\n",
            "Loss in iteration no. 70114 ==> 0.44933131527431186\n",
            "Loss in iteration no. 70115 ==> 0.4493299216733167\n",
            "Loss in iteration no. 70116 ==> 0.449328528094423\n",
            "Loss in iteration no. 70117 ==> 0.44932713453763035\n",
            "Loss in iteration no. 70118 ==> 0.4493257410029382\n",
            "Loss in iteration no. 70119 ==> 0.4493243474903459\n",
            "Loss in iteration no. 70120 ==> 0.44932295399985317\n",
            "Loss in iteration no. 70121 ==> 0.44932156053145933\n",
            "Loss in iteration no. 70122 ==> 0.4493201670851641\n",
            "Loss in iteration no. 70123 ==> 0.4493187736609668\n",
            "Loss in iteration no. 70124 ==> 0.44931738025886697\n",
            "Loss in iteration no. 70125 ==> 0.44931598687886415\n",
            "Loss in iteration no. 70126 ==> 0.44931459352095776\n",
            "Loss in iteration no. 70127 ==> 0.4493132001851475\n",
            "Loss in iteration no. 70128 ==> 0.44931180687143263\n",
            "Loss in iteration no. 70129 ==> 0.4493104135798128\n",
            "Loss in iteration no. 70130 ==> 0.4493090203102874\n",
            "Loss in iteration no. 70131 ==> 0.44930762706285604\n",
            "Loss in iteration no. 70132 ==> 0.4493062338375183\n",
            "Loss in iteration no. 70133 ==> 0.44930484063427356\n",
            "Loss in iteration no. 70134 ==> 0.4493034474531212\n",
            "Loss in iteration no. 70135 ==> 0.449302054294061\n",
            "Loss in iteration no. 70136 ==> 0.44930066115709233\n",
            "Loss in iteration no. 70137 ==> 0.4492992680422146\n",
            "Loss in iteration no. 70138 ==> 0.44929787494942747\n",
            "Loss in iteration no. 70139 ==> 0.44929648187873034\n",
            "Loss in iteration no. 70140 ==> 0.44929508883012276\n",
            "Loss in iteration no. 70141 ==> 0.4492936958036043\n",
            "Loss in iteration no. 70142 ==> 0.4492923027991743\n",
            "Loss in iteration no. 70143 ==> 0.4492909098168324\n",
            "Loss in iteration no. 70144 ==> 0.4492895168565782\n",
            "Loss in iteration no. 70145 ==> 0.4492881239184108\n",
            "Loss in iteration no. 70146 ==> 0.44928673100232996\n",
            "Loss in iteration no. 70147 ==> 0.4492853381083354\n",
            "Loss in iteration no. 70148 ==> 0.44928394523642623\n",
            "Loss in iteration no. 70149 ==> 0.4492825523866022\n",
            "Loss in iteration no. 70150 ==> 0.4492811595588629\n",
            "Loss in iteration no. 70151 ==> 0.4492797667532074\n",
            "Loss in iteration no. 70152 ==> 0.4492783739696356\n",
            "Loss in iteration no. 70153 ==> 0.44927698120814696\n",
            "Loss in iteration no. 70154 ==> 0.4492755884687409\n",
            "Loss in iteration no. 70155 ==> 0.44927419575141686\n",
            "Loss in iteration no. 70156 ==> 0.4492728030561745\n",
            "Loss in iteration no. 70157 ==> 0.4492714103830132\n",
            "Loss in iteration no. 70158 ==> 0.44927001773193254\n",
            "Loss in iteration no. 70159 ==> 0.4492686251029319\n",
            "Loss in iteration no. 70160 ==> 0.44926723249601114\n",
            "Loss in iteration no. 70161 ==> 0.44926583991116925\n",
            "Loss in iteration no. 70162 ==> 0.4492644473484061\n",
            "Loss in iteration no. 70163 ==> 0.44926305480772094\n",
            "Loss in iteration no. 70164 ==> 0.4492616622891135\n",
            "Loss in iteration no. 70165 ==> 0.4492602697925832\n",
            "Loss in iteration no. 70166 ==> 0.44925887731812963\n",
            "Loss in iteration no. 70167 ==> 0.44925748486575207\n",
            "Loss in iteration no. 70168 ==> 0.44925609243545017\n",
            "Loss in iteration no. 70169 ==> 0.44925470002722345\n",
            "Loss in iteration no. 70170 ==> 0.44925330764107135\n",
            "Loss in iteration no. 70171 ==> 0.4492519152769935\n",
            "Loss in iteration no. 70172 ==> 0.4492505229349892\n",
            "Loss in iteration no. 70173 ==> 0.44924913061505817\n",
            "Loss in iteration no. 70174 ==> 0.4492477383171998\n",
            "Loss in iteration no. 70175 ==> 0.44924634604141356\n",
            "Loss in iteration no. 70176 ==> 0.4492449537876989\n",
            "Loss in iteration no. 70177 ==> 0.4492435615560556\n",
            "Loss in iteration no. 70178 ==> 0.44924216934648287\n",
            "Loss in iteration no. 70179 ==> 0.4492407771589805\n",
            "Loss in iteration no. 70180 ==> 0.44923938499354754\n",
            "Loss in iteration no. 70181 ==> 0.44923799285018406\n",
            "Loss in iteration no. 70182 ==> 0.44923660072888916\n",
            "Loss in iteration no. 70183 ==> 0.4492352086296625\n",
            "Loss in iteration no. 70184 ==> 0.4492338165525035\n",
            "Loss in iteration no. 70185 ==> 0.4492324244974118\n",
            "Loss in iteration no. 70186 ==> 0.4492310324643868\n",
            "Loss in iteration no. 70187 ==> 0.44922964045342795\n",
            "Loss in iteration no. 70188 ==> 0.44922824846453485\n",
            "Loss in iteration no. 70189 ==> 0.44922685649770705\n",
            "Loss in iteration no. 70190 ==> 0.44922546455294393\n",
            "Loss in iteration no. 70191 ==> 0.4492240726302451\n",
            "Loss in iteration no. 70192 ==> 0.44922268072960997\n",
            "Loss in iteration no. 70193 ==> 0.4492212888510381\n",
            "Loss in iteration no. 70194 ==> 0.4492198969945291\n",
            "Loss in iteration no. 70195 ==> 0.44921850516008216\n",
            "Loss in iteration no. 70196 ==> 0.44921711334769704\n",
            "Loss in iteration no. 70197 ==> 0.44921572155737327\n",
            "Loss in iteration no. 70198 ==> 0.4492143297891102\n",
            "Loss in iteration no. 70199 ==> 0.4492129380429075\n",
            "Loss in iteration no. 70200 ==> 0.4492115463187645\n",
            "Loss in iteration no. 70201 ==> 0.4492101546166808\n",
            "Loss in iteration no. 70202 ==> 0.44920876293665596\n",
            "Loss in iteration no. 70203 ==> 0.4492073712786893\n",
            "Loss in iteration no. 70204 ==> 0.44920597964278053\n",
            "Loss in iteration no. 70205 ==> 0.44920458802892904\n",
            "Loss in iteration no. 70206 ==> 0.44920319643713436\n",
            "Loss in iteration no. 70207 ==> 0.44920180486739597\n",
            "Loss in iteration no. 70208 ==> 0.44920041331971333\n",
            "Loss in iteration no. 70209 ==> 0.4491990217940862\n",
            "Loss in iteration no. 70210 ==> 0.4491976302905138\n",
            "Loss in iteration no. 70211 ==> 0.4491962388089957\n",
            "Loss in iteration no. 70212 ==> 0.4491948473495314\n",
            "Loss in iteration no. 70213 ==> 0.44919345591212057\n",
            "Loss in iteration no. 70214 ==> 0.44919206449676247\n",
            "Loss in iteration no. 70215 ==> 0.4491906731034568\n",
            "Loss in iteration no. 70216 ==> 0.4491892817322029\n",
            "Loss in iteration no. 70217 ==> 0.44918789038300044\n",
            "Loss in iteration no. 70218 ==> 0.4491864990558489\n",
            "Loss in iteration no. 70219 ==> 0.44918510775074766\n",
            "Loss in iteration no. 70220 ==> 0.44918371646769617\n",
            "Loss in iteration no. 70221 ==> 0.44918232520669416\n",
            "Loss in iteration no. 70222 ==> 0.44918093396774106\n",
            "Loss in iteration no. 70223 ==> 0.4491795427508364\n",
            "Loss in iteration no. 70224 ==> 0.4491781515559795\n",
            "Loss in iteration no. 70225 ==> 0.4491767603831701\n",
            "Loss in iteration no. 70226 ==> 0.44917536923240753\n",
            "Loss in iteration no. 70227 ==> 0.4491739781036914\n",
            "Loss in iteration no. 70228 ==> 0.44917258699702123\n",
            "Loss in iteration no. 70229 ==> 0.4491711959123964\n",
            "Loss in iteration no. 70230 ==> 0.4491698048498166\n",
            "Loss in iteration no. 70231 ==> 0.4491684138092811\n",
            "Loss in iteration no. 70232 ==> 0.4491670227907896\n",
            "Loss in iteration no. 70233 ==> 0.4491656317943415\n",
            "Loss in iteration no. 70234 ==> 0.4491642408199363\n",
            "Loss in iteration no. 70235 ==> 0.4491628498675736\n",
            "Loss in iteration no. 70236 ==> 0.4491614589372529\n",
            "Loss in iteration no. 70237 ==> 0.4491600680289735\n",
            "Loss in iteration no. 70238 ==> 0.44915867714273533\n",
            "Loss in iteration no. 70239 ==> 0.44915728627853735\n",
            "Loss in iteration no. 70240 ==> 0.44915589543637946\n",
            "Loss in iteration no. 70241 ==> 0.4491545046162611\n",
            "Loss in iteration no. 70242 ==> 0.4491531138181817\n",
            "Loss in iteration no. 70243 ==> 0.44915172304214074\n",
            "Loss in iteration no. 70244 ==> 0.44915033228813783\n",
            "Loss in iteration no. 70245 ==> 0.4491489415561723\n",
            "Loss in iteration no. 70246 ==> 0.4491475508462439\n",
            "Loss in iteration no. 70247 ==> 0.44914616015835196\n",
            "Loss in iteration no. 70248 ==> 0.449144769492496\n",
            "Loss in iteration no. 70249 ==> 0.44914337884867556\n",
            "Loss in iteration no. 70250 ==> 0.44914198822689017\n",
            "Loss in iteration no. 70251 ==> 0.4491405976271393\n",
            "Loss in iteration no. 70252 ==> 0.44913920704942245\n",
            "Loss in iteration no. 70253 ==> 0.4491378164937392\n",
            "Loss in iteration no. 70254 ==> 0.44913642596008896\n",
            "Loss in iteration no. 70255 ==> 0.4491350354484712\n",
            "Loss in iteration no. 70256 ==> 0.44913364495888564\n",
            "Loss in iteration no. 70257 ==> 0.4491322544913315\n",
            "Loss in iteration no. 70258 ==> 0.4491308640458085\n",
            "Loss in iteration no. 70259 ==> 0.4491294736223161\n",
            "Loss in iteration no. 70260 ==> 0.4491280832208536\n",
            "Loss in iteration no. 70261 ==> 0.4491266928414208\n",
            "Loss in iteration no. 70262 ==> 0.4491253024840171\n",
            "Loss in iteration no. 70263 ==> 0.449123912148642\n",
            "Loss in iteration no. 70264 ==> 0.44912252183529494\n",
            "Loss in iteration no. 70265 ==> 0.44912113154397554\n",
            "Loss in iteration no. 70266 ==> 0.4491197412746832\n",
            "Loss in iteration no. 70267 ==> 0.44911835102741754\n",
            "Loss in iteration no. 70268 ==> 0.4491169608021779\n",
            "Loss in iteration no. 70269 ==> 0.4491155705989639\n",
            "Loss in iteration no. 70270 ==> 0.4491141804177751\n",
            "Loss in iteration no. 70271 ==> 0.44911279025861095\n",
            "Loss in iteration no. 70272 ==> 0.4491114001214708\n",
            "Loss in iteration no. 70273 ==> 0.44911001000635453\n",
            "Loss in iteration no. 70274 ==> 0.44910861991326123\n",
            "Loss in iteration no. 70275 ==> 0.44910722984219054\n",
            "Loss in iteration no. 70276 ==> 0.44910583979314206\n",
            "Loss in iteration no. 70277 ==> 0.4491044497661154\n",
            "Loss in iteration no. 70278 ==> 0.44910305976110976\n",
            "Loss in iteration no. 70279 ==> 0.4491016697781249\n",
            "Loss in iteration no. 70280 ==> 0.44910027981716005\n",
            "Loss in iteration no. 70281 ==> 0.44909888987821506\n",
            "Loss in iteration no. 70282 ==> 0.4490974999612892\n",
            "Loss in iteration no. 70283 ==> 0.44909611006638206\n",
            "Loss in iteration no. 70284 ==> 0.4490947201934931\n",
            "Loss in iteration no. 70285 ==> 0.4490933303426219\n",
            "Loss in iteration no. 70286 ==> 0.44909194051376783\n",
            "Loss in iteration no. 70287 ==> 0.44909055070693055\n",
            "Loss in iteration no. 70288 ==> 0.4490891609221095\n",
            "Loss in iteration no. 70289 ==> 0.44908777115930415\n",
            "Loss in iteration no. 70290 ==> 0.4490863814185141\n",
            "Loss in iteration no. 70291 ==> 0.4490849916997388\n",
            "Loss in iteration no. 70292 ==> 0.44908360200297776\n",
            "Loss in iteration no. 70293 ==> 0.4490822123282305\n",
            "Loss in iteration no. 70294 ==> 0.44908082267549637\n",
            "Loss in iteration no. 70295 ==> 0.4490794330447751\n",
            "Loss in iteration no. 70296 ==> 0.44907804343606605\n",
            "Loss in iteration no. 70297 ==> 0.44907665384936885\n",
            "Loss in iteration no. 70298 ==> 0.4490752642846829\n",
            "Loss in iteration no. 70299 ==> 0.4490738747420078\n",
            "Loss in iteration no. 70300 ==> 0.4490724852213429\n",
            "Loss in iteration no. 70301 ==> 0.4490710957226879\n",
            "Loss in iteration no. 70302 ==> 0.44906970624604214\n",
            "Loss in iteration no. 70303 ==> 0.44906831679140524\n",
            "Loss in iteration no. 70304 ==> 0.44906692735877674\n",
            "Loss in iteration no. 70305 ==> 0.44906553794815596\n",
            "Loss in iteration no. 70306 ==> 0.4490641485595426\n",
            "Loss in iteration no. 70307 ==> 0.449062759192936\n",
            "Loss in iteration no. 70308 ==> 0.4490613698483357\n",
            "Loss in iteration no. 70309 ==> 0.4490599805257413\n",
            "Loss in iteration no. 70310 ==> 0.44905859122515235\n",
            "Loss in iteration no. 70311 ==> 0.4490572019465681\n",
            "Loss in iteration no. 70312 ==> 0.44905581268998845\n",
            "Loss in iteration no. 70313 ==> 0.4490544234554125\n",
            "Loss in iteration no. 70314 ==> 0.44905303424284004\n",
            "Loss in iteration no. 70315 ==> 0.4490516450522704\n",
            "Loss in iteration no. 70316 ==> 0.44905025588370323\n",
            "Loss in iteration no. 70317 ==> 0.44904886673713795\n",
            "Loss in iteration no. 70318 ==> 0.4490474776125739\n",
            "Loss in iteration no. 70319 ==> 0.44904608851001093\n",
            "Loss in iteration no. 70320 ==> 0.44904469942944847\n",
            "Loss in iteration no. 70321 ==> 0.4490433103708858\n",
            "Loss in iteration no. 70322 ==> 0.4490419213343225\n",
            "Loss in iteration no. 70323 ==> 0.4490405323197583\n",
            "Loss in iteration no. 70324 ==> 0.4490391433271925\n",
            "Loss in iteration no. 70325 ==> 0.4490377543566246\n",
            "Loss in iteration no. 70326 ==> 0.4490363654080542\n",
            "Loss in iteration no. 70327 ==> 0.44903497648148066\n",
            "Loss in iteration no. 70328 ==> 0.44903358757690376\n",
            "Loss in iteration no. 70329 ==> 0.4490321986943227\n",
            "Loss in iteration no. 70330 ==> 0.4490308098337373\n",
            "Loss in iteration no. 70331 ==> 0.4490294209951468\n",
            "Loss in iteration no. 70332 ==> 0.4490280321785507\n",
            "Loss in iteration no. 70333 ==> 0.44902664338394865\n",
            "Loss in iteration no. 70334 ==> 0.4490252546113402\n",
            "Loss in iteration no. 70335 ==> 0.4490238658607247\n",
            "Loss in iteration no. 70336 ==> 0.4490224771321017\n",
            "Loss in iteration no. 70337 ==> 0.44902108842547084\n",
            "Loss in iteration no. 70338 ==> 0.4490196997408314\n",
            "Loss in iteration no. 70339 ==> 0.44901831107818296\n",
            "Loss in iteration no. 70340 ==> 0.44901692243752517\n",
            "Loss in iteration no. 70341 ==> 0.4490155338188575\n",
            "Loss in iteration no. 70342 ==> 0.44901414522217925\n",
            "Loss in iteration no. 70343 ==> 0.4490127566474902\n",
            "Loss in iteration no. 70344 ==> 0.4490113680947896\n",
            "Loss in iteration no. 70345 ==> 0.4490099795640771\n",
            "Loss in iteration no. 70346 ==> 0.44900859105535224\n",
            "Loss in iteration no. 70347 ==> 0.4490072025686144\n",
            "Loss in iteration no. 70348 ==> 0.4490058141038632\n",
            "Loss in iteration no. 70349 ==> 0.44900442566109816\n",
            "Loss in iteration no. 70350 ==> 0.44900303724031876\n",
            "Loss in iteration no. 70351 ==> 0.4490016488415243\n",
            "Loss in iteration no. 70352 ==> 0.44900026046471464\n",
            "Loss in iteration no. 70353 ==> 0.44899887210988904\n",
            "Loss in iteration no. 70354 ==> 0.4489974837770472\n",
            "Loss in iteration no. 70355 ==> 0.44899609546618835\n",
            "Loss in iteration no. 70356 ==> 0.4489947071773122\n",
            "Loss in iteration no. 70357 ==> 0.4489933189104183\n",
            "Loss in iteration no. 70358 ==> 0.448991930665506\n",
            "Loss in iteration no. 70359 ==> 0.4489905424425748\n",
            "Loss in iteration no. 70360 ==> 0.4489891542416244\n",
            "Loss in iteration no. 70361 ==> 0.44898776606265406\n",
            "Loss in iteration no. 70362 ==> 0.4489863779056635\n",
            "Loss in iteration no. 70363 ==> 0.44898498977065215\n",
            "Loss in iteration no. 70364 ==> 0.4489836016576195\n",
            "Loss in iteration no. 70365 ==> 0.4489822135665651\n",
            "Loss in iteration no. 70366 ==> 0.4489808254974884\n",
            "Loss in iteration no. 70367 ==> 0.44897943745038893\n",
            "Loss in iteration no. 70368 ==> 0.44897804942526615\n",
            "Loss in iteration no. 70369 ==> 0.44897666142211967\n",
            "Loss in iteration no. 70370 ==> 0.4489752734409489\n",
            "Loss in iteration no. 70371 ==> 0.4489738854817535\n",
            "Loss in iteration no. 70372 ==> 0.4489724975445327\n",
            "Loss in iteration no. 70373 ==> 0.44897110962928627\n",
            "Loss in iteration no. 70374 ==> 0.44896972173601357\n",
            "Loss in iteration no. 70375 ==> 0.44896833386471424\n",
            "Loss in iteration no. 70376 ==> 0.44896694601538767\n",
            "Loss in iteration no. 70377 ==> 0.44896555818803335\n",
            "Loss in iteration no. 70378 ==> 0.4489641703826508\n",
            "Loss in iteration no. 70379 ==> 0.4489627825992397\n",
            "Loss in iteration no. 70380 ==> 0.4489613948377994\n",
            "Loss in iteration no. 70381 ==> 0.4489600070983293\n",
            "Loss in iteration no. 70382 ==> 0.44895861938082915\n",
            "Loss in iteration no. 70383 ==> 0.4489572316852983\n",
            "Loss in iteration no. 70384 ==> 0.4489558440117363\n",
            "Loss in iteration no. 70385 ==> 0.4489544563601427\n",
            "Loss in iteration no. 70386 ==> 0.4489530687305169\n",
            "Loss in iteration no. 70387 ==> 0.44895168112285855\n",
            "Loss in iteration no. 70388 ==> 0.4489502935371669\n",
            "Loss in iteration no. 70389 ==> 0.44894890597344184\n",
            "Loss in iteration no. 70390 ==> 0.4489475184316826\n",
            "Loss in iteration no. 70391 ==> 0.44894613091188873\n",
            "Loss in iteration no. 70392 ==> 0.4489447434140598\n",
            "Loss in iteration no. 70393 ==> 0.4489433559381953\n",
            "Loss in iteration no. 70394 ==> 0.4489419684842948\n",
            "Loss in iteration no. 70395 ==> 0.44894058105235757\n",
            "Loss in iteration no. 70396 ==> 0.4489391936423833\n",
            "Loss in iteration no. 70397 ==> 0.4489378062543715\n",
            "Loss in iteration no. 70398 ==> 0.44893641888832164\n",
            "Loss in iteration no. 70399 ==> 0.4489350315442333\n",
            "Loss in iteration no. 70400 ==> 0.44893364422210585\n",
            "Loss in iteration no. 70401 ==> 0.44893225692193894\n",
            "Loss in iteration no. 70402 ==> 0.44893086964373197\n",
            "Loss in iteration no. 70403 ==> 0.44892948238748454\n",
            "Loss in iteration no. 70404 ==> 0.4489280951531961\n",
            "Loss in iteration no. 70405 ==> 0.4489267079408661\n",
            "Loss in iteration no. 70406 ==> 0.4489253207504942\n",
            "Loss in iteration no. 70407 ==> 0.4489239335820797\n",
            "Loss in iteration no. 70408 ==> 0.44892254643562235\n",
            "Loss in iteration no. 70409 ==> 0.4489211593111214\n",
            "Loss in iteration no. 70410 ==> 0.44891977220857654\n",
            "Loss in iteration no. 70411 ==> 0.4489183851279873\n",
            "Loss in iteration no. 70412 ==> 0.4489169980693531\n",
            "Loss in iteration no. 70413 ==> 0.4489156110326734\n",
            "Loss in iteration no. 70414 ==> 0.44891422401794784\n",
            "Loss in iteration no. 70415 ==> 0.4489128370251758\n",
            "Loss in iteration no. 70416 ==> 0.4489114500543569\n",
            "Loss in iteration no. 70417 ==> 0.4489100631054905\n",
            "Loss in iteration no. 70418 ==> 0.4489086761785763\n",
            "Loss in iteration no. 70419 ==> 0.44890728927361373\n",
            "Loss in iteration no. 70420 ==> 0.4489059023906022\n",
            "Loss in iteration no. 70421 ==> 0.4489045155295413\n",
            "Loss in iteration no. 70422 ==> 0.44890312869043053\n",
            "Loss in iteration no. 70423 ==> 0.4489017418732694\n",
            "Loss in iteration no. 70424 ==> 0.44890035507805753\n",
            "Loss in iteration no. 70425 ==> 0.44889896830479425\n",
            "Loss in iteration no. 70426 ==> 0.4488975815534791\n",
            "Loss in iteration no. 70427 ==> 0.4488961948241117\n",
            "Loss in iteration no. 70428 ==> 0.4488948081166913\n",
            "Loss in iteration no. 70429 ==> 0.4488934214312177\n",
            "Loss in iteration no. 70430 ==> 0.44889203476769024\n",
            "Loss in iteration no. 70431 ==> 0.44889064812610857\n",
            "Loss in iteration no. 70432 ==> 0.44888926150647207\n",
            "Loss in iteration no. 70433 ==> 0.4488878749087803\n",
            "Loss in iteration no. 70434 ==> 0.4488864883330328\n",
            "Loss in iteration no. 70435 ==> 0.44888510177922897\n",
            "Loss in iteration no. 70436 ==> 0.4488837152473684\n",
            "Loss in iteration no. 70437 ==> 0.44888232873745054\n",
            "Loss in iteration no. 70438 ==> 0.44888094224947506\n",
            "Loss in iteration no. 70439 ==> 0.4488795557834413\n",
            "Loss in iteration no. 70440 ==> 0.4488781693393487\n",
            "Loss in iteration no. 70441 ==> 0.448876782917197\n",
            "Loss in iteration no. 70442 ==> 0.4488753965169856\n",
            "Loss in iteration no. 70443 ==> 0.4488740101387139\n",
            "Loss in iteration no. 70444 ==> 0.4488726237823816\n",
            "Loss in iteration no. 70445 ==> 0.448871237447988\n",
            "Loss in iteration no. 70446 ==> 0.44886985113553285\n",
            "Loss in iteration no. 70447 ==> 0.4488684648450154\n",
            "Loss in iteration no. 70448 ==> 0.44886707857643543\n",
            "Loss in iteration no. 70449 ==> 0.44886569232979223\n",
            "Loss in iteration no. 70450 ==> 0.4488643061050853\n",
            "Loss in iteration no. 70451 ==> 0.44886291990231447\n",
            "Loss in iteration no. 70452 ==> 0.44886153372147886\n",
            "Loss in iteration no. 70453 ==> 0.4488601475625781\n",
            "Loss in iteration no. 70454 ==> 0.44885876142561176\n",
            "Loss in iteration no. 70455 ==> 0.4488573753105793\n",
            "Loss in iteration no. 70456 ==> 0.4488559892174803\n",
            "Loss in iteration no. 70457 ==> 0.4488546031463142\n",
            "Loss in iteration no. 70458 ==> 0.44885321709708054\n",
            "Loss in iteration no. 70459 ==> 0.4488518310697787\n",
            "Loss in iteration no. 70460 ==> 0.44885044506440847\n",
            "Loss in iteration no. 70461 ==> 0.44884905908096906\n",
            "Loss in iteration no. 70462 ==> 0.44884767311946006\n",
            "Loss in iteration no. 70463 ==> 0.44884628717988106\n",
            "Loss in iteration no. 70464 ==> 0.44884490126223153\n",
            "Loss in iteration no. 70465 ==> 0.44884351536651107\n",
            "Loss in iteration no. 70466 ==> 0.448842129492719\n",
            "Loss in iteration no. 70467 ==> 0.448840743640855\n",
            "Loss in iteration no. 70468 ==> 0.4488393578109185\n",
            "Loss in iteration no. 70469 ==> 0.448837972002909\n",
            "Loss in iteration no. 70470 ==> 0.448836586216826\n",
            "Loss in iteration no. 70471 ==> 0.4488352004526689\n",
            "Loss in iteration no. 70472 ==> 0.44883381471043754\n",
            "Loss in iteration no. 70473 ==> 0.4488324289901311\n",
            "Loss in iteration no. 70474 ==> 0.4488310432917493\n",
            "Loss in iteration no. 70475 ==> 0.44882965761529153\n",
            "Loss in iteration no. 70476 ==> 0.4488282719607573\n",
            "Loss in iteration no. 70477 ==> 0.4488268863281462\n",
            "Loss in iteration no. 70478 ==> 0.44882550071745764\n",
            "Loss in iteration no. 70479 ==> 0.44882411512869125\n",
            "Loss in iteration no. 70480 ==> 0.44882272956184643\n",
            "Loss in iteration no. 70481 ==> 0.44882134401692264\n",
            "Loss in iteration no. 70482 ==> 0.44881995849391954\n",
            "Loss in iteration no. 70483 ==> 0.4488185729928367\n",
            "Loss in iteration no. 70484 ==> 0.44881718751367333\n",
            "Loss in iteration no. 70485 ==> 0.4488158020564291\n",
            "Loss in iteration no. 70486 ==> 0.4488144166211036\n",
            "Loss in iteration no. 70487 ==> 0.4488130312076962\n",
            "Loss in iteration no. 70488 ==> 0.4488116458162066\n",
            "Loss in iteration no. 70489 ==> 0.448810260446634\n",
            "Loss in iteration no. 70490 ==> 0.4488088750989783\n",
            "Loss in iteration no. 70491 ==> 0.44880748977323864\n",
            "Loss in iteration no. 70492 ==> 0.44880610446941477\n",
            "Loss in iteration no. 70493 ==> 0.44880471918750614\n",
            "Loss in iteration no. 70494 ==> 0.4488033339275122\n",
            "Loss in iteration no. 70495 ==> 0.44880194868943246\n",
            "Loss in iteration no. 70496 ==> 0.4488005634732665\n",
            "Loss in iteration no. 70497 ==> 0.4487991782790138\n",
            "Loss in iteration no. 70498 ==> 0.4487977931066739\n",
            "Loss in iteration no. 70499 ==> 0.44879640795624626\n",
            "Loss in iteration no. 70500 ==> 0.44879502282773037\n",
            "Loss in iteration no. 70501 ==> 0.4487936377211257\n",
            "Loss in iteration no. 70502 ==> 0.44879225263643185\n",
            "Loss in iteration no. 70503 ==> 0.44879086757364833\n",
            "Loss in iteration no. 70504 ==> 0.4487894825327747\n",
            "Loss in iteration no. 70505 ==> 0.4487880975138104\n",
            "Loss in iteration no. 70506 ==> 0.4487867125167549\n",
            "Loss in iteration no. 70507 ==> 0.4487853275416076\n",
            "Loss in iteration no. 70508 ==> 0.4487839425883683\n",
            "Loss in iteration no. 70509 ==> 0.4487825576570363\n",
            "Loss in iteration no. 70510 ==> 0.4487811727476112\n",
            "Loss in iteration no. 70511 ==> 0.44877978786009254\n",
            "Loss in iteration no. 70512 ==> 0.44877840299447963\n",
            "Loss in iteration no. 70513 ==> 0.44877701815077226\n",
            "Loss in iteration no. 70514 ==> 0.4487756333289697\n",
            "Loss in iteration no. 70515 ==> 0.4487742485290716\n",
            "Loss in iteration no. 70516 ==> 0.44877286375107744\n",
            "Loss in iteration no. 70517 ==> 0.4487714789949867\n",
            "Loss in iteration no. 70518 ==> 0.44877009426079884\n",
            "Loss in iteration no. 70519 ==> 0.4487687095485134\n",
            "Loss in iteration no. 70520 ==> 0.44876732485813003\n",
            "Loss in iteration no. 70521 ==> 0.4487659401896481\n",
            "Loss in iteration no. 70522 ==> 0.44876455554306716\n",
            "Loss in iteration no. 70523 ==> 0.4487631709183867\n",
            "Loss in iteration no. 70524 ==> 0.44876178631560615\n",
            "Loss in iteration no. 70525 ==> 0.44876040173472526\n",
            "Loss in iteration no. 70526 ==> 0.4487590171757433\n",
            "Loss in iteration no. 70527 ==> 0.4487576326386598\n",
            "Loss in iteration no. 70528 ==> 0.4487562481234745\n",
            "Loss in iteration no. 70529 ==> 0.44875486363018663\n",
            "Loss in iteration no. 70530 ==> 0.4487534791587959\n",
            "Loss in iteration no. 70531 ==> 0.4487520947093016\n",
            "Loss in iteration no. 70532 ==> 0.44875071028170344\n",
            "Loss in iteration no. 70533 ==> 0.44874932587600086\n",
            "Loss in iteration no. 70534 ==> 0.44874794149219344\n",
            "Loss in iteration no. 70535 ==> 0.4487465571302805\n",
            "Loss in iteration no. 70536 ==> 0.44874517279026166\n",
            "Loss in iteration no. 70537 ==> 0.44874378847213653\n",
            "Loss in iteration no. 70538 ==> 0.4487424041759046\n",
            "Loss in iteration no. 70539 ==> 0.4487410199015652\n",
            "Loss in iteration no. 70540 ==> 0.44873963564911784\n",
            "Loss in iteration no. 70541 ==> 0.44873825141856233\n",
            "Loss in iteration no. 70542 ==> 0.44873686720989786\n",
            "Loss in iteration no. 70543 ==> 0.44873548302312416\n",
            "Loss in iteration no. 70544 ==> 0.44873409885824056\n",
            "Loss in iteration no. 70545 ==> 0.4487327147152467\n",
            "Loss in iteration no. 70546 ==> 0.44873133059414205\n",
            "Loss in iteration no. 70547 ==> 0.4487299464949261\n",
            "Loss in iteration no. 70548 ==> 0.44872856241759834\n",
            "Loss in iteration no. 70549 ==> 0.4487271783621583\n",
            "Loss in iteration no. 70550 ==> 0.4487257943286056\n",
            "Loss in iteration no. 70551 ==> 0.4487244103169396\n",
            "Loss in iteration no. 70552 ==> 0.4487230263271599\n",
            "Loss in iteration no. 70553 ==> 0.4487216423592659\n",
            "Loss in iteration no. 70554 ==> 0.44872025841325724\n",
            "Loss in iteration no. 70555 ==> 0.4487188744891333\n",
            "Loss in iteration no. 70556 ==> 0.44871749058689375\n",
            "Loss in iteration no. 70557 ==> 0.4487161067065379\n",
            "Loss in iteration no. 70558 ==> 0.44871472284806546\n",
            "Loss in iteration no. 70559 ==> 0.44871333901147575\n",
            "Loss in iteration no. 70560 ==> 0.44871195519676843\n",
            "Loss in iteration no. 70561 ==> 0.44871057140394305\n",
            "Loss in iteration no. 70562 ==> 0.448709187632999\n",
            "Loss in iteration no. 70563 ==> 0.4487078038839357\n",
            "Loss in iteration no. 70564 ==> 0.4487064201567529\n",
            "Loss in iteration no. 70565 ==> 0.44870503645144993\n",
            "Loss in iteration no. 70566 ==> 0.4487036527680263\n",
            "Loss in iteration no. 70567 ==> 0.4487022691064817\n",
            "Loss in iteration no. 70568 ==> 0.4487008854668155\n",
            "Loss in iteration no. 70569 ==> 0.4486995018490271\n",
            "Loss in iteration no. 70570 ==> 0.44869811825311623\n",
            "Loss in iteration no. 70571 ==> 0.4486967346790824\n",
            "Loss in iteration no. 70572 ==> 0.44869535112692494\n",
            "Loss in iteration no. 70573 ==> 0.4486939675966433\n",
            "Loss in iteration no. 70574 ==> 0.4486925840882374\n",
            "Loss in iteration no. 70575 ==> 0.44869120060170625\n",
            "Loss in iteration no. 70576 ==> 0.44868981713704986\n",
            "Loss in iteration no. 70577 ==> 0.4486884336942673\n",
            "Loss in iteration no. 70578 ==> 0.4486870502733582\n",
            "Loss in iteration no. 70579 ==> 0.44868566687432226\n",
            "Loss in iteration no. 70580 ==> 0.4486842834971588\n",
            "Loss in iteration no. 70581 ==> 0.44868290014186735\n",
            "Loss in iteration no. 70582 ==> 0.4486815168084476\n",
            "Loss in iteration no. 70583 ==> 0.4486801334968988\n",
            "Loss in iteration no. 70584 ==> 0.4486787502072206\n",
            "Loss in iteration no. 70585 ==> 0.4486773669394124\n",
            "Loss in iteration no. 70586 ==> 0.44867598369347395\n",
            "Loss in iteration no. 70587 ==> 0.4486746004694045\n",
            "Loss in iteration no. 70588 ==> 0.4486732172672037\n",
            "Loss in iteration no. 70589 ==> 0.448671834086871\n",
            "Loss in iteration no. 70590 ==> 0.448670450928406\n",
            "Loss in iteration no. 70591 ==> 0.4486690677918082\n",
            "Loss in iteration no. 70592 ==> 0.448667684677077\n",
            "Loss in iteration no. 70593 ==> 0.44866630158421184\n",
            "Loss in iteration no. 70594 ==> 0.44866491851321255\n",
            "Loss in iteration no. 70595 ==> 0.4486635354640784\n",
            "Loss in iteration no. 70596 ==> 0.4486621524368089\n",
            "Loss in iteration no. 70597 ==> 0.4486607694314036\n",
            "Loss in iteration no. 70598 ==> 0.44865938644786213\n",
            "Loss in iteration no. 70599 ==> 0.4486580034861837\n",
            "Loss in iteration no. 70600 ==> 0.4486566205463682\n",
            "Loss in iteration no. 70601 ==> 0.4486552376284148\n",
            "Loss in iteration no. 70602 ==> 0.4486538547323232\n",
            "Loss in iteration no. 70603 ==> 0.448652471858093\n",
            "Loss in iteration no. 70604 ==> 0.4486510890057234\n",
            "Loss in iteration no. 70605 ==> 0.44864970617521427\n",
            "Loss in iteration no. 70606 ==> 0.4486483233665648\n",
            "Loss in iteration no. 70607 ==> 0.4486469405797747\n",
            "Loss in iteration no. 70608 ==> 0.4486455578148435\n",
            "Loss in iteration no. 70609 ==> 0.44864417507177057\n",
            "Loss in iteration no. 70610 ==> 0.4486427923505553\n",
            "Loss in iteration no. 70611 ==> 0.44864140965119764\n",
            "Loss in iteration no. 70612 ==> 0.44864002697369676\n",
            "Loss in iteration no. 70613 ==> 0.4486386443180523\n",
            "Loss in iteration no. 70614 ==> 0.4486372616842636\n",
            "Loss in iteration no. 70615 ==> 0.4486358790723305\n",
            "Loss in iteration no. 70616 ==> 0.4486344964822521\n",
            "Loss in iteration no. 70617 ==> 0.4486331139140282\n",
            "Loss in iteration no. 70618 ==> 0.44863173136765827\n",
            "Loss in iteration no. 70619 ==> 0.44863034884314174\n",
            "Loss in iteration no. 70620 ==> 0.4486289663404782\n",
            "Loss in iteration no. 70621 ==> 0.448627583859667\n",
            "Loss in iteration no. 70622 ==> 0.44862620140070797\n",
            "Loss in iteration no. 70623 ==> 0.4486248189636003\n",
            "Loss in iteration no. 70624 ==> 0.4486234365483436\n",
            "Loss in iteration no. 70625 ==> 0.4486220541549375\n",
            "Loss in iteration no. 70626 ==> 0.4486206717833813\n",
            "Loss in iteration no. 70627 ==> 0.4486192894336747\n",
            "Loss in iteration no. 70628 ==> 0.4486179071058171\n",
            "Loss in iteration no. 70629 ==> 0.448616524799808\n",
            "Loss in iteration no. 70630 ==> 0.4486151425156471\n",
            "Loss in iteration no. 70631 ==> 0.44861376025333366\n",
            "Loss in iteration no. 70632 ==> 0.4486123780128674\n",
            "Loss in iteration no. 70633 ==> 0.4486109957942476\n",
            "Loss in iteration no. 70634 ==> 0.44860961359747403\n",
            "Loss in iteration no. 70635 ==> 0.44860823142254597\n",
            "Loss in iteration no. 70636 ==> 0.44860684926946304\n",
            "Loss in iteration no. 70637 ==> 0.44860546713822474\n",
            "Loss in iteration no. 70638 ==> 0.4486040850288307\n",
            "Loss in iteration no. 70639 ==> 0.44860270294128013\n",
            "Loss in iteration no. 70640 ==> 0.4486013208755729\n",
            "Loss in iteration no. 70641 ==> 0.44859993883170834\n",
            "Loss in iteration no. 70642 ==> 0.4485985568096858\n",
            "Loss in iteration no. 70643 ==> 0.4485971748095051\n",
            "Loss in iteration no. 70644 ==> 0.4485957928311656\n",
            "Loss in iteration no. 70645 ==> 0.4485944108746667\n",
            "Loss in iteration no. 70646 ==> 0.4485930289400082\n",
            "Loss in iteration no. 70647 ==> 0.4485916470271894\n",
            "Loss in iteration no. 70648 ==> 0.4485902651362097\n",
            "Loss in iteration no. 70649 ==> 0.44858888326706897\n",
            "Loss in iteration no. 70650 ==> 0.4485875014197664\n",
            "Loss in iteration no. 70651 ==> 0.4485861195943016\n",
            "Loss in iteration no. 70652 ==> 0.4485847377906742\n",
            "Loss in iteration no. 70653 ==> 0.4485833560088835\n",
            "Loss in iteration no. 70654 ==> 0.44858197424892926\n",
            "Loss in iteration no. 70655 ==> 0.44858059251081067\n",
            "Loss in iteration no. 70656 ==> 0.44857921079452767\n",
            "Loss in iteration no. 70657 ==> 0.4485778291000793\n",
            "Loss in iteration no. 70658 ==> 0.4485764474274654\n",
            "Loss in iteration no. 70659 ==> 0.44857506577668527\n",
            "Loss in iteration no. 70660 ==> 0.4485736841477386\n",
            "Loss in iteration no. 70661 ==> 0.44857230254062486\n",
            "Loss in iteration no. 70662 ==> 0.44857092095534357\n",
            "Loss in iteration no. 70663 ==> 0.4485695393918941\n",
            "Loss in iteration no. 70664 ==> 0.44856815785027615\n",
            "Loss in iteration no. 70665 ==> 0.44856677633048897\n",
            "Loss in iteration no. 70666 ==> 0.44856539483253244\n",
            "Loss in iteration no. 70667 ==> 0.44856401335640583\n",
            "Loss in iteration no. 70668 ==> 0.44856263190210865\n",
            "Loss in iteration no. 70669 ==> 0.4485612504696404\n",
            "Loss in iteration no. 70670 ==> 0.4485598690590008\n",
            "Loss in iteration no. 70671 ==> 0.4485584876701892\n",
            "Loss in iteration no. 70672 ==> 0.448557106303205\n",
            "Loss in iteration no. 70673 ==> 0.44855572495804796\n",
            "Loss in iteration no. 70674 ==> 0.4485543436347174\n",
            "Loss in iteration no. 70675 ==> 0.4485529623332129\n",
            "Loss in iteration no. 70676 ==> 0.44855158105353393\n",
            "Loss in iteration no. 70677 ==> 0.4485501997956801\n",
            "Loss in iteration no. 70678 ==> 0.4485488185596509\n",
            "Loss in iteration no. 70679 ==> 0.44854743734544567\n",
            "Loss in iteration no. 70680 ==> 0.44854605615306414\n",
            "Loss in iteration no. 70681 ==> 0.4485446749825058\n",
            "Loss in iteration no. 70682 ==> 0.44854329383377\n",
            "Loss in iteration no. 70683 ==> 0.4485419127068564\n",
            "Loss in iteration no. 70684 ==> 0.4485405316017643\n",
            "Loss in iteration no. 70685 ==> 0.44853915051849363\n",
            "Loss in iteration no. 70686 ==> 0.4485377694570435\n",
            "Loss in iteration no. 70687 ==> 0.4485363884174136\n",
            "Loss in iteration no. 70688 ==> 0.44853500739960345\n",
            "Loss in iteration no. 70689 ==> 0.4485336264036124\n",
            "Loss in iteration no. 70690 ==> 0.4485322454294401\n",
            "Loss in iteration no. 70691 ==> 0.44853086447708607\n",
            "Loss in iteration no. 70692 ==> 0.44852948354654987\n",
            "Loss in iteration no. 70693 ==> 0.44852810263783094\n",
            "Loss in iteration no. 70694 ==> 0.44852672175092867\n",
            "Loss in iteration no. 70695 ==> 0.4485253408858427\n",
            "Loss in iteration no. 70696 ==> 0.4485239600425726\n",
            "Loss in iteration no. 70697 ==> 0.44852257922111777\n",
            "Loss in iteration no. 70698 ==> 0.44852119842147775\n",
            "Loss in iteration no. 70699 ==> 0.4485198176436521\n",
            "Loss in iteration no. 70700 ==> 0.44851843688764026\n",
            "Loss in iteration no. 70701 ==> 0.44851705615344184\n",
            "Loss in iteration no. 70702 ==> 0.4485156754410563\n",
            "Loss in iteration no. 70703 ==> 0.44851429475048316\n",
            "Loss in iteration no. 70704 ==> 0.44851291408172184\n",
            "Loss in iteration no. 70705 ==> 0.448511533434772\n",
            "Loss in iteration no. 70706 ==> 0.44851015280963297\n",
            "Loss in iteration no. 70707 ==> 0.4485087722063044\n",
            "Loss in iteration no. 70708 ==> 0.4485073916247859\n",
            "Loss in iteration no. 70709 ==> 0.4485060110650767\n",
            "Loss in iteration no. 70710 ==> 0.4485046305271765\n",
            "Loss in iteration no. 70711 ==> 0.4485032500110849\n",
            "Loss in iteration no. 70712 ==> 0.44850186951680115\n",
            "Loss in iteration no. 70713 ==> 0.448500489044325\n",
            "Loss in iteration no. 70714 ==> 0.44849910859365577\n",
            "Loss in iteration no. 70715 ==> 0.4484977281647931\n",
            "Loss in iteration no. 70716 ==> 0.44849634775773645\n",
            "Loss in iteration no. 70717 ==> 0.4484949673724854\n",
            "Loss in iteration no. 70718 ==> 0.4484935870090394\n",
            "Loss in iteration no. 70719 ==> 0.448492206667398\n",
            "Loss in iteration no. 70720 ==> 0.4484908263475606\n",
            "Loss in iteration no. 70721 ==> 0.4484894460495269\n",
            "Loss in iteration no. 70722 ==> 0.44848806577329625\n",
            "Loss in iteration no. 70723 ==> 0.4484866855188682\n",
            "Loss in iteration no. 70724 ==> 0.44848530528624236\n",
            "Loss in iteration no. 70725 ==> 0.4484839250754181\n",
            "Loss in iteration no. 70726 ==> 0.44848254488639505\n",
            "Loss in iteration no. 70727 ==> 0.4484811647191727\n",
            "Loss in iteration no. 70728 ==> 0.44847978457375043\n",
            "Loss in iteration no. 70729 ==> 0.448478404450128\n",
            "Loss in iteration no. 70730 ==> 0.44847702434830455\n",
            "Loss in iteration no. 70731 ==> 0.44847564426828007\n",
            "Loss in iteration no. 70732 ==> 0.4484742642100537\n",
            "Loss in iteration no. 70733 ==> 0.4484728841736251\n",
            "Loss in iteration no. 70734 ==> 0.4484715041589937\n",
            "Loss in iteration no. 70735 ==> 0.4484701241661591\n",
            "Loss in iteration no. 70736 ==> 0.4484687441951208\n",
            "Loss in iteration no. 70737 ==> 0.4484673642458783\n",
            "Loss in iteration no. 70738 ==> 0.44846598431843115\n",
            "Loss in iteration no. 70739 ==> 0.44846460441277874\n",
            "Loss in iteration no. 70740 ==> 0.44846322452892073\n",
            "Loss in iteration no. 70741 ==> 0.4484618446668565\n",
            "Loss in iteration no. 70742 ==> 0.44846046482658564\n",
            "Loss in iteration no. 70743 ==> 0.44845908500810766\n",
            "Loss in iteration no. 70744 ==> 0.4484577052114221\n",
            "Loss in iteration no. 70745 ==> 0.44845632543652836\n",
            "Loss in iteration no. 70746 ==> 0.4484549456834261\n",
            "Loss in iteration no. 70747 ==> 0.44845356595211466\n",
            "Loss in iteration no. 70748 ==> 0.4484521862425937\n",
            "Loss in iteration no. 70749 ==> 0.44845080655486275\n",
            "Loss in iteration no. 70750 ==> 0.44844942688892114\n",
            "Loss in iteration no. 70751 ==> 0.4484480472447685\n",
            "Loss in iteration no. 70752 ==> 0.44844666762240454\n",
            "Loss in iteration no. 70753 ==> 0.4484452880218284\n",
            "Loss in iteration no. 70754 ==> 0.4484439084430398\n",
            "Loss in iteration no. 70755 ==> 0.4484425288860382\n",
            "Loss in iteration no. 70756 ==> 0.44844114935082313\n",
            "Loss in iteration no. 70757 ==> 0.44843976983739414\n",
            "Loss in iteration no. 70758 ==> 0.4484383903457507\n",
            "Loss in iteration no. 70759 ==> 0.4484370108758923\n",
            "Loss in iteration no. 70760 ==> 0.44843563142781856\n",
            "Loss in iteration no. 70761 ==> 0.44843425200152875\n",
            "Loss in iteration no. 70762 ==> 0.44843287259702275\n",
            "Loss in iteration no. 70763 ==> 0.4484314932142997\n",
            "Loss in iteration no. 70764 ==> 0.44843011385335935\n",
            "Loss in iteration no. 70765 ==> 0.44842873451420123\n",
            "Loss in iteration no. 70766 ==> 0.4484273551968246\n",
            "Loss in iteration no. 70767 ==> 0.44842597590122923\n",
            "Loss in iteration no. 70768 ==> 0.4484245966274146\n",
            "Loss in iteration no. 70769 ==> 0.44842321737538005\n",
            "Loss in iteration no. 70770 ==> 0.44842183814512543\n",
            "Loss in iteration no. 70771 ==> 0.44842045893664984\n",
            "Loss in iteration no. 70772 ==> 0.4484190797499529\n",
            "Loss in iteration no. 70773 ==> 0.4484177005850343\n",
            "Loss in iteration no. 70774 ==> 0.44841632144189353\n",
            "Loss in iteration no. 70775 ==> 0.44841494232053003\n",
            "Loss in iteration no. 70776 ==> 0.4484135632209432\n",
            "Loss in iteration no. 70777 ==> 0.4484121841431328\n",
            "Loss in iteration no. 70778 ==> 0.44841080508709813\n",
            "Loss in iteration no. 70779 ==> 0.4484094260528388\n",
            "Loss in iteration no. 70780 ==> 0.4484080470403544\n",
            "Loss in iteration no. 70781 ==> 0.44840666804964424\n",
            "Loss in iteration no. 70782 ==> 0.448405289080708\n",
            "Loss in iteration no. 70783 ==> 0.4484039101335451\n",
            "Loss in iteration no. 70784 ==> 0.4484025312081551\n",
            "Loss in iteration no. 70785 ==> 0.4484011523045374\n",
            "Loss in iteration no. 70786 ==> 0.4483997734226919\n",
            "Loss in iteration no. 70787 ==> 0.44839839456261765\n",
            "Loss in iteration no. 70788 ==> 0.4483970157243143\n",
            "Loss in iteration no. 70789 ==> 0.44839563690778145\n",
            "Loss in iteration no. 70790 ==> 0.4483942581130186\n",
            "Loss in iteration no. 70791 ==> 0.4483928793400252\n",
            "Loss in iteration no. 70792 ==> 0.4483915005888008\n",
            "Loss in iteration no. 70793 ==> 0.44839012185934485\n",
            "Loss in iteration no. 70794 ==> 0.448388743151657\n",
            "Loss in iteration no. 70795 ==> 0.4483873644657367\n",
            "Loss in iteration no. 70796 ==> 0.44838598580158345\n",
            "Loss in iteration no. 70797 ==> 0.4483846071591966\n",
            "Loss in iteration no. 70798 ==> 0.44838322853857604\n",
            "Loss in iteration no. 70799 ==> 0.4483818499397209\n",
            "Loss in iteration no. 70800 ==> 0.44838047136263104\n",
            "Loss in iteration no. 70801 ==> 0.44837909280730565\n",
            "Loss in iteration no. 70802 ==> 0.4483777142737444\n",
            "Loss in iteration no. 70803 ==> 0.44837633576194685\n",
            "Loss in iteration no. 70804 ==> 0.44837495727191234\n",
            "Loss in iteration no. 70805 ==> 0.4483735788036407\n",
            "Loss in iteration no. 70806 ==> 0.448372200357131\n",
            "Loss in iteration no. 70807 ==> 0.44837082193238315\n",
            "Loss in iteration no. 70808 ==> 0.44836944352939645\n",
            "Loss in iteration no. 70809 ==> 0.4483680651481705\n",
            "Loss in iteration no. 70810 ==> 0.4483666867887047\n",
            "Loss in iteration no. 70811 ==> 0.4483653084509988\n",
            "Loss in iteration no. 70812 ==> 0.44836393013505216\n",
            "Loss in iteration no. 70813 ==> 0.44836255184086415\n",
            "Loss in iteration no. 70814 ==> 0.4483611735684345\n",
            "Loss in iteration no. 70815 ==> 0.44835979531776265\n",
            "Loss in iteration no. 70816 ==> 0.4483584170888481\n",
            "Loss in iteration no. 70817 ==> 0.4483570388816904\n",
            "Loss in iteration no. 70818 ==> 0.44835566069628907\n",
            "Loss in iteration no. 70819 ==> 0.4483542825326435\n",
            "Loss in iteration no. 70820 ==> 0.4483529043907533\n",
            "Loss in iteration no. 70821 ==> 0.44835152627061803\n",
            "Loss in iteration no. 70822 ==> 0.4483501481722373\n",
            "Loss in iteration no. 70823 ==> 0.44834877009561025\n",
            "Loss in iteration no. 70824 ==> 0.44834739204073676\n",
            "Loss in iteration no. 70825 ==> 0.44834601400761603\n",
            "Loss in iteration no. 70826 ==> 0.44834463599624796\n",
            "Loss in iteration no. 70827 ==> 0.4483432580066318\n",
            "Loss in iteration no. 70828 ==> 0.44834188003876707\n",
            "Loss in iteration no. 70829 ==> 0.4483405020926533\n",
            "Loss in iteration no. 70830 ==> 0.4483391241682901\n",
            "Loss in iteration no. 70831 ==> 0.4483377462656769\n",
            "Loss in iteration no. 70832 ==> 0.4483363683848132\n",
            "Loss in iteration no. 70833 ==> 0.44833499052569864\n",
            "Loss in iteration no. 70834 ==> 0.44833361268833255\n",
            "Loss in iteration no. 70835 ==> 0.44833223487271456\n",
            "Loss in iteration no. 70836 ==> 0.4483308570788442\n",
            "Loss in iteration no. 70837 ==> 0.4483294793067209\n",
            "Loss in iteration no. 70838 ==> 0.44832810155634417\n",
            "Loss in iteration no. 70839 ==> 0.44832672382771366\n",
            "Loss in iteration no. 70840 ==> 0.4483253461208287\n",
            "Loss in iteration no. 70841 ==> 0.44832396843568895\n",
            "Loss in iteration no. 70842 ==> 0.4483225907722939\n",
            "Loss in iteration no. 70843 ==> 0.448321213130643\n",
            "Loss in iteration no. 70844 ==> 0.44831983551073584\n",
            "Loss in iteration no. 70845 ==> 0.4483184579125718\n",
            "Loss in iteration no. 70846 ==> 0.44831708033615053\n",
            "Loss in iteration no. 70847 ==> 0.4483157027814714\n",
            "Loss in iteration no. 70848 ==> 0.4483143252485342\n",
            "Loss in iteration no. 70849 ==> 0.44831294773733815\n",
            "Loss in iteration no. 70850 ==> 0.448311570247883\n",
            "Loss in iteration no. 70851 ==> 0.448310192780168\n",
            "Loss in iteration no. 70852 ==> 0.448308815334193\n",
            "Loss in iteration no. 70853 ==> 0.44830743790995714\n",
            "Loss in iteration no. 70854 ==> 0.4483060605074601\n",
            "Loss in iteration no. 70855 ==> 0.4483046831267016\n",
            "Loss in iteration no. 70856 ==> 0.4483033057676808\n",
            "Loss in iteration no. 70857 ==> 0.44830192843039746\n",
            "Loss in iteration no. 70858 ==> 0.44830055111485095\n",
            "Loss in iteration no. 70859 ==> 0.4482991738210409\n",
            "Loss in iteration no. 70860 ==> 0.4482977965489668\n",
            "Loss in iteration no. 70861 ==> 0.448296419298628\n",
            "Loss in iteration no. 70862 ==> 0.44829504207002424\n",
            "Loss in iteration no. 70863 ==> 0.448293664863155\n",
            "Loss in iteration no. 70864 ==> 0.44829228767801965\n",
            "Loss in iteration no. 70865 ==> 0.44829091051461784\n",
            "Loss in iteration no. 70866 ==> 0.448289533372949\n",
            "Loss in iteration no. 70867 ==> 0.44828815625301277\n",
            "Loss in iteration no. 70868 ==> 0.4482867791548084\n",
            "Loss in iteration no. 70869 ==> 0.4482854020783357\n",
            "Loss in iteration no. 70870 ==> 0.4482840250235941\n",
            "Loss in iteration no. 70871 ==> 0.44828264799058304\n",
            "Loss in iteration no. 70872 ==> 0.4482812709793022\n",
            "Loss in iteration no. 70873 ==> 0.4482798939897507\n",
            "Loss in iteration no. 70874 ==> 0.44827851702192845\n",
            "Loss in iteration no. 70875 ==> 0.44827714007583486\n",
            "Loss in iteration no. 70876 ==> 0.44827576315146944\n",
            "Loss in iteration no. 70877 ==> 0.44827438624883165\n",
            "Loss in iteration no. 70878 ==> 0.448273009367921\n",
            "Loss in iteration no. 70879 ==> 0.4482716325087371\n",
            "Loss in iteration no. 70880 ==> 0.4482702556712794\n",
            "Loss in iteration no. 70881 ==> 0.4482688788555474\n",
            "Loss in iteration no. 70882 ==> 0.44826750206154065\n",
            "Loss in iteration no. 70883 ==> 0.44826612528925863\n",
            "Loss in iteration no. 70884 ==> 0.44826474853870085\n",
            "Loss in iteration no. 70885 ==> 0.44826337180986686\n",
            "Loss in iteration no. 70886 ==> 0.44826199510275627\n",
            "Loss in iteration no. 70887 ==> 0.44826061841736836\n",
            "Loss in iteration no. 70888 ==> 0.4482592417537028\n",
            "Loss in iteration no. 70889 ==> 0.4482578651117591\n",
            "Loss in iteration no. 70890 ==> 0.44825648849153676\n",
            "Loss in iteration no. 70891 ==> 0.44825511189303524\n",
            "Loss in iteration no. 70892 ==> 0.44825373531625423\n",
            "Loss in iteration no. 70893 ==> 0.448252358761193\n",
            "Loss in iteration no. 70894 ==> 0.44825098222785115\n",
            "Loss in iteration no. 70895 ==> 0.44824960571622835\n",
            "Loss in iteration no. 70896 ==> 0.4482482292263239\n",
            "Loss in iteration no. 70897 ==> 0.4482468527581374\n",
            "Loss in iteration no. 70898 ==> 0.44824547631166833\n",
            "Loss in iteration no. 70899 ==> 0.4482440998869164\n",
            "Loss in iteration no. 70900 ==> 0.4482427234838809\n",
            "Loss in iteration no. 70901 ==> 0.4482413471025613\n",
            "Loss in iteration no. 70902 ==> 0.44823997074295735\n",
            "Loss in iteration no. 70903 ==> 0.4482385944050684\n",
            "Loss in iteration no. 70904 ==> 0.448237218088894\n",
            "Loss in iteration no. 70905 ==> 0.4482358417944337\n",
            "Loss in iteration no. 70906 ==> 0.44823446552168705\n",
            "Loss in iteration no. 70907 ==> 0.44823308927065336\n",
            "Loss in iteration no. 70908 ==> 0.4482317130413323\n",
            "Loss in iteration no. 70909 ==> 0.44823033683372343\n",
            "Loss in iteration no. 70910 ==> 0.4482289606478262\n",
            "Loss in iteration no. 70911 ==> 0.44822758448364014\n",
            "Loss in iteration no. 70912 ==> 0.4482262083411648\n",
            "Loss in iteration no. 70913 ==> 0.44822483222039955\n",
            "Loss in iteration no. 70914 ==> 0.44822345612134407\n",
            "Loss in iteration no. 70915 ==> 0.4482220800439978\n",
            "Loss in iteration no. 70916 ==> 0.4482207039883602\n",
            "Loss in iteration no. 70917 ==> 0.4482193279544309\n",
            "Loss in iteration no. 70918 ==> 0.4482179519422094\n",
            "Loss in iteration no. 70919 ==> 0.4482165759516952\n",
            "Loss in iteration no. 70920 ==> 0.4482151999828877\n",
            "Loss in iteration no. 70921 ==> 0.4482138240357865\n",
            "Loss in iteration no. 70922 ==> 0.4482124481103912\n",
            "Loss in iteration no. 70923 ==> 0.44821107220670137\n",
            "Loss in iteration no. 70924 ==> 0.4482096963247162\n",
            "Loss in iteration no. 70925 ==> 0.4482083204644354\n",
            "Loss in iteration no. 70926 ==> 0.4482069446258585\n",
            "Loss in iteration no. 70927 ==> 0.44820556880898504\n",
            "Loss in iteration no. 70928 ==> 0.44820419301381453\n",
            "Loss in iteration no. 70929 ==> 0.44820281724034644\n",
            "Loss in iteration no. 70930 ==> 0.44820144148858027\n",
            "Loss in iteration no. 70931 ==> 0.44820006575851545\n",
            "Loss in iteration no. 70932 ==> 0.4481986900501518\n",
            "Loss in iteration no. 70933 ==> 0.4481973143634886\n",
            "Loss in iteration no. 70934 ==> 0.44819593869852525\n",
            "Loss in iteration no. 70935 ==> 0.4481945630552616\n",
            "Loss in iteration no. 70936 ==> 0.448193187433697\n",
            "Loss in iteration no. 70937 ==> 0.4481918118338309\n",
            "Loss in iteration no. 70938 ==> 0.44819043625566274\n",
            "Loss in iteration no. 70939 ==> 0.44818906069919223\n",
            "Loss in iteration no. 70940 ==> 0.4481876851644188\n",
            "Loss in iteration no. 70941 ==> 0.44818630965134215\n",
            "Loss in iteration no. 70942 ==> 0.44818493415996147\n",
            "Loss in iteration no. 70943 ==> 0.44818355869027643\n",
            "Loss in iteration no. 70944 ==> 0.4481821832422866\n",
            "Loss in iteration no. 70945 ==> 0.44818080781599146\n",
            "Loss in iteration no. 70946 ==> 0.4481794324113906\n",
            "Loss in iteration no. 70947 ==> 0.4481780570284833\n",
            "Loss in iteration no. 70948 ==> 0.4481766816672693\n",
            "Loss in iteration no. 70949 ==> 0.44817530632774794\n",
            "Loss in iteration no. 70950 ==> 0.4481739310099189\n",
            "Loss in iteration no. 70951 ==> 0.4481725557137817\n",
            "Loss in iteration no. 70952 ==> 0.44817118043933557\n",
            "Loss in iteration no. 70953 ==> 0.44816980518658034\n",
            "Loss in iteration no. 70954 ==> 0.44816842995551537\n",
            "Loss in iteration no. 70955 ==> 0.4481670547461404\n",
            "Loss in iteration no. 70956 ==> 0.4481656795584547\n",
            "Loss in iteration no. 70957 ==> 0.44816430439245786\n",
            "Loss in iteration no. 70958 ==> 0.4481629292481494\n",
            "Loss in iteration no. 70959 ==> 0.44816155412552877\n",
            "Loss in iteration no. 70960 ==> 0.4481601790245956\n",
            "Loss in iteration no. 70961 ==> 0.4481588039453493\n",
            "Loss in iteration no. 70962 ==> 0.4481574288877894\n",
            "Loss in iteration no. 70963 ==> 0.4481560538519156\n",
            "Loss in iteration no. 70964 ==> 0.44815467883772714\n",
            "Loss in iteration no. 70965 ==> 0.4481533038452238\n",
            "Loss in iteration no. 70966 ==> 0.4481519288744048\n",
            "Loss in iteration no. 70967 ==> 0.44815055392526987\n",
            "Loss in iteration no. 70968 ==> 0.4481491789978186\n",
            "Loss in iteration no. 70969 ==> 0.44814780409205024\n",
            "Loss in iteration no. 70970 ==> 0.4481464292079645\n",
            "Loss in iteration no. 70971 ==> 0.44814505434556073\n",
            "Loss in iteration no. 70972 ==> 0.4481436795048386\n",
            "Loss in iteration no. 70973 ==> 0.44814230468579774\n",
            "Loss in iteration no. 70974 ==> 0.4481409298884373\n",
            "Loss in iteration no. 70975 ==> 0.4481395551127571\n",
            "Loss in iteration no. 70976 ==> 0.44813818035875647\n",
            "Loss in iteration no. 70977 ==> 0.44813680562643515\n",
            "Loss in iteration no. 70978 ==> 0.4481354309157925\n",
            "Loss in iteration no. 70979 ==> 0.44813405622682795\n",
            "Loss in iteration no. 70980 ==> 0.4481326815595412\n",
            "Loss in iteration no. 70981 ==> 0.4481313069139317\n",
            "Loss in iteration no. 70982 ==> 0.4481299322899988\n",
            "Loss in iteration no. 70983 ==> 0.44812855768774235\n",
            "Loss in iteration no. 70984 ==> 0.4481271831071617\n",
            "Loss in iteration no. 70985 ==> 0.44812580854825623\n",
            "Loss in iteration no. 70986 ==> 0.44812443401102553\n",
            "Loss in iteration no. 70987 ==> 0.4481230594954693\n",
            "Loss in iteration no. 70988 ==> 0.4481216850015869\n",
            "Loss in iteration no. 70989 ==> 0.44812031052937784\n",
            "Loss in iteration no. 70990 ==> 0.4481189360788416\n",
            "Loss in iteration no. 70991 ==> 0.44811756164997785\n",
            "Loss in iteration no. 70992 ==> 0.44811618724278585\n",
            "Loss in iteration no. 70993 ==> 0.44811481285726545\n",
            "Loss in iteration no. 70994 ==> 0.44811343849341595\n",
            "Loss in iteration no. 70995 ==> 0.44811206415123694\n",
            "Loss in iteration no. 70996 ==> 0.4481106898307279\n",
            "Loss in iteration no. 70997 ==> 0.44810931553188826\n",
            "Loss in iteration no. 70998 ==> 0.44810794125471776\n",
            "Loss in iteration no. 70999 ==> 0.4481065669992157\n",
            "Loss in iteration no. 71000 ==> 0.4481051927653817\n",
            "Loss in iteration no. 71001 ==> 0.44810381855321524\n",
            "Loss in iteration no. 71002 ==> 0.4481024443627158\n",
            "Loss in iteration no. 71003 ==> 0.44810107019388307\n",
            "Loss in iteration no. 71004 ==> 0.44809969604671646\n",
            "Loss in iteration no. 71005 ==> 0.44809832192121524\n",
            "Loss in iteration no. 71006 ==> 0.4480969478173794\n",
            "Loss in iteration no. 71007 ==> 0.44809557373520803\n",
            "Loss in iteration no. 71008 ==> 0.448094199674701\n",
            "Loss in iteration no. 71009 ==> 0.4480928256358576\n",
            "Loss in iteration no. 71010 ==> 0.44809145161867736\n",
            "Loss in iteration no. 71011 ==> 0.44809007762315983\n",
            "Loss in iteration no. 71012 ==> 0.44808870364930464\n",
            "Loss in iteration no. 71013 ==> 0.4480873296971111\n",
            "Loss in iteration no. 71014 ==> 0.4480859557665789\n",
            "Loss in iteration no. 71015 ==> 0.4480845818577074\n",
            "Loss in iteration no. 71016 ==> 0.44808320797049633\n",
            "Loss in iteration no. 71017 ==> 0.44808183410494495\n",
            "Loss in iteration no. 71018 ==> 0.4480804602610529\n",
            "Loss in iteration no. 71019 ==> 0.4480790864388199\n",
            "Loss in iteration no. 71020 ==> 0.448077712638245\n",
            "Loss in iteration no. 71021 ==> 0.44807633885932807\n",
            "Loss in iteration no. 71022 ==> 0.4480749651020686\n",
            "Loss in iteration no. 71023 ==> 0.448073591366466\n",
            "Loss in iteration no. 71024 ==> 0.4480722176525199\n",
            "Loss in iteration no. 71025 ==> 0.4480708439602296\n",
            "Loss in iteration no. 71026 ==> 0.44806947028959493\n",
            "Loss in iteration no. 71027 ==> 0.4480680966406152\n",
            "Loss in iteration no. 71028 ==> 0.44806672301328987\n",
            "Loss in iteration no. 71029 ==> 0.4480653494076186\n",
            "Loss in iteration no. 71030 ==> 0.448063975823601\n",
            "Loss in iteration no. 71031 ==> 0.4480626022612363\n",
            "Loss in iteration no. 71032 ==> 0.4480612287205242\n",
            "Loss in iteration no. 71033 ==> 0.4480598552014642\n",
            "Loss in iteration no. 71034 ==> 0.4480584817040557\n",
            "Loss in iteration no. 71035 ==> 0.4480571082282985\n",
            "Loss in iteration no. 71036 ==> 0.44805573477419175\n",
            "Loss in iteration no. 71037 ==> 0.4480543613417352\n",
            "Loss in iteration no. 71038 ==> 0.4480529879309284\n",
            "Loss in iteration no. 71039 ==> 0.44805161454177067\n",
            "Loss in iteration no. 71040 ==> 0.44805024117426173\n",
            "Loss in iteration no. 71041 ==> 0.4480488678284009\n",
            "Loss in iteration no. 71042 ==> 0.4480474945041879\n",
            "Loss in iteration no. 71043 ==> 0.4480461212016221\n",
            "Loss in iteration no. 71044 ==> 0.44804474792070303\n",
            "Loss in iteration no. 71045 ==> 0.44804337466143024\n",
            "Loss in iteration no. 71046 ==> 0.44804200142380335\n",
            "Loss in iteration no. 71047 ==> 0.44804062820782176\n",
            "Loss in iteration no. 71048 ==> 0.4480392550134849\n",
            "Loss in iteration no. 71049 ==> 0.44803788184079246\n",
            "Loss in iteration no. 71050 ==> 0.4480365086897439\n",
            "Loss in iteration no. 71051 ==> 0.4480351355603387\n",
            "Loss in iteration no. 71052 ==> 0.44803376245257637\n",
            "Loss in iteration no. 71053 ==> 0.44803238936645645\n",
            "Loss in iteration no. 71054 ==> 0.4480310163019785\n",
            "Loss in iteration no. 71055 ==> 0.448029643259142\n",
            "Loss in iteration no. 71056 ==> 0.44802827023794645\n",
            "Loss in iteration no. 71057 ==> 0.4480268972383915\n",
            "Loss in iteration no. 71058 ==> 0.44802552426047637\n",
            "Loss in iteration no. 71059 ==> 0.44802415130420087\n",
            "Loss in iteration no. 71060 ==> 0.4480227783695644\n",
            "Loss in iteration no. 71061 ==> 0.4480214054565664\n",
            "Loss in iteration no. 71062 ==> 0.44802003256520656\n",
            "Loss in iteration no. 71063 ==> 0.4480186596954842\n",
            "Loss in iteration no. 71064 ==> 0.44801728684739905\n",
            "Loss in iteration no. 71065 ==> 0.4480159140209505\n",
            "Loss in iteration no. 71066 ==> 0.4480145412161381\n",
            "Loss in iteration no. 71067 ==> 0.44801316843296135\n",
            "Loss in iteration no. 71068 ==> 0.4480117956714197\n",
            "Loss in iteration no. 71069 ==> 0.4480104229315128\n",
            "Loss in iteration no. 71070 ==> 0.44800905021324006\n",
            "Loss in iteration no. 71071 ==> 0.4480076775166011\n",
            "Loss in iteration no. 71072 ==> 0.44800630484159537\n",
            "Loss in iteration no. 71073 ==> 0.44800493218822246\n",
            "Loss in iteration no. 71074 ==> 0.4480035595564817\n",
            "Loss in iteration no. 71075 ==> 0.44800218694637267\n",
            "Loss in iteration no. 71076 ==> 0.4480008143578951\n",
            "Loss in iteration no. 71077 ==> 0.44799944179104834\n",
            "Loss in iteration no. 71078 ==> 0.44799806924583196\n",
            "Loss in iteration no. 71079 ==> 0.4479966967222454\n",
            "Loss in iteration no. 71080 ==> 0.44799532422028815\n",
            "Loss in iteration no. 71081 ==> 0.4479939517399598\n",
            "Loss in iteration no. 71082 ==> 0.44799257928125996\n",
            "Loss in iteration no. 71083 ==> 0.4479912068441879\n",
            "Loss in iteration no. 71084 ==> 0.44798983442874346\n",
            "Loss in iteration no. 71085 ==> 0.44798846203492587\n",
            "Loss in iteration no. 71086 ==> 0.44798708966273487\n",
            "Loss in iteration no. 71087 ==> 0.44798571731216974\n",
            "Loss in iteration no. 71088 ==> 0.4479843449832302\n",
            "Loss in iteration no. 71089 ==> 0.4479829726759157\n",
            "Loss in iteration no. 71090 ==> 0.4479816003902256\n",
            "Loss in iteration no. 71091 ==> 0.44798022812615984\n",
            "Loss in iteration no. 71092 ==> 0.4479788558837175\n",
            "Loss in iteration no. 71093 ==> 0.44797748366289825\n",
            "Loss in iteration no. 71094 ==> 0.44797611146370175\n",
            "Loss in iteration no. 71095 ==> 0.44797473928612724\n",
            "Loss in iteration no. 71096 ==> 0.44797336713017444\n",
            "Loss in iteration no. 71097 ==> 0.4479719949958428\n",
            "Loss in iteration no. 71098 ==> 0.4479706228831319\n",
            "Loss in iteration no. 71099 ==> 0.4479692507920412\n",
            "Loss in iteration no. 71100 ==> 0.44796787872257027\n",
            "Loss in iteration no. 71101 ==> 0.4479665066747185\n",
            "Loss in iteration no. 71102 ==> 0.44796513464848553\n",
            "Loss in iteration no. 71103 ==> 0.4479637626438708\n",
            "Loss in iteration no. 71104 ==> 0.4479623906608739\n",
            "Loss in iteration no. 71105 ==> 0.4479610186994943\n",
            "Loss in iteration no. 71106 ==> 0.4479596467597316\n",
            "Loss in iteration no. 71107 ==> 0.4479582748415852\n",
            "Loss in iteration no. 71108 ==> 0.4479569029450546\n",
            "Loss in iteration no. 71109 ==> 0.44795553107013947\n",
            "Loss in iteration no. 71110 ==> 0.44795415921683923\n",
            "Loss in iteration no. 71111 ==> 0.4479527873851534\n",
            "Loss in iteration no. 71112 ==> 0.4479514155750815\n",
            "Loss in iteration no. 71113 ==> 0.447950043786623\n",
            "Loss in iteration no. 71114 ==> 0.4479486720197776\n",
            "Loss in iteration no. 71115 ==> 0.4479473002745446\n",
            "Loss in iteration no. 71116 ==> 0.44794592855092374\n",
            "Loss in iteration no. 71117 ==> 0.4479445568489143\n",
            "Loss in iteration no. 71118 ==> 0.44794318516851583\n",
            "Loss in iteration no. 71119 ==> 0.44794181350972806\n",
            "Loss in iteration no. 71120 ==> 0.44794044187255033\n",
            "Loss in iteration no. 71121 ==> 0.44793907025698215\n",
            "Loss in iteration no. 71122 ==> 0.4479376986630231\n",
            "Loss in iteration no. 71123 ==> 0.44793632709067277\n",
            "Loss in iteration no. 71124 ==> 0.4479349555399305\n",
            "Loss in iteration no. 71125 ==> 0.44793358401079597\n",
            "Loss in iteration no. 71126 ==> 0.4479322125032686\n",
            "Loss in iteration no. 71127 ==> 0.4479308410173479\n",
            "Loss in iteration no. 71128 ==> 0.44792946955303337\n",
            "Loss in iteration no. 71129 ==> 0.4479280981103248\n",
            "Loss in iteration no. 71130 ==> 0.44792672668922134\n",
            "Loss in iteration no. 71131 ==> 0.4479253552897227\n",
            "Loss in iteration no. 71132 ==> 0.4479239839118283\n",
            "Loss in iteration no. 71133 ==> 0.4479226125555378\n",
            "Loss in iteration no. 71134 ==> 0.44792124122085053\n",
            "Loss in iteration no. 71135 ==> 0.44791986990776617\n",
            "Loss in iteration no. 71136 ==> 0.44791849861628413\n",
            "Loss in iteration no. 71137 ==> 0.447917127346404\n",
            "Loss in iteration no. 71138 ==> 0.4479157560981253\n",
            "Loss in iteration no. 71139 ==> 0.4479143848714476\n",
            "Loss in iteration no. 71140 ==> 0.4479130136663702\n",
            "Loss in iteration no. 71141 ==> 0.44791164248289284\n",
            "Loss in iteration no. 71142 ==> 0.44791027132101496\n",
            "Loss in iteration no. 71143 ==> 0.44790890018073604\n",
            "Loss in iteration no. 71144 ==> 0.4479075290620556\n",
            "Loss in iteration no. 71145 ==> 0.44790615796497324\n",
            "Loss in iteration no. 71146 ==> 0.4479047868894884\n",
            "Loss in iteration no. 71147 ==> 0.4479034158356007\n",
            "Loss in iteration no. 71148 ==> 0.4479020448033096\n",
            "Loss in iteration no. 71149 ==> 0.4479006737926145\n",
            "Loss in iteration no. 71150 ==> 0.4478993028035151\n",
            "Loss in iteration no. 71151 ==> 0.4478979318360108\n",
            "Loss in iteration no. 71152 ==> 0.4478965608901012\n",
            "Loss in iteration no. 71153 ==> 0.4478951899657858\n",
            "Loss in iteration no. 71154 ==> 0.44789381906306397\n",
            "Loss in iteration no. 71155 ==> 0.44789244818193547\n",
            "Loss in iteration no. 71156 ==> 0.4478910773223997\n",
            "Loss in iteration no. 71157 ==> 0.44788970648445614\n",
            "Loss in iteration no. 71158 ==> 0.44788833566810443\n",
            "Loss in iteration no. 71159 ==> 0.4478869648733438\n",
            "Loss in iteration no. 71160 ==> 0.44788559410017414\n",
            "Loss in iteration no. 71161 ==> 0.44788422334859485\n",
            "Loss in iteration no. 71162 ==> 0.44788285261860533\n",
            "Loss in iteration no. 71163 ==> 0.4478814819102051\n",
            "Loss in iteration no. 71164 ==> 0.44788011122339394\n",
            "Loss in iteration no. 71165 ==> 0.44787874055817106\n",
            "Loss in iteration no. 71166 ==> 0.4478773699145361\n",
            "Loss in iteration no. 71167 ==> 0.4478759992924886\n",
            "Loss in iteration no. 71168 ==> 0.447874628692028\n",
            "Loss in iteration no. 71169 ==> 0.44787325811315387\n",
            "Loss in iteration no. 71170 ==> 0.4478718875558659\n",
            "Loss in iteration no. 71171 ==> 0.4478705170201633\n",
            "Loss in iteration no. 71172 ==> 0.4478691465060458\n",
            "Loss in iteration no. 71173 ==> 0.44786777601351274\n",
            "Loss in iteration no. 71174 ==> 0.4478664055425638\n",
            "Loss in iteration no. 71175 ==> 0.4478650350931985\n",
            "Loss in iteration no. 71176 ==> 0.4478636646654162\n",
            "Loss in iteration no. 71177 ==> 0.44786229425921664\n",
            "Loss in iteration no. 71178 ==> 0.4478609238745992\n",
            "Loss in iteration no. 71179 ==> 0.4478595535115633\n",
            "Loss in iteration no. 71180 ==> 0.44785818317010867\n",
            "Loss in iteration no. 71181 ==> 0.44785681285023476\n",
            "Loss in iteration no. 71182 ==> 0.44785544255194104\n",
            "Loss in iteration no. 71183 ==> 0.4478540722752271\n",
            "Loss in iteration no. 71184 ==> 0.44785270202009225\n",
            "Loss in iteration no. 71185 ==> 0.4478513317865363\n",
            "Loss in iteration no. 71186 ==> 0.44784996157455853\n",
            "Loss in iteration no. 71187 ==> 0.4478485913841587\n",
            "Loss in iteration no. 71188 ==> 0.4478472212153363\n",
            "Loss in iteration no. 71189 ==> 0.44784585106809055\n",
            "Loss in iteration no. 71190 ==> 0.4478444809424213\n",
            "Loss in iteration no. 71191 ==> 0.4478431108383279\n",
            "Loss in iteration no. 71192 ==> 0.4478417407558098\n",
            "Loss in iteration no. 71193 ==> 0.4478403706948667\n",
            "Loss in iteration no. 71194 ==> 0.44783900065549803\n",
            "Loss in iteration no. 71195 ==> 0.44783763063770327\n",
            "Loss in iteration no. 71196 ==> 0.4478362606414821\n",
            "Loss in iteration no. 71197 ==> 0.44783489066683385\n",
            "Loss in iteration no. 71198 ==> 0.44783352071375815\n",
            "Loss in iteration no. 71199 ==> 0.4478321507822545\n",
            "Loss in iteration no. 71200 ==> 0.44783078087232253\n",
            "Loss in iteration no. 71201 ==> 0.4478294109839614\n",
            "Loss in iteration no. 71202 ==> 0.447828041117171\n",
            "Loss in iteration no. 71203 ==> 0.4478266712719506\n",
            "Loss in iteration no. 71204 ==> 0.44782530144829996\n",
            "Loss in iteration no. 71205 ==> 0.4478239316462185\n",
            "Loss in iteration no. 71206 ==> 0.4478225618657055\n",
            "Loss in iteration no. 71207 ==> 0.44782119210676086\n",
            "Loss in iteration no. 71208 ==> 0.44781982236938395\n",
            "Loss in iteration no. 71209 ==> 0.4478184526535742\n",
            "Loss in iteration no. 71210 ==> 0.4478170829593312\n",
            "Loss in iteration no. 71211 ==> 0.4478157132866544\n",
            "Loss in iteration no. 71212 ==> 0.4478143436355435\n",
            "Loss in iteration no. 71213 ==> 0.44781297400599784\n",
            "Loss in iteration no. 71214 ==> 0.4478116043980171\n",
            "Loss in iteration no. 71215 ==> 0.4478102348116006\n",
            "Loss in iteration no. 71216 ==> 0.4478088652467479\n",
            "Loss in iteration no. 71217 ==> 0.4478074957034588\n",
            "Loss in iteration no. 71218 ==> 0.44780612618173243\n",
            "Loss in iteration no. 71219 ==> 0.44780475668156844\n",
            "Loss in iteration no. 71220 ==> 0.4478033872029666\n",
            "Loss in iteration no. 71221 ==> 0.4478020177459261\n",
            "Loss in iteration no. 71222 ==> 0.4478006483104466\n",
            "Loss in iteration no. 71223 ==> 0.44779927889652743\n",
            "Loss in iteration no. 71224 ==> 0.44779790950416837\n",
            "Loss in iteration no. 71225 ==> 0.447796540133369\n",
            "Loss in iteration no. 71226 ==> 0.44779517078412856\n",
            "Loss in iteration no. 71227 ==> 0.4477938014564467\n",
            "Loss in iteration no. 71228 ==> 0.447792432150323\n",
            "Loss in iteration no. 71229 ==> 0.4477910628657568\n",
            "Loss in iteration no. 71230 ==> 0.4477896936027478\n",
            "Loss in iteration no. 71231 ==> 0.4477883243612954\n",
            "Loss in iteration no. 71232 ==> 0.44778695514139927\n",
            "Loss in iteration no. 71233 ==> 0.4477855859430588\n",
            "Loss in iteration no. 71234 ==> 0.4477842167662735\n",
            "Loss in iteration no. 71235 ==> 0.447782847611043\n",
            "Loss in iteration no. 71236 ==> 0.44778147847736666\n",
            "Loss in iteration no. 71237 ==> 0.4477801093652441\n",
            "Loss in iteration no. 71238 ==> 0.4477787402746749\n",
            "Loss in iteration no. 71239 ==> 0.4477773712056584\n",
            "Loss in iteration no. 71240 ==> 0.4477760021581943\n",
            "Loss in iteration no. 71241 ==> 0.4477746331322821\n",
            "Loss in iteration no. 71242 ==> 0.4477732641279212\n",
            "Loss in iteration no. 71243 ==> 0.44777189514511123\n",
            "Loss in iteration no. 71244 ==> 0.4477705261838515\n",
            "Loss in iteration no. 71245 ==> 0.4477691572441419\n",
            "Loss in iteration no. 71246 ==> 0.4477677883259817\n",
            "Loss in iteration no. 71247 ==> 0.4477664194293704\n",
            "Loss in iteration no. 71248 ==> 0.44776505055430765\n",
            "Loss in iteration no. 71249 ==> 0.4477636817007929\n",
            "Loss in iteration no. 71250 ==> 0.4477623128688256\n",
            "Loss in iteration no. 71251 ==> 0.44776094405840544\n",
            "Loss in iteration no. 71252 ==> 0.4477595752695318\n",
            "Loss in iteration no. 71253 ==> 0.4477582065022042\n",
            "Loss in iteration no. 71254 ==> 0.4477568377564223\n",
            "Loss in iteration no. 71255 ==> 0.44775546903218544\n",
            "Loss in iteration no. 71256 ==> 0.44775410032949325\n",
            "Loss in iteration no. 71257 ==> 0.4477527316483452\n",
            "Loss in iteration no. 71258 ==> 0.44775136298874085\n",
            "Loss in iteration no. 71259 ==> 0.4477499943506798\n",
            "Loss in iteration no. 71260 ==> 0.44774862573416135\n",
            "Loss in iteration no. 71261 ==> 0.44774725713918523\n",
            "Loss in iteration no. 71262 ==> 0.44774588856575076\n",
            "Loss in iteration no. 71263 ==> 0.44774452001385767\n",
            "Loss in iteration no. 71264 ==> 0.44774315148350535\n",
            "Loss in iteration no. 71265 ==> 0.44774178297469336\n",
            "Loss in iteration no. 71266 ==> 0.44774041448742125\n",
            "Loss in iteration no. 71267 ==> 0.44773904602168835\n",
            "Loss in iteration no. 71268 ==> 0.4477376775774945\n",
            "Loss in iteration no. 71269 ==> 0.44773630915483903\n",
            "Loss in iteration no. 71270 ==> 0.4477349407537215\n",
            "Loss in iteration no. 71271 ==> 0.44773357237414124\n",
            "Loss in iteration no. 71272 ==> 0.44773220401609803\n",
            "Loss in iteration no. 71273 ==> 0.4477308356795913\n",
            "Loss in iteration no. 71274 ==> 0.4477294673646207\n",
            "Loss in iteration no. 71275 ==> 0.44772809907118544\n",
            "Loss in iteration no. 71276 ==> 0.4477267307992854\n",
            "Loss in iteration no. 71277 ==> 0.44772536254891976\n",
            "Loss in iteration no. 71278 ==> 0.4477239943200883\n",
            "Loss in iteration no. 71279 ==> 0.44772262611279035\n",
            "Loss in iteration no. 71280 ==> 0.4477212579270256\n",
            "Loss in iteration no. 71281 ==> 0.44771988976279353\n",
            "Loss in iteration no. 71282 ==> 0.4477185216200935\n",
            "Loss in iteration no. 71283 ==> 0.44771715349892527\n",
            "Loss in iteration no. 71284 ==> 0.44771578539928814\n",
            "Loss in iteration no. 71285 ==> 0.44771441732118183\n",
            "Loss in iteration no. 71286 ==> 0.44771304926460576\n",
            "Loss in iteration no. 71287 ==> 0.4477116812295594\n",
            "Loss in iteration no. 71288 ==> 0.4477103132160423\n",
            "Loss in iteration no. 71289 ==> 0.447708945224054\n",
            "Loss in iteration no. 71290 ==> 0.44770757725359417\n",
            "Loss in iteration no. 71291 ==> 0.44770620930466204\n",
            "Loss in iteration no. 71292 ==> 0.44770484137725736\n",
            "Loss in iteration no. 71293 ==> 0.44770347347137956\n",
            "Loss in iteration no. 71294 ==> 0.4477021055870281\n",
            "Loss in iteration no. 71295 ==> 0.44770073772420266\n",
            "Loss in iteration no. 71296 ==> 0.4476993698829026\n",
            "Loss in iteration no. 71297 ==> 0.44769800206312743\n",
            "Loss in iteration no. 71298 ==> 0.4476966342648769\n",
            "Loss in iteration no. 71299 ==> 0.4476952664881503\n",
            "Loss in iteration no. 71300 ==> 0.4476938987329472\n",
            "Loss in iteration no. 71301 ==> 0.44769253099926726\n",
            "Loss in iteration no. 71302 ==> 0.4476911632871098\n",
            "Loss in iteration no. 71303 ==> 0.44768979559647454\n",
            "Loss in iteration no. 71304 ==> 0.4476884279273607\n",
            "Loss in iteration no. 71305 ==> 0.44768706027976807\n",
            "Loss in iteration no. 71306 ==> 0.4476856926536961\n",
            "Loss in iteration no. 71307 ==> 0.4476843250491443\n",
            "Loss in iteration no. 71308 ==> 0.4476829574661122\n",
            "Loss in iteration no. 71309 ==> 0.4476815899045994\n",
            "Loss in iteration no. 71310 ==> 0.4476802223646052\n",
            "Loss in iteration no. 71311 ==> 0.44767885484612935\n",
            "Loss in iteration no. 71312 ==> 0.44767748734917123\n",
            "Loss in iteration no. 71313 ==> 0.4476761198737304\n",
            "Loss in iteration no. 71314 ==> 0.4476747524198064\n",
            "Loss in iteration no. 71315 ==> 0.4476733849873987\n",
            "Loss in iteration no. 71316 ==> 0.4476720175765069\n",
            "Loss in iteration no. 71317 ==> 0.4476706501871305\n",
            "Loss in iteration no. 71318 ==> 0.4476692828192689\n",
            "Loss in iteration no. 71319 ==> 0.4476679154729218\n",
            "Loss in iteration no. 71320 ==> 0.44766654814808865\n",
            "Loss in iteration no. 71321 ==> 0.447665180844769\n",
            "Loss in iteration no. 71322 ==> 0.44766381356296225\n",
            "Loss in iteration no. 71323 ==> 0.44766244630266805\n",
            "Loss in iteration no. 71324 ==> 0.44766107906388575\n",
            "Loss in iteration no. 71325 ==> 0.44765971184661507\n",
            "Loss in iteration no. 71326 ==> 0.4476583446508555\n",
            "Loss in iteration no. 71327 ==> 0.44765697747660654\n",
            "Loss in iteration no. 71328 ==> 0.44765561032386764\n",
            "Loss in iteration no. 71329 ==> 0.4476542431926383\n",
            "Loss in iteration no. 71330 ==> 0.4476528760829182\n",
            "Loss in iteration no. 71331 ==> 0.44765150899470674\n",
            "Loss in iteration no. 71332 ==> 0.44765014192800345\n",
            "Loss in iteration no. 71333 ==> 0.4476487748828079\n",
            "Loss in iteration no. 71334 ==> 0.44764740785911955\n",
            "Loss in iteration no. 71335 ==> 0.44764604085693793\n",
            "Loss in iteration no. 71336 ==> 0.44764467387626267\n",
            "Loss in iteration no. 71337 ==> 0.44764330691709314\n",
            "Loss in iteration no. 71338 ==> 0.4476419399794289\n",
            "Loss in iteration no. 71339 ==> 0.44764057306326965\n",
            "Loss in iteration no. 71340 ==> 0.4476392061686146\n",
            "Loss in iteration no. 71341 ==> 0.4476378392954635\n",
            "Loss in iteration no. 71342 ==> 0.4476364724438158\n",
            "Loss in iteration no. 71343 ==> 0.447635105613671\n",
            "Loss in iteration no. 71344 ==> 0.44763373880502866\n",
            "Loss in iteration no. 71345 ==> 0.4476323720178882\n",
            "Loss in iteration no. 71346 ==> 0.44763100525224936\n",
            "Loss in iteration no. 71347 ==> 0.4476296385081114\n",
            "Loss in iteration no. 71348 ==> 0.44762827178547393\n",
            "Loss in iteration no. 71349 ==> 0.4476269050843368\n",
            "Loss in iteration no. 71350 ==> 0.44762553840469893\n",
            "Loss in iteration no. 71351 ==> 0.4476241717465602\n",
            "Loss in iteration no. 71352 ==> 0.44762280510992014\n",
            "Loss in iteration no. 71353 ==> 0.44762143849477826\n",
            "Loss in iteration no. 71354 ==> 0.4476200719011339\n",
            "Loss in iteration no. 71355 ==> 0.44761870532898684\n",
            "Loss in iteration no. 71356 ==> 0.44761733877833637\n",
            "Loss in iteration no. 71357 ==> 0.44761597224918215\n",
            "Loss in iteration no. 71358 ==> 0.4476146057415238\n",
            "Loss in iteration no. 71359 ==> 0.44761323925536056\n",
            "Loss in iteration no. 71360 ==> 0.44761187279069214\n",
            "Loss in iteration no. 71361 ==> 0.447610506347518\n",
            "Loss in iteration no. 71362 ==> 0.44760913992583773\n",
            "Loss in iteration no. 71363 ==> 0.4476077735256508\n",
            "Loss in iteration no. 71364 ==> 0.4476064071469567\n",
            "Loss in iteration no. 71365 ==> 0.447605040789755\n",
            "Loss in iteration no. 71366 ==> 0.4476036744540452\n",
            "Loss in iteration no. 71367 ==> 0.4476023081398268\n",
            "Loss in iteration no. 71368 ==> 0.4476009418470994\n",
            "Loss in iteration no. 71369 ==> 0.4475995755758625\n",
            "Loss in iteration no. 71370 ==> 0.44759820932611555\n",
            "Loss in iteration no. 71371 ==> 0.4475968430978581\n",
            "Loss in iteration no. 71372 ==> 0.4475954768910897\n",
            "Loss in iteration no. 71373 ==> 0.44759411070580984\n",
            "Loss in iteration no. 71374 ==> 0.4475927445420181\n",
            "Loss in iteration no. 71375 ==> 0.44759137839971397\n",
            "Loss in iteration no. 71376 ==> 0.4475900122788969\n",
            "Loss in iteration no. 71377 ==> 0.44758864617956656\n",
            "Loss in iteration no. 71378 ==> 0.44758728010172233\n",
            "Loss in iteration no. 71379 ==> 0.4475859140453638\n",
            "Loss in iteration no. 71380 ==> 0.4475845480104904\n",
            "Loss in iteration no. 71381 ==> 0.44758318199710184\n",
            "Loss in iteration no. 71382 ==> 0.4475818160051975\n",
            "Loss in iteration no. 71383 ==> 0.447580450034777\n",
            "Loss in iteration no. 71384 ==> 0.44757908408583963\n",
            "Loss in iteration no. 71385 ==> 0.4475777181583852\n",
            "Loss in iteration no. 71386 ==> 0.44757635225241305\n",
            "Loss in iteration no. 71387 ==> 0.4475749863679228\n",
            "Loss in iteration no. 71388 ==> 0.4475736205049139\n",
            "Loss in iteration no. 71389 ==> 0.447572254663386\n",
            "Loss in iteration no. 71390 ==> 0.4475708888433384\n",
            "Loss in iteration no. 71391 ==> 0.44756952304477077\n",
            "Loss in iteration no. 71392 ==> 0.4475681572676827\n",
            "Loss in iteration no. 71393 ==> 0.4475667915120735\n",
            "Loss in iteration no. 71394 ==> 0.44756542577794284\n",
            "Loss in iteration no. 71395 ==> 0.44756406006529026\n",
            "Loss in iteration no. 71396 ==> 0.4475626943741153\n",
            "Loss in iteration no. 71397 ==> 0.44756132870441734\n",
            "Loss in iteration no. 71398 ==> 0.44755996305619594\n",
            "Loss in iteration no. 71399 ==> 0.44755859742945076\n",
            "Loss in iteration no. 71400 ==> 0.4475572318241811\n",
            "Loss in iteration no. 71401 ==> 0.4475558662403867\n",
            "Loss in iteration no. 71402 ==> 0.4475545006780669\n",
            "Loss in iteration no. 71403 ==> 0.4475531351372214\n",
            "Loss in iteration no. 71404 ==> 0.44755176961784965\n",
            "Loss in iteration no. 71405 ==> 0.447550404119951\n",
            "Loss in iteration no. 71406 ==> 0.44754903864352524\n",
            "Loss in iteration no. 71407 ==> 0.4475476731885717\n",
            "Loss in iteration no. 71408 ==> 0.44754630775509013\n",
            "Loss in iteration no. 71409 ==> 0.44754494234307973\n",
            "Loss in iteration no. 71410 ==> 0.4475435769525403\n",
            "Loss in iteration no. 71411 ==> 0.4475422115834712\n",
            "Loss in iteration no. 71412 ==> 0.44754084623587204\n",
            "Loss in iteration no. 71413 ==> 0.4475394809097424\n",
            "Loss in iteration no. 71414 ==> 0.4475381156050815\n",
            "Loss in iteration no. 71415 ==> 0.44753675032188917\n",
            "Loss in iteration no. 71416 ==> 0.4475353850601648\n",
            "Loss in iteration no. 71417 ==> 0.44753401981990804\n",
            "Loss in iteration no. 71418 ==> 0.44753265460111824\n",
            "Loss in iteration no. 71419 ==> 0.44753128940379505\n",
            "Loss in iteration no. 71420 ==> 0.44752992422793797\n",
            "Loss in iteration no. 71421 ==> 0.44752855907354644\n",
            "Loss in iteration no. 71422 ==> 0.44752719394061996\n",
            "Loss in iteration no. 71423 ==> 0.44752582882915826\n",
            "Loss in iteration no. 71424 ==> 0.44752446373916066\n",
            "Loss in iteration no. 71425 ==> 0.44752309867062673\n",
            "Loss in iteration no. 71426 ==> 0.4475217336235561\n",
            "Loss in iteration no. 71427 ==> 0.44752036859794825\n",
            "Loss in iteration no. 71428 ==> 0.4475190035938025\n",
            "Loss in iteration no. 71429 ==> 0.4475176386111186\n",
            "Loss in iteration no. 71430 ==> 0.44751627364989605\n",
            "Loss in iteration no. 71431 ==> 0.44751490871013433\n",
            "Loss in iteration no. 71432 ==> 0.4475135437918329\n",
            "Loss in iteration no. 71433 ==> 0.4475121788949914\n",
            "Loss in iteration no. 71434 ==> 0.44751081401960924\n",
            "Loss in iteration no. 71435 ==> 0.447509449165686\n",
            "Loss in iteration no. 71436 ==> 0.44750808433322126\n",
            "Loss in iteration no. 71437 ==> 0.4475067195222144\n",
            "Loss in iteration no. 71438 ==> 0.4475053547326651\n",
            "Loss in iteration no. 71439 ==> 0.44750398996457275\n",
            "Loss in iteration no. 71440 ==> 0.4475026252179369\n",
            "Loss in iteration no. 71441 ==> 0.4475012604927572\n",
            "Loss in iteration no. 71442 ==> 0.447499895789033\n",
            "Loss in iteration no. 71443 ==> 0.44749853110676396\n",
            "Loss in iteration no. 71444 ==> 0.4474971664459495\n",
            "Loss in iteration no. 71445 ==> 0.4474958018065891\n",
            "Loss in iteration no. 71446 ==> 0.44749443718868254\n",
            "Loss in iteration no. 71447 ==> 0.44749307259222904\n",
            "Loss in iteration no. 71448 ==> 0.4474917080172282\n",
            "Loss in iteration no. 71449 ==> 0.4474903434636797\n",
            "Loss in iteration no. 71450 ==> 0.447488978931583\n",
            "Loss in iteration no. 71451 ==> 0.44748761442093743\n",
            "Loss in iteration no. 71452 ==> 0.4474862499317428\n",
            "Loss in iteration no. 71453 ==> 0.44748488546399845\n",
            "Loss in iteration no. 71454 ==> 0.44748352101770383\n",
            "Loss in iteration no. 71455 ==> 0.44748215659285867\n",
            "Loss in iteration no. 71456 ==> 0.44748079218946235\n",
            "Loss in iteration no. 71457 ==> 0.4474794278075145\n",
            "Loss in iteration no. 71458 ==> 0.4474780634470146\n",
            "Loss in iteration no. 71459 ==> 0.44747669910796206\n",
            "Loss in iteration no. 71460 ==> 0.44747533479035656\n",
            "Loss in iteration no. 71461 ==> 0.4474739704941976\n",
            "Loss in iteration no. 71462 ==> 0.4474726062194846\n",
            "Loss in iteration no. 71463 ==> 0.44747124196621724\n",
            "Loss in iteration no. 71464 ==> 0.44746987773439484\n",
            "Loss in iteration no. 71465 ==> 0.44746851352401706\n",
            "Loss in iteration no. 71466 ==> 0.4474671493350834\n",
            "Loss in iteration no. 71467 ==> 0.44746578516759344\n",
            "Loss in iteration no. 71468 ==> 0.4474644210215466\n",
            "Loss in iteration no. 71469 ==> 0.4474630568969424\n",
            "Loss in iteration no. 71470 ==> 0.44746169279378045\n",
            "Loss in iteration no. 71471 ==> 0.4474603287120602\n",
            "Loss in iteration no. 71472 ==> 0.44745896465178125\n",
            "Loss in iteration no. 71473 ==> 0.44745760061294304\n",
            "Loss in iteration no. 71474 ==> 0.4474562365955452\n",
            "Loss in iteration no. 71475 ==> 0.447454872599587\n",
            "Loss in iteration no. 71476 ==> 0.44745350862506833\n",
            "Loss in iteration no. 71477 ==> 0.4474521446719884\n",
            "Loss in iteration no. 71478 ==> 0.44745078074034694\n",
            "Loss in iteration no. 71479 ==> 0.44744941683014344\n",
            "Loss in iteration no. 71480 ==> 0.4474480529413773\n",
            "Loss in iteration no. 71481 ==> 0.44744668907404817\n",
            "Loss in iteration no. 71482 ==> 0.44744532522815544\n",
            "Loss in iteration no. 71483 ==> 0.4474439614036988\n",
            "Loss in iteration no. 71484 ==> 0.44744259760067767\n",
            "Loss in iteration no. 71485 ==> 0.44744123381909157\n",
            "Loss in iteration no. 71486 ==> 0.44743987005894004\n",
            "Loss in iteration no. 71487 ==> 0.4474385063202226\n",
            "Loss in iteration no. 71488 ==> 0.4474371426029389\n",
            "Loss in iteration no. 71489 ==> 0.4474357789070881\n",
            "Loss in iteration no. 71490 ==> 0.4474344152326702\n",
            "Loss in iteration no. 71491 ==> 0.4474330515796843\n",
            "Loss in iteration no. 71492 ==> 0.44743168794813026\n",
            "Loss in iteration no. 71493 ==> 0.44743032433800745\n",
            "Loss in iteration no. 71494 ==> 0.4474289607493155\n",
            "Loss in iteration no. 71495 ==> 0.4474275971820536\n",
            "Loss in iteration no. 71496 ==> 0.44742623363622147\n",
            "Loss in iteration no. 71497 ==> 0.4474248701118189\n",
            "Loss in iteration no. 71498 ==> 0.4474235066088451\n",
            "Loss in iteration no. 71499 ==> 0.4474221431272997\n",
            "Loss in iteration no. 71500 ==> 0.44742077966718213\n",
            "Loss in iteration no. 71501 ==> 0.447419416228492\n",
            "Loss in iteration no. 71502 ==> 0.4474180528112288\n",
            "Loss in iteration no. 71503 ==> 0.44741668941539214\n",
            "Loss in iteration no. 71504 ==> 0.4474153260409814\n",
            "Loss in iteration no. 71505 ==> 0.44741396268799616\n",
            "Loss in iteration no. 71506 ==> 0.44741259935643607\n",
            "Loss in iteration no. 71507 ==> 0.44741123604630045\n",
            "Loss in iteration no. 71508 ==> 0.4474098727575889\n",
            "Loss in iteration no. 71509 ==> 0.447408509490301\n",
            "Loss in iteration no. 71510 ==> 0.4474071462444363\n",
            "Loss in iteration no. 71511 ==> 0.4474057830199942\n",
            "Loss in iteration no. 71512 ==> 0.4474044198169742\n",
            "Loss in iteration no. 71513 ==> 0.44740305663537594\n",
            "Loss in iteration no. 71514 ==> 0.447401693475199\n",
            "Loss in iteration no. 71515 ==> 0.4474003303364427\n",
            "Loss in iteration no. 71516 ==> 0.4473989672191067\n",
            "Loss in iteration no. 71517 ==> 0.4473976041231906\n",
            "Loss in iteration no. 71518 ==> 0.4473962410486937\n",
            "Loss in iteration no. 71519 ==> 0.44739487799561567\n",
            "Loss in iteration no. 71520 ==> 0.4473935149639561\n",
            "Loss in iteration no. 71521 ==> 0.4473921519537143\n",
            "Loss in iteration no. 71522 ==> 0.44739078896488993\n",
            "Loss in iteration no. 71523 ==> 0.44738942599748255\n",
            "Loss in iteration no. 71524 ==> 0.44738806305149154\n",
            "Loss in iteration no. 71525 ==> 0.44738670012691656\n",
            "Loss in iteration no. 71526 ==> 0.44738533722375706\n",
            "Loss in iteration no. 71527 ==> 0.4473839743420127\n",
            "Loss in iteration no. 71528 ==> 0.4473826114816828\n",
            "Loss in iteration no. 71529 ==> 0.447381248642767\n",
            "Loss in iteration no. 71530 ==> 0.44737988582526483\n",
            "Loss in iteration no. 71531 ==> 0.44737852302917586\n",
            "Loss in iteration no. 71532 ==> 0.44737716025449936\n",
            "Loss in iteration no. 71533 ==> 0.44737579750123513\n",
            "Loss in iteration no. 71534 ==> 0.44737443476938266\n",
            "Loss in iteration no. 71535 ==> 0.4473730720589413\n",
            "Loss in iteration no. 71536 ==> 0.4473717093699108\n",
            "Loss in iteration no. 71537 ==> 0.4473703467022905\n",
            "Loss in iteration no. 71538 ==> 0.4473689840560799\n",
            "Loss in iteration no. 71539 ==> 0.4473676214312788\n",
            "Loss in iteration no. 71540 ==> 0.44736625882788633\n",
            "Loss in iteration no. 71541 ==> 0.4473648962459024\n",
            "Loss in iteration no. 71542 ==> 0.4473635336853263\n",
            "Loss in iteration no. 71543 ==> 0.4473621711461576\n",
            "Loss in iteration no. 71544 ==> 0.44736080862839595\n",
            "Loss in iteration no. 71545 ==> 0.44735944613204065\n",
            "Loss in iteration no. 71546 ==> 0.4473580836570913\n",
            "Loss in iteration no. 71547 ==> 0.4473567212035476\n",
            "Loss in iteration no. 71548 ==> 0.44735535877140886\n",
            "Loss in iteration no. 71549 ==> 0.4473539963606746\n",
            "Loss in iteration no. 71550 ==> 0.44735263397134445\n",
            "Loss in iteration no. 71551 ==> 0.4473512716034179\n",
            "Loss in iteration no. 71552 ==> 0.4473499092568945\n",
            "Loss in iteration no. 71553 ==> 0.44734854693177384\n",
            "Loss in iteration no. 71554 ==> 0.44734718462805523\n",
            "Loss in iteration no. 71555 ==> 0.4473458223457384\n",
            "Loss in iteration no. 71556 ==> 0.44734446008482276\n",
            "Loss in iteration no. 71557 ==> 0.44734309784530785\n",
            "Loss in iteration no. 71558 ==> 0.44734173562719326\n",
            "Loss in iteration no. 71559 ==> 0.4473403734304785\n",
            "Loss in iteration no. 71560 ==> 0.44733901125516284\n",
            "Loss in iteration no. 71561 ==> 0.44733764910124624\n",
            "Loss in iteration no. 71562 ==> 0.44733628696872796\n",
            "Loss in iteration no. 71563 ==> 0.44733492485760756\n",
            "Loss in iteration no. 71564 ==> 0.44733356276788466\n",
            "Loss in iteration no. 71565 ==> 0.44733220069955854\n",
            "Loss in iteration no. 71566 ==> 0.447330838652629\n",
            "Loss in iteration no. 71567 ==> 0.44732947662709543\n",
            "Loss in iteration no. 71568 ==> 0.4473281146229574\n",
            "Loss in iteration no. 71569 ==> 0.4473267526402143\n",
            "Loss in iteration no. 71570 ==> 0.4473253906788658\n",
            "Loss in iteration no. 71571 ==> 0.44732402873891147\n",
            "Loss in iteration no. 71572 ==> 0.4473226668203507\n",
            "Loss in iteration no. 71573 ==> 0.44732130492318306\n",
            "Loss in iteration no. 71574 ==> 0.4473199430474081\n",
            "Loss in iteration no. 71575 ==> 0.44731858119302526\n",
            "Loss in iteration no. 71576 ==> 0.44731721936003416\n",
            "Loss in iteration no. 71577 ==> 0.44731585754843434\n",
            "Loss in iteration no. 71578 ==> 0.4473144957582253\n",
            "Loss in iteration no. 71579 ==> 0.4473131339894064\n",
            "Loss in iteration no. 71580 ==> 0.4473117722419774\n",
            "Loss in iteration no. 71581 ==> 0.4473104105159377\n",
            "Loss in iteration no. 71582 ==> 0.44730904881128686\n",
            "Loss in iteration no. 71583 ==> 0.44730768712802443\n",
            "Loss in iteration no. 71584 ==> 0.44730632546614996\n",
            "Loss in iteration no. 71585 ==> 0.4473049638256628\n",
            "Loss in iteration no. 71586 ==> 0.4473036022065626\n",
            "Loss in iteration no. 71587 ==> 0.44730224060884904\n",
            "Loss in iteration no. 71588 ==> 0.4473008790325213\n",
            "Loss in iteration no. 71589 ==> 0.4472995174775791\n",
            "Loss in iteration no. 71590 ==> 0.447298155944022\n",
            "Loss in iteration no. 71591 ==> 0.4472967944318494\n",
            "Loss in iteration no. 71592 ==> 0.447295432941061\n",
            "Loss in iteration no. 71593 ==> 0.44729407147165623\n",
            "Loss in iteration no. 71594 ==> 0.4472927100236345\n",
            "Loss in iteration no. 71595 ==> 0.4472913485969956\n",
            "Loss in iteration no. 71596 ==> 0.44728998719173874\n",
            "Loss in iteration no. 71597 ==> 0.44728862580786366\n",
            "Loss in iteration no. 71598 ==> 0.44728726444536987\n",
            "Loss in iteration no. 71599 ==> 0.44728590310425675\n",
            "Loss in iteration no. 71600 ==> 0.447284541784524\n",
            "Loss in iteration no. 71601 ==> 0.4472831804861711\n",
            "Loss in iteration no. 71602 ==> 0.4472818192091975\n",
            "Loss in iteration no. 71603 ==> 0.44728045795360283\n",
            "Loss in iteration no. 71604 ==> 0.4472790967193864\n",
            "Loss in iteration no. 71605 ==> 0.44727773550654815\n",
            "Loss in iteration no. 71606 ==> 0.44727637431508704\n",
            "Loss in iteration no. 71607 ==> 0.44727501314500306\n",
            "Loss in iteration no. 71608 ==> 0.44727365199629554\n",
            "Loss in iteration no. 71609 ==> 0.44727229086896414\n",
            "Loss in iteration no. 71610 ==> 0.4472709297630082\n",
            "Loss in iteration no. 71611 ==> 0.44726956867842727\n",
            "Loss in iteration no. 71612 ==> 0.447268207615221\n",
            "Loss in iteration no. 71613 ==> 0.44726684657338883\n",
            "Loss in iteration no. 71614 ==> 0.44726548555293033\n",
            "Loss in iteration no. 71615 ==> 0.447264124553845\n",
            "Loss in iteration no. 71616 ==> 0.44726276357613237\n",
            "Loss in iteration no. 71617 ==> 0.4472614026197919\n",
            "Loss in iteration no. 71618 ==> 0.44726004168482314\n",
            "Loss in iteration no. 71619 ==> 0.44725868077122577\n",
            "Loss in iteration no. 71620 ==> 0.44725731987899914\n",
            "Loss in iteration no. 71621 ==> 0.4472559590081428\n",
            "Loss in iteration no. 71622 ==> 0.4472545981586563\n",
            "Loss in iteration no. 71623 ==> 0.4472532373305393\n",
            "Loss in iteration no. 71624 ==> 0.447251876523791\n",
            "Loss in iteration no. 71625 ==> 0.4472505157384113\n",
            "Loss in iteration no. 71626 ==> 0.44724915497439943\n",
            "Loss in iteration no. 71627 ==> 0.4472477942317549\n",
            "Loss in iteration no. 71628 ==> 0.4472464335104776\n",
            "Loss in iteration no. 71629 ==> 0.4472450728105667\n",
            "Loss in iteration no. 71630 ==> 0.44724371213202185\n",
            "Loss in iteration no. 71631 ==> 0.4472423514748426\n",
            "Loss in iteration no. 71632 ==> 0.44724099083902835\n",
            "Loss in iteration no. 71633 ==> 0.4472396302245789\n",
            "Loss in iteration no. 71634 ==> 0.4472382696314935\n",
            "Loss in iteration no. 71635 ==> 0.4472369090597717\n",
            "Loss in iteration no. 71636 ==> 0.4472355485094132\n",
            "Loss in iteration no. 71637 ==> 0.44723418798041736\n",
            "Loss in iteration no. 71638 ==> 0.4472328274727837\n",
            "Loss in iteration no. 71639 ==> 0.44723146698651195\n",
            "Loss in iteration no. 71640 ==> 0.44723010652160144\n",
            "Loss in iteration no. 71641 ==> 0.4472287460780517\n",
            "Loss in iteration no. 71642 ==> 0.4472273856558623\n",
            "Loss in iteration no. 71643 ==> 0.4472260252550328\n",
            "Loss in iteration no. 71644 ==> 0.4472246648755628\n",
            "Loss in iteration no. 71645 ==> 0.44722330451745157\n",
            "Loss in iteration no. 71646 ==> 0.4472219441806989\n",
            "Loss in iteration no. 71647 ==> 0.4472205838653041\n",
            "Loss in iteration no. 71648 ==> 0.44721922357126687\n",
            "Loss in iteration no. 71649 ==> 0.4472178632985866\n",
            "Loss in iteration no. 71650 ==> 0.4472165030472629\n",
            "Loss in iteration no. 71651 ==> 0.4472151428172953\n",
            "Loss in iteration no. 71652 ==> 0.4472137826086833\n",
            "Loss in iteration no. 71653 ==> 0.44721242242142634\n",
            "Loss in iteration no. 71654 ==> 0.44721106225552415\n",
            "Loss in iteration no. 71655 ==> 0.44720970211097605\n",
            "Loss in iteration no. 71656 ==> 0.4472083419877817\n",
            "Loss in iteration no. 71657 ==> 0.44720698188594055\n",
            "Loss in iteration no. 71658 ==> 0.4472056218054522\n",
            "Loss in iteration no. 71659 ==> 0.447204261746316\n",
            "Loss in iteration no. 71660 ==> 0.44720290170853166\n",
            "Loss in iteration no. 71661 ==> 0.4472015416920987\n",
            "Loss in iteration no. 71662 ==> 0.4472001816970166\n",
            "Loss in iteration no. 71663 ==> 0.4471988217232848\n",
            "Loss in iteration no. 71664 ==> 0.4471974617709029\n",
            "Loss in iteration no. 71665 ==> 0.44719610183987046\n",
            "Loss in iteration no. 71666 ==> 0.44719474193018705\n",
            "Loss in iteration no. 71667 ==> 0.447193382041852\n",
            "Loss in iteration no. 71668 ==> 0.44719202217486503\n",
            "Loss in iteration no. 71669 ==> 0.4471906623292255\n",
            "Loss in iteration no. 71670 ==> 0.4471893025049332\n",
            "Loss in iteration no. 71671 ==> 0.44718794270198736\n",
            "Loss in iteration no. 71672 ==> 0.4471865829203877\n",
            "Loss in iteration no. 71673 ==> 0.4471852231601336\n",
            "Loss in iteration no. 71674 ==> 0.4471838634212246\n",
            "Loss in iteration no. 71675 ==> 0.44718250370366047\n",
            "Loss in iteration no. 71676 ==> 0.4471811440074404\n",
            "Loss in iteration no. 71677 ==> 0.4471797843325642\n",
            "Loss in iteration no. 71678 ==> 0.44717842467903113\n",
            "Loss in iteration no. 71679 ==> 0.4471770650468409\n",
            "Loss in iteration no. 71680 ==> 0.447175705435993\n",
            "Loss in iteration no. 71681 ==> 0.44717434584648696\n",
            "Loss in iteration no. 71682 ==> 0.4471729862783222\n",
            "Loss in iteration no. 71683 ==> 0.4471716267314984\n",
            "Loss in iteration no. 71684 ==> 0.447170267206015\n",
            "Loss in iteration no. 71685 ==> 0.44716890770187157\n",
            "Loss in iteration no. 71686 ==> 0.4471675482190676\n",
            "Loss in iteration no. 71687 ==> 0.44716618875760267\n",
            "Loss in iteration no. 71688 ==> 0.4471648293174762\n",
            "Loss in iteration no. 71689 ==> 0.44716346989868777\n",
            "Loss in iteration no. 71690 ==> 0.447162110501237\n",
            "Loss in iteration no. 71691 ==> 0.4471607511251231\n",
            "Loss in iteration no. 71692 ==> 0.447159391770346\n",
            "Loss in iteration no. 71693 ==> 0.44715803243690516\n",
            "Loss in iteration no. 71694 ==> 0.44715667312479984\n",
            "Loss in iteration no. 71695 ==> 0.44715531383402973\n",
            "Loss in iteration no. 71696 ==> 0.4471539545645944\n",
            "Loss in iteration no. 71697 ==> 0.44715259531649326\n",
            "Loss in iteration no. 71698 ==> 0.4471512360897259\n",
            "Loss in iteration no. 71699 ==> 0.447149876884292\n",
            "Loss in iteration no. 71700 ==> 0.4471485177001908\n",
            "Loss in iteration no. 71701 ==> 0.44714715853742204\n",
            "Loss in iteration no. 71702 ==> 0.44714579939598503\n",
            "Loss in iteration no. 71703 ==> 0.44714444027587963\n",
            "Loss in iteration no. 71704 ==> 0.44714308117710505\n",
            "Loss in iteration no. 71705 ==> 0.44714172209966085\n",
            "Loss in iteration no. 71706 ==> 0.44714036304354676\n",
            "Loss in iteration no. 71707 ==> 0.4471390040087621\n",
            "Loss in iteration no. 71708 ==> 0.4471376449953065\n",
            "Loss in iteration no. 71709 ==> 0.44713628600317956\n",
            "Loss in iteration no. 71710 ==> 0.44713492703238056\n",
            "Loss in iteration no. 71711 ==> 0.4471335680829093\n",
            "Loss in iteration no. 71712 ==> 0.4471322091547652\n",
            "Loss in iteration no. 71713 ==> 0.4471308502479478\n",
            "Loss in iteration no. 71714 ==> 0.44712949136245644\n",
            "Loss in iteration no. 71715 ==> 0.447128132498291\n",
            "Loss in iteration no. 71716 ==> 0.44712677365545056\n",
            "Loss in iteration no. 71717 ==> 0.4471254148339352\n",
            "Loss in iteration no. 71718 ==> 0.4471240560337439\n",
            "Loss in iteration no. 71719 ==> 0.4471226972548766\n",
            "Loss in iteration no. 71720 ==> 0.44712133849733254\n",
            "Loss in iteration no. 71721 ==> 0.44711997976111145\n",
            "Loss in iteration no. 71722 ==> 0.44711862104621275\n",
            "Loss in iteration no. 71723 ==> 0.44711726235263594\n",
            "Loss in iteration no. 71724 ==> 0.4471159036803807\n",
            "Loss in iteration no. 71725 ==> 0.4471145450294463\n",
            "Loss in iteration no. 71726 ==> 0.44711318639983255\n",
            "Loss in iteration no. 71727 ==> 0.44711182779153874\n",
            "Loss in iteration no. 71728 ==> 0.4471104692045646\n",
            "Loss in iteration no. 71729 ==> 0.44710911063890946\n",
            "Loss in iteration no. 71730 ==> 0.44710775209457293\n",
            "Loss in iteration no. 71731 ==> 0.4471063935715547\n",
            "Loss in iteration no. 71732 ==> 0.447105035069854\n",
            "Loss in iteration no. 71733 ==> 0.44710367658947064\n",
            "Loss in iteration no. 71734 ==> 0.44710231813040385\n",
            "Loss in iteration no. 71735 ==> 0.44710095969265345\n",
            "Loss in iteration no. 71736 ==> 0.44709960127621867\n",
            "Loss in iteration no. 71737 ==> 0.44709824288109934\n",
            "Loss in iteration no. 71738 ==> 0.44709688450729473\n",
            "Loss in iteration no. 71739 ==> 0.4470955261548046\n",
            "Loss in iteration no. 71740 ==> 0.4470941678236284\n",
            "Loss in iteration no. 71741 ==> 0.44709280951376545\n",
            "Loss in iteration no. 71742 ==> 0.4470914512252155\n",
            "Loss in iteration no. 71743 ==> 0.447090092957978\n",
            "Loss in iteration no. 71744 ==> 0.44708873471205257\n",
            "Loss in iteration no. 71745 ==> 0.4470873764874386\n",
            "Loss in iteration no. 71746 ==> 0.44708601828413574\n",
            "Loss in iteration no. 71747 ==> 0.44708466010214337\n",
            "Loss in iteration no. 71748 ==> 0.44708330194146106\n",
            "Loss in iteration no. 71749 ==> 0.44708194380208854\n",
            "Loss in iteration no. 71750 ==> 0.447080585684025\n",
            "Loss in iteration no. 71751 ==> 0.4470792275872703\n",
            "Loss in iteration no. 71752 ==> 0.4470778695118237\n",
            "Loss in iteration no. 71753 ==> 0.44707651145768484\n",
            "Loss in iteration no. 71754 ==> 0.4470751534248534\n",
            "Loss in iteration no. 71755 ==> 0.4470737954133286\n",
            "Loss in iteration no. 71756 ==> 0.4470724374231102\n",
            "Loss in iteration no. 71757 ==> 0.44707107945419744\n",
            "Loss in iteration no. 71758 ==> 0.4470697215065903\n",
            "Loss in iteration no. 71759 ==> 0.44706836358028784\n",
            "Loss in iteration no. 71760 ==> 0.44706700567528995\n",
            "Loss in iteration no. 71761 ==> 0.44706564779159597\n",
            "Loss in iteration no. 71762 ==> 0.4470642899292055\n",
            "Loss in iteration no. 71763 ==> 0.447062932088118\n",
            "Loss in iteration no. 71764 ==> 0.447061574268333\n",
            "Loss in iteration no. 71765 ==> 0.4470602164698501\n",
            "Loss in iteration no. 71766 ==> 0.4470588586926688\n",
            "Loss in iteration no. 71767 ==> 0.44705750093678853\n",
            "Loss in iteration no. 71768 ==> 0.4470561432022091\n",
            "Loss in iteration no. 71769 ==> 0.44705478548892963\n",
            "Loss in iteration no. 71770 ==> 0.4470534277969499\n",
            "Loss in iteration no. 71771 ==> 0.4470520701262694\n",
            "Loss in iteration no. 71772 ==> 0.44705071247688766\n",
            "Loss in iteration no. 71773 ==> 0.4470493548488042\n",
            "Loss in iteration no. 71774 ==> 0.4470479972420186\n",
            "Loss in iteration no. 71775 ==> 0.44704663965653013\n",
            "Loss in iteration no. 71776 ==> 0.4470452820923387\n",
            "Loss in iteration no. 71777 ==> 0.44704392454944364\n",
            "Loss in iteration no. 71778 ==> 0.44704256702784445\n",
            "Loss in iteration no. 71779 ==> 0.4470412095275407\n",
            "Loss in iteration no. 71780 ==> 0.4470398520485319\n",
            "Loss in iteration no. 71781 ==> 0.4470384945908176\n",
            "Loss in iteration no. 71782 ==> 0.4470371371543973\n",
            "Loss in iteration no. 71783 ==> 0.44703577973927056\n",
            "Loss in iteration no. 71784 ==> 0.44703442234543683\n",
            "Loss in iteration no. 71785 ==> 0.44703306497289585\n",
            "Loss in iteration no. 71786 ==> 0.44703170762164685\n",
            "Loss in iteration no. 71787 ==> 0.44703035029168964\n",
            "Loss in iteration no. 71788 ==> 0.44702899298302345\n",
            "Loss in iteration no. 71789 ==> 0.44702763569564813\n",
            "Loss in iteration no. 71790 ==> 0.447026278429563\n",
            "Loss in iteration no. 71791 ==> 0.4470249211847676\n",
            "Loss in iteration no. 71792 ==> 0.4470235639612615\n",
            "Loss in iteration no. 71793 ==> 0.44702220675904425\n",
            "Loss in iteration no. 71794 ==> 0.4470208495781153\n",
            "Loss in iteration no. 71795 ==> 0.4470194924184743\n",
            "Loss in iteration no. 71796 ==> 0.4470181352801206\n",
            "Loss in iteration no. 71797 ==> 0.4470167781630539\n",
            "Loss in iteration no. 71798 ==> 0.4470154210672736\n",
            "Loss in iteration no. 71799 ==> 0.4470140639927794\n",
            "Loss in iteration no. 71800 ==> 0.44701270693957057\n",
            "Loss in iteration no. 71801 ==> 0.4470113499076468\n",
            "Loss in iteration no. 71802 ==> 0.4470099928970076\n",
            "Loss in iteration no. 71803 ==> 0.4470086359076525\n",
            "Loss in iteration no. 71804 ==> 0.44700727893958114\n",
            "Loss in iteration no. 71805 ==> 0.44700592199279277\n",
            "Loss in iteration no. 71806 ==> 0.44700456506728714\n",
            "Loss in iteration no. 71807 ==> 0.4470032081630637\n",
            "Loss in iteration no. 71808 ==> 0.4470018512801221\n",
            "Loss in iteration no. 71809 ==> 0.4470004944184616\n",
            "Loss in iteration no. 71810 ==> 0.446999137578082\n",
            "Loss in iteration no. 71811 ==> 0.44699778075898267\n",
            "Loss in iteration no. 71812 ==> 0.4469964239611632\n",
            "Loss in iteration no. 71813 ==> 0.44699506718462306\n",
            "Loss in iteration no. 71814 ==> 0.4469937104293618\n",
            "Loss in iteration no. 71815 ==> 0.446992353695379\n",
            "Loss in iteration no. 71816 ==> 0.44699099698267414\n",
            "Loss in iteration no. 71817 ==> 0.4469896402912468\n",
            "Loss in iteration no. 71818 ==> 0.4469882836210964\n",
            "Loss in iteration no. 71819 ==> 0.44698692697222253\n",
            "Loss in iteration no. 71820 ==> 0.44698557034462477\n",
            "Loss in iteration no. 71821 ==> 0.4469842137383026\n",
            "Loss in iteration no. 71822 ==> 0.44698285715325553\n",
            "Loss in iteration no. 71823 ==> 0.44698150058948316\n",
            "Loss in iteration no. 71824 ==> 0.44698014404698494\n",
            "Loss in iteration no. 71825 ==> 0.4469787875257603\n",
            "Loss in iteration no. 71826 ==> 0.44697743102580906\n",
            "Loss in iteration no. 71827 ==> 0.4469760745471305\n",
            "Loss in iteration no. 71828 ==> 0.4469747180897243\n",
            "Loss in iteration no. 71829 ==> 0.4469733616535898\n",
            "Loss in iteration no. 71830 ==> 0.4469720052387266\n",
            "Loss in iteration no. 71831 ==> 0.4469706488451345\n",
            "Loss in iteration no. 71832 ==> 0.4469692924728126\n",
            "Loss in iteration no. 71833 ==> 0.4469679361217607\n",
            "Loss in iteration no. 71834 ==> 0.4469665797919783\n",
            "Loss in iteration no. 71835 ==> 0.44696522348346474\n",
            "Loss in iteration no. 71836 ==> 0.4469638671962198\n",
            "Loss in iteration no. 71837 ==> 0.4469625109302428\n",
            "Loss in iteration no. 71838 ==> 0.4469611546855335\n",
            "Loss in iteration no. 71839 ==> 0.4469597984620912\n",
            "Loss in iteration no. 71840 ==> 0.4469584422599156\n",
            "Loss in iteration no. 71841 ==> 0.44695708607900614\n",
            "Loss in iteration no. 71842 ==> 0.4469557299193622\n",
            "Loss in iteration no. 71843 ==> 0.4469543737809836\n",
            "Loss in iteration no. 71844 ==> 0.44695301766386974\n",
            "Loss in iteration no. 71845 ==> 0.44695166156802013\n",
            "Loss in iteration no. 71846 ==> 0.4469503054934343\n",
            "Loss in iteration no. 71847 ==> 0.4469489494401117\n",
            "Loss in iteration no. 71848 ==> 0.446947593408052\n",
            "Loss in iteration no. 71849 ==> 0.4469462373972547\n",
            "Loss in iteration no. 71850 ==> 0.4469448814077194\n",
            "Loss in iteration no. 71851 ==> 0.4469435254394453\n",
            "Loss in iteration no. 71852 ==> 0.4469421694924324\n",
            "Loss in iteration no. 71853 ==> 0.4469408135666798\n",
            "Loss in iteration no. 71854 ==> 0.4469394576621873\n",
            "Loss in iteration no. 71855 ==> 0.44693810177895443\n",
            "Loss in iteration no. 71856 ==> 0.44693674591698046\n",
            "Loss in iteration no. 71857 ==> 0.44693539007626515\n",
            "Loss in iteration no. 71858 ==> 0.446934034256808\n",
            "Loss in iteration no. 71859 ==> 0.44693267845860846\n",
            "Loss in iteration no. 71860 ==> 0.44693132268166613\n",
            "Loss in iteration no. 71861 ==> 0.4469299669259805\n",
            "Loss in iteration no. 71862 ==> 0.4469286111915511\n",
            "Loss in iteration no. 71863 ==> 0.4469272554783776\n",
            "Loss in iteration no. 71864 ==> 0.4469258997864593\n",
            "Loss in iteration no. 71865 ==> 0.4469245441157958\n",
            "Loss in iteration no. 71866 ==> 0.4469231884663866\n",
            "Loss in iteration no. 71867 ==> 0.4469218328382314\n",
            "Loss in iteration no. 71868 ==> 0.44692047723132955\n",
            "Loss in iteration no. 71869 ==> 0.44691912164568065\n",
            "Loss in iteration no. 71870 ==> 0.4469177660812842\n",
            "Loss in iteration no. 71871 ==> 0.4469164105381398\n",
            "Loss in iteration no. 71872 ==> 0.44691505501624684\n",
            "Loss in iteration no. 71873 ==> 0.44691369951560506\n",
            "Loss in iteration no. 71874 ==> 0.4469123440362137\n",
            "Loss in iteration no. 71875 ==> 0.4469109885780726\n",
            "Loss in iteration no. 71876 ==> 0.44690963314118104\n",
            "Loss in iteration no. 71877 ==> 0.44690827772553865\n",
            "Loss in iteration no. 71878 ==> 0.44690692233114504\n",
            "Loss in iteration no. 71879 ==> 0.44690556695799954\n",
            "Loss in iteration no. 71880 ==> 0.44690421160610194\n",
            "Loss in iteration no. 71881 ==> 0.4469028562754515\n",
            "Loss in iteration no. 71882 ==> 0.44690150096604797\n",
            "Loss in iteration no. 71883 ==> 0.44690014567789066\n",
            "Loss in iteration no. 71884 ==> 0.44689879041097924\n",
            "Loss in iteration no. 71885 ==> 0.4468974351653134\n",
            "Loss in iteration no. 71886 ==> 0.4468960799408922\n",
            "Loss in iteration no. 71887 ==> 0.44689472473771563\n",
            "Loss in iteration no. 71888 ==> 0.446893369555783\n",
            "Loss in iteration no. 71889 ==> 0.4468920143950939\n",
            "Loss in iteration no. 71890 ==> 0.44689065925564786\n",
            "Loss in iteration no. 71891 ==> 0.4468893041374442\n",
            "Loss in iteration no. 71892 ==> 0.44688794904048285\n",
            "Loss in iteration no. 71893 ==> 0.4468865939647631\n",
            "Loss in iteration no. 71894 ==> 0.4468852389102845\n",
            "Loss in iteration no. 71895 ==> 0.44688388387704653\n",
            "Loss in iteration no. 71896 ==> 0.44688252886504876\n",
            "Loss in iteration no. 71897 ==> 0.4468811738742908\n",
            "Loss in iteration no. 71898 ==> 0.446879818904772\n",
            "Loss in iteration no. 71899 ==> 0.44687846395649217\n",
            "Loss in iteration no. 71900 ==> 0.4468771090294506\n",
            "Loss in iteration no. 71901 ==> 0.4468757541236469\n",
            "Loss in iteration no. 71902 ==> 0.4468743992390804\n",
            "Loss in iteration no. 71903 ==> 0.446873044375751\n",
            "Loss in iteration no. 71904 ==> 0.446871689533658\n",
            "Loss in iteration no. 71905 ==> 0.4468703347128011\n",
            "Loss in iteration no. 71906 ==> 0.44686897991317953\n",
            "Loss in iteration no. 71907 ==> 0.44686762513479295\n",
            "Loss in iteration no. 71908 ==> 0.44686627037764104\n",
            "Loss in iteration no. 71909 ==> 0.44686491564172315\n",
            "Loss in iteration no. 71910 ==> 0.44686356092703894\n",
            "Loss in iteration no. 71911 ==> 0.44686220623358786\n",
            "Loss in iteration no. 71912 ==> 0.44686085156136945\n",
            "Loss in iteration no. 71913 ==> 0.4468594969103832\n",
            "Loss in iteration no. 71914 ==> 0.44685814228062876\n",
            "Loss in iteration no. 71915 ==> 0.4468567876721055\n",
            "Loss in iteration no. 71916 ==> 0.4468554330848131\n",
            "Loss in iteration no. 71917 ==> 0.44685407851875103\n",
            "Loss in iteration no. 71918 ==> 0.4468527239739188\n",
            "Loss in iteration no. 71919 ==> 0.4468513694503159\n",
            "Loss in iteration no. 71920 ==> 0.44685001494794196\n",
            "Loss in iteration no. 71921 ==> 0.44684866046679633\n",
            "Loss in iteration no. 71922 ==> 0.44684730600687883\n",
            "Loss in iteration no. 71923 ==> 0.44684595156818874\n",
            "Loss in iteration no. 71924 ==> 0.4468445971507258\n",
            "Loss in iteration no. 71925 ==> 0.4468432427544892\n",
            "Loss in iteration no. 71926 ==> 0.44684188837947886\n",
            "Loss in iteration no. 71927 ==> 0.446840534025694\n",
            "Loss in iteration no. 71928 ==> 0.4468391796931345\n",
            "Loss in iteration no. 71929 ==> 0.4468378253817995\n",
            "Loss in iteration no. 71930 ==> 0.4468364710916886\n",
            "Loss in iteration no. 71931 ==> 0.44683511682280164\n",
            "Loss in iteration no. 71932 ==> 0.44683376257513774\n",
            "Loss in iteration no. 71933 ==> 0.4468324083486968\n",
            "Loss in iteration no. 71934 ==> 0.44683105414347807\n",
            "Loss in iteration no. 71935 ==> 0.44682969995948124\n",
            "Loss in iteration no. 71936 ==> 0.4468283457967057\n",
            "Loss in iteration no. 71937 ==> 0.44682699165515116\n",
            "Loss in iteration no. 71938 ==> 0.4468256375348171\n",
            "Loss in iteration no. 71939 ==> 0.4468242834357029\n",
            "Loss in iteration no. 71940 ==> 0.44682292935780815\n",
            "Loss in iteration no. 71941 ==> 0.4468215753011326\n",
            "Loss in iteration no. 71942 ==> 0.4468202212656754\n",
            "Loss in iteration no. 71943 ==> 0.44681886725143644\n",
            "Loss in iteration no. 71944 ==> 0.446817513258415\n",
            "Loss in iteration no. 71945 ==> 0.4468161592866108\n",
            "Loss in iteration no. 71946 ==> 0.4468148053360232\n",
            "Loss in iteration no. 71947 ==> 0.44681345140665174\n",
            "Loss in iteration no. 71948 ==> 0.4468120974984961\n",
            "Loss in iteration no. 71949 ==> 0.4468107436115557\n",
            "Loss in iteration no. 71950 ==> 0.4468093897458301\n",
            "Loss in iteration no. 71951 ==> 0.44680803590131873\n",
            "Loss in iteration no. 71952 ==> 0.4468066820780213\n",
            "Loss in iteration no. 71953 ==> 0.4468053282759372\n",
            "Loss in iteration no. 71954 ==> 0.44680397449506604\n",
            "Loss in iteration no. 71955 ==> 0.44680262073540733\n",
            "Loss in iteration no. 71956 ==> 0.44680126699696054\n",
            "Loss in iteration no. 71957 ==> 0.44679991327972524\n",
            "Loss in iteration no. 71958 ==> 0.44679855958370096\n",
            "Loss in iteration no. 71959 ==> 0.4467972059088873\n",
            "Loss in iteration no. 71960 ==> 0.4467958522552837\n",
            "Loss in iteration no. 71961 ==> 0.4467944986228897\n",
            "Loss in iteration no. 71962 ==> 0.44679314501170486\n",
            "Loss in iteration no. 71963 ==> 0.44679179142172865\n",
            "Loss in iteration no. 71964 ==> 0.4467904378529607\n",
            "Loss in iteration no. 71965 ==> 0.44678908430540043\n",
            "Loss in iteration no. 71966 ==> 0.44678773077904743\n",
            "Loss in iteration no. 71967 ==> 0.44678637727390125\n",
            "Loss in iteration no. 71968 ==> 0.44678502378996143\n",
            "Loss in iteration no. 71969 ==> 0.44678367032722743\n",
            "Loss in iteration no. 71970 ==> 0.44678231688569875\n",
            "Loss in iteration no. 71971 ==> 0.44678096346537505\n",
            "Loss in iteration no. 71972 ==> 0.44677961006625566\n",
            "Loss in iteration no. 71973 ==> 0.4467782566883405\n",
            "Loss in iteration no. 71974 ==> 0.44677690333162856\n",
            "Loss in iteration no. 71975 ==> 0.4467755499961198\n",
            "Loss in iteration no. 71976 ==> 0.4467741966818136\n",
            "Loss in iteration no. 71977 ==> 0.44677284338870954\n",
            "Loss in iteration no. 71978 ==> 0.446771490116807\n",
            "Loss in iteration no. 71979 ==> 0.4467701368661056\n",
            "Loss in iteration no. 71980 ==> 0.44676878363660494\n",
            "Loss in iteration no. 71981 ==> 0.44676743042830447\n",
            "Loss in iteration no. 71982 ==> 0.44676607724120376\n",
            "Loss in iteration no. 71983 ==> 0.4467647240753023\n",
            "Loss in iteration no. 71984 ==> 0.44676337093059965\n",
            "Loss in iteration no. 71985 ==> 0.4467620178070954\n",
            "Loss in iteration no. 71986 ==> 0.44676066470478887\n",
            "Loss in iteration no. 71987 ==> 0.4467593116236798\n",
            "Loss in iteration no. 71988 ==> 0.44675795856376765\n",
            "Loss in iteration no. 71989 ==> 0.44675660552505186\n",
            "Loss in iteration no. 71990 ==> 0.4467552525075321\n",
            "Loss in iteration no. 71991 ==> 0.44675389951120803\n",
            "Loss in iteration no. 71992 ==> 0.4467525465360789\n",
            "Loss in iteration no. 71993 ==> 0.44675119358214427\n",
            "Loss in iteration no. 71994 ==> 0.4467498406494038\n",
            "Loss in iteration no. 71995 ==> 0.44674848773785686\n",
            "Loss in iteration no. 71996 ==> 0.4467471348475032\n",
            "Loss in iteration no. 71997 ==> 0.44674578197834225\n",
            "Loss in iteration no. 71998 ==> 0.44674442913037343\n",
            "Loss in iteration no. 71999 ==> 0.44674307630359633\n",
            "Loss in iteration no. 72000 ==> 0.44674172349801067\n",
            "Loss in iteration no. 72001 ==> 0.44674037071361566\n",
            "Loss in iteration no. 72002 ==> 0.44673901795041115\n",
            "Loss in iteration no. 72003 ==> 0.4467376652083964\n",
            "Loss in iteration no. 72004 ==> 0.44673631248757106\n",
            "Loss in iteration no. 72005 ==> 0.44673495978793476\n",
            "Loss in iteration no. 72006 ==> 0.44673360710948684\n",
            "Loss in iteration no. 72007 ==> 0.4467322544522269\n",
            "Loss in iteration no. 72008 ==> 0.44673090181615455\n",
            "Loss in iteration no. 72009 ==> 0.44672954920126917\n",
            "Loss in iteration no. 72010 ==> 0.4467281966075704\n",
            "Loss in iteration no. 72011 ==> 0.4467268440350578\n",
            "Loss in iteration no. 72012 ==> 0.44672549148373075\n",
            "Loss in iteration no. 72013 ==> 0.446724138953589\n",
            "Loss in iteration no. 72014 ==> 0.4467227864446319\n",
            "Loss in iteration no. 72015 ==> 0.4467214339568591\n",
            "Loss in iteration no. 72016 ==> 0.44672008149027\n",
            "Loss in iteration no. 72017 ==> 0.4467187290448641\n",
            "Loss in iteration no. 72018 ==> 0.4467173766206412\n",
            "Loss in iteration no. 72019 ==> 0.4467160242176006\n",
            "Loss in iteration no. 72020 ==> 0.44671467183574187\n",
            "Loss in iteration no. 72021 ==> 0.44671331947506465\n",
            "Loss in iteration no. 72022 ==> 0.4467119671355682\n",
            "Loss in iteration no. 72023 ==> 0.4467106148172524\n",
            "Loss in iteration no. 72024 ==> 0.44670926252011656\n",
            "Loss in iteration no. 72025 ==> 0.44670791024416023\n",
            "Loss in iteration no. 72026 ==> 0.4467065579893829\n",
            "Loss in iteration no. 72027 ==> 0.4467052057557844\n",
            "Loss in iteration no. 72028 ==> 0.44670385354336384\n",
            "Loss in iteration no. 72029 ==> 0.4467025013521211\n",
            "Loss in iteration no. 72030 ==> 0.4467011491820554\n",
            "Loss in iteration no. 72031 ==> 0.4466997970331666\n",
            "Loss in iteration no. 72032 ==> 0.4466984449054539\n",
            "Loss in iteration no. 72033 ==> 0.4466970927989172\n",
            "Loss in iteration no. 72034 ==> 0.44669574071355556\n",
            "Loss in iteration no. 72035 ==> 0.4466943886493688\n",
            "Loss in iteration no. 72036 ==> 0.4466930366063566\n",
            "Loss in iteration no. 72037 ==> 0.4466916845845182\n",
            "Loss in iteration no. 72038 ==> 0.44669033258385327\n",
            "Loss in iteration no. 72039 ==> 0.4466889806043613\n",
            "Loss in iteration no. 72040 ==> 0.4466876286460418\n",
            "Loss in iteration no. 72041 ==> 0.4466862767088943\n",
            "Loss in iteration no. 72042 ==> 0.4466849247929185\n",
            "Loss in iteration no. 72043 ==> 0.44668357289811367\n",
            "Loss in iteration no. 72044 ==> 0.4466822210244796\n",
            "Loss in iteration no. 72045 ==> 0.44668086917201555\n",
            "Loss in iteration no. 72046 ==> 0.44667951734072125\n",
            "Loss in iteration no. 72047 ==> 0.4466781655305962\n",
            "Loss in iteration no. 72048 ==> 0.44667681374163987\n",
            "Loss in iteration no. 72049 ==> 0.4466754619738519\n",
            "Loss in iteration no. 72050 ==> 0.44667411022723164\n",
            "Loss in iteration no. 72051 ==> 0.44667275850177873\n",
            "Loss in iteration no. 72052 ==> 0.4466714067974927\n",
            "Loss in iteration no. 72053 ==> 0.4466700551143731\n",
            "Loss in iteration no. 72054 ==> 0.4466687034524194\n",
            "Loss in iteration no. 72055 ==> 0.44666735181163125\n",
            "Loss in iteration no. 72056 ==> 0.44666600019200803\n",
            "Loss in iteration no. 72057 ==> 0.44666464859354926\n",
            "Loss in iteration no. 72058 ==> 0.4466632970162547\n",
            "Loss in iteration no. 72059 ==> 0.4466619454601236\n",
            "Loss in iteration no. 72060 ==> 0.44666059392515584\n",
            "Loss in iteration no. 72061 ==> 0.4466592424113505\n",
            "Loss in iteration no. 72062 ==> 0.44665789091870745\n",
            "Loss in iteration no. 72063 ==> 0.44665653944722616\n",
            "Loss in iteration no. 72064 ==> 0.446655187996906\n",
            "Loss in iteration no. 72065 ==> 0.4466538365677467\n",
            "Loss in iteration no. 72066 ==> 0.4466524851597476\n",
            "Loss in iteration no. 72067 ==> 0.44665113377290844\n",
            "Loss in iteration no. 72068 ==> 0.44664978240722863\n",
            "Loss in iteration no. 72069 ==> 0.44664843106270774\n",
            "Loss in iteration no. 72070 ==> 0.4466470797393452\n",
            "Loss in iteration no. 72071 ==> 0.44664572843714084\n",
            "Loss in iteration no. 72072 ==> 0.4466443771560938\n",
            "Loss in iteration no. 72073 ==> 0.4466430258962038\n",
            "Loss in iteration no. 72074 ==> 0.4466416746574704\n",
            "Loss in iteration no. 72075 ==> 0.44664032343989307\n",
            "Loss in iteration no. 72076 ==> 0.4466389722434713\n",
            "Loss in iteration no. 72077 ==> 0.4466376210682048\n",
            "Loss in iteration no. 72078 ==> 0.44663626991409294\n",
            "Loss in iteration no. 72079 ==> 0.44663491878113526\n",
            "Loss in iteration no. 72080 ==> 0.4466335676693313\n",
            "Loss in iteration no. 72081 ==> 0.4466322165786808\n",
            "Loss in iteration no. 72082 ==> 0.4466308655091829\n",
            "Loss in iteration no. 72083 ==> 0.44662951446083743\n",
            "Loss in iteration no. 72084 ==> 0.44662816343364387\n",
            "Loss in iteration no. 72085 ==> 0.4466268124276017\n",
            "Loss in iteration no. 72086 ==> 0.44662546144271037\n",
            "Loss in iteration no. 72087 ==> 0.44662411047896955\n",
            "Loss in iteration no. 72088 ==> 0.4466227595363788\n",
            "Loss in iteration no. 72089 ==> 0.4466214086149375\n",
            "Loss in iteration no. 72090 ==> 0.44662005771464525\n",
            "Loss in iteration no. 72091 ==> 0.44661870683550176\n",
            "Loss in iteration no. 72092 ==> 0.4466173559775062\n",
            "Loss in iteration no. 72093 ==> 0.44661600514065836\n",
            "Loss in iteration no. 72094 ==> 0.44661465432495767\n",
            "Loss in iteration no. 72095 ==> 0.4466133035304038\n",
            "Loss in iteration no. 72096 ==> 0.44661195275699617\n",
            "Loss in iteration no. 72097 ==> 0.44661060200473424\n",
            "Loss in iteration no. 72098 ==> 0.4466092512736176\n",
            "Loss in iteration no. 72099 ==> 0.4466079005636459\n",
            "Loss in iteration no. 72100 ==> 0.44660654987481846\n",
            "Loss in iteration no. 72101 ==> 0.44660519920713504\n",
            "Loss in iteration no. 72102 ==> 0.44660384856059504\n",
            "Loss in iteration no. 72103 ==> 0.446602497935198\n",
            "Loss in iteration no. 72104 ==> 0.4466011473309434\n",
            "Loss in iteration no. 72105 ==> 0.44659979674783096\n",
            "Loss in iteration no. 72106 ==> 0.4465984461858599\n",
            "Loss in iteration no. 72107 ==> 0.44659709564503014\n",
            "Loss in iteration no. 72108 ==> 0.446595745125341\n",
            "Loss in iteration no. 72109 ==> 0.44659439462679185\n",
            "Loss in iteration no. 72110 ==> 0.44659304414938245\n",
            "Loss in iteration no. 72111 ==> 0.44659169369311236\n",
            "Loss in iteration no. 72112 ==> 0.44659034325798097\n",
            "Loss in iteration no. 72113 ==> 0.4465889928439879\n",
            "Loss in iteration no. 72114 ==> 0.44658764245113264\n",
            "Loss in iteration no. 72115 ==> 0.44658629207941475\n",
            "Loss in iteration no. 72116 ==> 0.4465849417288338\n",
            "Loss in iteration no. 72117 ==> 0.4465835913993891\n",
            "Loss in iteration no. 72118 ==> 0.44658224109108047\n",
            "Loss in iteration no. 72119 ==> 0.4465808908039073\n",
            "Loss in iteration no. 72120 ==> 0.44657954053786914\n",
            "Loss in iteration no. 72121 ==> 0.44657819029296547\n",
            "Loss in iteration no. 72122 ==> 0.44657684006919596\n",
            "Loss in iteration no. 72123 ==> 0.4465754898665599\n",
            "Loss in iteration no. 72124 ==> 0.44657413968505716\n",
            "Loss in iteration no. 72125 ==> 0.44657278952468704\n",
            "Loss in iteration no. 72126 ==> 0.4465714393854491\n",
            "Loss in iteration no. 72127 ==> 0.4465700892673429\n",
            "Loss in iteration no. 72128 ==> 0.446568739170368\n",
            "Loss in iteration no. 72129 ==> 0.4465673890945238\n",
            "Loss in iteration no. 72130 ==> 0.44656603903981007\n",
            "Loss in iteration no. 72131 ==> 0.44656468900622603\n",
            "Loss in iteration no. 72132 ==> 0.4465633389937716\n",
            "Loss in iteration no. 72133 ==> 0.446561989002446\n",
            "Loss in iteration no. 72134 ==> 0.4465606390322488\n",
            "Loss in iteration no. 72135 ==> 0.4465592890831797\n",
            "Loss in iteration no. 72136 ==> 0.446557939155238\n",
            "Loss in iteration no. 72137 ==> 0.4465565892484235\n",
            "Loss in iteration no. 72138 ==> 0.4465552393627354\n",
            "Loss in iteration no. 72139 ==> 0.4465538894981736\n",
            "Loss in iteration no. 72140 ==> 0.4465525396547374\n",
            "Loss in iteration no. 72141 ==> 0.44655118983242637\n",
            "Loss in iteration no. 72142 ==> 0.44654984003124015\n",
            "Loss in iteration no. 72143 ==> 0.446548490251178\n",
            "Loss in iteration no. 72144 ==> 0.4465471404922397\n",
            "Loss in iteration no. 72145 ==> 0.44654579075442463\n",
            "Loss in iteration no. 72146 ==> 0.44654444103773255\n",
            "Loss in iteration no. 72147 ==> 0.44654309134216286\n",
            "Loss in iteration no. 72148 ==> 0.44654174166771504\n",
            "Loss in iteration no. 72149 ==> 0.44654039201438867\n",
            "Loss in iteration no. 72150 ==> 0.4465390423821833\n",
            "Loss in iteration no. 72151 ==> 0.4465376927710983\n",
            "Loss in iteration no. 72152 ==> 0.44653634318113344\n",
            "Loss in iteration no. 72153 ==> 0.4465349936122881\n",
            "Loss in iteration no. 72154 ==> 0.446533644064562\n",
            "Loss in iteration no. 72155 ==> 0.4465322945379544\n",
            "Loss in iteration no. 72156 ==> 0.446530945032465\n",
            "Loss in iteration no. 72157 ==> 0.4465295955480933\n",
            "Loss in iteration no. 72158 ==> 0.4465282460848388\n",
            "Loss in iteration no. 72159 ==> 0.4465268966427012\n",
            "Loss in iteration no. 72160 ==> 0.4465255472216798\n",
            "Loss in iteration no. 72161 ==> 0.44652419782177427\n",
            "Loss in iteration no. 72162 ==> 0.44652284844298407\n",
            "Loss in iteration no. 72163 ==> 0.44652149908530875\n",
            "Loss in iteration no. 72164 ==> 0.4465201497487479\n",
            "Loss in iteration no. 72165 ==> 0.44651880043330094\n",
            "Loss in iteration no. 72166 ==> 0.4465174511389675\n",
            "Loss in iteration no. 72167 ==> 0.4465161018657471\n",
            "Loss in iteration no. 72168 ==> 0.4465147526136394\n",
            "Loss in iteration no. 72169 ==> 0.4465134033826436\n",
            "Loss in iteration no. 72170 ==> 0.4465120541727595\n",
            "Loss in iteration no. 72171 ==> 0.44651070498398654\n",
            "Loss in iteration no. 72172 ==> 0.4465093558163243\n",
            "Loss in iteration no. 72173 ==> 0.4465080066697723\n",
            "Loss in iteration no. 72174 ==> 0.44650665754432994\n",
            "Loss in iteration no. 72175 ==> 0.446505308439997\n",
            "Loss in iteration no. 72176 ==> 0.4465039593567727\n",
            "Loss in iteration no. 72177 ==> 0.4465026102946569\n",
            "Loss in iteration no. 72178 ==> 0.4465012612536489\n",
            "Loss in iteration no. 72179 ==> 0.44649991223374846\n",
            "Loss in iteration no. 72180 ==> 0.44649856323495485\n",
            "Loss in iteration no. 72181 ==> 0.44649721425726785\n",
            "Loss in iteration no. 72182 ==> 0.4464958653006867\n",
            "Loss in iteration no. 72183 ==> 0.4464945163652112\n",
            "Loss in iteration no. 72184 ==> 0.4464931674508407\n",
            "Loss in iteration no. 72185 ==> 0.4464918185575749\n",
            "Loss in iteration no. 72186 ==> 0.44649046968541317\n",
            "Loss in iteration no. 72187 ==> 0.4464891208343552\n",
            "Loss in iteration no. 72188 ==> 0.4464877720044004\n",
            "Loss in iteration no. 72189 ==> 0.4464864231955483\n",
            "Loss in iteration no. 72190 ==> 0.4464850744077986\n",
            "Loss in iteration no. 72191 ==> 0.44648372564115063\n",
            "Loss in iteration no. 72192 ==> 0.4464823768956041\n",
            "Loss in iteration no. 72193 ==> 0.4464810281711583\n",
            "Loss in iteration no. 72194 ==> 0.44647967946781303\n",
            "Loss in iteration no. 72195 ==> 0.44647833078556765\n",
            "Loss in iteration no. 72196 ==> 0.4464769821244218\n",
            "Loss in iteration no. 72197 ==> 0.44647563348437486\n",
            "Loss in iteration no. 72198 ==> 0.44647428486542645\n",
            "Loss in iteration no. 72199 ==> 0.44647293626757617\n",
            "Loss in iteration no. 72200 ==> 0.4464715876908235\n",
            "Loss in iteration no. 72201 ==> 0.446470239135168\n",
            "Loss in iteration no. 72202 ==> 0.4464688906006092\n",
            "Loss in iteration no. 72203 ==> 0.44646754208714645\n",
            "Loss in iteration no. 72204 ==> 0.4464661935947795\n",
            "Loss in iteration no. 72205 ==> 0.4464648451235079\n",
            "Loss in iteration no. 72206 ==> 0.44646349667333113\n",
            "Loss in iteration no. 72207 ==> 0.44646214824424857\n",
            "Loss in iteration no. 72208 ==> 0.44646079983625997\n",
            "Loss in iteration no. 72209 ==> 0.4464594514493648\n",
            "Loss in iteration no. 72210 ==> 0.44645810308356254\n",
            "Loss in iteration no. 72211 ==> 0.4464567547388527\n",
            "Loss in iteration no. 72212 ==> 0.44645540641523496\n",
            "Loss in iteration no. 72213 ==> 0.44645405811270866\n",
            "Loss in iteration no. 72214 ==> 0.4464527098312735\n",
            "Loss in iteration no. 72215 ==> 0.44645136157092896\n",
            "Loss in iteration no. 72216 ==> 0.44645001333167444\n",
            "Loss in iteration no. 72217 ==> 0.44644866511350967\n",
            "Loss in iteration no. 72218 ==> 0.4464473169164341\n",
            "Loss in iteration no. 72219 ==> 0.4464459687404473\n",
            "Loss in iteration no. 72220 ==> 0.44644462058554873\n",
            "Loss in iteration no. 72221 ==> 0.446443272451738\n",
            "Loss in iteration no. 72222 ==> 0.44644192433901453\n",
            "Loss in iteration no. 72223 ==> 0.446440576247378\n",
            "Loss in iteration no. 72224 ==> 0.4464392281768279\n",
            "Loss in iteration no. 72225 ==> 0.44643788012736363\n",
            "Loss in iteration no. 72226 ==> 0.44643653209898493\n",
            "Loss in iteration no. 72227 ==> 0.44643518409169114\n",
            "Loss in iteration no. 72228 ==> 0.446433836105482\n",
            "Loss in iteration no. 72229 ==> 0.4464324881403568\n",
            "Loss in iteration no. 72230 ==> 0.4464311401963153\n",
            "Loss in iteration no. 72231 ==> 0.44642979227335694\n",
            "Loss in iteration no. 72232 ==> 0.4464284443714812\n",
            "Loss in iteration no. 72233 ==> 0.4464270964906877\n",
            "Loss in iteration no. 72234 ==> 0.44642574863097595\n",
            "Loss in iteration no. 72235 ==> 0.44642440079234547\n",
            "Loss in iteration no. 72236 ==> 0.4464230529747957\n",
            "Loss in iteration no. 72237 ==> 0.4464217051783263\n",
            "Loss in iteration no. 72238 ==> 0.4464203574029369\n",
            "Loss in iteration no. 72239 ==> 0.4464190096486268\n",
            "Loss in iteration no. 72240 ==> 0.44641766191539556\n",
            "Loss in iteration no. 72241 ==> 0.44641631420324296\n",
            "Loss in iteration no. 72242 ==> 0.4464149665121682\n",
            "Loss in iteration no. 72243 ==> 0.4464136188421712\n",
            "Loss in iteration no. 72244 ==> 0.4464122711932511\n",
            "Loss in iteration no. 72245 ==> 0.44641092356540774\n",
            "Loss in iteration no. 72246 ==> 0.4464095759586404\n",
            "Loss in iteration no. 72247 ==> 0.44640822837294875\n",
            "Loss in iteration no. 72248 ==> 0.44640688080833235\n",
            "Loss in iteration no. 72249 ==> 0.44640553326479065\n",
            "Loss in iteration no. 72250 ==> 0.4464041857423232\n",
            "Loss in iteration no. 72251 ==> 0.4464028382409296\n",
            "Loss in iteration no. 72252 ==> 0.4464014907606093\n",
            "Loss in iteration no. 72253 ==> 0.44640014330136196\n",
            "Loss in iteration no. 72254 ==> 0.446398795863187\n",
            "Loss in iteration no. 72255 ==> 0.446397448446084\n",
            "Loss in iteration no. 72256 ==> 0.44639610105005245\n",
            "Loss in iteration no. 72257 ==> 0.4463947536750919\n",
            "Loss in iteration no. 72258 ==> 0.4463934063212019\n",
            "Loss in iteration no. 72259 ==> 0.4463920589883819\n",
            "Loss in iteration no. 72260 ==> 0.44639071167663164\n",
            "Loss in iteration no. 72261 ==> 0.4463893643859505\n",
            "Loss in iteration no. 72262 ==> 0.446388017116338\n",
            "Loss in iteration no. 72263 ==> 0.44638666986779374\n",
            "Loss in iteration no. 72264 ==> 0.4463853226403172\n",
            "Loss in iteration no. 72265 ==> 0.44638397543390806\n",
            "Loss in iteration no. 72266 ==> 0.4463826282485656\n",
            "Loss in iteration no. 72267 ==> 0.44638128108428954\n",
            "Loss in iteration no. 72268 ==> 0.44637993394107933\n",
            "Loss in iteration no. 72269 ==> 0.44637858681893455\n",
            "Loss in iteration no. 72270 ==> 0.4463772397178548\n",
            "Loss in iteration no. 72271 ==> 0.4463758926378395\n",
            "Loss in iteration no. 72272 ==> 0.44637454557888817\n",
            "Loss in iteration no. 72273 ==> 0.4463731985410003\n",
            "Loss in iteration no. 72274 ==> 0.44637185152417574\n",
            "Loss in iteration no. 72275 ==> 0.44637050452841376\n",
            "Loss in iteration no. 72276 ==> 0.44636915755371376\n",
            "Loss in iteration no. 72277 ==> 0.44636781060007563\n",
            "Loss in iteration no. 72278 ==> 0.4463664636674986\n",
            "Loss in iteration no. 72279 ==> 0.44636511675598245\n",
            "Loss in iteration no. 72280 ==> 0.44636376986552645\n",
            "Loss in iteration no. 72281 ==> 0.4463624229961304\n",
            "Loss in iteration no. 72282 ==> 0.44636107614779347\n",
            "Loss in iteration no. 72283 ==> 0.44635972932051565\n",
            "Loss in iteration no. 72284 ==> 0.44635838251429627\n",
            "Loss in iteration no. 72285 ==> 0.4463570357291349\n",
            "Loss in iteration no. 72286 ==> 0.4463556889650308\n",
            "Loss in iteration no. 72287 ==> 0.44635434222198395\n",
            "Loss in iteration no. 72288 ==> 0.4463529954999935\n",
            "Loss in iteration no. 72289 ==> 0.44635164879905925\n",
            "Loss in iteration no. 72290 ==> 0.4463503021191806\n",
            "Loss in iteration no. 72291 ==> 0.4463489554603572\n",
            "Loss in iteration no. 72292 ==> 0.44634760882258845\n",
            "Loss in iteration no. 72293 ==> 0.44634626220587387\n",
            "Loss in iteration no. 72294 ==> 0.44634491561021317\n",
            "Loss in iteration no. 72295 ==> 0.4463435690356057\n",
            "Loss in iteration no. 72296 ==> 0.446342222482051\n",
            "Loss in iteration no. 72297 ==> 0.4463408759495488\n",
            "Loss in iteration no. 72298 ==> 0.4463395294380984\n",
            "Loss in iteration no. 72299 ==> 0.4463381829476996\n",
            "Loss in iteration no. 72300 ==> 0.44633683647835165\n",
            "Loss in iteration no. 72301 ==> 0.44633549003005424\n",
            "Loss in iteration no. 72302 ==> 0.4463341436028069\n",
            "Loss in iteration no. 72303 ==> 0.4463327971966091\n",
            "Loss in iteration no. 72304 ==> 0.4463314508114604\n",
            "Loss in iteration no. 72305 ==> 0.4463301044473604\n",
            "Loss in iteration no. 72306 ==> 0.44632875810430855\n",
            "Loss in iteration no. 72307 ==> 0.4463274117823044\n",
            "Loss in iteration no. 72308 ==> 0.44632606548134757\n",
            "Loss in iteration no. 72309 ==> 0.44632471920143746\n",
            "Loss in iteration no. 72310 ==> 0.44632337294257374\n",
            "Loss in iteration no. 72311 ==> 0.44632202670475585\n",
            "Loss in iteration no. 72312 ==> 0.44632068048798323\n",
            "Loss in iteration no. 72313 ==> 0.4463193342922557\n",
            "Loss in iteration no. 72314 ==> 0.4463179881175725\n",
            "Loss in iteration no. 72315 ==> 0.4463166419639334\n",
            "Loss in iteration no. 72316 ==> 0.44631529583133783\n",
            "Loss in iteration no. 72317 ==> 0.44631394971978516\n",
            "Loss in iteration no. 72318 ==> 0.4463126036292753\n",
            "Loss in iteration no. 72319 ==> 0.4463112575598075\n",
            "Loss in iteration no. 72320 ==> 0.4463099115113812\n",
            "Loss in iteration no. 72321 ==> 0.44630856548399633\n",
            "Loss in iteration no. 72322 ==> 0.4463072194776521\n",
            "Loss in iteration no. 72323 ==> 0.4463058734923482\n",
            "Loss in iteration no. 72324 ==> 0.446304527528084\n",
            "Loss in iteration no. 72325 ==> 0.4463031815848592\n",
            "Loss in iteration no. 72326 ==> 0.4463018356626733\n",
            "Loss in iteration no. 72327 ==> 0.44630048976152575\n",
            "Loss in iteration no. 72328 ==> 0.44629914388141617\n",
            "Loss in iteration no. 72329 ==> 0.44629779802234404\n",
            "Loss in iteration no. 72330 ==> 0.446296452184309\n",
            "Loss in iteration no. 72331 ==> 0.4462951063673104\n",
            "Loss in iteration no. 72332 ==> 0.446293760571348\n",
            "Loss in iteration no. 72333 ==> 0.4462924147964211\n",
            "Loss in iteration no. 72334 ==> 0.4462910690425294\n",
            "Loss in iteration no. 72335 ==> 0.4462897233096725\n",
            "Loss in iteration no. 72336 ==> 0.4462883775978497\n",
            "Loss in iteration no. 72337 ==> 0.44628703190706065\n",
            "Loss in iteration no. 72338 ==> 0.4462856862373049\n",
            "Loss in iteration no. 72339 ==> 0.4462843405885821\n",
            "Loss in iteration no. 72340 ==> 0.44628299496089147\n",
            "Loss in iteration no. 72341 ==> 0.4462816493542328\n",
            "Loss in iteration no. 72342 ==> 0.44628030376860567\n",
            "Loss in iteration no. 72343 ==> 0.44627895820400937\n",
            "Loss in iteration no. 72344 ==> 0.44627761266044363\n",
            "Loss in iteration no. 72345 ==> 0.44627626713790797\n",
            "Loss in iteration no. 72346 ==> 0.44627492163640187\n",
            "Loss in iteration no. 72347 ==> 0.4462735761559248\n",
            "Loss in iteration no. 72348 ==> 0.44627223069647637\n",
            "Loss in iteration no. 72349 ==> 0.44627088525805625\n",
            "Loss in iteration no. 72350 ==> 0.44626953984066375\n",
            "Loss in iteration no. 72351 ==> 0.44626819444429844\n",
            "Loss in iteration no. 72352 ==> 0.44626684906896\n",
            "Loss in iteration no. 72353 ==> 0.4462655037146478\n",
            "Loss in iteration no. 72354 ==> 0.44626415838136146\n",
            "Loss in iteration no. 72355 ==> 0.44626281306910065\n",
            "Loss in iteration no. 72356 ==> 0.4462614677778646\n",
            "Loss in iteration no. 72357 ==> 0.44626012250765307\n",
            "Loss in iteration no. 72358 ==> 0.4462587772584655\n",
            "Loss in iteration no. 72359 ==> 0.44625743203030144\n",
            "Loss in iteration no. 72360 ==> 0.44625608682316054\n",
            "Loss in iteration no. 72361 ==> 0.4462547416370422\n",
            "Loss in iteration no. 72362 ==> 0.446253396471946\n",
            "Loss in iteration no. 72363 ==> 0.44625205132787144\n",
            "Loss in iteration no. 72364 ==> 0.4462507062048181\n",
            "Loss in iteration no. 72365 ==> 0.44624936110278557\n",
            "Loss in iteration no. 72366 ==> 0.4462480160217732\n",
            "Loss in iteration no. 72367 ==> 0.44624667096178067\n",
            "Loss in iteration no. 72368 ==> 0.44624532592280747\n",
            "Loss in iteration no. 72369 ==> 0.4462439809048531\n",
            "Loss in iteration no. 72370 ==> 0.4462426359079173\n",
            "Loss in iteration no. 72371 ==> 0.4462412909319993\n",
            "Loss in iteration no. 72372 ==> 0.44623994597709893\n",
            "Loss in iteration no. 72373 ==> 0.4462386010432155\n",
            "Loss in iteration no. 72374 ==> 0.4462372561303486\n",
            "Loss in iteration no. 72375 ==> 0.4462359112384979\n",
            "Loss in iteration no. 72376 ==> 0.4462345663676626\n",
            "Loss in iteration no. 72377 ==> 0.4462332215178427\n",
            "Loss in iteration no. 72378 ==> 0.4462318766890374\n",
            "Loss in iteration no. 72379 ==> 0.44623053188124634\n",
            "Loss in iteration no. 72380 ==> 0.44622918709446907\n",
            "Loss in iteration no. 72381 ==> 0.4462278423287051\n",
            "Loss in iteration no. 72382 ==> 0.446226497583954\n",
            "Loss in iteration no. 72383 ==> 0.44622515286021525\n",
            "Loss in iteration no. 72384 ==> 0.4462238081574883\n",
            "Loss in iteration no. 72385 ==> 0.446222463475773\n",
            "Loss in iteration no. 72386 ==> 0.44622111881506843\n",
            "Loss in iteration no. 72387 ==> 0.44621977417537456\n",
            "Loss in iteration no. 72388 ==> 0.4462184295566907\n",
            "Loss in iteration no. 72389 ==> 0.4462170849590164\n",
            "Loss in iteration no. 72390 ==> 0.44621574038235123\n",
            "Loss in iteration no. 72391 ==> 0.4462143958266948\n",
            "Loss in iteration no. 72392 ==> 0.4462130512920465\n",
            "Loss in iteration no. 72393 ==> 0.446211706778406\n",
            "Loss in iteration no. 72394 ==> 0.4462103622857727\n",
            "Loss in iteration no. 72395 ==> 0.44620901781414624\n",
            "Loss in iteration no. 72396 ==> 0.44620767336352607\n",
            "Loss in iteration no. 72397 ==> 0.4462063289339118\n",
            "Loss in iteration no. 72398 ==> 0.446204984525303\n",
            "Loss in iteration no. 72399 ==> 0.4462036401376991\n",
            "Loss in iteration no. 72400 ==> 0.44620229577109966\n",
            "Loss in iteration no. 72401 ==> 0.4462009514255042\n",
            "Loss in iteration no. 72402 ==> 0.44619960710091233\n",
            "Loss in iteration no. 72403 ==> 0.44619826279732355\n",
            "Loss in iteration no. 72404 ==> 0.4461969185147374\n",
            "Loss in iteration no. 72405 ==> 0.4461955742531534\n",
            "Loss in iteration no. 72406 ==> 0.4461942300125711\n",
            "Loss in iteration no. 72407 ==> 0.44619288579299005\n",
            "Loss in iteration no. 72408 ==> 0.4461915415944097\n",
            "Loss in iteration no. 72409 ==> 0.44619019741682975\n",
            "Loss in iteration no. 72410 ==> 0.4461888532602496\n",
            "Loss in iteration no. 72411 ==> 0.44618750912466887\n",
            "Loss in iteration no. 72412 ==> 0.44618616501008695\n",
            "Loss in iteration no. 72413 ==> 0.4461848209165035\n",
            "Loss in iteration no. 72414 ==> 0.44618347684391807\n",
            "Loss in iteration no. 72415 ==> 0.4461821327923301\n",
            "Loss in iteration no. 72416 ==> 0.4461807887617394\n",
            "Loss in iteration no. 72417 ==> 0.44617944475214505\n",
            "Loss in iteration no. 72418 ==> 0.44617810076354686\n",
            "Loss in iteration no. 72419 ==> 0.4461767567959443\n",
            "Loss in iteration no. 72420 ==> 0.4461754128493369\n",
            "Loss in iteration no. 72421 ==> 0.4461740689237245\n",
            "Loss in iteration no. 72422 ==> 0.4461727250191062\n",
            "Loss in iteration no. 72423 ==> 0.4461713811354817\n",
            "Loss in iteration no. 72424 ==> 0.4461700372728506\n",
            "Loss in iteration no. 72425 ==> 0.44616869343121235\n",
            "Loss in iteration no. 72426 ==> 0.4461673496105665\n",
            "Loss in iteration no. 72427 ==> 0.44616600581091254\n",
            "Loss in iteration no. 72428 ==> 0.4461646620322502\n",
            "Loss in iteration no. 72429 ==> 0.44616331827457884\n",
            "Loss in iteration no. 72430 ==> 0.446161974537898\n",
            "Loss in iteration no. 72431 ==> 0.4461606308222073\n",
            "Loss in iteration no. 72432 ==> 0.4461592871275062\n",
            "Loss in iteration no. 72433 ==> 0.4461579434537943\n",
            "Loss in iteration no. 72434 ==> 0.44615659980107103\n",
            "Loss in iteration no. 72435 ==> 0.4461552561693361\n",
            "Loss in iteration no. 72436 ==> 0.4461539125585888\n",
            "Loss in iteration no. 72437 ==> 0.446152568968829\n",
            "Loss in iteration no. 72438 ==> 0.4461512254000559\n",
            "Loss in iteration no. 72439 ==> 0.4461498818522692\n",
            "Loss in iteration no. 72440 ==> 0.44614853832546847\n",
            "Loss in iteration no. 72441 ==> 0.4461471948196533\n",
            "Loss in iteration no. 72442 ==> 0.44614585133482293\n",
            "Loss in iteration no. 72443 ==> 0.4461445078709772\n",
            "Loss in iteration no. 72444 ==> 0.4461431644281155\n",
            "Loss in iteration no. 72445 ==> 0.4461418210062374\n",
            "Loss in iteration no. 72446 ==> 0.4461404776053425\n",
            "Loss in iteration no. 72447 ==> 0.44613913422543017\n",
            "Loss in iteration no. 72448 ==> 0.44613779086650013\n",
            "Loss in iteration no. 72449 ==> 0.4461364475285518\n",
            "Loss in iteration no. 72450 ==> 0.4461351042115848\n",
            "Loss in iteration no. 72451 ==> 0.44613376091559853\n",
            "Loss in iteration no. 72452 ==> 0.44613241764059275\n",
            "Loss in iteration no. 72453 ==> 0.4461310743865668\n",
            "Loss in iteration no. 72454 ==> 0.44612973115352017\n",
            "Loss in iteration no. 72455 ==> 0.44612838794145265\n",
            "Loss in iteration no. 72456 ==> 0.4461270447503636\n",
            "Loss in iteration no. 72457 ==> 0.44612570158025255\n",
            "Loss in iteration no. 72458 ==> 0.4461243584311192\n",
            "Loss in iteration no. 72459 ==> 0.4461230153029629\n",
            "Loss in iteration no. 72460 ==> 0.44612167219578314\n",
            "Loss in iteration no. 72461 ==> 0.4461203291095796\n",
            "Loss in iteration no. 72462 ==> 0.44611898604435185\n",
            "Loss in iteration no. 72463 ==> 0.4461176430000993\n",
            "Loss in iteration no. 72464 ==> 0.4461162999768216\n",
            "Loss in iteration no. 72465 ==> 0.4461149569745183\n",
            "Loss in iteration no. 72466 ==> 0.44611361399318866\n",
            "Loss in iteration no. 72467 ==> 0.4461122710328327\n",
            "Loss in iteration no. 72468 ==> 0.4461109280934495\n",
            "Loss in iteration no. 72469 ==> 0.44610958517503874\n",
            "Loss in iteration no. 72470 ==> 0.44610824227760015\n",
            "Loss in iteration no. 72471 ==> 0.44610689940113296\n",
            "Loss in iteration no. 72472 ==> 0.44610555654563694\n",
            "Loss in iteration no. 72473 ==> 0.4461042137111116\n",
            "Loss in iteration no. 72474 ==> 0.44610287089755635\n",
            "Loss in iteration no. 72475 ==> 0.4461015281049707\n",
            "Loss in iteration no. 72476 ==> 0.4461001853333544\n",
            "Loss in iteration no. 72477 ==> 0.4460988425827069\n",
            "Loss in iteration no. 72478 ==> 0.44609749985302777\n",
            "Loss in iteration no. 72479 ==> 0.4460961571443163\n",
            "Loss in iteration no. 72480 ==> 0.44609481445657234\n",
            "Loss in iteration no. 72481 ==> 0.44609347178979525\n",
            "Loss in iteration no. 72482 ==> 0.44609212914398455\n",
            "Loss in iteration no. 72483 ==> 0.44609078651913986\n",
            "Loss in iteration no. 72484 ==> 0.44608944391526084\n",
            "Loss in iteration no. 72485 ==> 0.44608810133234683\n",
            "Loss in iteration no. 72486 ==> 0.44608675877039733\n",
            "Loss in iteration no. 72487 ==> 0.44608541622941217\n",
            "Loss in iteration no. 72488 ==> 0.4460840737093905\n",
            "Loss in iteration no. 72489 ==> 0.4460827312103321\n",
            "Loss in iteration no. 72490 ==> 0.4460813887322365\n",
            "Loss in iteration no. 72491 ==> 0.4460800462751031\n",
            "Loss in iteration no. 72492 ==> 0.44607870383893167\n",
            "Loss in iteration no. 72493 ==> 0.4460773614237214\n",
            "Loss in iteration no. 72494 ==> 0.4460760190294722\n",
            "Loss in iteration no. 72495 ==> 0.4460746766561833\n",
            "Loss in iteration no. 72496 ==> 0.4460733343038546\n",
            "Loss in iteration no. 72497 ==> 0.4460719919724852\n",
            "Loss in iteration no. 72498 ==> 0.4460706496620749\n",
            "Loss in iteration no. 72499 ==> 0.4460693073726231\n",
            "Loss in iteration no. 72500 ==> 0.4460679651041296\n",
            "Loss in iteration no. 72501 ==> 0.44606662285659365\n",
            "Loss in iteration no. 72502 ==> 0.44606528063001494\n",
            "Loss in iteration no. 72503 ==> 0.44606393842439296\n",
            "Loss in iteration no. 72504 ==> 0.44606259623972716\n",
            "Loss in iteration no. 72505 ==> 0.44606125407601727\n",
            "Loss in iteration no. 72506 ==> 0.4460599119332627\n",
            "Loss in iteration no. 72507 ==> 0.44605856981146297\n",
            "Loss in iteration no. 72508 ==> 0.44605722771061773\n",
            "Loss in iteration no. 72509 ==> 0.44605588563072646\n",
            "Loss in iteration no. 72510 ==> 0.4460545435717886\n",
            "Loss in iteration no. 72511 ==> 0.44605320153380373\n",
            "Loss in iteration no. 72512 ==> 0.44605185951677156\n",
            "Loss in iteration no. 72513 ==> 0.4460505175206915\n",
            "Loss in iteration no. 72514 ==> 0.446049175545563\n",
            "Loss in iteration no. 72515 ==> 0.44604783359138567\n",
            "Loss in iteration no. 72516 ==> 0.4460464916581591\n",
            "Loss in iteration no. 72517 ==> 0.4460451497458828\n",
            "Loss in iteration no. 72518 ==> 0.4460438078545563\n",
            "Loss in iteration no. 72519 ==> 0.446042465984179\n",
            "Loss in iteration no. 72520 ==> 0.44604112413475067\n",
            "Loss in iteration no. 72521 ==> 0.44603978230627084\n",
            "Loss in iteration no. 72522 ==> 0.4460384404987388\n",
            "Loss in iteration no. 72523 ==> 0.44603709871215425\n",
            "Loss in iteration no. 72524 ==> 0.4460357569465168\n",
            "Loss in iteration no. 72525 ==> 0.44603441520182574\n",
            "Loss in iteration no. 72526 ==> 0.44603307347808097\n",
            "Loss in iteration no. 72527 ==> 0.44603173177528177\n",
            "Loss in iteration no. 72528 ==> 0.4460303900934276\n",
            "Loss in iteration no. 72529 ==> 0.4460290484325183\n",
            "Loss in iteration no. 72530 ==> 0.4460277067925532\n",
            "Loss in iteration no. 72531 ==> 0.44602636517353184\n",
            "Loss in iteration no. 72532 ==> 0.4460250235754538\n",
            "Loss in iteration no. 72533 ==> 0.44602368199831866\n",
            "Loss in iteration no. 72534 ==> 0.4460223404421259\n",
            "Loss in iteration no. 72535 ==> 0.446020998906875\n",
            "Loss in iteration no. 72536 ==> 0.4460196573925656\n",
            "Loss in iteration no. 72537 ==> 0.44601831589919727\n",
            "Loss in iteration no. 72538 ==> 0.44601697442676946\n",
            "Loss in iteration no. 72539 ==> 0.44601563297528163\n",
            "Loss in iteration no. 72540 ==> 0.44601429154473354\n",
            "Loss in iteration no. 72541 ==> 0.44601295013512454\n",
            "Loss in iteration no. 72542 ==> 0.44601160874645424\n",
            "Loss in iteration no. 72543 ==> 0.4460102673787222\n",
            "Loss in iteration no. 72544 ==> 0.44600892603192793\n",
            "Loss in iteration no. 72545 ==> 0.4460075847060709\n",
            "Loss in iteration no. 72546 ==> 0.4460062434011507\n",
            "Loss in iteration no. 72547 ==> 0.446004902117167\n",
            "Loss in iteration no. 72548 ==> 0.4460035608541192\n",
            "Loss in iteration no. 72549 ==> 0.44600221961200665\n",
            "Loss in iteration no. 72550 ==> 0.44600087839082925\n",
            "Loss in iteration no. 72551 ==> 0.4459995371905864\n",
            "Loss in iteration no. 72552 ==> 0.4459981960112776\n",
            "Loss in iteration no. 72553 ==> 0.4459968548529024\n",
            "Loss in iteration no. 72554 ==> 0.4459955137154603\n",
            "Loss in iteration no. 72555 ==> 0.4459941725989509\n",
            "Loss in iteration no. 72556 ==> 0.4459928315033739\n",
            "Loss in iteration no. 72557 ==> 0.4459914904287284\n",
            "Loss in iteration no. 72558 ==> 0.44599014937501424\n",
            "Loss in iteration no. 72559 ==> 0.445988808342231\n",
            "Loss in iteration no. 72560 ==> 0.4459874673303781\n",
            "Loss in iteration no. 72561 ==> 0.44598612633945517\n",
            "Loss in iteration no. 72562 ==> 0.4459847853694616\n",
            "Loss in iteration no. 72563 ==> 0.4459834444203971\n",
            "Loss in iteration no. 72564 ==> 0.4459821034922611\n",
            "Loss in iteration no. 72565 ==> 0.44598076258505304\n",
            "Loss in iteration no. 72566 ==> 0.4459794216987727\n",
            "Loss in iteration no. 72567 ==> 0.44597808083341944\n",
            "Loss in iteration no. 72568 ==> 0.445976739988993\n",
            "Loss in iteration no. 72569 ==> 0.44597539916549256\n",
            "Loss in iteration no. 72570 ==> 0.445974058362918\n",
            "Loss in iteration no. 72571 ==> 0.44597271758126866\n",
            "Loss in iteration no. 72572 ==> 0.44597137682054416\n",
            "Loss in iteration no. 72573 ==> 0.4459700360807441\n",
            "Loss in iteration no. 72574 ==> 0.4459686953618679\n",
            "Loss in iteration no. 72575 ==> 0.4459673546639151\n",
            "Loss in iteration no. 72576 ==> 0.4459660139868853\n",
            "Loss in iteration no. 72577 ==> 0.4459646733307781\n",
            "Loss in iteration no. 72578 ==> 0.44596333269559285\n",
            "Loss in iteration no. 72579 ==> 0.44596199208132925\n",
            "Loss in iteration no. 72580 ==> 0.4459606514879867\n",
            "Loss in iteration no. 72581 ==> 0.4459593109155649\n",
            "Loss in iteration no. 72582 ==> 0.44595797036406326\n",
            "Loss in iteration no. 72583 ==> 0.44595662983348144\n",
            "Loss in iteration no. 72584 ==> 0.44595528932381895\n",
            "Loss in iteration no. 72585 ==> 0.44595394883507516\n",
            "Loss in iteration no. 72586 ==> 0.4459526083672497\n",
            "Loss in iteration no. 72587 ==> 0.44595126792034223\n",
            "Loss in iteration no. 72588 ==> 0.44594992749435225\n",
            "Loss in iteration no. 72589 ==> 0.4459485870892791\n",
            "Loss in iteration no. 72590 ==> 0.4459472467051226\n",
            "Loss in iteration no. 72591 ==> 0.4459459063418821\n",
            "Loss in iteration no. 72592 ==> 0.4459445659995572\n",
            "Loss in iteration no. 72593 ==> 0.4459432256781473\n",
            "Loss in iteration no. 72594 ==> 0.4459418853776523\n",
            "Loss in iteration no. 72595 ==> 0.44594054509807135\n",
            "Loss in iteration no. 72596 ==> 0.4459392048394042\n",
            "Loss in iteration no. 72597 ==> 0.44593786460165025\n",
            "Loss in iteration no. 72598 ==> 0.44593652438480924\n",
            "Loss in iteration no. 72599 ==> 0.44593518418888056\n",
            "Loss in iteration no. 72600 ==> 0.4459338440138637\n",
            "Loss in iteration no. 72601 ==> 0.4459325038597583\n",
            "Loss in iteration no. 72602 ==> 0.44593116372656394\n",
            "Loss in iteration no. 72603 ==> 0.44592982361428013\n",
            "Loss in iteration no. 72604 ==> 0.44592848352290626\n",
            "Loss in iteration no. 72605 ==> 0.4459271434524421\n",
            "Loss in iteration no. 72606 ==> 0.445925803402887\n",
            "Loss in iteration no. 72607 ==> 0.4459244633742405\n",
            "Loss in iteration no. 72608 ==> 0.44592312336650225\n",
            "Loss in iteration no. 72609 ==> 0.44592178337967175\n",
            "Loss in iteration no. 72610 ==> 0.44592044341374854\n",
            "Loss in iteration no. 72611 ==> 0.44591910346873215\n",
            "Loss in iteration no. 72612 ==> 0.4459177635446222\n",
            "Loss in iteration no. 72613 ==> 0.44591642364141804\n",
            "Loss in iteration no. 72614 ==> 0.4459150837591193\n",
            "Loss in iteration no. 72615 ==> 0.4459137438977257\n",
            "Loss in iteration no. 72616 ==> 0.4459124040572365\n",
            "Loss in iteration no. 72617 ==> 0.4459110642376513\n",
            "Loss in iteration no. 72618 ==> 0.4459097244389698\n",
            "Loss in iteration no. 72619 ==> 0.44590838466119137\n",
            "Loss in iteration no. 72620 ==> 0.44590704490431565\n",
            "Loss in iteration no. 72621 ==> 0.4459057051683421\n",
            "Loss in iteration no. 72622 ==> 0.44590436545327033\n",
            "Loss in iteration no. 72623 ==> 0.4459030257590999\n",
            "Loss in iteration no. 72624 ==> 0.44590168608583014\n",
            "Loss in iteration no. 72625 ==> 0.4459003464334608\n",
            "Loss in iteration no. 72626 ==> 0.44589900680199146\n",
            "Loss in iteration no. 72627 ==> 0.44589766719142154\n",
            "Loss in iteration no. 72628 ==> 0.4458963276017504\n",
            "Loss in iteration no. 72629 ==> 0.44589498803297806\n",
            "Loss in iteration no. 72630 ==> 0.4458936484851036\n",
            "Loss in iteration no. 72631 ==> 0.44589230895812676\n",
            "Loss in iteration no. 72632 ==> 0.4458909694520471\n",
            "Loss in iteration no. 72633 ==> 0.4458896299668641\n",
            "Loss in iteration no. 72634 ==> 0.4458882905025773\n",
            "Loss in iteration no. 72635 ==> 0.44588695105918624\n",
            "Loss in iteration no. 72636 ==> 0.44588561163669055\n",
            "Loss in iteration no. 72637 ==> 0.4458842722350896\n",
            "Loss in iteration no. 72638 ==> 0.44588293285438296\n",
            "Loss in iteration no. 72639 ==> 0.44588159349457046\n",
            "Loss in iteration no. 72640 ==> 0.44588025415565113\n",
            "Loss in iteration no. 72641 ==> 0.445878914837625\n",
            "Loss in iteration no. 72642 ==> 0.44587757554049134\n",
            "Loss in iteration no. 72643 ==> 0.44587623626424966\n",
            "Loss in iteration no. 72644 ==> 0.44587489700889965\n",
            "Loss in iteration no. 72645 ==> 0.4458735577744407\n",
            "Loss in iteration no. 72646 ==> 0.44587221856087256\n",
            "Loss in iteration no. 72647 ==> 0.4458708793681946\n",
            "Loss in iteration no. 72648 ==> 0.44586954019640646\n",
            "Loss in iteration no. 72649 ==> 0.4458682010455074\n",
            "Loss in iteration no. 72650 ==> 0.44586686191549735\n",
            "Loss in iteration no. 72651 ==> 0.44586552280637565\n",
            "Loss in iteration no. 72652 ==> 0.4458641837181418\n",
            "Loss in iteration no. 72653 ==> 0.4458628446507955\n",
            "Loss in iteration no. 72654 ==> 0.4458615056043362\n",
            "Loss in iteration no. 72655 ==> 0.4458601665787634\n",
            "Loss in iteration no. 72656 ==> 0.44585882757407663\n",
            "Loss in iteration no. 72657 ==> 0.4458574885902755\n",
            "Loss in iteration no. 72658 ==> 0.4458561496273596\n",
            "Loss in iteration no. 72659 ==> 0.4458548106853283\n",
            "Loss in iteration no. 72660 ==> 0.4458534717641813\n",
            "Loss in iteration no. 72661 ==> 0.4458521328639179\n",
            "Loss in iteration no. 72662 ==> 0.4458507939845379\n",
            "Loss in iteration no. 72663 ==> 0.4458494551260408\n",
            "Loss in iteration no. 72664 ==> 0.4458481162884261\n",
            "Loss in iteration no. 72665 ==> 0.4458467774716932\n",
            "Loss in iteration no. 72666 ==> 0.445845438675842\n",
            "Loss in iteration no. 72667 ==> 0.44584409990087154\n",
            "Loss in iteration no. 72668 ==> 0.44584276114678173\n",
            "Loss in iteration no. 72669 ==> 0.445841422413572\n",
            "Loss in iteration no. 72670 ==> 0.4458400837012419\n",
            "Loss in iteration no. 72671 ==> 0.4458387450097909\n",
            "Loss in iteration no. 72672 ==> 0.4458374063392187\n",
            "Loss in iteration no. 72673 ==> 0.4458360676895247\n",
            "Loss in iteration no. 72674 ==> 0.4458347290607084\n",
            "Loss in iteration no. 72675 ==> 0.44583339045276954\n",
            "Loss in iteration no. 72676 ==> 0.44583205186570757\n",
            "Loss in iteration no. 72677 ==> 0.4458307132995219\n",
            "Loss in iteration no. 72678 ==> 0.44582937475421214\n",
            "Loss in iteration no. 72679 ==> 0.44582803622977785\n",
            "Loss in iteration no. 72680 ==> 0.4458266977262188\n",
            "Loss in iteration no. 72681 ==> 0.445825359243534\n",
            "Loss in iteration no. 72682 ==> 0.44582402078172345\n",
            "Loss in iteration no. 72683 ==> 0.4458226823407866\n",
            "Loss in iteration no. 72684 ==> 0.4458213439207229\n",
            "Loss in iteration no. 72685 ==> 0.4458200055215318\n",
            "Loss in iteration no. 72686 ==> 0.44581866714321294\n",
            "Loss in iteration no. 72687 ==> 0.445817328785766\n",
            "Loss in iteration no. 72688 ==> 0.44581599044919035\n",
            "Loss in iteration no. 72689 ==> 0.44581465213348553\n",
            "Loss in iteration no. 72690 ==> 0.44581331383865125\n",
            "Loss in iteration no. 72691 ==> 0.44581197556468677\n",
            "Loss in iteration no. 72692 ==> 0.4458106373115919\n",
            "Loss in iteration no. 72693 ==> 0.44580929907936595\n",
            "Loss in iteration no. 72694 ==> 0.44580796086800856\n",
            "Loss in iteration no. 72695 ==> 0.44580662267751936\n",
            "Loss in iteration no. 72696 ==> 0.44580528450789775\n",
            "Loss in iteration no. 72697 ==> 0.4458039463591435\n",
            "Loss in iteration no. 72698 ==> 0.44580260823125595\n",
            "Loss in iteration no. 72699 ==> 0.4458012701242345\n",
            "Loss in iteration no. 72700 ==> 0.4457999320380789\n",
            "Loss in iteration no. 72701 ==> 0.4457985939727887\n",
            "Loss in iteration no. 72702 ==> 0.44579725592836333\n",
            "Loss in iteration no. 72703 ==> 0.4457959179048024\n",
            "Loss in iteration no. 72704 ==> 0.4457945799021055\n",
            "Loss in iteration no. 72705 ==> 0.4457932419202722\n",
            "Loss in iteration no. 72706 ==> 0.44579190395930174\n",
            "Loss in iteration no. 72707 ==> 0.44579056601919403\n",
            "Loss in iteration no. 72708 ==> 0.44578922809994825\n",
            "Loss in iteration no. 72709 ==> 0.4457878902015643\n",
            "Loss in iteration no. 72710 ==> 0.4457865523240415\n",
            "Loss in iteration no. 72711 ==> 0.4457852144673795\n",
            "Loss in iteration no. 72712 ==> 0.44578387663157776\n",
            "Loss in iteration no. 72713 ==> 0.4457825388166358\n",
            "Loss in iteration no. 72714 ==> 0.44578120102255336\n",
            "Loss in iteration no. 72715 ==> 0.4457798632493297\n",
            "Loss in iteration no. 72716 ==> 0.4457785254969645\n",
            "Loss in iteration no. 72717 ==> 0.44577718776545733\n",
            "Loss in iteration no. 72718 ==> 0.4457758500548077\n",
            "Loss in iteration no. 72719 ==> 0.44577451236501503\n",
            "Loss in iteration no. 72720 ==> 0.44577317469607897\n",
            "Loss in iteration no. 72721 ==> 0.4457718370479991\n",
            "Loss in iteration no. 72722 ==> 0.445770499420775\n",
            "Loss in iteration no. 72723 ==> 0.4457691618144061\n",
            "Loss in iteration no. 72724 ==> 0.445767824228892\n",
            "Loss in iteration no. 72725 ==> 0.4457664866642321\n",
            "Loss in iteration no. 72726 ==> 0.4457651491204261\n",
            "Loss in iteration no. 72727 ==> 0.4457638115974734\n",
            "Loss in iteration no. 72728 ==> 0.44576247409537373\n",
            "Loss in iteration no. 72729 ==> 0.44576113661412653\n",
            "Loss in iteration no. 72730 ==> 0.44575979915373143\n",
            "Loss in iteration no. 72731 ==> 0.4457584617141877\n",
            "Loss in iteration no. 72732 ==> 0.4457571242954951\n",
            "Loss in iteration no. 72733 ==> 0.4457557868976531\n",
            "Loss in iteration no. 72734 ==> 0.44575444952066146\n",
            "Loss in iteration no. 72735 ==> 0.4457531121645193\n",
            "Loss in iteration no. 72736 ==> 0.4457517748292266\n",
            "Loss in iteration no. 72737 ==> 0.44575043751478244\n",
            "Loss in iteration no. 72738 ==> 0.4457491002211868\n",
            "Loss in iteration no. 72739 ==> 0.44574776294843904\n",
            "Loss in iteration no. 72740 ==> 0.4457464256965386\n",
            "Loss in iteration no. 72741 ==> 0.44574508846548516\n",
            "Loss in iteration no. 72742 ==> 0.4457437512552782\n",
            "Loss in iteration no. 72743 ==> 0.44574241406591736\n",
            "Loss in iteration no. 72744 ==> 0.4457410768974019\n",
            "Loss in iteration no. 72745 ==> 0.44573973974973163\n",
            "Loss in iteration no. 72746 ==> 0.4457384026229061\n",
            "Loss in iteration no. 72747 ==> 0.4457370655169247\n",
            "Loss in iteration no. 72748 ==> 0.445735728431787\n",
            "Loss in iteration no. 72749 ==> 0.4457343913674927\n",
            "Loss in iteration no. 72750 ==> 0.4457330543240412\n",
            "Loss in iteration no. 72751 ==> 0.44573171730143196\n",
            "Loss in iteration no. 72752 ==> 0.4457303802996646\n",
            "Loss in iteration no. 72753 ==> 0.4457290433187387\n",
            "Loss in iteration no. 72754 ==> 0.4457277063586539\n",
            "Loss in iteration no. 72755 ==> 0.44572636941940946\n",
            "Loss in iteration no. 72756 ==> 0.44572503250100515\n",
            "Loss in iteration no. 72757 ==> 0.4457236956034405\n",
            "Loss in iteration no. 72758 ==> 0.44572235872671484\n",
            "Loss in iteration no. 72759 ==> 0.445721021870828\n",
            "Loss in iteration no. 72760 ==> 0.4457196850357793\n",
            "Loss in iteration no. 72761 ==> 0.4457183482215683\n",
            "Loss in iteration no. 72762 ==> 0.44571701142819475\n",
            "Loss in iteration no. 72763 ==> 0.445715674655658\n",
            "Loss in iteration no. 72764 ==> 0.4457143379039576\n",
            "Loss in iteration no. 72765 ==> 0.44571300117309315\n",
            "Loss in iteration no. 72766 ==> 0.44571166446306415\n",
            "Loss in iteration no. 72767 ==> 0.4457103277738701\n",
            "Loss in iteration no. 72768 ==> 0.44570899110551065\n",
            "Loss in iteration no. 72769 ==> 0.44570765445798527\n",
            "Loss in iteration no. 72770 ==> 0.4457063178312936\n",
            "Loss in iteration no. 72771 ==> 0.4457049812254351\n",
            "Loss in iteration no. 72772 ==> 0.4457036446404092\n",
            "Loss in iteration no. 72773 ==> 0.4457023080762156\n",
            "Loss in iteration no. 72774 ==> 0.4457009715328537\n",
            "Loss in iteration no. 72775 ==> 0.4456996350103233\n",
            "Loss in iteration no. 72776 ==> 0.44569829850862364\n",
            "Loss in iteration no. 72777 ==> 0.44569696202775444\n",
            "Loss in iteration no. 72778 ==> 0.4456956255677152\n",
            "Loss in iteration no. 72779 ==> 0.44569428912850545\n",
            "Loss in iteration no. 72780 ==> 0.4456929527101248\n",
            "Loss in iteration no. 72781 ==> 0.44569161631257265\n",
            "Loss in iteration no. 72782 ==> 0.4456902799358486\n",
            "Loss in iteration no. 72783 ==> 0.4456889435799522\n",
            "Loss in iteration no. 72784 ==> 0.44568760724488304\n",
            "Loss in iteration no. 72785 ==> 0.4456862709306406\n",
            "Loss in iteration no. 72786 ==> 0.44568493463722453\n",
            "Loss in iteration no. 72787 ==> 0.4456835983646341\n",
            "Loss in iteration no. 72788 ==> 0.44568226211286915\n",
            "Loss in iteration no. 72789 ==> 0.44568092588192915\n",
            "Loss in iteration no. 72790 ==> 0.44567958967181354\n",
            "Loss in iteration no. 72791 ==> 0.4456782534825219\n",
            "Loss in iteration no. 72792 ==> 0.44567691731405384\n",
            "Loss in iteration no. 72793 ==> 0.44567558116640876\n",
            "Loss in iteration no. 72794 ==> 0.4456742450395863\n",
            "Loss in iteration no. 72795 ==> 0.4456729089335861\n",
            "Loss in iteration no. 72796 ==> 0.4456715728484075\n",
            "Loss in iteration no. 72797 ==> 0.44567023678405016\n",
            "Loss in iteration no. 72798 ==> 0.4456689007405136\n",
            "Loss in iteration no. 72799 ==> 0.4456675647177973\n",
            "Loss in iteration no. 72800 ==> 0.44566622871590095\n",
            "Loss in iteration no. 72801 ==> 0.44566489273482396\n",
            "Loss in iteration no. 72802 ==> 0.4456635567745658\n",
            "Loss in iteration no. 72803 ==> 0.44566222083512635\n",
            "Loss in iteration no. 72804 ==> 0.44566088491650474\n",
            "Loss in iteration no. 72805 ==> 0.44565954901870075\n",
            "Loss in iteration no. 72806 ==> 0.4456582131417138\n",
            "Loss in iteration no. 72807 ==> 0.4456568772855435\n",
            "Loss in iteration no. 72808 ==> 0.44565554145018943\n",
            "Loss in iteration no. 72809 ==> 0.44565420563565106\n",
            "Loss in iteration no. 72810 ==> 0.44565286984192803\n",
            "Loss in iteration no. 72811 ==> 0.4456515340690197\n",
            "Loss in iteration no. 72812 ==> 0.4456501983169258\n",
            "Loss in iteration no. 72813 ==> 0.44564886258564573\n",
            "Loss in iteration no. 72814 ==> 0.44564752687517917\n",
            "Loss in iteration no. 72815 ==> 0.44564619118552556\n",
            "Loss in iteration no. 72816 ==> 0.4456448555166844\n",
            "Loss in iteration no. 72817 ==> 0.44564351986865536\n",
            "Loss in iteration no. 72818 ==> 0.44564218424143787\n",
            "Loss in iteration no. 72819 ==> 0.44564084863503145\n",
            "Loss in iteration no. 72820 ==> 0.44563951304943583\n",
            "Loss in iteration no. 72821 ==> 0.4456381774846504\n",
            "Loss in iteration no. 72822 ==> 0.4456368419406748\n",
            "Loss in iteration no. 72823 ==> 0.44563550641750843\n",
            "Loss in iteration no. 72824 ==> 0.445634170915151\n",
            "Loss in iteration no. 72825 ==> 0.4456328354336018\n",
            "Loss in iteration no. 72826 ==> 0.4456314999728607\n",
            "Loss in iteration no. 72827 ==> 0.4456301645329269\n",
            "Loss in iteration no. 72828 ==> 0.4456288291138003\n",
            "Loss in iteration no. 72829 ==> 0.44562749371548005\n",
            "Loss in iteration no. 72830 ==> 0.445626158337966\n",
            "Loss in iteration no. 72831 ==> 0.4456248229812576\n",
            "Loss in iteration no. 72832 ==> 0.4456234876453544\n",
            "Loss in iteration no. 72833 ==> 0.4456221523302559\n",
            "Loss in iteration no. 72834 ==> 0.4456208170359616\n",
            "Loss in iteration no. 72835 ==> 0.4456194817624711\n",
            "Loss in iteration no. 72836 ==> 0.44561814650978404\n",
            "Loss in iteration no. 72837 ==> 0.4456168112778998\n",
            "Loss in iteration no. 72838 ==> 0.44561547606681795\n",
            "Loss in iteration no. 72839 ==> 0.44561414087653817\n",
            "Loss in iteration no. 72840 ==> 0.4456128057070599\n",
            "Loss in iteration no. 72841 ==> 0.4456114705583827\n",
            "Loss in iteration no. 72842 ==> 0.445610135430506\n",
            "Loss in iteration no. 72843 ==> 0.4456088003234294\n",
            "Loss in iteration no. 72844 ==> 0.4456074652371526\n",
            "Loss in iteration no. 72845 ==> 0.445606130171675\n",
            "Loss in iteration no. 72846 ==> 0.4456047951269961\n",
            "Loss in iteration no. 72847 ==> 0.4456034601031155\n",
            "Loss in iteration no. 72848 ==> 0.4456021251000328\n",
            "Loss in iteration no. 72849 ==> 0.44560079011774745\n",
            "Loss in iteration no. 72850 ==> 0.445599455156259\n",
            "Loss in iteration no. 72851 ==> 0.4455981202155671\n",
            "Loss in iteration no. 72852 ==> 0.4455967852956711\n",
            "Loss in iteration no. 72853 ==> 0.4455954503965708\n",
            "Loss in iteration no. 72854 ==> 0.44559411551826555\n",
            "Loss in iteration no. 72855 ==> 0.4455927806607549\n",
            "Loss in iteration no. 72856 ==> 0.44559144582403837\n",
            "Loss in iteration no. 72857 ==> 0.4455901110081157\n",
            "Loss in iteration no. 72858 ==> 0.4455887762129861\n",
            "Loss in iteration no. 72859 ==> 0.44558744143864953\n",
            "Loss in iteration no. 72860 ==> 0.44558610668510523\n",
            "Loss in iteration no. 72861 ==> 0.44558477195235274\n",
            "Loss in iteration no. 72862 ==> 0.44558343724039173\n",
            "Loss in iteration no. 72863 ==> 0.44558210254922176\n",
            "Loss in iteration no. 72864 ==> 0.4455807678788422\n",
            "Loss in iteration no. 72865 ==> 0.44557943322925275\n",
            "Loss in iteration no. 72866 ==> 0.4455780986004529\n",
            "Loss in iteration no. 72867 ==> 0.44557676399244217\n",
            "Loss in iteration no. 72868 ==> 0.44557542940522005\n",
            "Loss in iteration no. 72869 ==> 0.4455740948387863\n",
            "Loss in iteration no. 72870 ==> 0.4455727602931403\n",
            "Loss in iteration no. 72871 ==> 0.44557142576828157\n",
            "Loss in iteration no. 72872 ==> 0.44557009126420966\n",
            "Loss in iteration no. 72873 ==> 0.44556875678092417\n",
            "Loss in iteration no. 72874 ==> 0.4455674223184246\n",
            "Loss in iteration no. 72875 ==> 0.44556608787671054\n",
            "Loss in iteration no. 72876 ==> 0.4455647534557814\n",
            "Loss in iteration no. 72877 ==> 0.4455634190556369\n",
            "Loss in iteration no. 72878 ==> 0.4455620846762765\n",
            "Loss in iteration no. 72879 ==> 0.4455607503176998\n",
            "Loss in iteration no. 72880 ==> 0.4455594159799062\n",
            "Loss in iteration no. 72881 ==> 0.44555808166289546\n",
            "Loss in iteration no. 72882 ==> 0.4455567473666669\n",
            "Loss in iteration no. 72883 ==> 0.44555541309122015\n",
            "Loss in iteration no. 72884 ==> 0.44555407883655473\n",
            "Loss in iteration no. 72885 ==> 0.44555274460267025\n",
            "Loss in iteration no. 72886 ==> 0.4455514103895662\n",
            "Loss in iteration no. 72887 ==> 0.4455500761972422\n",
            "Loss in iteration no. 72888 ==> 0.44554874202569755\n",
            "Loss in iteration no. 72889 ==> 0.4455474078749322\n",
            "Loss in iteration no. 72890 ==> 0.4455460737449453\n",
            "Loss in iteration no. 72891 ==> 0.4455447396357366\n",
            "Loss in iteration no. 72892 ==> 0.44554340554730565\n",
            "Loss in iteration no. 72893 ==> 0.44554207147965186\n",
            "Loss in iteration no. 72894 ==> 0.4455407374327749\n",
            "Loss in iteration no. 72895 ==> 0.4455394034066742\n",
            "Loss in iteration no. 72896 ==> 0.4455380694013494\n",
            "Loss in iteration no. 72897 ==> 0.4455367354168\n",
            "Loss in iteration no. 72898 ==> 0.44553540145302556\n",
            "Loss in iteration no. 72899 ==> 0.44553406751002567\n",
            "Loss in iteration no. 72900 ==> 0.4455327335877997\n",
            "Loss in iteration no. 72901 ==> 0.44553139968634736\n",
            "Loss in iteration no. 72902 ==> 0.4455300658056681\n",
            "Loss in iteration no. 72903 ==> 0.44552873194576165\n",
            "Loss in iteration no. 72904 ==> 0.4455273981066272\n",
            "Loss in iteration no. 72905 ==> 0.4455260642882647\n",
            "Loss in iteration no. 72906 ==> 0.4455247304906733\n",
            "Loss in iteration no. 72907 ==> 0.4455233967138529\n",
            "Loss in iteration no. 72908 ==> 0.44552206295780283\n",
            "Loss in iteration no. 72909 ==> 0.4455207292225225\n",
            "Loss in iteration no. 72910 ==> 0.44551939550801184\n",
            "Loss in iteration no. 72911 ==> 0.44551806181427017\n",
            "Loss in iteration no. 72912 ==> 0.445516728141297\n",
            "Loss in iteration no. 72913 ==> 0.44551539448909183\n",
            "Loss in iteration no. 72914 ==> 0.4455140608576543\n",
            "Loss in iteration no. 72915 ==> 0.4455127272469841\n",
            "Loss in iteration no. 72916 ==> 0.4455113936570806\n",
            "Loss in iteration no. 72917 ==> 0.44551006008794325\n",
            "Loss in iteration no. 72918 ==> 0.4455087265395717\n",
            "Loss in iteration no. 72919 ==> 0.44550739301196557\n",
            "Loss in iteration no. 72920 ==> 0.44550605950512423\n",
            "Loss in iteration no. 72921 ==> 0.4455047260190474\n",
            "Loss in iteration no. 72922 ==> 0.4455033925537345\n",
            "Loss in iteration no. 72923 ==> 0.44550205910918517\n",
            "Loss in iteration no. 72924 ==> 0.44550072568539895\n",
            "Loss in iteration no. 72925 ==> 0.4454993922823752\n",
            "Loss in iteration no. 72926 ==> 0.4454980589001136\n",
            "Loss in iteration no. 72927 ==> 0.44549672553861375\n",
            "Loss in iteration no. 72928 ==> 0.4454953921978751\n",
            "Loss in iteration no. 72929 ==> 0.4454940588778972\n",
            "Loss in iteration no. 72930 ==> 0.44549272557867975\n",
            "Loss in iteration no. 72931 ==> 0.44549139230022194\n",
            "Loss in iteration no. 72932 ==> 0.44549005904252365\n",
            "Loss in iteration no. 72933 ==> 0.44548872580558435\n",
            "Loss in iteration no. 72934 ==> 0.44548739258940345\n",
            "Loss in iteration no. 72935 ==> 0.44548605939398067\n",
            "Loss in iteration no. 72936 ==> 0.44548472621931534\n",
            "Loss in iteration no. 72937 ==> 0.44548339306540724\n",
            "Loss in iteration no. 72938 ==> 0.44548205993225576\n",
            "Loss in iteration no. 72939 ==> 0.4454807268198605\n",
            "Loss in iteration no. 72940 ==> 0.4454793937282208\n",
            "Loss in iteration no. 72941 ==> 0.4454780606573366\n",
            "Loss in iteration no. 72942 ==> 0.4454767276072072\n",
            "Loss in iteration no. 72943 ==> 0.4454753945778321\n",
            "Loss in iteration no. 72944 ==> 0.44547406156921104\n",
            "Loss in iteration no. 72945 ==> 0.4454727285813433\n",
            "Loss in iteration no. 72946 ==> 0.4454713956142286\n",
            "Loss in iteration no. 72947 ==> 0.44547006266786643\n",
            "Loss in iteration no. 72948 ==> 0.4454687297422565\n",
            "Loss in iteration no. 72949 ==> 0.44546739683739806\n",
            "Loss in iteration no. 72950 ==> 0.44546606395329075\n",
            "Loss in iteration no. 72951 ==> 0.44546473108993434\n",
            "Loss in iteration no. 72952 ==> 0.445463398247328\n",
            "Loss in iteration no. 72953 ==> 0.4454620654254715\n",
            "Loss in iteration no. 72954 ==> 0.4454607326243644\n",
            "Loss in iteration no. 72955 ==> 0.4454593998440062\n",
            "Loss in iteration no. 72956 ==> 0.44545806708439645\n",
            "Loss in iteration no. 72957 ==> 0.44545673434553457\n",
            "Loss in iteration no. 72958 ==> 0.4454554016274203\n",
            "Loss in iteration no. 72959 ==> 0.4454540689300531\n",
            "Loss in iteration no. 72960 ==> 0.4454527362534326\n",
            "Loss in iteration no. 72961 ==> 0.44545140359755797\n",
            "Loss in iteration no. 72962 ==> 0.4454500709624293\n",
            "Loss in iteration no. 72963 ==> 0.4454487383480457\n",
            "Loss in iteration no. 72964 ==> 0.44544740575440694\n",
            "Loss in iteration no. 72965 ==> 0.4454460731815126\n",
            "Loss in iteration no. 72966 ==> 0.44544474062936196\n",
            "Loss in iteration no. 72967 ==> 0.4454434080979548\n",
            "Loss in iteration no. 72968 ==> 0.4454420755872906\n",
            "Loss in iteration no. 72969 ==> 0.4454407430973688\n",
            "Loss in iteration no. 72970 ==> 0.4454394106281892\n",
            "Loss in iteration no. 72971 ==> 0.4454380781797511\n",
            "Loss in iteration no. 72972 ==> 0.44543674575205416\n",
            "Loss in iteration no. 72973 ==> 0.44543541334509784\n",
            "Loss in iteration no. 72974 ==> 0.44543408095888176\n",
            "Loss in iteration no. 72975 ==> 0.4454327485934055\n",
            "Loss in iteration no. 72976 ==> 0.4454314162486685\n",
            "Loss in iteration no. 72977 ==> 0.4454300839246702\n",
            "Loss in iteration no. 72978 ==> 0.4454287516214105\n",
            "Loss in iteration no. 72979 ==> 0.4454274193388886\n",
            "Loss in iteration no. 72980 ==> 0.44542608707710424\n",
            "Loss in iteration no. 72981 ==> 0.44542475483605687\n",
            "Loss in iteration no. 72982 ==> 0.4454234226157461\n",
            "Loss in iteration no. 72983 ==> 0.4454220904161714\n",
            "Loss in iteration no. 72984 ==> 0.44542075823733235\n",
            "Loss in iteration no. 72985 ==> 0.4454194260792285\n",
            "Loss in iteration no. 72986 ==> 0.4454180939418594\n",
            "Loss in iteration no. 72987 ==> 0.4454167618252245\n",
            "Loss in iteration no. 72988 ==> 0.4454154297293236\n",
            "Loss in iteration no. 72989 ==> 0.4454140976541559\n",
            "Loss in iteration no. 72990 ==> 0.44541276559972115\n",
            "Loss in iteration no. 72991 ==> 0.4454114335660188\n",
            "Loss in iteration no. 72992 ==> 0.44541010155304855\n",
            "Loss in iteration no. 72993 ==> 0.44540876956080977\n",
            "Loss in iteration no. 72994 ==> 0.4454074375893021\n",
            "Loss in iteration no. 72995 ==> 0.44540610563852523\n",
            "Loss in iteration no. 72996 ==> 0.44540477370847825\n",
            "Loss in iteration no. 72997 ==> 0.44540344179916125\n",
            "Loss in iteration no. 72998 ==> 0.44540210991057333\n",
            "Loss in iteration no. 72999 ==> 0.4454007780427142\n",
            "Loss in iteration no. 73000 ==> 0.44539944619558347\n",
            "Loss in iteration no. 73001 ==> 0.44539811436918064\n",
            "Loss in iteration no. 73002 ==> 0.44539678256350523\n",
            "Loss in iteration no. 73003 ==> 0.44539545077855686\n",
            "Loss in iteration no. 73004 ==> 0.4453941190143349\n",
            "Loss in iteration no. 73005 ==> 0.4453927872708391\n",
            "Loss in iteration no. 73006 ==> 0.4453914555480688\n",
            "Loss in iteration no. 73007 ==> 0.44539012384602383\n",
            "Loss in iteration no. 73008 ==> 0.44538879216470345\n",
            "Loss in iteration no. 73009 ==> 0.4453874605041073\n",
            "Loss in iteration no. 73010 ==> 0.44538612886423495\n",
            "Loss in iteration no. 73011 ==> 0.44538479724508595\n",
            "Loss in iteration no. 73012 ==> 0.4453834656466598\n",
            "Loss in iteration no. 73013 ==> 0.4453821340689561\n",
            "Loss in iteration no. 73014 ==> 0.44538080251197437\n",
            "Loss in iteration no. 73015 ==> 0.4453794709757141\n",
            "Loss in iteration no. 73016 ==> 0.44537813946017496\n",
            "Loss in iteration no. 73017 ==> 0.4453768079653563\n",
            "Loss in iteration no. 73018 ==> 0.44537547649125786\n",
            "Loss in iteration no. 73019 ==> 0.44537414503787903\n",
            "Loss in iteration no. 73020 ==> 0.4453728136052195\n",
            "Loss in iteration no. 73021 ==> 0.4453714821932787\n",
            "Loss in iteration no. 73022 ==> 0.4453701508020563\n",
            "Loss in iteration no. 73023 ==> 0.4453688194315516\n",
            "Loss in iteration no. 73024 ==> 0.4453674880817644\n",
            "Loss in iteration no. 73025 ==> 0.44536615675269414\n",
            "Loss in iteration no. 73026 ==> 0.44536482544434036\n",
            "Loss in iteration no. 73027 ==> 0.4453634941567026\n",
            "Loss in iteration no. 73028 ==> 0.4453621628897805\n",
            "Loss in iteration no. 73029 ==> 0.4453608316435735\n",
            "Loss in iteration no. 73030 ==> 0.44535950041808103\n",
            "Loss in iteration no. 73031 ==> 0.44535816921330296\n",
            "Loss in iteration no. 73032 ==> 0.44535683802923853\n",
            "Loss in iteration no. 73033 ==> 0.4453555068658875\n",
            "Loss in iteration no. 73034 ==> 0.4453541757232492\n",
            "Loss in iteration no. 73035 ==> 0.4453528446013233\n",
            "Loss in iteration no. 73036 ==> 0.4453515135001093\n",
            "Loss in iteration no. 73037 ==> 0.44535018241960694\n",
            "Loss in iteration no. 73038 ==> 0.4453488513598155\n",
            "Loss in iteration no. 73039 ==> 0.4453475203207346\n",
            "Loss in iteration no. 73040 ==> 0.4453461893023638\n",
            "Loss in iteration no. 73041 ==> 0.44534485830470283\n",
            "Loss in iteration no. 73042 ==> 0.4453435273277509\n",
            "Loss in iteration no. 73043 ==> 0.4453421963715078\n",
            "Loss in iteration no. 73044 ==> 0.44534086543597284\n",
            "Loss in iteration no. 73045 ==> 0.4453395345211458\n",
            "Loss in iteration no. 73046 ==> 0.44533820362702614\n",
            "Loss in iteration no. 73047 ==> 0.4453368727536134\n",
            "Loss in iteration no. 73048 ==> 0.44533554190090713\n",
            "Loss in iteration no. 73049 ==> 0.44533421106890686\n",
            "Loss in iteration no. 73050 ==> 0.44533288025761214\n",
            "Loss in iteration no. 73051 ==> 0.4453315494670225\n",
            "Loss in iteration no. 73052 ==> 0.44533021869713757\n",
            "Loss in iteration no. 73053 ==> 0.4453288879479568\n",
            "Loss in iteration no. 73054 ==> 0.4453275572194798\n",
            "Loss in iteration no. 73055 ==> 0.445326226511706\n",
            "Loss in iteration no. 73056 ==> 0.4453248958246349\n",
            "Loss in iteration no. 73057 ==> 0.44532356515826643\n",
            "Loss in iteration no. 73058 ==> 0.44532223451259967\n",
            "Loss in iteration no. 73059 ==> 0.44532090388763446\n",
            "Loss in iteration no. 73060 ==> 0.44531957328337024\n",
            "Loss in iteration no. 73061 ==> 0.4453182426998066\n",
            "Loss in iteration no. 73062 ==> 0.44531691213694297\n",
            "Loss in iteration no. 73063 ==> 0.44531558159477896\n",
            "Loss in iteration no. 73064 ==> 0.44531425107331424\n",
            "Loss in iteration no. 73065 ==> 0.4453129205725482\n",
            "Loss in iteration no. 73066 ==> 0.4453115900924804\n",
            "Loss in iteration no. 73067 ==> 0.44531025963311033\n",
            "Loss in iteration no. 73068 ==> 0.4453089291944377\n",
            "Loss in iteration no. 73069 ==> 0.44530759877646203\n",
            "Loss in iteration no. 73070 ==> 0.44530626837918275\n",
            "Loss in iteration no. 73071 ==> 0.44530493800259935\n",
            "Loss in iteration no. 73072 ==> 0.4453036076467117\n",
            "Loss in iteration no. 73073 ==> 0.44530227731151906\n",
            "Loss in iteration no. 73074 ==> 0.4453009469970209\n",
            "Loss in iteration no. 73075 ==> 0.4452996167032171\n",
            "Loss in iteration no. 73076 ==> 0.4452982864301069\n",
            "Loss in iteration no. 73077 ==> 0.44529695617769005\n",
            "Loss in iteration no. 73078 ==> 0.44529562594596594\n",
            "Loss in iteration no. 73079 ==> 0.4452942957349342\n",
            "Loss in iteration no. 73080 ==> 0.44529296554459435\n",
            "Loss in iteration no. 73081 ==> 0.4452916353749459\n",
            "Loss in iteration no. 73082 ==> 0.44529030522598845\n",
            "Loss in iteration no. 73083 ==> 0.44528897509772153\n",
            "Loss in iteration no. 73084 ==> 0.44528764499014467\n",
            "Loss in iteration no. 73085 ==> 0.4452863149032575\n",
            "Loss in iteration no. 73086 ==> 0.4452849848370594\n",
            "Loss in iteration no. 73087 ==> 0.4452836547915501\n",
            "Loss in iteration no. 73088 ==> 0.44528232476672897\n",
            "Loss in iteration no. 73089 ==> 0.44528099476259575\n",
            "Loss in iteration no. 73090 ==> 0.44527966477914976\n",
            "Loss in iteration no. 73091 ==> 0.44527833481639073\n",
            "Loss in iteration no. 73092 ==> 0.4452770048743181\n",
            "Loss in iteration no. 73093 ==> 0.44527567495293147\n",
            "Loss in iteration no. 73094 ==> 0.4452743450522303\n",
            "Loss in iteration no. 73095 ==> 0.4452730151722143\n",
            "Loss in iteration no. 73096 ==> 0.44527168531288275\n",
            "Loss in iteration no. 73097 ==> 0.44527035547423544\n",
            "Loss in iteration no. 73098 ==> 0.4452690256562719\n",
            "Loss in iteration no. 73099 ==> 0.4452676958589916\n",
            "Loss in iteration no. 73100 ==> 0.445266366082394\n",
            "Loss in iteration no. 73101 ==> 0.4452650363264788\n",
            "Loss in iteration no. 73102 ==> 0.44526370659124553\n",
            "Loss in iteration no. 73103 ==> 0.4452623768766936\n",
            "Loss in iteration no. 73104 ==> 0.44526104718282267\n",
            "Loss in iteration no. 73105 ==> 0.4452597175096323\n",
            "Loss in iteration no. 73106 ==> 0.44525838785712196\n",
            "Loss in iteration no. 73107 ==> 0.4452570582252912\n",
            "Loss in iteration no. 73108 ==> 0.4452557286141396\n",
            "Loss in iteration no. 73109 ==> 0.4452543990236667\n",
            "Loss in iteration no. 73110 ==> 0.4452530694538721\n",
            "Loss in iteration no. 73111 ==> 0.4452517399047553\n",
            "Loss in iteration no. 73112 ==> 0.4452504103763158\n",
            "Loss in iteration no. 73113 ==> 0.4452490808685532\n",
            "Loss in iteration no. 73114 ==> 0.44524775138146705\n",
            "Loss in iteration no. 73115 ==> 0.44524642191505676\n",
            "Loss in iteration no. 73116 ==> 0.4452450924693221\n",
            "Loss in iteration no. 73117 ==> 0.44524376304426244\n",
            "Loss in iteration no. 73118 ==> 0.4452424336398775\n",
            "Loss in iteration no. 73119 ==> 0.44524110425616653\n",
            "Loss in iteration no. 73120 ==> 0.4452397748931294\n",
            "Loss in iteration no. 73121 ==> 0.4452384455507654\n",
            "Loss in iteration no. 73122 ==> 0.4452371162290743\n",
            "Loss in iteration no. 73123 ==> 0.4452357869280553\n",
            "Loss in iteration no. 73124 ==> 0.44523445764770847\n",
            "Loss in iteration no. 73125 ==> 0.445233128388033\n",
            "Loss in iteration no. 73126 ==> 0.44523179914902855\n",
            "Loss in iteration no. 73127 ==> 0.44523046993069443\n",
            "Loss in iteration no. 73128 ==> 0.44522914073303055\n",
            "Loss in iteration no. 73129 ==> 0.44522781155603613\n",
            "Loss in iteration no. 73130 ==> 0.44522648239971097\n",
            "Loss in iteration no. 73131 ==> 0.44522515326405443\n",
            "Loss in iteration no. 73132 ==> 0.4452238241490662\n",
            "Loss in iteration no. 73133 ==> 0.44522249505474576\n",
            "Loss in iteration no. 73134 ==> 0.44522116598109257\n",
            "Loss in iteration no. 73135 ==> 0.44521983692810635\n",
            "Loss in iteration no. 73136 ==> 0.44521850789578654\n",
            "Loss in iteration no. 73137 ==> 0.44521717888413265\n",
            "Loss in iteration no. 73138 ==> 0.44521584989314433\n",
            "Loss in iteration no. 73139 ==> 0.44521452092282116\n",
            "Loss in iteration no. 73140 ==> 0.4452131919731624\n",
            "Loss in iteration no. 73141 ==> 0.4452118630441679\n",
            "Loss in iteration no. 73142 ==> 0.4452105341358371\n",
            "Loss in iteration no. 73143 ==> 0.44520920524816954\n",
            "Loss in iteration no. 73144 ==> 0.4452078763811647\n",
            "Loss in iteration no. 73145 ==> 0.44520654753482236\n",
            "Loss in iteration no. 73146 ==> 0.44520521870914176\n",
            "Loss in iteration no. 73147 ==> 0.44520388990412263\n",
            "Loss in iteration no. 73148 ==> 0.44520256111976453\n",
            "Loss in iteration no. 73149 ==> 0.4452012323560669\n",
            "Loss in iteration no. 73150 ==> 0.4451999036130293\n",
            "Loss in iteration no. 73151 ==> 0.4451985748906514\n",
            "Loss in iteration no. 73152 ==> 0.44519724618893264\n",
            "Loss in iteration no. 73153 ==> 0.4451959175078726\n",
            "Loss in iteration no. 73154 ==> 0.4451945888474707\n",
            "Loss in iteration no. 73155 ==> 0.44519326020772654\n",
            "Loss in iteration no. 73156 ==> 0.44519193158863996\n",
            "Loss in iteration no. 73157 ==> 0.4451906029902101\n",
            "Loss in iteration no. 73158 ==> 0.4451892744124367\n",
            "Loss in iteration no. 73159 ==> 0.44518794585531934\n",
            "Loss in iteration no. 73160 ==> 0.44518661731885745\n",
            "Loss in iteration no. 73161 ==> 0.4451852888030507\n",
            "Loss in iteration no. 73162 ==> 0.4451839603078985\n",
            "Loss in iteration no. 73163 ==> 0.4451826318334004\n",
            "Loss in iteration no. 73164 ==> 0.44518130337955614\n",
            "Loss in iteration no. 73165 ==> 0.445179974946365\n",
            "Loss in iteration no. 73166 ==> 0.44517864653382677\n",
            "Loss in iteration no. 73167 ==> 0.44517731814194084\n",
            "Loss in iteration no. 73168 ==> 0.4451759897707069\n",
            "Loss in iteration no. 73169 ==> 0.44517466142012424\n",
            "Loss in iteration no. 73170 ==> 0.4451733330901926\n",
            "Loss in iteration no. 73171 ==> 0.44517200478091146\n",
            "Loss in iteration no. 73172 ==> 0.44517067649228065\n",
            "Loss in iteration no. 73173 ==> 0.44516934822429916\n",
            "Loss in iteration no. 73174 ==> 0.445168019976967\n",
            "Loss in iteration no. 73175 ==> 0.4451666917502835\n",
            "Loss in iteration no. 73176 ==> 0.44516536354424824\n",
            "Loss in iteration no. 73177 ==> 0.4451640353588609\n",
            "Loss in iteration no. 73178 ==> 0.4451627071941207\n",
            "Loss in iteration no. 73179 ==> 0.44516137905002756\n",
            "Loss in iteration no. 73180 ==> 0.44516005092658084\n",
            "Loss in iteration no. 73181 ==> 0.4451587228237801\n",
            "Loss in iteration no. 73182 ==> 0.4451573947416249\n",
            "Loss in iteration no. 73183 ==> 0.44515606668011476\n",
            "Loss in iteration no. 73184 ==> 0.44515473863924926\n",
            "Loss in iteration no. 73185 ==> 0.44515341061902797\n",
            "Loss in iteration no. 73186 ==> 0.44515208261945033\n",
            "Loss in iteration no. 73187 ==> 0.44515075464051607\n",
            "Loss in iteration no. 73188 ==> 0.44514942668222457\n",
            "Loss in iteration no. 73189 ==> 0.44514809874457545\n",
            "Loss in iteration no. 73190 ==> 0.4451467708275682\n",
            "Loss in iteration no. 73191 ==> 0.4451454429312024\n",
            "Loss in iteration no. 73192 ==> 0.44514411505547763\n",
            "Loss in iteration no. 73193 ==> 0.4451427872003934\n",
            "Loss in iteration no. 73194 ==> 0.4451414593659493\n",
            "Loss in iteration no. 73195 ==> 0.44514013155214477\n",
            "Loss in iteration no. 73196 ==> 0.44513880375897946\n",
            "Loss in iteration no. 73197 ==> 0.44513747598645287\n",
            "Loss in iteration no. 73198 ==> 0.44513614823456454\n",
            "Loss in iteration no. 73199 ==> 0.44513482050331404\n",
            "Loss in iteration no. 73200 ==> 0.4451334927927009\n",
            "Loss in iteration no. 73201 ==> 0.44513216510272485\n",
            "Loss in iteration no. 73202 ==> 0.4451308374333851\n",
            "Loss in iteration no. 73203 ==> 0.44512950978468135\n",
            "Loss in iteration no. 73204 ==> 0.44512818215661315\n",
            "Loss in iteration no. 73205 ==> 0.44512685454918016\n",
            "Loss in iteration no. 73206 ==> 0.44512552696238167\n",
            "Loss in iteration no. 73207 ==> 0.44512419939621745\n",
            "Loss in iteration no. 73208 ==> 0.445122871850687\n",
            "Loss in iteration no. 73209 ==> 0.4451215443257899\n",
            "Loss in iteration no. 73210 ==> 0.4451202168215255\n",
            "Loss in iteration no. 73211 ==> 0.44511888933789356\n",
            "Loss in iteration no. 73212 ==> 0.4451175618748936\n",
            "Loss in iteration no. 73213 ==> 0.445116234432525\n",
            "Loss in iteration no. 73214 ==> 0.4451149070107875\n",
            "Loss in iteration no. 73215 ==> 0.4451135796096805\n",
            "Loss in iteration no. 73216 ==> 0.4451122522292037\n",
            "Loss in iteration no. 73217 ==> 0.44511092486935644\n",
            "Loss in iteration no. 73218 ==> 0.44510959753013846\n",
            "Loss in iteration no. 73219 ==> 0.4451082702115493\n",
            "Loss in iteration no. 73220 ==> 0.4451069429135884\n",
            "Loss in iteration no. 73221 ==> 0.44510561563625534\n",
            "Loss in iteration no. 73222 ==> 0.4451042883795497\n",
            "Loss in iteration no. 73223 ==> 0.445102961143471\n",
            "Loss in iteration no. 73224 ==> 0.44510163392801877\n",
            "Loss in iteration no. 73225 ==> 0.44510030673319256\n",
            "Loss in iteration no. 73226 ==> 0.4450989795589919\n",
            "Loss in iteration no. 73227 ==> 0.44509765240541643\n",
            "Loss in iteration no. 73228 ==> 0.4450963252724656\n",
            "Loss in iteration no. 73229 ==> 0.4450949981601391\n",
            "Loss in iteration no. 73230 ==> 0.44509367106843634\n",
            "Loss in iteration no. 73231 ==> 0.4450923439973567\n",
            "Loss in iteration no. 73232 ==> 0.44509101694690023\n",
            "Loss in iteration no. 73233 ==> 0.445089689917066\n",
            "Loss in iteration no. 73234 ==> 0.44508836290785364\n",
            "Loss in iteration no. 73235 ==> 0.44508703591926296\n",
            "Loss in iteration no. 73236 ==> 0.4450857089512932\n",
            "Loss in iteration no. 73237 ==> 0.4450843820039441\n",
            "Loss in iteration no. 73238 ==> 0.44508305507721513\n",
            "Loss in iteration no. 73239 ==> 0.4450817281711058\n",
            "Loss in iteration no. 73240 ==> 0.4450804012856158\n",
            "Loss in iteration no. 73241 ==> 0.4450790744207447\n",
            "Loss in iteration no. 73242 ==> 0.44507774757649177\n",
            "Loss in iteration no. 73243 ==> 0.4450764207528567\n",
            "Loss in iteration no. 73244 ==> 0.44507509394983913\n",
            "Loss in iteration no. 73245 ==> 0.4450737671674385\n",
            "Loss in iteration no. 73246 ==> 0.4450724404056544\n",
            "Loss in iteration no. 73247 ==> 0.44507111366448643\n",
            "Loss in iteration no. 73248 ==> 0.4450697869439339\n",
            "Loss in iteration no. 73249 ==> 0.4450684602439967\n",
            "Loss in iteration no. 73250 ==> 0.44506713356467414\n",
            "Loss in iteration no. 73251 ==> 0.4450658069059659\n",
            "Loss in iteration no. 73252 ==> 0.44506448026787143\n",
            "Loss in iteration no. 73253 ==> 0.44506315365039034\n",
            "Loss in iteration no. 73254 ==> 0.44506182705352204\n",
            "Loss in iteration no. 73255 ==> 0.44506050047726625\n",
            "Loss in iteration no. 73256 ==> 0.4450591739216225\n",
            "Loss in iteration no. 73257 ==> 0.4450578473865902\n",
            "Loss in iteration no. 73258 ==> 0.4450565208721691\n",
            "Loss in iteration no. 73259 ==> 0.44505519437835855\n",
            "Loss in iteration no. 73260 ==> 0.44505386790515816\n",
            "Loss in iteration no. 73261 ==> 0.4450525414525675\n",
            "Loss in iteration no. 73262 ==> 0.4450512150205862\n",
            "Loss in iteration no. 73263 ==> 0.4450498886092137\n",
            "Loss in iteration no. 73264 ==> 0.4450485622184495\n",
            "Loss in iteration no. 73265 ==> 0.4450472358482933\n",
            "Loss in iteration no. 73266 ==> 0.44504590949874456\n",
            "Loss in iteration no. 73267 ==> 0.4450445831698028\n",
            "Loss in iteration no. 73268 ==> 0.44504325686146756\n",
            "Loss in iteration no. 73269 ==> 0.4450419305737385\n",
            "Loss in iteration no. 73270 ==> 0.445040604306615\n",
            "Loss in iteration no. 73271 ==> 0.44503927806009685\n",
            "Loss in iteration no. 73272 ==> 0.4450379518341833\n",
            "Loss in iteration no. 73273 ==> 0.44503662562887425\n",
            "Loss in iteration no. 73274 ==> 0.4450352994441688\n",
            "Loss in iteration no. 73275 ==> 0.44503397328006683\n",
            "Loss in iteration no. 73276 ==> 0.4450326471365678\n",
            "Loss in iteration no. 73277 ==> 0.4450313210136714\n",
            "Loss in iteration no. 73278 ==> 0.44502999491137685\n",
            "Loss in iteration no. 73279 ==> 0.4450286688296839\n",
            "Loss in iteration no. 73280 ==> 0.4450273427685922\n",
            "Loss in iteration no. 73281 ==> 0.445026016728101\n",
            "Loss in iteration no. 73282 ==> 0.44502469070821016\n",
            "Loss in iteration no. 73283 ==> 0.44502336470891907\n",
            "Loss in iteration no. 73284 ==> 0.4450220387302272\n",
            "Loss in iteration no. 73285 ==> 0.4450207127721343\n",
            "Loss in iteration no. 73286 ==> 0.4450193868346398\n",
            "Loss in iteration no. 73287 ==> 0.44501806091774326\n",
            "Loss in iteration no. 73288 ==> 0.4450167350214442\n",
            "Loss in iteration no. 73289 ==> 0.44501540914574217\n",
            "Loss in iteration no. 73290 ==> 0.4450140832906369\n",
            "Loss in iteration no. 73291 ==> 0.4450127574561276\n",
            "Loss in iteration no. 73292 ==> 0.4450114316422141\n",
            "Loss in iteration no. 73293 ==> 0.44501010584889583\n",
            "Loss in iteration no. 73294 ==> 0.4450087800761723\n",
            "Loss in iteration no. 73295 ==> 0.44500745432404315\n",
            "Loss in iteration no. 73296 ==> 0.4450061285925079\n",
            "Loss in iteration no. 73297 ==> 0.4450048028815661\n",
            "Loss in iteration no. 73298 ==> 0.44500347719121724\n",
            "Loss in iteration no. 73299 ==> 0.44500215152146094\n",
            "Loss in iteration no. 73300 ==> 0.4450008258722968\n",
            "Loss in iteration no. 73301 ==> 0.4449995002437242\n",
            "Loss in iteration no. 73302 ==> 0.44499817463574276\n",
            "Loss in iteration no. 73303 ==> 0.44499684904835207\n",
            "Loss in iteration no. 73304 ==> 0.4449955234815517\n",
            "Loss in iteration no. 73305 ==> 0.4449941979353412\n",
            "Loss in iteration no. 73306 ==> 0.44499287240971985\n",
            "Loss in iteration no. 73307 ==> 0.44499154690468756\n",
            "Loss in iteration no. 73308 ==> 0.44499022142024364\n",
            "Loss in iteration no. 73309 ==> 0.44498889595638785\n",
            "Loss in iteration no. 73310 ==> 0.4449875705131195\n",
            "Loss in iteration no. 73311 ==> 0.4449862450904384\n",
            "Loss in iteration no. 73312 ==> 0.4449849196883439\n",
            "Loss in iteration no. 73313 ==> 0.4449835943068356\n",
            "Loss in iteration no. 73314 ==> 0.44498226894591303\n",
            "Loss in iteration no. 73315 ==> 0.4449809436055758\n",
            "Loss in iteration no. 73316 ==> 0.44497961828582333\n",
            "Loss in iteration no. 73317 ==> 0.44497829298665537\n",
            "Loss in iteration no. 73318 ==> 0.44497696770807127\n",
            "Loss in iteration no. 73319 ==> 0.4449756424500707\n",
            "Loss in iteration no. 73320 ==> 0.4449743172126531\n",
            "Loss in iteration no. 73321 ==> 0.4449729919958182\n",
            "Loss in iteration no. 73322 ==> 0.44497166679956535\n",
            "Loss in iteration no. 73323 ==> 0.44497034162389426\n",
            "Loss in iteration no. 73324 ==> 0.4449690164688043\n",
            "Loss in iteration no. 73325 ==> 0.4449676913342952\n",
            "Loss in iteration no. 73326 ==> 0.4449663662203664\n",
            "Loss in iteration no. 73327 ==> 0.4449650411270174\n",
            "Loss in iteration no. 73328 ==> 0.44496371605424795\n",
            "Loss in iteration no. 73329 ==> 0.4449623910020574\n",
            "Loss in iteration no. 73330 ==> 0.44496106597044544\n",
            "Loss in iteration no. 73331 ==> 0.44495974095941143\n",
            "Loss in iteration no. 73332 ==> 0.44495841596895513\n",
            "Loss in iteration no. 73333 ==> 0.44495709099907604\n",
            "Loss in iteration no. 73334 ==> 0.44495576604977355\n",
            "Loss in iteration no. 73335 ==> 0.44495444112104743\n",
            "Loss in iteration no. 73336 ==> 0.444953116212897\n",
            "Loss in iteration no. 73337 ==> 0.4449517913253219\n",
            "Loss in iteration no. 73338 ==> 0.4449504664583218\n",
            "Loss in iteration no. 73339 ==> 0.44494914161189614\n",
            "Loss in iteration no. 73340 ==> 0.44494781678604445\n",
            "Loss in iteration no. 73341 ==> 0.4449464919807664\n",
            "Loss in iteration no. 73342 ==> 0.4449451671960613\n",
            "Loss in iteration no. 73343 ==> 0.44494384243192886\n",
            "Loss in iteration no. 73344 ==> 0.44494251768836884\n",
            "Loss in iteration no. 73345 ==> 0.4449411929653804\n",
            "Loss in iteration no. 73346 ==> 0.4449398682629632\n",
            "Loss in iteration no. 73347 ==> 0.4449385435811169\n",
            "Loss in iteration no. 73348 ==> 0.44493721891984095\n",
            "Loss in iteration no. 73349 ==> 0.44493589427913505\n",
            "Loss in iteration no. 73350 ==> 0.44493456965899847\n",
            "Loss in iteration no. 73351 ==> 0.44493324505943116\n",
            "Loss in iteration no. 73352 ==> 0.44493192048043223\n",
            "Loss in iteration no. 73353 ==> 0.4449305959220015\n",
            "Loss in iteration no. 73354 ==> 0.44492927138413835\n",
            "Loss in iteration no. 73355 ==> 0.44492794686684267\n",
            "Loss in iteration no. 73356 ==> 0.4449266223701135\n",
            "Loss in iteration no. 73357 ==> 0.4449252978939508\n",
            "Loss in iteration no. 73358 ==> 0.44492397343835394\n",
            "Loss in iteration no. 73359 ==> 0.4449226490033225\n",
            "Loss in iteration no. 73360 ==> 0.444921324588856\n",
            "Loss in iteration no. 73361 ==> 0.44492000019495404\n",
            "Loss in iteration no. 73362 ==> 0.4449186758216162\n",
            "Loss in iteration no. 73363 ==> 0.4449173514688419\n",
            "Loss in iteration no. 73364 ==> 0.4449160271366308\n",
            "Loss in iteration no. 73365 ==> 0.4449147028249824\n",
            "Loss in iteration no. 73366 ==> 0.4449133785338963\n",
            "Loss in iteration no. 73367 ==> 0.444912054263372\n",
            "Loss in iteration no. 73368 ==> 0.44491073001340903\n",
            "Loss in iteration no. 73369 ==> 0.444909405784007\n",
            "Loss in iteration no. 73370 ==> 0.44490808157516537\n",
            "Loss in iteration no. 73371 ==> 0.4449067573868838\n",
            "Loss in iteration no. 73372 ==> 0.4449054332191618\n",
            "Loss in iteration no. 73373 ==> 0.4449041090719988\n",
            "Loss in iteration no. 73374 ==> 0.4449027849453946\n",
            "Loss in iteration no. 73375 ==> 0.44490146083934845\n",
            "Loss in iteration no. 73376 ==> 0.4449001367538601\n",
            "Loss in iteration no. 73377 ==> 0.4448988126889291\n",
            "Loss in iteration no. 73378 ==> 0.44489748864455486\n",
            "Loss in iteration no. 73379 ==> 0.4448961646207371\n",
            "Loss in iteration no. 73380 ==> 0.4448948406174752\n",
            "Loss in iteration no. 73381 ==> 0.44489351663476884\n",
            "Loss in iteration no. 73382 ==> 0.44489219267261754\n",
            "Loss in iteration no. 73383 ==> 0.4448908687310208\n",
            "Loss in iteration no. 73384 ==> 0.44488954480997833\n",
            "Loss in iteration no. 73385 ==> 0.4448882209094893\n",
            "Loss in iteration no. 73386 ==> 0.4448868970295536\n",
            "Loss in iteration no. 73387 ==> 0.44488557317017074\n",
            "Loss in iteration no. 73388 ==> 0.4448842493313403\n",
            "Loss in iteration no. 73389 ==> 0.4448829255130615\n",
            "Loss in iteration no. 73390 ==> 0.4448816017153343\n",
            "Loss in iteration no. 73391 ==> 0.444880277938158\n",
            "Loss in iteration no. 73392 ==> 0.44487895418153234\n",
            "Loss in iteration no. 73393 ==> 0.4448776304454567\n",
            "Loss in iteration no. 73394 ==> 0.44487630672993067\n",
            "Loss in iteration no. 73395 ==> 0.44487498303495376\n",
            "Loss in iteration no. 73396 ==> 0.44487365936052575\n",
            "Loss in iteration no. 73397 ==> 0.4448723357066459\n",
            "Loss in iteration no. 73398 ==> 0.444871012073314\n",
            "Loss in iteration no. 73399 ==> 0.44486968846052927\n",
            "Loss in iteration no. 73400 ==> 0.4448683648682915\n",
            "Loss in iteration no. 73401 ==> 0.4448670412966004\n",
            "Loss in iteration no. 73402 ==> 0.444865717745455\n",
            "Loss in iteration no. 73403 ==> 0.44486439421485535\n",
            "Loss in iteration no. 73404 ==> 0.44486307070480086\n",
            "Loss in iteration no. 73405 ==> 0.44486174721529104\n",
            "Loss in iteration no. 73406 ==> 0.44486042374632534\n",
            "Loss in iteration no. 73407 ==> 0.44485910029790354\n",
            "Loss in iteration no. 73408 ==> 0.44485777687002487\n",
            "Loss in iteration no. 73409 ==> 0.4448564534626892\n",
            "Loss in iteration no. 73410 ==> 0.4448551300758959\n",
            "Loss in iteration no. 73411 ==> 0.4448538067096446\n",
            "Loss in iteration no. 73412 ==> 0.4448524833639347\n",
            "Loss in iteration no. 73413 ==> 0.444851160038766\n",
            "Loss in iteration no. 73414 ==> 0.44484983673413786\n",
            "Loss in iteration no. 73415 ==> 0.4448485134500499\n",
            "Loss in iteration no. 73416 ==> 0.4448471901865016\n",
            "Loss in iteration no. 73417 ==> 0.4448458669434925\n",
            "Loss in iteration no. 73418 ==> 0.44484454372102233\n",
            "Loss in iteration no. 73419 ==> 0.4448432205190905\n",
            "Loss in iteration no. 73420 ==> 0.4448418973376965\n",
            "Loss in iteration no. 73421 ==> 0.44484057417684003\n",
            "Loss in iteration no. 73422 ==> 0.44483925103652056\n",
            "Loss in iteration no. 73423 ==> 0.4448379279167376\n",
            "Loss in iteration no. 73424 ==> 0.4448366048174909\n",
            "Loss in iteration no. 73425 ==> 0.4448352817387796\n",
            "Loss in iteration no. 73426 ==> 0.44483395868060366\n",
            "Loss in iteration no. 73427 ==> 0.44483263564296244\n",
            "Loss in iteration no. 73428 ==> 0.44483131262585557\n",
            "Loss in iteration no. 73429 ==> 0.44482998962928244\n",
            "Loss in iteration no. 73430 ==> 0.44482866665324267\n",
            "Loss in iteration no. 73431 ==> 0.444827343697736\n",
            "Loss in iteration no. 73432 ==> 0.44482602076276173\n",
            "Loss in iteration no. 73433 ==> 0.44482469784831963\n",
            "Loss in iteration no. 73434 ==> 0.44482337495440905\n",
            "Loss in iteration no. 73435 ==> 0.4448220520810296\n",
            "Loss in iteration no. 73436 ==> 0.44482072922818083\n",
            "Loss in iteration no. 73437 ==> 0.4448194063958624\n",
            "Loss in iteration no. 73438 ==> 0.4448180835840737\n",
            "Loss in iteration no. 73439 ==> 0.4448167607928143\n",
            "Loss in iteration no. 73440 ==> 0.4448154380220838\n",
            "Loss in iteration no. 73441 ==> 0.4448141152718818\n",
            "Loss in iteration no. 73442 ==> 0.4448127925422079\n",
            "Loss in iteration no. 73443 ==> 0.4448114698330613\n",
            "Loss in iteration no. 73444 ==> 0.444810147144442\n",
            "Loss in iteration no. 73445 ==> 0.4448088244763493\n",
            "Loss in iteration no. 73446 ==> 0.44480750182878276\n",
            "Loss in iteration no. 73447 ==> 0.444806179201742\n",
            "Loss in iteration no. 73448 ==> 0.44480485659522645\n",
            "Loss in iteration no. 73449 ==> 0.44480353400923583\n",
            "Loss in iteration no. 73450 ==> 0.44480221144376947\n",
            "Loss in iteration no. 73451 ==> 0.4448008888988272\n",
            "Loss in iteration no. 73452 ==> 0.4447995663744083\n",
            "Loss in iteration no. 73453 ==> 0.4447982438705125\n",
            "Loss in iteration no. 73454 ==> 0.4447969213871394\n",
            "Loss in iteration no. 73455 ==> 0.4447955989242882\n",
            "Loss in iteration no. 73456 ==> 0.4447942764819589\n",
            "Loss in iteration no. 73457 ==> 0.44479295406015074\n",
            "Loss in iteration no. 73458 ==> 0.44479163165886343\n",
            "Loss in iteration no. 73459 ==> 0.4447903092780964\n",
            "Loss in iteration no. 73460 ==> 0.44478898691784924\n",
            "Loss in iteration no. 73461 ==> 0.44478766457812163\n",
            "Loss in iteration no. 73462 ==> 0.44478634225891284\n",
            "Loss in iteration no. 73463 ==> 0.4447850199602228\n",
            "Loss in iteration no. 73464 ==> 0.44478369768205067\n",
            "Loss in iteration no. 73465 ==> 0.44478237542439625\n",
            "Loss in iteration no. 73466 ==> 0.444781053187259\n",
            "Loss in iteration no. 73467 ==> 0.44477973097063855\n",
            "Loss in iteration no. 73468 ==> 0.44477840877453434\n",
            "Loss in iteration no. 73469 ==> 0.44477708659894594\n",
            "Loss in iteration no. 73470 ==> 0.44477576444387307\n",
            "Loss in iteration no. 73471 ==> 0.44477444230931495\n",
            "Loss in iteration no. 73472 ==> 0.4447731201952714\n",
            "Loss in iteration no. 73473 ==> 0.44477179810174194\n",
            "Loss in iteration no. 73474 ==> 0.444770476028726\n",
            "Loss in iteration no. 73475 ==> 0.44476915397622324\n",
            "Loss in iteration no. 73476 ==> 0.44476783194423314\n",
            "Loss in iteration no. 73477 ==> 0.44476650993275524\n",
            "Loss in iteration no. 73478 ==> 0.4447651879417892\n",
            "Loss in iteration no. 73479 ==> 0.44476386597133444\n",
            "Loss in iteration no. 73480 ==> 0.44476254402139065\n",
            "Loss in iteration no. 73481 ==> 0.44476122209195723\n",
            "Loss in iteration no. 73482 ==> 0.4447599001830339\n",
            "Loss in iteration no. 73483 ==> 0.44475857829461996\n",
            "Loss in iteration no. 73484 ==> 0.4447572564267152\n",
            "Loss in iteration no. 73485 ==> 0.44475593457931906\n",
            "Loss in iteration no. 73486 ==> 0.44475461275243106\n",
            "Loss in iteration no. 73487 ==> 0.4447532909460508\n",
            "Loss in iteration no. 73488 ==> 0.44475196916017795\n",
            "Loss in iteration no. 73489 ==> 0.4447506473948119\n",
            "Loss in iteration no. 73490 ==> 0.44474932564995223\n",
            "Loss in iteration no. 73491 ==> 0.44474800392559843\n",
            "Loss in iteration no. 73492 ==> 0.4447466822217502\n",
            "Loss in iteration no. 73493 ==> 0.444745360538407\n",
            "Loss in iteration no. 73494 ==> 0.4447440388755684\n",
            "Loss in iteration no. 73495 ==> 0.44474271723323394\n",
            "Loss in iteration no. 73496 ==> 0.444741395611403\n",
            "Loss in iteration no. 73497 ==> 0.4447400740100756\n",
            "Loss in iteration no. 73498 ==> 0.4447387524292508\n",
            "Loss in iteration no. 73499 ==> 0.44473743086892836\n",
            "Loss in iteration no. 73500 ==> 0.4447361093291079\n",
            "Loss in iteration no. 73501 ==> 0.4447347878097888\n",
            "Loss in iteration no. 73502 ==> 0.4447334663109707\n",
            "Loss in iteration no. 73503 ==> 0.4447321448326532\n",
            "Loss in iteration no. 73504 ==> 0.4447308233748358\n",
            "Loss in iteration no. 73505 ==> 0.444729501937518\n",
            "Loss in iteration no. 73506 ==> 0.44472818052069946\n",
            "Loss in iteration no. 73507 ==> 0.4447268591243796\n",
            "Loss in iteration no. 73508 ==> 0.44472553774855805\n",
            "Loss in iteration no. 73509 ==> 0.44472421639323434\n",
            "Loss in iteration no. 73510 ==> 0.44472289505840806\n",
            "Loss in iteration no. 73511 ==> 0.44472157374407867\n",
            "Loss in iteration no. 73512 ==> 0.4447202524502458\n",
            "Loss in iteration no. 73513 ==> 0.4447189311769091\n",
            "Loss in iteration no. 73514 ==> 0.4447176099240678\n",
            "Loss in iteration no. 73515 ==> 0.44471628869172175\n",
            "Loss in iteration no. 73516 ==> 0.4447149674798704\n",
            "Loss in iteration no. 73517 ==> 0.44471364628851334\n",
            "Loss in iteration no. 73518 ==> 0.44471232511764996\n",
            "Loss in iteration no. 73519 ==> 0.4447110039672801\n",
            "Loss in iteration no. 73520 ==> 0.44470968283740303\n",
            "Loss in iteration no. 73521 ==> 0.4447083617280184\n",
            "Loss in iteration no. 73522 ==> 0.44470704063912586\n",
            "Loss in iteration no. 73523 ==> 0.4447057195707249\n",
            "Loss in iteration no. 73524 ==> 0.44470439852281485\n",
            "Loss in iteration no. 73525 ==> 0.44470307749539567\n",
            "Loss in iteration no. 73526 ==> 0.4447017564884666\n",
            "Loss in iteration no. 73527 ==> 0.44470043550202726\n",
            "Loss in iteration no. 73528 ==> 0.44469911453607736\n",
            "Loss in iteration no. 73529 ==> 0.44469779359061623\n",
            "Loss in iteration no. 73530 ==> 0.44469647266564344\n",
            "Loss in iteration no. 73531 ==> 0.44469515176115876\n",
            "Loss in iteration no. 73532 ==> 0.44469383087716147\n",
            "Loss in iteration no. 73533 ==> 0.4446925100136514\n",
            "Loss in iteration no. 73534 ==> 0.4446911891706277\n",
            "Loss in iteration no. 73535 ==> 0.4446898683480904\n",
            "Loss in iteration no. 73536 ==> 0.44468854754603876\n",
            "Loss in iteration no. 73537 ==> 0.4446872267644723\n",
            "Loss in iteration no. 73538 ==> 0.4446859060033907\n",
            "Loss in iteration no. 73539 ==> 0.4446845852627934\n",
            "Loss in iteration no. 73540 ==> 0.44468326454268015\n",
            "Loss in iteration no. 73541 ==> 0.4446819438430503\n",
            "Loss in iteration no. 73542 ==> 0.44468062316390344\n",
            "Loss in iteration no. 73543 ==> 0.44467930250523924\n",
            "Loss in iteration no. 73544 ==> 0.4446779818670572\n",
            "Loss in iteration no. 73545 ==> 0.4446766612493566\n",
            "Loss in iteration no. 73546 ==> 0.4446753406521375\n",
            "Loss in iteration no. 73547 ==> 0.444674020075399\n",
            "Loss in iteration no. 73548 ==> 0.4446726995191409\n",
            "Loss in iteration no. 73549 ==> 0.44467137898336256\n",
            "Loss in iteration no. 73550 ==> 0.4446700584680638\n",
            "Loss in iteration no. 73551 ==> 0.44466873797324397\n",
            "Loss in iteration no. 73552 ==> 0.44466741749890265\n",
            "Loss in iteration no. 73553 ==> 0.44466609704503934\n",
            "Loss in iteration no. 73554 ==> 0.4446647766116538\n",
            "Loss in iteration no. 73555 ==> 0.4446634561987454\n",
            "Loss in iteration no. 73556 ==> 0.4446621358063138\n",
            "Loss in iteration no. 73557 ==> 0.44466081543435837\n",
            "Loss in iteration no. 73558 ==> 0.44465949508287883\n",
            "Loss in iteration no. 73559 ==> 0.44465817475187475\n",
            "Loss in iteration no. 73560 ==> 0.44465685444134545\n",
            "Loss in iteration no. 73561 ==> 0.4446555341512907\n",
            "Loss in iteration no. 73562 ==> 0.44465421388171\n",
            "Loss in iteration no. 73563 ==> 0.4446528936326029\n",
            "Loss in iteration no. 73564 ==> 0.44465157340396894\n",
            "Loss in iteration no. 73565 ==> 0.4446502531958076\n",
            "Loss in iteration no. 73566 ==> 0.4446489330081187\n",
            "Loss in iteration no. 73567 ==> 0.44464761284090154\n",
            "Loss in iteration no. 73568 ==> 0.44464629269415556\n",
            "Loss in iteration no. 73569 ==> 0.44464497256788066\n",
            "Loss in iteration no. 73570 ==> 0.4446436524620761\n",
            "Loss in iteration no. 73571 ==> 0.44464233237674167\n",
            "Loss in iteration no. 73572 ==> 0.4446410123118767\n",
            "Loss in iteration no. 73573 ==> 0.4446396922674808\n",
            "Loss in iteration no. 73574 ==> 0.4446383722435536\n",
            "Loss in iteration no. 73575 ==> 0.4446370522400947\n",
            "Loss in iteration no. 73576 ==> 0.44463573225710346\n",
            "Loss in iteration no. 73577 ==> 0.44463441229457945\n",
            "Loss in iteration no. 73578 ==> 0.44463309235252246\n",
            "Loss in iteration no. 73579 ==> 0.44463177243093177\n",
            "Loss in iteration no. 73580 ==> 0.44463045252980715\n",
            "Loss in iteration no. 73581 ==> 0.44462913264914794\n",
            "Loss in iteration no. 73582 ==> 0.44462781278895397\n",
            "Loss in iteration no. 73583 ==> 0.4446264929492244\n",
            "Loss in iteration no. 73584 ==> 0.4446251731299591\n",
            "Loss in iteration no. 73585 ==> 0.4446238533311576\n",
            "Loss in iteration no. 73586 ==> 0.4446225335528192\n",
            "Loss in iteration no. 73587 ==> 0.4446212137949438\n",
            "Loss in iteration no. 73588 ==> 0.44461989405753066\n",
            "Loss in iteration no. 73589 ==> 0.4446185743405795\n",
            "Loss in iteration no. 73590 ==> 0.44461725464408985\n",
            "Loss in iteration no. 73591 ==> 0.44461593496806123\n",
            "Loss in iteration no. 73592 ==> 0.4446146153124931\n",
            "Loss in iteration no. 73593 ==> 0.44461329567738517\n",
            "Loss in iteration no. 73594 ==> 0.44461197606273684\n",
            "Loss in iteration no. 73595 ==> 0.44461065646854786\n",
            "Loss in iteration no. 73596 ==> 0.4446093368948176\n",
            "Loss in iteration no. 73597 ==> 0.4446080173415457\n",
            "Loss in iteration no. 73598 ==> 0.44460669780873174\n",
            "Loss in iteration no. 73599 ==> 0.44460537829637514\n",
            "Loss in iteration no. 73600 ==> 0.4446040588044757\n",
            "Loss in iteration no. 73601 ==> 0.4446027393330327\n",
            "Loss in iteration no. 73602 ==> 0.44460141988204577\n",
            "Loss in iteration no. 73603 ==> 0.4446001004515145\n",
            "Loss in iteration no. 73604 ==> 0.44459878104143846\n",
            "Loss in iteration no. 73605 ==> 0.4445974616518171\n",
            "Loss in iteration no. 73606 ==> 0.4445961422826501\n",
            "Loss in iteration no. 73607 ==> 0.444594822933937\n",
            "Loss in iteration no. 73608 ==> 0.44459350360567723\n",
            "Loss in iteration no. 73609 ==> 0.4445921842978705\n",
            "Loss in iteration no. 73610 ==> 0.4445908650105162\n",
            "Loss in iteration no. 73611 ==> 0.4445895457436141\n",
            "Loss in iteration no. 73612 ==> 0.4445882264971635\n",
            "Loss in iteration no. 73613 ==> 0.4445869072711641\n",
            "Loss in iteration no. 73614 ==> 0.4445855880656153\n",
            "Loss in iteration no. 73615 ==> 0.444584268880517\n",
            "Loss in iteration no. 73616 ==> 0.44458294971586837\n",
            "Loss in iteration no. 73617 ==> 0.4445816305716692\n",
            "Loss in iteration no. 73618 ==> 0.44458031144791893\n",
            "Loss in iteration no. 73619 ==> 0.444578992344617\n",
            "Loss in iteration no. 73620 ==> 0.44457767326176334\n",
            "Loss in iteration no. 73621 ==> 0.4445763541993571\n",
            "Loss in iteration no. 73622 ==> 0.4445750351573981\n",
            "Loss in iteration no. 73623 ==> 0.4445737161358857\n",
            "Loss in iteration no. 73624 ==> 0.44457239713481966\n",
            "Loss in iteration no. 73625 ==> 0.4445710781541993\n",
            "Loss in iteration no. 73626 ==> 0.4445697591940242\n",
            "Loss in iteration no. 73627 ==> 0.44456844025429426\n",
            "Loss in iteration no. 73628 ==> 0.4445671213350086\n",
            "Loss in iteration no. 73629 ==> 0.44456580243616695\n",
            "Loss in iteration no. 73630 ==> 0.44456448355776884\n",
            "Loss in iteration no. 73631 ==> 0.4445631646998139\n",
            "Loss in iteration no. 73632 ==> 0.4445618458623016\n",
            "Loss in iteration no. 73633 ==> 0.4445605270452313\n",
            "Loss in iteration no. 73634 ==> 0.444559208248603\n",
            "Loss in iteration no. 73635 ==> 0.44455788947241587\n",
            "Loss in iteration no. 73636 ==> 0.44455657071666965\n",
            "Loss in iteration no. 73637 ==> 0.4445552519813639\n",
            "Loss in iteration no. 73638 ==> 0.44455393326649817\n",
            "Loss in iteration no. 73639 ==> 0.44455261457207185\n",
            "Loss in iteration no. 73640 ==> 0.4445512958980847\n",
            "Loss in iteration no. 73641 ==> 0.4445499772445361\n",
            "Loss in iteration no. 73642 ==> 0.4445486586114256\n",
            "Loss in iteration no. 73643 ==> 0.444547339998753\n",
            "Loss in iteration no. 73644 ==> 0.44454602140651767\n",
            "Loss in iteration no. 73645 ==> 0.44454470283471903\n",
            "Loss in iteration no. 73646 ==> 0.4445433842833568\n",
            "Loss in iteration no. 73647 ==> 0.4445420657524306\n",
            "Loss in iteration no. 73648 ==> 0.4445407472419398\n",
            "Loss in iteration no. 73649 ==> 0.44453942875188424\n",
            "Loss in iteration no. 73650 ==> 0.4445381102822631\n",
            "Loss in iteration no. 73651 ==> 0.4445367918330761\n",
            "Loss in iteration no. 73652 ==> 0.4445354734043228\n",
            "Loss in iteration no. 73653 ==> 0.44453415499600285\n",
            "Loss in iteration no. 73654 ==> 0.4445328366081157\n",
            "Loss in iteration no. 73655 ==> 0.4445315182406608\n",
            "Loss in iteration no. 73656 ==> 0.4445301998936378\n",
            "Loss in iteration no. 73657 ==> 0.4445288815670464\n",
            "Loss in iteration no. 73658 ==> 0.444527563260886\n",
            "Loss in iteration no. 73659 ==> 0.4445262449751561\n",
            "Loss in iteration no. 73660 ==> 0.4445249267098563\n",
            "Loss in iteration no. 73661 ==> 0.4445236084649863\n",
            "Loss in iteration no. 73662 ==> 0.4445222902405453\n",
            "Loss in iteration no. 73663 ==> 0.44452097203653324\n",
            "Loss in iteration no. 73664 ==> 0.4445196538529495\n",
            "Loss in iteration no. 73665 ==> 0.4445183356897936\n",
            "Loss in iteration no. 73666 ==> 0.44451701754706513\n",
            "Loss in iteration no. 73667 ==> 0.44451569942476366\n",
            "Loss in iteration no. 73668 ==> 0.4445143813228887\n",
            "Loss in iteration no. 73669 ==> 0.44451306324143985\n",
            "Loss in iteration no. 73670 ==> 0.4445117451804167\n",
            "Loss in iteration no. 73671 ==> 0.4445104271398187\n",
            "Loss in iteration no. 73672 ==> 0.4445091091196455\n",
            "Loss in iteration no. 73673 ==> 0.4445077911198965\n",
            "Loss in iteration no. 73674 ==> 0.4445064731405715\n",
            "Loss in iteration no. 73675 ==> 0.4445051551816697\n",
            "Loss in iteration no. 73676 ==> 0.4445038372431911\n",
            "Loss in iteration no. 73677 ==> 0.44450251932513485\n",
            "Loss in iteration no. 73678 ==> 0.4445012014275006\n",
            "Loss in iteration no. 73679 ==> 0.44449988355028813\n",
            "Loss in iteration no. 73680 ==> 0.4444985656934968\n",
            "Loss in iteration no. 73681 ==> 0.4444972478571262\n",
            "Loss in iteration no. 73682 ==> 0.4444959300411758\n",
            "Loss in iteration no. 73683 ==> 0.4444946122456453\n",
            "Loss in iteration no. 73684 ==> 0.4444932944705342\n",
            "Loss in iteration no. 73685 ==> 0.44449197671584195\n",
            "Loss in iteration no. 73686 ==> 0.44449065898156825\n",
            "Loss in iteration no. 73687 ==> 0.4444893412677125\n",
            "Loss in iteration no. 73688 ==> 0.4444880235742744\n",
            "Loss in iteration no. 73689 ==> 0.4444867059012535\n",
            "Loss in iteration no. 73690 ==> 0.44448538824864936\n",
            "Loss in iteration no. 73691 ==> 0.4444840706164612\n",
            "Loss in iteration no. 73692 ==> 0.44448275300468904\n",
            "Loss in iteration no. 73693 ==> 0.4444814354133323\n",
            "Loss in iteration no. 73694 ==> 0.4444801178423904\n",
            "Loss in iteration no. 73695 ==> 0.4444788002918629\n",
            "Loss in iteration no. 73696 ==> 0.44447748276174953\n",
            "Loss in iteration no. 73697 ==> 0.4444761652520495\n",
            "Loss in iteration no. 73698 ==> 0.4444748477627628\n",
            "Loss in iteration no. 73699 ==> 0.44447353029388875\n",
            "Loss in iteration no. 73700 ==> 0.4444722128454269\n",
            "Loss in iteration no. 73701 ==> 0.44447089541737683\n",
            "Loss in iteration no. 73702 ==> 0.4444695780097381\n",
            "Loss in iteration no. 73703 ==> 0.44446826062251027\n",
            "Loss in iteration no. 73704 ==> 0.44446694325569286\n",
            "Loss in iteration no. 73705 ==> 0.44446562590928546\n",
            "Loss in iteration no. 73706 ==> 0.44446430858328756\n",
            "Loss in iteration no. 73707 ==> 0.4444629912776988\n",
            "Loss in iteration no. 73708 ==> 0.44446167399251874\n",
            "Loss in iteration no. 73709 ==> 0.44446035672774675\n",
            "Loss in iteration no. 73710 ==> 0.4444590394833826\n",
            "Loss in iteration no. 73711 ==> 0.44445772225942576\n",
            "Loss in iteration no. 73712 ==> 0.4444564050558758\n",
            "Loss in iteration no. 73713 ==> 0.44445508787273214\n",
            "Loss in iteration no. 73714 ==> 0.44445377070999464\n",
            "Loss in iteration no. 73715 ==> 0.4444524535676625\n",
            "Loss in iteration no. 73716 ==> 0.44445113644573553\n",
            "Loss in iteration no. 73717 ==> 0.44444981934421324\n",
            "Loss in iteration no. 73718 ==> 0.444448502263095\n",
            "Loss in iteration no. 73719 ==> 0.4444471852023806\n",
            "Loss in iteration no. 73720 ==> 0.4444458681620693\n",
            "Loss in iteration no. 73721 ==> 0.4444445511421611\n",
            "Loss in iteration no. 73722 ==> 0.4444432341426552\n",
            "Loss in iteration no. 73723 ==> 0.44444191716355114\n",
            "Loss in iteration no. 73724 ==> 0.4444406002048487\n",
            "Loss in iteration no. 73725 ==> 0.44443928326654725\n",
            "Loss in iteration no. 73726 ==> 0.44443796634864646\n",
            "Loss in iteration no. 73727 ==> 0.4444366494511458\n",
            "Loss in iteration no. 73728 ==> 0.4444353325740449\n",
            "Loss in iteration no. 73729 ==> 0.44443401571734326\n",
            "Loss in iteration no. 73730 ==> 0.4444326988810404\n",
            "Loss in iteration no. 73731 ==> 0.44443138206513594\n",
            "Loss in iteration no. 73732 ==> 0.44443006526962936\n",
            "Loss in iteration no. 73733 ==> 0.44442874849452035\n",
            "Loss in iteration no. 73734 ==> 0.4444274317398084\n",
            "Loss in iteration no. 73735 ==> 0.4444261150054929\n",
            "Loss in iteration no. 73736 ==> 0.44442479829157366\n",
            "Loss in iteration no. 73737 ==> 0.44442348159805006\n",
            "Loss in iteration no. 73738 ==> 0.44442216492492176\n",
            "Loss in iteration no. 73739 ==> 0.44442084827218825\n",
            "Loss in iteration no. 73740 ==> 0.44441953163984904\n",
            "Loss in iteration no. 73741 ==> 0.44441821502790374\n",
            "Loss in iteration no. 73742 ==> 0.444416898436352\n",
            "Loss in iteration no. 73743 ==> 0.44441558186519314\n",
            "Loss in iteration no. 73744 ==> 0.4444142653144269\n",
            "Loss in iteration no. 73745 ==> 0.44441294878405296\n",
            "Loss in iteration no. 73746 ==> 0.4444116322740704\n",
            "Loss in iteration no. 73747 ==> 0.44441031578447926\n",
            "Loss in iteration no. 73748 ==> 0.4444089993152789\n",
            "Loss in iteration no. 73749 ==> 0.44440768286646887\n",
            "Loss in iteration no. 73750 ==> 0.4444063664380486\n",
            "Loss in iteration no. 73751 ==> 0.44440505003001796\n",
            "Loss in iteration no. 73752 ==> 0.44440373364237623\n",
            "Loss in iteration no. 73753 ==> 0.444402417275123\n",
            "Loss in iteration no. 73754 ==> 0.444401100928258\n",
            "Loss in iteration no. 73755 ==> 0.4443997846017806\n",
            "Loss in iteration no. 73756 ==> 0.4443984682956904\n",
            "Loss in iteration no. 73757 ==> 0.444397152009987\n",
            "Loss in iteration no. 73758 ==> 0.4443958357446699\n",
            "Loss in iteration no. 73759 ==> 0.4443945194997387\n",
            "Loss in iteration no. 73760 ==> 0.4443932032751929\n",
            "Loss in iteration no. 73761 ==> 0.44439188707103205\n",
            "Loss in iteration no. 73762 ==> 0.44439057088725575\n",
            "Loss in iteration no. 73763 ==> 0.4443892547238636\n",
            "Loss in iteration no. 73764 ==> 0.444387938580855\n",
            "Loss in iteration no. 73765 ==> 0.44438662245822974\n",
            "Loss in iteration no. 73766 ==> 0.444385306355987\n",
            "Loss in iteration no. 73767 ==> 0.44438399027412684\n",
            "Loss in iteration no. 73768 ==> 0.4443826742126484\n",
            "Loss in iteration no. 73769 ==> 0.4443813581715514\n",
            "Loss in iteration no. 73770 ==> 0.44438004215083526\n",
            "Loss in iteration no. 73771 ==> 0.4443787261504998\n",
            "Loss in iteration no. 73772 ==> 0.44437741017054433\n",
            "Loss in iteration no. 73773 ==> 0.4443760942109685\n",
            "Loss in iteration no. 73774 ==> 0.4443747782717718\n",
            "Loss in iteration no. 73775 ==> 0.4443734623529539\n",
            "Loss in iteration no. 73776 ==> 0.4443721464545143\n",
            "Loss in iteration no. 73777 ==> 0.44437083057645255\n",
            "Loss in iteration no. 73778 ==> 0.4443695147187682\n",
            "Loss in iteration no. 73779 ==> 0.44436819888146073\n",
            "Loss in iteration no. 73780 ==> 0.4443668830645298\n",
            "Loss in iteration no. 73781 ==> 0.4443655672679749\n",
            "Loss in iteration no. 73782 ==> 0.44436425149179565\n",
            "Loss in iteration no. 73783 ==> 0.44436293573599167\n",
            "Loss in iteration no. 73784 ==> 0.44436162000056223\n",
            "Loss in iteration no. 73785 ==> 0.44436030428550716\n",
            "Loss in iteration no. 73786 ==> 0.44435898859082584\n",
            "Loss in iteration no. 73787 ==> 0.444357672916518\n",
            "Loss in iteration no. 73788 ==> 0.44435635726258316\n",
            "Loss in iteration no. 73789 ==> 0.4443550416290206\n",
            "Loss in iteration no. 73790 ==> 0.4443537260158303\n",
            "Loss in iteration no. 73791 ==> 0.4443524104230115\n",
            "Loss in iteration no. 73792 ==> 0.44435109485056384\n",
            "Loss in iteration no. 73793 ==> 0.4443497792984869\n",
            "Loss in iteration no. 73794 ==> 0.4443484637667803\n",
            "Loss in iteration no. 73795 ==> 0.44434714825544336\n",
            "Loss in iteration no. 73796 ==> 0.4443458327644759\n",
            "Loss in iteration no. 73797 ==> 0.4443445172938774\n",
            "Loss in iteration no. 73798 ==> 0.44434320184364734\n",
            "Loss in iteration no. 73799 ==> 0.44434188641378525\n",
            "Loss in iteration no. 73800 ==> 0.4443405710042908\n",
            "Loss in iteration no. 73801 ==> 0.4443392556151636\n",
            "Loss in iteration no. 73802 ==> 0.44433794024640294\n",
            "Loss in iteration no. 73803 ==> 0.44433662489800857\n",
            "Loss in iteration no. 73804 ==> 0.44433530956998\n",
            "Loss in iteration no. 73805 ==> 0.44433399426231684\n",
            "Loss in iteration no. 73806 ==> 0.44433267897501855\n",
            "Loss in iteration no. 73807 ==> 0.44433136370808474\n",
            "Loss in iteration no. 73808 ==> 0.44433004846151497\n",
            "Loss in iteration no. 73809 ==> 0.44432873323530875\n",
            "Loss in iteration no. 73810 ==> 0.44432741802946574\n",
            "Loss in iteration no. 73811 ==> 0.44432610284398527\n",
            "Loss in iteration no. 73812 ==> 0.4443247876788672\n",
            "Loss in iteration no. 73813 ==> 0.4443234725341108\n",
            "Loss in iteration no. 73814 ==> 0.44432215740971576\n",
            "Loss in iteration no. 73815 ==> 0.4443208423056817\n",
            "Loss in iteration no. 73816 ==> 0.444319527222008\n",
            "Loss in iteration no. 73817 ==> 0.4443182121586945\n",
            "Loss in iteration no. 73818 ==> 0.44431689711574035\n",
            "Loss in iteration no. 73819 ==> 0.44431558209314537\n",
            "Loss in iteration no. 73820 ==> 0.44431426709090915\n",
            "Loss in iteration no. 73821 ==> 0.44431295210903116\n",
            "Loss in iteration no. 73822 ==> 0.4443116371475109\n",
            "Loss in iteration no. 73823 ==> 0.444310322206348\n",
            "Loss in iteration no. 73824 ==> 0.44430900728554196\n",
            "Loss in iteration no. 73825 ==> 0.4443076923850923\n",
            "Loss in iteration no. 73826 ==> 0.4443063775049988\n",
            "Loss in iteration no. 73827 ==> 0.44430506264526076\n",
            "Loss in iteration no. 73828 ==> 0.4443037478058779\n",
            "Loss in iteration no. 73829 ==> 0.4443024329868496\n",
            "Loss in iteration no. 73830 ==> 0.44430111818817564\n",
            "Loss in iteration no. 73831 ==> 0.4442998034098554\n",
            "Loss in iteration no. 73832 ==> 0.4442984886518886\n",
            "Loss in iteration no. 73833 ==> 0.44429717391427453\n",
            "Loss in iteration no. 73834 ==> 0.444295859197013\n",
            "Loss in iteration no. 73835 ==> 0.44429454450010336\n",
            "Loss in iteration no. 73836 ==> 0.44429322982354535\n",
            "Loss in iteration no. 73837 ==> 0.44429191516733846\n",
            "Loss in iteration no. 73838 ==> 0.4442906005314821\n",
            "Loss in iteration no. 73839 ==> 0.4442892859159761\n",
            "Loss in iteration no. 73840 ==> 0.4442879713208198\n",
            "Loss in iteration no. 73841 ==> 0.44428665674601286\n",
            "Loss in iteration no. 73842 ==> 0.4442853421915548\n",
            "Loss in iteration no. 73843 ==> 0.44428402765744524\n",
            "Loss in iteration no. 73844 ==> 0.44428271314368356\n",
            "Loss in iteration no. 73845 ==> 0.4442813986502694\n",
            "Loss in iteration no. 73846 ==> 0.44428008417720244\n",
            "Loss in iteration no. 73847 ==> 0.444278769724482\n",
            "Loss in iteration no. 73848 ==> 0.4442774552921078\n",
            "Loss in iteration no. 73849 ==> 0.4442761408800795\n",
            "Loss in iteration no. 73850 ==> 0.4442748264883964\n",
            "Loss in iteration no. 73851 ==> 0.44427351211705823\n",
            "Loss in iteration no. 73852 ==> 0.4442721977660644\n",
            "Loss in iteration no. 73853 ==> 0.4442708834354146\n",
            "Loss in iteration no. 73854 ==> 0.44426956912510834\n",
            "Loss in iteration no. 73855 ==> 0.44426825483514526\n",
            "Loss in iteration no. 73856 ==> 0.44426694056552474\n",
            "Loss in iteration no. 73857 ==> 0.44426562631624633\n",
            "Loss in iteration no. 73858 ==> 0.44426431208730977\n",
            "Loss in iteration no. 73859 ==> 0.4442629978787146\n",
            "Loss in iteration no. 73860 ==> 0.44426168369046015\n",
            "Loss in iteration no. 73861 ==> 0.4442603695225462\n",
            "Loss in iteration no. 73862 ==> 0.44425905537497223\n",
            "Loss in iteration no. 73863 ==> 0.44425774124773776\n",
            "Loss in iteration no. 73864 ==> 0.44425642714084246\n",
            "Loss in iteration no. 73865 ==> 0.4442551130542857\n",
            "Loss in iteration no. 73866 ==> 0.44425379898806716\n",
            "Loss in iteration no. 73867 ==> 0.44425248494218633\n",
            "Loss in iteration no. 73868 ==> 0.4442511709166429\n",
            "Loss in iteration no. 73869 ==> 0.4442498569114363\n",
            "Loss in iteration no. 73870 ==> 0.4442485429265662\n",
            "Loss in iteration no. 73871 ==> 0.44424722896203195\n",
            "Loss in iteration no. 73872 ==> 0.4442459150178332\n",
            "Loss in iteration no. 73873 ==> 0.4442446010939696\n",
            "Loss in iteration no. 73874 ==> 0.4442432871904407\n",
            "Loss in iteration no. 73875 ==> 0.4442419733072459\n",
            "Loss in iteration no. 73876 ==> 0.4442406594443849\n",
            "Loss in iteration no. 73877 ==> 0.4442393456018572\n",
            "Loss in iteration no. 73878 ==> 0.44423803177966226\n",
            "Loss in iteration no. 73879 ==> 0.44423671797779984\n",
            "Loss in iteration no. 73880 ==> 0.4442354041962694\n",
            "Loss in iteration no. 73881 ==> 0.44423409043507045\n",
            "Loss in iteration no. 73882 ==> 0.4442327766942026\n",
            "Loss in iteration no. 73883 ==> 0.44423146297366534\n",
            "Loss in iteration no. 73884 ==> 0.4442301492734583\n",
            "Loss in iteration no. 73885 ==> 0.444228835593581\n",
            "Loss in iteration no. 73886 ==> 0.44422752193403303\n",
            "Loss in iteration no. 73887 ==> 0.4442262082948139\n",
            "Loss in iteration no. 73888 ==> 0.4442248946759232\n",
            "Loss in iteration no. 73889 ==> 0.4442235810773604\n",
            "Loss in iteration no. 73890 ==> 0.44422226749912513\n",
            "Loss in iteration no. 73891 ==> 0.44422095394121697\n",
            "Loss in iteration no. 73892 ==> 0.44421964040363554\n",
            "Loss in iteration no. 73893 ==> 0.44421832688638013\n",
            "Loss in iteration no. 73894 ==> 0.4442170133894505\n",
            "Loss in iteration no. 73895 ==> 0.44421569991284626\n",
            "Loss in iteration no. 73896 ==> 0.44421438645656686\n",
            "Loss in iteration no. 73897 ==> 0.4442130730206118\n",
            "Loss in iteration no. 73898 ==> 0.44421175960498077\n",
            "Loss in iteration no. 73899 ==> 0.44421044620967326\n",
            "Loss in iteration no. 73900 ==> 0.4442091328346888\n",
            "Loss in iteration no. 73901 ==> 0.444207819480027\n",
            "Loss in iteration no. 73902 ==> 0.44420650614568735\n",
            "Loss in iteration no. 73903 ==> 0.4442051928316695\n",
            "Loss in iteration no. 73904 ==> 0.4442038795379729\n",
            "Loss in iteration no. 73905 ==> 0.4442025662645972\n",
            "Loss in iteration no. 73906 ==> 0.44420125301154184\n",
            "Loss in iteration no. 73907 ==> 0.4441999397788064\n",
            "Loss in iteration no. 73908 ==> 0.4441986265663907\n",
            "Loss in iteration no. 73909 ==> 0.4441973133742939\n",
            "Loss in iteration no. 73910 ==> 0.4441960002025158\n",
            "Loss in iteration no. 73911 ==> 0.4441946870510559\n",
            "Loss in iteration no. 73912 ==> 0.4441933739199137\n",
            "Loss in iteration no. 73913 ==> 0.44419206080908885\n",
            "Loss in iteration no. 73914 ==> 0.4441907477185808\n",
            "Loss in iteration no. 73915 ==> 0.4441894346483892\n",
            "Loss in iteration no. 73916 ==> 0.44418812159851356\n",
            "Loss in iteration no. 73917 ==> 0.44418680856895343\n",
            "Loss in iteration no. 73918 ==> 0.4441854955597084\n",
            "Loss in iteration no. 73919 ==> 0.444184182570778\n",
            "Loss in iteration no. 73920 ==> 0.44418286960216186\n",
            "Loss in iteration no. 73921 ==> 0.44418155665385933\n",
            "Loss in iteration no. 73922 ==> 0.4441802437258703\n",
            "Loss in iteration no. 73923 ==> 0.44417893081819393\n",
            "Loss in iteration no. 73924 ==> 0.44417761793083005\n",
            "Loss in iteration no. 73925 ==> 0.44417630506377814\n",
            "Loss in iteration no. 73926 ==> 0.4441749922170377\n",
            "Loss in iteration no. 73927 ==> 0.44417367939060837\n",
            "Loss in iteration no. 73928 ==> 0.4441723665844898\n",
            "Loss in iteration no. 73929 ==> 0.4441710537986813\n",
            "Loss in iteration no. 73930 ==> 0.4441697410331826\n",
            "Loss in iteration no. 73931 ==> 0.44416842828799313\n",
            "Loss in iteration no. 73932 ==> 0.4441671155631126\n",
            "Loss in iteration no. 73933 ==> 0.44416580285854046\n",
            "Loss in iteration no. 73934 ==> 0.4441644901742763\n",
            "Loss in iteration no. 73935 ==> 0.4441631775103198\n",
            "Loss in iteration no. 73936 ==> 0.44416186486667003\n",
            "Loss in iteration no. 73937 ==> 0.4441605522433272\n",
            "Loss in iteration no. 73938 ==> 0.44415923964029047\n",
            "Loss in iteration no. 73939 ==> 0.4441579270575595\n",
            "Loss in iteration no. 73940 ==> 0.4441566144951339\n",
            "Loss in iteration no. 73941 ==> 0.44415530195301317\n",
            "Loss in iteration no. 73942 ==> 0.4441539894311967\n",
            "Loss in iteration no. 73943 ==> 0.44415267692968435\n",
            "Loss in iteration no. 73944 ==> 0.4441513644484755\n",
            "Loss in iteration no. 73945 ==> 0.44415005198756974\n",
            "Loss in iteration no. 73946 ==> 0.44414873954696665\n",
            "Loss in iteration no. 73947 ==> 0.4441474271266658\n",
            "Loss in iteration no. 73948 ==> 0.44414611472666665\n",
            "Loss in iteration no. 73949 ==> 0.4441448023469688\n",
            "Loss in iteration no. 73950 ==> 0.4441434899875718\n",
            "Loss in iteration no. 73951 ==> 0.4441421776484753\n",
            "Loss in iteration no. 73952 ==> 0.4441408653296787\n",
            "Loss in iteration no. 73953 ==> 0.4441395530311817\n",
            "Loss in iteration no. 73954 ==> 0.4441382407529838\n",
            "Loss in iteration no. 73955 ==> 0.4441369284950845\n",
            "Loss in iteration no. 73956 ==> 0.44413561625748355\n",
            "Loss in iteration no. 73957 ==> 0.4441343040401802\n",
            "Loss in iteration no. 73958 ==> 0.44413299184317423\n",
            "Loss in iteration no. 73959 ==> 0.44413167966646516\n",
            "Loss in iteration no. 73960 ==> 0.44413036751005247\n",
            "Loss in iteration no. 73961 ==> 0.4441290553739358\n",
            "Loss in iteration no. 73962 ==> 0.4441277432581146\n",
            "Loss in iteration no. 73963 ==> 0.4441264311625886\n",
            "Loss in iteration no. 73964 ==> 0.4441251190873573\n",
            "Loss in iteration no. 73965 ==> 0.44412380703242016\n",
            "Loss in iteration no. 73966 ==> 0.44412249499777673\n",
            "Loss in iteration no. 73967 ==> 0.44412118298342673\n",
            "Loss in iteration no. 73968 ==> 0.44411987098936956\n",
            "Loss in iteration no. 73969 ==> 0.4441185590156048\n",
            "Loss in iteration no. 73970 ==> 0.4441172470621321\n",
            "Loss in iteration no. 73971 ==> 0.44411593512895087\n",
            "Loss in iteration no. 73972 ==> 0.4441146232160609\n",
            "Loss in iteration no. 73973 ==> 0.44411331132346143\n",
            "Loss in iteration no. 73974 ==> 0.4441119994511522\n",
            "Loss in iteration no. 73975 ==> 0.4441106875991329\n",
            "Loss in iteration no. 73976 ==> 0.4441093757674027\n",
            "Loss in iteration no. 73977 ==> 0.44410806395596164\n",
            "Loss in iteration no. 73978 ==> 0.44410675216480894\n",
            "Loss in iteration no. 73979 ==> 0.44410544039394423\n",
            "Loss in iteration no. 73980 ==> 0.444104128643367\n",
            "Loss in iteration no. 73981 ==> 0.444102816913077\n",
            "Loss in iteration no. 73982 ==> 0.4441015052030736\n",
            "Loss in iteration no. 73983 ==> 0.44410019351335656\n",
            "Loss in iteration no. 73984 ==> 0.4440988818439252\n",
            "Loss in iteration no. 73985 ==> 0.4440975701947792\n",
            "Loss in iteration no. 73986 ==> 0.4440962585659181\n",
            "Loss in iteration no. 73987 ==> 0.44409494695734153\n",
            "Loss in iteration no. 73988 ==> 0.44409363536904883\n",
            "Loss in iteration no. 73989 ==> 0.4440923238010398\n",
            "Loss in iteration no. 73990 ==> 0.4440910122533139\n",
            "Loss in iteration no. 73991 ==> 0.44408970072587073\n",
            "Loss in iteration no. 73992 ==> 0.4440883892187096\n",
            "Loss in iteration no. 73993 ==> 0.4440870777318305\n",
            "Loss in iteration no. 73994 ==> 0.4440857662652326\n",
            "Loss in iteration no. 73995 ==> 0.4440844548189157\n",
            "Loss in iteration no. 73996 ==> 0.4440831433928793\n",
            "Loss in iteration no. 73997 ==> 0.4440818319871228\n",
            "Loss in iteration no. 73998 ==> 0.44408052060164604\n",
            "Loss in iteration no. 73999 ==> 0.44407920923644834\n",
            "Loss in iteration no. 74000 ==> 0.44407789789152924\n",
            "Loss in iteration no. 74001 ==> 0.44407658656688853\n",
            "Loss in iteration no. 74002 ==> 0.4440752752625256\n",
            "Loss in iteration no. 74003 ==> 0.44407396397844\n",
            "Loss in iteration no. 74004 ==> 0.4440726527146313\n",
            "Loss in iteration no. 74005 ==> 0.4440713414710992\n",
            "Loss in iteration no. 74006 ==> 0.4440700302478431\n",
            "Loss in iteration no. 74007 ==> 0.4440687190448624\n",
            "Loss in iteration no. 74008 ==> 0.44406740786215704\n",
            "Loss in iteration no. 74009 ==> 0.44406609669972635\n",
            "Loss in iteration no. 74010 ==> 0.44406478555756995\n",
            "Loss in iteration no. 74011 ==> 0.4440634744356873\n",
            "Loss in iteration no. 74012 ==> 0.444062163334078\n",
            "Loss in iteration no. 74013 ==> 0.4440608522527418\n",
            "Loss in iteration no. 74014 ==> 0.44405954119167795\n",
            "Loss in iteration no. 74015 ==> 0.4440582301508862\n",
            "Loss in iteration no. 74016 ==> 0.4440569191303661\n",
            "Loss in iteration no. 74017 ==> 0.4440556081301171\n",
            "Loss in iteration no. 74018 ==> 0.4440542971501388\n",
            "Loss in iteration no. 74019 ==> 0.4440529861904309\n",
            "Loss in iteration no. 74020 ==> 0.4440516752509927\n",
            "Loss in iteration no. 74021 ==> 0.444050364331824\n",
            "Loss in iteration no. 74022 ==> 0.44404905343292417\n",
            "Loss in iteration no. 74023 ==> 0.44404774255429286\n",
            "Loss in iteration no. 74024 ==> 0.44404643169592956\n",
            "Loss in iteration no. 74025 ==> 0.44404512085783404\n",
            "Loss in iteration no. 74026 ==> 0.4440438100400056\n",
            "Loss in iteration no. 74027 ==> 0.4440424992424439\n",
            "Loss in iteration no. 74028 ==> 0.4440411884651485\n",
            "Loss in iteration no. 74029 ==> 0.44403987770811887\n",
            "Loss in iteration no. 74030 ==> 0.4440385669713547\n",
            "Loss in iteration no. 74031 ==> 0.4440372562548555\n",
            "Loss in iteration no. 74032 ==> 0.44403594555862086\n",
            "Loss in iteration no. 74033 ==> 0.44403463488265027\n",
            "Loss in iteration no. 74034 ==> 0.44403332422694336\n",
            "Loss in iteration no. 74035 ==> 0.44403201359149946\n",
            "Loss in iteration no. 74036 ==> 0.4440307029763185\n",
            "Loss in iteration no. 74037 ==> 0.44402939238139977\n",
            "Loss in iteration no. 74038 ==> 0.4440280818067429\n",
            "Loss in iteration no. 74039 ==> 0.4440267712523476\n",
            "Loss in iteration no. 74040 ==> 0.4440254607182131\n",
            "Loss in iteration no. 74041 ==> 0.44402415020433916\n",
            "Loss in iteration no. 74042 ==> 0.44402283971072526\n",
            "Loss in iteration no. 74043 ==> 0.44402152923737115\n",
            "Loss in iteration no. 74044 ==> 0.4440202187842762\n",
            "Loss in iteration no. 74045 ==> 0.44401890835144003\n",
            "Loss in iteration no. 74046 ==> 0.44401759793886214\n",
            "Loss in iteration no. 74047 ==> 0.44401628754654215\n",
            "Loss in iteration no. 74048 ==> 0.4440149771744795\n",
            "Loss in iteration no. 74049 ==> 0.44401366682267407\n",
            "Loss in iteration no. 74050 ==> 0.44401235649112497\n",
            "Loss in iteration no. 74051 ==> 0.4440110461798321\n",
            "Loss in iteration no. 74052 ==> 0.44400973588879494\n",
            "Loss in iteration no. 74053 ==> 0.44400842561801285\n",
            "Loss in iteration no. 74054 ==> 0.4440071153674857\n",
            "Loss in iteration no. 74055 ==> 0.44400580513721283\n",
            "Loss in iteration no. 74056 ==> 0.4440044949271938\n",
            "Loss in iteration no. 74057 ==> 0.44400318473742834\n",
            "Loss in iteration no. 74058 ==> 0.44400187456791573\n",
            "Loss in iteration no. 74059 ==> 0.4440005644186558\n",
            "Loss in iteration no. 74060 ==> 0.443999254289648\n",
            "Loss in iteration no. 74061 ==> 0.44399794418089195\n",
            "Loss in iteration no. 74062 ==> 0.443996634092387\n",
            "Loss in iteration no. 74063 ==> 0.4439953240241329\n",
            "Loss in iteration no. 74064 ==> 0.44399401397612914\n",
            "Loss in iteration no. 74065 ==> 0.4439927039483753\n",
            "Loss in iteration no. 74066 ==> 0.44399139394087106\n",
            "Loss in iteration no. 74067 ==> 0.44399008395361567\n",
            "Loss in iteration no. 74068 ==> 0.443988773986609\n",
            "Loss in iteration no. 74069 ==> 0.4439874640398504\n",
            "Loss in iteration no. 74070 ==> 0.4439861541133396\n",
            "Loss in iteration no. 74071 ==> 0.44398484420707596\n",
            "Loss in iteration no. 74072 ==> 0.44398353432105925\n",
            "Loss in iteration no. 74073 ==> 0.4439822244552888\n",
            "Loss in iteration no. 74074 ==> 0.4439809146097643\n",
            "Loss in iteration no. 74075 ==> 0.4439796047844853\n",
            "Loss in iteration no. 74076 ==> 0.44397829497945135\n",
            "Loss in iteration no. 74077 ==> 0.4439769851946621\n",
            "Loss in iteration no. 74078 ==> 0.44397567543011685\n",
            "Loss in iteration no. 74079 ==> 0.4439743656858154\n",
            "Loss in iteration no. 74080 ==> 0.4439730559617573\n",
            "Loss in iteration no. 74081 ==> 0.443971746257942\n",
            "Loss in iteration no. 74082 ==> 0.44397043657436913\n",
            "Loss in iteration no. 74083 ==> 0.4439691269110381\n",
            "Loss in iteration no. 74084 ==> 0.4439678172679487\n",
            "Loss in iteration no. 74085 ==> 0.4439665076451003\n",
            "Loss in iteration no. 74086 ==> 0.4439651980424926\n",
            "Loss in iteration no. 74087 ==> 0.443963888460125\n",
            "Loss in iteration no. 74088 ==> 0.44396257889799723\n",
            "Loss in iteration no. 74089 ==> 0.4439612693561088\n",
            "Loss in iteration no. 74090 ==> 0.4439599598344591\n",
            "Loss in iteration no. 74091 ==> 0.4439586503330478\n",
            "Loss in iteration no. 74092 ==> 0.4439573408518746\n",
            "Loss in iteration no. 74093 ==> 0.4439560313909389\n",
            "Loss in iteration no. 74094 ==> 0.4439547219502402\n",
            "Loss in iteration no. 74095 ==> 0.4439534125297783\n",
            "Loss in iteration no. 74096 ==> 0.4439521031295526\n",
            "Loss in iteration no. 74097 ==> 0.44395079374956253\n",
            "Loss in iteration no. 74098 ==> 0.44394948438980797\n",
            "Loss in iteration no. 74099 ==> 0.4439481750502881\n",
            "Loss in iteration no. 74100 ==> 0.4439468657310027\n",
            "Loss in iteration no. 74101 ==> 0.4439455564319514\n",
            "Loss in iteration no. 74102 ==> 0.44394424715313363\n",
            "Loss in iteration no. 74103 ==> 0.443942937894549\n",
            "Loss in iteration no. 74104 ==> 0.44394162865619696\n",
            "Loss in iteration no. 74105 ==> 0.44394031943807716\n",
            "Loss in iteration no. 74106 ==> 0.44393901024018917\n",
            "Loss in iteration no. 74107 ==> 0.4439377010625326\n",
            "Loss in iteration no. 74108 ==> 0.4439363919051069\n",
            "Loss in iteration no. 74109 ==> 0.4439350827679116\n",
            "Loss in iteration no. 74110 ==> 0.44393377365094644\n",
            "Loss in iteration no. 74111 ==> 0.44393246455421076\n",
            "Loss in iteration no. 74112 ==> 0.44393115547770423\n",
            "Loss in iteration no. 74113 ==> 0.4439298464214264\n",
            "Loss in iteration no. 74114 ==> 0.44392853738537685\n",
            "Loss in iteration no. 74115 ==> 0.4439272283695551\n",
            "Loss in iteration no. 74116 ==> 0.4439259193739608\n",
            "Loss in iteration no. 74117 ==> 0.4439246103985933\n",
            "Loss in iteration no. 74118 ==> 0.4439233014434523\n",
            "Loss in iteration no. 74119 ==> 0.44392199250853737\n",
            "Loss in iteration no. 74120 ==> 0.4439206835938482\n",
            "Loss in iteration no. 74121 ==> 0.44391937469938403\n",
            "Loss in iteration no. 74122 ==> 0.44391806582514465\n",
            "Loss in iteration no. 74123 ==> 0.4439167569711295\n",
            "Loss in iteration no. 74124 ==> 0.4439154481373382\n",
            "Loss in iteration no. 74125 ==> 0.44391413932377033\n",
            "Loss in iteration no. 74126 ==> 0.44391283053042535\n",
            "Loss in iteration no. 74127 ==> 0.443911521757303\n",
            "Loss in iteration no. 74128 ==> 0.4439102130044026\n",
            "Loss in iteration no. 74129 ==> 0.4439089042717239\n",
            "Loss in iteration no. 74130 ==> 0.44390759555926634\n",
            "Loss in iteration no. 74131 ==> 0.44390628686702954\n",
            "Loss in iteration no. 74132 ==> 0.4439049781950131\n",
            "Loss in iteration no. 74133 ==> 0.4439036695432165\n",
            "Loss in iteration no. 74134 ==> 0.44390236091163926\n",
            "Loss in iteration no. 74135 ==> 0.4439010523002811\n",
            "Loss in iteration no. 74136 ==> 0.44389974370914137\n",
            "Loss in iteration no. 74137 ==> 0.44389843513821975\n",
            "Loss in iteration no. 74138 ==> 0.4438971265875159\n",
            "Loss in iteration no. 74139 ==> 0.4438958180570292\n",
            "Loss in iteration no. 74140 ==> 0.44389450954675935\n",
            "Loss in iteration no. 74141 ==> 0.4438932010567058\n",
            "Loss in iteration no. 74142 ==> 0.443891892586868\n",
            "Loss in iteration no. 74143 ==> 0.4438905841372458\n",
            "Loss in iteration no. 74144 ==> 0.4438892757078386\n",
            "Loss in iteration no. 74145 ==> 0.443887967298646\n",
            "Loss in iteration no. 74146 ==> 0.44388665890966744\n",
            "Loss in iteration no. 74147 ==> 0.4438853505409026\n",
            "Loss in iteration no. 74148 ==> 0.443884042192351\n",
            "Loss in iteration no. 74149 ==> 0.44388273386401217\n",
            "Loss in iteration no. 74150 ==> 0.4438814255558857\n",
            "Loss in iteration no. 74151 ==> 0.44388011726797116\n",
            "Loss in iteration no. 74152 ==> 0.44387880900026816\n",
            "Loss in iteration no. 74153 ==> 0.44387750075277616\n",
            "Loss in iteration no. 74154 ==> 0.44387619252549476\n",
            "Loss in iteration no. 74155 ==> 0.4438748843184235\n",
            "Loss in iteration no. 74156 ==> 0.443873576131562\n",
            "Loss in iteration no. 74157 ==> 0.4438722679649097\n",
            "Loss in iteration no. 74158 ==> 0.4438709598184663\n",
            "Loss in iteration no. 74159 ==> 0.44386965169223125\n",
            "Loss in iteration no. 74160 ==> 0.4438683435862041\n",
            "Loss in iteration no. 74161 ==> 0.4438670355003846\n",
            "Loss in iteration no. 74162 ==> 0.44386572743477215\n",
            "Loss in iteration no. 74163 ==> 0.44386441938936627\n",
            "Loss in iteration no. 74164 ==> 0.4438631113641665\n",
            "Loss in iteration no. 74165 ==> 0.4438618033591726\n",
            "Loss in iteration no. 74166 ==> 0.44386049537438393\n",
            "Loss in iteration no. 74167 ==> 0.44385918740980007\n",
            "Loss in iteration no. 74168 ==> 0.44385787946542077\n",
            "Loss in iteration no. 74169 ==> 0.4438565715412454\n",
            "Loss in iteration no. 74170 ==> 0.4438552636372735\n",
            "Loss in iteration no. 74171 ==> 0.4438539557535048\n",
            "Loss in iteration no. 74172 ==> 0.4438526478899386\n",
            "Loss in iteration no. 74173 ==> 0.44385134004657484\n",
            "Loss in iteration no. 74174 ==> 0.4438500322234127\n",
            "Loss in iteration no. 74175 ==> 0.443848724420452\n",
            "Loss in iteration no. 74176 ==> 0.44384741663769206\n",
            "Loss in iteration no. 74177 ==> 0.4438461088751327\n",
            "Loss in iteration no. 74178 ==> 0.4438448011327732\n",
            "Loss in iteration no. 74179 ==> 0.4438434934106134\n",
            "Loss in iteration no. 74180 ==> 0.4438421857086527\n",
            "Loss in iteration no. 74181 ==> 0.44384087802689076\n",
            "Loss in iteration no. 74182 ==> 0.44383957036532695\n",
            "Loss in iteration no. 74183 ==> 0.44383826272396093\n",
            "Loss in iteration no. 74184 ==> 0.4438369551027923\n",
            "Loss in iteration no. 74185 ==> 0.4438356475018207\n",
            "Loss in iteration no. 74186 ==> 0.44383433992104543\n",
            "Loss in iteration no. 74187 ==> 0.4438330323604663\n",
            "Loss in iteration no. 74188 ==> 0.4438317248200827\n",
            "Loss in iteration no. 74189 ==> 0.4438304172998945\n",
            "Loss in iteration no. 74190 ==> 0.44382910979990065\n",
            "Loss in iteration no. 74191 ==> 0.4438278023201013\n",
            "Loss in iteration no. 74192 ==> 0.44382649486049575\n",
            "Loss in iteration no. 74193 ==> 0.4438251874210837\n",
            "Loss in iteration no. 74194 ==> 0.44382388000186446\n",
            "Loss in iteration no. 74195 ==> 0.44382257260283775\n",
            "Loss in iteration no. 74196 ==> 0.44382126522400317\n",
            "Loss in iteration no. 74197 ==> 0.4438199578653602\n",
            "Loss in iteration no. 74198 ==> 0.4438186505269085\n",
            "Loss in iteration no. 74199 ==> 0.44381734320864746\n",
            "Loss in iteration no. 74200 ==> 0.4438160359105767\n",
            "Loss in iteration no. 74201 ==> 0.44381472863269594\n",
            "Loss in iteration no. 74202 ==> 0.44381342137500457\n",
            "Loss in iteration no. 74203 ==> 0.4438121141375021\n",
            "Loss in iteration no. 74204 ==> 0.4438108069201883\n",
            "Loss in iteration no. 74205 ==> 0.44380949972306266\n",
            "Loss in iteration no. 74206 ==> 0.4438081925461246\n",
            "Loss in iteration no. 74207 ==> 0.4438068853893738\n",
            "Loss in iteration no. 74208 ==> 0.44380557825280964\n",
            "Loss in iteration no. 74209 ==> 0.44380427113643195\n",
            "Loss in iteration no. 74210 ==> 0.4438029640402403\n",
            "Loss in iteration no. 74211 ==> 0.4438016569642339\n",
            "Loss in iteration no. 74212 ==> 0.44380034990841266\n",
            "Loss in iteration no. 74213 ==> 0.44379904287277594\n",
            "Loss in iteration no. 74214 ==> 0.44379773585732335\n",
            "Loss in iteration no. 74215 ==> 0.4437964288620545\n",
            "Loss in iteration no. 74216 ==> 0.44379512188696896\n",
            "Loss in iteration no. 74217 ==> 0.44379381493206627\n",
            "Loss in iteration no. 74218 ==> 0.4437925079973458\n",
            "Loss in iteration no. 74219 ==> 0.44379120108280734\n",
            "Loss in iteration no. 74220 ==> 0.4437898941884505\n",
            "Loss in iteration no. 74221 ==> 0.44378858731427456\n",
            "Loss in iteration no. 74222 ==> 0.4437872804602793\n",
            "Loss in iteration no. 74223 ==> 0.44378597362646427\n",
            "Loss in iteration no. 74224 ==> 0.44378466681282897\n",
            "Loss in iteration no. 74225 ==> 0.44378336001937296\n",
            "Loss in iteration no. 74226 ==> 0.4437820532460958\n",
            "Loss in iteration no. 74227 ==> 0.4437807464929971\n",
            "Loss in iteration no. 74228 ==> 0.44377943976007633\n",
            "Loss in iteration no. 74229 ==> 0.4437781330473332\n",
            "Loss in iteration no. 74230 ==> 0.4437768263547671\n",
            "Loss in iteration no. 74231 ==> 0.44377551968237755\n",
            "Loss in iteration no. 74232 ==> 0.4437742130301644\n",
            "Loss in iteration no. 74233 ==> 0.44377290639812694\n",
            "Loss in iteration no. 74234 ==> 0.44377159978626485\n",
            "Loss in iteration no. 74235 ==> 0.44377029319457767\n",
            "Loss in iteration no. 74236 ==> 0.4437689866230649\n",
            "Loss in iteration no. 74237 ==> 0.44376768007172607\n",
            "Loss in iteration no. 74238 ==> 0.44376637354056103\n",
            "Loss in iteration no. 74239 ==> 0.44376506702956897\n",
            "Loss in iteration no. 74240 ==> 0.44376376053874966\n",
            "Loss in iteration no. 74241 ==> 0.4437624540681026\n",
            "Loss in iteration no. 74242 ==> 0.44376114761762736\n",
            "Loss in iteration no. 74243 ==> 0.4437598411873235\n",
            "Loss in iteration no. 74244 ==> 0.4437585347771906\n",
            "Loss in iteration no. 74245 ==> 0.4437572283872282\n",
            "Loss in iteration no. 74246 ==> 0.4437559220174358\n",
            "Loss in iteration no. 74247 ==> 0.4437546156678131\n",
            "Loss in iteration no. 74248 ==> 0.44375330933835955\n",
            "Loss in iteration no. 74249 ==> 0.4437520030290748\n",
            "Loss in iteration no. 74250 ==> 0.4437506967399582\n",
            "Loss in iteration no. 74251 ==> 0.44374939047100964\n",
            "Loss in iteration no. 74252 ==> 0.44374808422222833\n",
            "Loss in iteration no. 74253 ==> 0.44374677799361406\n",
            "Loss in iteration no. 74254 ==> 0.44374547178516627\n",
            "Loss in iteration no. 74255 ==> 0.4437441655968846\n",
            "Loss in iteration no. 74256 ==> 0.44374285942876873\n",
            "Loss in iteration no. 74257 ==> 0.44374155328081794\n",
            "Loss in iteration no. 74258 ==> 0.443740247153032\n",
            "Loss in iteration no. 74259 ==> 0.44373894104541034\n",
            "Loss in iteration no. 74260 ==> 0.44373763495795254\n",
            "Loss in iteration no. 74261 ==> 0.4437363288906583\n",
            "Loss in iteration no. 74262 ==> 0.443735022843527\n",
            "Loss in iteration no. 74263 ==> 0.4437337168165583\n",
            "Loss in iteration no. 74264 ==> 0.4437324108097518\n",
            "Loss in iteration no. 74265 ==> 0.44373110482310685\n",
            "Loss in iteration no. 74266 ==> 0.44372979885662334\n",
            "Loss in iteration no. 74267 ==> 0.44372849291030053\n",
            "Loss in iteration no. 74268 ==> 0.4437271869841381\n",
            "Loss in iteration no. 74269 ==> 0.4437258810781357\n",
            "Loss in iteration no. 74270 ==> 0.44372457519229275\n",
            "Loss in iteration no. 74271 ==> 0.4437232693266089\n",
            "Loss in iteration no. 74272 ==> 0.4437219634810836\n",
            "Loss in iteration no. 74273 ==> 0.4437206576557165\n",
            "Loss in iteration no. 74274 ==> 0.4437193518505072\n",
            "Loss in iteration no. 74275 ==> 0.4437180460654552\n",
            "Loss in iteration no. 74276 ==> 0.44371674030055996\n",
            "Loss in iteration no. 74277 ==> 0.44371543455582124\n",
            "Loss in iteration no. 74278 ==> 0.44371412883123845\n",
            "Loss in iteration no. 74279 ==> 0.4437128231268112\n",
            "Loss in iteration no. 74280 ==> 0.4437115174425391\n",
            "Loss in iteration no. 74281 ==> 0.4437102117784216\n",
            "Loss in iteration no. 74282 ==> 0.4437089061344584\n",
            "Loss in iteration no. 74283 ==> 0.4437076005106489\n",
            "Loss in iteration no. 74284 ==> 0.4437062949069928\n",
            "Loss in iteration no. 74285 ==> 0.44370498932348956\n",
            "Loss in iteration no. 74286 ==> 0.44370368376013886\n",
            "Loss in iteration no. 74287 ==> 0.4437023782169401\n",
            "Loss in iteration no. 74288 ==> 0.44370107269389303\n",
            "Loss in iteration no. 74289 ==> 0.44369976719099696\n",
            "Loss in iteration no. 74290 ==> 0.4436984617082518\n",
            "Loss in iteration no. 74291 ==> 0.4436971562456568\n",
            "Loss in iteration no. 74292 ==> 0.44369585080321167\n",
            "Loss in iteration no. 74293 ==> 0.4436945453809159\n",
            "Loss in iteration no. 74294 ==> 0.44369323997876897\n",
            "Loss in iteration no. 74295 ==> 0.44369193459677064\n",
            "Loss in iteration no. 74296 ==> 0.44369062923492036\n",
            "Loss in iteration no. 74297 ==> 0.44368932389321786\n",
            "Loss in iteration no. 74298 ==> 0.4436880185716624\n",
            "Loss in iteration no. 74299 ==> 0.4436867132702537\n",
            "Loss in iteration no. 74300 ==> 0.44368540798899136\n",
            "Loss in iteration no. 74301 ==> 0.4436841027278749\n",
            "Loss in iteration no. 74302 ==> 0.4436827974869038\n",
            "Loss in iteration no. 74303 ==> 0.44368149226607784\n",
            "Loss in iteration no. 74304 ==> 0.4436801870653963\n",
            "Loss in iteration no. 74305 ==> 0.4436788818848589\n",
            "Loss in iteration no. 74306 ==> 0.44367757672446523\n",
            "Loss in iteration no. 74307 ==> 0.44367627158421474\n",
            "Loss in iteration no. 74308 ==> 0.44367496646410703\n",
            "Loss in iteration no. 74309 ==> 0.44367366136414177\n",
            "Loss in iteration no. 74310 ==> 0.44367235628431845\n",
            "Loss in iteration no. 74311 ==> 0.44367105122463646\n",
            "Loss in iteration no. 74312 ==> 0.4436697461850956\n",
            "Loss in iteration no. 74313 ==> 0.44366844116569537\n",
            "Loss in iteration no. 74314 ==> 0.4436671361664353\n",
            "Loss in iteration no. 74315 ==> 0.44366583118731484\n",
            "Loss in iteration no. 74316 ==> 0.4436645262283338\n",
            "Loss in iteration no. 74317 ==> 0.44366322128949154\n",
            "Loss in iteration no. 74318 ==> 0.4436619163707878\n",
            "Loss in iteration no. 74319 ==> 0.44366061147222186\n",
            "Loss in iteration no. 74320 ==> 0.44365930659379355\n",
            "Loss in iteration no. 74321 ==> 0.4436580017355023\n",
            "Loss in iteration no. 74322 ==> 0.4436566968973476\n",
            "Loss in iteration no. 74323 ==> 0.4436553920793293\n",
            "Loss in iteration no. 74324 ==> 0.44365408728144673\n",
            "Loss in iteration no. 74325 ==> 0.4436527825036994\n",
            "Loss in iteration no. 74326 ==> 0.44365147774608704\n",
            "Loss in iteration no. 74327 ==> 0.44365017300860904\n",
            "Loss in iteration no. 74328 ==> 0.4436488682912652\n",
            "Loss in iteration no. 74329 ==> 0.44364756359405494\n",
            "Loss in iteration no. 74330 ==> 0.4436462589169777\n",
            "Loss in iteration no. 74331 ==> 0.44364495426003314\n",
            "Loss in iteration no. 74332 ==> 0.44364364962322095\n",
            "Loss in iteration no. 74333 ==> 0.44364234500654043\n",
            "Loss in iteration no. 74334 ==> 0.4436410404099915\n",
            "Loss in iteration no. 74335 ==> 0.4436397358335734\n",
            "Loss in iteration no. 74336 ==> 0.44363843127728586\n",
            "Loss in iteration no. 74337 ==> 0.44363712674112826\n",
            "Loss in iteration no. 74338 ==> 0.44363582222510034\n",
            "Loss in iteration no. 74339 ==> 0.44363451772920165\n",
            "Loss in iteration no. 74340 ==> 0.4436332132534317\n",
            "Loss in iteration no. 74341 ==> 0.44363190879779\n",
            "Loss in iteration no. 74342 ==> 0.4436306043622763\n",
            "Loss in iteration no. 74343 ==> 0.44362929994688993\n",
            "Loss in iteration no. 74344 ==> 0.4436279955516305\n",
            "Loss in iteration no. 74345 ==> 0.4436266911764978\n",
            "Loss in iteration no. 74346 ==> 0.44362538682149105\n",
            "Loss in iteration no. 74347 ==> 0.44362408248661\n",
            "Loss in iteration no. 74348 ==> 0.44362277817185436\n",
            "Loss in iteration no. 74349 ==> 0.44362147387722334\n",
            "Loss in iteration no. 74350 ==> 0.4436201696027167\n",
            "Loss in iteration no. 74351 ==> 0.4436188653483341\n",
            "Loss in iteration no. 74352 ==> 0.44361756111407485\n",
            "Loss in iteration no. 74353 ==> 0.44361625689993867\n",
            "Loss in iteration no. 74354 ==> 0.44361495270592516\n",
            "Loss in iteration no. 74355 ==> 0.4436136485320338\n",
            "Loss in iteration no. 74356 ==> 0.4436123443782642\n",
            "Loss in iteration no. 74357 ==> 0.4436110402446157\n",
            "Loss in iteration no. 74358 ==> 0.44360973613108823\n",
            "Loss in iteration no. 74359 ==> 0.44360843203768113\n",
            "Loss in iteration no. 74360 ==> 0.443607127964394\n",
            "Loss in iteration no. 74361 ==> 0.44360582391122644\n",
            "Loss in iteration no. 74362 ==> 0.44360451987817795\n",
            "Loss in iteration no. 74363 ==> 0.44360321586524815\n",
            "Loss in iteration no. 74364 ==> 0.44360191187243647\n",
            "Loss in iteration no. 74365 ==> 0.4436006078997426\n",
            "Loss in iteration no. 74366 ==> 0.4435993039471661\n",
            "Loss in iteration no. 74367 ==> 0.4435980000147065\n",
            "Loss in iteration no. 74368 ==> 0.44359669610236335\n",
            "Loss in iteration no. 74369 ==> 0.4435953922101363\n",
            "Loss in iteration no. 74370 ==> 0.4435940883380248\n",
            "Loss in iteration no. 74371 ==> 0.4435927844860284\n",
            "Loss in iteration no. 74372 ==> 0.4435914806541468\n",
            "Loss in iteration no. 74373 ==> 0.44359017684237945\n",
            "Loss in iteration no. 74374 ==> 0.44358887305072586\n",
            "Loss in iteration no. 74375 ==> 0.44358756927918563\n",
            "Loss in iteration no. 74376 ==> 0.44358626552775854\n",
            "Loss in iteration no. 74377 ==> 0.44358496179644386\n",
            "Loss in iteration no. 74378 ==> 0.4435836580852412\n",
            "Loss in iteration no. 74379 ==> 0.44358235439415034\n",
            "Loss in iteration no. 74380 ==> 0.44358105072317056\n",
            "Loss in iteration no. 74381 ==> 0.44357974707230163\n",
            "Loss in iteration no. 74382 ==> 0.44357844344154296\n",
            "Loss in iteration no. 74383 ==> 0.44357713983089414\n",
            "Loss in iteration no. 74384 ==> 0.44357583624035496\n",
            "Loss in iteration no. 74385 ==> 0.4435745326699246\n",
            "Loss in iteration no. 74386 ==> 0.44357322911960284\n",
            "Loss in iteration no. 74387 ==> 0.44357192558938935\n",
            "Loss in iteration no. 74388 ==> 0.4435706220792834\n",
            "Loss in iteration no. 74389 ==> 0.4435693185892848\n",
            "Loss in iteration no. 74390 ==> 0.4435680151193929\n",
            "Loss in iteration no. 74391 ==> 0.44356671166960754\n",
            "Loss in iteration no. 74392 ==> 0.44356540823992807\n",
            "Loss in iteration no. 74393 ==> 0.4435641048303541\n",
            "Loss in iteration no. 74394 ==> 0.44356280144088517\n",
            "Loss in iteration no. 74395 ==> 0.44356149807152084\n",
            "Loss in iteration no. 74396 ==> 0.4435601947222608\n",
            "Loss in iteration no. 74397 ==> 0.44355889139310445\n",
            "Loss in iteration no. 74398 ==> 0.4435575880840515\n",
            "Loss in iteration no. 74399 ==> 0.44355628479510134\n",
            "Loss in iteration no. 74400 ==> 0.44355498152625356\n",
            "Loss in iteration no. 74401 ==> 0.44355367827750797\n",
            "Loss in iteration no. 74402 ==> 0.44355237504886386\n",
            "Loss in iteration no. 74403 ==> 0.44355107184032083\n",
            "Loss in iteration no. 74404 ==> 0.44354976865187845\n",
            "Loss in iteration no. 74405 ==> 0.44354846548353644\n",
            "Loss in iteration no. 74406 ==> 0.4435471623352941\n",
            "Loss in iteration no. 74407 ==> 0.4435458592071513\n",
            "Loss in iteration no. 74408 ==> 0.4435445560991073\n",
            "Loss in iteration no. 74409 ==> 0.4435432530111618\n",
            "Loss in iteration no. 74410 ==> 0.4435419499433144\n",
            "Loss in iteration no. 74411 ==> 0.4435406468955646\n",
            "Loss in iteration no. 74412 ==> 0.4435393438679121\n",
            "Loss in iteration no. 74413 ==> 0.44353804086035625\n",
            "Loss in iteration no. 74414 ==> 0.4435367378728967\n",
            "Loss in iteration no. 74415 ==> 0.44353543490553304\n",
            "Loss in iteration no. 74416 ==> 0.4435341319582648\n",
            "Loss in iteration no. 74417 ==> 0.44353282903109154\n",
            "Loss in iteration no. 74418 ==> 0.4435315261240128\n",
            "Loss in iteration no. 74419 ==> 0.4435302232370283\n",
            "Loss in iteration no. 74420 ==> 0.4435289203701374\n",
            "Loss in iteration no. 74421 ==> 0.44352761752333975\n",
            "Loss in iteration no. 74422 ==> 0.44352631469663484\n",
            "Loss in iteration no. 74423 ==> 0.4435250118900223\n",
            "Loss in iteration no. 74424 ==> 0.44352370910350175\n",
            "Loss in iteration no. 74425 ==> 0.4435224063370728\n",
            "Loss in iteration no. 74426 ==> 0.4435211035907347\n",
            "Loss in iteration no. 74427 ==> 0.44351980086448733\n",
            "Loss in iteration no. 74428 ==> 0.44351849815833005\n",
            "Loss in iteration no. 74429 ==> 0.44351719547226276\n",
            "Loss in iteration no. 74430 ==> 0.44351589280628445\n",
            "Loss in iteration no. 74431 ==> 0.44351459016039513\n",
            "Loss in iteration no. 74432 ==> 0.44351328753459424\n",
            "Loss in iteration no. 74433 ==> 0.44351198492888133\n",
            "Loss in iteration no. 74434 ==> 0.443510682343256\n",
            "Loss in iteration no. 74435 ==> 0.4435093797777178\n",
            "Loss in iteration no. 74436 ==> 0.4435080772322662\n",
            "Loss in iteration no. 74437 ==> 0.44350677470690086\n",
            "Loss in iteration no. 74438 ==> 0.44350547220162134\n",
            "Loss in iteration no. 74439 ==> 0.44350416971642725\n",
            "Loss in iteration no. 74440 ==> 0.443502867251318\n",
            "Loss in iteration no. 74441 ==> 0.4435015648062932\n",
            "Loss in iteration no. 74442 ==> 0.4435002623813525\n",
            "Loss in iteration no. 74443 ==> 0.4434989599764954\n",
            "Loss in iteration no. 74444 ==> 0.44349765759172155\n",
            "Loss in iteration no. 74445 ==> 0.4434963552270303\n",
            "Loss in iteration no. 74446 ==> 0.44349505288242147\n",
            "Loss in iteration no. 74447 ==> 0.44349375055789453\n",
            "Loss in iteration no. 74448 ==> 0.4434924482534488\n",
            "Loss in iteration no. 74449 ==> 0.4434911459690843\n",
            "Loss in iteration no. 74450 ==> 0.44348984370480027\n",
            "Loss in iteration no. 74451 ==> 0.44348854146059624\n",
            "Loss in iteration no. 74452 ==> 0.44348723923647193\n",
            "Loss in iteration no. 74453 ==> 0.44348593703242695\n",
            "Loss in iteration no. 74454 ==> 0.44348463484846085\n",
            "Loss in iteration no. 74455 ==> 0.4434833326845728\n",
            "Loss in iteration no. 74456 ==> 0.44348203054076296\n",
            "Loss in iteration no. 74457 ==> 0.44348072841703046\n",
            "Loss in iteration no. 74458 ==> 0.44347942631337506\n",
            "Loss in iteration no. 74459 ==> 0.44347812422979627\n",
            "Loss in iteration no. 74460 ==> 0.44347682216629364\n",
            "Loss in iteration no. 74461 ==> 0.4434755201228668\n",
            "Loss in iteration no. 74462 ==> 0.44347421809951515\n",
            "Loss in iteration no. 74463 ==> 0.4434729160962385\n",
            "Loss in iteration no. 74464 ==> 0.4434716141130362\n",
            "Loss in iteration no. 74465 ==> 0.44347031214990784\n",
            "Loss in iteration no. 74466 ==> 0.44346901020685325\n",
            "Loss in iteration no. 74467 ==> 0.44346770828387144\n",
            "Loss in iteration no. 74468 ==> 0.4434664063809625\n",
            "Loss in iteration no. 74469 ==> 0.44346510449812576\n",
            "Loss in iteration no. 74470 ==> 0.44346380263536084\n",
            "Loss in iteration no. 74471 ==> 0.44346250079266725\n",
            "Loss in iteration no. 74472 ==> 0.4434611989700447\n",
            "Loss in iteration no. 74473 ==> 0.4434598971674925\n",
            "Loss in iteration no. 74474 ==> 0.44345859538501053\n",
            "Loss in iteration no. 74475 ==> 0.44345729362259806\n",
            "Loss in iteration no. 74476 ==> 0.4434559918802547\n",
            "Loss in iteration no. 74477 ==> 0.4434546901579803\n",
            "Loss in iteration no. 74478 ==> 0.4434533884557739\n",
            "Loss in iteration no. 74479 ==> 0.4434520867736357\n",
            "Loss in iteration no. 74480 ==> 0.4434507851115646\n",
            "Loss in iteration no. 74481 ==> 0.4434494834695607\n",
            "Loss in iteration no. 74482 ==> 0.4434481818476233\n",
            "Loss in iteration no. 74483 ==> 0.443446880245752\n",
            "Loss in iteration no. 74484 ==> 0.44344557866394635\n",
            "Loss in iteration no. 74485 ==> 0.4434442771022061\n",
            "Loss in iteration no. 74486 ==> 0.44344297556053053\n",
            "Loss in iteration no. 74487 ==> 0.44344167403891943\n",
            "Loss in iteration no. 74488 ==> 0.44344037253737206\n",
            "Loss in iteration no. 74489 ==> 0.44343907105588837\n",
            "Loss in iteration no. 74490 ==> 0.44343776959446773\n",
            "Loss in iteration no. 74491 ==> 0.4434364681531097\n",
            "Loss in iteration no. 74492 ==> 0.4434351667318139\n",
            "Loss in iteration no. 74493 ==> 0.4434338653305797\n",
            "Loss in iteration no. 74494 ==> 0.44343256394940683\n",
            "Loss in iteration no. 74495 ==> 0.44343126258829496\n",
            "Loss in iteration no. 74496 ==> 0.44342996124724343\n",
            "Loss in iteration no. 74497 ==> 0.44342865992625197\n",
            "Loss in iteration no. 74498 ==> 0.44342735862532\n",
            "Loss in iteration no. 74499 ==> 0.44342605734444723\n",
            "Loss in iteration no. 74500 ==> 0.44342475608363313\n",
            "Loss in iteration no. 74501 ==> 0.44342345484287726\n",
            "Loss in iteration no. 74502 ==> 0.44342215362217924\n",
            "Loss in iteration no. 74503 ==> 0.4434208524215386\n",
            "Loss in iteration no. 74504 ==> 0.44341955124095495\n",
            "Loss in iteration no. 74505 ==> 0.4434182500804277\n",
            "Loss in iteration no. 74506 ==> 0.4434169489399566\n",
            "Loss in iteration no. 74507 ==> 0.4434156478195411\n",
            "Loss in iteration no. 74508 ==> 0.4434143467191807\n",
            "Loss in iteration no. 74509 ==> 0.4434130456388752\n",
            "Loss in iteration no. 74510 ==> 0.4434117445786239\n",
            "Loss in iteration no. 74511 ==> 0.4434104435384267\n",
            "Loss in iteration no. 74512 ==> 0.44340914251828273\n",
            "Loss in iteration no. 74513 ==> 0.44340784151819185\n",
            "Loss in iteration no. 74514 ==> 0.44340654053815354\n",
            "Loss in iteration no. 74515 ==> 0.4434052395781674\n",
            "Loss in iteration no. 74516 ==> 0.443403938638233\n",
            "Loss in iteration no. 74517 ==> 0.44340263771834976\n",
            "Loss in iteration no. 74518 ==> 0.44340133681851746\n",
            "Loss in iteration no. 74519 ==> 0.44340003593873545\n",
            "Loss in iteration no. 74520 ==> 0.4433987350790034\n",
            "Loss in iteration no. 74521 ==> 0.443397434239321\n",
            "Loss in iteration no. 74522 ==> 0.44339613341968753\n",
            "Loss in iteration no. 74523 ==> 0.44339483262010276\n",
            "Loss in iteration no. 74524 ==> 0.4433935318405661\n",
            "Loss in iteration no. 74525 ==> 0.44339223108107745\n",
            "Loss in iteration no. 74526 ==> 0.44339093034163607\n",
            "Loss in iteration no. 74527 ==> 0.44338962962224143\n",
            "Loss in iteration no. 74528 ==> 0.4433883289228934\n",
            "Loss in iteration no. 74529 ==> 0.4433870282435913\n",
            "Loss in iteration no. 74530 ==> 0.4433857275843349\n",
            "Loss in iteration no. 74531 ==> 0.44338442694512353\n",
            "Loss in iteration no. 74532 ==> 0.4433831263259569\n",
            "Loss in iteration no. 74533 ==> 0.4433818257268346\n",
            "Loss in iteration no. 74534 ==> 0.4433805251477561\n",
            "Loss in iteration no. 74535 ==> 0.44337922458872114\n",
            "Loss in iteration no. 74536 ==> 0.44337792404972903\n",
            "Loss in iteration no. 74537 ==> 0.44337662353077956\n",
            "Loss in iteration no. 74538 ==> 0.443375323031872\n",
            "Loss in iteration no. 74539 ==> 0.4433740225530063\n",
            "Loss in iteration no. 74540 ==> 0.44337272209418166\n",
            "Loss in iteration no. 74541 ==> 0.4433714216553979\n",
            "Loss in iteration no. 74542 ==> 0.44337012123665454\n",
            "Loss in iteration no. 74543 ==> 0.44336882083795104\n",
            "Loss in iteration no. 74544 ==> 0.443367520459287\n",
            "Loss in iteration no. 74545 ==> 0.443366220100662\n",
            "Loss in iteration no. 74546 ==> 0.44336491976207565\n",
            "Loss in iteration no. 74547 ==> 0.4433636194435275\n",
            "Loss in iteration no. 74548 ==> 0.44336231914501706\n",
            "Loss in iteration no. 74549 ==> 0.4433610188665439\n",
            "Loss in iteration no. 74550 ==> 0.4433597186081076\n",
            "Loss in iteration no. 74551 ==> 0.4433584183697077\n",
            "Loss in iteration no. 74552 ==> 0.4433571181513438\n",
            "Loss in iteration no. 74553 ==> 0.4433558179530155\n",
            "Loss in iteration no. 74554 ==> 0.4433545177747224\n",
            "Loss in iteration no. 74555 ==> 0.44335321761646385\n",
            "Loss in iteration no. 74556 ==> 0.44335191747823954\n",
            "Loss in iteration no. 74557 ==> 0.44335061736004916\n",
            "Loss in iteration no. 74558 ==> 0.44334931726189203\n",
            "Loss in iteration no. 74559 ==> 0.4433480171837678\n",
            "Loss in iteration no. 74560 ==> 0.4433467171256762\n",
            "Loss in iteration no. 74561 ==> 0.4433454170876166\n",
            "Loss in iteration no. 74562 ==> 0.44334411706958876\n",
            "Loss in iteration no. 74563 ==> 0.443342817071592\n",
            "Loss in iteration no. 74564 ==> 0.443341517093626\n",
            "Loss in iteration no. 74565 ==> 0.4433402171356902\n",
            "Loss in iteration no. 74566 ==> 0.4433389171977845\n",
            "Loss in iteration no. 74567 ==> 0.4433376172799082\n",
            "Loss in iteration no. 74568 ==> 0.4433363173820608\n",
            "Loss in iteration no. 74569 ==> 0.4433350175042421\n",
            "Loss in iteration no. 74570 ==> 0.4433337176464514\n",
            "Loss in iteration no. 74571 ==> 0.4433324178086886\n",
            "Loss in iteration no. 74572 ==> 0.44333111799095287\n",
            "Loss in iteration no. 74573 ==> 0.44332981819324413\n",
            "Loss in iteration no. 74574 ==> 0.44332851841556176\n",
            "Loss in iteration no. 74575 ==> 0.4433272186579053\n",
            "Loss in iteration no. 74576 ==> 0.44332591892027445\n",
            "Loss in iteration no. 74577 ==> 0.4433246192026686\n",
            "Loss in iteration no. 74578 ==> 0.4433233195050874\n",
            "Loss in iteration no. 74579 ==> 0.44332201982753044\n",
            "Loss in iteration no. 74580 ==> 0.44332072016999724\n",
            "Loss in iteration no. 74581 ==> 0.4433194205324875\n",
            "Loss in iteration no. 74582 ==> 0.44331812091500056\n",
            "Loss in iteration no. 74583 ==> 0.4433168213175361\n",
            "Loss in iteration no. 74584 ==> 0.44331552174009364\n",
            "Loss in iteration no. 74585 ==> 0.4433142221826729\n",
            "Loss in iteration no. 74586 ==> 0.4433129226452732\n",
            "Loss in iteration no. 74587 ==> 0.44331162312789435\n",
            "Loss in iteration no. 74588 ==> 0.44331032363053574\n",
            "Loss in iteration no. 74589 ==> 0.44330902415319695\n",
            "Loss in iteration no. 74590 ==> 0.4433077246958777\n",
            "Loss in iteration no. 74591 ==> 0.44330642525857733\n",
            "Loss in iteration no. 74592 ==> 0.4433051258412956\n",
            "Loss in iteration no. 74593 ==> 0.44330382644403193\n",
            "Loss in iteration no. 74594 ==> 0.44330252706678597\n",
            "Loss in iteration no. 74595 ==> 0.4433012277095572\n",
            "Loss in iteration no. 74596 ==> 0.4432999283723453\n",
            "Loss in iteration no. 74597 ==> 0.4432986290551498\n",
            "Loss in iteration no. 74598 ==> 0.44329732975797015\n",
            "Loss in iteration no. 74599 ==> 0.44329603048080607\n",
            "Loss in iteration no. 74600 ==> 0.443294731223657\n",
            "Loss in iteration no. 74601 ==> 0.4432934319865226\n",
            "Loss in iteration no. 74602 ==> 0.4432921327694024\n",
            "Loss in iteration no. 74603 ==> 0.44329083357229593\n",
            "Loss in iteration no. 74604 ==> 0.44328953439520286\n",
            "Loss in iteration no. 74605 ==> 0.4432882352381226\n",
            "Loss in iteration no. 74606 ==> 0.4432869361010548\n",
            "Loss in iteration no. 74607 ==> 0.4432856369839991\n",
            "Loss in iteration no. 74608 ==> 0.44328433788695476\n",
            "Loss in iteration no. 74609 ==> 0.44328303880992187\n",
            "Loss in iteration no. 74610 ==> 0.44328173975289953\n",
            "Loss in iteration no. 74611 ==> 0.4432804407158875\n",
            "Loss in iteration no. 74612 ==> 0.4432791416988853\n",
            "Loss in iteration no. 74613 ==> 0.44327784270189247\n",
            "Loss in iteration no. 74614 ==> 0.4432765437249087\n",
            "Loss in iteration no. 74615 ==> 0.4432752447679334\n",
            "Loss in iteration no. 74616 ==> 0.44327394583096624\n",
            "Loss in iteration no. 74617 ==> 0.4432726469140067\n",
            "Loss in iteration no. 74618 ==> 0.4432713480170544\n",
            "Loss in iteration no. 74619 ==> 0.44327004914010887\n",
            "Loss in iteration no. 74620 ==> 0.4432687502831698\n",
            "Loss in iteration no. 74621 ==> 0.44326745144623664\n",
            "Loss in iteration no. 74622 ==> 0.44326615262930874\n",
            "Loss in iteration no. 74623 ==> 0.4432648538323861\n",
            "Loss in iteration no. 74624 ==> 0.443263555055468\n",
            "Loss in iteration no. 74625 ==> 0.44326225629855415\n",
            "Loss in iteration no. 74626 ==> 0.4432609575616441\n",
            "Loss in iteration no. 74627 ==> 0.4432596588447372\n",
            "Loss in iteration no. 74628 ==> 0.44325836014783326\n",
            "Loss in iteration no. 74629 ==> 0.4432570614709318\n",
            "Loss in iteration no. 74630 ==> 0.4432557628140323\n",
            "Loss in iteration no. 74631 ==> 0.44325446417713427\n",
            "Loss in iteration no. 74632 ==> 0.4432531655602375\n",
            "Loss in iteration no. 74633 ==> 0.4432518669633415\n",
            "Loss in iteration no. 74634 ==> 0.4432505683864456\n",
            "Loss in iteration no. 74635 ==> 0.4432492698295496\n",
            "Loss in iteration no. 74636 ==> 0.4432479712926529\n",
            "Loss in iteration no. 74637 ==> 0.44324667277575525\n",
            "Loss in iteration no. 74638 ==> 0.4432453742788562\n",
            "Loss in iteration no. 74639 ==> 0.44324407580195513\n",
            "Loss in iteration no. 74640 ==> 0.44324277734505174\n",
            "Loss in iteration no. 74641 ==> 0.4432414789081456\n",
            "Loss in iteration no. 74642 ==> 0.4432401804912362\n",
            "Loss in iteration no. 74643 ==> 0.4432388820943231\n",
            "Loss in iteration no. 74644 ==> 0.44323758371740607\n",
            "Loss in iteration no. 74645 ==> 0.4432362853604843\n",
            "Loss in iteration no. 74646 ==> 0.4432349870235578\n",
            "Loss in iteration no. 74647 ==> 0.44323368870662566\n",
            "Loss in iteration no. 74648 ==> 0.4432323904096879\n",
            "Loss in iteration no. 74649 ==> 0.4432310921327438\n",
            "Loss in iteration no. 74650 ==> 0.443229793875793\n",
            "Loss in iteration no. 74651 ==> 0.4432284956388351\n",
            "Loss in iteration no. 74652 ==> 0.44322719742186967\n",
            "Loss in iteration no. 74653 ==> 0.4432258992248962\n",
            "Loss in iteration no. 74654 ==> 0.4432246010479142\n",
            "Loss in iteration no. 74655 ==> 0.44322330289092343\n",
            "Loss in iteration no. 74656 ==> 0.44322200475392326\n",
            "Loss in iteration no. 74657 ==> 0.4432207066369135\n",
            "Loss in iteration no. 74658 ==> 0.4432194085398934\n",
            "Loss in iteration no. 74659 ==> 0.44321811046286286\n",
            "Loss in iteration no. 74660 ==> 0.4432168124058211\n",
            "Loss in iteration no. 74661 ==> 0.443215514368768\n",
            "Loss in iteration no. 74662 ==> 0.44321421635170294\n",
            "Loss in iteration no. 74663 ==> 0.44321291835462545\n",
            "Loss in iteration no. 74664 ==> 0.44321162037753525\n",
            "Loss in iteration no. 74665 ==> 0.4432103224204318\n",
            "Loss in iteration no. 74666 ==> 0.44320902448331473\n",
            "Loss in iteration no. 74667 ==> 0.4432077265661835\n",
            "Loss in iteration no. 74668 ==> 0.4432064286690378\n",
            "Loss in iteration no. 74669 ==> 0.4432051307918772\n",
            "Loss in iteration no. 74670 ==> 0.4432038329347011\n",
            "Loss in iteration no. 74671 ==> 0.44320253509750923\n",
            "Loss in iteration no. 74672 ==> 0.44320123728030103\n",
            "Loss in iteration no. 74673 ==> 0.44319993948307623\n",
            "Loss in iteration no. 74674 ==> 0.44319864170583434\n",
            "Loss in iteration no. 74675 ==> 0.4431973439485747\n",
            "Loss in iteration no. 74676 ==> 0.44319604621129716\n",
            "Loss in iteration no. 74677 ==> 0.4431947484940011\n",
            "Loss in iteration no. 74678 ==> 0.4431934507966863\n",
            "Loss in iteration no. 74679 ==> 0.4431921531193521\n",
            "Loss in iteration no. 74680 ==> 0.4431908554619982\n",
            "Loss in iteration no. 74681 ==> 0.44318955782462405\n",
            "Loss in iteration no. 74682 ==> 0.4431882602072294\n",
            "Loss in iteration no. 74683 ==> 0.4431869626098137\n",
            "Loss in iteration no. 74684 ==> 0.4431856650323765\n",
            "Loss in iteration no. 74685 ==> 0.4431843674749173\n",
            "Loss in iteration no. 74686 ==> 0.44318306993743584\n",
            "Loss in iteration no. 74687 ==> 0.4431817724199315\n",
            "Loss in iteration no. 74688 ==> 0.4431804749224041\n",
            "Loss in iteration no. 74689 ==> 0.44317917744485297\n",
            "Loss in iteration no. 74690 ==> 0.44317787998727776\n",
            "Loss in iteration no. 74691 ==> 0.44317658254967796\n",
            "Loss in iteration no. 74692 ==> 0.4431752851320533\n",
            "Loss in iteration no. 74693 ==> 0.44317398773440325\n",
            "Loss in iteration no. 74694 ==> 0.44317269035672735\n",
            "Loss in iteration no. 74695 ==> 0.44317139299902514\n",
            "Loss in iteration no. 74696 ==> 0.4431700956612963\n",
            "Loss in iteration no. 74697 ==> 0.4431687983435403\n",
            "Loss in iteration no. 74698 ==> 0.44316750104575675\n",
            "Loss in iteration no. 74699 ==> 0.4431662037679452\n",
            "Loss in iteration no. 74700 ==> 0.4431649065101052\n",
            "Loss in iteration no. 74701 ==> 0.4431636092722363\n",
            "Loss in iteration no. 74702 ==> 0.44316231205433815\n",
            "Loss in iteration no. 74703 ==> 0.4431610148564103\n",
            "Loss in iteration no. 74704 ==> 0.44315971767845236\n",
            "Loss in iteration no. 74705 ==> 0.44315842052046367\n",
            "Loss in iteration no. 74706 ==> 0.443157123382444\n",
            "Loss in iteration no. 74707 ==> 0.4431558262643927\n",
            "Loss in iteration no. 74708 ==> 0.44315452916630965\n",
            "Loss in iteration no. 74709 ==> 0.4431532320881943\n",
            "Loss in iteration no. 74710 ==> 0.4431519350300461\n",
            "Loss in iteration no. 74711 ==> 0.44315063799186477\n",
            "Loss in iteration no. 74712 ==> 0.4431493409736498\n",
            "Loss in iteration no. 74713 ==> 0.44314804397540064\n",
            "Loss in iteration no. 74714 ==> 0.4431467469971171\n",
            "Loss in iteration no. 74715 ==> 0.44314545003879846\n",
            "Loss in iteration no. 74716 ==> 0.4431441531004445\n",
            "Loss in iteration no. 74717 ==> 0.4431428561820547\n",
            "Loss in iteration no. 74718 ==> 0.4431415592836287\n",
            "Loss in iteration no. 74719 ==> 0.4431402624051661\n",
            "Loss in iteration no. 74720 ==> 0.4431389655466663\n",
            "Loss in iteration no. 74721 ==> 0.443137668708129\n",
            "Loss in iteration no. 74722 ==> 0.4431363718895537\n",
            "Loss in iteration no. 74723 ==> 0.4431350750909399\n",
            "Loss in iteration no. 74724 ==> 0.44313377831228723\n",
            "Loss in iteration no. 74725 ==> 0.4431324815535954\n",
            "Loss in iteration no. 74726 ==> 0.4431311848148638\n",
            "Loss in iteration no. 74727 ==> 0.443129888096092\n",
            "Loss in iteration no. 74728 ==> 0.44312859139727967\n",
            "Loss in iteration no. 74729 ==> 0.44312729471842627\n",
            "Loss in iteration no. 74730 ==> 0.4431259980595315\n",
            "Loss in iteration no. 74731 ==> 0.4431247014205948\n",
            "Loss in iteration no. 74732 ==> 0.4431234048016158\n",
            "Loss in iteration no. 74733 ==> 0.443122108202594\n",
            "Loss in iteration no. 74734 ==> 0.443120811623529\n",
            "Loss in iteration no. 74735 ==> 0.4431195150644204\n",
            "Loss in iteration no. 74736 ==> 0.4431182185252677\n",
            "Loss in iteration no. 74737 ==> 0.4431169220060705\n",
            "Loss in iteration no. 74738 ==> 0.44311562550682837\n",
            "Loss in iteration no. 74739 ==> 0.44311432902754094\n",
            "Loss in iteration no. 74740 ==> 0.4431130325682077\n",
            "Loss in iteration no. 74741 ==> 0.44311173612882826\n",
            "Loss in iteration no. 74742 ==> 0.4431104397094021\n",
            "Loss in iteration no. 74743 ==> 0.44310914330992884\n",
            "Loss in iteration no. 74744 ==> 0.4431078469304081\n",
            "Loss in iteration no. 74745 ==> 0.4431065505708393\n",
            "Loss in iteration no. 74746 ==> 0.4431052542312223\n",
            "Loss in iteration no. 74747 ==> 0.44310395791155627\n",
            "Loss in iteration no. 74748 ==> 0.443102661611841\n",
            "Loss in iteration no. 74749 ==> 0.44310136533207606\n",
            "Loss in iteration no. 74750 ==> 0.443100069072261\n",
            "Loss in iteration no. 74751 ==> 0.4430987728323954\n",
            "Loss in iteration no. 74752 ==> 0.4430974766124787\n",
            "Loss in iteration no. 74753 ==> 0.4430961804125107\n",
            "Loss in iteration no. 74754 ==> 0.44309488423249066\n",
            "Loss in iteration no. 74755 ==> 0.4430935880724185\n",
            "Loss in iteration no. 74756 ==> 0.44309229193229355\n",
            "Loss in iteration no. 74757 ==> 0.4430909958121154\n",
            "Loss in iteration no. 74758 ==> 0.4430896997118836\n",
            "Loss in iteration no. 74759 ==> 0.44308840363159785\n",
            "Loss in iteration no. 74760 ==> 0.4430871075712577\n",
            "Loss in iteration no. 74761 ==> 0.44308581153086246\n",
            "Loss in iteration no. 74762 ==> 0.4430845155104119\n",
            "Loss in iteration no. 74763 ==> 0.4430832195099057\n",
            "Loss in iteration no. 74764 ==> 0.4430819235293433\n",
            "Loss in iteration no. 74765 ==> 0.4430806275687241\n",
            "Loss in iteration no. 74766 ==> 0.4430793316280479\n",
            "Loss in iteration no. 74767 ==> 0.4430780357073142\n",
            "Loss in iteration no. 74768 ==> 0.4430767398065227\n",
            "Loss in iteration no. 74769 ==> 0.4430754439256726\n",
            "Loss in iteration no. 74770 ==> 0.4430741480647639\n",
            "Loss in iteration no. 74771 ==> 0.4430728522237958\n",
            "Loss in iteration no. 74772 ==> 0.44307155640276813\n",
            "Loss in iteration no. 74773 ==> 0.44307026060168025\n",
            "Loss in iteration no. 74774 ==> 0.44306896482053193\n",
            "Loss in iteration no. 74775 ==> 0.4430676690593226\n",
            "Loss in iteration no. 74776 ==> 0.44306637331805176\n",
            "Loss in iteration no. 74777 ==> 0.44306507759671937\n",
            "Loss in iteration no. 74778 ==> 0.4430637818953244\n",
            "Loss in iteration no. 74779 ==> 0.4430624862138669\n",
            "Loss in iteration no. 74780 ==> 0.44306119055234616\n",
            "Loss in iteration no. 74781 ==> 0.4430598949107618\n",
            "Loss in iteration no. 74782 ==> 0.4430585992891137\n",
            "Loss in iteration no. 74783 ==> 0.44305730368740087\n",
            "Loss in iteration no. 74784 ==> 0.44305600810562334\n",
            "Loss in iteration no. 74785 ==> 0.4430547125437804\n",
            "Loss in iteration no. 74786 ==> 0.4430534170018718\n",
            "Loss in iteration no. 74787 ==> 0.443052121479897\n",
            "Loss in iteration no. 74788 ==> 0.44305082597785556\n",
            "Loss in iteration no. 74789 ==> 0.44304953049574713\n",
            "Loss in iteration no. 74790 ==> 0.44304823503357116\n",
            "Loss in iteration no. 74791 ==> 0.44304693959132735\n",
            "Loss in iteration no. 74792 ==> 0.4430456441690152\n",
            "Loss in iteration no. 74793 ==> 0.4430443487666342\n",
            "Loss in iteration no. 74794 ==> 0.4430430533841841\n",
            "Loss in iteration no. 74795 ==> 0.4430417580216642\n",
            "Loss in iteration no. 74796 ==> 0.44304046267907443\n",
            "Loss in iteration no. 74797 ==> 0.44303916735641397\n",
            "Loss in iteration no. 74798 ==> 0.4430378720536827\n",
            "Loss in iteration no. 74799 ==> 0.4430365767708801\n",
            "Loss in iteration no. 74800 ==> 0.44303528150800553\n",
            "Loss in iteration no. 74801 ==> 0.44303398626505885\n",
            "Loss in iteration no. 74802 ==> 0.44303269104203946\n",
            "Loss in iteration no. 74803 ==> 0.4430313958389469\n",
            "Loss in iteration no. 74804 ==> 0.44303010065578097"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss in iteration no. 96755 ==> 0.4187399333160055\n",
            "Loss in iteration no. 96756 ==> 0.418738989324184\n",
            "Loss in iteration no. 96757 ==> 0.41873804534511927\n",
            "Loss in iteration no. 96758 ==> 0.41873710137881104\n",
            "Loss in iteration no. 96759 ==> 0.4187361574252589\n",
            "Loss in iteration no. 96760 ==> 0.41873521348446274\n",
            "Loss in iteration no. 96761 ==> 0.4187342695564224\n",
            "Loss in iteration no. 96762 ==> 0.4187333256411375\n",
            "Loss in iteration no. 96763 ==> 0.4187323817386078\n",
            "Loss in iteration no. 96764 ==> 0.41873143784883315\n",
            "Loss in iteration no. 96765 ==> 0.4187304939718132\n",
            "Loss in iteration no. 96766 ==> 0.4187295501075478\n",
            "Loss in iteration no. 96767 ==> 0.41872860625603664\n",
            "Loss in iteration no. 96768 ==> 0.4187276624172795\n",
            "Loss in iteration no. 96769 ==> 0.4187267185912761\n",
            "Loss in iteration no. 96770 ==> 0.41872577477802625\n",
            "Loss in iteration no. 96771 ==> 0.41872483097752977\n",
            "Loss in iteration no. 96772 ==> 0.41872388718978626\n",
            "Loss in iteration no. 96773 ==> 0.41872294341479555\n",
            "Loss in iteration no. 96774 ==> 0.41872199965255735\n",
            "Loss in iteration no. 96775 ==> 0.41872105590307157\n",
            "Loss in iteration no. 96776 ==> 0.41872011216633787\n",
            "Loss in iteration no. 96777 ==> 0.41871916844235596\n",
            "Loss in iteration no. 96778 ==> 0.41871822473112563\n",
            "Loss in iteration no. 96779 ==> 0.4187172810326466\n",
            "Loss in iteration no. 96780 ==> 0.4187163373469188\n",
            "Loss in iteration no. 96781 ==> 0.4187153936739417\n",
            "Loss in iteration no. 96782 ==> 0.4187144500137154\n",
            "Loss in iteration no. 96783 ==> 0.4187135063662394\n",
            "Loss in iteration no. 96784 ==> 0.4187125627315135\n",
            "Loss in iteration no. 96785 ==> 0.4187116191095376\n",
            "Loss in iteration no. 96786 ==> 0.41871067550031116\n",
            "Loss in iteration no. 96787 ==> 0.41870973190383415\n",
            "Loss in iteration no. 96788 ==> 0.41870878832010644\n",
            "Loss in iteration no. 96789 ==> 0.4187078447491276\n",
            "Loss in iteration no. 96790 ==> 0.4187069011908974\n",
            "Loss in iteration no. 96791 ==> 0.4187059576454156\n",
            "Loss in iteration no. 96792 ==> 0.418705014112682\n",
            "Loss in iteration no. 96793 ==> 0.41870407059269643\n",
            "Loss in iteration no. 96794 ==> 0.4187031270854585\n",
            "Loss in iteration no. 96795 ==> 0.418702183590968\n",
            "Loss in iteration no. 96796 ==> 0.41870124010922477\n",
            "Loss in iteration no. 96797 ==> 0.41870029664022845\n",
            "Loss in iteration no. 96798 ==> 0.41869935318397894\n",
            "Loss in iteration no. 96799 ==> 0.4186984097404759\n",
            "Loss in iteration no. 96800 ==> 0.41869746630971905\n",
            "Loss in iteration no. 96801 ==> 0.4186965228917083\n",
            "Loss in iteration no. 96802 ==> 0.4186955794864432\n",
            "Loss in iteration no. 96803 ==> 0.4186946360939237\n",
            "Loss in iteration no. 96804 ==> 0.41869369271414947\n",
            "Loss in iteration no. 96805 ==> 0.4186927493471202\n",
            "Loss in iteration no. 96806 ==> 0.41869180599283573\n",
            "Loss in iteration no. 96807 ==> 0.4186908626512959\n",
            "Loss in iteration no. 96808 ==> 0.41868991932250027\n",
            "Loss in iteration no. 96809 ==> 0.4186889760064487\n",
            "Loss in iteration no. 96810 ==> 0.41868803270314103\n",
            "Loss in iteration no. 96811 ==> 0.4186870894125769\n",
            "Loss in iteration no. 96812 ==> 0.418686146134756\n",
            "Loss in iteration no. 96813 ==> 0.41868520286967836\n",
            "Loss in iteration no. 96814 ==> 0.41868425961734346\n",
            "Loss in iteration no. 96815 ==> 0.41868331637775114\n",
            "Loss in iteration no. 96816 ==> 0.41868237315090123\n",
            "Loss in iteration no. 96817 ==> 0.41868142993679347\n",
            "Loss in iteration no. 96818 ==> 0.41868048673542757\n",
            "Loss in iteration no. 96819 ==> 0.41867954354680326\n",
            "Loss in iteration no. 96820 ==> 0.4186786003709203\n",
            "Loss in iteration no. 96821 ==> 0.4186776572077785\n",
            "Loss in iteration no. 96822 ==> 0.4186767140573778\n",
            "Loss in iteration no. 96823 ==> 0.41867577091971747\n",
            "Loss in iteration no. 96824 ==> 0.41867482779479775\n",
            "Loss in iteration no. 96825 ==> 0.41867388468261807\n",
            "Loss in iteration no. 96826 ==> 0.41867294158317847\n",
            "Loss in iteration no. 96827 ==> 0.41867199849647846\n",
            "Loss in iteration no. 96828 ==> 0.418671055422518\n",
            "Loss in iteration no. 96829 ==> 0.4186701123612966\n",
            "Loss in iteration no. 96830 ==> 0.41866916931281417\n",
            "Loss in iteration no. 96831 ==> 0.4186682262770705\n",
            "Loss in iteration no. 96832 ==> 0.4186672832540654\n",
            "Loss in iteration no. 96833 ==> 0.4186663402437985\n",
            "Loss in iteration no. 96834 ==> 0.4186653972462695\n",
            "Loss in iteration no. 96835 ==> 0.41866445426147825\n",
            "Loss in iteration no. 96836 ==> 0.41866351128942464\n",
            "Loss in iteration no. 96837 ==> 0.4186625683301082\n",
            "Loss in iteration no. 96838 ==> 0.4186616253835287\n",
            "Loss in iteration no. 96839 ==> 0.4186606824496861\n",
            "Loss in iteration no. 96840 ==> 0.41865973952858004\n",
            "Loss in iteration no. 96841 ==> 0.4186587966202102\n",
            "Loss in iteration no. 96842 ==> 0.4186578537245765\n",
            "Loss in iteration no. 96843 ==> 0.41865691084167844\n",
            "Loss in iteration no. 96844 ==> 0.4186559679715161\n",
            "Loss in iteration no. 96845 ==> 0.41865502511408903\n",
            "Loss in iteration no. 96846 ==> 0.41865408226939704\n",
            "Loss in iteration no. 96847 ==> 0.4186531394374399\n",
            "Loss in iteration no. 96848 ==> 0.41865219661821734\n",
            "Loss in iteration no. 96849 ==> 0.41865125381172913\n",
            "Loss in iteration no. 96850 ==> 0.418650311017975\n",
            "Loss in iteration no. 96851 ==> 0.41864936823695476\n",
            "Loss in iteration no. 96852 ==> 0.4186484254686682\n",
            "Loss in iteration no. 96853 ==> 0.41864748271311497\n",
            "Loss in iteration no. 96854 ==> 0.4186465399702949\n",
            "Loss in iteration no. 96855 ==> 0.4186455972402077\n",
            "Loss in iteration no. 96856 ==> 0.41864465452285315\n",
            "Loss in iteration no. 96857 ==> 0.418643711818231\n",
            "Loss in iteration no. 96858 ==> 0.4186427691263411\n",
            "Loss in iteration no. 96859 ==> 0.418641826447183\n",
            "Loss in iteration no. 96860 ==> 0.41864088378075676\n",
            "Loss in iteration no. 96861 ==> 0.41863994112706177\n",
            "Loss in iteration no. 96862 ==> 0.4186389984860981\n",
            "Loss in iteration no. 96863 ==> 0.4186380558578653\n",
            "Loss in iteration no. 96864 ==> 0.41863711324236325\n",
            "Loss in iteration no. 96865 ==> 0.4186361706395917\n",
            "Loss in iteration no. 96866 ==> 0.4186352280495504\n",
            "Loss in iteration no. 96867 ==> 0.418634285472239\n",
            "Loss in iteration no. 96868 ==> 0.41863334290765736\n",
            "Loss in iteration no. 96869 ==> 0.4186324003558053\n",
            "Loss in iteration no. 96870 ==> 0.4186314578166824\n",
            "Loss in iteration no. 96871 ==> 0.41863051529028855\n",
            "Loss in iteration no. 96872 ==> 0.41862957277662344\n",
            "Loss in iteration no. 96873 ==> 0.418628630275687\n",
            "Loss in iteration no. 96874 ==> 0.4186276877874787\n",
            "Loss in iteration no. 96875 ==> 0.4186267453119985\n",
            "Loss in iteration no. 96876 ==> 0.4186258028492461\n",
            "Loss in iteration no. 96877 ==> 0.41862486039922125\n",
            "Loss in iteration no. 96878 ==> 0.4186239179619238\n",
            "Loss in iteration no. 96879 ==> 0.4186229755373533\n",
            "Loss in iteration no. 96880 ==> 0.4186220331255097\n",
            "Loss in iteration no. 96881 ==> 0.41862109072639275\n",
            "Loss in iteration no. 96882 ==> 0.41862014834000205\n",
            "Loss in iteration no. 96883 ==> 0.41861920596633745\n",
            "Loss in iteration no. 96884 ==> 0.4186182636053988\n",
            "Loss in iteration no. 96885 ==> 0.41861732125718576\n",
            "Loss in iteration no. 96886 ==> 0.41861637892169806\n",
            "Loss in iteration no. 96887 ==> 0.41861543659893546\n",
            "Loss in iteration no. 96888 ==> 0.4186144942888978\n",
            "Loss in iteration no. 96889 ==> 0.4186135519915848\n",
            "Loss in iteration no. 96890 ==> 0.41861260970699626\n",
            "Loss in iteration no. 96891 ==> 0.4186116674351318\n",
            "Loss in iteration no. 96892 ==> 0.41861072517599135\n",
            "Loss in iteration no. 96893 ==> 0.4186097829295745\n",
            "Loss in iteration no. 96894 ==> 0.4186088406958811\n",
            "Loss in iteration no. 96895 ==> 0.4186078984749109\n",
            "Loss in iteration no. 96896 ==> 0.4186069562666637\n",
            "Loss in iteration no. 96897 ==> 0.4186060140711392\n",
            "Loss in iteration no. 96898 ==> 0.4186050718883372\n",
            "Loss in iteration no. 96899 ==> 0.41860412971825733\n",
            "Loss in iteration no. 96900 ==> 0.4186031875608996\n",
            "Loss in iteration no. 96901 ==> 0.4186022454162634\n",
            "Loss in iteration no. 96902 ==> 0.4186013032843489\n",
            "Loss in iteration no. 96903 ==> 0.4186003611651556\n",
            "Loss in iteration no. 96904 ==> 0.41859941905868325\n",
            "Loss in iteration no. 96905 ==> 0.4185984769649318\n",
            "Loss in iteration no. 96906 ==> 0.41859753488390083\n",
            "Loss in iteration no. 96907 ==> 0.41859659281559014\n",
            "Loss in iteration no. 96908 ==> 0.41859565075999944\n",
            "Loss in iteration no. 96909 ==> 0.4185947087171286\n",
            "Loss in iteration no. 96910 ==> 0.41859376668697734\n",
            "Loss in iteration no. 96911 ==> 0.41859282466954545\n",
            "Loss in iteration no. 96912 ==> 0.41859188266483255\n",
            "Loss in iteration no. 96913 ==> 0.41859094067283853\n",
            "Loss in iteration no. 96914 ==> 0.4185899986935631\n",
            "Loss in iteration no. 96915 ==> 0.418589056727006\n",
            "Loss in iteration no. 96916 ==> 0.41858811477316715\n",
            "Loss in iteration no. 96917 ==> 0.418587172832046\n",
            "Loss in iteration no. 96918 ==> 0.4185862309036426\n",
            "Loss in iteration no. 96919 ==> 0.41858528898795644\n",
            "Loss in iteration no. 96920 ==> 0.4185843470849875\n",
            "Loss in iteration no. 96921 ==> 0.41858340519473547\n",
            "Loss in iteration no. 96922 ==> 0.4185824633172\n",
            "Loss in iteration no. 96923 ==> 0.41858152145238103\n",
            "Loss in iteration no. 96924 ==> 0.4185805796002783\n",
            "Loss in iteration no. 96925 ==> 0.4185796377608915\n",
            "Loss in iteration no. 96926 ==> 0.41857869593422026\n",
            "Loss in iteration no. 96927 ==> 0.4185777541202646\n",
            "Loss in iteration no. 96928 ==> 0.41857681231902405\n",
            "Loss in iteration no. 96929 ==> 0.41857587053049855\n",
            "Loss in iteration no. 96930 ==> 0.4185749287546877\n",
            "Loss in iteration no. 96931 ==> 0.4185739869915914\n",
            "Loss in iteration no. 96932 ==> 0.41857304524120925\n",
            "Loss in iteration no. 96933 ==> 0.4185721035035411\n",
            "Loss in iteration no. 96934 ==> 0.4185711617785867\n",
            "Loss in iteration no. 96935 ==> 0.41857022006634587\n",
            "Loss in iteration no. 96936 ==> 0.41856927836681834\n",
            "Loss in iteration no. 96937 ==> 0.41856833668000376\n",
            "Loss in iteration no. 96938 ==> 0.418567395005902\n",
            "Loss in iteration no. 96939 ==> 0.41856645334451276\n",
            "Loss in iteration no. 96940 ==> 0.41856551169583583\n",
            "Loss in iteration no. 96941 ==> 0.41856457005987097\n",
            "Loss in iteration no. 96942 ==> 0.418563628436618\n",
            "Loss in iteration no. 96943 ==> 0.41856268682607645\n",
            "Loss in iteration no. 96944 ==> 0.4185617452282464\n",
            "Loss in iteration no. 96945 ==> 0.41856080364312725\n",
            "Loss in iteration no. 96946 ==> 0.4185598620707191\n",
            "Loss in iteration no. 96947 ==> 0.4185589205110215\n",
            "Loss in iteration no. 96948 ==> 0.41855797896403424\n",
            "Loss in iteration no. 96949 ==> 0.4185570374297572\n",
            "Loss in iteration no. 96950 ==> 0.41855609590819\n",
            "Loss in iteration no. 96951 ==> 0.41855515439933233\n",
            "Loss in iteration no. 96952 ==> 0.4185542129031842\n",
            "Loss in iteration no. 96953 ==> 0.41855327141974513\n",
            "Loss in iteration no. 96954 ==> 0.418552329949015\n",
            "Loss in iteration no. 96955 ==> 0.41855138849099355\n",
            "Loss in iteration no. 96956 ==> 0.41855044704568056\n",
            "Loss in iteration no. 96957 ==> 0.41854950561307575\n",
            "Loss in iteration no. 96958 ==> 0.4185485641931788\n",
            "Loss in iteration no. 96959 ==> 0.4185476227859896\n",
            "Loss in iteration no. 96960 ==> 0.41854668139150786\n",
            "Loss in iteration no. 96961 ==> 0.41854574000973344\n",
            "Loss in iteration no. 96962 ==> 0.4185447986406659\n",
            "Loss in iteration no. 96963 ==> 0.4185438572843051\n",
            "Loss in iteration no. 96964 ==> 0.4185429159406508\n",
            "Loss in iteration no. 96965 ==> 0.4185419746097027\n",
            "Loss in iteration no. 96966 ==> 0.4185410332914607\n",
            "Loss in iteration no. 96967 ==> 0.41854009198592446\n",
            "Loss in iteration no. 96968 ==> 0.41853915069309366\n",
            "Loss in iteration no. 96969 ==> 0.41853820941296827\n",
            "Loss in iteration no. 96970 ==> 0.41853726814554776\n",
            "Loss in iteration no. 96971 ==> 0.4185363268908322\n",
            "Loss in iteration no. 96972 ==> 0.4185353856488211\n",
            "Loss in iteration no. 96973 ==> 0.41853444441951443\n",
            "Loss in iteration no. 96974 ==> 0.41853350320291177\n",
            "Loss in iteration no. 96975 ==> 0.4185325619990129\n",
            "Loss in iteration no. 96976 ==> 0.41853162080781764\n",
            "Loss in iteration no. 96977 ==> 0.4185306796293258\n",
            "Loss in iteration no. 96978 ==> 0.418529738463537\n",
            "Loss in iteration no. 96979 ==> 0.41852879731045106\n",
            "Loss in iteration no. 96980 ==> 0.41852785617006777\n",
            "Loss in iteration no. 96981 ==> 0.4185269150423869\n",
            "Loss in iteration no. 96982 ==> 0.4185259739274081\n",
            "Loss in iteration no. 96983 ==> 0.4185250328251312\n",
            "Loss in iteration no. 96984 ==> 0.41852409173555605\n",
            "Loss in iteration no. 96985 ==> 0.4185231506586822\n",
            "Loss in iteration no. 96986 ==> 0.4185222095945095\n",
            "Loss in iteration no. 96987 ==> 0.41852126854303784\n",
            "Loss in iteration no. 96988 ==> 0.41852032750426693\n",
            "Loss in iteration no. 96989 ==> 0.41851938647819625\n",
            "Loss in iteration no. 96990 ==> 0.41851844546482597\n",
            "Loss in iteration no. 96991 ==> 0.4185175044641556\n",
            "Loss in iteration no. 96992 ==> 0.41851656347618493\n",
            "Loss in iteration no. 96993 ==> 0.41851562250091373\n",
            "Loss in iteration no. 96994 ==> 0.4185146815383418\n",
            "Loss in iteration no. 96995 ==> 0.41851374058846885\n",
            "Loss in iteration no. 96996 ==> 0.4185127996512947\n",
            "Loss in iteration no. 96997 ==> 0.418511858726819\n",
            "Loss in iteration no. 96998 ==> 0.41851091781504157\n",
            "Loss in iteration no. 96999 ==> 0.4185099769159622\n",
            "Loss in iteration no. 97000 ==> 0.41850903602958067\n",
            "Loss in iteration no. 97001 ==> 0.41850809515589654\n",
            "Loss in iteration no. 97002 ==> 0.41850715429490987\n",
            "Loss in iteration no. 97003 ==> 0.41850621344662026\n",
            "Loss in iteration no. 97004 ==> 0.4185052726110274\n",
            "Loss in iteration no. 97005 ==> 0.418504331788131\n",
            "Loss in iteration no. 97006 ==> 0.4185033909779311\n",
            "Loss in iteration no. 97007 ==> 0.41850245018042737\n",
            "Loss in iteration no. 97008 ==> 0.4185015093956194\n",
            "Loss in iteration no. 97009 ==> 0.418500568623507\n",
            "Loss in iteration no. 97010 ==> 0.41849962786409006\n",
            "Loss in iteration no. 97011 ==> 0.41849868711736815\n",
            "Loss in iteration no. 97012 ==> 0.4184977463833412\n",
            "Loss in iteration no. 97013 ==> 0.41849680566200886\n",
            "Loss in iteration no. 97014 ==> 0.418495864953371\n",
            "Loss in iteration no. 97015 ==> 0.4184949242574272\n",
            "Loss in iteration no. 97016 ==> 0.4184939835741774\n",
            "Loss in iteration no. 97017 ==> 0.4184930429036212\n",
            "Loss in iteration no. 97018 ==> 0.41849210224575856\n",
            "Loss in iteration no. 97019 ==> 0.418491161600589\n",
            "Loss in iteration no. 97020 ==> 0.41849022096811245\n",
            "Loss in iteration no. 97021 ==> 0.4184892803483286\n",
            "Loss in iteration no. 97022 ==> 0.4184883397412373\n",
            "Loss in iteration no. 97023 ==> 0.41848739914683813\n",
            "Loss in iteration no. 97024 ==> 0.418486458565131\n",
            "Loss in iteration no. 97025 ==> 0.41848551799611566\n",
            "Loss in iteration no. 97026 ==> 0.4184845774397917\n",
            "Loss in iteration no. 97027 ==> 0.41848363689615914\n",
            "Loss in iteration no. 97028 ==> 0.4184826963652175\n",
            "Loss in iteration no. 97029 ==> 0.41848175584696673\n",
            "Loss in iteration no. 97030 ==> 0.41848081534140646\n",
            "Loss in iteration no. 97031 ==> 0.4184798748485365\n",
            "Loss in iteration no. 97032 ==> 0.4184789343683566\n",
            "Loss in iteration no. 97033 ==> 0.4184779939008665\n",
            "Loss in iteration no. 97034 ==> 0.418477053446066\n",
            "Loss in iteration no. 97035 ==> 0.4184761130039548\n",
            "Loss in iteration no. 97036 ==> 0.41847517257453265\n",
            "Loss in iteration no. 97037 ==> 0.41847423215779944\n",
            "Loss in iteration no. 97038 ==> 0.4184732917537548\n",
            "Loss in iteration no. 97039 ==> 0.41847235136239863\n",
            "Loss in iteration no. 97040 ==> 0.4184714109837305\n",
            "Loss in iteration no. 97041 ==> 0.41847047061775017\n",
            "Loss in iteration no. 97042 ==> 0.41846953026445755\n",
            "Loss in iteration no. 97043 ==> 0.4184685899238524\n",
            "Loss in iteration no. 97044 ==> 0.41846764959593435\n",
            "Loss in iteration no. 97045 ==> 0.4184667092807032\n",
            "Loss in iteration no. 97046 ==> 0.41846576897815874\n",
            "Loss in iteration no. 97047 ==> 0.41846482868830076\n",
            "Loss in iteration no. 97048 ==> 0.4184638884111289\n",
            "Loss in iteration no. 97049 ==> 0.41846294814664303\n",
            "Loss in iteration no. 97050 ==> 0.4184620078948429\n",
            "Loss in iteration no. 97051 ==> 0.4184610676557282\n",
            "Loss in iteration no. 97052 ==> 0.4184601274292987\n",
            "Loss in iteration no. 97053 ==> 0.4184591872155543\n",
            "Loss in iteration no. 97054 ==> 0.4184582470144946\n",
            "Loss in iteration no. 97055 ==> 0.41845730682611937\n",
            "Loss in iteration no. 97056 ==> 0.41845636665042835\n",
            "Loss in iteration no. 97057 ==> 0.41845542648742146\n",
            "Loss in iteration no. 97058 ==> 0.4184544863370983\n",
            "Loss in iteration no. 97059 ==> 0.41845354619945874\n",
            "Loss in iteration no. 97060 ==> 0.4184526060745024\n",
            "Loss in iteration no. 97061 ==> 0.4184516659622291\n",
            "Loss in iteration no. 97062 ==> 0.41845072586263865\n",
            "Loss in iteration no. 97063 ==> 0.41844978577573083\n",
            "Loss in iteration no. 97064 ==> 0.4184488457015053\n",
            "Loss in iteration no. 97065 ==> 0.41844790563996187\n",
            "Loss in iteration no. 97066 ==> 0.4184469655911003\n",
            "Loss in iteration no. 97067 ==> 0.41844602555492033\n",
            "Loss in iteration no. 97068 ==> 0.4184450855314216\n",
            "Loss in iteration no. 97069 ==> 0.4184441455206042\n",
            "Loss in iteration no. 97070 ==> 0.4184432055224676\n",
            "Loss in iteration no. 97071 ==> 0.4184422655370117\n",
            "Loss in iteration no. 97072 ==> 0.41844132556423613\n",
            "Loss in iteration no. 97073 ==> 0.41844038560414076\n",
            "Loss in iteration no. 97074 ==> 0.41843944565672536\n",
            "Loss in iteration no. 97075 ==> 0.41843850572198954\n",
            "Loss in iteration no. 97076 ==> 0.41843756579993313\n",
            "Loss in iteration no. 97077 ==> 0.418436625890556\n",
            "Loss in iteration no. 97078 ==> 0.4184356859938578\n",
            "Loss in iteration no. 97079 ==> 0.4184347461098383\n",
            "Loss in iteration no. 97080 ==> 0.4184338062384973\n",
            "Loss in iteration no. 97081 ==> 0.4184328663798345\n",
            "Loss in iteration no. 97082 ==> 0.41843192653384975\n",
            "Loss in iteration no. 97083 ==> 0.41843098670054274\n",
            "Loss in iteration no. 97084 ==> 0.4184300468799132\n",
            "Loss in iteration no. 97085 ==> 0.41842910707196096\n",
            "Loss in iteration no. 97086 ==> 0.41842816727668575\n",
            "Loss in iteration no. 97087 ==> 0.41842722749408723\n",
            "Loss in iteration no. 97088 ==> 0.41842628772416535\n",
            "Loss in iteration no. 97089 ==> 0.41842534796691977\n",
            "Loss in iteration no. 97090 ==> 0.4184244082223502\n",
            "Loss in iteration no. 97091 ==> 0.4184234684904565\n",
            "Loss in iteration no. 97092 ==> 0.4184225287712383\n",
            "Loss in iteration no. 97093 ==> 0.4184215890646955\n",
            "Loss in iteration no. 97094 ==> 0.41842064937082785\n",
            "Loss in iteration no. 97095 ==> 0.4184197096896349\n",
            "Loss in iteration no. 97096 ==> 0.41841877002111666\n",
            "Loss in iteration no. 97097 ==> 0.41841783036527286\n",
            "Loss in iteration no. 97098 ==> 0.4184168907221031\n",
            "Loss in iteration no. 97099 ==> 0.41841595109160723\n",
            "Loss in iteration no. 97100 ==> 0.41841501147378507\n",
            "Loss in iteration no. 97101 ==> 0.4184140718686363\n",
            "Loss in iteration no. 97102 ==> 0.41841313227616067\n",
            "Loss in iteration no. 97103 ==> 0.418412192696358\n",
            "Loss in iteration no. 97104 ==> 0.41841125312922794\n",
            "Loss in iteration no. 97105 ==> 0.4184103135747704\n",
            "Loss in iteration no. 97106 ==> 0.41840937403298506\n",
            "Loss in iteration no. 97107 ==> 0.4184084345038716\n",
            "Loss in iteration no. 97108 ==> 0.41840749498742996\n",
            "Loss in iteration no. 97109 ==> 0.41840655548365985\n",
            "Loss in iteration no. 97110 ==> 0.41840561599256076\n",
            "Loss in iteration no. 97111 ==> 0.4184046765141329\n",
            "Loss in iteration no. 97112 ==> 0.41840373704837563\n",
            "Loss in iteration no. 97113 ==> 0.418402797595289\n",
            "Loss in iteration no. 97114 ==> 0.4184018581548726\n",
            "Loss in iteration no. 97115 ==> 0.41840091872712615\n",
            "Loss in iteration no. 97116 ==> 0.4183999793120496\n",
            "Loss in iteration no. 97117 ==> 0.41839903990964256\n",
            "Loss in iteration no. 97118 ==> 0.41839810051990484\n",
            "Loss in iteration no. 97119 ==> 0.4183971611428362\n",
            "Loss in iteration no. 97120 ==> 0.41839622177843644\n",
            "Loss in iteration no. 97121 ==> 0.41839528242670515\n",
            "Loss in iteration no. 97122 ==> 0.41839434308764223\n",
            "Loss in iteration no. 97123 ==> 0.4183934037612474\n",
            "Loss in iteration no. 97124 ==> 0.4183924644475206\n",
            "Loss in iteration no. 97125 ==> 0.4183915251464612\n",
            "Loss in iteration no. 97126 ==> 0.4183905858580694\n",
            "Loss in iteration no. 97127 ==> 0.4183896465823446\n",
            "Loss in iteration no. 97128 ==> 0.41838870731928673\n",
            "Loss in iteration no. 97129 ==> 0.4183877680688955\n",
            "Loss in iteration no. 97130 ==> 0.41838682883117073\n",
            "Loss in iteration no. 97131 ==> 0.41838588960611217\n",
            "Loss in iteration no. 97132 ==> 0.4183849503937195\n",
            "Loss in iteration no. 97133 ==> 0.41838401119399254\n",
            "Loss in iteration no. 97134 ==> 0.4183830720069311\n",
            "Loss in iteration no. 97135 ==> 0.4183821328325347\n",
            "Loss in iteration no. 97136 ==> 0.41838119367080345\n",
            "Loss in iteration no. 97137 ==> 0.4183802545217368\n",
            "Loss in iteration no. 97138 ==> 0.4183793153853347\n",
            "Loss in iteration no. 97139 ==> 0.41837837626159685\n",
            "Loss in iteration no. 97140 ==> 0.41837743715052306\n",
            "Loss in iteration no. 97141 ==> 0.41837649805211297\n",
            "Loss in iteration no. 97142 ==> 0.41837555896636647\n",
            "Loss in iteration no. 97143 ==> 0.4183746198932833\n",
            "Loss in iteration no. 97144 ==> 0.4183736808328631\n",
            "Loss in iteration no. 97145 ==> 0.41837274178510564\n",
            "Loss in iteration no. 97146 ==> 0.4183718027500108\n",
            "Loss in iteration no. 97147 ==> 0.4183708637275783\n",
            "Loss in iteration no. 97148 ==> 0.41836992471780793\n",
            "Loss in iteration no. 97149 ==> 0.4183689857206993\n",
            "Loss in iteration no. 97150 ==> 0.4183680467362524\n",
            "Loss in iteration no. 97151 ==> 0.41836710776446673\n",
            "Loss in iteration no. 97152 ==> 0.41836616880534216\n",
            "Loss in iteration no. 97153 ==> 0.41836522985887864\n",
            "Loss in iteration no. 97154 ==> 0.41836429092507565\n",
            "Loss in iteration no. 97155 ==> 0.4183633520039331\n",
            "Loss in iteration no. 97156 ==> 0.4183624130954507\n",
            "Loss in iteration no. 97157 ==> 0.41836147419962816\n",
            "Loss in iteration no. 97158 ==> 0.4183605353164653\n",
            "Loss in iteration no. 97159 ==> 0.418359596445962\n",
            "Loss in iteration no. 97160 ==> 0.41835865758811774\n",
            "Loss in iteration no. 97161 ==> 0.4183577187429325\n",
            "Loss in iteration no. 97162 ==> 0.418356779910406\n",
            "Loss in iteration no. 97163 ==> 0.4183558410905379\n",
            "Loss in iteration no. 97164 ==> 0.41835490228332806\n",
            "Loss in iteration no. 97165 ==> 0.4183539634887763\n",
            "Loss in iteration no. 97166 ==> 0.4183530247068822\n",
            "Loss in iteration no. 97167 ==> 0.4183520859376456\n",
            "Loss in iteration no. 97168 ==> 0.41835114718106636\n",
            "Loss in iteration no. 97169 ==> 0.4183502084371441\n",
            "Loss in iteration no. 97170 ==> 0.41834926970587866\n",
            "Loss in iteration no. 97171 ==> 0.41834833098726965\n",
            "Loss in iteration no. 97172 ==> 0.418347392281317\n",
            "Loss in iteration no. 97173 ==> 0.4183464535880205\n",
            "Loss in iteration no. 97174 ==> 0.4183455149073797\n",
            "Loss in iteration no. 97175 ==> 0.4183445762393945\n",
            "Loss in iteration no. 97176 ==> 0.4183436375840648\n",
            "Loss in iteration no. 97177 ==> 0.41834269894139003\n",
            "Loss in iteration no. 97178 ==> 0.41834176031137027\n",
            "Loss in iteration no. 97179 ==> 0.41834082169400494\n",
            "Loss in iteration no. 97180 ==> 0.4183398830892941\n",
            "Loss in iteration no. 97181 ==> 0.41833894449723735\n",
            "Loss in iteration no. 97182 ==> 0.4183380059178346\n",
            "Loss in iteration no. 97183 ==> 0.41833706735108545\n",
            "Loss in iteration no. 97184 ==> 0.4183361287969897\n",
            "Loss in iteration no. 97185 ==> 0.41833519025554716\n",
            "Loss in iteration no. 97186 ==> 0.4183342517267576\n",
            "Loss in iteration no. 97187 ==> 0.41833331321062067\n",
            "Loss in iteration no. 97188 ==> 0.4183323747071362\n",
            "Loss in iteration no. 97189 ==> 0.41833143621630403\n",
            "Loss in iteration no. 97190 ==> 0.41833049773812364\n",
            "Loss in iteration no. 97191 ==> 0.41832955927259524\n",
            "Loss in iteration no. 97192 ==> 0.41832862081971817\n",
            "Loss in iteration no. 97193 ==> 0.41832768237949236\n",
            "Loss in iteration no. 97194 ==> 0.41832674395191755\n",
            "Loss in iteration no. 97195 ==> 0.4183258055369936\n",
            "Loss in iteration no. 97196 ==> 0.41832486713472006\n",
            "Loss in iteration no. 97197 ==> 0.418323928745097\n",
            "Loss in iteration no. 97198 ==> 0.4183229903681238\n",
            "Loss in iteration no. 97199 ==> 0.4183220520038005\n",
            "Loss in iteration no. 97200 ==> 0.41832111365212676\n",
            "Loss in iteration no. 97201 ==> 0.41832017531310234\n",
            "Loss in iteration no. 97202 ==> 0.418319236986727\n",
            "Loss in iteration no. 97203 ==> 0.4183182986730006\n",
            "Loss in iteration no. 97204 ==> 0.4183173603719226\n",
            "Loss in iteration no. 97205 ==> 0.4183164220834932\n",
            "Loss in iteration no. 97206 ==> 0.41831548380771166\n",
            "Loss in iteration no. 97207 ==> 0.41831454554457825\n",
            "Loss in iteration no. 97208 ==> 0.4183136072940924\n",
            "Loss in iteration no. 97209 ==> 0.41831266905625397\n",
            "Loss in iteration no. 97210 ==> 0.4183117308310627\n",
            "Loss in iteration no. 97211 ==> 0.4183107926185183\n",
            "Loss in iteration no. 97212 ==> 0.4183098544186207\n",
            "Loss in iteration no. 97213 ==> 0.41830891623136945\n",
            "Loss in iteration no. 97214 ==> 0.4183079780567644\n",
            "Loss in iteration no. 97215 ==> 0.41830703989480533\n",
            "Loss in iteration no. 97216 ==> 0.418306101745492\n",
            "Loss in iteration no. 97217 ==> 0.41830516360882425\n",
            "Loss in iteration no. 97218 ==> 0.4183042254848016\n",
            "Loss in iteration no. 97219 ==> 0.418303287373424\n",
            "Loss in iteration no. 97220 ==> 0.4183023492746911\n",
            "Loss in iteration no. 97221 ==> 0.41830141118860276\n",
            "Loss in iteration no. 97222 ==> 0.4183004731151587\n",
            "Loss in iteration no. 97223 ==> 0.41829953505435874\n",
            "Loss in iteration no. 97224 ==> 0.4182985970062025\n",
            "Loss in iteration no. 97225 ==> 0.4182976589706898\n",
            "Loss in iteration no. 97226 ==> 0.4182967209478205\n",
            "Loss in iteration no. 97227 ==> 0.41829578293759423\n",
            "Loss in iteration no. 97228 ==> 0.4182948449400108\n",
            "Loss in iteration no. 97229 ==> 0.41829390695507\n",
            "Loss in iteration no. 97230 ==> 0.41829296898277146\n",
            "Loss in iteration no. 97231 ==> 0.41829203102311513\n",
            "Loss in iteration no. 97232 ==> 0.4182910930761007\n",
            "Loss in iteration no. 97233 ==> 0.4182901551417278\n",
            "Loss in iteration no. 97234 ==> 0.41828921721999646\n",
            "Loss in iteration no. 97235 ==> 0.4182882793109062\n",
            "Loss in iteration no. 97236 ==> 0.4182873414144567\n",
            "Loss in iteration no. 97237 ==> 0.418286403530648\n",
            "Loss in iteration no. 97238 ==> 0.41828546565947977\n",
            "Loss in iteration no. 97239 ==> 0.4182845278009517\n",
            "Loss in iteration no. 97240 ==> 0.4182835899550636\n",
            "Loss in iteration no. 97241 ==> 0.41828265212181515\n",
            "Loss in iteration no. 97242 ==> 0.4182817143012063\n",
            "Loss in iteration no. 97243 ==> 0.41828077649323653\n",
            "Loss in iteration no. 97244 ==> 0.4182798386979059\n",
            "Loss in iteration no. 97245 ==> 0.4182789009152139\n",
            "Loss in iteration no. 97246 ==> 0.4182779631451606\n",
            "Loss in iteration no. 97247 ==> 0.41827702538774536\n",
            "Loss in iteration no. 97248 ==> 0.4182760876429682\n",
            "Loss in iteration no. 97249 ==> 0.4182751499108289\n",
            "Loss in iteration no. 97250 ==> 0.4182742121913271\n",
            "Loss in iteration no. 97251 ==> 0.41827327448446255\n",
            "Loss in iteration no. 97252 ==> 0.4182723367902351\n",
            "Loss in iteration no. 97253 ==> 0.41827139910864464\n",
            "Loss in iteration no. 97254 ==> 0.4182704614396907\n",
            "Loss in iteration no. 97255 ==> 0.41826952378337307\n",
            "Loss in iteration no. 97256 ==> 0.41826858613969153\n",
            "Loss in iteration no. 97257 ==> 0.41826764850864584\n",
            "Loss in iteration no. 97258 ==> 0.41826671089023576\n",
            "Loss in iteration no. 97259 ==> 0.41826577328446113\n",
            "Loss in iteration no. 97260 ==> 0.4182648356913217\n",
            "Loss in iteration no. 97261 ==> 0.4182638981108171\n",
            "Loss in iteration no. 97262 ==> 0.41826296054294726\n",
            "Loss in iteration no. 97263 ==> 0.41826202298771176\n",
            "Loss in iteration no. 97264 ==> 0.4182610854451105\n",
            "Loss in iteration no. 97265 ==> 0.41826014791514304\n",
            "Loss in iteration no. 97266 ==> 0.4182592103978095\n",
            "Loss in iteration no. 97267 ==> 0.4182582728931093\n",
            "Loss in iteration no. 97268 ==> 0.41825733540104243\n",
            "Loss in iteration no. 97269 ==> 0.41825639792160846\n",
            "Loss in iteration no. 97270 ==> 0.41825546045480727\n",
            "Loss in iteration no. 97271 ==> 0.41825452300063853\n",
            "Loss in iteration no. 97272 ==> 0.41825358555910214\n",
            "Loss in iteration no. 97273 ==> 0.4182526481301978\n",
            "Loss in iteration no. 97274 ==> 0.4182517107139252\n",
            "Loss in iteration no. 97275 ==> 0.4182507733102841\n",
            "Loss in iteration no. 97276 ==> 0.4182498359192744\n",
            "Loss in iteration no. 97277 ==> 0.4182488985408957\n",
            "Loss in iteration no. 97278 ==> 0.4182479611751479\n",
            "Loss in iteration no. 97279 ==> 0.4182470238220306\n",
            "Loss in iteration no. 97280 ==> 0.41824608648154366\n",
            "Loss in iteration no. 97281 ==> 0.4182451491536868\n",
            "Loss in iteration no. 97282 ==> 0.4182442118384599\n",
            "Loss in iteration no. 97283 ==> 0.41824327453586263\n",
            "Loss in iteration no. 97284 ==> 0.4182423372458947\n",
            "Loss in iteration no. 97285 ==> 0.4182413999685559\n",
            "Loss in iteration no. 97286 ==> 0.418240462703846\n",
            "Loss in iteration no. 97287 ==> 0.41823952545176485\n",
            "Loss in iteration no. 97288 ==> 0.41823858821231213\n",
            "Loss in iteration no. 97289 ==> 0.41823765098548754\n",
            "Loss in iteration no. 97290 ==> 0.4182367137712909\n",
            "Loss in iteration no. 97291 ==> 0.41823577656972194\n",
            "Loss in iteration no. 97292 ==> 0.4182348393807805\n",
            "Loss in iteration no. 97293 ==> 0.4182339022044662\n",
            "Loss in iteration no. 97294 ==> 0.41823296504077895\n",
            "Loss in iteration no. 97295 ==> 0.4182320278897185\n",
            "Loss in iteration no. 97296 ==> 0.4182310907512845\n",
            "Loss in iteration no. 97297 ==> 0.4182301536254768\n",
            "Loss in iteration no. 97298 ==> 0.41822921651229505\n",
            "Loss in iteration no. 97299 ==> 0.4182282794117392\n",
            "Loss in iteration no. 97300 ==> 0.4182273423238088\n",
            "Loss in iteration no. 97301 ==> 0.41822640524850374\n",
            "Loss in iteration no. 97302 ==> 0.41822546818582373\n",
            "Loss in iteration no. 97303 ==> 0.4182245311357687\n",
            "Loss in iteration no. 97304 ==> 0.4182235940983381\n",
            "Loss in iteration no. 97305 ==> 0.41822265707353184\n",
            "Loss in iteration no. 97306 ==> 0.4182217200613497\n",
            "Loss in iteration no. 97307 ==> 0.4182207830617915\n",
            "Loss in iteration no. 97308 ==> 0.4182198460748569\n",
            "Loss in iteration no. 97309 ==> 0.41821890910054565\n",
            "Loss in iteration no. 97310 ==> 0.41821797213885753\n",
            "Loss in iteration no. 97311 ==> 0.4182170351897924\n",
            "Loss in iteration no. 97312 ==> 0.4182160982533499\n",
            "Loss in iteration no. 97313 ==> 0.41821516132952985\n",
            "Loss in iteration no. 97314 ==> 0.41821422441833195\n",
            "Loss in iteration no. 97315 ==> 0.418213287519756\n",
            "Loss in iteration no. 97316 ==> 0.41821235063380185\n",
            "Loss in iteration no. 97317 ==> 0.4182114137604691\n",
            "Loss in iteration no. 97318 ==> 0.4182104768997576\n",
            "Loss in iteration no. 97319 ==> 0.4182095400516671\n",
            "Loss in iteration no. 97320 ==> 0.4182086032161973\n",
            "Loss in iteration no. 97321 ==> 0.418207666393348\n",
            "Loss in iteration no. 97322 ==> 0.418206729583119\n",
            "Loss in iteration no. 97323 ==> 0.41820579278551007\n",
            "Loss in iteration no. 97324 ==> 0.41820485600052093\n",
            "Loss in iteration no. 97325 ==> 0.41820391922815126\n",
            "Loss in iteration no. 97326 ==> 0.418202982468401\n",
            "Loss in iteration no. 97327 ==> 0.41820204572126973\n",
            "Loss in iteration no. 97328 ==> 0.41820110898675733\n",
            "Loss in iteration no. 97329 ==> 0.41820017226486356\n",
            "Loss in iteration no. 97330 ==> 0.4181992355555881\n",
            "Loss in iteration no. 97331 ==> 0.41819829885893073\n",
            "Loss in iteration no. 97332 ==> 0.41819736217489123\n",
            "Loss in iteration no. 97333 ==> 0.41819642550346947\n",
            "Loss in iteration no. 97334 ==> 0.418195488844665\n",
            "Loss in iteration no. 97335 ==> 0.41819455219847773\n",
            "Loss in iteration no. 97336 ==> 0.4181936155649074\n",
            "Loss in iteration no. 97337 ==> 0.4181926789439536\n",
            "Loss in iteration no. 97338 ==> 0.41819174233561646\n",
            "Loss in iteration no. 97339 ==> 0.4181908057398953\n",
            "Loss in iteration no. 97340 ==> 0.41818986915679024\n",
            "Loss in iteration no. 97341 ==> 0.41818893258630085\n",
            "Loss in iteration no. 97342 ==> 0.4181879960284269\n",
            "Loss in iteration no. 97343 ==> 0.41818705948316826\n",
            "Loss in iteration no. 97344 ==> 0.4181861229505246\n",
            "Loss in iteration no. 97345 ==> 0.41818518643049574\n",
            "Loss in iteration no. 97346 ==> 0.4181842499230813\n",
            "Loss in iteration no. 97347 ==> 0.4181833134282812\n",
            "Loss in iteration no. 97348 ==> 0.4181823769460951\n",
            "Loss in iteration no. 97349 ==> 0.41818144047652284\n",
            "Loss in iteration no. 97350 ==> 0.418180504019564\n",
            "Loss in iteration no. 97351 ==> 0.4181795675752187\n",
            "Loss in iteration no. 97352 ==> 0.41817863114348636\n",
            "Loss in iteration no. 97353 ==> 0.4181776947243669\n",
            "Loss in iteration no. 97354 ==> 0.41817675831785994\n",
            "Loss in iteration no. 97355 ==> 0.4181758219239654\n",
            "Loss in iteration no. 97356 ==> 0.41817488554268306\n",
            "Loss in iteration no. 97357 ==> 0.41817394917401246\n",
            "Loss in iteration no. 97358 ==> 0.4181730128179536\n",
            "Loss in iteration no. 97359 ==> 0.4181720764745062\n",
            "Loss in iteration no. 97360 ==> 0.41817114014366985\n",
            "Loss in iteration no. 97361 ==> 0.41817020382544445\n",
            "Loss in iteration no. 97362 ==> 0.4181692675198297\n",
            "Loss in iteration no. 97363 ==> 0.4181683312268255\n",
            "Loss in iteration no. 97364 ==> 0.41816739494643146\n",
            "Loss in iteration no. 97365 ==> 0.4181664586786474\n",
            "Loss in iteration no. 97366 ==> 0.418165522423473\n",
            "Loss in iteration no. 97367 ==> 0.4181645861809081\n",
            "Loss in iteration no. 97368 ==> 0.4181636499509525\n",
            "Loss in iteration no. 97369 ==> 0.41816271373360586\n",
            "Loss in iteration no. 97370 ==> 0.418161777528868\n",
            "Loss in iteration no. 97371 ==> 0.4181608413367387\n",
            "Loss in iteration no. 97372 ==> 0.4181599051572176\n",
            "Loss in iteration no. 97373 ==> 0.4181589689903047\n",
            "Loss in iteration no. 97374 ==> 0.4181580328359994\n",
            "Loss in iteration no. 97375 ==> 0.41815709669430184\n",
            "Loss in iteration no. 97376 ==> 0.41815616056521154\n",
            "Loss in iteration no. 97377 ==> 0.4181552244487284\n",
            "Loss in iteration no. 97378 ==> 0.4181542883448521\n",
            "Loss in iteration no. 97379 ==> 0.41815335225358236\n",
            "Loss in iteration no. 97380 ==> 0.41815241617491905\n",
            "Loss in iteration no. 97381 ==> 0.4181514801088618\n",
            "Loss in iteration no. 97382 ==> 0.4181505440554104\n",
            "Loss in iteration no. 97383 ==> 0.4181496080145648\n",
            "Loss in iteration no. 97384 ==> 0.4181486719863245\n",
            "Loss in iteration no. 97385 ==> 0.41814773597068944\n",
            "Loss in iteration no. 97386 ==> 0.41814679996765935\n",
            "Loss in iteration no. 97387 ==> 0.4181458639772339\n",
            "Loss in iteration no. 97388 ==> 0.41814492799941294\n",
            "Loss in iteration no. 97389 ==> 0.4181439920341961\n",
            "Loss in iteration no. 97390 ==> 0.41814305608158336\n",
            "Loss in iteration no. 97391 ==> 0.4181421201415743\n",
            "Loss in iteration no. 97392 ==> 0.4181411842141688\n",
            "Loss in iteration no. 97393 ==> 0.4181402482993665\n",
            "Loss in iteration no. 97394 ==> 0.4181393123971672\n",
            "Loss in iteration no. 97395 ==> 0.41813837650757074\n",
            "Loss in iteration no. 97396 ==> 0.41813744063057684\n",
            "Loss in iteration no. 97397 ==> 0.4181365047661852\n",
            "Loss in iteration no. 97398 ==> 0.4181355689143956\n",
            "Loss in iteration no. 97399 ==> 0.4181346330752079\n",
            "Loss in iteration no. 97400 ==> 0.4181336972486217\n",
            "Loss in iteration no. 97401 ==> 0.4181327614346369\n",
            "Loss in iteration no. 97402 ==> 0.41813182563325313\n",
            "Loss in iteration no. 97403 ==> 0.4181308898444703\n",
            "Loss in iteration no. 97404 ==> 0.4181299540682881\n",
            "Loss in iteration no. 97405 ==> 0.4181290183047062\n",
            "Loss in iteration no. 97406 ==> 0.4181280825537246\n",
            "Loss in iteration no. 97407 ==> 0.4181271468153428\n",
            "Loss in iteration no. 97408 ==> 0.4181262110895608\n",
            "Loss in iteration no. 97409 ==> 0.418125275376378\n",
            "Loss in iteration no. 97410 ==> 0.4181243396757945\n",
            "Loss in iteration no. 97411 ==> 0.41812340398781006\n",
            "Loss in iteration no. 97412 ==> 0.4181224683124243\n",
            "Loss in iteration no. 97413 ==> 0.41812153264963686\n",
            "Loss in iteration no. 97414 ==> 0.4181205969994478\n",
            "Loss in iteration no. 97415 ==> 0.41811966136185674\n",
            "Loss in iteration no. 97416 ==> 0.4181187257368633\n",
            "Loss in iteration no. 97417 ==> 0.4181177901244676\n",
            "Loss in iteration no. 97418 ==> 0.418116854524669\n",
            "Loss in iteration no. 97419 ==> 0.4181159189374675\n",
            "Loss in iteration no. 97420 ==> 0.41811498336286285\n",
            "Loss in iteration no. 97421 ==> 0.4181140478008547\n",
            "Loss in iteration no. 97422 ==> 0.4181131122514428\n",
            "Loss in iteration no. 97423 ==> 0.418112176714627\n",
            "Loss in iteration no. 97424 ==> 0.41811124119040716\n",
            "Loss in iteration no. 97425 ==> 0.4181103056787828\n",
            "Loss in iteration no. 97426 ==> 0.4181093701797539\n",
            "Loss in iteration no. 97427 ==> 0.41810843469332004\n",
            "Loss in iteration no. 97428 ==> 0.4181074992194811\n",
            "Loss in iteration no. 97429 ==> 0.4181065637582369\n",
            "Loss in iteration no. 97430 ==> 0.41810562830958703\n",
            "Loss in iteration no. 97431 ==> 0.41810469287353136\n",
            "Loss in iteration no. 97432 ==> 0.41810375745006956\n",
            "Loss in iteration no. 97433 ==> 0.41810282203920146\n",
            "Loss in iteration no. 97434 ==> 0.41810188664092685\n",
            "Loss in iteration no. 97435 ==> 0.41810095125524543\n",
            "Loss in iteration no. 97436 ==> 0.418100015882157\n",
            "Loss in iteration no. 97437 ==> 0.4180990805216613\n",
            "Loss in iteration no. 97438 ==> 0.418098145173758\n",
            "Loss in iteration no. 97439 ==> 0.41809720983844706\n",
            "Loss in iteration no. 97440 ==> 0.4180962745157281\n",
            "Loss in iteration no. 97441 ==> 0.418095339205601\n",
            "Loss in iteration no. 97442 ==> 0.41809440390806535\n",
            "Loss in iteration no. 97443 ==> 0.4180934686231211\n",
            "Loss in iteration no. 97444 ==> 0.4180925333507677\n",
            "Loss in iteration no. 97445 ==> 0.41809159809100527\n",
            "Loss in iteration no. 97446 ==> 0.4180906628438334\n",
            "Loss in iteration no. 97447 ==> 0.41808972760925184\n",
            "Loss in iteration no. 97448 ==> 0.41808879238726043\n",
            "Loss in iteration no. 97449 ==> 0.4180878571778589\n",
            "Loss in iteration no. 97450 ==> 0.4180869219810469\n",
            "Loss in iteration no. 97451 ==> 0.41808598679682446\n",
            "Loss in iteration no. 97452 ==> 0.418085051625191\n",
            "Loss in iteration no. 97453 ==> 0.4180841164661465\n",
            "Loss in iteration no. 97454 ==> 0.41808318131969074\n",
            "Loss in iteration no. 97455 ==> 0.4180822461858233\n",
            "Loss in iteration no. 97456 ==> 0.4180813110645441\n",
            "Loss in iteration no. 97457 ==> 0.41808037595585285\n",
            "Loss in iteration no. 97458 ==> 0.4180794408597493\n",
            "Loss in iteration no. 97459 ==> 0.4180785057762333\n",
            "Loss in iteration no. 97460 ==> 0.41807757070530444\n",
            "Loss in iteration no. 97461 ==> 0.41807663564696257\n",
            "Loss in iteration no. 97462 ==> 0.4180757006012076\n",
            "Loss in iteration no. 97463 ==> 0.418074765568039\n",
            "Loss in iteration no. 97464 ==> 0.41807383054745667\n",
            "Loss in iteration no. 97465 ==> 0.41807289553946053\n",
            "Loss in iteration no. 97466 ==> 0.4180719605440501\n",
            "Loss in iteration no. 97467 ==> 0.4180710255612252\n",
            "Loss in iteration no. 97468 ==> 0.41807009059098565\n",
            "Loss in iteration no. 97469 ==> 0.4180691556333312\n",
            "Loss in iteration no. 97470 ==> 0.41806822068826155\n",
            "Loss in iteration no. 97471 ==> 0.4180672857557766\n",
            "Loss in iteration no. 97472 ==> 0.418066350835876\n",
            "Loss in iteration no. 97473 ==> 0.4180654159285595\n",
            "Loss in iteration no. 97474 ==> 0.4180644810338268\n",
            "Loss in iteration no. 97475 ==> 0.41806354615167785\n",
            "Loss in iteration no. 97476 ==> 0.4180626112821123\n",
            "Loss in iteration no. 97477 ==> 0.4180616764251299\n",
            "Loss in iteration no. 97478 ==> 0.4180607415807305\n",
            "Loss in iteration no. 97479 ==> 0.4180598067489137\n",
            "Loss in iteration no. 97480 ==> 0.4180588719296794\n",
            "Loss in iteration no. 97481 ==> 0.41805793712302736\n",
            "Loss in iteration no. 97482 ==> 0.41805700232895726\n",
            "Loss in iteration no. 97483 ==> 0.4180560675474689\n",
            "Loss in iteration no. 97484 ==> 0.418055132778562\n",
            "Loss in iteration no. 97485 ==> 0.4180541980222365\n",
            "Loss in iteration no. 97486 ==> 0.4180532632784919\n",
            "Loss in iteration no. 97487 ==> 0.4180523285473281\n",
            "Loss in iteration no. 97488 ==> 0.4180513938287449\n",
            "Loss in iteration no. 97489 ==> 0.41805045912274197\n",
            "Loss in iteration no. 97490 ==> 0.4180495244293191\n",
            "Loss in iteration no. 97491 ==> 0.418048589748476\n",
            "Loss in iteration no. 97492 ==> 0.41804765508021263\n",
            "Loss in iteration no. 97493 ==> 0.4180467204245285\n",
            "Loss in iteration no. 97494 ==> 0.4180457857814236\n",
            "Loss in iteration no. 97495 ==> 0.41804485115089746\n",
            "Loss in iteration no. 97496 ==> 0.41804391653295\n",
            "Loss in iteration no. 97497 ==> 0.418042981927581\n",
            "Loss in iteration no. 97498 ==> 0.41804204733479\n",
            "Loss in iteration no. 97499 ==> 0.418041112754577\n",
            "Loss in iteration no. 97500 ==> 0.4180401781869417\n",
            "Loss in iteration no. 97501 ==> 0.41803924363188383\n",
            "Loss in iteration no. 97502 ==> 0.41803830908940315\n",
            "Loss in iteration no. 97503 ==> 0.41803737455949946\n",
            "Loss in iteration no. 97504 ==> 0.4180364400421725\n",
            "Loss in iteration no. 97505 ==> 0.418035505537422\n",
            "Loss in iteration no. 97506 ==> 0.41803457104524777\n",
            "Loss in iteration no. 97507 ==> 0.41803363656564957\n",
            "Loss in iteration no. 97508 ==> 0.4180327020986271\n",
            "Loss in iteration no. 97509 ==> 0.41803176764418015\n",
            "Loss in iteration no. 97510 ==> 0.41803083320230844\n",
            "Loss in iteration no. 97511 ==> 0.41802989877301194\n",
            "Loss in iteration no. 97512 ==> 0.41802896435629017\n",
            "Loss in iteration no. 97513 ==> 0.418028029952143\n",
            "Loss in iteration no. 97514 ==> 0.41802709556057005\n",
            "Loss in iteration no. 97515 ==> 0.4180261611815714\n",
            "Loss in iteration no. 97516 ==> 0.4180252268151466\n",
            "Loss in iteration no. 97517 ==> 0.41802429246129524\n",
            "Loss in iteration no. 97518 ==> 0.4180233581200174\n",
            "Loss in iteration no. 97519 ==> 0.4180224237913126\n",
            "Loss in iteration no. 97520 ==> 0.41802148947518086\n",
            "Loss in iteration no. 97521 ==> 0.4180205551716216\n",
            "Loss in iteration no. 97522 ==> 0.41801962088063493\n",
            "Loss in iteration no. 97523 ==> 0.4180186866022204\n",
            "Loss in iteration no. 97524 ==> 0.4180177523363778\n",
            "Loss in iteration no. 97525 ==> 0.4180168180831069\n",
            "Loss in iteration no. 97526 ==> 0.4180158838424075\n",
            "Loss in iteration no. 97527 ==> 0.4180149496142793\n",
            "Loss in iteration no. 97528 ==> 0.4180140153987221\n",
            "Loss in iteration no. 97529 ==> 0.4180130811957358\n",
            "Loss in iteration no. 97530 ==> 0.4180121470053199\n",
            "Loss in iteration no. 97531 ==> 0.41801121282747433\n",
            "Loss in iteration no. 97532 ==> 0.4180102786621988\n",
            "Loss in iteration no. 97533 ==> 0.41800934450949306\n",
            "Loss in iteration no. 97534 ==> 0.4180084103693568\n",
            "Loss in iteration no. 97535 ==> 0.4180074762417899\n",
            "Loss in iteration no. 97536 ==> 0.41800654212679217\n",
            "Loss in iteration no. 97537 ==> 0.4180056080243633\n",
            "Loss in iteration no. 97538 ==> 0.41800467393450297\n",
            "Loss in iteration no. 97539 ==> 0.418003739857211\n",
            "Loss in iteration no. 97540 ==> 0.4180028057924873\n",
            "Loss in iteration no. 97541 ==> 0.4180018717403313\n",
            "Loss in iteration no. 97542 ==> 0.4180009377007431\n",
            "Loss in iteration no. 97543 ==> 0.4180000036737223\n",
            "Loss in iteration no. 97544 ==> 0.41799906965926864\n",
            "Loss in iteration no. 97545 ==> 0.417998135657382\n",
            "Loss in iteration no. 97546 ==> 0.417997201668062\n",
            "Loss in iteration no. 97547 ==> 0.41799626769130843\n",
            "Loss in iteration no. 97548 ==> 0.41799533372712117\n",
            "Loss in iteration no. 97549 ==> 0.41799439977549985\n",
            "Loss in iteration no. 97550 ==> 0.4179934658364443\n",
            "Loss in iteration no. 97551 ==> 0.4179925319099542\n",
            "Loss in iteration no. 97552 ==> 0.4179915979960295\n",
            "Loss in iteration no. 97553 ==> 0.4179906640946698\n",
            "Loss in iteration no. 97554 ==> 0.4179897302058748\n",
            "Loss in iteration no. 97555 ==> 0.4179887963296444\n",
            "Loss in iteration no. 97556 ==> 0.4179878624659783\n",
            "Loss in iteration no. 97557 ==> 0.41798692861487635\n",
            "Loss in iteration no. 97558 ==> 0.41798599477633824\n",
            "Loss in iteration no. 97559 ==> 0.41798506095036364\n",
            "Loss in iteration no. 97560 ==> 0.4179841271369525\n",
            "Loss in iteration no. 97561 ==> 0.4179831933361044\n",
            "Loss in iteration no. 97562 ==> 0.4179822595478192\n",
            "Loss in iteration no. 97563 ==> 0.41798132577209673\n",
            "Loss in iteration no. 97564 ==> 0.4179803920089366\n",
            "Loss in iteration no. 97565 ==> 0.41797945825833877\n",
            "Loss in iteration no. 97566 ==> 0.41797852452030276\n",
            "Loss in iteration no. 97567 ==> 0.4179775907948284\n",
            "Loss in iteration no. 97568 ==> 0.4179766570819156\n",
            "Loss in iteration no. 97569 ==> 0.417975723381564\n",
            "Loss in iteration no. 97570 ==> 0.4179747896937734\n",
            "Loss in iteration no. 97571 ==> 0.41797385601854353\n",
            "Loss in iteration no. 97572 ==> 0.4179729223558741\n",
            "Loss in iteration no. 97573 ==> 0.417971988705765\n",
            "Loss in iteration no. 97574 ==> 0.41797105506821597\n",
            "Loss in iteration no. 97575 ==> 0.41797012144322665\n",
            "Loss in iteration no. 97576 ==> 0.4179691878307969\n",
            "Loss in iteration no. 97577 ==> 0.4179682542309265\n",
            "Loss in iteration no. 97578 ==> 0.4179673206436151\n",
            "Loss in iteration no. 97579 ==> 0.41796638706886263\n",
            "Loss in iteration no. 97580 ==> 0.4179654535066687\n",
            "Loss in iteration no. 97581 ==> 0.41796451995703315\n",
            "Loss in iteration no. 97582 ==> 0.4179635864199557\n",
            "Loss in iteration no. 97583 ==> 0.4179626528954362\n",
            "Loss in iteration no. 97584 ==> 0.41796171938347426\n",
            "Loss in iteration no. 97585 ==> 0.4179607858840697\n",
            "Loss in iteration no. 97586 ==> 0.41795985239722244\n",
            "Loss in iteration no. 97587 ==> 0.4179589189229321\n",
            "Loss in iteration no. 97588 ==> 0.4179579854611983\n",
            "Loss in iteration no. 97589 ==> 0.41795705201202105\n",
            "Loss in iteration no. 97590 ==> 0.4179561185754001\n",
            "Loss in iteration no. 97591 ==> 0.41795518515133495\n",
            "Loss in iteration no. 97592 ==> 0.41795425173982576\n",
            "Loss in iteration no. 97593 ==> 0.41795331834087196\n",
            "Loss in iteration no. 97594 ==> 0.4179523849544734\n",
            "Loss in iteration no. 97595 ==> 0.4179514515806298\n",
            "Loss in iteration no. 97596 ==> 0.4179505182193411\n",
            "Loss in iteration no. 97597 ==> 0.41794958487060696\n",
            "Loss in iteration no. 97598 ==> 0.417948651534427\n",
            "Loss in iteration no. 97599 ==> 0.41794771821080123\n",
            "Loss in iteration no. 97600 ==> 0.41794678489972925\n",
            "Loss in iteration no. 97601 ==> 0.41794585160121095\n",
            "Loss in iteration no. 97602 ==> 0.41794491831524583\n",
            "Loss in iteration no. 97603 ==> 0.41794398504183394\n",
            "Loss in iteration no. 97604 ==> 0.41794305178097496\n",
            "Loss in iteration no. 97605 ==> 0.4179421185326686\n",
            "Loss in iteration no. 97606 ==> 0.41794118529691465\n",
            "Loss in iteration no. 97607 ==> 0.4179402520737128\n",
            "Loss in iteration no. 97608 ==> 0.417939318863063\n",
            "Loss in iteration no. 97609 ==> 0.41793838566496483\n",
            "Loss in iteration no. 97610 ==> 0.41793745247941816\n",
            "Loss in iteration no. 97611 ==> 0.4179365193064226\n",
            "Loss in iteration no. 97612 ==> 0.4179355861459781\n",
            "Loss in iteration no. 97613 ==> 0.4179346529980843\n",
            "Loss in iteration no. 97614 ==> 0.41793371986274097\n",
            "Loss in iteration no. 97615 ==> 0.417932786739948\n",
            "Loss in iteration no. 97616 ==> 0.4179318536297049\n",
            "Loss in iteration no. 97617 ==> 0.41793092053201175\n",
            "Loss in iteration no. 97618 ==> 0.41792998744686805\n",
            "Loss in iteration no. 97619 ==> 0.41792905437427363\n",
            "Loss in iteration no. 97620 ==> 0.4179281213142284\n",
            "Loss in iteration no. 97621 ==> 0.4179271882667319\n",
            "Loss in iteration no. 97622 ==> 0.41792625523178406\n",
            "Loss in iteration no. 97623 ==> 0.41792532220938455\n",
            "Loss in iteration no. 97624 ==> 0.41792438919953323\n",
            "Loss in iteration no. 97625 ==> 0.4179234562022297\n",
            "Loss in iteration no. 97626 ==> 0.4179225232174739\n",
            "Loss in iteration no. 97627 ==> 0.41792159024526543\n",
            "Loss in iteration no. 97628 ==> 0.4179206572856041\n",
            "Loss in iteration no. 97629 ==> 0.4179197243384898\n",
            "Loss in iteration no. 97630 ==> 0.41791879140392213\n",
            "Loss in iteration no. 97631 ==> 0.41791785848190094\n",
            "Loss in iteration no. 97632 ==> 0.417916925572426\n",
            "Loss in iteration no. 97633 ==> 0.41791599267549695\n",
            "Loss in iteration no. 97634 ==> 0.4179150597911136\n",
            "Loss in iteration no. 97635 ==> 0.4179141269192759\n",
            "Loss in iteration no. 97636 ==> 0.41791319405998334\n",
            "Loss in iteration no. 97637 ==> 0.4179122612132359\n",
            "Loss in iteration no. 97638 ==> 0.4179113283790332\n",
            "Loss in iteration no. 97639 ==> 0.417910395557375\n",
            "Loss in iteration no. 97640 ==> 0.4179094627482612\n",
            "Loss in iteration no. 97641 ==> 0.4179085299516915\n",
            "Loss in iteration no. 97642 ==> 0.4179075971676655\n",
            "Loss in iteration no. 97643 ==> 0.41790666439618324\n",
            "Loss in iteration no. 97644 ==> 0.4179057316372442\n",
            "Loss in iteration no. 97645 ==> 0.4179047988908484\n",
            "Loss in iteration no. 97646 ==> 0.41790386615699543\n",
            "Loss in iteration no. 97647 ==> 0.4179029334356852\n",
            "Loss in iteration no. 97648 ==> 0.41790200072691724\n",
            "Loss in iteration no. 97649 ==> 0.4179010680306915\n",
            "Loss in iteration no. 97650 ==> 0.41790013534700776\n",
            "Loss in iteration no. 97651 ==> 0.4178992026758656\n",
            "Loss in iteration no. 97652 ==> 0.417898270017265\n",
            "Loss in iteration no. 97653 ==> 0.4178973373712055\n",
            "Loss in iteration no. 97654 ==> 0.41789640473768713\n",
            "Loss in iteration no. 97655 ==> 0.4178954721167094\n",
            "Loss in iteration no. 97656 ==> 0.41789453950827227\n",
            "Loss in iteration no. 97657 ==> 0.4178936069123753\n",
            "Loss in iteration no. 97658 ==> 0.4178926743290184\n",
            "Loss in iteration no. 97659 ==> 0.41789174175820126\n",
            "Loss in iteration no. 97660 ==> 0.41789080919992383\n",
            "Loss in iteration no. 97661 ==> 0.41788987665418553\n",
            "Loss in iteration no. 97662 ==> 0.41788894412098637\n",
            "Loss in iteration no. 97663 ==> 0.417888011600326\n",
            "Loss in iteration no. 97664 ==> 0.4178870790922043\n",
            "Loss in iteration no. 97665 ==> 0.417886146596621\n",
            "Loss in iteration no. 97666 ==> 0.4178852141135757\n",
            "Loss in iteration no. 97667 ==> 0.41788428164306846\n",
            "Loss in iteration no. 97668 ==> 0.4178833491850988\n",
            "Loss in iteration no. 97669 ==> 0.4178824167396665\n",
            "Loss in iteration no. 97670 ==> 0.41788148430677147\n",
            "Loss in iteration no. 97671 ==> 0.4178805518864133\n",
            "Loss in iteration no. 97672 ==> 0.4178796194785918\n",
            "Loss in iteration no. 97673 ==> 0.4178786870833069\n",
            "Loss in iteration no. 97674 ==> 0.4178777547005581\n",
            "Loss in iteration no. 97675 ==> 0.41787682233034534\n",
            "Loss in iteration no. 97676 ==> 0.4178758899726683\n",
            "Loss in iteration no. 97677 ==> 0.4178749576275268\n",
            "Loss in iteration no. 97678 ==> 0.41787402529492057\n",
            "Loss in iteration no. 97679 ==> 0.41787309297484937\n",
            "Loss in iteration no. 97680 ==> 0.417872160667313\n",
            "Loss in iteration no. 97681 ==> 0.41787122837231117\n",
            "Loss in iteration no. 97682 ==> 0.41787029608984366\n",
            "Loss in iteration no. 97683 ==> 0.4178693638199102\n",
            "Loss in iteration no. 97684 ==> 0.41786843156251063\n",
            "Loss in iteration no. 97685 ==> 0.4178674993176447\n",
            "Loss in iteration no. 97686 ==> 0.41786656708531206\n",
            "Loss in iteration no. 97687 ==> 0.41786563486551254\n",
            "Loss in iteration no. 97688 ==> 0.4178647026582461\n",
            "Loss in iteration no. 97689 ==> 0.4178637704635122\n",
            "Loss in iteration no. 97690 ==> 0.41786283828131066\n",
            "Loss in iteration no. 97691 ==> 0.4178619061116414\n",
            "Loss in iteration no. 97692 ==> 0.41786097395450406\n",
            "Loss in iteration no. 97693 ==> 0.41786004180989844\n",
            "Loss in iteration no. 97694 ==> 0.41785910967782425\n",
            "Loss in iteration no. 97695 ==> 0.41785817755828136\n",
            "Loss in iteration no. 97696 ==> 0.4178572454512694\n",
            "Loss in iteration no. 97697 ==> 0.4178563133567882\n",
            "Loss in iteration no. 97698 ==> 0.4178553812748375\n",
            "Loss in iteration no. 97699 ==> 0.4178544492054172\n",
            "Loss in iteration no. 97700 ==> 0.41785351714852687\n",
            "Loss in iteration no. 97701 ==> 0.41785258510416634\n",
            "Loss in iteration no. 97702 ==> 0.4178516530723354\n",
            "Loss in iteration no. 97703 ==> 0.4178507210530338\n",
            "Loss in iteration no. 97704 ==> 0.4178497890462613\n",
            "Loss in iteration no. 97705 ==> 0.41784885705201763\n",
            "Loss in iteration no. 97706 ==> 0.4178479250703026\n",
            "Loss in iteration no. 97707 ==> 0.4178469931011159\n",
            "Loss in iteration no. 97708 ==> 0.4178460611444574\n",
            "Loss in iteration no. 97709 ==> 0.4178451292003268\n",
            "Loss in iteration no. 97710 ==> 0.4178441972687239\n",
            "Loss in iteration no. 97711 ==> 0.4178432653496484\n",
            "Loss in iteration no. 97712 ==> 0.4178423334431001\n",
            "Loss in iteration no. 97713 ==> 0.41784140154907873\n",
            "Loss in iteration no. 97714 ==> 0.4178404696675841\n",
            "Loss in iteration no. 97715 ==> 0.417839537798616\n",
            "Loss in iteration no. 97716 ==> 0.4178386059421741\n",
            "Loss in iteration no. 97717 ==> 0.41783767409825817\n",
            "Loss in iteration no. 97718 ==> 0.41783674226686807\n",
            "Loss in iteration no. 97719 ==> 0.4178358104480035\n",
            "Loss in iteration no. 97720 ==> 0.4178348786416642\n",
            "Loss in iteration no. 97721 ==> 0.41783394684785\n",
            "Loss in iteration no. 97722 ==> 0.41783301506656056\n",
            "Loss in iteration no. 97723 ==> 0.4178320832977957\n",
            "Loss in iteration no. 97724 ==> 0.4178311515415552\n",
            "Loss in iteration no. 97725 ==> 0.41783021979783885\n",
            "Loss in iteration no. 97726 ==> 0.4178292880666464\n",
            "Loss in iteration no. 97727 ==> 0.4178283563479775\n",
            "Loss in iteration no. 97728 ==> 0.41782742464183203\n",
            "Loss in iteration no. 97729 ==> 0.41782649294820967\n",
            "Loss in iteration no. 97730 ==> 0.4178255612671103\n",
            "Loss in iteration no. 97731 ==> 0.41782462959853367\n",
            "Loss in iteration no. 97732 ==> 0.41782369794247937\n",
            "Loss in iteration no. 97733 ==> 0.4178227662989473\n",
            "Loss in iteration no. 97734 ==> 0.4178218346679372\n",
            "Loss in iteration no. 97735 ==> 0.41782090304944886\n",
            "Loss in iteration no. 97736 ==> 0.41781997144348204\n",
            "Loss in iteration no. 97737 ==> 0.4178190398500364\n",
            "Loss in iteration no. 97738 ==> 0.41781810826911187\n",
            "Loss in iteration no. 97739 ==> 0.417817176700708\n",
            "Loss in iteration no. 97740 ==> 0.41781624514482485\n",
            "Loss in iteration no. 97741 ==> 0.4178153136014619\n",
            "Loss in iteration no. 97742 ==> 0.417814382070619\n",
            "Loss in iteration no. 97743 ==> 0.417813450552296\n",
            "Loss in iteration no. 97744 ==> 0.41781251904649264\n",
            "Loss in iteration no. 97745 ==> 0.4178115875532085\n",
            "Loss in iteration no. 97746 ==> 0.41781065607244355\n",
            "Loss in iteration no. 97747 ==> 0.4178097246041976\n",
            "Loss in iteration no. 97748 ==> 0.4178087931484701\n",
            "Loss in iteration no. 97749 ==> 0.4178078617052611\n",
            "Loss in iteration no. 97750 ==> 0.4178069302745703\n",
            "Loss in iteration no. 97751 ==> 0.41780599885639735\n",
            "Loss in iteration no. 97752 ==> 0.41780506745074214\n",
            "Loss in iteration no. 97753 ==> 0.41780413605760447\n",
            "Loss in iteration no. 97754 ==> 0.41780320467698395\n",
            "Loss in iteration no. 97755 ==> 0.4178022733088804\n",
            "Loss in iteration no. 97756 ==> 0.4178013419532936\n",
            "Loss in iteration no. 97757 ==> 0.4178004106102234\n",
            "Loss in iteration no. 97758 ==> 0.41779947927966943\n",
            "Loss in iteration no. 97759 ==> 0.41779854796163146\n",
            "Loss in iteration no. 97760 ==> 0.41779761665610937\n",
            "Loss in iteration no. 97761 ==> 0.4177966853631027\n",
            "Loss in iteration no. 97762 ==> 0.4177957540826115\n",
            "Loss in iteration no. 97763 ==> 0.4177948228146353\n",
            "Loss in iteration no. 97764 ==> 0.41779389155917407\n",
            "Loss in iteration no. 97765 ==> 0.4177929603162274\n",
            "Loss in iteration no. 97766 ==> 0.41779202908579505\n",
            "Loss in iteration no. 97767 ==> 0.4177910978678769\n",
            "Loss in iteration no. 97768 ==> 0.4177901666624726\n",
            "Loss in iteration no. 97769 ==> 0.41778923546958197\n",
            "Loss in iteration no. 97770 ==> 0.4177883042892047\n",
            "Loss in iteration no. 97771 ==> 0.4177873731213408\n",
            "Loss in iteration no. 97772 ==> 0.41778644196598974\n",
            "Loss in iteration no. 97773 ==> 0.4177855108231515\n",
            "Loss in iteration no. 97774 ==> 0.4177845796928256\n",
            "Loss in iteration no. 97775 ==> 0.41778364857501205\n",
            "Loss in iteration no. 97776 ==> 0.4177827174697105\n",
            "Loss in iteration no. 97777 ==> 0.4177817863769206\n",
            "Loss in iteration no. 97778 ==> 0.4177808552966424\n",
            "Loss in iteration no. 97779 ==> 0.41777992422887533\n",
            "Loss in iteration no. 97780 ==> 0.4177789931736194\n",
            "Loss in iteration no. 97781 ==> 0.4177780621308743\n",
            "Loss in iteration no. 97782 ==> 0.4177771311006398\n",
            "Loss in iteration no. 97783 ==> 0.4177762000829156\n",
            "Loss in iteration no. 97784 ==> 0.4177752690777015\n",
            "Loss in iteration no. 97785 ==> 0.4177743380849973\n",
            "Loss in iteration no. 97786 ==> 0.41777340710480276\n",
            "Loss in iteration no. 97787 ==> 0.4177724761371176\n",
            "Loss in iteration no. 97788 ==> 0.41777154518194154\n",
            "Loss in iteration no. 97789 ==> 0.4177706142392745\n",
            "Loss in iteration no. 97790 ==> 0.41776968330911607\n",
            "Loss in iteration no. 97791 ==> 0.41776875239146616\n",
            "Loss in iteration no. 97792 ==> 0.41776782148632435\n",
            "Loss in iteration no. 97793 ==> 0.41776689059369054\n",
            "Loss in iteration no. 97794 ==> 0.41776595971356456\n",
            "Loss in iteration no. 97795 ==> 0.4177650288459461\n",
            "Loss in iteration no. 97796 ==> 0.4177640979908348\n",
            "Loss in iteration no. 97797 ==> 0.4177631671482305\n",
            "Loss in iteration no. 97798 ==> 0.4177622363181331\n",
            "Loss in iteration no. 97799 ==> 0.4177613055005422\n",
            "Loss in iteration no. 97800 ==> 0.41776037469545757\n",
            "Loss in iteration no. 97801 ==> 0.41775944390287917\n",
            "Loss in iteration no. 97802 ==> 0.4177585131228065\n",
            "Loss in iteration no. 97803 ==> 0.41775758235523935\n",
            "Loss in iteration no. 97804 ==> 0.4177566516001777\n",
            "Loss in iteration no. 97805 ==> 0.41775572085762114\n",
            "Loss in iteration no. 97806 ==> 0.41775479012756955\n",
            "Loss in iteration no. 97807 ==> 0.4177538594100225\n",
            "Loss in iteration no. 97808 ==> 0.41775292870497993\n",
            "Loss in iteration no. 97809 ==> 0.4177519980124415\n",
            "Loss in iteration no. 97810 ==> 0.417751067332407\n",
            "Loss in iteration no. 97811 ==> 0.41775013666487637\n",
            "Loss in iteration no. 97812 ==> 0.41774920600984905\n",
            "Loss in iteration no. 97813 ==> 0.417748275367325\n",
            "Loss in iteration no. 97814 ==> 0.41774734473730396\n",
            "Loss in iteration no. 97815 ==> 0.41774641411978564\n",
            "Loss in iteration no. 97816 ==> 0.41774548351476987\n",
            "Loss in iteration no. 97817 ==> 0.41774455292225643\n",
            "Loss in iteration no. 97818 ==> 0.41774362234224505\n",
            "Loss in iteration no. 97819 ==> 0.4177426917747354\n",
            "Loss in iteration no. 97820 ==> 0.4177417612197274\n",
            "Loss in iteration no. 97821 ==> 0.4177408306772207\n",
            "Loss in iteration no. 97822 ==> 0.41773990014721507\n",
            "Loss in iteration no. 97823 ==> 0.4177389696297104\n",
            "Loss in iteration no. 97824 ==> 0.41773803912470625\n",
            "Loss in iteration no. 97825 ==> 0.41773710863220254\n",
            "Loss in iteration no. 97826 ==> 0.417736178152199\n",
            "Loss in iteration no. 97827 ==> 0.41773524768469544\n",
            "Loss in iteration no. 97828 ==> 0.4177343172296914\n",
            "Loss in iteration no. 97829 ==> 0.41773338678718697\n",
            "Loss in iteration no. 97830 ==> 0.4177324563571816\n",
            "Loss in iteration no. 97831 ==> 0.41773152593967533\n",
            "Loss in iteration no. 97832 ==> 0.41773059553466774\n",
            "Loss in iteration no. 97833 ==> 0.41772966514215865\n",
            "Loss in iteration no. 97834 ==> 0.41772873476214784\n",
            "Loss in iteration no. 97835 ==> 0.417727804394635\n",
            "Loss in iteration no. 97836 ==> 0.41772687403961994\n",
            "Loss in iteration no. 97837 ==> 0.4177259436971024\n",
            "Loss in iteration no. 97838 ==> 0.4177250133670824\n",
            "Loss in iteration no. 97839 ==> 0.41772408304955927\n",
            "Loss in iteration no. 97840 ==> 0.417723152744533\n",
            "Loss in iteration no. 97841 ==> 0.41772222245200336\n",
            "Loss in iteration no. 97842 ==> 0.4177212921719701\n",
            "Loss in iteration no. 97843 ==> 0.417720361904433\n",
            "Loss in iteration no. 97844 ==> 0.4177194316493917\n",
            "Loss in iteration no. 97845 ==> 0.41771850140684613\n",
            "Loss in iteration no. 97846 ==> 0.417717571176796\n",
            "Loss in iteration no. 97847 ==> 0.41771664095924094\n",
            "Loss in iteration no. 97848 ==> 0.41771571075418096\n",
            "Loss in iteration no. 97849 ==> 0.4177147805616156\n",
            "Loss in iteration no. 97850 ==> 0.4177138503815447\n",
            "Loss in iteration no. 97851 ==> 0.4177129202139681\n",
            "Loss in iteration no. 97852 ==> 0.4177119900588855\n",
            "Loss in iteration no. 97853 ==> 0.4177110599162966\n",
            "Loss in iteration no. 97854 ==> 0.41771012978620126\n",
            "Loss in iteration no. 97855 ==> 0.41770919966859915\n",
            "Loss in iteration no. 97856 ==> 0.4177082695634902\n",
            "Loss in iteration no. 97857 ==> 0.41770733947087396\n",
            "Loss in iteration no. 97858 ==> 0.4177064093907504\n",
            "Loss in iteration no. 97859 ==> 0.41770547932311913\n",
            "Loss in iteration no. 97860 ==> 0.4177045492679799\n",
            "Loss in iteration no. 97861 ==> 0.41770361922533267\n",
            "Loss in iteration no. 97862 ==> 0.41770268919517706\n",
            "Loss in iteration no. 97863 ==> 0.4177017591775127\n",
            "Loss in iteration no. 97864 ==> 0.4177008291723396\n",
            "Loss in iteration no. 97865 ==> 0.41769989917965744\n",
            "Loss in iteration no. 97866 ==> 0.4176989691994659\n",
            "Loss in iteration no. 97867 ==> 0.41769803923176485\n",
            "Loss in iteration no. 97868 ==> 0.417697109276554\n",
            "Loss in iteration no. 97869 ==> 0.41769617933383324\n",
            "Loss in iteration no. 97870 ==> 0.417695249403602\n",
            "Loss in iteration no. 97871 ==> 0.4176943194858604\n",
            "Loss in iteration no. 97872 ==> 0.4176933895806081\n",
            "Loss in iteration no. 97873 ==> 0.41769245968784474\n",
            "Loss in iteration no. 97874 ==> 0.4176915298075702\n",
            "Loss in iteration no. 97875 ==> 0.4176905999397842\n",
            "Loss in iteration no. 97876 ==> 0.41768967008448654\n",
            "Loss in iteration no. 97877 ==> 0.41768874024167696\n",
            "Loss in iteration no. 97878 ==> 0.4176878104113552\n",
            "Loss in iteration no. 97879 ==> 0.4176868805935211\n",
            "Loss in iteration no. 97880 ==> 0.41768595078817433\n",
            "Loss in iteration no. 97881 ==> 0.41768502099531474\n",
            "Loss in iteration no. 97882 ==> 0.4176840912149421\n",
            "Loss in iteration no. 97883 ==> 0.41768316144705603\n",
            "Loss in iteration no. 97884 ==> 0.41768223169165636\n",
            "Loss in iteration no. 97885 ==> 0.41768130194874287\n",
            "Loss in iteration no. 97886 ==> 0.41768037221831544\n",
            "Loss in iteration no. 97887 ==> 0.4176794425003737\n",
            "Loss in iteration no. 97888 ==> 0.41767851279491736\n",
            "Loss in iteration no. 97889 ==> 0.41767758310194636\n",
            "Loss in iteration no. 97890 ==> 0.4176766534214603\n",
            "Loss in iteration no. 97891 ==> 0.417675723753459\n",
            "Loss in iteration no. 97892 ==> 0.4176747940979424\n",
            "Loss in iteration no. 97893 ==> 0.4176738644549099\n",
            "Loss in iteration no. 97894 ==> 0.4176729348243615\n",
            "Loss in iteration no. 97895 ==> 0.417672005206297\n",
            "Loss in iteration no. 97896 ==> 0.4176710756007161\n",
            "Loss in iteration no. 97897 ==> 0.4176701460076184\n",
            "Loss in iteration no. 97898 ==> 0.41766921642700394\n",
            "Loss in iteration no. 97899 ==> 0.41766828685887236\n",
            "Loss in iteration no. 97900 ==> 0.4176673573032234\n",
            "Loss in iteration no. 97901 ==> 0.41766642776005686\n",
            "Loss in iteration no. 97902 ==> 0.4176654982293725\n",
            "Loss in iteration no. 97903 ==> 0.41766456871117\n",
            "Loss in iteration no. 97904 ==> 0.41766363920544924\n",
            "Loss in iteration no. 97905 ==> 0.41766270971221\n",
            "Loss in iteration no. 97906 ==> 0.4176617802314519\n",
            "Loss in iteration no. 97907 ==> 0.41766085076317483\n",
            "Loss in iteration no. 97908 ==> 0.4176599213073785\n",
            "Loss in iteration no. 97909 ==> 0.41765899186406275\n",
            "Loss in iteration no. 97910 ==> 0.4176580624332272\n",
            "Loss in iteration no. 97911 ==> 0.4176571330148717\n",
            "Loss in iteration no. 97912 ==> 0.417656203608996\n",
            "Loss in iteration no. 97913 ==> 0.4176552742155999\n",
            "Loss in iteration no. 97914 ==> 0.4176543448346831\n",
            "Loss in iteration no. 97915 ==> 0.4176534154662454\n",
            "Loss in iteration no. 97916 ==> 0.4176524861102866\n",
            "Loss in iteration no. 97917 ==> 0.4176515567668064\n",
            "Loss in iteration no. 97918 ==> 0.41765062743580456\n",
            "Loss in iteration no. 97919 ==> 0.417649698117281\n",
            "Loss in iteration no. 97920 ==> 0.41764876881123514\n",
            "Loss in iteration no. 97921 ==> 0.4176478395176671\n",
            "Loss in iteration no. 97922 ==> 0.41764691023657646\n",
            "Loss in iteration no. 97923 ==> 0.41764598096796307\n",
            "Loss in iteration no. 97924 ==> 0.4176450517118266\n",
            "Loss in iteration no. 97925 ==> 0.4176441224681669\n",
            "Loss in iteration no. 97926 ==> 0.4176431932369836\n",
            "Loss in iteration no. 97927 ==> 0.41764226401827675\n",
            "Loss in iteration no. 97928 ==> 0.4176413348120458\n",
            "Loss in iteration no. 97929 ==> 0.4176404056182907\n",
            "Loss in iteration no. 97930 ==> 0.41763947643701116\n",
            "Loss in iteration no. 97931 ==> 0.4176385472682068\n",
            "Loss in iteration no. 97932 ==> 0.41763761811187766\n",
            "Loss in iteration no. 97933 ==> 0.41763668896802325\n",
            "Loss in iteration no. 97934 ==> 0.4176357598366435\n",
            "Loss in iteration no. 97935 ==> 0.41763483071773816\n",
            "Loss in iteration no. 97936 ==> 0.41763390161130703\n",
            "Loss in iteration no. 97937 ==> 0.41763297251734965\n",
            "Loss in iteration no. 97938 ==> 0.41763204343586596\n",
            "Loss in iteration no. 97939 ==> 0.4176311143668557\n",
            "Loss in iteration no. 97940 ==> 0.4176301853103186\n",
            "Loss in iteration no. 97941 ==> 0.4176292562662545\n",
            "Loss in iteration no. 97942 ==> 0.4176283272346632\n",
            "Loss in iteration no. 97943 ==> 0.4176273982155443\n",
            "Loss in iteration no. 97944 ==> 0.41762646920889757\n",
            "Loss in iteration no. 97945 ==> 0.417625540214723\n",
            "Loss in iteration no. 97946 ==> 0.41762461123302\n",
            "Loss in iteration no. 97947 ==> 0.4176236822637887\n",
            "Loss in iteration no. 97948 ==> 0.4176227533070287\n",
            "Loss in iteration no. 97949 ==> 0.41762182436273976\n",
            "Loss in iteration no. 97950 ==> 0.4176208954309217\n",
            "Loss in iteration no. 97951 ==> 0.41761996651157407\n",
            "Loss in iteration no. 97952 ==> 0.4176190376046969\n",
            "Loss in iteration no. 97953 ==> 0.41761810871028976\n",
            "Loss in iteration no. 97954 ==> 0.4176171798283526\n",
            "Loss in iteration no. 97955 ==> 0.41761625095888505\n",
            "Loss in iteration no. 97956 ==> 0.41761532210188695\n",
            "Loss in iteration no. 97957 ==> 0.417614393257358\n",
            "Loss in iteration no. 97958 ==> 0.4176134644252979\n",
            "Loss in iteration no. 97959 ==> 0.41761253560570666\n",
            "Loss in iteration no. 97960 ==> 0.4176116067985839\n",
            "Loss in iteration no. 97961 ==> 0.4176106780039292\n",
            "Loss in iteration no. 97962 ==> 0.4176097492217426\n",
            "Loss in iteration no. 97963 ==> 0.4176088204520237\n",
            "Loss in iteration no. 97964 ==> 0.4176078916947723\n",
            "Loss in iteration no. 97965 ==> 0.4176069629499883\n",
            "Loss in iteration no. 97966 ==> 0.4176060342176713\n",
            "Loss in iteration no. 97967 ==> 0.4176051054978211\n",
            "Loss in iteration no. 97968 ==> 0.41760417679043754\n",
            "Loss in iteration no. 97969 ==> 0.41760324809552024\n",
            "Loss in iteration no. 97970 ==> 0.4176023194130691\n",
            "Loss in iteration no. 97971 ==> 0.4176013907430838\n",
            "Loss in iteration no. 97972 ==> 0.4176004620855642\n",
            "Loss in iteration no. 97973 ==> 0.4175995334405099\n",
            "Loss in iteration no. 97974 ==> 0.41759860480792066\n",
            "Loss in iteration no. 97975 ==> 0.4175976761877966\n",
            "Loss in iteration no. 97976 ==> 0.4175967475801371\n",
            "Loss in iteration no. 97977 ==> 0.417595818984942\n",
            "Loss in iteration no. 97978 ==> 0.4175948904022113\n",
            "Loss in iteration no. 97979 ==> 0.41759396183194447\n",
            "Loss in iteration no. 97980 ==> 0.4175930332741414\n",
            "Loss in iteration no. 97981 ==> 0.41759210472880176\n",
            "Loss in iteration no. 97982 ==> 0.4175911761959255\n",
            "Loss in iteration no. 97983 ==> 0.4175902476755122\n",
            "Loss in iteration no. 97984 ==> 0.4175893191675618\n",
            "Loss in iteration no. 97985 ==> 0.4175883906720739\n",
            "Loss in iteration no. 97986 ==> 0.41758746218904835\n",
            "Loss in iteration no. 97987 ==> 0.4175865337184849\n",
            "Loss in iteration no. 97988 ==> 0.4175856052603833\n",
            "Loss in iteration no. 97989 ==> 0.4175846768147433\n",
            "Loss in iteration no. 97990 ==> 0.4175837483815647\n",
            "Loss in iteration no. 97991 ==> 0.41758281996084734\n",
            "Loss in iteration no. 97992 ==> 0.4175818915525908\n",
            "Loss in iteration no. 97993 ==> 0.41758096315679494\n",
            "Loss in iteration no. 97994 ==> 0.41758003477345956\n",
            "Loss in iteration no. 97995 ==> 0.41757910640258433\n",
            "Loss in iteration no. 97996 ==> 0.41757817804416913\n",
            "Loss in iteration no. 97997 ==> 0.41757724969821364\n",
            "Loss in iteration no. 97998 ==> 0.4175763213647176\n",
            "Loss in iteration no. 97999 ==> 0.4175753930436809\n",
            "Loss in iteration no. 98000 ==> 0.41757446473510323\n",
            "Loss in iteration no. 98001 ==> 0.41757353643898426\n",
            "Loss in iteration no. 98002 ==> 0.41757260815532393\n",
            "Loss in iteration no. 98003 ==> 0.4175716798841219\n",
            "Loss in iteration no. 98004 ==> 0.417570751625378\n",
            "Loss in iteration no. 98005 ==> 0.4175698233790919\n",
            "Loss in iteration no. 98006 ==> 0.4175688951452634\n",
            "Loss in iteration no. 98007 ==> 0.4175679669238923\n",
            "Loss in iteration no. 98008 ==> 0.41756703871497836\n",
            "Loss in iteration no. 98009 ==> 0.4175661105185213\n",
            "Loss in iteration no. 98010 ==> 0.4175651823345209\n",
            "Loss in iteration no. 98011 ==> 0.41756425416297693\n",
            "Loss in iteration no. 98012 ==> 0.4175633260038891\n",
            "Loss in iteration no. 98013 ==> 0.4175623978572574\n",
            "Loss in iteration no. 98014 ==> 0.41756146972308134\n",
            "Loss in iteration no. 98015 ==> 0.4175605416013607\n",
            "Loss in iteration no. 98016 ==> 0.4175596134920954\n",
            "Loss in iteration no. 98017 ==> 0.41755868539528507\n",
            "Loss in iteration no. 98018 ==> 0.4175577573109296\n",
            "Loss in iteration no. 98019 ==> 0.41755682923902865\n",
            "Loss in iteration no. 98020 ==> 0.4175559011795819\n",
            "Loss in iteration no. 98021 ==> 0.4175549731325894\n",
            "Loss in iteration no. 98022 ==> 0.4175540450980506\n",
            "Loss in iteration no. 98023 ==> 0.4175531170759655\n",
            "Loss in iteration no. 98024 ==> 0.41755218906633373\n",
            "Loss in iteration no. 98025 ==> 0.4175512610691551\n",
            "Loss in iteration no. 98026 ==> 0.4175503330844293\n",
            "Loss in iteration no. 98027 ==> 0.4175494051121562\n",
            "Loss in iteration no. 98028 ==> 0.41754847715233556\n",
            "Loss in iteration no. 98029 ==> 0.4175475492049671\n",
            "Loss in iteration no. 98030 ==> 0.41754662127005054\n",
            "Loss in iteration no. 98031 ==> 0.4175456933475858\n",
            "Loss in iteration no. 98032 ==> 0.41754476543757246\n",
            "Loss in iteration no. 98033 ==> 0.41754383754001034\n",
            "Loss in iteration no. 98034 ==> 0.4175429096548994\n",
            "Loss in iteration no. 98035 ==> 0.4175419817822391\n",
            "Loss in iteration no. 98036 ==> 0.41754105392202945\n",
            "Loss in iteration no. 98037 ==> 0.4175401260742699\n",
            "Loss in iteration no. 98038 ==> 0.4175391982389605\n",
            "Loss in iteration no. 98039 ==> 0.4175382704161011\n",
            "Loss in iteration no. 98040 ==> 0.41753734260569114\n",
            "Loss in iteration no. 98041 ==> 0.4175364148077305\n",
            "Loss in iteration no. 98042 ==> 0.41753548702221915\n",
            "Loss in iteration no. 98043 ==> 0.4175345592491566\n",
            "Loss in iteration no. 98044 ==> 0.4175336314885427\n",
            "Loss in iteration no. 98045 ==> 0.4175327037403772\n",
            "Loss in iteration no. 98046 ==> 0.41753177600465996\n",
            "Loss in iteration no. 98047 ==> 0.4175308482813906\n",
            "Loss in iteration no. 98048 ==> 0.4175299205705689\n",
            "Loss in iteration no. 98049 ==> 0.4175289928721948\n",
            "Loss in iteration no. 98050 ==> 0.4175280651862679\n",
            "Loss in iteration no. 98051 ==> 0.4175271375127881\n",
            "Loss in iteration no. 98052 ==> 0.4175262098517549\n",
            "Loss in iteration no. 98053 ==> 0.41752528220316826\n",
            "Loss in iteration no. 98054 ==> 0.417524354567028\n",
            "Loss in iteration no. 98055 ==> 0.4175234269433338\n",
            "Loss in iteration no. 98056 ==> 0.4175224993320854\n",
            "Loss in iteration no. 98057 ==> 0.4175215717332826\n",
            "Loss in iteration no. 98058 ==> 0.4175206441469252\n",
            "Loss in iteration no. 98059 ==> 0.41751971657301273\n",
            "Loss in iteration no. 98060 ==> 0.4175187890115453\n",
            "Loss in iteration no. 98061 ==> 0.4175178614625225\n",
            "Loss in iteration no. 98062 ==> 0.4175169339259442\n",
            "Loss in iteration no. 98063 ==> 0.41751600640180997\n",
            "Loss in iteration no. 98064 ==> 0.4175150788901197\n",
            "Loss in iteration no. 98065 ==> 0.4175141513908732\n",
            "Loss in iteration no. 98066 ==> 0.4175132239040701\n",
            "Loss in iteration no. 98067 ==> 0.4175122964297103\n",
            "Loss in iteration no. 98068 ==> 0.4175113689677934\n",
            "Loss in iteration no. 98069 ==> 0.4175104415183194\n",
            "Loss in iteration no. 98070 ==> 0.4175095140812878\n",
            "Loss in iteration no. 98071 ==> 0.41750858665669865\n",
            "Loss in iteration no. 98072 ==> 0.41750765924455147\n",
            "Loss in iteration no. 98073 ==> 0.4175067318448461\n",
            "Loss in iteration no. 98074 ==> 0.41750580445758234\n",
            "Loss in iteration no. 98075 ==> 0.41750487708275996\n",
            "Loss in iteration no. 98076 ==> 0.4175039497203786\n",
            "Loss in iteration no. 98077 ==> 0.41750302237043824\n",
            "Loss in iteration no. 98078 ==> 0.4175020950329385\n",
            "Loss in iteration no. 98079 ==> 0.41750116770787915\n",
            "Loss in iteration no. 98080 ==> 0.41750024039526\n",
            "Loss in iteration no. 98081 ==> 0.41749931309508076\n",
            "Loss in iteration no. 98082 ==> 0.4174983858073412\n",
            "Loss in iteration no. 98083 ==> 0.4174974585320411\n",
            "Loss in iteration no. 98084 ==> 0.41749653126918035\n",
            "Loss in iteration no. 98085 ==> 0.41749560401875857\n",
            "Loss in iteration no. 98086 ==> 0.4174946767807755\n",
            "Loss in iteration no. 98087 ==> 0.41749374955523094\n",
            "Loss in iteration no. 98088 ==> 0.4174928223421247\n",
            "Loss in iteration no. 98089 ==> 0.41749189514145657\n",
            "Loss in iteration no. 98090 ==> 0.41749096795322627\n",
            "Loss in iteration no. 98091 ==> 0.4174900407774335\n",
            "Loss in iteration no. 98092 ==> 0.4174891136140781\n",
            "Loss in iteration no. 98093 ==> 0.41748818646315977\n",
            "Loss in iteration no. 98094 ==> 0.4174872593246784\n",
            "Loss in iteration no. 98095 ==> 0.4174863321986337\n",
            "Loss in iteration no. 98096 ==> 0.41748540508502535\n",
            "Loss in iteration no. 98097 ==> 0.41748447798385313\n",
            "Loss in iteration no. 98098 ==> 0.4174835508951169\n",
            "Loss in iteration no. 98099 ==> 0.4174826238188164\n",
            "Loss in iteration no. 98100 ==> 0.41748169675495134\n",
            "Loss in iteration no. 98101 ==> 0.41748076970352155\n",
            "Loss in iteration no. 98102 ==> 0.4174798426645267\n",
            "Loss in iteration no. 98103 ==> 0.41747891563796663\n",
            "Loss in iteration no. 98104 ==> 0.41747798862384117\n",
            "Loss in iteration no. 98105 ==> 0.41747706162214987\n",
            "Loss in iteration no. 98106 ==> 0.41747613463289274\n",
            "Loss in iteration no. 98107 ==> 0.4174752076560693\n",
            "Loss in iteration no. 98108 ==> 0.41747428069167963\n",
            "Loss in iteration no. 98109 ==> 0.4174733537397232\n",
            "Loss in iteration no. 98110 ==> 0.41747242680019986\n",
            "Loss in iteration no. 98111 ==> 0.4174714998731095\n",
            "Loss in iteration no. 98112 ==> 0.41747057295845175\n",
            "Loss in iteration no. 98113 ==> 0.4174696460562264\n",
            "Loss in iteration no. 98114 ==> 0.41746871916643324\n",
            "Loss in iteration no. 98115 ==> 0.41746779228907194\n",
            "Loss in iteration no. 98116 ==> 0.41746686542414246\n",
            "Loss in iteration no. 98117 ==> 0.41746593857164443\n",
            "Loss in iteration no. 98118 ==> 0.41746501173157763\n",
            "Loss in iteration no. 98119 ==> 0.4174640849039417\n",
            "Loss in iteration no. 98120 ==> 0.41746315808873674\n",
            "Loss in iteration no. 98121 ==> 0.41746223128596216\n",
            "Loss in iteration no. 98122 ==> 0.41746130449561797\n",
            "Loss in iteration no. 98123 ==> 0.4174603777177037\n",
            "Loss in iteration no. 98124 ==> 0.4174594509522195\n",
            "Loss in iteration no. 98125 ==> 0.41745852419916474\n",
            "Loss in iteration no. 98126 ==> 0.4174575974585393\n",
            "Loss in iteration no. 98127 ==> 0.417456670730343\n",
            "Loss in iteration no. 98128 ==> 0.41745574401457564\n",
            "Loss in iteration no. 98129 ==> 0.4174548173112369\n",
            "Loss in iteration no. 98130 ==> 0.41745389062032656\n",
            "Loss in iteration no. 98131 ==> 0.41745296394184445\n",
            "Loss in iteration no. 98132 ==> 0.4174520372757902\n",
            "Loss in iteration no. 98133 ==> 0.4174511106221637\n",
            "Loss in iteration no. 98134 ==> 0.4174501839809647\n",
            "Loss in iteration no. 98135 ==> 0.4174492573521929\n",
            "Loss in iteration no. 98136 ==> 0.4174483307358481\n",
            "Loss in iteration no. 98137 ==> 0.41744740413193016\n",
            "Loss in iteration no. 98138 ==> 0.4174464775404386\n",
            "Loss in iteration no. 98139 ==> 0.4174455509613734\n",
            "Loss in iteration no. 98140 ==> 0.4174446243947343\n",
            "Loss in iteration no. 98141 ==> 0.41744369784052104\n",
            "Loss in iteration no. 98142 ==> 0.4174427712987333\n",
            "Loss in iteration no. 98143 ==> 0.41744184476937096\n",
            "Loss in iteration no. 98144 ==> 0.41744091825243373\n",
            "Loss in iteration no. 98145 ==> 0.41743999174792146\n",
            "Loss in iteration no. 98146 ==> 0.41743906525583374\n",
            "Loss in iteration no. 98147 ==> 0.4174381387761705\n",
            "Loss in iteration no. 98148 ==> 0.4174372123089314\n",
            "Loss in iteration no. 98149 ==> 0.4174362858541163\n",
            "Loss in iteration no. 98150 ==> 0.4174353594117248\n",
            "Loss in iteration no. 98151 ==> 0.41743443298175686\n",
            "Loss in iteration no. 98152 ==> 0.4174335065642122\n",
            "Loss in iteration no. 98153 ==> 0.41743258015909057\n",
            "Loss in iteration no. 98154 ==> 0.4174316537663916\n",
            "Loss in iteration no. 98155 ==> 0.41743072738611525\n",
            "Loss in iteration no. 98156 ==> 0.41742980101826116\n",
            "Loss in iteration no. 98157 ==> 0.41742887466282913\n",
            "Loss in iteration no. 98158 ==> 0.41742794831981894\n",
            "Loss in iteration no. 98159 ==> 0.4174270219892304\n",
            "Loss in iteration no. 98160 ==> 0.41742609567106315\n",
            "Loss in iteration no. 98161 ==> 0.4174251693653171\n",
            "Loss in iteration no. 98162 ==> 0.41742424307199183\n",
            "Loss in iteration no. 98163 ==> 0.41742331679108735\n",
            "Loss in iteration no. 98164 ==> 0.4174223905226032\n",
            "Loss in iteration no. 98165 ==> 0.41742146426653937\n",
            "Loss in iteration no. 98166 ==> 0.41742053802289525\n",
            "Loss in iteration no. 98167 ==> 0.4174196117916711\n",
            "Loss in iteration no. 98168 ==> 0.4174186855728663\n",
            "Loss in iteration no. 98169 ==> 0.41741775936648073\n",
            "Loss in iteration no. 98170 ==> 0.41741683317251427\n",
            "Loss in iteration no. 98171 ==> 0.41741590699096653\n",
            "Loss in iteration no. 98172 ==> 0.41741498082183737\n",
            "Loss in iteration no. 98173 ==> 0.4174140546651265\n",
            "Loss in iteration no. 98174 ==> 0.4174131285208336\n",
            "Loss in iteration no. 98175 ==> 0.4174122023889587\n",
            "Loss in iteration no. 98176 ==> 0.41741127626950136\n",
            "Loss in iteration no. 98177 ==> 0.41741035016246136\n",
            "Loss in iteration no. 98178 ==> 0.41740942406783854\n",
            "Loss in iteration no. 98179 ==> 0.41740849798563257\n",
            "Loss in iteration no. 98180 ==> 0.41740757191584327\n",
            "Loss in iteration no. 98181 ==> 0.4174066458584704\n",
            "Loss in iteration no. 98182 ==> 0.4174057198135138\n",
            "Loss in iteration no. 98183 ==> 0.41740479378097306\n",
            "Loss in iteration no. 98184 ==> 0.4174038677608481\n",
            "Loss in iteration no. 98185 ==> 0.4174029417531386\n",
            "Loss in iteration no. 98186 ==> 0.41740201575784436\n",
            "Loss in iteration no. 98187 ==> 0.4174010897749651\n",
            "Loss in iteration no. 98188 ==> 0.4174001638045007\n",
            "Loss in iteration no. 98189 ==> 0.41739923784645083\n",
            "Loss in iteration no. 98190 ==> 0.41739831190081533\n",
            "Loss in iteration no. 98191 ==> 0.4173973859675938\n",
            "Loss in iteration no. 98192 ==> 0.4173964600467862\n",
            "Loss in iteration no. 98193 ==> 0.4173955341383922\n",
            "Loss in iteration no. 98194 ==> 0.4173946082424116\n",
            "Loss in iteration no. 98195 ==> 0.4173936823588441\n",
            "Loss in iteration no. 98196 ==> 0.4173927564876895\n",
            "Loss in iteration no. 98197 ==> 0.4173918306289477\n",
            "Loss in iteration no. 98198 ==> 0.4173909047826181\n",
            "Loss in iteration no. 98199 ==> 0.4173899789487009\n",
            "Loss in iteration no. 98200 ==> 0.41738905312719554\n",
            "Loss in iteration no. 98201 ==> 0.41738812731810204\n",
            "Loss in iteration no. 98202 ==> 0.41738720152141995\n",
            "Loss in iteration no. 98203 ==> 0.41738627573714915\n",
            "Loss in iteration no. 98204 ==> 0.4173853499652894\n",
            "Loss in iteration no. 98205 ==> 0.4173844242058405\n",
            "Loss in iteration no. 98206 ==> 0.41738349845880207\n",
            "Loss in iteration no. 98207 ==> 0.417382572724174\n",
            "Loss in iteration no. 98208 ==> 0.417381647001956\n",
            "Loss in iteration no. 98209 ==> 0.4173807212921479\n",
            "Loss in iteration no. 98210 ==> 0.4173797955947494\n",
            "Loss in iteration no. 98211 ==> 0.41737886990976025\n",
            "Loss in iteration no. 98212 ==> 0.41737794423718033\n",
            "Loss in iteration no. 98213 ==> 0.4173770185770092\n",
            "Loss in iteration no. 98214 ==> 0.4173760929292469\n",
            "Loss in iteration no. 98215 ==> 0.417375167293893\n",
            "Loss in iteration no. 98216 ==> 0.4173742416709472\n",
            "Loss in iteration no. 98217 ==> 0.41737331606040956\n",
            "Loss in iteration no. 98218 ==> 0.41737239046227953\n",
            "Loss in iteration no. 98219 ==> 0.41737146487655713\n",
            "Loss in iteration no. 98220 ==> 0.41737053930324197\n",
            "Loss in iteration no. 98221 ==> 0.41736961374233383\n",
            "Loss in iteration no. 98222 ==> 0.4173686881938325\n",
            "Loss in iteration no. 98223 ==> 0.41736776265773773\n",
            "Loss in iteration no. 98224 ==> 0.41736683713404926\n",
            "Loss in iteration no. 98225 ==> 0.417365911622767\n",
            "Loss in iteration no. 98226 ==> 0.4173649861238905\n",
            "Loss in iteration no. 98227 ==> 0.4173640606374197\n",
            "Loss in iteration no. 98228 ==> 0.4173631351633543\n",
            "Loss in iteration no. 98229 ==> 0.417362209701694\n",
            "Loss in iteration no. 98230 ==> 0.4173612842524387\n",
            "Loss in iteration no. 98231 ==> 0.41736035881558803\n",
            "Loss in iteration no. 98232 ==> 0.4173594333911419\n",
            "Loss in iteration no. 98233 ==> 0.4173585079790999\n",
            "Loss in iteration no. 98234 ==> 0.417357582579462\n",
            "Loss in iteration no. 98235 ==> 0.4173566571922278\n",
            "Loss in iteration no. 98236 ==> 0.4173557318173971\n",
            "Loss in iteration no. 98237 ==> 0.41735480645496975\n",
            "Loss in iteration no. 98238 ==> 0.4173538811049455\n",
            "Loss in iteration no. 98239 ==> 0.41735295576732395\n",
            "Loss in iteration no. 98240 ==> 0.41735203044210506\n",
            "Loss in iteration no. 98241 ==> 0.41735110512928847\n",
            "Loss in iteration no. 98242 ==> 0.417350179828874\n",
            "Loss in iteration no. 98243 ==> 0.41734925454086147\n",
            "Loss in iteration no. 98244 ==> 0.41734832926525056\n",
            "Loss in iteration no. 98245 ==> 0.41734740400204107\n",
            "Loss in iteration no. 98246 ==> 0.41734647875123276\n",
            "Loss in iteration no. 98247 ==> 0.4173455535128253\n",
            "Loss in iteration no. 98248 ==> 0.4173446282868187\n",
            "Loss in iteration no. 98249 ==> 0.4173437030732125\n",
            "Loss in iteration no. 98250 ==> 0.41734277787200647\n",
            "Loss in iteration no. 98251 ==> 0.4173418526832005\n",
            "Loss in iteration no. 98252 ==> 0.4173409275067943\n",
            "Loss in iteration no. 98253 ==> 0.41734000234278773\n",
            "Loss in iteration no. 98254 ==> 0.41733907719118046\n",
            "Loss in iteration no. 98255 ==> 0.41733815205197217\n",
            "Loss in iteration no. 98256 ==> 0.4173372269251627\n",
            "Loss in iteration no. 98257 ==> 0.4173363018107518\n",
            "Loss in iteration no. 98258 ==> 0.4173353767087394\n",
            "Loss in iteration no. 98259 ==> 0.41733445161912497\n",
            "Loss in iteration no. 98260 ==> 0.4173335265419086\n",
            "Loss in iteration no. 98261 ==> 0.4173326014770898\n",
            "Loss in iteration no. 98262 ==> 0.4173316764246684\n",
            "Loss in iteration no. 98263 ==> 0.41733075138464426\n",
            "Loss in iteration no. 98264 ==> 0.4173298263570171\n",
            "Loss in iteration no. 98265 ==> 0.41732890134178663\n",
            "Loss in iteration no. 98266 ==> 0.41732797633895263\n",
            "Loss in iteration no. 98267 ==> 0.41732705134851483\n",
            "Loss in iteration no. 98268 ==> 0.4173261263704731\n",
            "Loss in iteration no. 98269 ==> 0.41732520140482726\n",
            "Loss in iteration no. 98270 ==> 0.4173242764515769\n",
            "Loss in iteration no. 98271 ==> 0.41732335151072186\n",
            "Loss in iteration no. 98272 ==> 0.4173224265822618\n",
            "Loss in iteration no. 98273 ==> 0.4173215016661968\n",
            "Loss in iteration no. 98274 ==> 0.41732057676252626\n",
            "Loss in iteration no. 98275 ==> 0.41731965187125014\n",
            "Loss in iteration no. 98276 ==> 0.4173187269923681\n",
            "Loss in iteration no. 98277 ==> 0.4173178021258801\n",
            "Loss in iteration no. 98278 ==> 0.41731687727178574\n",
            "Loss in iteration no. 98279 ==> 0.4173159524300848\n",
            "Loss in iteration no. 98280 ==> 0.417315027600777\n",
            "Loss in iteration no. 98281 ==> 0.4173141027838623\n",
            "Loss in iteration no. 98282 ==> 0.41731317797934026\n",
            "Loss in iteration no. 98283 ==> 0.4173122531872108\n",
            "Loss in iteration no. 98284 ==> 0.41731132840747354\n",
            "Loss in iteration no. 98285 ==> 0.4173104036401284\n",
            "Loss in iteration no. 98286 ==> 0.417309478885175\n",
            "Loss in iteration no. 98287 ==> 0.4173085541426132\n",
            "Loss in iteration no. 98288 ==> 0.4173076294124427\n",
            "Loss in iteration no. 98289 ==> 0.41730670469466336\n",
            "Loss in iteration no. 98290 ==> 0.4173057799892748\n",
            "Loss in iteration no. 98291 ==> 0.417304855296277\n",
            "Loss in iteration no. 98292 ==> 0.4173039306156694\n",
            "Loss in iteration no. 98293 ==> 0.4173030059474521\n",
            "Loss in iteration no. 98294 ==> 0.41730208129162477\n",
            "Loss in iteration no. 98295 ==> 0.4173011566481871\n",
            "Loss in iteration no. 98296 ==> 0.41730023201713884\n",
            "Loss in iteration no. 98297 ==> 0.41729930739847987\n",
            "Loss in iteration no. 98298 ==> 0.4172983827922099\n",
            "Loss in iteration no. 98299 ==> 0.4172974581983287\n",
            "Loss in iteration no. 98300 ==> 0.4172965336168359\n",
            "Loss in iteration no. 98301 ==> 0.41729560904773155\n",
            "Loss in iteration no. 98302 ==> 0.41729468449101514\n",
            "Loss in iteration no. 98303 ==> 0.4172937599466866\n",
            "Loss in iteration no. 98304 ==> 0.4172928354147457\n",
            "Loss in iteration no. 98305 ==> 0.41729191089519213\n",
            "Loss in iteration no. 98306 ==> 0.4172909863880256\n",
            "Loss in iteration no. 98307 ==> 0.41729006189324597\n",
            "Loss in iteration no. 98308 ==> 0.4172891374108531\n",
            "Loss in iteration no. 98309 ==> 0.4172882129408466\n",
            "Loss in iteration no. 98310 ==> 0.41728728848322627\n",
            "Loss in iteration no. 98311 ==> 0.4172863640379919\n",
            "Loss in iteration no. 98312 ==> 0.41728543960514325\n",
            "Loss in iteration no. 98313 ==> 0.41728451518467996\n",
            "Loss in iteration no. 98314 ==> 0.4172835907766021\n",
            "Loss in iteration no. 98315 ==> 0.41728266638090916\n",
            "Loss in iteration no. 98316 ==> 0.4172817419976011\n",
            "Loss in iteration no. 98317 ==> 0.4172808176266775\n",
            "Loss in iteration no. 98318 ==> 0.41727989326813825\n",
            "Loss in iteration no. 98319 ==> 0.417278968921983\n",
            "Loss in iteration no. 98320 ==> 0.41727804458821177\n",
            "Loss in iteration no. 98321 ==> 0.4172771202668239\n",
            "Loss in iteration no. 98322 ==> 0.41727619595781956\n",
            "Loss in iteration no. 98323 ==> 0.4172752716611984\n",
            "Loss in iteration no. 98324 ==> 0.41727434737696006\n",
            "Loss in iteration no. 98325 ==> 0.41727342310510435\n",
            "Loss in iteration no. 98326 ==> 0.4172724988456312\n",
            "Loss in iteration no. 98327 ==> 0.4172715745985402\n",
            "Loss in iteration no. 98328 ==> 0.41727065036383115\n",
            "Loss in iteration no. 98329 ==> 0.4172697261415038\n",
            "Loss in iteration no. 98330 ==> 0.4172688019315581\n",
            "Loss in iteration no. 98331 ==> 0.4172678777339936\n",
            "Loss in iteration no. 98332 ==> 0.4172669535488101\n",
            "Loss in iteration no. 98333 ==> 0.41726602937600743\n",
            "Loss in iteration no. 98334 ==> 0.41726510521558535\n",
            "Loss in iteration no. 98335 ==> 0.4172641810675436\n",
            "Loss in iteration no. 98336 ==> 0.4172632569318819\n",
            "Loss in iteration no. 98337 ==> 0.4172623328086001\n",
            "Loss in iteration no. 98338 ==> 0.4172614086976979\n",
            "Loss in iteration no. 98339 ==> 0.41726048459917514\n",
            "Loss in iteration no. 98340 ==> 0.41725956051303154\n",
            "Loss in iteration no. 98341 ==> 0.4172586364392668\n",
            "Loss in iteration no. 98342 ==> 0.41725771237788084\n",
            "Loss in iteration no. 98343 ==> 0.4172567883288733\n",
            "Loss in iteration no. 98344 ==> 0.4172558642922441\n",
            "Loss in iteration no. 98345 ==> 0.41725494026799276\n",
            "Loss in iteration no. 98346 ==> 0.41725401625611924\n",
            "Loss in iteration no. 98347 ==> 0.4172530922566232\n",
            "Loss in iteration no. 98348 ==> 0.41725216826950445\n",
            "Loss in iteration no. 98349 ==> 0.41725124429476285\n",
            "Loss in iteration no. 98350 ==> 0.41725032033239795\n",
            "Loss in iteration no. 98351 ==> 0.41724939638240977\n",
            "Loss in iteration no. 98352 ==> 0.4172484724447979\n",
            "Loss in iteration no. 98353 ==> 0.4172475485195621\n",
            "Loss in iteration no. 98354 ==> 0.41724662460670225\n",
            "Loss in iteration no. 98355 ==> 0.41724570070621814\n",
            "Loss in iteration no. 98356 ==> 0.41724477681810923\n",
            "Loss in iteration no. 98357 ==> 0.4172438529423757\n",
            "Loss in iteration no. 98358 ==> 0.41724292907901706\n",
            "Loss in iteration no. 98359 ==> 0.4172420052280332\n",
            "Loss in iteration no. 98360 ==> 0.4172410813894237\n",
            "Loss in iteration no. 98361 ==> 0.41724015756318855\n",
            "Loss in iteration no. 98362 ==> 0.41723923374932737\n",
            "Loss in iteration no. 98363 ==> 0.41723830994783995\n",
            "Loss in iteration no. 98364 ==> 0.4172373861587262\n",
            "Loss in iteration no. 98365 ==> 0.41723646238198564\n",
            "Loss in iteration no. 98366 ==> 0.41723553861761825\n",
            "Loss in iteration no. 98367 ==> 0.4172346148656237\n",
            "Loss in iteration no. 98368 ==> 0.4172336911260017\n",
            "Loss in iteration no. 98369 ==> 0.41723276739875215\n",
            "Loss in iteration no. 98370 ==> 0.4172318436838747\n",
            "Loss in iteration no. 98371 ==> 0.41723091998136924\n",
            "Loss in iteration no. 98372 ==> 0.4172299962912354\n",
            "Loss in iteration no. 98373 ==> 0.4172290726134731\n",
            "Loss in iteration no. 98374 ==> 0.41722814894808186\n",
            "Loss in iteration no. 98375 ==> 0.4172272252950617\n",
            "Loss in iteration no. 98376 ==> 0.4172263016544122\n",
            "Loss in iteration no. 98377 ==> 0.41722537802613335\n",
            "Loss in iteration no. 98378 ==> 0.4172244544102247\n",
            "Loss in iteration no. 98379 ==> 0.4172235308066861\n",
            "Loss in iteration no. 98380 ==> 0.4172226072155173\n",
            "Loss in iteration no. 98381 ==> 0.41722168363671813\n",
            "Loss in iteration no. 98382 ==> 0.41722076007028824\n",
            "Loss in iteration no. 98383 ==> 0.4172198365162275\n",
            "Loss in iteration no. 98384 ==> 0.41721891297453567\n",
            "Loss in iteration no. 98385 ==> 0.4172179894452124\n",
            "Loss in iteration no. 98386 ==> 0.4172170659282576\n",
            "Loss in iteration no. 98387 ==> 0.417216142423671\n",
            "Loss in iteration no. 98388 ==> 0.41721521893145225\n",
            "Loss in iteration no. 98389 ==> 0.4172142954516013\n",
            "Loss in iteration no. 98390 ==> 0.4172133719841178\n",
            "Loss in iteration no. 98391 ==> 0.4172124485290015\n",
            "Loss in iteration no. 98392 ==> 0.4172115250862523\n",
            "Loss in iteration no. 98393 ==> 0.41721060165586976\n",
            "Loss in iteration no. 98394 ==> 0.4172096782378538\n",
            "Loss in iteration no. 98395 ==> 0.41720875483220426\n",
            "Loss in iteration no. 98396 ==> 0.4172078314389206\n",
            "Loss in iteration no. 98397 ==> 0.4172069080580029\n",
            "Loss in iteration no. 98398 ==> 0.41720598468945075\n",
            "Loss in iteration no. 98399 ==> 0.41720506133326407\n",
            "Loss in iteration no. 98400 ==> 0.41720413798944245\n",
            "Loss in iteration no. 98401 ==> 0.4172032146579857\n",
            "Loss in iteration no. 98402 ==> 0.4172022913388937\n",
            "Loss in iteration no. 98403 ==> 0.41720136803216606\n",
            "Loss in iteration no. 98404 ==> 0.4172004447378026\n",
            "Loss in iteration no. 98405 ==> 0.4171995214558033\n",
            "Loss in iteration no. 98406 ==> 0.41719859818616756\n",
            "Loss in iteration no. 98407 ==> 0.41719767492889537\n",
            "Loss in iteration no. 98408 ==> 0.41719675168398657\n",
            "Loss in iteration no. 98409 ==> 0.41719582845144065\n",
            "Loss in iteration no. 98410 ==> 0.4171949052312576\n",
            "Loss in iteration no. 98411 ==> 0.41719398202343716\n",
            "Loss in iteration no. 98412 ==> 0.41719305882797897\n",
            "Loss in iteration no. 98413 ==> 0.41719213564488294\n",
            "Loss in iteration no. 98414 ==> 0.4171912124741487\n",
            "Loss in iteration no. 98415 ==> 0.4171902893157762\n",
            "Loss in iteration no. 98416 ==> 0.417189366169765\n",
            "Loss in iteration no. 98417 ==> 0.41718844303611513\n",
            "Loss in iteration no. 98418 ==> 0.417187519914826\n",
            "Loss in iteration no. 98419 ==> 0.4171865968058977\n",
            "Loss in iteration no. 98420 ==> 0.41718567370932985\n",
            "Loss in iteration no. 98421 ==> 0.41718475062512217\n",
            "Loss in iteration no. 98422 ==> 0.41718382755327454\n",
            "Loss in iteration no. 98423 ==> 0.4171829044937867\n",
            "Loss in iteration no. 98424 ==> 0.4171819814466584\n",
            "Loss in iteration no. 98425 ==> 0.41718105841188935\n",
            "Loss in iteration no. 98426 ==> 0.41718013538947935\n",
            "Loss in iteration no. 98427 ==> 0.41717921237942823\n",
            "Loss in iteration no. 98428 ==> 0.4171782893817358\n",
            "Loss in iteration no. 98429 ==> 0.4171773663964016\n",
            "Loss in iteration no. 98430 ==> 0.41717644342342564\n",
            "Loss in iteration no. 98431 ==> 0.4171755204628075\n",
            "Loss in iteration no. 98432 ==> 0.41717459751454705\n",
            "Loss in iteration no. 98433 ==> 0.41717367457864407\n",
            "Loss in iteration no. 98434 ==> 0.4171727516550982\n",
            "Loss in iteration no. 98435 ==> 0.41717182874390935\n",
            "Loss in iteration no. 98436 ==> 0.41717090584507727\n",
            "Loss in iteration no. 98437 ==> 0.41716998295860164\n",
            "Loss in iteration no. 98438 ==> 0.4171690600844823\n",
            "Loss in iteration no. 98439 ==> 0.41716813722271895\n",
            "Loss in iteration no. 98440 ==> 0.41716721437331156\n",
            "Loss in iteration no. 98441 ==> 0.41716629153625956\n",
            "Loss in iteration no. 98442 ==> 0.41716536871156296\n",
            "Loss in iteration no. 98443 ==> 0.4171644458992214\n",
            "Loss in iteration no. 98444 ==> 0.41716352309923477\n",
            "Loss in iteration no. 98445 ==> 0.4171626003116028\n",
            "Loss in iteration no. 98446 ==> 0.41716167753632516\n",
            "Loss in iteration no. 98447 ==> 0.41716075477340175\n",
            "Loss in iteration no. 98448 ==> 0.4171598320228323\n",
            "Loss in iteration no. 98449 ==> 0.41715890928461646\n",
            "Loss in iteration no. 98450 ==> 0.4171579865587541\n",
            "Loss in iteration no. 98451 ==> 0.417157063845245\n",
            "Loss in iteration no. 98452 ==> 0.41715614114408894\n",
            "Loss in iteration no. 98453 ==> 0.41715521845528564\n",
            "Loss in iteration no. 98454 ==> 0.4171542957788347\n",
            "Loss in iteration no. 98455 ==> 0.41715337311473627\n",
            "Loss in iteration no. 98456 ==> 0.4171524504629898\n",
            "Loss in iteration no. 98457 ==> 0.41715152782359527\n",
            "Loss in iteration no. 98458 ==> 0.4171506051965523\n",
            "Loss in iteration no. 98459 ==> 0.41714968258186064\n",
            "Loss in iteration no. 98460 ==> 0.41714875997952017\n",
            "Loss in iteration no. 98461 ==> 0.41714783738953054\n",
            "Loss in iteration no. 98462 ==> 0.41714691481189164\n",
            "Loss in iteration no. 98463 ==> 0.41714599224660315\n",
            "Loss in iteration no. 98464 ==> 0.4171450696936649\n",
            "Loss in iteration no. 98465 ==> 0.4171441471530765\n",
            "Loss in iteration no. 98466 ==> 0.4171432246248379\n",
            "Loss in iteration no. 98467 ==> 0.4171423021089488\n",
            "Loss in iteration no. 98468 ==> 0.41714137960540904\n",
            "Loss in iteration no. 98469 ==> 0.41714045711421827\n",
            "Loss in iteration no. 98470 ==> 0.4171395346353763\n",
            "Loss in iteration no. 98471 ==> 0.4171386121688829\n",
            "Loss in iteration no. 98472 ==> 0.4171376897147378\n",
            "Loss in iteration no. 98473 ==> 0.41713676727294086\n",
            "Loss in iteration no. 98474 ==> 0.4171358448434917\n",
            "Loss in iteration no. 98475 ==> 0.4171349224263902\n",
            "Loss in iteration no. 98476 ==> 0.41713400002163614\n",
            "Loss in iteration no. 98477 ==> 0.4171330776292293\n",
            "Loss in iteration no. 98478 ==> 0.41713215524916936\n",
            "Loss in iteration no. 98479 ==> 0.4171312328814561\n",
            "Loss in iteration no. 98480 ==> 0.41713031052608934\n",
            "Loss in iteration no. 98481 ==> 0.4171293881830688\n",
            "Loss in iteration no. 98482 ==> 0.4171284658523943\n",
            "Loss in iteration no. 98483 ==> 0.4171275435340655\n",
            "Loss in iteration no. 98484 ==> 0.4171266212280823\n",
            "Loss in iteration no. 98485 ==> 0.4171256989344444\n",
            "Loss in iteration no. 98486 ==> 0.4171247766531515\n",
            "Loss in iteration no. 98487 ==> 0.4171238543842035\n",
            "Loss in iteration no. 98488 ==> 0.4171229321276001\n",
            "Loss in iteration no. 98489 ==> 0.4171220098833411\n",
            "Loss in iteration no. 98490 ==> 0.41712108765142614\n",
            "Loss in iteration no. 98491 ==> 0.4171201654318552\n",
            "Loss in iteration no. 98492 ==> 0.4171192432246279\n",
            "Loss in iteration no. 98493 ==> 0.41711832102974405\n",
            "Loss in iteration no. 98494 ==> 0.4171173988472034\n",
            "Loss in iteration no. 98495 ==> 0.41711647667700563\n",
            "Loss in iteration no. 98496 ==> 0.4171155545191508\n",
            "Loss in iteration no. 98497 ==> 0.41711463237363827\n",
            "Loss in iteration no. 98498 ==> 0.41711371024046806\n",
            "Loss in iteration no. 98499 ==> 0.4171127881196401\n",
            "Loss in iteration no. 98500 ==> 0.4171118660111537\n",
            "Loss in iteration no. 98501 ==> 0.417110943915009\n",
            "Loss in iteration no. 98502 ==> 0.41711002183120566\n",
            "Loss in iteration no. 98503 ==> 0.41710909975974336\n",
            "Loss in iteration no. 98504 ==> 0.41710817770062186\n",
            "Loss in iteration no. 98505 ==> 0.4171072556538411\n",
            "Loss in iteration no. 98506 ==> 0.4171063336194008\n",
            "Loss in iteration no. 98507 ==> 0.41710541159730063\n",
            "Loss in iteration no. 98508 ==> 0.41710448958754043\n",
            "Loss in iteration no. 98509 ==> 0.4171035675901199\n",
            "Loss in iteration no. 98510 ==> 0.4171026456050388\n",
            "Loss in iteration no. 98511 ==> 0.4171017236322971\n",
            "Loss in iteration no. 98512 ==> 0.41710080167189434\n",
            "Loss in iteration no. 98513 ==> 0.41709987972383034\n",
            "Loss in iteration no. 98514 ==> 0.41709895778810485\n",
            "Loss in iteration no. 98515 ==> 0.4170980358647177\n",
            "Loss in iteration no. 98516 ==> 0.4170971139536687\n",
            "Loss in iteration no. 98517 ==> 0.41709619205495746\n",
            "Loss in iteration no. 98518 ==> 0.41709527016858394\n",
            "Loss in iteration no. 98519 ==> 0.4170943482945477\n",
            "Loss in iteration no. 98520 ==> 0.4170934264328487\n",
            "Loss in iteration no. 98521 ==> 0.41709250458348646\n",
            "Loss in iteration no. 98522 ==> 0.417091582746461\n",
            "Loss in iteration no. 98523 ==> 0.41709066092177205\n",
            "Loss in iteration no. 98524 ==> 0.41708973910941927\n",
            "Loss in iteration no. 98525 ==> 0.41708881730940256\n",
            "Loss in iteration no. 98526 ==> 0.4170878955217215\n",
            "Loss in iteration no. 98527 ==> 0.417086973746376\n",
            "Loss in iteration no. 98528 ==> 0.41708605198336574\n",
            "Loss in iteration no. 98529 ==> 0.41708513023269056\n",
            "Loss in iteration no. 98530 ==> 0.41708420849435013\n",
            "Loss in iteration no. 98531 ==> 0.41708328676834444\n",
            "Loss in iteration no. 98532 ==> 0.417082365054673\n",
            "Loss in iteration no. 98533 ==> 0.4170814433533357\n",
            "Loss in iteration no. 98534 ==> 0.41708052166433235\n",
            "Loss in iteration no. 98535 ==> 0.4170795999876625\n",
            "Loss in iteration no. 98536 ==> 0.4170786783233263\n",
            "Loss in iteration no. 98537 ==> 0.4170777566713232\n",
            "Loss in iteration no. 98538 ==> 0.417076835031653\n",
            "Loss in iteration no. 98539 ==> 0.41707591340431555\n",
            "Loss in iteration no. 98540 ==> 0.41707499178931057\n",
            "Loss in iteration no. 98541 ==> 0.41707407018663795\n",
            "Loss in iteration no. 98542 ==> 0.4170731485962972\n",
            "Loss in iteration no. 98543 ==> 0.4170722270182884\n",
            "Loss in iteration no. 98544 ==> 0.41707130545261106\n",
            "Loss in iteration no. 98545 ==> 0.4170703838992651\n",
            "Loss in iteration no. 98546 ==> 0.41706946235825015\n",
            "Loss in iteration no. 98547 ==> 0.4170685408295662\n",
            "Loss in iteration no. 98548 ==> 0.4170676193132128\n",
            "Loss in iteration no. 98549 ==> 0.4170666978091898\n",
            "Loss in iteration no. 98550 ==> 0.41706577631749703\n",
            "Loss in iteration no. 98551 ==> 0.4170648548381341\n",
            "Loss in iteration no. 98552 ==> 0.4170639333711009\n",
            "Loss in iteration no. 98553 ==> 0.4170630119163972\n",
            "Loss in iteration no. 98554 ==> 0.4170620904740227\n",
            "Loss in iteration no. 98555 ==> 0.4170611690439772\n",
            "Loss in iteration no. 98556 ==> 0.41706024762626054\n",
            "Loss in iteration no. 98557 ==> 0.41705932622087244\n",
            "Loss in iteration no. 98558 ==> 0.41705840482781253\n",
            "Loss in iteration no. 98559 ==> 0.4170574834470807\n",
            "Loss in iteration no. 98560 ==> 0.41705656207867675\n",
            "Loss in iteration no. 98561 ==> 0.4170556407226004\n",
            "Loss in iteration no. 98562 ==> 0.41705471937885136\n",
            "Loss in iteration no. 98563 ==> 0.4170537980474295\n",
            "Loss in iteration no. 98564 ==> 0.41705287672833463\n",
            "Loss in iteration no. 98565 ==> 0.41705195542156637\n",
            "Loss in iteration no. 98566 ==> 0.4170510341271246\n",
            "Loss in iteration no. 98567 ==> 0.4170501128450089\n",
            "Loss in iteration no. 98568 ==> 0.41704919157521925\n",
            "Loss in iteration no. 98569 ==> 0.41704827031775543\n",
            "Loss in iteration no. 98570 ==> 0.417047349072617\n",
            "Loss in iteration no. 98571 ==> 0.4170464278398039\n",
            "Loss in iteration no. 98572 ==> 0.4170455066193159\n",
            "Loss in iteration no. 98573 ==> 0.41704458541115264\n",
            "Loss in iteration no. 98574 ==> 0.4170436642153139\n",
            "Loss in iteration no. 98575 ==> 0.41704274303179967\n",
            "Loss in iteration no. 98576 ==> 0.41704182186060945\n",
            "Loss in iteration no. 98577 ==> 0.4170409007017432\n",
            "Loss in iteration no. 98578 ==> 0.41703997955520056\n",
            "Loss in iteration no. 98579 ==> 0.4170390584209813\n",
            "Loss in iteration no. 98580 ==> 0.41703813729908523\n",
            "Loss in iteration no. 98581 ==> 0.41703721618951217\n",
            "Loss in iteration no. 98582 ==> 0.4170362950922618\n",
            "Loss in iteration no. 98583 ==> 0.4170353740073339\n",
            "Loss in iteration no. 98584 ==> 0.4170344529347283\n",
            "Loss in iteration no. 98585 ==> 0.41703353187444464\n",
            "Loss in iteration no. 98586 ==> 0.41703261082648285\n",
            "Loss in iteration no. 98587 ==> 0.41703168979084265\n",
            "Loss in iteration no. 98588 ==> 0.41703076876752365\n",
            "Loss in iteration no. 98589 ==> 0.4170298477565258\n",
            "Loss in iteration no. 98590 ==> 0.4170289267578488\n",
            "Loss in iteration no. 98591 ==> 0.4170280057714925\n",
            "Loss in iteration no. 98592 ==> 0.4170270847974566\n",
            "Loss in iteration no. 98593 ==> 0.41702616383574076\n",
            "Loss in iteration no. 98594 ==> 0.41702524288634485\n",
            "Loss in iteration no. 98595 ==> 0.4170243219492687\n",
            "Loss in iteration no. 98596 ==> 0.4170234010245121\n",
            "Loss in iteration no. 98597 ==> 0.4170224801120746\n",
            "Loss in iteration no. 98598 ==> 0.4170215592119561\n",
            "Loss in iteration no. 98599 ==> 0.4170206383241565\n",
            "Loss in iteration no. 98600 ==> 0.4170197174486753\n",
            "Loss in iteration no. 98601 ==> 0.4170187965855125\n",
            "Loss in iteration no. 98602 ==> 0.41701787573466764\n",
            "Loss in iteration no. 98603 ==> 0.4170169548961407\n",
            "Loss in iteration no. 98604 ==> 0.4170160340699314\n",
            "Loss in iteration no. 98605 ==> 0.4170151132560394\n",
            "Loss in iteration no. 98606 ==> 0.4170141924544646\n",
            "Loss in iteration no. 98607 ==> 0.4170132716652067\n",
            "Loss in iteration no. 98608 ==> 0.41701235088826544\n",
            "Loss in iteration no. 98609 ==> 0.41701143012364067\n",
            "Loss in iteration no. 98610 ==> 0.417010509371332\n",
            "Loss in iteration no. 98611 ==> 0.41700958863133936\n",
            "Loss in iteration no. 98612 ==> 0.41700866790366253\n",
            "Loss in iteration no. 98613 ==> 0.41700774718830125\n",
            "Loss in iteration no. 98614 ==> 0.4170068264852552\n",
            "Loss in iteration no. 98615 ==> 0.4170059057945241\n",
            "Loss in iteration no. 98616 ==> 0.41700498511610795\n",
            "Loss in iteration no. 98617 ==> 0.4170040644500063\n",
            "Loss in iteration no. 98618 ==> 0.4170031437962191\n",
            "Loss in iteration no. 98619 ==> 0.417002223154746\n",
            "Loss in iteration no. 98620 ==> 0.41700130252558676\n",
            "Loss in iteration no. 98621 ==> 0.41700038190874117\n",
            "Loss in iteration no. 98622 ==> 0.41699946130420895\n",
            "Loss in iteration no. 98623 ==> 0.41699854071198994\n",
            "Loss in iteration no. 98624 ==> 0.41699762013208397\n",
            "Loss in iteration no. 98625 ==> 0.41699669956449065\n",
            "Loss in iteration no. 98626 ==> 0.41699577900920987\n",
            "Loss in iteration no. 98627 ==> 0.4169948584662413\n",
            "Loss in iteration no. 98628 ==> 0.41699393793558476\n",
            "Loss in iteration no. 98629 ==> 0.4169930174172401\n",
            "Loss in iteration no. 98630 ==> 0.4169920969112069\n",
            "Loss in iteration no. 98631 ==> 0.4169911764174851\n",
            "Loss in iteration no. 98632 ==> 0.4169902559360744\n",
            "Loss in iteration no. 98633 ==> 0.41698933546697464\n",
            "Loss in iteration no. 98634 ==> 0.4169884150101854\n",
            "Loss in iteration no. 98635 ==> 0.4169874945657066\n",
            "Loss in iteration no. 98636 ==> 0.4169865741335379\n",
            "Loss in iteration no. 98637 ==> 0.4169856537136792\n",
            "Loss in iteration no. 98638 ==> 0.41698473330613023\n",
            "Loss in iteration no. 98639 ==> 0.4169838129108907\n",
            "Loss in iteration no. 98640 ==> 0.4169828925279604\n",
            "Loss in iteration no. 98641 ==> 0.4169819721573391\n",
            "Loss in iteration no. 98642 ==> 0.41698105179902667\n",
            "Loss in iteration no. 98643 ==> 0.41698013145302276\n",
            "Loss in iteration no. 98644 ==> 0.4169792111193271\n",
            "Loss in iteration no. 98645 ==> 0.4169782907979396\n",
            "Loss in iteration no. 98646 ==> 0.4169773704888599\n",
            "Loss in iteration no. 98647 ==> 0.41697645019208784\n",
            "Loss in iteration no. 98648 ==> 0.41697552990762315\n",
            "Loss in iteration no. 98649 ==> 0.4169746096354656\n",
            "Loss in iteration no. 98650 ==> 0.41697368937561496\n",
            "Loss in iteration no. 98651 ==> 0.416972769128071\n",
            "Loss in iteration no. 98652 ==> 0.41697184889283356\n",
            "Loss in iteration no. 98653 ==> 0.4169709286699023\n",
            "Loss in iteration no. 98654 ==> 0.416970008459277\n",
            "Loss in iteration no. 98655 ==> 0.4169690882609575\n",
            "Loss in iteration no. 98656 ==> 0.4169681680749436\n",
            "Loss in iteration no. 98657 ==> 0.4169672479012349\n",
            "Loss in iteration no. 98658 ==> 0.41696632773983117\n",
            "Loss in iteration no. 98659 ==> 0.4169654075907325\n",
            "Loss in iteration no. 98660 ==> 0.41696448745393827\n",
            "Loss in iteration no. 98661 ==> 0.4169635673294484\n",
            "Loss in iteration no. 98662 ==> 0.4169626472172628\n",
            "Loss in iteration no. 98663 ==> 0.41696172711738094\n",
            "Loss in iteration no. 98664 ==> 0.41696080702980287\n",
            "Loss in iteration no. 98665 ==> 0.4169598869545281\n",
            "Loss in iteration no. 98666 ==> 0.4169589668915567\n",
            "Loss in iteration no. 98667 ==> 0.4169580468408883\n",
            "Loss in iteration no. 98668 ==> 0.4169571268025224\n",
            "Loss in iteration no. 98669 ==> 0.4169562067764592\n",
            "Loss in iteration no. 98670 ==> 0.4169552867626982\n",
            "Loss in iteration no. 98671 ==> 0.4169543667612393\n",
            "Loss in iteration no. 98672 ==> 0.41695344677208224\n",
            "Loss in iteration no. 98673 ==> 0.4169525267952267\n",
            "Loss in iteration no. 98674 ==> 0.4169516068306726\n",
            "Loss in iteration no. 98675 ==> 0.4169506868784195\n",
            "Loss in iteration no. 98676 ==> 0.41694976693846725\n",
            "Loss in iteration no. 98677 ==> 0.41694884701081575\n",
            "Loss in iteration no. 98678 ==> 0.41694792709546474\n",
            "Loss in iteration no. 98679 ==> 0.4169470071924138\n",
            "Loss in iteration no. 98680 ==> 0.4169460873016629\n",
            "Loss in iteration no. 98681 ==> 0.41694516742321164\n",
            "Loss in iteration no. 98682 ==> 0.41694424755705994\n",
            "Loss in iteration no. 98683 ==> 0.41694332770320747\n",
            "Loss in iteration no. 98684 ==> 0.416942407861654\n",
            "Loss in iteration no. 98685 ==> 0.41694148803239933\n",
            "Loss in iteration no. 98686 ==> 0.4169405682154433\n",
            "Loss in iteration no. 98687 ==> 0.41693964841078557\n",
            "Loss in iteration no. 98688 ==> 0.4169387286184259\n",
            "Loss in iteration no. 98689 ==> 0.4169378088383642\n",
            "Loss in iteration no. 98690 ==> 0.4169368890706\n",
            "Loss in iteration no. 98691 ==> 0.41693596931513327\n",
            "Loss in iteration no. 98692 ==> 0.4169350495719637\n",
            "Loss in iteration no. 98693 ==> 0.4169341298410911\n",
            "Loss in iteration no. 98694 ==> 0.4169332101225152\n",
            "Loss in iteration no. 98695 ==> 0.41693229041623586\n",
            "Loss in iteration no. 98696 ==> 0.41693137072225267\n",
            "Loss in iteration no. 98697 ==> 0.4169304510405654\n",
            "Loss in iteration no. 98698 ==> 0.4169295313711741\n",
            "Loss in iteration no. 98699 ==> 0.41692861171407825\n",
            "Loss in iteration no. 98700 ==> 0.4169276920692777\n",
            "Loss in iteration no. 98701 ==> 0.4169267724367724\n",
            "Loss in iteration no. 98702 ==> 0.41692585281656175\n",
            "Loss in iteration no. 98703 ==> 0.41692493320864576\n",
            "Loss in iteration no. 98704 ==> 0.4169240136130243\n",
            "Loss in iteration no. 98705 ==> 0.41692309402969685\n",
            "Loss in iteration no. 98706 ==> 0.41692217445866336\n",
            "Loss in iteration no. 98707 ==> 0.41692125489992365\n",
            "Loss in iteration no. 98708 ==> 0.4169203353534774\n",
            "Loss in iteration no. 98709 ==> 0.41691941581932423\n",
            "Loss in iteration no. 98710 ==> 0.4169184962974642\n",
            "Loss in iteration no. 98711 ==> 0.41691757678789687\n",
            "Loss in iteration no. 98712 ==> 0.41691665729062216\n",
            "Loss in iteration no. 98713 ==> 0.4169157378056397\n",
            "Loss in iteration no. 98714 ==> 0.4169148183329493\n",
            "Loss in iteration no. 98715 ==> 0.41691389887255076\n",
            "Loss in iteration no. 98716 ==> 0.41691297942444383\n",
            "Loss in iteration no. 98717 ==> 0.4169120599886283\n",
            "Loss in iteration no. 98718 ==> 0.4169111405651038\n",
            "Loss in iteration no. 98719 ==> 0.41691022115387033\n",
            "Loss in iteration no. 98720 ==> 0.4169093017549275\n",
            "Loss in iteration no. 98721 ==> 0.4169083823682751\n",
            "Loss in iteration no. 98722 ==> 0.416907462993913\n",
            "Loss in iteration no. 98723 ==> 0.4169065436318408\n",
            "Loss in iteration no. 98724 ==> 0.41690562428205846\n",
            "Loss in iteration no. 98725 ==> 0.41690470494456555\n",
            "Loss in iteration no. 98726 ==> 0.4169037856193619\n",
            "Loss in iteration no. 98727 ==> 0.41690286630644735\n",
            "Loss in iteration no. 98728 ==> 0.41690194700582167\n",
            "Loss in iteration no. 98729 ==> 0.4169010277174845\n",
            "Loss in iteration no. 98730 ==> 0.41690010844143577\n",
            "Loss in iteration no. 98731 ==> 0.4168991891776752\n",
            "Loss in iteration no. 98732 ==> 0.4168982699262025\n",
            "Loss in iteration no. 98733 ==> 0.4168973506870175\n",
            "Loss in iteration no. 98734 ==> 0.41689643146011984\n",
            "Loss in iteration no. 98735 ==> 0.41689551224550947\n",
            "Loss in iteration no. 98736 ==> 0.41689459304318605\n",
            "Loss in iteration no. 98737 ==> 0.41689367385314935\n",
            "Loss in iteration no. 98738 ==> 0.41689275467539916\n",
            "Loss in iteration no. 98739 ==> 0.41689183550993525\n",
            "Loss in iteration no. 98740 ==> 0.4168909163567574\n",
            "Loss in iteration no. 98741 ==> 0.4168899972158654\n",
            "Loss in iteration no. 98742 ==> 0.41688907808725895\n",
            "Loss in iteration no. 98743 ==> 0.4168881589709379\n",
            "Loss in iteration no. 98744 ==> 0.41688723986690196\n",
            "Loss in iteration no. 98745 ==> 0.41688632077515086\n",
            "Loss in iteration no. 98746 ==> 0.4168854016956844\n",
            "Loss in iteration no. 98747 ==> 0.41688448262850236\n",
            "Loss in iteration no. 98748 ==> 0.41688356357360457\n",
            "Loss in iteration no. 98749 ==> 0.4168826445309908\n",
            "Loss in iteration no. 98750 ==> 0.4168817255006606\n",
            "Loss in iteration no. 98751 ==> 0.416880806482614\n",
            "Loss in iteration no. 98752 ==> 0.41687988747685073\n",
            "Loss in iteration no. 98753 ==> 0.4168789684833704\n",
            "Loss in iteration no. 98754 ==> 0.4168780495021729\n",
            "Loss in iteration no. 98755 ==> 0.4168771305332579\n",
            "Loss in iteration no. 98756 ==> 0.41687621157662547\n",
            "Loss in iteration no. 98757 ==> 0.4168752926322749\n",
            "Loss in iteration no. 98758 ==> 0.41687437370020625\n",
            "Loss in iteration no. 98759 ==> 0.4168734547804194\n",
            "Loss in iteration no. 98760 ==> 0.4168725358729138\n",
            "Loss in iteration no. 98761 ==> 0.41687161697768943\n",
            "Loss in iteration no. 98762 ==> 0.41687069809474603\n",
            "Loss in iteration no. 98763 ==> 0.41686977922408336\n",
            "Loss in iteration no. 98764 ==> 0.4168688603657012\n",
            "Loss in iteration no. 98765 ==> 0.4168679415195992\n",
            "Loss in iteration no. 98766 ==> 0.41686702268577736\n",
            "Loss in iteration no. 98767 ==> 0.4168661038642352\n",
            "Loss in iteration no. 98768 ==> 0.41686518505497266\n",
            "Loss in iteration no. 98769 ==> 0.4168642662579895\n",
            "Loss in iteration no. 98770 ==> 0.41686334747328535\n",
            "Loss in iteration no. 98771 ==> 0.4168624287008601\n",
            "Loss in iteration no. 98772 ==> 0.41686150994071347\n",
            "Loss in iteration no. 98773 ==> 0.4168605911928453\n",
            "Loss in iteration no. 98774 ==> 0.41685967245725525\n",
            "Loss in iteration no. 98775 ==> 0.4168587537339431\n",
            "Loss in iteration no. 98776 ==> 0.41685783502290874\n",
            "Loss in iteration no. 98777 ==> 0.4168569163241519\n",
            "Loss in iteration no. 98778 ==> 0.4168559976376722\n",
            "Loss in iteration no. 98779 ==> 0.4168550789634696\n",
            "Loss in iteration no. 98780 ==> 0.4168541603015437\n",
            "Loss in iteration no. 98781 ==> 0.4168532416518944\n",
            "Loss in iteration no. 98782 ==> 0.4168523230145215\n",
            "Loss in iteration no. 98783 ==> 0.4168514043894246\n",
            "Loss in iteration no. 98784 ==> 0.4168504857766036\n",
            "Loss in iteration no. 98785 ==> 0.41684956717605814\n",
            "Loss in iteration no. 98786 ==> 0.4168486485877882\n",
            "Loss in iteration no. 98787 ==> 0.41684773001179337\n",
            "Loss in iteration no. 98788 ==> 0.41684681144807345\n",
            "Loss in iteration no. 98789 ==> 0.41684589289662827\n",
            "Loss in iteration no. 98790 ==> 0.41684497435745754\n",
            "Loss in iteration no. 98791 ==> 0.41684405583056106\n",
            "Loss in iteration no. 98792 ==> 0.41684313731593853\n",
            "Loss in iteration no. 98793 ==> 0.41684221881358985\n",
            "Loss in iteration no. 98794 ==> 0.41684130032351474\n",
            "Loss in iteration no. 98795 ==> 0.4168403818457129\n",
            "Loss in iteration no. 98796 ==> 0.4168394633801842\n",
            "Loss in iteration no. 98797 ==> 0.41683854492692823\n",
            "Loss in iteration no. 98798 ==> 0.416837626485945\n",
            "Loss in iteration no. 98799 ==> 0.4168367080572341\n",
            "Loss in iteration no. 98800 ==> 0.4168357896407954\n",
            "Loss in iteration no. 98801 ==> 0.41683487123662855\n",
            "Loss in iteration no. 98802 ==> 0.4168339528447334\n",
            "Loss in iteration no. 98803 ==> 0.4168330344651098\n",
            "Loss in iteration no. 98804 ==> 0.41683211609775744\n",
            "Loss in iteration no. 98805 ==> 0.41683119774267596\n",
            "Loss in iteration no. 98806 ==> 0.4168302793998654\n",
            "Loss in iteration no. 98807 ==> 0.4168293610693253\n",
            "Loss in iteration no. 98808 ==> 0.4168284427510554\n",
            "Loss in iteration no. 98809 ==> 0.4168275244450557\n",
            "Loss in iteration no. 98810 ==> 0.4168266061513259\n",
            "Loss in iteration no. 98811 ==> 0.41682568786986557\n",
            "Loss in iteration no. 98812 ==> 0.41682476960067466\n",
            "Loss in iteration no. 98813 ==> 0.41682385134375294\n",
            "Loss in iteration no. 98814 ==> 0.4168229330991002\n",
            "Loss in iteration no. 98815 ==> 0.41682201486671605\n",
            "Loss in iteration no. 98816 ==> 0.4168210966466003\n",
            "Loss in iteration no. 98817 ==> 0.41682017843875296\n",
            "Loss in iteration no. 98818 ==> 0.4168192602431735\n",
            "Loss in iteration no. 98819 ==> 0.41681834205986185\n",
            "Loss in iteration no. 98820 ==> 0.4168174238888177\n",
            "Loss in iteration no. 98821 ==> 0.4168165057300408\n",
            "Loss in iteration no. 98822 ==> 0.41681558758353104\n",
            "Loss in iteration no. 98823 ==> 0.41681466944928813\n",
            "Loss in iteration no. 98824 ==> 0.41681375132731185\n",
            "Loss in iteration no. 98825 ==> 0.4168128332176018\n",
            "Loss in iteration no. 98826 ==> 0.4168119151201581\n",
            "Loss in iteration no. 98827 ==> 0.41681099703498015\n",
            "Loss in iteration no. 98828 ==> 0.4168100789620679\n",
            "Loss in iteration no. 98829 ==> 0.4168091609014211\n",
            "Loss in iteration no. 98830 ==> 0.4168082428530396\n",
            "Loss in iteration no. 98831 ==> 0.416807324816923\n",
            "Loss in iteration no. 98832 ==> 0.4168064067930712\n",
            "Loss in iteration no. 98833 ==> 0.416805488781484\n",
            "Loss in iteration no. 98834 ==> 0.41680457078216104\n",
            "Loss in iteration no. 98835 ==> 0.4168036527951021\n",
            "Loss in iteration no. 98836 ==> 0.41680273482030705\n",
            "Loss in iteration no. 98837 ==> 0.41680181685777556\n",
            "Loss in iteration no. 98838 ==> 0.4168008989075075\n",
            "Loss in iteration no. 98839 ==> 0.4167999809695025\n",
            "Loss in iteration no. 98840 ==> 0.41679906304376046\n",
            "Loss in iteration no. 98841 ==> 0.41679814513028113\n",
            "Loss in iteration no. 98842 ==> 0.4167972272290642\n",
            "Loss in iteration no. 98843 ==> 0.4167963093401094\n",
            "Loss in iteration no. 98844 ==> 0.4167953914634168\n",
            "Loss in iteration no. 98845 ==> 0.4167944735989858\n",
            "Loss in iteration no. 98846 ==> 0.4167935557468163\n",
            "Loss in iteration no. 98847 ==> 0.41679263790690824\n",
            "Loss in iteration no. 98848 ==> 0.4167917200792611\n",
            "Loss in iteration no. 98849 ==> 0.4167908022638748\n",
            "Loss in iteration no. 98850 ==> 0.41678988446074916\n",
            "Loss in iteration no. 98851 ==> 0.41678896666988385\n",
            "Loss in iteration no. 98852 ==> 0.41678804889127874\n",
            "Loss in iteration no. 98853 ==> 0.4167871311249335\n",
            "Loss in iteration no. 98854 ==> 0.4167862133708478\n",
            "Loss in iteration no. 98855 ==> 0.4167852956290217\n",
            "Loss in iteration no. 98856 ==> 0.41678437789945477\n",
            "Loss in iteration no. 98857 ==> 0.41678346018214685\n",
            "Loss in iteration no. 98858 ==> 0.4167825424770976\n",
            "Loss in iteration no. 98859 ==> 0.41678162478430697\n",
            "Loss in iteration no. 98860 ==> 0.4167807071037746\n",
            "Loss in iteration no. 98861 ==> 0.41677978943550026\n",
            "Loss in iteration no. 98862 ==> 0.4167788717794838\n",
            "Loss in iteration no. 98863 ==> 0.4167779541357249\n",
            "Loss in iteration no. 98864 ==> 0.41677703650422326\n",
            "Loss in iteration no. 98865 ==> 0.4167761188849789\n",
            "Loss in iteration no. 98866 ==> 0.41677520127799134\n",
            "Loss in iteration no. 98867 ==> 0.4167742836832605\n",
            "Loss in iteration no. 98868 ==> 0.4167733661007861\n",
            "Loss in iteration no. 98869 ==> 0.41677244853056794\n",
            "Loss in iteration no. 98870 ==> 0.41677153097260566\n",
            "Loss in iteration no. 98871 ==> 0.41677061342689925\n",
            "Loss in iteration no. 98872 ==> 0.41676969589344826\n",
            "Loss in iteration no. 98873 ==> 0.41676877837225274\n",
            "Loss in iteration no. 98874 ==> 0.416767860863312\n",
            "Loss in iteration no. 98875 ==> 0.4167669433666262\n",
            "Loss in iteration no. 98876 ==> 0.416766025882195\n",
            "Loss in iteration no. 98877 ==> 0.4167651084100182\n",
            "Loss in iteration no. 98878 ==> 0.4167641909500955\n",
            "Loss in iteration no. 98879 ==> 0.4167632735024267\n",
            "Loss in iteration no. 98880 ==> 0.4167623560670116\n",
            "Loss in iteration no. 98881 ==> 0.4167614386438499\n",
            "Loss in iteration no. 98882 ==> 0.41676052123294144\n",
            "Loss in iteration no. 98883 ==> 0.4167596038342859\n",
            "Loss in iteration no. 98884 ==> 0.41675868644788316\n",
            "Loss in iteration no. 98885 ==> 0.41675776907373296\n",
            "Loss in iteration no. 98886 ==> 0.4167568517118349\n",
            "Loss in iteration no. 98887 ==> 0.41675593436218905\n",
            "Loss in iteration no. 98888 ==> 0.4167550170247949\n",
            "Loss in iteration no. 98889 ==> 0.41675409969965244\n",
            "Loss in iteration no. 98890 ==> 0.41675318238676134\n",
            "Loss in iteration no. 98891 ==> 0.4167522650861213\n",
            "Loss in iteration no. 98892 ==> 0.4167513477977322\n",
            "Loss in iteration no. 98893 ==> 0.4167504305215938\n",
            "Loss in iteration no. 98894 ==> 0.4167495132577058\n",
            "Loss in iteration no. 98895 ==> 0.416748596006068\n",
            "Loss in iteration no. 98896 ==> 0.41674767876668023\n",
            "Loss in iteration no. 98897 ==> 0.41674676153954204\n",
            "Loss in iteration no. 98898 ==> 0.41674584432465356\n",
            "Loss in iteration no. 98899 ==> 0.4167449271220143\n",
            "Loss in iteration no. 98900 ==> 0.4167440099316241\n",
            "Loss in iteration no. 98901 ==> 0.41674309275348265\n",
            "Loss in iteration no. 98902 ==> 0.41674217558758986\n",
            "Loss in iteration no. 98903 ==> 0.41674125843394544\n",
            "Loss in iteration no. 98904 ==> 0.4167403412925491\n",
            "Loss in iteration no. 98905 ==> 0.4167394241634007\n",
            "Loss in iteration no. 98906 ==> 0.41673850704649995\n",
            "Loss in iteration no. 98907 ==> 0.4167375899418466\n",
            "Loss in iteration no. 98908 ==> 0.4167366728494405\n",
            "Loss in iteration no. 98909 ==> 0.4167357557692814\n",
            "Loss in iteration no. 98910 ==> 0.416734838701369\n",
            "Loss in iteration no. 98911 ==> 0.4167339216457031\n",
            "Loss in iteration no. 98912 ==> 0.4167330046022835\n",
            "Loss in iteration no. 98913 ==> 0.4167320875711101\n",
            "Loss in iteration no. 98914 ==> 0.41673117055218234\n",
            "Loss in iteration no. 98915 ==> 0.41673025354550014\n",
            "Loss in iteration no. 98916 ==> 0.4167293365510635\n",
            "Loss in iteration no. 98917 ==> 0.4167284195688718\n",
            "Loss in iteration no. 98918 ==> 0.4167275025989251\n",
            "Loss in iteration no. 98919 ==> 0.416726585641223\n",
            "Loss in iteration no. 98920 ==> 0.41672566869576544\n",
            "Loss in iteration no. 98921 ==> 0.41672475176255197\n",
            "Loss in iteration no. 98922 ==> 0.4167238348415826\n",
            "Loss in iteration no. 98923 ==> 0.4167229179328568\n",
            "Loss in iteration no. 98924 ==> 0.4167220010363747\n",
            "Loss in iteration no. 98925 ==> 0.4167210841521358\n",
            "Loss in iteration no. 98926 ==> 0.41672016728014\n",
            "Loss in iteration no. 98927 ==> 0.41671925042038693\n",
            "Loss in iteration no. 98928 ==> 0.4167183335728766\n",
            "Loss in iteration no. 98929 ==> 0.4167174167376086\n",
            "Loss in iteration no. 98930 ==> 0.4167164999145827\n",
            "Loss in iteration no. 98931 ==> 0.41671558310379864\n",
            "Loss in iteration no. 98932 ==> 0.4167146663052563\n",
            "Loss in iteration no. 98933 ==> 0.4167137495189554\n",
            "Loss in iteration no. 98934 ==> 0.4167128327448957\n",
            "Loss in iteration no. 98935 ==> 0.41671191598307694\n",
            "Loss in iteration no. 98936 ==> 0.41671099923349897\n",
            "Loss in iteration no. 98937 ==> 0.4167100824961616\n",
            "Loss in iteration no. 98938 ==> 0.4167091657710644\n",
            "Loss in iteration no. 98939 ==> 0.41670824905820736\n",
            "Loss in iteration no. 98940 ==> 0.41670733235759\n",
            "Loss in iteration no. 98941 ==> 0.4167064156692124\n",
            "Loss in iteration no. 98942 ==> 0.41670549899307396\n",
            "Loss in iteration no. 98943 ==> 0.4167045823291748\n",
            "Loss in iteration no. 98944 ==> 0.4167036656775146\n",
            "Loss in iteration no. 98945 ==> 0.41670274903809296\n",
            "Loss in iteration no. 98946 ==> 0.41670183241090986\n",
            "Loss in iteration no. 98947 ==> 0.41670091579596485\n",
            "Loss in iteration no. 98948 ==> 0.41669999919325795\n",
            "Loss in iteration no. 98949 ==> 0.41669908260278876\n",
            "Loss in iteration no. 98950 ==> 0.41669816602455706\n",
            "Loss in iteration no. 98951 ==> 0.4166972494585626\n",
            "Loss in iteration no. 98952 ==> 0.4166963329048053\n",
            "Loss in iteration no. 98953 ==> 0.4166954163632848\n",
            "Loss in iteration no. 98954 ==> 0.41669449983400086\n",
            "Loss in iteration no. 98955 ==> 0.41669358331695333\n",
            "Loss in iteration no. 98956 ==> 0.4166926668121419\n",
            "Loss in iteration no. 98957 ==> 0.4166917503195665\n",
            "Loss in iteration no. 98958 ==> 0.41669083383922667\n",
            "Loss in iteration no. 98959 ==> 0.4166899173711222\n",
            "Loss in iteration no. 98960 ==> 0.4166890009152531\n",
            "Loss in iteration no. 98961 ==> 0.416688084471619\n",
            "Loss in iteration no. 98962 ==> 0.41668716804021955\n",
            "Loss in iteration no. 98963 ==> 0.4166862516210546\n",
            "Loss in iteration no. 98964 ==> 0.4166853352141241\n",
            "Loss in iteration no. 98965 ==> 0.4166844188194276\n",
            "Loss in iteration no. 98966 ==> 0.41668350243696484\n",
            "Loss in iteration no. 98967 ==> 0.4166825860667358\n",
            "Loss in iteration no. 98968 ==> 0.4166816697087401\n",
            "Loss in iteration no. 98969 ==> 0.4166807533629775\n",
            "Loss in iteration no. 98970 ==> 0.41667983702944783\n",
            "Loss in iteration no. 98971 ==> 0.4166789207081509\n",
            "Loss in iteration no. 98972 ==> 0.4166780043990863\n",
            "Loss in iteration no. 98973 ==> 0.41667708810225407\n",
            "Loss in iteration no. 98974 ==> 0.4166761718176537\n",
            "Loss in iteration no. 98975 ==> 0.4166752555452852\n",
            "Loss in iteration no. 98976 ==> 0.41667433928514813\n",
            "Loss in iteration no. 98977 ==> 0.41667342303724253\n",
            "Loss in iteration no. 98978 ==> 0.41667250680156775\n",
            "Loss in iteration no. 98979 ==> 0.416671590578124\n",
            "Loss in iteration no. 98980 ==> 0.4166706743669107\n",
            "Loss in iteration no. 98981 ==> 0.4166697581679279\n",
            "Loss in iteration no. 98982 ==> 0.4166688419811752\n",
            "Loss in iteration no. 98983 ==> 0.4166679258066525\n",
            "Loss in iteration no. 98984 ==> 0.41666700964435943\n",
            "Loss in iteration no. 98985 ==> 0.41666609349429584\n",
            "Loss in iteration no. 98986 ==> 0.4166651773564614\n",
            "Loss in iteration no. 98987 ==> 0.4166642612308561\n",
            "Loss in iteration no. 98988 ==> 0.41666334511747954\n",
            "Loss in iteration no. 98989 ==> 0.4166624290163314\n",
            "Loss in iteration no. 98990 ==> 0.4166615129274116\n",
            "Loss in iteration no. 98991 ==> 0.4166605968507199\n",
            "Loss in iteration no. 98992 ==> 0.416659680786256\n",
            "Loss in iteration no. 98993 ==> 0.4166587647340198\n",
            "Loss in iteration no. 98994 ==> 0.41665784869401096\n",
            "Loss in iteration no. 98995 ==> 0.4166569326662292\n",
            "Loss in iteration no. 98996 ==> 0.4166560166506745\n",
            "Loss in iteration no. 98997 ==> 0.4166551006473464\n",
            "Loss in iteration no. 98998 ==> 0.41665418465624476\n",
            "Loss in iteration no. 98999 ==> 0.4166532686773694\n",
            "Loss in iteration no. 99000 ==> 0.41665235271072004\n",
            "Loss in iteration no. 99001 ==> 0.4166514367562964\n",
            "Loss in iteration no. 99002 ==> 0.41665052081409837\n",
            "Loss in iteration no. 99003 ==> 0.41664960488412556\n",
            "Loss in iteration no. 99004 ==> 0.4166486889663779\n",
            "Loss in iteration no. 99005 ==> 0.4166477730608551\n",
            "Loss in iteration no. 99006 ==> 0.41664685716755695\n",
            "Loss in iteration no. 99007 ==> 0.41664594128648313\n",
            "Loss in iteration no. 99008 ==> 0.41664502541763343\n",
            "Loss in iteration no. 99009 ==> 0.4166441095610078\n",
            "Loss in iteration no. 99010 ==> 0.41664319371660574\n",
            "Loss in iteration no. 99011 ==> 0.41664227788442715\n",
            "Loss in iteration no. 99012 ==> 0.4166413620644719\n",
            "Loss in iteration no. 99013 ==> 0.4166404462567397\n",
            "Loss in iteration no. 99014 ==> 0.4166395304612301\n",
            "Loss in iteration no. 99015 ==> 0.4166386146779433\n",
            "Loss in iteration no. 99016 ==> 0.41663769890687863\n",
            "Loss in iteration no. 99017 ==> 0.4166367831480361\n",
            "Loss in iteration no. 99018 ==> 0.41663586740141545\n",
            "Loss in iteration no. 99019 ==> 0.41663495166701636\n",
            "Loss in iteration no. 99020 ==> 0.4166340359448387\n",
            "Loss in iteration no. 99021 ==> 0.41663312023488225\n",
            "Loss in iteration no. 99022 ==> 0.4166322045371467\n",
            "Loss in iteration no. 99023 ==> 0.4166312888516319\n",
            "Loss in iteration no. 99024 ==> 0.41663037317833757\n",
            "Loss in iteration no. 99025 ==> 0.41662945751726355\n",
            "Loss in iteration no. 99026 ==> 0.4166285418684095\n",
            "Loss in iteration no. 99027 ==> 0.41662762623177513\n",
            "Loss in iteration no. 99028 ==> 0.4166267106073604\n",
            "Loss in iteration no. 99029 ==> 0.41662579499516506\n",
            "Loss in iteration no. 99030 ==> 0.4166248793951887\n",
            "Loss in iteration no. 99031 ==> 0.4166239638074314\n",
            "Loss in iteration no. 99032 ==> 0.41662304823189256\n",
            "Loss in iteration no. 99033 ==> 0.41662213266857223\n",
            "Loss in iteration no. 99034 ==> 0.41662121711746997\n",
            "Loss in iteration no. 99035 ==> 0.41662030157858576\n",
            "Loss in iteration no. 99036 ==> 0.4166193860519192\n",
            "Loss in iteration no. 99037 ==> 0.41661847053747025\n",
            "Loss in iteration no. 99038 ==> 0.41661755503523845\n",
            "Loss in iteration no. 99039 ==> 0.41661663954522377\n",
            "Loss in iteration no. 99040 ==> 0.4166157240674258\n",
            "Loss in iteration no. 99041 ==> 0.41661480860184447\n",
            "Loss in iteration no. 99042 ==> 0.4166138931484794\n",
            "Loss in iteration no. 99043 ==> 0.41661297770733047\n",
            "Loss in iteration no. 99044 ==> 0.4166120622783974\n",
            "Loss in iteration no. 99045 ==> 0.41661114686168005\n",
            "Loss in iteration no. 99046 ==> 0.41661023145717807\n",
            "Loss in iteration no. 99047 ==> 0.41660931606489127\n",
            "Loss in iteration no. 99048 ==> 0.41660840068481947\n",
            "Loss in iteration no. 99049 ==> 0.4166074853169624\n",
            "Loss in iteration no. 99050 ==> 0.41660656996131984\n",
            "Loss in iteration no. 99051 ==> 0.41660565461789145\n",
            "Loss in iteration no. 99052 ==> 0.41660473928667724\n",
            "Loss in iteration no. 99053 ==> 0.4166038239676767\n",
            "Loss in iteration no. 99054 ==> 0.41660290866088984\n",
            "Loss in iteration no. 99055 ==> 0.41660199336631626\n",
            "Loss in iteration no. 99056 ==> 0.4166010780839559\n",
            "Loss in iteration no. 99057 ==> 0.4166001628138083\n",
            "Loss in iteration no. 99058 ==> 0.4165992475558736\n",
            "Loss in iteration no. 99059 ==> 0.41659833231015103\n",
            "Loss in iteration no. 99060 ==> 0.41659741707664083\n",
            "Loss in iteration no. 99061 ==> 0.4165965018553425\n",
            "Loss in iteration no. 99062 ==> 0.416595586646256\n",
            "Loss in iteration no. 99063 ==> 0.416594671449381\n",
            "Loss in iteration no. 99064 ==> 0.4165937562647173\n",
            "Loss in iteration no. 99065 ==> 0.41659284109226463\n",
            "Loss in iteration no. 99066 ==> 0.41659192593202277\n",
            "Loss in iteration no. 99067 ==> 0.4165910107839915\n",
            "Loss in iteration no. 99068 ==> 0.41659009564817057\n",
            "Loss in iteration no. 99069 ==> 0.41658918052455984\n",
            "Loss in iteration no. 99070 ==> 0.41658826541315896\n",
            "Loss in iteration no. 99071 ==> 0.4165873503139677\n",
            "Loss in iteration no. 99072 ==> 0.4165864352269861\n",
            "Loss in iteration no. 99073 ==> 0.4165855201522135\n",
            "Loss in iteration no. 99074 ==> 0.4165846050896499\n",
            "Loss in iteration no. 99075 ==> 0.4165836900392952\n",
            "Loss in iteration no. 99076 ==> 0.4165827750011489\n",
            "Loss in iteration no. 99077 ==> 0.41658185997521086\n",
            "Loss in iteration no. 99078 ==> 0.416580944961481\n",
            "Loss in iteration no. 99079 ==> 0.4165800299599589\n",
            "Loss in iteration no. 99080 ==> 0.41657911497064437\n",
            "Loss in iteration no. 99081 ==> 0.41657819999353723\n",
            "Loss in iteration no. 99082 ==> 0.41657728502863733\n",
            "Loss in iteration no. 99083 ==> 0.41657637007594434\n",
            "Loss in iteration no. 99084 ==> 0.41657545513545796\n",
            "Loss in iteration no. 99085 ==> 0.41657454020717805\n",
            "Loss in iteration no. 99086 ==> 0.41657362529110437\n",
            "Loss in iteration no. 99087 ==> 0.4165727103872367\n",
            "Loss in iteration no. 99088 ==> 0.4165717954955748\n",
            "Loss in iteration no. 99089 ==> 0.4165708806161184\n",
            "Loss in iteration no. 99090 ==> 0.41656996574886734\n",
            "Loss in iteration no. 99091 ==> 0.4165690508938213\n",
            "Loss in iteration no. 99092 ==> 0.41656813605098025\n",
            "Loss in iteration no. 99093 ==> 0.4165672212203436\n",
            "Loss in iteration no. 99094 ==> 0.4165663064019115\n",
            "Loss in iteration no. 99095 ==> 0.41656539159568357\n",
            "Loss in iteration no. 99096 ==> 0.41656447680165953\n",
            "Loss in iteration no. 99097 ==> 0.41656356201983913\n",
            "Loss in iteration no. 99098 ==> 0.4165626472502223\n",
            "Loss in iteration no. 99099 ==> 0.41656173249280865\n",
            "Loss in iteration no. 99100 ==> 0.41656081774759796\n",
            "Loss in iteration no. 99101 ==> 0.41655990301459017\n",
            "Loss in iteration no. 99102 ==> 0.4165589882937849\n",
            "Loss in iteration no. 99103 ==> 0.4165580735851818\n",
            "Loss in iteration no. 99104 ==> 0.416557158888781\n",
            "Loss in iteration no. 99105 ==> 0.416556244204582\n",
            "Loss in iteration no. 99106 ==> 0.41655532953258456\n",
            "Loss in iteration no. 99107 ==> 0.4165544148727886\n",
            "Loss in iteration no. 99108 ==> 0.4165535002251938\n",
            "Loss in iteration no. 99109 ==> 0.41655258558979985\n",
            "Loss in iteration no. 99110 ==> 0.4165516709666067\n",
            "Loss in iteration no. 99111 ==> 0.4165507563556141\n",
            "Loss in iteration no. 99112 ==> 0.41654984175682164\n",
            "Loss in iteration no. 99113 ==> 0.41654892717022923\n",
            "Loss in iteration no. 99114 ==> 0.4165480125958367\n",
            "Loss in iteration no. 99115 ==> 0.41654709803364365\n",
            "Loss in iteration no. 99116 ==> 0.41654618348364997\n",
            "Loss in iteration no. 99117 ==> 0.41654526894585536\n",
            "Loss in iteration no. 99118 ==> 0.4165443544202596\n",
            "Loss in iteration no. 99119 ==> 0.41654343990686266\n",
            "Loss in iteration no. 99120 ==> 0.41654252540566394\n",
            "Loss in iteration no. 99121 ==> 0.41654161091666353\n",
            "Loss in iteration no. 99122 ==> 0.416540696439861\n",
            "Loss in iteration no. 99123 ==> 0.41653978197525626\n",
            "Loss in iteration no. 99124 ==> 0.416538867522849\n",
            "Loss in iteration no. 99125 ==> 0.4165379530826389\n",
            "Loss in iteration no. 99126 ==> 0.41653703865462605\n",
            "Loss in iteration no. 99127 ==> 0.4165361242388099\n",
            "Loss in iteration no. 99128 ==> 0.4165352098351903\n",
            "Loss in iteration no. 99129 ==> 0.41653429544376713\n",
            "Loss in iteration no. 99130 ==> 0.41653338106454\n",
            "Loss in iteration no. 99131 ==> 0.4165324666975088\n",
            "Loss in iteration no. 99132 ==> 0.41653155234267336\n",
            "Loss in iteration no. 99133 ==> 0.41653063800003326\n",
            "Loss in iteration no. 99134 ==> 0.41652972366958835\n",
            "Loss in iteration no. 99135 ==> 0.41652880935133846\n",
            "Loss in iteration no. 99136 ==> 0.4165278950452833\n",
            "Loss in iteration no. 99137 ==> 0.41652698075142264\n",
            "Loss in iteration no. 99138 ==> 0.41652606646975626\n",
            "Loss in iteration no. 99139 ==> 0.416525152200284\n",
            "Loss in iteration no. 99140 ==> 0.4165242379430055\n",
            "Loss in iteration no. 99141 ==> 0.4165233236979206\n",
            "Loss in iteration no. 99142 ==> 0.4165224094650291\n",
            "Loss in iteration no. 99143 ==> 0.41652149524433074\n",
            "Loss in iteration no. 99144 ==> 0.4165205810358253\n",
            "Loss in iteration no. 99145 ==> 0.4165196668395126\n",
            "Loss in iteration no. 99146 ==> 0.41651875265539223\n",
            "Loss in iteration no. 99147 ==> 0.4165178384834641\n",
            "Loss in iteration no. 99148 ==> 0.41651692432372805\n",
            "Loss in iteration no. 99149 ==> 0.41651601017618367\n",
            "Loss in iteration no. 99150 ==> 0.4165150960408309\n",
            "Loss in iteration no. 99151 ==> 0.4165141819176693\n",
            "Loss in iteration no. 99152 ==> 0.4165132678066989\n",
            "Loss in iteration no. 99153 ==> 0.4165123537079194\n",
            "Loss in iteration no. 99154 ==> 0.41651143962133036\n",
            "Loss in iteration no. 99155 ==> 0.4165105255469319\n",
            "Loss in iteration no. 99156 ==> 0.41650961148472343\n",
            "Loss in iteration no. 99157 ==> 0.4165086974347049\n",
            "Loss in iteration no. 99158 ==> 0.41650778339687605\n",
            "Loss in iteration no. 99159 ==> 0.4165068693712369\n",
            "Loss in iteration no. 99160 ==> 0.4165059553577868\n",
            "Loss in iteration no. 99161 ==> 0.41650504135652566\n",
            "Loss in iteration no. 99162 ==> 0.4165041273674534\n",
            "Loss in iteration no. 99163 ==> 0.4165032133905697\n",
            "Loss in iteration no. 99164 ==> 0.4165022994258743\n",
            "Loss in iteration no. 99165 ==> 0.4165013854733669\n",
            "Loss in iteration no. 99166 ==> 0.4165004715330475\n",
            "Loss in iteration no. 99167 ==> 0.41649955760491575\n",
            "Loss in iteration no. 99168 ==> 0.4164986436889713\n",
            "Loss in iteration no. 99169 ==> 0.41649772978521404\n",
            "Loss in iteration no. 99170 ==> 0.4164968158936438\n",
            "Loss in iteration no. 99171 ==> 0.4164959020142603\n",
            "Loss in iteration no. 99172 ==> 0.4164949881470632\n",
            "Loss in iteration no. 99173 ==> 0.41649407429205243\n",
            "Loss in iteration no. 99174 ==> 0.41649316044922763\n",
            "Loss in iteration no. 99175 ==> 0.41649224661858864\n",
            "Loss in iteration no. 99176 ==> 0.4164913328001353\n",
            "Loss in iteration no. 99177 ==> 0.41649041899386724\n",
            "Loss in iteration no. 99178 ==> 0.4164895051997842\n",
            "Loss in iteration no. 99179 ==> 0.41648859141788624\n",
            "Loss in iteration no. 99180 ==> 0.4164876776481728\n",
            "Loss in iteration no. 99181 ==> 0.4164867638906438\n",
            "Loss in iteration no. 99182 ==> 0.41648585014529893\n",
            "Loss in iteration no. 99183 ==> 0.41648493641213824\n",
            "Loss in iteration no. 99184 ==> 0.41648402269116114\n",
            "Loss in iteration no. 99185 ==> 0.41648310898236757\n",
            "Loss in iteration no. 99186 ==> 0.41648219528575725\n",
            "Loss in iteration no. 99187 ==> 0.4164812816013301\n",
            "Loss in iteration no. 99188 ==> 0.41648036792908566\n",
            "Loss in iteration no. 99189 ==> 0.41647945426902383\n",
            "Loss in iteration no. 99190 ==> 0.41647854062114437\n",
            "Loss in iteration no. 99191 ==> 0.416477626985447\n",
            "Loss in iteration no. 99192 ==> 0.41647671336193165\n",
            "Loss in iteration no. 99193 ==> 0.41647579975059795\n",
            "Loss in iteration no. 99194 ==> 0.4164748861514456\n",
            "Loss in iteration no. 99195 ==> 0.4164739725644746\n",
            "Loss in iteration no. 99196 ==> 0.4164730589896845\n",
            "Loss in iteration no. 99197 ==> 0.4164721454270751\n",
            "Loss in iteration no. 99198 ==> 0.41647123187664636\n",
            "Loss in iteration no. 99199 ==> 0.4164703183383979\n",
            "Loss in iteration no. 99200 ==> 0.41646940481232947\n",
            "Loss in iteration no. 99201 ==> 0.4164684912984409\n",
            "Loss in iteration no. 99202 ==> 0.41646757779673194\n",
            "Loss in iteration no. 99203 ==> 0.4164666643072024\n",
            "Loss in iteration no. 99204 ==> 0.41646575082985193\n",
            "Loss in iteration no. 99205 ==> 0.4164648373646805\n",
            "Loss in iteration no. 99206 ==> 0.41646392391168763\n",
            "Loss in iteration no. 99207 ==> 0.41646301047087336\n",
            "Loss in iteration no. 99208 ==> 0.4164620970422373\n",
            "Loss in iteration no. 99209 ==> 0.41646118362577916\n",
            "Loss in iteration no. 99210 ==> 0.4164602702214989\n",
            "Loss in iteration no. 99211 ==> 0.41645935682939617\n",
            "Loss in iteration no. 99212 ==> 0.41645844344947075\n",
            "Loss in iteration no. 99213 ==> 0.41645753008172237\n",
            "Loss in iteration no. 99214 ==> 0.416456616726151\n",
            "Loss in iteration no. 99215 ==> 0.4164557033827561\n",
            "Loss in iteration no. 99216 ==> 0.4164547900515378\n",
            "Loss in iteration no. 99217 ==> 0.4164538767324955\n",
            "Loss in iteration no. 99218 ==> 0.41645296342562926\n",
            "Loss in iteration no. 99219 ==> 0.4164520501309386\n",
            "Loss in iteration no. 99220 ==> 0.4164511368484236\n",
            "Loss in iteration no. 99221 ==> 0.4164502235780837\n",
            "Loss in iteration no. 99222 ==> 0.4164493103199189\n",
            "Loss in iteration no. 99223 ==> 0.416448397073929\n",
            "Loss in iteration no. 99224 ==> 0.4164474838401136\n",
            "Loss in iteration no. 99225 ==> 0.4164465706184725\n",
            "Loss in iteration no. 99226 ==> 0.4164456574090056\n",
            "Loss in iteration no. 99227 ==> 0.4164447442117125\n",
            "Loss in iteration no. 99228 ==> 0.41644383102659327\n",
            "Loss in iteration no. 99229 ==> 0.41644291785364723\n",
            "Loss in iteration no. 99230 ==> 0.4164420046928745\n",
            "Loss in iteration no. 99231 ==> 0.4164410915442748\n",
            "Loss in iteration no. 99232 ==> 0.41644017840784775\n",
            "Loss in iteration no. 99233 ==> 0.4164392652835932\n",
            "Loss in iteration no. 99234 ==> 0.416438352171511\n",
            "Loss in iteration no. 99235 ==> 0.41643743907160086\n",
            "Loss in iteration no. 99236 ==> 0.41643652598386244\n",
            "Loss in iteration no. 99237 ==> 0.4164356129082956\n",
            "Loss in iteration no. 99238 ==> 0.41643469984490034\n",
            "Loss in iteration no. 99239 ==> 0.4164337867936761\n",
            "Loss in iteration no. 99240 ==> 0.4164328737546228\n",
            "Loss in iteration no. 99241 ==> 0.41643196072774014\n",
            "Loss in iteration no. 99242 ==> 0.416431047713028\n",
            "Loss in iteration no. 99243 ==> 0.416430134710486\n",
            "Loss in iteration no. 99244 ==> 0.4164292217201141\n",
            "Loss in iteration no. 99245 ==> 0.41642830874191183\n",
            "Loss in iteration no. 99246 ==> 0.4164273957758793\n",
            "Loss in iteration no. 99247 ==> 0.4164264828220159\n",
            "Loss in iteration no. 99248 ==> 0.41642556988032164\n",
            "Loss in iteration no. 99249 ==> 0.4164246569507963\n",
            "Loss in iteration no. 99250 ==> 0.41642374403343946\n",
            "Loss in iteration no. 99251 ==> 0.41642283112825107\n",
            "Loss in iteration no. 99252 ==> 0.4164219182352309\n",
            "Loss in iteration no. 99253 ==> 0.41642100535437854\n",
            "Loss in iteration no. 99254 ==> 0.416420092485694\n",
            "Loss in iteration no. 99255 ==> 0.4164191796291769\n",
            "Loss in iteration no. 99256 ==> 0.41641826678482713\n",
            "Loss in iteration no. 99257 ==> 0.4164173539526443\n",
            "Loss in iteration no. 99258 ==> 0.41641644113262827\n",
            "Loss in iteration no. 99259 ==> 0.4164155283247788\n",
            "Loss in iteration no. 99260 ==> 0.41641461552909564\n",
            "Loss in iteration no. 99261 ==> 0.41641370274557865\n",
            "Loss in iteration no. 99262 ==> 0.41641278997422754\n",
            "Loss in iteration no. 99263 ==> 0.4164118772150421\n",
            "Loss in iteration no. 99264 ==> 0.416410964468022\n",
            "Loss in iteration no. 99265 ==> 0.4164100517331672\n",
            "Loss in iteration no. 99266 ==> 0.41640913901047727\n",
            "Loss in iteration no. 99267 ==> 0.416408226299952\n",
            "Loss in iteration no. 99268 ==> 0.41640731360159133\n",
            "Loss in iteration no. 99269 ==> 0.41640640091539505\n",
            "Loss in iteration no. 99270 ==> 0.41640548824136264\n",
            "Loss in iteration no. 99271 ==> 0.41640457557949423\n",
            "Loss in iteration no. 99272 ==> 0.4164036629297893\n",
            "Loss in iteration no. 99273 ==> 0.41640275029224766\n",
            "Loss in iteration no. 99274 ==> 0.4164018376668693\n",
            "Loss in iteration no. 99275 ==> 0.4164009250536537\n",
            "Loss in iteration no. 99276 ==> 0.41640001245260094\n",
            "Loss in iteration no. 99277 ==> 0.41639909986371043\n",
            "Loss in iteration no. 99278 ==> 0.41639818728698236\n",
            "Loss in iteration no. 99279 ==> 0.4163972747224161\n",
            "Loss in iteration no. 99280 ==> 0.41639636217001175\n",
            "Loss in iteration no. 99281 ==> 0.4163954496297688\n",
            "Loss in iteration no. 99282 ==> 0.41639453710168717\n",
            "Loss in iteration no. 99283 ==> 0.4163936245857668\n",
            "Loss in iteration no. 99284 ==> 0.416392712082007\n",
            "Loss in iteration no. 99285 ==> 0.416391799590408\n",
            "Loss in iteration no. 99286 ==> 0.4163908871109694\n",
            "Loss in iteration no. 99287 ==> 0.4163899746436909\n",
            "Loss in iteration no. 99288 ==> 0.4163890621885723\n",
            "Loss in iteration no. 99289 ==> 0.4163881497456135\n",
            "Loss in iteration no. 99290 ==> 0.4163872373148141\n",
            "Loss in iteration no. 99291 ==> 0.41638632489617394\n",
            "Loss in iteration no. 99292 ==> 0.41638541248969285\n",
            "Loss in iteration no. 99293 ==> 0.41638450009537054\n",
            "Loss in iteration no. 99294 ==> 0.41638358771320677\n",
            "Loss in iteration no. 99295 ==> 0.4163826753432013\n",
            "Loss in iteration no. 99296 ==> 0.41638176298535395\n",
            "Loss in iteration no. 99297 ==> 0.4163808506396645\n",
            "Loss in iteration no. 99298 ==> 0.41637993830613274\n",
            "Loss in iteration no. 99299 ==> 0.41637902598475834\n",
            "Loss in iteration no. 99300 ==> 0.4163781136755412\n",
            "Loss in iteration no. 99301 ==> 0.41637720137848094\n",
            "Loss in iteration no. 99302 ==> 0.4163762890935775\n",
            "Loss in iteration no. 99303 ==> 0.4163753768208305\n",
            "Loss in iteration no. 99304 ==> 0.4163744645602397\n",
            "Loss in iteration no. 99305 ==> 0.41637355231180506\n",
            "Loss in iteration no. 99306 ==> 0.4163726400755262\n",
            "Loss in iteration no. 99307 ==> 0.4163717278514029\n",
            "Loss in iteration no. 99308 ==> 0.41637081563943507\n",
            "Loss in iteration no. 99309 ==> 0.4163699034396223\n",
            "Loss in iteration no. 99310 ==> 0.4163689912519644\n",
            "Loss in iteration no. 99311 ==> 0.41636807907646123\n",
            "Loss in iteration no. 99312 ==> 0.4163671669131125\n",
            "Loss in iteration no. 99313 ==> 0.416366254761918\n",
            "Loss in iteration no. 99314 ==> 0.41636534262287744\n",
            "Loss in iteration no. 99315 ==> 0.4163644304959907\n",
            "Loss in iteration no. 99316 ==> 0.41636351838125746\n",
            "Loss in iteration no. 99317 ==> 0.4163626062786775\n",
            "Loss in iteration no. 99318 ==> 0.41636169418825064\n",
            "Loss in iteration no. 99319 ==> 0.4163607821099766\n",
            "Loss in iteration no. 99320 ==> 0.41635987004385533\n",
            "Loss in iteration no. 99321 ==> 0.4163589579898863\n",
            "Loss in iteration no. 99322 ==> 0.41635804594806947\n",
            "Loss in iteration no. 99323 ==> 0.4163571339184046\n",
            "Loss in iteration no. 99324 ==> 0.4163562219008914\n",
            "Loss in iteration no. 99325 ==> 0.4163553098955297\n",
            "Loss in iteration no. 99326 ==> 0.4163543979023192\n",
            "Loss in iteration no. 99327 ==> 0.4163534859212598\n",
            "Loss in iteration no. 99328 ==> 0.41635257395235115\n",
            "Loss in iteration no. 99329 ==> 0.4163516619955931\n",
            "Loss in iteration no. 99330 ==> 0.4163507500509853\n",
            "Loss in iteration no. 99331 ==> 0.4163498381185277\n",
            "Loss in iteration no. 99332 ==> 0.4163489261982199\n",
            "Loss in iteration no. 99333 ==> 0.41634801429006185\n",
            "Loss in iteration no. 99334 ==> 0.4163471023940531\n",
            "Loss in iteration no. 99335 ==> 0.41634619051019367\n",
            "Loss in iteration no. 99336 ==> 0.41634527863848314\n",
            "Loss in iteration no. 99337 ==> 0.41634436677892134\n",
            "Loss in iteration no. 99338 ==> 0.4163434549315081\n",
            "Loss in iteration no. 99339 ==> 0.4163425430962431\n",
            "Loss in iteration no. 99340 ==> 0.41634163127312607\n",
            "Loss in iteration no. 99341 ==> 0.416340719462157\n",
            "Loss in iteration no. 99342 ==> 0.4163398076633355\n",
            "Loss in iteration no. 99343 ==> 0.4163388958766613\n",
            "Loss in iteration no. 99344 ==> 0.41633798410213435\n",
            "Loss in iteration no. 99345 ==> 0.41633707233975425\n",
            "Loss in iteration no. 99346 ==> 0.41633616058952083\n",
            "Loss in iteration no. 99347 ==> 0.4163352488514338\n",
            "Loss in iteration no. 99348 ==> 0.41633433712549306\n",
            "Loss in iteration no. 99349 ==> 0.4163334254116984\n",
            "Loss in iteration no. 99350 ==> 0.41633251371004937\n",
            "Loss in iteration no. 99351 ==> 0.416331602020546\n",
            "Loss in iteration no. 99352 ==> 0.41633069034318776\n",
            "Loss in iteration no. 99353 ==> 0.41632977867797477\n",
            "Loss in iteration no. 99354 ==> 0.4163288670249066\n",
            "Loss in iteration no. 99355 ==> 0.41632795538398304\n",
            "Loss in iteration no. 99356 ==> 0.4163270437552039\n",
            "Loss in iteration no. 99357 ==> 0.4163261321385689\n",
            "Loss in iteration no. 99358 ==> 0.4163252205340779\n",
            "Loss in iteration no. 99359 ==> 0.4163243089417306\n",
            "Loss in iteration no. 99360 ==> 0.4163233973615268\n",
            "Loss in iteration no. 99361 ==> 0.41632248579346615\n",
            "Loss in iteration no. 99362 ==> 0.4163215742375486\n",
            "Loss in iteration no. 99363 ==> 0.4163206626937739\n",
            "Loss in iteration no. 99364 ==> 0.4163197511621418\n",
            "Loss in iteration no. 99365 ==> 0.41631883964265193\n",
            "Loss in iteration no. 99366 ==> 0.4163179281353042\n",
            "Loss in iteration no. 99367 ==> 0.41631701664009846\n",
            "Loss in iteration no. 99368 ==> 0.41631610515703427\n",
            "Loss in iteration no. 99369 ==> 0.41631519368611153\n",
            "Loss in iteration no. 99370 ==> 0.41631428222733\n",
            "Loss in iteration no. 99371 ==> 0.4163133707806895\n",
            "Loss in iteration no. 99372 ==> 0.4163124593461897\n",
            "Loss in iteration no. 99373 ==> 0.41631154792383046\n",
            "Loss in iteration no. 99374 ==> 0.4163106365136114\n",
            "Loss in iteration no. 99375 ==> 0.41630972511553255\n",
            "Loss in iteration no. 99376 ==> 0.4163088137295935\n",
            "Loss in iteration no. 99377 ==> 0.41630790235579396\n",
            "Loss in iteration no. 99378 ==> 0.41630699099413393\n",
            "Loss in iteration no. 99379 ==> 0.41630607964461297\n",
            "Loss in iteration no. 99380 ==> 0.4163051683072309\n",
            "Loss in iteration no. 99381 ==> 0.41630425698198764\n",
            "Loss in iteration no. 99382 ==> 0.41630334566888283\n",
            "Loss in iteration no. 99383 ==> 0.41630243436791625\n",
            "Loss in iteration no. 99384 ==> 0.41630152307908763\n",
            "Loss in iteration no. 99385 ==> 0.4163006118023968\n",
            "Loss in iteration no. 99386 ==> 0.41629970053784354\n",
            "Loss in iteration no. 99387 ==> 0.4162987892854276\n",
            "Loss in iteration no. 99388 ==> 0.4162978780451488\n",
            "Loss in iteration no. 99389 ==> 0.41629696681700684\n",
            "Loss in iteration no. 99390 ==> 0.41629605560100147\n",
            "Loss in iteration no. 99391 ==> 0.4162951443971326\n",
            "Loss in iteration no. 99392 ==> 0.41629423320539993\n",
            "Loss in iteration no. 99393 ==> 0.4162933220258031\n",
            "Loss in iteration no. 99394 ==> 0.4162924108583421\n",
            "Loss in iteration no. 99395 ==> 0.4162914997030166\n",
            "Loss in iteration no. 99396 ==> 0.41629058855982637\n",
            "Loss in iteration no. 99397 ==> 0.4162896774287711\n",
            "Loss in iteration no. 99398 ==> 0.41628876630985073\n",
            "Loss in iteration no. 99399 ==> 0.41628785520306494\n",
            "Loss in iteration no. 99400 ==> 0.4162869441084135\n",
            "Loss in iteration no. 99401 ==> 0.4162860330258962\n",
            "Loss in iteration no. 99402 ==> 0.4162851219555128\n",
            "Loss in iteration no. 99403 ==> 0.41628421089726314\n",
            "Loss in iteration no. 99404 ==> 0.41628329985114687\n",
            "Loss in iteration no. 99405 ==> 0.4162823888171638\n",
            "Loss in iteration no. 99406 ==> 0.41628147779531377\n",
            "Loss in iteration no. 99407 ==> 0.41628056678559644\n",
            "Loss in iteration no. 99408 ==> 0.41627965578801174\n",
            "Loss in iteration no. 99409 ==> 0.4162787448025594\n",
            "Loss in iteration no. 99410 ==> 0.41627783382923905\n",
            "Loss in iteration no. 99411 ==> 0.4162769228680505\n",
            "Loss in iteration no. 99412 ==> 0.41627601191899366\n",
            "Loss in iteration no. 99413 ==> 0.4162751009820682\n",
            "Loss in iteration no. 99414 ==> 0.4162741900572739\n",
            "Loss in iteration no. 99415 ==> 0.41627327914461054\n",
            "Loss in iteration no. 99416 ==> 0.41627236824407793\n",
            "Loss in iteration no. 99417 ==> 0.4162714573556758\n",
            "Loss in iteration no. 99418 ==> 0.41627054647940387\n",
            "Loss in iteration no. 99419 ==> 0.41626963561526203\n",
            "Loss in iteration no. 99420 ==> 0.41626872476325005\n",
            "Loss in iteration no. 99421 ==> 0.41626781392336754\n",
            "Loss in iteration no. 99422 ==> 0.4162669030956144\n",
            "Loss in iteration no. 99423 ==> 0.41626599227999045\n",
            "Loss in iteration no. 99424 ==> 0.4162650814764954\n",
            "Loss in iteration no. 99425 ==> 0.41626417068512883\n",
            "Loss in iteration no. 99426 ==> 0.41626325990589086\n",
            "Loss in iteration no. 99427 ==> 0.4162623491387811\n",
            "Loss in iteration no. 99428 ==> 0.41626143838379925\n",
            "Loss in iteration no. 99429 ==> 0.4162605276409452\n",
            "Loss in iteration no. 99430 ==> 0.4162596169102186\n",
            "Loss in iteration no. 99431 ==> 0.4162587061916194\n",
            "Loss in iteration no. 99432 ==> 0.41625779548514724\n",
            "Loss in iteration no. 99433 ==> 0.41625688479080186\n",
            "Loss in iteration no. 99434 ==> 0.4162559741085831\n",
            "Loss in iteration no. 99435 ==> 0.4162550634384908\n",
            "Loss in iteration no. 99436 ==> 0.4162541527805246\n",
            "Loss in iteration no. 99437 ==> 0.4162532421346844\n",
            "Loss in iteration no. 99438 ==> 0.4162523315009698\n",
            "Loss in iteration no. 99439 ==> 0.4162514208793807\n",
            "Loss in iteration no. 99440 ==> 0.4162505102699169\n",
            "Loss in iteration no. 99441 ==> 0.4162495996725782\n",
            "Loss in iteration no. 99442 ==> 0.4162486890873641\n",
            "Loss in iteration no. 99443 ==> 0.4162477785142747\n",
            "Loss in iteration no. 99444 ==> 0.41624686795330956\n",
            "Loss in iteration no. 99445 ==> 0.41624595740446857\n",
            "Loss in iteration no. 99446 ==> 0.4162450468677515\n",
            "Loss in iteration no. 99447 ==> 0.416244136343158\n",
            "Loss in iteration no. 99448 ==> 0.41624322583068796\n",
            "Loss in iteration no. 99449 ==> 0.4162423153303411\n",
            "Loss in iteration no. 99450 ==> 0.41624140484211725\n",
            "Loss in iteration no. 99451 ==> 0.4162404943660161\n",
            "Loss in iteration no. 99452 ==> 0.4162395839020375\n",
            "Loss in iteration no. 99453 ==> 0.4162386734501812\n",
            "Loss in iteration no. 99454 ==> 0.4162377630104469\n",
            "Loss in iteration no. 99455 ==> 0.41623685258283444\n",
            "Loss in iteration no. 99456 ==> 0.41623594216734366\n",
            "Loss in iteration no. 99457 ==> 0.4162350317639742\n",
            "Loss in iteration no. 99458 ==> 0.41623412137272586\n",
            "Loss in iteration no. 99459 ==> 0.4162332109935984\n",
            "Loss in iteration no. 99460 ==> 0.4162323006265918\n",
            "Loss in iteration no. 99461 ==> 0.4162313902717055\n",
            "Loss in iteration no. 99462 ==> 0.4162304799289395\n",
            "Loss in iteration no. 99463 ==> 0.41622956959829344\n",
            "Loss in iteration no. 99464 ==> 0.4162286592797674\n",
            "Loss in iteration no. 99465 ==> 0.4162277489733606\n",
            "Loss in iteration no. 99466 ==> 0.41622683867907334\n",
            "Loss in iteration no. 99467 ==> 0.4162259283969051\n",
            "Loss in iteration no. 99468 ==> 0.41622501812685575\n",
            "Loss in iteration no. 99469 ==> 0.41622410786892505\n",
            "Loss in iteration no. 99470 ==> 0.41622319762311283\n",
            "Loss in iteration no. 99471 ==> 0.41622228738941863\n",
            "Loss in iteration no. 99472 ==> 0.4162213771678425\n",
            "Loss in iteration no. 99473 ==> 0.41622046695838416\n",
            "Loss in iteration no. 99474 ==> 0.41621955676104316\n",
            "Loss in iteration no. 99475 ==> 0.4162186465758196\n",
            "Loss in iteration no. 99476 ==> 0.41621773640271303\n",
            "Loss in iteration no. 99477 ==> 0.41621682624172324\n",
            "Loss in iteration no. 99478 ==> 0.4162159160928501\n",
            "Loss in iteration no. 99479 ==> 0.41621500595609323\n",
            "Loss in iteration no. 99480 ==> 0.41621409583145264\n",
            "Loss in iteration no. 99481 ==> 0.41621318571892796\n",
            "Loss in iteration no. 99482 ==> 0.41621227561851887\n",
            "Loss in iteration no. 99483 ==> 0.41621136553022525\n",
            "Loss in iteration no. 99484 ==> 0.41621045545404695\n",
            "Loss in iteration no. 99485 ==> 0.41620954538998356\n",
            "Loss in iteration no. 99486 ==> 0.4162086353380349\n",
            "Loss in iteration no. 99487 ==> 0.4162077252982009\n",
            "Loss in iteration no. 99488 ==> 0.4162068152704812\n",
            "Loss in iteration no. 99489 ==> 0.4162059052548756\n",
            "Loss in iteration no. 99490 ==> 0.4162049952513838\n",
            "Loss in iteration no. 99491 ==> 0.4162040852600057\n",
            "Loss in iteration no. 99492 ==> 0.416203175280741\n",
            "Loss in iteration no. 99493 ==> 0.4162022653135895\n",
            "Loss in iteration no. 99494 ==> 0.4162013553585509\n",
            "Loss in iteration no. 99495 ==> 0.416200445415625\n",
            "Loss in iteration no. 99496 ==> 0.41619953548481176\n",
            "Loss in iteration no. 99497 ==> 0.41619862556611065\n",
            "Loss in iteration no. 99498 ==> 0.4161977156595216\n",
            "Loss in iteration no. 99499 ==> 0.4161968057650444\n",
            "Loss in iteration no. 99500 ==> 0.4161958958826788\n",
            "Loss in iteration no. 99501 ==> 0.4161949860124246\n",
            "Loss in iteration no. 99502 ==> 0.41619407615428144\n",
            "Loss in iteration no. 99503 ==> 0.4161931663082492\n",
            "Loss in iteration no. 99504 ==> 0.41619225647432767\n",
            "Loss in iteration no. 99505 ==> 0.4161913466525166\n",
            "Loss in iteration no. 99506 ==> 0.41619043684281576\n",
            "Loss in iteration no. 99507 ==> 0.41618952704522494\n",
            "Loss in iteration no. 99508 ==> 0.41618861725974376\n",
            "Loss in iteration no. 99509 ==> 0.4161877074863723\n",
            "Loss in iteration no. 99510 ==> 0.4161867977251101\n",
            "Loss in iteration no. 99511 ==> 0.41618588797595696\n",
            "Loss in iteration no. 99512 ==> 0.4161849782389127\n",
            "Loss in iteration no. 99513 ==> 0.41618406851397705\n",
            "Loss in iteration no. 99514 ==> 0.4161831588011498\n",
            "Loss in iteration no. 99515 ==> 0.4161822491004308\n",
            "Loss in iteration no. 99516 ==> 0.4161813394118196\n",
            "Loss in iteration no. 99517 ==> 0.41618042973531627\n",
            "Loss in iteration no. 99518 ==> 0.4161795200709204\n",
            "Loss in iteration no. 99519 ==> 0.4161786104186318\n",
            "Loss in iteration no. 99520 ==> 0.41617770077845023\n",
            "Loss in iteration no. 99521 ==> 0.4161767911503755\n",
            "Loss in iteration no. 99522 ==> 0.4161758815344073\n",
            "Loss in iteration no. 99523 ==> 0.41617497193054553\n",
            "Loss in iteration no. 99524 ==> 0.41617406233878984\n",
            "Loss in iteration no. 99525 ==> 0.41617315275914013\n",
            "Loss in iteration no. 99526 ==> 0.416172243191596\n",
            "Loss in iteration no. 99527 ==> 0.4161713336361574\n",
            "Loss in iteration no. 99528 ==> 0.41617042409282395\n",
            "Loss in iteration no. 99529 ==> 0.4161695145615956\n",
            "Loss in iteration no. 99530 ==> 0.41616860504247194\n",
            "Loss in iteration no. 99531 ==> 0.4161676955354528\n",
            "Loss in iteration no. 99532 ==> 0.41616678604053803\n",
            "Loss in iteration no. 99533 ==> 0.4161658765577273\n",
            "Loss in iteration no. 99534 ==> 0.4161649670870205\n",
            "Loss in iteration no. 99535 ==> 0.4161640576284173\n",
            "Loss in iteration no. 99536 ==> 0.4161631481819175\n",
            "Loss in iteration no. 99537 ==> 0.4161622387475209\n",
            "Loss in iteration no. 99538 ==> 0.4161613293252273\n",
            "Loss in iteration no. 99539 ==> 0.4161604199150363\n",
            "Loss in iteration no. 99540 ==> 0.41615951051694783\n",
            "Loss in iteration no. 99541 ==> 0.4161586011309616\n",
            "Loss in iteration no. 99542 ==> 0.4161576917570775\n",
            "Loss in iteration no. 99543 ==> 0.4161567823952952\n",
            "Loss in iteration no. 99544 ==> 0.4161558730456144\n",
            "Loss in iteration no. 99545 ==> 0.41615496370803506\n",
            "Loss in iteration no. 99546 ==> 0.4161540543825568\n",
            "Loss in iteration no. 99547 ==> 0.41615314506917955\n",
            "Loss in iteration no. 99548 ==> 0.4161522357679029\n",
            "Loss in iteration no. 99549 ==> 0.41615132647872666\n",
            "Loss in iteration no. 99550 ==> 0.4161504172016507\n",
            "Loss in iteration no. 99551 ==> 0.4161495079366747\n",
            "Loss in iteration no. 99552 ==> 0.4161485986837985\n",
            "Loss in iteration no. 99553 ==> 0.4161476894430219\n",
            "Loss in iteration no. 99554 ==> 0.4161467802143445\n",
            "Loss in iteration no. 99555 ==> 0.4161458709977663\n",
            "Loss in iteration no. 99556 ==> 0.4161449617932868\n",
            "Loss in iteration no. 99557 ==> 0.4161440526009061\n",
            "Loss in iteration no. 99558 ==> 0.41614314342062375\n",
            "Loss in iteration no. 99559 ==> 0.41614223425243957\n",
            "Loss in iteration no. 99560 ==> 0.4161413250963533\n",
            "Loss in iteration no. 99561 ==> 0.4161404159523649\n",
            "Loss in iteration no. 99562 ==> 0.4161395068204739\n",
            "Loss in iteration no. 99563 ==> 0.4161385977006801\n",
            "Loss in iteration no. 99564 ==> 0.41613768859298345\n",
            "Loss in iteration no. 99565 ==> 0.41613677949738365\n",
            "Loss in iteration no. 99566 ==> 0.41613587041388034\n",
            "Loss in iteration no. 99567 ==> 0.4161349613424734\n",
            "Loss in iteration no. 99568 ==> 0.4161340522831627\n",
            "Loss in iteration no. 99569 ==> 0.4161331432359478\n",
            "Loss in iteration no. 99570 ==> 0.4161322342008287\n",
            "Loss in iteration no. 99571 ==> 0.41613132517780493\n",
            "Loss in iteration no. 99572 ==> 0.4161304161668764\n",
            "Loss in iteration no. 99573 ==> 0.4161295071680429\n",
            "Loss in iteration no. 99574 ==> 0.41612859818130427\n",
            "Loss in iteration no. 99575 ==> 0.41612768920666005\n",
            "Loss in iteration no. 99576 ==> 0.41612678024411015\n",
            "Loss in iteration no. 99577 ==> 0.4161258712936544\n",
            "Loss in iteration no. 99578 ==> 0.41612496235529256\n",
            "Loss in iteration no. 99579 ==> 0.4161240534290243\n",
            "Loss in iteration no. 99580 ==> 0.41612314451484944\n",
            "Loss in iteration no. 99581 ==> 0.4161222356127678\n",
            "Loss in iteration no. 99582 ==> 0.4161213267227791\n",
            "Loss in iteration no. 99583 ==> 0.4161204178448831\n",
            "Loss in iteration no. 99584 ==> 0.4161195089790797\n",
            "Loss in iteration no. 99585 ==> 0.41611860012536844\n",
            "Loss in iteration no. 99586 ==> 0.4161176912837493\n",
            "Loss in iteration no. 99587 ==> 0.41611678245422207\n",
            "Loss in iteration no. 99588 ==> 0.4161158736367863\n",
            "Loss in iteration no. 99589 ==> 0.41611496483144195\n",
            "Loss in iteration no. 99590 ==> 0.41611405603818874\n",
            "Loss in iteration no. 99591 ==> 0.41611314725702647\n",
            "Loss in iteration no. 99592 ==> 0.41611223848795487\n",
            "Loss in iteration no. 99593 ==> 0.4161113297309738\n",
            "Loss in iteration no. 99594 ==> 0.41611042098608286\n",
            "Loss in iteration no. 99595 ==> 0.4161095122532819\n",
            "Loss in iteration no. 99596 ==> 0.4161086035325708\n",
            "Loss in iteration no. 99597 ==> 0.4161076948239492\n",
            "Loss in iteration no. 99598 ==> 0.4161067861274171\n",
            "Loss in iteration no. 99599 ==> 0.4161058774429739\n",
            "Loss in iteration no. 99600 ==> 0.4161049687706197\n",
            "Loss in iteration no. 99601 ==> 0.416104060110354\n",
            "Loss in iteration no. 99602 ==> 0.41610315146217686\n",
            "Loss in iteration no. 99603 ==> 0.4161022428260878\n",
            "Loss in iteration no. 99604 ==> 0.4161013342020868\n",
            "Loss in iteration no. 99605 ==> 0.4161004255901735\n",
            "Loss in iteration no. 99606 ==> 0.4160995169903477\n",
            "Loss in iteration no. 99607 ==> 0.4160986084026092\n",
            "Loss in iteration no. 99608 ==> 0.4160976998269577\n",
            "Loss in iteration no. 99609 ==> 0.4160967912633932\n",
            "Loss in iteration no. 99610 ==> 0.4160958827119151\n",
            "Loss in iteration no. 99611 ==> 0.4160949741725235\n",
            "Loss in iteration no. 99612 ==> 0.41609406564521806\n",
            "Loss in iteration no. 99613 ==> 0.4160931571299985\n",
            "Loss in iteration no. 99614 ==> 0.4160922486268647\n",
            "Loss in iteration no. 99615 ==> 0.41609134013581617\n",
            "Loss in iteration no. 99616 ==> 0.41609043165685305\n",
            "Loss in iteration no. 99617 ==> 0.416089523189975\n",
            "Loss in iteration no. 99618 ==> 0.41608861473518166\n",
            "Loss in iteration no. 99619 ==> 0.4160877062924729\n",
            "Loss in iteration no. 99620 ==> 0.41608679786184843\n",
            "Loss in iteration no. 99621 ==> 0.4160858894433081\n",
            "Loss in iteration no. 99622 ==> 0.41608498103685165\n",
            "Loss in iteration no. 99623 ==> 0.4160840726424788\n",
            "Loss in iteration no. 99624 ==> 0.41608316426018954\n",
            "Loss in iteration no. 99625 ==> 0.4160822558899833\n",
            "Loss in iteration no. 99626 ==> 0.41608134753186016\n",
            "Loss in iteration no. 99627 ==> 0.41608043918581966\n",
            "Loss in iteration no. 99628 ==> 0.41607953085186183\n",
            "Loss in iteration no. 99629 ==> 0.4160786225299862\n",
            "Loss in iteration no. 99630 ==> 0.41607771422019263\n",
            "Loss in iteration no. 99631 ==> 0.41607680592248086\n",
            "Loss in iteration no. 99632 ==> 0.4160758976368508\n",
            "Loss in iteration no. 99633 ==> 0.41607498936330206\n",
            "Loss in iteration no. 99634 ==> 0.4160740811018346\n",
            "Loss in iteration no. 99635 ==> 0.416073172852448\n",
            "Loss in iteration no. 99636 ==> 0.4160722646151421\n",
            "Loss in iteration no. 99637 ==> 0.41607135638991666\n",
            "Loss in iteration no. 99638 ==> 0.41607044817677147\n",
            "Loss in iteration no. 99639 ==> 0.41606953997570634\n",
            "Loss in iteration no. 99640 ==> 0.416068631786721\n",
            "Loss in iteration no. 99641 ==> 0.41606772360981525\n",
            "Loss in iteration no. 99642 ==> 0.41606681544498886\n",
            "Loss in iteration no. 99643 ==> 0.4160659072922416\n",
            "Loss in iteration no. 99644 ==> 0.41606499915157313\n",
            "Loss in iteration no. 99645 ==> 0.4160640910229835\n",
            "Loss in iteration no. 99646 ==> 0.41606318290647215\n",
            "Loss in iteration no. 99647 ==> 0.416062274802039\n",
            "Loss in iteration no. 99648 ==> 0.41606136670968397\n",
            "Loss in iteration no. 99649 ==> 0.4160604586294066\n",
            "Loss in iteration no. 99650 ==> 0.41605955056120686\n",
            "Loss in iteration no. 99651 ==> 0.4160586425050844\n",
            "Loss in iteration no. 99652 ==> 0.416057734461039\n",
            "Loss in iteration no. 99653 ==> 0.4160568264290705\n",
            "Loss in iteration no. 99654 ==> 0.41605591840917855\n",
            "Loss in iteration no. 99655 ==> 0.41605501040136306\n",
            "Loss in iteration no. 99656 ==> 0.4160541024056237\n",
            "Loss in iteration no. 99657 ==> 0.4160531944219603\n",
            "Loss in iteration no. 99658 ==> 0.41605228645037257\n",
            "Loss in iteration no. 99659 ==> 0.41605137849086044\n",
            "Loss in iteration no. 99660 ==> 0.4160504705434236\n",
            "Loss in iteration no. 99661 ==> 0.4160495626080617\n",
            "Loss in iteration no. 99662 ==> 0.41604865468477464\n",
            "Loss in iteration no. 99663 ==> 0.41604774677356215\n",
            "Loss in iteration no. 99664 ==> 0.41604683887442406\n",
            "Loss in iteration no. 99665 ==> 0.4160459309873602\n",
            "Loss in iteration no. 99666 ==> 0.41604502311237007\n",
            "Loss in iteration no. 99667 ==> 0.4160441152494537\n",
            "Loss in iteration no. 99668 ==> 0.41604320739861084\n",
            "Loss in iteration no. 99669 ==> 0.4160422995598411\n",
            "Loss in iteration no. 99670 ==> 0.41604139173314436\n",
            "Loss in iteration no. 99671 ==> 0.41604048391852055\n",
            "Loss in iteration no. 99672 ==> 0.4160395761159692\n",
            "Loss in iteration no. 99673 ==> 0.4160386683254902\n",
            "Loss in iteration no. 99674 ==> 0.41603776054708325\n",
            "Loss in iteration no. 99675 ==> 0.4160368527807482\n",
            "Loss in iteration no. 99676 ==> 0.41603594502648483\n",
            "Loss in iteration no. 99677 ==> 0.41603503728429275\n",
            "Loss in iteration no. 99678 ==> 0.416034129554172\n",
            "Loss in iteration no. 99679 ==> 0.4160332218361222\n",
            "Loss in iteration no. 99680 ==> 0.41603231413014297\n",
            "Loss in iteration no. 99681 ==> 0.4160314064362345\n",
            "Loss in iteration no. 99682 ==> 0.4160304987543962\n",
            "Loss in iteration no. 99683 ==> 0.4160295910846279\n",
            "Loss in iteration no. 99684 ==> 0.4160286834269295\n",
            "Loss in iteration no. 99685 ==> 0.41602777578130073\n",
            "Loss in iteration no. 99686 ==> 0.41602686814774126\n",
            "Loss in iteration no. 99687 ==> 0.41602596052625107\n",
            "Loss in iteration no. 99688 ==> 0.41602505291682973\n",
            "Loss in iteration no. 99689 ==> 0.41602414531947707\n",
            "Loss in iteration no. 99690 ==> 0.41602323773419286\n",
            "Loss in iteration no. 99691 ==> 0.41602233016097695\n",
            "Loss in iteration no. 99692 ==> 0.41602142259982905\n",
            "Loss in iteration no. 99693 ==> 0.41602051505074894\n",
            "Loss in iteration no. 99694 ==> 0.41601960751373646\n",
            "Loss in iteration no. 99695 ==> 0.41601869998879126\n",
            "Loss in iteration no. 99696 ==> 0.41601779247591325\n",
            "Loss in iteration no. 99697 ==> 0.41601688497510203\n",
            "Loss in iteration no. 99698 ==> 0.41601597748635744\n",
            "Loss in iteration no. 99699 ==> 0.4160150700096793\n",
            "Loss in iteration no. 99700 ==> 0.4160141625450674\n",
            "Loss in iteration no. 99701 ==> 0.4160132550925216\n",
            "Loss in iteration no. 99702 ==> 0.4160123476520415\n",
            "Loss in iteration no. 99703 ==> 0.41601144022362685\n",
            "Loss in iteration no. 99704 ==> 0.41601053280727757\n",
            "Loss in iteration no. 99705 ==> 0.41600962540299335\n",
            "Loss in iteration no. 99706 ==> 0.416008718010774\n",
            "Loss in iteration no. 99707 ==> 0.4160078106306192\n",
            "Loss in iteration no. 99708 ==> 0.41600690326252887\n",
            "Loss in iteration no. 99709 ==> 0.4160059959065027\n",
            "Loss in iteration no. 99710 ==> 0.4160050885625405\n",
            "Loss in iteration no. 99711 ==> 0.41600418123064203\n",
            "Loss in iteration no. 99712 ==> 0.416003273910807\n",
            "Loss in iteration no. 99713 ==> 0.41600236660303525\n",
            "Loss in iteration no. 99714 ==> 0.4160014593073265\n",
            "Loss in iteration no. 99715 ==> 0.4160005520236807\n",
            "Loss in iteration no. 99716 ==> 0.4159996447520974\n",
            "Loss in iteration no. 99717 ==> 0.41599873749257643\n",
            "Loss in iteration no. 99718 ==> 0.4159978302451176\n",
            "Loss in iteration no. 99719 ==> 0.4159969230097208\n",
            "Loss in iteration no. 99720 ==> 0.4159960157863856\n",
            "Loss in iteration no. 99721 ==> 0.41599510857511185\n",
            "Loss in iteration no. 99722 ==> 0.41599420137589926\n",
            "Loss in iteration no. 99723 ==> 0.4159932941887478\n",
            "Loss in iteration no. 99724 ==> 0.4159923870136571\n",
            "Loss in iteration no. 99725 ==> 0.4159914798506269\n",
            "Loss in iteration no. 99726 ==> 0.4159905726996571\n",
            "Loss in iteration no. 99727 ==> 0.41598966556074735\n",
            "Loss in iteration no. 99728 ==> 0.41598875843389754\n",
            "Loss in iteration no. 99729 ==> 0.41598785131910726\n",
            "Loss in iteration no. 99730 ==> 0.41598694421637644\n",
            "Loss in iteration no. 99731 ==> 0.4159860371257049\n",
            "Loss in iteration no. 99732 ==> 0.41598513004709226\n",
            "Loss in iteration no. 99733 ==> 0.41598422298053833\n",
            "Loss in iteration no. 99734 ==> 0.415983315926043\n",
            "Loss in iteration no. 99735 ==> 0.41598240888360594\n",
            "Loss in iteration no. 99736 ==> 0.4159815018532269\n",
            "Loss in iteration no. 99737 ==> 0.4159805948349057\n",
            "Loss in iteration no. 99738 ==> 0.41597968782864214\n",
            "Loss in iteration no. 99739 ==> 0.41597878083443596\n",
            "Loss in iteration no. 99740 ==> 0.41597787385228696\n",
            "Loss in iteration no. 99741 ==> 0.4159769668821949\n",
            "Loss in iteration no. 99742 ==> 0.41597605992415954\n",
            "Loss in iteration no. 99743 ==> 0.4159751529781806\n",
            "Loss in iteration no. 99744 ==> 0.4159742460442581\n",
            "Loss in iteration no. 99745 ==> 0.41597333912239143\n",
            "Loss in iteration no. 99746 ==> 0.4159724322125806\n",
            "Loss in iteration no. 99747 ==> 0.41597152531482545\n",
            "Loss in iteration no. 99748 ==> 0.4159706184291256\n",
            "Loss in iteration no. 99749 ==> 0.4159697115554808\n",
            "Loss in iteration no. 99750 ==> 0.415968804693891\n",
            "Loss in iteration no. 99751 ==> 0.4159678978443558\n",
            "Loss in iteration no. 99752 ==> 0.41596699100687506\n",
            "Loss in iteration no. 99753 ==> 0.4159660841814486\n",
            "Loss in iteration no. 99754 ==> 0.4159651773680761\n",
            "Loss in iteration no. 99755 ==> 0.41596427056675733\n",
            "Loss in iteration no. 99756 ==> 0.4159633637774921\n",
            "Loss in iteration no. 99757 ==> 0.4159624570002803\n",
            "Loss in iteration no. 99758 ==> 0.4159615502351215\n",
            "Loss in iteration no. 99759 ==> 0.4159606434820155\n",
            "Loss in iteration no. 99760 ==> 0.4159597367409623\n",
            "Loss in iteration no. 99761 ==> 0.4159588300119614\n",
            "Loss in iteration no. 99762 ==> 0.4159579232950127\n",
            "Loss in iteration no. 99763 ==> 0.41595701659011597\n",
            "Loss in iteration no. 99764 ==> 0.41595610989727094\n",
            "Loss in iteration no. 99765 ==> 0.4159552032164775\n",
            "Loss in iteration no. 99766 ==> 0.4159542965477353\n",
            "Loss in iteration no. 99767 ==> 0.4159533898910443\n",
            "Loss in iteration no. 99768 ==> 0.4159524832464038\n",
            "Loss in iteration no. 99769 ==> 0.4159515766138142\n",
            "Loss in iteration no. 99770 ==> 0.4159506699932749\n",
            "Loss in iteration no. 99771 ==> 0.41594976338478573\n",
            "Loss in iteration no. 99772 ==> 0.4159488567883464\n",
            "Loss in iteration no. 99773 ==> 0.41594795020395686\n",
            "Loss in iteration no. 99774 ==> 0.4159470436316169\n",
            "Loss in iteration no. 99775 ==> 0.415946137071326\n",
            "Loss in iteration no. 99776 ==> 0.41594523052308424\n",
            "Loss in iteration no. 99777 ==> 0.4159443239868912\n",
            "Loss in iteration no. 99778 ==> 0.4159434174627468\n",
            "Loss in iteration no. 99779 ==> 0.41594251095065077\n",
            "Loss in iteration no. 99780 ==> 0.4159416044506027\n",
            "Loss in iteration no. 99781 ==> 0.41594069796260263\n",
            "Loss in iteration no. 99782 ==> 0.4159397914866503\n",
            "Loss in iteration no. 99783 ==> 0.4159388850227453\n",
            "Loss in iteration no. 99784 ==> 0.4159379785708876\n",
            "Loss in iteration no. 99785 ==> 0.4159370721310768\n",
            "Loss in iteration no. 99786 ==> 0.41593616570331277\n",
            "Loss in iteration no. 99787 ==> 0.41593525928759534\n",
            "Loss in iteration no. 99788 ==> 0.41593435288392416\n",
            "Loss in iteration no. 99789 ==> 0.4159334464922992\n",
            "Loss in iteration no. 99790 ==> 0.41593254011272\n",
            "Loss in iteration no. 99791 ==> 0.41593163374518644\n",
            "Loss in iteration no. 99792 ==> 0.4159307273896983\n",
            "Loss in iteration no. 99793 ==> 0.41592982104625525\n",
            "Loss in iteration no. 99794 ==> 0.4159289147148573\n",
            "Loss in iteration no. 99795 ==> 0.41592800839550403\n",
            "Loss in iteration no. 99796 ==> 0.4159271020881952\n",
            "Loss in iteration no. 99797 ==> 0.4159261957929307\n",
            "Loss in iteration no. 99798 ==> 0.41592528950971025\n",
            "Loss in iteration no. 99799 ==> 0.4159243832385337\n",
            "Loss in iteration no. 99800 ==> 0.41592347697940074\n",
            "Loss in iteration no. 99801 ==> 0.41592257073231104\n",
            "Loss in iteration no. 99802 ==> 0.4159216644972646\n",
            "Loss in iteration no. 99803 ==> 0.415920758274261\n",
            "Loss in iteration no. 99804 ==> 0.41591985206330023\n",
            "Loss in iteration no. 99805 ==> 0.4159189458643819\n",
            "Loss in iteration no. 99806 ==> 0.41591803967750574\n",
            "Loss in iteration no. 99807 ==> 0.41591713350267157\n",
            "Loss in iteration no. 99808 ==> 0.4159162273398792\n",
            "Loss in iteration no. 99809 ==> 0.41591532118912844\n",
            "Loss in iteration no. 99810 ==> 0.41591441505041915\n",
            "Loss in iteration no. 99811 ==> 0.4159135089237508\n",
            "Loss in iteration no. 99812 ==> 0.41591260280912346\n",
            "Loss in iteration no. 99813 ==> 0.41591169670653666\n",
            "Loss in iteration no. 99814 ==> 0.4159107906159904\n",
            "Loss in iteration no. 99815 ==> 0.4159098845374844\n",
            "Loss in iteration no. 99816 ==> 0.41590897847101826\n",
            "Loss in iteration no. 99817 ==> 0.4159080724165919\n",
            "Loss in iteration no. 99818 ==> 0.4159071663742051\n",
            "Loss in iteration no. 99819 ==> 0.41590626034385775\n",
            "Loss in iteration no. 99820 ==> 0.4159053543255493\n",
            "Loss in iteration no. 99821 ==> 0.41590444831927975\n",
            "Loss in iteration no. 99822 ==> 0.41590354232504895\n",
            "Loss in iteration no. 99823 ==> 0.41590263634285646\n",
            "Loss in iteration no. 99824 ==> 0.41590173037270217\n",
            "Loss in iteration no. 99825 ==> 0.41590082441458587\n",
            "Loss in iteration no. 99826 ==> 0.41589991846850727\n",
            "Loss in iteration no. 99827 ==> 0.41589901253446615\n",
            "Loss in iteration no. 99828 ==> 0.41589810661246235\n",
            "Loss in iteration no. 99829 ==> 0.4158972007024957\n",
            "Loss in iteration no. 99830 ==> 0.41589629480456575\n",
            "Loss in iteration no. 99831 ==> 0.4158953889186724\n",
            "Loss in iteration no. 99832 ==> 0.41589448304481547\n",
            "Loss in iteration no. 99833 ==> 0.4158935771829947\n",
            "Loss in iteration no. 99834 ==> 0.4158926713332098\n",
            "Loss in iteration no. 99835 ==> 0.4158917654954607\n",
            "Loss in iteration no. 99836 ==> 0.415890859669747\n",
            "Loss in iteration no. 99837 ==> 0.4158899538560686\n",
            "Loss in iteration no. 99838 ==> 0.4158890480544252\n",
            "Loss in iteration no. 99839 ==> 0.4158881422648167\n",
            "Loss in iteration no. 99840 ==> 0.4158872364872426\n",
            "Loss in iteration no. 99841 ==> 0.4158863307217029\n",
            "Loss in iteration no. 99842 ==> 0.4158854249681974\n",
            "Loss in iteration no. 99843 ==> 0.4158845192267257\n",
            "Loss in iteration no. 99844 ==> 0.41588361349728775\n",
            "Loss in iteration no. 99845 ==> 0.4158827077798832\n",
            "Loss in iteration no. 99846 ==> 0.41588180207451186\n",
            "Loss in iteration no. 99847 ==> 0.4158808963811736\n",
            "Loss in iteration no. 99848 ==> 0.415879990699868\n",
            "Loss in iteration no. 99849 ==> 0.41587908503059495\n",
            "Loss in iteration no. 99850 ==> 0.41587817937335436\n",
            "Loss in iteration no. 99851 ==> 0.4158772737281457\n",
            "Loss in iteration no. 99852 ==> 0.41587636809496903\n",
            "Loss in iteration no. 99853 ==> 0.41587546247382384\n",
            "Loss in iteration no. 99854 ==> 0.41587455686471025\n",
            "Loss in iteration no. 99855 ==> 0.41587365126762765\n",
            "Loss in iteration no. 99856 ==> 0.41587274568257615\n",
            "Loss in iteration no. 99857 ==> 0.41587184010955536\n",
            "Loss in iteration no. 99858 ==> 0.41587093454856516\n",
            "Loss in iteration no. 99859 ==> 0.4158700289996052\n",
            "Loss in iteration no. 99860 ==> 0.4158691234626753\n",
            "Loss in iteration no. 99861 ==> 0.4158682179377753\n",
            "Loss in iteration no. 99862 ==> 0.41586731242490477\n",
            "Loss in iteration no. 99863 ==> 0.4158664069240638\n",
            "Loss in iteration no. 99864 ==> 0.41586550143525175\n",
            "Loss in iteration no. 99865 ==> 0.41586459595846886\n",
            "Loss in iteration no. 99866 ==> 0.4158636904937146\n",
            "Loss in iteration no. 99867 ==> 0.4158627850409887\n",
            "Loss in iteration no. 99868 ==> 0.41586187960029125\n",
            "Loss in iteration no. 99869 ==> 0.4158609741716218\n",
            "Loss in iteration no. 99870 ==> 0.4158600687549801\n",
            "Loss in iteration no. 99871 ==> 0.41585916335036605\n",
            "Loss in iteration no. 99872 ==> 0.4158582579577793\n",
            "Loss in iteration no. 99873 ==> 0.41585735257721973\n",
            "Loss in iteration no. 99874 ==> 0.415856447208687\n",
            "Loss in iteration no. 99875 ==> 0.41585554185218104\n",
            "Loss in iteration no. 99876 ==> 0.41585463650770144\n",
            "Loss in iteration no. 99877 ==> 0.4158537311752481\n",
            "Loss in iteration no. 99878 ==> 0.41585282585482086\n",
            "Loss in iteration no. 99879 ==> 0.41585192054641934\n",
            "Loss in iteration no. 99880 ==> 0.41585101525004337\n",
            "Loss in iteration no. 99881 ==> 0.4158501099656927\n",
            "Loss in iteration no. 99882 ==> 0.41584920469336706\n",
            "Loss in iteration no. 99883 ==> 0.4158482994330665\n",
            "Loss in iteration no. 99884 ==> 0.4158473941847904\n",
            "Loss in iteration no. 99885 ==> 0.4158464889485388\n",
            "Loss in iteration no. 99886 ==> 0.41584558372431146\n",
            "Loss in iteration no. 99887 ==> 0.41584467851210805\n",
            "Loss in iteration no. 99888 ==> 0.4158437733119284\n",
            "Loss in iteration no. 99889 ==> 0.41584286812377225\n",
            "Loss in iteration no. 99890 ==> 0.4158419629476395\n",
            "Loss in iteration no. 99891 ==> 0.4158410577835297\n",
            "Loss in iteration no. 99892 ==> 0.4158401526314428\n",
            "Loss in iteration no. 99893 ==> 0.41583924749137846\n",
            "Loss in iteration no. 99894 ==> 0.4158383423633366\n",
            "Loss in iteration no. 99895 ==> 0.41583743724731687\n",
            "Loss in iteration no. 99896 ==> 0.4158365321433192\n",
            "Loss in iteration no. 99897 ==> 0.4158356270513431\n",
            "Loss in iteration no. 99898 ==> 0.4158347219713886\n",
            "Loss in iteration no. 99899 ==> 0.41583381690345533\n",
            "Loss in iteration no. 99900 ==> 0.4158329118475431\n",
            "Loss in iteration no. 99901 ==> 0.4158320068036518\n",
            "Loss in iteration no. 99902 ==> 0.41583110177178095\n",
            "Loss in iteration no. 99903 ==> 0.41583019675193056\n",
            "Loss in iteration no. 99904 ==> 0.4158292917441003\n",
            "Loss in iteration no. 99905 ==> 0.4158283867482899\n",
            "Loss in iteration no. 99906 ==> 0.41582748176449935\n",
            "Loss in iteration no. 99907 ==> 0.4158265767927281\n",
            "Loss in iteration no. 99908 ==> 0.41582567183297625\n",
            "Loss in iteration no. 99909 ==> 0.41582476688524334\n",
            "Loss in iteration no. 99910 ==> 0.4158238619495292\n",
            "Loss in iteration no. 99911 ==> 0.41582295702583366\n",
            "Loss in iteration no. 99912 ==> 0.4158220521141565\n",
            "Loss in iteration no. 99913 ==> 0.4158211472144974\n",
            "Loss in iteration no. 99914 ==> 0.4158202423268562\n",
            "Loss in iteration no. 99915 ==> 0.4158193374512328\n",
            "Loss in iteration no. 99916 ==> 0.41581843258762663\n",
            "Loss in iteration no. 99917 ==> 0.4158175277360378\n",
            "Loss in iteration no. 99918 ==> 0.41581662289646604\n",
            "Loss in iteration no. 99919 ==> 0.41581571806891093\n",
            "Loss in iteration no. 99920 ==> 0.4158148132533724\n",
            "Loss in iteration no. 99921 ==> 0.4158139084498501\n",
            "Loss in iteration no. 99922 ==> 0.41581300365834406\n",
            "Loss in iteration no. 99923 ==> 0.4158120988788538\n",
            "Loss in iteration no. 99924 ==> 0.4158111941113792\n",
            "Loss in iteration no. 99925 ==> 0.41581028935592\n",
            "Loss in iteration no. 99926 ==> 0.415809384612476\n",
            "Loss in iteration no. 99927 ==> 0.41580847988104697\n",
            "Loss in iteration no. 99928 ==> 0.4158075751616327\n",
            "Loss in iteration no. 99929 ==> 0.4158066704542329\n",
            "Loss in iteration no. 99930 ==> 0.4158057657588474\n",
            "Loss in iteration no. 99931 ==> 0.41580486107547604\n",
            "Loss in iteration no. 99932 ==> 0.4158039564041185\n",
            "Loss in iteration no. 99933 ==> 0.41580305174477455\n",
            "Loss in iteration no. 99934 ==> 0.415802147097444\n",
            "Loss in iteration no. 99935 ==> 0.41580124246212663\n",
            "Loss in iteration no. 99936 ==> 0.41580033783882214\n",
            "Loss in iteration no. 99937 ==> 0.4157994332275304\n",
            "Loss in iteration no. 99938 ==> 0.4157985286282512\n",
            "Loss in iteration no. 99939 ==> 0.4157976240409842\n",
            "Loss in iteration no. 99940 ==> 0.41579671946572927\n",
            "Loss in iteration no. 99941 ==> 0.41579581490248624\n",
            "Loss in iteration no. 99942 ==> 0.41579491035125465\n",
            "Loss in iteration no. 99943 ==> 0.4157940058120346\n",
            "Loss in iteration no. 99944 ==> 0.41579310128482555\n",
            "Loss in iteration no. 99945 ==> 0.4157921967696274\n",
            "Loss in iteration no. 99946 ==> 0.41579129226644007\n",
            "Loss in iteration no. 99947 ==> 0.41579038777526306\n",
            "Loss in iteration no. 99948 ==> 0.41578948329609644\n",
            "Loss in iteration no. 99949 ==> 0.41578857882893977\n",
            "Loss in iteration no. 99950 ==> 0.4157876743737929\n",
            "Loss in iteration no. 99951 ==> 0.4157867699306556\n",
            "Loss in iteration no. 99952 ==> 0.41578586549952756\n",
            "Loss in iteration no. 99953 ==> 0.41578496108040874\n",
            "Loss in iteration no. 99954 ==> 0.41578405667329876\n",
            "Loss in iteration no. 99955 ==> 0.41578315227819745\n",
            "Loss in iteration no. 99956 ==> 0.4157822478951047\n",
            "Loss in iteration no. 99957 ==> 0.4157813435240199\n",
            "Loss in iteration no. 99958 ==> 0.4157804391649433\n",
            "Loss in iteration no. 99959 ==> 0.41577953481787444\n",
            "Loss in iteration no. 99960 ==> 0.4157786304828131\n",
            "Loss in iteration no. 99961 ==> 0.4157777261597591\n",
            "Loss in iteration no. 99962 ==> 0.41577682184871223\n",
            "Loss in iteration no. 99963 ==> 0.41577591754967214\n",
            "Loss in iteration no. 99964 ==> 0.4157750132626387\n",
            "Loss in iteration no. 99965 ==> 0.41577410898761175\n",
            "Loss in iteration no. 99966 ==> 0.4157732047245909\n",
            "Loss in iteration no. 99967 ==> 0.41577230047357605\n",
            "Loss in iteration no. 99968 ==> 0.415771396234567\n",
            "Loss in iteration no. 99969 ==> 0.4157704920075634\n",
            "Loss in iteration no. 99970 ==> 0.4157695877925651\n",
            "Loss in iteration no. 99971 ==> 0.41576868358957186\n",
            "Loss in iteration no. 99972 ==> 0.4157677793985835\n",
            "Loss in iteration no. 99973 ==> 0.4157668752195998\n",
            "Loss in iteration no. 99974 ==> 0.41576597105262036\n",
            "Loss in iteration no. 99975 ==> 0.41576506689764525\n",
            "Loss in iteration no. 99976 ==> 0.415764162754674\n",
            "Loss in iteration no. 99977 ==> 0.41576325862370644\n",
            "Loss in iteration no. 99978 ==> 0.4157623545047424\n",
            "Loss in iteration no. 99979 ==> 0.4157614503977816\n",
            "Loss in iteration no. 99980 ==> 0.4157605463028239\n",
            "Loss in iteration no. 99981 ==> 0.41575964221986905\n",
            "Loss in iteration no. 99982 ==> 0.4157587381489167\n",
            "Loss in iteration no. 99983 ==> 0.4157578340899668\n",
            "Loss in iteration no. 99984 ==> 0.41575693004301895\n",
            "Loss in iteration no. 99985 ==> 0.41575602600807315\n",
            "Loss in iteration no. 99986 ==> 0.41575512198512893\n",
            "Loss in iteration no. 99987 ==> 0.41575421797418627\n",
            "Loss in iteration no. 99988 ==> 0.41575331397524484\n",
            "Loss in iteration no. 99989 ==> 0.41575240998830437\n",
            "Loss in iteration no. 99990 ==> 0.4157515060133647\n",
            "Loss in iteration no. 99991 ==> 0.4157506020504256\n",
            "Loss in iteration no. 99992 ==> 0.41574969809948686\n",
            "Loss in iteration no. 99993 ==> 0.41574879416054833\n",
            "Loss in iteration no. 99994 ==> 0.4157478902336096\n",
            "Loss in iteration no. 99995 ==> 0.41574698631867063\n",
            "Loss in iteration no. 99996 ==> 0.415746082415731\n",
            "Loss in iteration no. 99997 ==> 0.4157451785247906\n",
            "Loss in iteration no. 99998 ==> 0.41574427464584934\n",
            "Loss in iteration no. 99999 ==> 0.4157433707789068\n",
            "Loss in iteration no. 100000 ==> 0.41574246692396266\n",
            "Loss in iteration no. 100001 ==> 0.4157415630810169\n",
            "Loss in iteration no. 100002 ==> 0.41574065925006926\n",
            "Loss in iteration no. 100003 ==> 0.41573975543111963\n",
            "Loss in iteration no. 100004 ==> 0.41573885162416757\n",
            "Loss in iteration no. 100005 ==> 0.4157379478292128\n",
            "Loss in iteration no. 100006 ==> 0.41573704404625533\n",
            "Loss in iteration no. 100007 ==> 0.41573614027529493\n",
            "Loss in iteration no. 100008 ==> 0.41573523651633115\n",
            "Loss in iteration no. 100009 ==> 0.41573433276936395\n",
            "Loss in iteration no. 100010 ==> 0.4157334290343931\n",
            "Loss in iteration no. 100011 ==> 0.41573252531141824\n",
            "Loss in iteration no. 100012 ==> 0.4157316216004392\n",
            "Loss in iteration no. 100013 ==> 0.41573071790145594\n",
            "Loss in iteration no. 100014 ==> 0.415729814214468\n",
            "Loss in iteration no. 100015 ==> 0.41572891053947514\n",
            "Loss in iteration no. 100016 ==> 0.4157280068764774\n",
            "Loss in iteration no. 100017 ==> 0.41572710322547424\n",
            "Loss in iteration no. 100018 ==> 0.4157261995864658\n",
            "Loss in iteration no. 100019 ==> 0.4157252959594514\n",
            "Loss in iteration no. 100020 ==> 0.4157243923444312\n",
            "Loss in iteration no. 100021 ==> 0.41572348874140486\n",
            "Loss in iteration no. 100022 ==> 0.41572258515037197\n",
            "Loss in iteration no. 100023 ==> 0.41572168157133255\n",
            "Loss in iteration no. 100024 ==> 0.4157207780042863\n",
            "Loss in iteration no. 100025 ==> 0.4157198744492329\n",
            "Loss in iteration no. 100026 ==> 0.4157189709061723\n",
            "Loss in iteration no. 100027 ==> 0.4157180673751042\n",
            "Loss in iteration no. 100028 ==> 0.41571716385602825\n",
            "Loss in iteration no. 100029 ==> 0.41571626034894443\n",
            "Loss in iteration no. 100030 ==> 0.4157153568538524\n",
            "Loss in iteration no. 100031 ==> 0.41571445337075186\n",
            "Loss in iteration no. 100032 ==> 0.4157135498996428\n",
            "Loss in iteration no. 100033 ==> 0.41571264644052486\n",
            "Loss in iteration no. 100034 ==> 0.41571174299339786\n",
            "Loss in iteration no. 100035 ==> 0.41571083955826144\n",
            "Loss in iteration no. 100036 ==> 0.4157099361351156\n",
            "Loss in iteration no. 100037 ==> 0.4157090327239599\n",
            "Loss in iteration no. 100038 ==> 0.4157081293247943\n",
            "Loss in iteration no. 100039 ==> 0.41570722593761844\n",
            "Loss in iteration no. 100040 ==> 0.4157063225624321\n",
            "Loss in iteration no. 100041 ==> 0.41570541919923515\n",
            "Loss in iteration no. 100042 ==> 0.4157045158480274\n",
            "Loss in iteration no. 100043 ==> 0.41570361250880833\n",
            "Loss in iteration no. 100044 ==> 0.41570270918157814\n",
            "Loss in iteration no. 100045 ==> 0.4157018058663363\n",
            "Loss in iteration no. 100046 ==> 0.41570090256308256\n",
            "Loss in iteration no. 100047 ==> 0.41569999927181706\n",
            "Loss in iteration no. 100048 ==> 0.4156990959925392\n",
            "Loss in iteration no. 100049 ==> 0.41569819272524877\n",
            "Loss in iteration no. 100050 ==> 0.4156972894699458\n",
            "Loss in iteration no. 100051 ==> 0.41569638622662997\n",
            "Loss in iteration no. 100052 ==> 0.41569548299530096\n",
            "Loss in iteration no. 100053 ==> 0.4156945797759586\n",
            "Loss in iteration no. 100054 ==> 0.4156936765686026\n",
            "Loss in iteration no. 100055 ==> 0.4156927733732328\n",
            "Loss in iteration no. 100056 ==> 0.415691870189849\n",
            "Loss in iteration no. 100057 ==> 0.415690967018451\n",
            "Loss in iteration no. 100058 ==> 0.41569006385903845\n",
            "Loss in iteration no. 100059 ==> 0.4156891607116112\n",
            "Loss in iteration no. 100060 ==> 0.41568825757616906\n",
            "Loss in iteration no. 100061 ==> 0.4156873544527117\n",
            "Loss in iteration no. 100062 ==> 0.41568645134123905\n",
            "Loss in iteration no. 100063 ==> 0.41568554824175075\n",
            "Loss in iteration no. 100064 ==> 0.4156846451542467\n",
            "Loss in iteration no. 100065 ==> 0.4156837420787266\n",
            "Loss in iteration no. 100066 ==> 0.41568283901519015\n",
            "Loss in iteration no. 100067 ==> 0.4156819359636372\n",
            "Loss in iteration no. 100068 ==> 0.41568103292406766\n",
            "Loss in iteration no. 100069 ==> 0.41568012989648107\n",
            "Loss in iteration no. 100070 ==> 0.4156792268808773\n",
            "Loss in iteration no. 100071 ==> 0.41567832387725623\n",
            "Loss in iteration no. 100072 ==> 0.41567742088561743\n",
            "Loss in iteration no. 100073 ==> 0.41567651790596083\n",
            "Loss in iteration no. 100074 ==> 0.41567561493828625\n",
            "Loss in iteration no. 100075 ==> 0.41567471198259326\n",
            "Loss in iteration no. 100076 ==> 0.4156738090388818\n",
            "Loss in iteration no. 100077 ==> 0.4156729061071516\n",
            "Loss in iteration no. 100078 ==> 0.4156720031874024\n",
            "Loss in iteration no. 100079 ==> 0.4156711002796341\n",
            "Loss in iteration no. 100080 ==> 0.4156701973838463\n",
            "Loss in iteration no. 100081 ==> 0.4156692945000389\n",
            "Loss in iteration no. 100082 ==> 0.4156683916282116\n",
            "Loss in iteration no. 100083 ==> 0.41566748876836435\n",
            "Loss in iteration no. 100084 ==> 0.41566658592049666\n",
            "Loss in iteration no. 100085 ==> 0.41566568308460855\n",
            "Loss in iteration no. 100086 ==> 0.41566478026069964\n",
            "Loss in iteration no. 100087 ==> 0.41566387744876965\n",
            "Loss in iteration no. 100088 ==> 0.41566297464881846\n",
            "Loss in iteration no. 100089 ==> 0.4156620718608459\n",
            "Loss in iteration no. 100090 ==> 0.41566116908485173\n",
            "Loss in iteration no. 100091 ==> 0.4156602663208357\n",
            "Loss in iteration no. 100092 ==> 0.4156593635687975\n",
            "Loss in iteration no. 100093 ==> 0.415658460828737\n",
            "Loss in iteration no. 100094 ==> 0.4156575581006539\n",
            "Loss in iteration no. 100095 ==> 0.41565665538454805\n",
            "Loss in iteration no. 100096 ==> 0.41565575268041915\n",
            "Loss in iteration no. 100097 ==> 0.4156548499882671\n",
            "Loss in iteration no. 100098 ==> 0.41565394730809163\n",
            "Loss in iteration no. 100099 ==> 0.41565304463989244\n",
            "Loss in iteration no. 100100 ==> 0.41565214198366934\n"
          ]
        }
      ],
      "source": [
        "for i,loss in enumerate(model.model_loss):\n",
        "  print(f\"Loss in iteration no. {i+1} ==> {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNKp5RYaNqCt",
        "outputId": "cd40872c-6f90-44c7-e2eb-cf15f24d86a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the Logistic Regression Model ==> 81.16%\n",
            "Number of Correct Predictions ==> 56\n",
            "Number of Wrong Predictions ==> 13\n"
          ]
        }
      ],
      "source": [
        "# SET : 2\n",
        "\n",
        "weights_latest = None\n",
        "model = LogitRegression(learning_rate = 0.01, num_of_iter = 120000)\n",
        "\n",
        "y_train = y_train.squeeze()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "accuracy_vald = np.random.rand()\n",
        "\n",
        "if accuracy_vald > accuracy:\n",
        "  accuracy = accuracy_vald\n",
        "  weights_latest = {\n",
        "      \"weights\" : model.weights.tolist(),\n",
        "      \"bias\" : model.bias\n",
        "  }\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "y_test = y_test.squeeze()\n",
        "prediction_truth_values = (predictions == y_test).astype(int)\n",
        "accuracy = np.mean(prediction_truth_values) * 100\n",
        "\n",
        "print(f\"Accuracy of the Logistic Regression Model ==> {accuracy:.2f}%\")\n",
        "print(f\"Number of Correct Predictions ==> {round((accuracy/100) * 69)}\")\n",
        "print(f\"Number of Wrong Predictions ==> {round(69 - ((accuracy/100) * 69))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqJXIWdCOBFx",
        "outputId": "ad0f74b0-4855-4aab-fbf0-6eb83c7af075"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-8.463975884586507, -2.475206545636244, -0.12528160311836878, 4.853979943485019, 5.713296338673486, 3.481031856265465, 10.392594520052787]\n"
          ]
        }
      ],
      "source": [
        "print(model.weights.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "id": "8gYN6GAmOwM3",
        "outputId": "635c98c1-686f-482e-df2b-5e6e472933e0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "\n",
        "plt.plot(np.arange(model.num_of_iter), model.model_loss)\n",
        "\n",
        "plt.xlabel(\"No. of Iterations\")\n",
        "plt.ylabel(\"Loss Values\")\n",
        "\n",
        "plt.title(\"SET 2 : Loss values w.r.t. no. of iterations\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qmy_ICKwOyoJ",
        "outputId": "41f7b94a-9372-4015-8d95-b673f897b0df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Loss in iteration no. 48297 ==> 0.35044555179099884\n",
            "Loss in iteration no. 48298 ==> 0.3504444533984948\n",
            "Loss in iteration no. 48299 ==> 0.35044335504689095\n",
            "Loss in iteration no. 48300 ==> 0.35044225673618523\n",
            "Loss in iteration no. 48301 ==> 0.35044115846637564\n",
            "Loss in iteration no. 48302 ==> 0.3504400602374598\n",
            "Loss in iteration no. 48303 ==> 0.3504389620494359\n",
            "Loss in iteration no. 48304 ==> 0.3504378639023017\n",
            "Loss in iteration no. 48305 ==> 0.350436765796055\n",
            "Loss in iteration no. 48306 ==> 0.3504356677306937\n",
            "Loss in iteration no. 48307 ==> 0.3504345697062157\n",
            "Loss in iteration no. 48308 ==> 0.35043347172261907\n",
            "Loss in iteration no. 48309 ==> 0.3504323737799014\n",
            "Loss in iteration no. 48310 ==> 0.3504312758780607\n",
            "Loss in iteration no. 48311 ==> 0.35043017801709486\n",
            "Loss in iteration no. 48312 ==> 0.35042908019700175\n",
            "Loss in iteration no. 48313 ==> 0.3504279824177793\n",
            "Loss in iteration no. 48314 ==> 0.3504268846794253\n",
            "Loss in iteration no. 48315 ==> 0.35042578698193766\n",
            "Loss in iteration no. 48316 ==> 0.3504246893253143\n",
            "Loss in iteration no. 48317 ==> 0.350423591709553\n",
            "Loss in iteration no. 48318 ==> 0.35042249413465193\n",
            "Loss in iteration no. 48319 ==> 0.3504213966006085\n",
            "Loss in iteration no. 48320 ==> 0.35042029910742106\n",
            "Loss in iteration no. 48321 ==> 0.3504192016550872\n",
            "Loss in iteration no. 48322 ==> 0.350418104243605\n",
            "Loss in iteration no. 48323 ==> 0.35041700687297206\n",
            "Loss in iteration no. 48324 ==> 0.3504159095431865\n",
            "Loss in iteration no. 48325 ==> 0.35041481225424626\n",
            "Loss in iteration no. 48326 ==> 0.350413715006149\n",
            "Loss in iteration no. 48327 ==> 0.3504126177988928\n",
            "Loss in iteration no. 48328 ==> 0.3504115206324754\n",
            "Loss in iteration no. 48329 ==> 0.3504104235068948\n",
            "Loss in iteration no. 48330 ==> 0.3504093264221487\n",
            "Loss in iteration no. 48331 ==> 0.35040822937823524\n",
            "Loss in iteration no. 48332 ==> 0.35040713237515214\n",
            "Loss in iteration no. 48333 ==> 0.35040603541289733\n",
            "Loss in iteration no. 48334 ==> 0.35040493849146853\n",
            "Loss in iteration no. 48335 ==> 0.350403841610864\n",
            "Loss in iteration no. 48336 ==> 0.3504027447710813\n",
            "Loss in iteration no. 48337 ==> 0.3504016479721185\n",
            "Loss in iteration no. 48338 ==> 0.35040055121397334\n",
            "Loss in iteration no. 48339 ==> 0.3503994544966438\n",
            "Loss in iteration no. 48340 ==> 0.3503983578201277\n",
            "Loss in iteration no. 48341 ==> 0.350397261184423\n",
            "Loss in iteration no. 48342 ==> 0.3503961645895276\n",
            "Loss in iteration no. 48343 ==> 0.35039506803543924\n",
            "Loss in iteration no. 48344 ==> 0.350393971522156\n",
            "Loss in iteration no. 48345 ==> 0.35039287504967565\n",
            "Loss in iteration no. 48346 ==> 0.35039177861799603\n",
            "Loss in iteration no. 48347 ==> 0.35039068222711517\n",
            "Loss in iteration no. 48348 ==> 0.35038958587703084\n",
            "Loss in iteration no. 48349 ==> 0.35038848956774094\n",
            "Loss in iteration no. 48350 ==> 0.35038739329924345\n",
            "Loss in iteration no. 48351 ==> 0.3503862970715362\n",
            "Loss in iteration no. 48352 ==> 0.35038520088461705\n",
            "Loss in iteration no. 48353 ==> 0.3503841047384838\n",
            "Loss in iteration no. 48354 ==> 0.35038300863313454\n",
            "Loss in iteration no. 48355 ==> 0.3503819125685671\n",
            "Loss in iteration no. 48356 ==> 0.3503808165447793\n",
            "Loss in iteration no. 48357 ==> 0.35037972056176897\n",
            "Loss in iteration no. 48358 ==> 0.35037862461953423\n",
            "Loss in iteration no. 48359 ==> 0.35037752871807276\n",
            "Loss in iteration no. 48360 ==> 0.3503764328573825\n",
            "Loss in iteration no. 48361 ==> 0.35037533703746143\n",
            "Loss in iteration no. 48362 ==> 0.3503742412583073\n",
            "Loss in iteration no. 48363 ==> 0.3503731455199181\n",
            "Loss in iteration no. 48364 ==> 0.3503720498222917\n",
            "Loss in iteration no. 48365 ==> 0.35037095416542585\n",
            "Loss in iteration no. 48366 ==> 0.3503698585493186\n",
            "Loss in iteration no. 48367 ==> 0.35036876297396796\n",
            "Loss in iteration no. 48368 ==> 0.35036766743937153\n",
            "Loss in iteration no. 48369 ==> 0.3503665719455274\n",
            "Loss in iteration no. 48370 ==> 0.3503654764924333\n",
            "Loss in iteration no. 48371 ==> 0.3503643810800872\n",
            "Loss in iteration no. 48372 ==> 0.3503632857084872\n",
            "Loss in iteration no. 48373 ==> 0.3503621903776307\n",
            "Loss in iteration no. 48374 ==> 0.35036109508751606\n",
            "Loss in iteration no. 48375 ==> 0.35035999983814103\n",
            "Loss in iteration no. 48376 ==> 0.35035890462950336\n",
            "Loss in iteration no. 48377 ==> 0.35035780946160117\n",
            "Loss in iteration no. 48378 ==> 0.35035671433443205\n",
            "Loss in iteration no. 48379 ==> 0.3503556192479942\n",
            "Loss in iteration no. 48380 ==> 0.3503545242022853\n",
            "Loss in iteration no. 48381 ==> 0.35035342919730333\n",
            "Loss in iteration no. 48382 ==> 0.35035233423304624\n",
            "Loss in iteration no. 48383 ==> 0.3503512393095118\n",
            "Loss in iteration no. 48384 ==> 0.35035014442669804\n",
            "Loss in iteration no. 48385 ==> 0.35034904958460267\n",
            "Loss in iteration no. 48386 ==> 0.35034795478322367\n",
            "Loss in iteration no. 48387 ==> 0.35034686002255905\n",
            "Loss in iteration no. 48388 ==> 0.3503457653026066\n",
            "Loss in iteration no. 48389 ==> 0.35034467062336416\n",
            "Loss in iteration no. 48390 ==> 0.3503435759848296\n",
            "Loss in iteration no. 48391 ==> 0.35034248138700097\n",
            "Loss in iteration no. 48392 ==> 0.3503413868298761\n",
            "Loss in iteration no. 48393 ==> 0.3503402923134529\n",
            "Loss in iteration no. 48394 ==> 0.35033919783772915\n",
            "Loss in iteration no. 48395 ==> 0.35033810340270277\n",
            "Loss in iteration no. 48396 ==> 0.3503370090083717\n",
            "Loss in iteration no. 48397 ==> 0.350335914654734\n",
            "Loss in iteration no. 48398 ==> 0.3503348203417873\n",
            "Loss in iteration no. 48399 ==> 0.35033372606952956\n",
            "Loss in iteration no. 48400 ==> 0.35033263183795876\n",
            "Loss in iteration no. 48401 ==> 0.3503315376470728\n",
            "Loss in iteration no. 48402 ==> 0.3503304434968694\n",
            "Loss in iteration no. 48403 ==> 0.3503293493873466\n",
            "Loss in iteration no. 48404 ==> 0.3503282553185023\n",
            "Loss in iteration no. 48405 ==> 0.3503271612903344\n",
            "Loss in iteration no. 48406 ==> 0.3503260673028407\n",
            "Loss in iteration no. 48407 ==> 0.35032497335601914\n",
            "Loss in iteration no. 48408 ==> 0.35032387944986776\n",
            "Loss in iteration no. 48409 ==> 0.3503227855843843\n",
            "Loss in iteration no. 48410 ==> 0.3503216917595665\n",
            "Loss in iteration no. 48411 ==> 0.3503205979754126\n",
            "Loss in iteration no. 48412 ==> 0.35031950423192026\n",
            "Loss in iteration no. 48413 ==> 0.3503184105290876\n",
            "Loss in iteration no. 48414 ==> 0.3503173168669122\n",
            "Loss in iteration no. 48415 ==> 0.35031622324539224\n",
            "Loss in iteration no. 48416 ==> 0.35031512966452544\n",
            "Loss in iteration no. 48417 ==> 0.3503140361243097\n",
            "Loss in iteration no. 48418 ==> 0.35031294262474305\n",
            "Loss in iteration no. 48419 ==> 0.3503118491658233\n",
            "Loss in iteration no. 48420 ==> 0.35031075574754833\n",
            "Loss in iteration no. 48421 ==> 0.35030966236991606\n",
            "Loss in iteration no. 48422 ==> 0.35030856903292446\n",
            "Loss in iteration no. 48423 ==> 0.35030747573657134\n",
            "Loss in iteration no. 48424 ==> 0.3503063824808546\n",
            "Loss in iteration no. 48425 ==> 0.3503052892657721\n",
            "Loss in iteration no. 48426 ==> 0.3503041960913219\n",
            "Loss in iteration no. 48427 ==> 0.3503031029575018\n",
            "Loss in iteration no. 48428 ==> 0.3503020098643096\n",
            "Loss in iteration no. 48429 ==> 0.3503009168117433\n",
            "Loss in iteration no. 48430 ==> 0.35029982379980085\n",
            "Loss in iteration no. 48431 ==> 0.35029873082847995\n",
            "Loss in iteration no. 48432 ==> 0.35029763789777885\n",
            "Loss in iteration no. 48433 ==> 0.3502965450076951\n",
            "Loss in iteration no. 48434 ==> 0.3502954521582267\n",
            "Loss in iteration no. 48435 ==> 0.35029435934937164\n",
            "Loss in iteration no. 48436 ==> 0.3502932665811278\n",
            "Loss in iteration no. 48437 ==> 0.3502921738534929\n",
            "Loss in iteration no. 48438 ==> 0.35029108116646523\n",
            "Loss in iteration no. 48439 ==> 0.35028998852004223\n",
            "Loss in iteration no. 48440 ==> 0.35028889591422213\n",
            "Loss in iteration no. 48441 ==> 0.35028780334900267\n",
            "Loss in iteration no. 48442 ==> 0.3502867108243818\n",
            "Loss in iteration no. 48443 ==> 0.3502856183403573\n",
            "Loss in iteration no. 48444 ==> 0.3502845258969274\n",
            "Loss in iteration no. 48445 ==> 0.35028343349408964\n",
            "Loss in iteration no. 48446 ==> 0.35028234113184203\n",
            "Loss in iteration no. 48447 ==> 0.35028124881018263\n",
            "Loss in iteration no. 48448 ==> 0.35028015652910915\n",
            "Loss in iteration no. 48449 ==> 0.3502790642886196\n",
            "Loss in iteration no. 48450 ==> 0.3502779720887118\n",
            "Loss in iteration no. 48451 ==> 0.3502768799293837\n",
            "Loss in iteration no. 48452 ==> 0.35027578781063323\n",
            "Loss in iteration no. 48453 ==> 0.3502746957324582\n",
            "Loss in iteration no. 48454 ==> 0.35027360369485655\n",
            "Loss in iteration no. 48455 ==> 0.3502725116978263\n",
            "Loss in iteration no. 48456 ==> 0.3502714197413651\n",
            "Loss in iteration no. 48457 ==> 0.35027032782547113\n",
            "Loss in iteration no. 48458 ==> 0.3502692359501422\n",
            "Loss in iteration no. 48459 ==> 0.35026814411537605\n",
            "Loss in iteration no. 48460 ==> 0.35026705232117084\n",
            "Loss in iteration no. 48461 ==> 0.3502659605675243\n",
            "Loss in iteration no. 48462 ==> 0.3502648688544343\n",
            "Loss in iteration no. 48463 ==> 0.3502637771818988\n",
            "Loss in iteration no. 48464 ==> 0.35026268554991596\n",
            "Loss in iteration no. 48465 ==> 0.3502615939584834\n",
            "Loss in iteration no. 48466 ==> 0.35026050240759893\n",
            "Loss in iteration no. 48467 ==> 0.3502594108972606\n",
            "Loss in iteration no. 48468 ==> 0.3502583194274663\n",
            "Loss in iteration no. 48469 ==> 0.35025722799821407\n",
            "Loss in iteration no. 48470 ==> 0.3502561366095016\n",
            "Loss in iteration no. 48471 ==> 0.350255045261327\n",
            "Loss in iteration no. 48472 ==> 0.3502539539536879\n",
            "Loss in iteration no. 48473 ==> 0.35025286268658246\n",
            "Loss in iteration no. 48474 ==> 0.35025177146000847\n",
            "Loss in iteration no. 48475 ==> 0.3502506802739638\n",
            "Loss in iteration no. 48476 ==> 0.3502495891284464\n",
            "Loss in iteration no. 48477 ==> 0.3502484980234542\n",
            "Loss in iteration no. 48478 ==> 0.3502474069589852\n",
            "Loss in iteration no. 48479 ==> 0.3502463159350372\n",
            "Loss in iteration no. 48480 ==> 0.3502452249516079\n",
            "Loss in iteration no. 48481 ==> 0.35024413400869553\n",
            "Loss in iteration no. 48482 ==> 0.3502430431062979\n",
            "Loss in iteration no. 48483 ==> 0.35024195224441285\n",
            "Loss in iteration no. 48484 ==> 0.3502408614230383\n",
            "Loss in iteration no. 48485 ==> 0.3502397706421722\n",
            "Loss in iteration no. 48486 ==> 0.3502386799018125\n",
            "Loss in iteration no. 48487 ==> 0.35023758920195697\n",
            "Loss in iteration no. 48488 ==> 0.35023649854260364\n",
            "Loss in iteration no. 48489 ==> 0.35023540792375035\n",
            "Loss in iteration no. 48490 ==> 0.3502343173453949\n",
            "Loss in iteration no. 48491 ==> 0.3502332268075355\n",
            "Loss in iteration no. 48492 ==> 0.35023213631016975\n",
            "Loss in iteration no. 48493 ==> 0.35023104585329584\n",
            "Loss in iteration no. 48494 ==> 0.35022995543691143\n",
            "Loss in iteration no. 48495 ==> 0.3502288650610145\n",
            "Loss in iteration no. 48496 ==> 0.350227774725603\n",
            "Loss in iteration no. 48497 ==> 0.3502266844306748\n",
            "Loss in iteration no. 48498 ==> 0.3502255941762279\n",
            "Loss in iteration no. 48499 ==> 0.3502245039622601\n",
            "Loss in iteration no. 48500 ==> 0.3502234137887693\n",
            "Loss in iteration no. 48501 ==> 0.3502223236557535\n",
            "Loss in iteration no. 48502 ==> 0.35022123356321055\n",
            "Loss in iteration no. 48503 ==> 0.3502201435111384\n",
            "Loss in iteration no. 48504 ==> 0.3502190534995349\n",
            "Loss in iteration no. 48505 ==> 0.35021796352839796\n",
            "Loss in iteration no. 48506 ==> 0.35021687359772563\n",
            "Loss in iteration no. 48507 ==> 0.35021578370751555\n",
            "Loss in iteration no. 48508 ==> 0.3502146938577659\n",
            "Loss in iteration no. 48509 ==> 0.35021360404847446\n",
            "Loss in iteration no. 48510 ==> 0.35021251427963906\n",
            "Loss in iteration no. 48511 ==> 0.35021142455125776\n",
            "Loss in iteration no. 48512 ==> 0.3502103348633285\n",
            "Loss in iteration no. 48513 ==> 0.35020924521584895\n",
            "Loss in iteration no. 48514 ==> 0.35020815560881735\n",
            "Loss in iteration no. 48515 ==> 0.3502070660422314\n",
            "Loss in iteration no. 48516 ==> 0.350205976516089\n",
            "Loss in iteration no. 48517 ==> 0.35020488703038805\n",
            "Loss in iteration no. 48518 ==> 0.35020379758512654\n",
            "Loss in iteration no. 48519 ==> 0.3502027081803024\n",
            "Loss in iteration no. 48520 ==> 0.3502016188159136\n",
            "Loss in iteration no. 48521 ==> 0.3502005294919579\n",
            "Loss in iteration no. 48522 ==> 0.35019944020843313\n",
            "Loss in iteration no. 48523 ==> 0.3501983509653375\n",
            "Loss in iteration no. 48524 ==> 0.35019726176266863\n",
            "Loss in iteration no. 48525 ==> 0.3501961726004246\n",
            "Loss in iteration no. 48526 ==> 0.35019508347860345\n",
            "Loss in iteration no. 48527 ==> 0.3501939943972028\n",
            "Loss in iteration no. 48528 ==> 0.35019290535622066\n",
            "Loss in iteration no. 48529 ==> 0.350191816355655\n",
            "Loss in iteration no. 48530 ==> 0.35019072739550366\n",
            "Loss in iteration no. 48531 ==> 0.3501896384757646\n",
            "Loss in iteration no. 48532 ==> 0.3501885495964358\n",
            "Loss in iteration no. 48533 ==> 0.3501874607575151\n",
            "Loss in iteration no. 48534 ==> 0.3501863719590003\n",
            "Loss in iteration no. 48535 ==> 0.3501852832008897\n",
            "Loss in iteration no. 48536 ==> 0.35018419448318067\n",
            "Loss in iteration no. 48537 ==> 0.3501831058058715\n",
            "Loss in iteration no. 48538 ==> 0.35018201716895997\n",
            "Loss in iteration no. 48539 ==> 0.35018092857244404\n",
            "Loss in iteration no. 48540 ==> 0.3501798400163216\n",
            "Loss in iteration no. 48541 ==> 0.35017875150059063\n",
            "Loss in iteration no. 48542 ==> 0.35017766302524894\n",
            "Loss in iteration no. 48543 ==> 0.35017657459029444\n",
            "Loss in iteration no. 48544 ==> 0.35017548619572514\n",
            "Loss in iteration no. 48545 ==> 0.35017439784153903\n",
            "Loss in iteration no. 48546 ==> 0.35017330952773373\n",
            "Loss in iteration no. 48547 ==> 0.35017222125430747\n",
            "Loss in iteration no. 48548 ==> 0.35017113302125796\n",
            "Loss in iteration no. 48549 ==> 0.35017004482858316\n",
            "Loss in iteration no. 48550 ==> 0.350168956676281\n",
            "Loss in iteration no. 48551 ==> 0.35016786856434945\n",
            "Loss in iteration no. 48552 ==> 0.35016678049278643\n",
            "Loss in iteration no. 48553 ==> 0.35016569246158974\n",
            "Loss in iteration no. 48554 ==> 0.3501646044707573\n",
            "Loss in iteration no. 48555 ==> 0.35016351652028715\n",
            "Loss in iteration no. 48556 ==> 0.35016242861017716\n",
            "Loss in iteration no. 48557 ==> 0.3501613407404252\n",
            "Loss in iteration no. 48558 ==> 0.3501602529110292\n",
            "Loss in iteration no. 48559 ==> 0.35015916512198725\n",
            "Loss in iteration no. 48560 ==> 0.35015807737329696\n",
            "Loss in iteration no. 48561 ==> 0.3501569896649565\n",
            "Loss in iteration no. 48562 ==> 0.3501559019969635\n",
            "Loss in iteration no. 48563 ==> 0.3501548143693162\n",
            "Loss in iteration no. 48564 ==> 0.3501537267820124\n",
            "Loss in iteration no. 48565 ==> 0.3501526392350499\n",
            "Loss in iteration no. 48566 ==> 0.35015155172842677\n",
            "Loss in iteration no. 48567 ==> 0.3501504642621409\n",
            "Loss in iteration no. 48568 ==> 0.3501493768361902\n",
            "Loss in iteration no. 48569 ==> 0.3501482894505725\n",
            "Loss in iteration no. 48570 ==> 0.3501472021052858\n",
            "Loss in iteration no. 48571 ==> 0.35014611480032803\n",
            "Loss in iteration no. 48572 ==> 0.35014502753569715\n",
            "Loss in iteration no. 48573 ==> 0.3501439403113909\n",
            "Loss in iteration no. 48574 ==> 0.35014285312740734\n",
            "Loss in iteration no. 48575 ==> 0.3501417659837444\n",
            "Loss in iteration no. 48576 ==> 0.35014067888039996\n",
            "Loss in iteration no. 48577 ==> 0.3501395918173719\n",
            "Loss in iteration no. 48578 ==> 0.35013850479465813\n",
            "Loss in iteration no. 48579 ==> 0.35013741781225677\n",
            "Loss in iteration no. 48580 ==> 0.35013633087016555\n",
            "Loss in iteration no. 48581 ==> 0.35013524396838236\n",
            "Loss in iteration no. 48582 ==> 0.3501341571069051\n",
            "Loss in iteration no. 48583 ==> 0.350133070285732\n",
            "Loss in iteration no. 48584 ==> 0.3501319835048606\n",
            "Loss in iteration no. 48585 ==> 0.35013089676428905\n",
            "Loss in iteration no. 48586 ==> 0.35012981006401517\n",
            "Loss in iteration no. 48587 ==> 0.350128723404037\n",
            "Loss in iteration no. 48588 ==> 0.3501276367843522\n",
            "Loss in iteration no. 48589 ==> 0.350126550204959\n",
            "Loss in iteration no. 48590 ==> 0.3501254636658552\n",
            "Loss in iteration no. 48591 ==> 0.35012437716703865\n",
            "Loss in iteration no. 48592 ==> 0.35012329070850734\n",
            "Loss in iteration no. 48593 ==> 0.3501222042902592\n",
            "Loss in iteration no. 48594 ==> 0.35012111791229206\n",
            "Loss in iteration no. 48595 ==> 0.3501200315746039\n",
            "Loss in iteration no. 48596 ==> 0.35011894527719273\n",
            "Loss in iteration no. 48597 ==> 0.3501178590200563\n",
            "Loss in iteration no. 48598 ==> 0.35011677280319276\n",
            "Loss in iteration no. 48599 ==> 0.3501156866265998\n",
            "Loss in iteration no. 48600 ==> 0.35011460049027554\n",
            "Loss in iteration no. 48601 ==> 0.3501135143942178\n",
            "Loss in iteration no. 48602 ==> 0.3501124283384243\n",
            "Loss in iteration no. 48603 ==> 0.3501113423228934\n",
            "Loss in iteration no. 48604 ==> 0.3501102563476227\n",
            "Loss in iteration no. 48605 ==> 0.35010917041261025\n",
            "Loss in iteration no. 48606 ==> 0.3501080845178539\n",
            "Loss in iteration no. 48607 ==> 0.3501069986633517\n",
            "Loss in iteration no. 48608 ==> 0.35010591284910136\n",
            "Loss in iteration no. 48609 ==> 0.35010482707510104\n",
            "Loss in iteration no. 48610 ==> 0.3501037413413485\n",
            "Loss in iteration no. 48611 ==> 0.3501026556478417\n",
            "Loss in iteration no. 48612 ==> 0.3501015699945787\n",
            "Loss in iteration no. 48613 ==> 0.3501004843815572\n",
            "Loss in iteration no. 48614 ==> 0.3500993988087753\n",
            "Loss in iteration no. 48615 ==> 0.3500983132762308\n",
            "Loss in iteration no. 48616 ==> 0.3500972277839217\n",
            "Loss in iteration no. 48617 ==> 0.35009614233184594\n",
            "Loss in iteration no. 48618 ==> 0.3500950569200013\n",
            "Loss in iteration no. 48619 ==> 0.35009397154838595\n",
            "Loss in iteration no. 48620 ==> 0.35009288621699763\n",
            "Loss in iteration no. 48621 ==> 0.35009180092583436\n",
            "Loss in iteration no. 48622 ==> 0.350090715674894\n",
            "Loss in iteration no. 48623 ==> 0.35008963046417446\n",
            "Loss in iteration no. 48624 ==> 0.3500885452936738\n",
            "Loss in iteration no. 48625 ==> 0.35008746016338976\n",
            "Loss in iteration no. 48626 ==> 0.35008637507332035\n",
            "Loss in iteration no. 48627 ==> 0.35008529002346356\n",
            "Loss in iteration no. 48628 ==> 0.35008420501381726\n",
            "Loss in iteration no. 48629 ==> 0.35008312004437925\n",
            "Loss in iteration no. 48630 ==> 0.3500820351151477\n",
            "Loss in iteration no. 48631 ==> 0.3500809502261204\n",
            "Loss in iteration no. 48632 ==> 0.35007986537729535\n",
            "Loss in iteration no. 48633 ==> 0.3500787805686704\n",
            "Loss in iteration no. 48634 ==> 0.35007769580024345\n",
            "Loss in iteration no. 48635 ==> 0.35007661107201254\n",
            "Loss in iteration no. 48636 ==> 0.3500755263839754\n",
            "Loss in iteration no. 48637 ==> 0.3500744417361302\n",
            "Loss in iteration no. 48638 ==> 0.3500733571284748\n",
            "Loss in iteration no. 48639 ==> 0.35007227256100704\n",
            "Loss in iteration no. 48640 ==> 0.3500711880337249\n",
            "Loss in iteration no. 48641 ==> 0.3500701035466263\n",
            "Loss in iteration no. 48642 ==> 0.3500690190997093\n",
            "Loss in iteration no. 48643 ==> 0.35006793469297154\n",
            "Loss in iteration no. 48644 ==> 0.3500668503264111\n",
            "Loss in iteration no. 48645 ==> 0.350065766000026\n",
            "Loss in iteration no. 48646 ==> 0.35006468171381416\n",
            "Loss in iteration no. 48647 ==> 0.3500635974677733\n",
            "Loss in iteration no. 48648 ==> 0.3500625132619016\n",
            "Loss in iteration no. 48649 ==> 0.35006142909619675\n",
            "Loss in iteration no. 48650 ==> 0.35006034497065686\n",
            "Loss in iteration no. 48651 ==> 0.3500592608852798\n",
            "Loss in iteration no. 48652 ==> 0.3500581768400636\n",
            "Loss in iteration no. 48653 ==> 0.35005709283500597\n",
            "Loss in iteration no. 48654 ==> 0.350056008870105\n",
            "Loss in iteration no. 48655 ==> 0.3500549249453586\n",
            "Loss in iteration no. 48656 ==> 0.3500538410607647\n",
            "Loss in iteration no. 48657 ==> 0.35005275721632123\n",
            "Loss in iteration no. 48658 ==> 0.3500516734120261\n",
            "Loss in iteration no. 48659 ==> 0.35005058964787716\n",
            "Loss in iteration no. 48660 ==> 0.3500495059238725\n",
            "Loss in iteration no. 48661 ==> 0.35004842224001004\n",
            "Loss in iteration no. 48662 ==> 0.3500473385962876\n",
            "Loss in iteration no. 48663 ==> 0.35004625499270314\n",
            "Loss in iteration no. 48664 ==> 0.3500451714292547\n",
            "Loss in iteration no. 48665 ==> 0.35004408790593994\n",
            "Loss in iteration no. 48666 ==> 0.35004300442275715\n",
            "Loss in iteration no. 48667 ==> 0.350041920979704\n",
            "Loss in iteration no. 48668 ==> 0.35004083757677856\n",
            "Loss in iteration no. 48669 ==> 0.3500397542139787\n",
            "Loss in iteration no. 48670 ==> 0.35003867089130236\n",
            "Loss in iteration no. 48671 ==> 0.3500375876087475\n",
            "Loss in iteration no. 48672 ==> 0.3500365043663119\n",
            "Loss in iteration no. 48673 ==> 0.3500354211639939\n",
            "Loss in iteration no. 48674 ==> 0.35003433800179085\n",
            "Loss in iteration no. 48675 ==> 0.35003325487970116\n",
            "Loss in iteration no. 48676 ==> 0.35003217179772256\n",
            "Loss in iteration no. 48677 ==> 0.3500310887558529\n",
            "Loss in iteration no. 48678 ==> 0.3500300057540904\n",
            "Loss in iteration no. 48679 ==> 0.35002892279243275\n",
            "Loss in iteration no. 48680 ==> 0.350027839870878\n",
            "Loss in iteration no. 48681 ==> 0.3500267569894239\n",
            "Loss in iteration no. 48682 ==> 0.3500256741480687\n",
            "Loss in iteration no. 48683 ==> 0.3500245913468101\n",
            "Loss in iteration no. 48684 ==> 0.35002350858564607\n",
            "Loss in iteration no. 48685 ==> 0.3500224258645745\n",
            "Loss in iteration no. 48686 ==> 0.35002134318359357\n",
            "Loss in iteration no. 48687 ==> 0.3500202605427009\n",
            "Loss in iteration no. 48688 ==> 0.3500191779418946\n",
            "Loss in iteration no. 48689 ==> 0.3500180953811725\n",
            "Loss in iteration no. 48690 ==> 0.35001701286053266\n",
            "Loss in iteration no. 48691 ==> 0.3500159303799729\n",
            "Loss in iteration no. 48692 ==> 0.3500148479394913\n",
            "Loss in iteration no. 48693 ==> 0.35001376553908564\n",
            "Loss in iteration no. 48694 ==> 0.350012683178754\n",
            "Loss in iteration no. 48695 ==> 0.3500116008584942\n",
            "Loss in iteration no. 48696 ==> 0.3500105185783041\n",
            "Loss in iteration no. 48697 ==> 0.35000943633818193\n",
            "Loss in iteration no. 48698 ==> 0.3500083541381253\n",
            "Loss in iteration no. 48699 ==> 0.3500072719781323\n",
            "Loss in iteration no. 48700 ==> 0.350006189858201\n",
            "Loss in iteration no. 48701 ==> 0.35000510777832905\n",
            "Loss in iteration no. 48702 ==> 0.3500040257385146\n",
            "Loss in iteration no. 48703 ==> 0.3500029437387555\n",
            "Loss in iteration no. 48704 ==> 0.35000186177904963\n",
            "Loss in iteration no. 48705 ==> 0.3500007798593951\n",
            "Loss in iteration no. 48706 ==> 0.3499996979797897\n",
            "Loss in iteration no. 48707 ==> 0.3499986161402314\n",
            "Loss in iteration no. 48708 ==> 0.3499975343407183\n",
            "Loss in iteration no. 48709 ==> 0.34999645258124806\n",
            "Loss in iteration no. 48710 ==> 0.3499953708618188\n",
            "Loss in iteration no. 48711 ==> 0.3499942891824283\n",
            "Loss in iteration no. 48712 ==> 0.34999320754307467\n",
            "Loss in iteration no. 48713 ==> 0.34999212594375584\n",
            "Loss in iteration no. 48714 ==> 0.3499910443844696\n",
            "Loss in iteration no. 48715 ==> 0.34998996286521405\n",
            "Loss in iteration no. 48716 ==> 0.349988881385987\n",
            "Loss in iteration no. 48717 ==> 0.34998779994678647\n",
            "Loss in iteration no. 48718 ==> 0.34998671854761043\n",
            "Loss in iteration no. 48719 ==> 0.3499856371884567\n",
            "Loss in iteration no. 48720 ==> 0.3499845558693233\n",
            "Loss in iteration no. 48721 ==> 0.3499834745902082\n",
            "Loss in iteration no. 48722 ==> 0.34998239335110926\n",
            "Loss in iteration no. 48723 ==> 0.3499813121520244\n",
            "Loss in iteration no. 48724 ==> 0.34998023099295167\n",
            "Loss in iteration no. 48725 ==> 0.349979149873889\n",
            "Loss in iteration no. 48726 ==> 0.34997806879483423\n",
            "Loss in iteration no. 48727 ==> 0.34997698775578523\n",
            "Loss in iteration no. 48728 ==> 0.34997590675674023\n",
            "Loss in iteration no. 48729 ==> 0.34997482579769695\n",
            "Loss in iteration no. 48730 ==> 0.34997374487865346\n",
            "Loss in iteration no. 48731 ==> 0.3499726639996075\n",
            "Loss in iteration no. 48732 ==> 0.3499715831605572\n",
            "Loss in iteration no. 48733 ==> 0.34997050236150035\n",
            "Loss in iteration no. 48734 ==> 0.3499694216024351\n",
            "Loss in iteration no. 48735 ==> 0.34996834088335926\n",
            "Loss in iteration no. 48736 ==> 0.3499672602042707\n",
            "Loss in iteration no. 48737 ==> 0.3499661795651675\n",
            "Loss in iteration no. 48738 ==> 0.34996509896604755\n",
            "Loss in iteration no. 48739 ==> 0.3499640184069087\n",
            "Loss in iteration no. 48740 ==> 0.349962937887749\n",
            "Loss in iteration no. 48741 ==> 0.3499618574085665\n",
            "Loss in iteration no. 48742 ==> 0.3499607769693589\n",
            "Loss in iteration no. 48743 ==> 0.34995969657012427\n",
            "Loss in iteration no. 48744 ==> 0.34995861621086055\n",
            "Loss in iteration no. 48745 ==> 0.34995753589156564\n",
            "Loss in iteration no. 48746 ==> 0.34995645561223754\n",
            "Loss in iteration no. 48747 ==> 0.3499553753728742\n",
            "Loss in iteration no. 48748 ==> 0.34995429517347343\n",
            "Loss in iteration no. 48749 ==> 0.3499532150140333\n",
            "Loss in iteration no. 48750 ==> 0.3499521348945518\n",
            "Loss in iteration no. 48751 ==> 0.3499510548150267\n",
            "Loss in iteration no. 48752 ==> 0.34994997477545614\n",
            "Loss in iteration no. 48753 ==> 0.34994889477583785\n",
            "Loss in iteration no. 48754 ==> 0.34994781481617\n",
            "Loss in iteration no. 48755 ==> 0.3499467348964504\n",
            "Loss in iteration no. 48756 ==> 0.34994565501667696\n",
            "Loss in iteration no. 48757 ==> 0.34994457517684774\n",
            "Loss in iteration no. 48758 ==> 0.3499434953769605\n",
            "Loss in iteration no. 48759 ==> 0.3499424156170135\n",
            "Loss in iteration no. 48760 ==> 0.3499413358970044\n",
            "Loss in iteration no. 48761 ==> 0.3499402562169312\n",
            "Loss in iteration no. 48762 ==> 0.3499391765767919\n",
            "Loss in iteration no. 48763 ==> 0.34993809697658446\n",
            "Loss in iteration no. 48764 ==> 0.34993701741630684\n",
            "Loss in iteration no. 48765 ==> 0.34993593789595684\n",
            "Loss in iteration no. 48766 ==> 0.3499348584155325\n",
            "Loss in iteration no. 48767 ==> 0.3499337789750319\n",
            "Loss in iteration no. 48768 ==> 0.3499326995744527\n",
            "Loss in iteration no. 48769 ==> 0.3499316202137931\n",
            "Loss in iteration no. 48770 ==> 0.34993054089305103\n",
            "Loss in iteration no. 48771 ==> 0.3499294616122242\n",
            "Loss in iteration no. 48772 ==> 0.3499283823713108\n",
            "Loss in iteration no. 48773 ==> 0.3499273031703087\n",
            "Loss in iteration no. 48774 ==> 0.3499262240092157\n",
            "Loss in iteration no. 48775 ==> 0.34992514488803\n",
            "Loss in iteration no. 48776 ==> 0.34992406580674945\n",
            "Loss in iteration no. 48777 ==> 0.34992298676537187\n",
            "Loss in iteration no. 48778 ==> 0.3499219077638954\n",
            "Loss in iteration no. 48779 ==> 0.34992082880231784\n",
            "Loss in iteration no. 48780 ==> 0.34991974988063734\n",
            "Loss in iteration no. 48781 ==> 0.3499186709988515\n",
            "Loss in iteration no. 48782 ==> 0.34991759215695856\n",
            "Loss in iteration no. 48783 ==> 0.34991651335495644\n",
            "Loss in iteration no. 48784 ==> 0.34991543459284297\n",
            "Loss in iteration no. 48785 ==> 0.34991435587061614\n",
            "Loss in iteration no. 48786 ==> 0.349913277188274\n",
            "Loss in iteration no. 48787 ==> 0.3499121985458143\n",
            "Loss in iteration no. 48788 ==> 0.34991111994323515\n",
            "Loss in iteration no. 48789 ==> 0.3499100413805345\n",
            "Loss in iteration no. 48790 ==> 0.34990896285771017\n",
            "Loss in iteration no. 48791 ==> 0.3499078843747602\n",
            "Loss in iteration no. 48792 ==> 0.34990680593168255\n",
            "Loss in iteration no. 48793 ==> 0.34990572752847515\n",
            "Loss in iteration no. 48794 ==> 0.349904649165136\n",
            "Loss in iteration no. 48795 ==> 0.34990357084166296\n",
            "Loss in iteration no. 48796 ==> 0.34990249255805395\n",
            "Loss in iteration no. 48797 ==> 0.349901414314307\n",
            "Loss in iteration no. 48798 ==> 0.3499003361104201\n",
            "Loss in iteration no. 48799 ==> 0.34989925794639115\n",
            "Loss in iteration no. 48800 ==> 0.349898179822218\n",
            "Loss in iteration no. 48801 ==> 0.34989710173789884\n",
            "Loss in iteration no. 48802 ==> 0.3498960236934314\n",
            "Loss in iteration no. 48803 ==> 0.34989494568881363\n",
            "Loss in iteration no. 48804 ==> 0.34989386772404363\n",
            "Loss in iteration no. 48805 ==> 0.3498927897991193\n",
            "Loss in iteration no. 48806 ==> 0.34989171191403856\n",
            "Loss in iteration no. 48807 ==> 0.3498906340687994\n",
            "Loss in iteration no. 48808 ==> 0.34988955626339974\n",
            "Loss in iteration no. 48809 ==> 0.34988847849783744\n",
            "Loss in iteration no. 48810 ==> 0.3498874007721106\n",
            "Loss in iteration no. 48811 ==> 0.3498863230862171\n",
            "Loss in iteration no. 48812 ==> 0.349885245440155\n",
            "Loss in iteration no. 48813 ==> 0.34988416783392196\n",
            "Loss in iteration no. 48814 ==> 0.3498830902675163\n",
            "Loss in iteration no. 48815 ==> 0.34988201274093583\n",
            "Loss in iteration no. 48816 ==> 0.34988093525417835\n",
            "Loss in iteration no. 48817 ==> 0.34987985780724196\n",
            "Loss in iteration no. 48818 ==> 0.34987878040012466\n",
            "Loss in iteration no. 48819 ==> 0.3498777030328243\n",
            "Loss in iteration no. 48820 ==> 0.34987662570533884\n",
            "Loss in iteration no. 48821 ==> 0.3498755484176663\n",
            "Loss in iteration no. 48822 ==> 0.3498744711698045\n",
            "Loss in iteration no. 48823 ==> 0.34987339396175166\n",
            "Loss in iteration no. 48824 ==> 0.34987231679350544\n",
            "Loss in iteration no. 48825 ==> 0.34987123966506395\n",
            "Loss in iteration no. 48826 ==> 0.34987016257642517\n",
            "Loss in iteration no. 48827 ==> 0.3498690855275869\n",
            "Loss in iteration no. 48828 ==> 0.3498680085185472\n",
            "Loss in iteration no. 48829 ==> 0.34986693154930404\n",
            "Loss in iteration no. 48830 ==> 0.34986585461985537\n",
            "Loss in iteration no. 48831 ==> 0.34986477773019903\n",
            "Loss in iteration no. 48832 ==> 0.34986370088033314\n",
            "Loss in iteration no. 48833 ==> 0.34986262407025553\n",
            "Loss in iteration no. 48834 ==> 0.3498615472999642\n",
            "Loss in iteration no. 48835 ==> 0.3498604705694571\n",
            "Loss in iteration no. 48836 ==> 0.34985939387873227\n",
            "Loss in iteration no. 48837 ==> 0.3498583172277875\n",
            "Loss in iteration no. 48838 ==> 0.34985724061662093\n",
            "Loss in iteration no. 48839 ==> 0.3498561640452303\n",
            "Loss in iteration no. 48840 ==> 0.34985508751361377\n",
            "Loss in iteration no. 48841 ==> 0.34985401102176916\n",
            "Loss in iteration no. 48842 ==> 0.3498529345696945\n",
            "Loss in iteration no. 48843 ==> 0.3498518581573878\n",
            "Loss in iteration no. 48844 ==> 0.3498507817848469\n",
            "Loss in iteration no. 48845 ==> 0.3498497054520697\n",
            "Loss in iteration no. 48846 ==> 0.3498486291590543\n",
            "Loss in iteration no. 48847 ==> 0.34984755290579866\n",
            "Loss in iteration no. 48848 ==> 0.3498464766923007\n",
            "Loss in iteration no. 48849 ==> 0.3498454005185583\n",
            "Loss in iteration no. 48850 ==> 0.34984432438456947\n",
            "Loss in iteration no. 48851 ==> 0.3498432482903322\n",
            "Loss in iteration no. 48852 ==> 0.34984217223584435\n",
            "Loss in iteration no. 48853 ==> 0.3498410962211041\n",
            "Loss in iteration no. 48854 ==> 0.34984002024610916\n",
            "Loss in iteration no. 48855 ==> 0.3498389443108576\n",
            "Loss in iteration no. 48856 ==> 0.34983786841534736\n",
            "Loss in iteration no. 48857 ==> 0.34983679255957645\n",
            "Loss in iteration no. 48858 ==> 0.3498357167435427\n",
            "Loss in iteration no. 48859 ==> 0.3498346409672442\n",
            "Loss in iteration no. 48860 ==> 0.3498335652306789\n",
            "Loss in iteration no. 48861 ==> 0.3498324895338446\n",
            "Loss in iteration no. 48862 ==> 0.3498314138767395\n",
            "Loss in iteration no. 48863 ==> 0.34983033825936133\n",
            "Loss in iteration no. 48864 ==> 0.3498292626817083\n",
            "Loss in iteration no. 48865 ==> 0.3498281871437781\n",
            "Loss in iteration no. 48866 ==> 0.3498271116455688\n",
            "Loss in iteration no. 48867 ==> 0.34982603618707836\n",
            "Loss in iteration no. 48868 ==> 0.34982496076830477\n",
            "Loss in iteration no. 48869 ==> 0.349823885389246\n",
            "Loss in iteration no. 48870 ==> 0.3498228100499\n",
            "Loss in iteration no. 48871 ==> 0.3498217347502647\n",
            "Loss in iteration no. 48872 ==> 0.349820659490338\n",
            "Loss in iteration no. 48873 ==> 0.349819584270118\n",
            "Loss in iteration no. 48874 ==> 0.3498185090896026\n",
            "Loss in iteration no. 48875 ==> 0.3498174339487896\n",
            "Loss in iteration no. 48876 ==> 0.3498163588476773\n",
            "Loss in iteration no. 48877 ==> 0.34981528378626336\n",
            "Loss in iteration no. 48878 ==> 0.3498142087645459\n",
            "Loss in iteration no. 48879 ==> 0.3498131337825228\n",
            "Loss in iteration no. 48880 ==> 0.3498120588401921\n",
            "Loss in iteration no. 48881 ==> 0.3498109839375517\n",
            "Loss in iteration no. 48882 ==> 0.3498099090745995\n",
            "Loss in iteration no. 48883 ==> 0.3498088342513337\n",
            "Loss in iteration no. 48884 ==> 0.34980775946775194\n",
            "Loss in iteration no. 48885 ==> 0.34980668472385246\n",
            "Loss in iteration no. 48886 ==> 0.349805610019633\n",
            "Loss in iteration no. 48887 ==> 0.3498045353550917\n",
            "Loss in iteration no. 48888 ==> 0.3498034607302263\n",
            "Loss in iteration no. 48889 ==> 0.3498023861450351\n",
            "Loss in iteration no. 48890 ==> 0.3498013115995158\n",
            "Loss in iteration no. 48891 ==> 0.3498002370936665\n",
            "Loss in iteration no. 48892 ==> 0.34979916262748495\n",
            "Loss in iteration no. 48893 ==> 0.3497980882009694\n",
            "Loss in iteration no. 48894 ==> 0.3497970138141176\n",
            "Loss in iteration no. 48895 ==> 0.34979593946692755\n",
            "Loss in iteration no. 48896 ==> 0.3497948651593974\n",
            "Loss in iteration no. 48897 ==> 0.34979379089152485\n",
            "Loss in iteration no. 48898 ==> 0.349792716663308\n",
            "Loss in iteration no. 48899 ==> 0.3497916424747447\n",
            "Loss in iteration no. 48900 ==> 0.34979056832583316\n",
            "Loss in iteration no. 48901 ==> 0.34978949421657113\n",
            "Loss in iteration no. 48902 ==> 0.34978842014695666\n",
            "Loss in iteration no. 48903 ==> 0.3497873461169877\n",
            "Loss in iteration no. 48904 ==> 0.3497862721266621\n",
            "Loss in iteration no. 48905 ==> 0.349785198175978\n",
            "Loss in iteration no. 48906 ==> 0.34978412426493327\n",
            "Loss in iteration no. 48907 ==> 0.3497830503935259\n",
            "Loss in iteration no. 48908 ==> 0.3497819765617538\n",
            "Loss in iteration no. 48909 ==> 0.34978090276961504\n",
            "Loss in iteration no. 48910 ==> 0.3497798290171076\n",
            "Loss in iteration no. 48911 ==> 0.3497787553042292\n",
            "Loss in iteration no. 48912 ==> 0.34977768163097817\n",
            "Loss in iteration no. 48913 ==> 0.3497766079973521\n",
            "Loss in iteration no. 48914 ==> 0.34977553440334935\n",
            "Loss in iteration no. 48915 ==> 0.34977446084896757\n",
            "Loss in iteration no. 48916 ==> 0.3497733873342049\n",
            "Loss in iteration no. 48917 ==> 0.3497723138590591\n",
            "Loss in iteration no. 48918 ==> 0.34977124042352836\n",
            "Loss in iteration no. 48919 ==> 0.34977016702761066\n",
            "Loss in iteration no. 48920 ==> 0.3497690936713037\n",
            "Loss in iteration no. 48921 ==> 0.34976802035460564\n",
            "Loss in iteration no. 48922 ==> 0.3497669470775145\n",
            "Loss in iteration no. 48923 ==> 0.34976587384002816\n",
            "Loss in iteration no. 48924 ==> 0.34976480064214455\n",
            "Loss in iteration no. 48925 ==> 0.3497637274838617\n",
            "Loss in iteration no. 48926 ==> 0.3497626543651776\n",
            "Loss in iteration no. 48927 ==> 0.34976158128609025\n",
            "Loss in iteration no. 48928 ==> 0.3497605082465974\n",
            "Loss in iteration no. 48929 ==> 0.3497594352466973\n",
            "Loss in iteration no. 48930 ==> 0.3497583622863876\n",
            "Loss in iteration no. 48931 ==> 0.34975728936566663\n",
            "Loss in iteration no. 48932 ==> 0.3497562164845321\n",
            "Loss in iteration no. 48933 ==> 0.3497551436429821\n",
            "Loss in iteration no. 48934 ==> 0.3497540708410145\n",
            "Loss in iteration no. 48935 ==> 0.34975299807862736\n",
            "Loss in iteration no. 48936 ==> 0.34975192535581856\n",
            "Loss in iteration no. 48937 ==> 0.3497508526725862\n",
            "Loss in iteration no. 48938 ==> 0.3497497800289282\n",
            "Loss in iteration no. 48939 ==> 0.34974870742484243\n",
            "Loss in iteration no. 48940 ==> 0.349747634860327\n",
            "Loss in iteration no. 48941 ==> 0.3497465623353797\n",
            "Loss in iteration no. 48942 ==> 0.34974548984999865\n",
            "Loss in iteration no. 48943 ==> 0.3497444174041818\n",
            "Loss in iteration no. 48944 ==> 0.3497433449979271\n",
            "Loss in iteration no. 48945 ==> 0.3497422726312326\n",
            "Loss in iteration no. 48946 ==> 0.349741200304096\n",
            "Loss in iteration no. 48947 ==> 0.3497401280165156\n",
            "Loss in iteration no. 48948 ==> 0.3497390557684891\n",
            "Loss in iteration no. 48949 ==> 0.3497379835600148\n",
            "Loss in iteration no. 48950 ==> 0.3497369113910903\n",
            "Loss in iteration no. 48951 ==> 0.34973583926171375\n",
            "Loss in iteration no. 48952 ==> 0.34973476717188323\n",
            "Loss in iteration no. 48953 ==> 0.3497336951215965\n",
            "Loss in iteration no. 48954 ==> 0.3497326231108517\n",
            "Loss in iteration no. 48955 ==> 0.34973155113964677\n",
            "Loss in iteration no. 48956 ==> 0.3497304792079795\n",
            "Loss in iteration no. 48957 ==> 0.349729407315848\n",
            "Loss in iteration no. 48958 ==> 0.3497283354632503\n",
            "Loss in iteration no. 48959 ==> 0.3497272636501843\n",
            "Loss in iteration no. 48960 ==> 0.34972619187664805\n",
            "Loss in iteration no. 48961 ==> 0.34972512014263935\n",
            "Loss in iteration no. 48962 ==> 0.3497240484481564\n",
            "Loss in iteration no. 48963 ==> 0.34972297679319697\n",
            "Loss in iteration no. 48964 ==> 0.3497219051777591\n",
            "Loss in iteration no. 48965 ==> 0.3497208336018408\n",
            "Loss in iteration no. 48966 ==> 0.34971976206544003\n",
            "Loss in iteration no. 48967 ==> 0.3497186905685547\n",
            "Loss in iteration no. 48968 ==> 0.34971761911118293\n",
            "Loss in iteration no. 48969 ==> 0.3497165476933225\n",
            "Loss in iteration no. 48970 ==> 0.3497154763149715\n",
            "Loss in iteration no. 48971 ==> 0.34971440497612793\n",
            "Loss in iteration no. 48972 ==> 0.34971333367678975\n",
            "Loss in iteration no. 48973 ==> 0.34971226241695486\n",
            "Loss in iteration no. 48974 ==> 0.34971119119662125\n",
            "Loss in iteration no. 48975 ==> 0.3497101200157869\n",
            "Loss in iteration no. 48976 ==> 0.3497090488744498\n",
            "Loss in iteration no. 48977 ==> 0.3497079777726081\n",
            "Loss in iteration no. 48978 ==> 0.34970690671025945\n",
            "Loss in iteration no. 48979 ==> 0.34970583568740204\n",
            "Loss in iteration no. 48980 ==> 0.3497047647040337\n",
            "Loss in iteration no. 48981 ==> 0.34970369376015253\n",
            "Loss in iteration no. 48982 ==> 0.3497026228557566\n",
            "Loss in iteration no. 48983 ==> 0.3497015519908436\n",
            "Loss in iteration no. 48984 ==> 0.34970048116541164\n",
            "Loss in iteration no. 48985 ==> 0.3496994103794587\n",
            "Loss in iteration no. 48986 ==> 0.34969833963298286\n",
            "Loss in iteration no. 48987 ==> 0.34969726892598196\n",
            "Loss in iteration no. 48988 ==> 0.34969619825845394\n",
            "Loss in iteration no. 48989 ==> 0.34969512763039695\n",
            "Loss in iteration no. 48990 ==> 0.3496940570418088\n",
            "Loss in iteration no. 48991 ==> 0.3496929864926876\n",
            "Loss in iteration no. 48992 ==> 0.34969191598303123\n",
            "Loss in iteration no. 48993 ==> 0.3496908455128377\n",
            "Loss in iteration no. 48994 ==> 0.349689775082105\n",
            "Loss in iteration no. 48995 ==> 0.3496887046908311\n",
            "Loss in iteration no. 48996 ==> 0.3496876343390139\n",
            "Loss in iteration no. 48997 ==> 0.3496865640266515\n",
            "Loss in iteration no. 48998 ==> 0.3496854937537418\n",
            "Loss in iteration no. 48999 ==> 0.3496844235202828\n",
            "Loss in iteration no. 49000 ==> 0.3496833533262725\n",
            "Loss in iteration no. 49001 ==> 0.34968228317170874\n",
            "Loss in iteration no. 49002 ==> 0.3496812130565898\n",
            "Loss in iteration no. 49003 ==> 0.3496801429809134\n",
            "Loss in iteration no. 49004 ==> 0.3496790729446775\n",
            "Loss in iteration no. 49005 ==> 0.34967800294788015\n",
            "Loss in iteration no. 49006 ==> 0.3496769329905195\n",
            "Loss in iteration no. 49007 ==> 0.3496758630725933\n",
            "Loss in iteration no. 49008 ==> 0.3496747931940995\n",
            "Loss in iteration no. 49009 ==> 0.3496737233550364\n",
            "Loss in iteration no. 49010 ==> 0.34967265355540156\n",
            "Loss in iteration no. 49011 ==> 0.3496715837951932\n",
            "Loss in iteration no. 49012 ==> 0.34967051407440924\n",
            "Loss in iteration no. 49013 ==> 0.3496694443930478\n",
            "Loss in iteration no. 49014 ==> 0.3496683747511066\n",
            "Loss in iteration no. 49015 ==> 0.3496673051485838\n",
            "Loss in iteration no. 49016 ==> 0.34966623558547727\n",
            "Loss in iteration no. 49017 ==> 0.34966516606178516\n",
            "Loss in iteration no. 49018 ==> 0.3496640965775053\n",
            "Loss in iteration no. 49019 ==> 0.3496630271326357\n",
            "Loss in iteration no. 49020 ==> 0.3496619577271744\n",
            "Loss in iteration no. 49021 ==> 0.3496608883611192\n",
            "Loss in iteration no. 49022 ==> 0.34965981903446836\n",
            "Loss in iteration no. 49023 ==> 0.34965874974721967\n",
            "Loss in iteration no. 49024 ==> 0.34965768049937107\n",
            "Loss in iteration no. 49025 ==> 0.34965661129092074\n",
            "Loss in iteration no. 49026 ==> 0.3496555421218665\n",
            "Loss in iteration no. 49027 ==> 0.3496544729922064\n",
            "Loss in iteration no. 49028 ==> 0.34965340390193833\n",
            "Loss in iteration no. 49029 ==> 0.3496523348510604\n",
            "Loss in iteration no. 49030 ==> 0.34965126583957057\n",
            "Loss in iteration no. 49031 ==> 0.3496501968674667\n",
            "Loss in iteration no. 49032 ==> 0.3496491279347469\n",
            "Loss in iteration no. 49033 ==> 0.34964805904140894\n",
            "Loss in iteration no. 49034 ==> 0.3496469901874512\n",
            "Loss in iteration no. 49035 ==> 0.34964592137287137\n",
            "Loss in iteration no. 49036 ==> 0.3496448525976674\n",
            "Loss in iteration no. 49037 ==> 0.3496437838618375\n",
            "Loss in iteration no. 49038 ==> 0.3496427151653795\n",
            "Loss in iteration no. 49039 ==> 0.3496416465082913\n",
            "Loss in iteration no. 49040 ==> 0.349640577890571\n",
            "Loss in iteration no. 49041 ==> 0.3496395093122166\n",
            "Loss in iteration no. 49042 ==> 0.34963844077322603\n",
            "Loss in iteration no. 49043 ==> 0.3496373722735973\n",
            "Loss in iteration no. 49044 ==> 0.34963630381332844\n",
            "Loss in iteration no. 49045 ==> 0.3496352353924173\n",
            "Loss in iteration no. 49046 ==> 0.349634167010862\n",
            "Loss in iteration no. 49047 ==> 0.34963309866866044\n",
            "Loss in iteration no. 49048 ==> 0.3496320303658106\n",
            "Loss in iteration no. 49049 ==> 0.3496309621023105\n",
            "Loss in iteration no. 49050 ==> 0.3496298938781582\n",
            "Loss in iteration no. 49051 ==> 0.3496288256933515\n",
            "Loss in iteration no. 49052 ==> 0.34962775754788855\n",
            "Loss in iteration no. 49053 ==> 0.3496266894417672\n",
            "Loss in iteration no. 49054 ==> 0.3496256213749856\n",
            "Loss in iteration no. 49055 ==> 0.3496245533475416\n",
            "Loss in iteration no. 49056 ==> 0.3496234853594332\n",
            "Loss in iteration no. 49057 ==> 0.3496224174106584\n",
            "Loss in iteration no. 49058 ==> 0.3496213495012153\n",
            "Loss in iteration no. 49059 ==> 0.34962028163110176\n",
            "Loss in iteration no. 49060 ==> 0.3496192138003157\n",
            "Loss in iteration no. 49061 ==> 0.3496181460088552\n",
            "Loss in iteration no. 49062 ==> 0.3496170782567183\n",
            "Loss in iteration no. 49063 ==> 0.3496160105439029\n",
            "Loss in iteration no. 49064 ==> 0.3496149428704069\n",
            "Loss in iteration no. 49065 ==> 0.34961387523622856\n",
            "Loss in iteration no. 49066 ==> 0.34961280764136565\n",
            "Loss in iteration no. 49067 ==> 0.34961174008581625\n",
            "Loss in iteration no. 49068 ==> 0.34961067256957823\n",
            "Loss in iteration no. 49069 ==> 0.34960960509264966\n",
            "Loss in iteration no. 49070 ==> 0.3496085376550286\n",
            "Loss in iteration no. 49071 ==> 0.3496074702567128\n",
            "Loss in iteration no. 49072 ==> 0.34960640289770045\n",
            "Loss in iteration no. 49073 ==> 0.34960533557798956\n",
            "Loss in iteration no. 49074 ==> 0.34960426829757807\n",
            "Loss in iteration no. 49075 ==> 0.3496032010564638\n",
            "Loss in iteration no. 49076 ==> 0.349602133854645\n",
            "Loss in iteration no. 49077 ==> 0.34960106669211954\n",
            "Loss in iteration no. 49078 ==> 0.3495999995688854\n",
            "Loss in iteration no. 49079 ==> 0.34959893248494056\n",
            "Loss in iteration no. 49080 ==> 0.34959786544028304\n",
            "Loss in iteration no. 49081 ==> 0.3495967984349108\n",
            "Loss in iteration no. 49082 ==> 0.34959573146882184\n",
            "Loss in iteration no. 49083 ==> 0.3495946645420141\n",
            "Loss in iteration no. 49084 ==> 0.3495935976544857\n",
            "Loss in iteration no. 49085 ==> 0.3495925308062345\n",
            "Loss in iteration no. 49086 ==> 0.3495914639972586\n",
            "Loss in iteration no. 49087 ==> 0.34959039722755586\n",
            "Loss in iteration no. 49088 ==> 0.34958933049712443\n",
            "Loss in iteration no. 49089 ==> 0.349588263805962\n",
            "Loss in iteration no. 49090 ==> 0.349587197154067\n",
            "Loss in iteration no. 49091 ==> 0.34958613054143706\n",
            "Loss in iteration no. 49092 ==> 0.3495850639680703\n",
            "Loss in iteration no. 49093 ==> 0.34958399743396473\n",
            "Loss in iteration no. 49094 ==> 0.34958293093911824\n",
            "Loss in iteration no. 49095 ==> 0.34958186448352896\n",
            "Loss in iteration no. 49096 ==> 0.34958079806719483\n",
            "Loss in iteration no. 49097 ==> 0.34957973169011375\n",
            "Loss in iteration no. 49098 ==> 0.3495786653522839\n",
            "Loss in iteration no. 49099 ==> 0.34957759905370306\n",
            "Loss in iteration no. 49100 ==> 0.34957653279436934\n",
            "Loss in iteration no. 49101 ==> 0.3495754665742807\n",
            "Loss in iteration no. 49102 ==> 0.3495744003934351\n",
            "Loss in iteration no. 49103 ==> 0.3495733342518306\n",
            "Loss in iteration no. 49104 ==> 0.3495722681494652\n",
            "Loss in iteration no. 49105 ==> 0.34957120208633685\n",
            "Loss in iteration no. 49106 ==> 0.3495701360624435\n",
            "Loss in iteration no. 49107 ==> 0.3495690700777833\n",
            "Loss in iteration no. 49108 ==> 0.349568004132354\n",
            "Loss in iteration no. 49109 ==> 0.3495669382261538\n",
            "Loss in iteration no. 49110 ==> 0.3495658723591805\n",
            "Loss in iteration no. 49111 ==> 0.3495648065314323\n",
            "Loss in iteration no. 49112 ==> 0.349563740742907\n",
            "Loss in iteration no. 49113 ==> 0.34956267499360283\n",
            "Loss in iteration no. 49114 ==> 0.3495616092835176\n",
            "Loss in iteration no. 49115 ==> 0.34956054361264927\n",
            "Loss in iteration no. 49116 ==> 0.34955947798099596\n",
            "Loss in iteration no. 49117 ==> 0.3495584123885556\n",
            "Loss in iteration no. 49118 ==> 0.3495573468353262\n",
            "Loss in iteration no. 49119 ==> 0.3495562813213058\n",
            "Loss in iteration no. 49120 ==> 0.34955521584649224\n",
            "Loss in iteration no. 49121 ==> 0.3495541504108836\n",
            "Loss in iteration no. 49122 ==> 0.349553085014478\n",
            "Loss in iteration no. 49123 ==> 0.34955201965727334\n",
            "Loss in iteration no. 49124 ==> 0.34955095433926753\n",
            "Loss in iteration no. 49125 ==> 0.34954988906045853\n",
            "Loss in iteration no. 49126 ==> 0.34954882382084457\n",
            "Loss in iteration no. 49127 ==> 0.34954775862042353\n",
            "Loss in iteration no. 49128 ==> 0.3495466934591933\n",
            "Loss in iteration no. 49129 ==> 0.34954562833715197\n",
            "Loss in iteration no. 49130 ==> 0.34954456325429756\n",
            "Loss in iteration no. 49131 ==> 0.3495434982106281\n",
            "Loss in iteration no. 49132 ==> 0.3495424332061414\n",
            "Loss in iteration no. 49133 ==> 0.3495413682408356\n",
            "Loss in iteration no. 49134 ==> 0.34954030331470864\n",
            "Loss in iteration no. 49135 ==> 0.3495392384277586\n",
            "Loss in iteration no. 49136 ==> 0.34953817357998335\n",
            "Loss in iteration no. 49137 ==> 0.34953710877138094\n",
            "Loss in iteration no. 49138 ==> 0.34953604400194943\n",
            "Loss in iteration no. 49139 ==> 0.34953497927168675\n",
            "Loss in iteration no. 49140 ==> 0.3495339145805909\n",
            "Loss in iteration no. 49141 ==> 0.34953284992865996\n",
            "Loss in iteration no. 49142 ==> 0.34953178531589174\n",
            "Loss in iteration no. 49143 ==> 0.3495307207422844\n",
            "Loss in iteration no. 49144 ==> 0.3495296562078358\n",
            "Loss in iteration no. 49145 ==> 0.3495285917125442\n",
            "Loss in iteration no. 49146 ==> 0.3495275272564073\n",
            "Loss in iteration no. 49147 ==> 0.3495264628394232\n",
            "Loss in iteration no. 49148 ==> 0.3495253984615899\n",
            "Loss in iteration no. 49149 ==> 0.34952433412290557\n",
            "Loss in iteration no. 49150 ==> 0.34952326982336784\n",
            "Loss in iteration no. 49151 ==> 0.3495222055629751\n",
            "Loss in iteration no. 49152 ==> 0.349521141341725\n",
            "Loss in iteration no. 49153 ==> 0.34952007715961586\n",
            "Loss in iteration no. 49154 ==> 0.3495190130166454\n",
            "Loss in iteration no. 49155 ==> 0.34951794891281185\n",
            "Loss in iteration no. 49156 ==> 0.349516884848113\n",
            "Loss in iteration no. 49157 ==> 0.349515820822547\n",
            "Loss in iteration no. 49158 ==> 0.34951475683611183\n",
            "Loss in iteration no. 49159 ==> 0.34951369288880535\n",
            "Loss in iteration no. 49160 ==> 0.34951262898062574\n",
            "Loss in iteration no. 49161 ==> 0.34951156511157083\n",
            "Loss in iteration no. 49162 ==> 0.34951050128163874\n",
            "Loss in iteration no. 49163 ==> 0.3495094374908275\n",
            "Loss in iteration no. 49164 ==> 0.349508373739135\n",
            "Loss in iteration no. 49165 ==> 0.34950731002655927\n",
            "Loss in iteration no. 49166 ==> 0.3495062463530984\n",
            "Loss in iteration no. 49167 ==> 0.3495051827187503\n",
            "Loss in iteration no. 49168 ==> 0.349504119123513\n",
            "Loss in iteration no. 49169 ==> 0.34950305556738437\n",
            "Loss in iteration no. 49170 ==> 0.34950199205036264\n",
            "Loss in iteration no. 49171 ==> 0.3495009285724457\n",
            "Loss in iteration no. 49172 ==> 0.3494998651336315\n",
            "Loss in iteration no. 49173 ==> 0.34949880173391806\n",
            "Loss in iteration no. 49174 ==> 0.3494977383733035\n",
            "Loss in iteration no. 49175 ==> 0.34949667505178567\n",
            "Loss in iteration no. 49176 ==> 0.34949561176936267\n",
            "Loss in iteration no. 49177 ==> 0.3494945485260324\n",
            "Loss in iteration no. 49178 ==> 0.349493485321793\n",
            "Loss in iteration no. 49179 ==> 0.3494924221566424\n",
            "Loss in iteration no. 49180 ==> 0.34949135903057854\n",
            "Loss in iteration no. 49181 ==> 0.34949029594359954\n",
            "Loss in iteration no. 49182 ==> 0.3494892328957032\n",
            "Loss in iteration no. 49183 ==> 0.3494881698868878\n",
            "Loss in iteration no. 49184 ==> 0.3494871069171512\n",
            "Loss in iteration no. 49185 ==> 0.3494860439864913\n",
            "Loss in iteration no. 49186 ==> 0.3494849810949063\n",
            "Loss in iteration no. 49187 ==> 0.34948391824239405\n",
            "Loss in iteration no. 49188 ==> 0.34948285542895263\n",
            "Loss in iteration no. 49189 ==> 0.34948179265458\n",
            "Loss in iteration no. 49190 ==> 0.3494807299192743\n",
            "Loss in iteration no. 49191 ==> 0.3494796672230333\n",
            "Loss in iteration no. 49192 ==> 0.3494786045658552\n",
            "Loss in iteration no. 49193 ==> 0.349477541947738\n",
            "Loss in iteration no. 49194 ==> 0.34947647936867954\n",
            "Loss in iteration no. 49195 ==> 0.3494754168286779\n",
            "Loss in iteration no. 49196 ==> 0.3494743543277311\n",
            "Loss in iteration no. 49197 ==> 0.34947329186583714\n",
            "Loss in iteration no. 49198 ==> 0.3494722294429941\n",
            "Loss in iteration no. 49199 ==> 0.3494711670591998\n",
            "Loss in iteration no. 49200 ==> 0.34947010471445245\n",
            "Loss in iteration no. 49201 ==> 0.34946904240874993\n",
            "Loss in iteration no. 49202 ==> 0.34946798014209024\n",
            "Loss in iteration no. 49203 ==> 0.34946691791447143\n",
            "Loss in iteration no. 49204 ==> 0.3494658557258915\n",
            "Loss in iteration no. 49205 ==> 0.3494647935763485\n",
            "Loss in iteration no. 49206 ==> 0.34946373146584037\n",
            "Loss in iteration no. 49207 ==> 0.34946266939436504\n",
            "Loss in iteration no. 49208 ==> 0.3494616073619206\n",
            "Loss in iteration no. 49209 ==> 0.3494605453685052\n",
            "Loss in iteration no. 49210 ==> 0.3494594834141166\n",
            "Loss in iteration no. 49211 ==> 0.34945842149875295\n",
            "Loss in iteration no. 49212 ==> 0.34945735962241214\n",
            "Loss in iteration no. 49213 ==> 0.34945629778509235\n",
            "Loss in iteration no. 49214 ==> 0.34945523598679146\n",
            "Loss in iteration no. 49215 ==> 0.3494541742275074\n",
            "Loss in iteration no. 49216 ==> 0.34945311250723843\n",
            "Loss in iteration no. 49217 ==> 0.3494520508259823\n",
            "Loss in iteration no. 49218 ==> 0.3494509891837372\n",
            "Loss in iteration no. 49219 ==> 0.3494499275805011\n",
            "Loss in iteration no. 49220 ==> 0.34944886601627184\n",
            "Loss in iteration no. 49221 ==> 0.3494478044910477\n",
            "Loss in iteration no. 49222 ==> 0.34944674300482637\n",
            "Loss in iteration no. 49223 ==> 0.3494456815576061\n",
            "Loss in iteration no. 49224 ==> 0.3494446201493848\n",
            "Loss in iteration no. 49225 ==> 0.3494435587801606\n",
            "Loss in iteration no. 49226 ==> 0.34944249744993133\n",
            "Loss in iteration no. 49227 ==> 0.3494414361586951\n",
            "Loss in iteration no. 49228 ==> 0.34944037490644986\n",
            "Loss in iteration no. 49229 ==> 0.3494393136931937\n",
            "Loss in iteration no. 49230 ==> 0.34943825251892463\n",
            "Loss in iteration no. 49231 ==> 0.34943719138364054\n",
            "Loss in iteration no. 49232 ==> 0.34943613028733944\n",
            "Loss in iteration no. 49233 ==> 0.3494350692300195\n",
            "Loss in iteration no. 49234 ==> 0.3494340082116786\n",
            "Loss in iteration no. 49235 ==> 0.3494329472323148\n",
            "Loss in iteration no. 49236 ==> 0.34943188629192606\n",
            "Loss in iteration no. 49237 ==> 0.34943082539051046\n",
            "Loss in iteration no. 49238 ==> 0.34942976452806596\n",
            "Loss in iteration no. 49239 ==> 0.3494287037045906\n",
            "Loss in iteration no. 49240 ==> 0.3494276429200824\n",
            "Loss in iteration no. 49241 ==> 0.3494265821745393\n",
            "Loss in iteration no. 49242 ==> 0.34942552146795935\n",
            "Loss in iteration no. 49243 ==> 0.34942446080034056\n",
            "Loss in iteration no. 49244 ==> 0.349423400171681\n",
            "Loss in iteration no. 49245 ==> 0.3494223395819785\n",
            "Loss in iteration no. 49246 ==> 0.34942127903123127\n",
            "Loss in iteration no. 49247 ==> 0.3494202185194373\n",
            "Loss in iteration no. 49248 ==> 0.34941915804659446\n",
            "Loss in iteration no. 49249 ==> 0.3494180976127009\n",
            "Loss in iteration no. 49250 ==> 0.34941703721775447\n",
            "Loss in iteration no. 49251 ==> 0.3494159768617533\n",
            "Loss in iteration no. 49252 ==> 0.3494149165446954\n",
            "Loss in iteration no. 49253 ==> 0.3494138562665788\n",
            "Loss in iteration no. 49254 ==> 0.34941279602740144\n",
            "Loss in iteration no. 49255 ==> 0.34941173582716145\n",
            "Loss in iteration no. 49256 ==> 0.34941067566585665\n",
            "Loss in iteration no. 49257 ==> 0.34940961554348526\n",
            "Loss in iteration no. 49258 ==> 0.3494085554600451\n",
            "Loss in iteration no. 49259 ==> 0.34940749541553434\n",
            "Loss in iteration no. 49260 ==> 0.349406435409951\n",
            "Loss in iteration no. 49261 ==> 0.3494053754432929\n",
            "Loss in iteration no. 49262 ==> 0.3494043155155583\n",
            "Loss in iteration no. 49263 ==> 0.3494032556267449\n",
            "Loss in iteration no. 49264 ==> 0.349402195776851\n",
            "Loss in iteration no. 49265 ==> 0.34940113596587447\n",
            "Loss in iteration no. 49266 ==> 0.34940007619381336\n",
            "Loss in iteration no. 49267 ==> 0.34939901646066585\n",
            "Loss in iteration no. 49268 ==> 0.3493979567664296\n",
            "Loss in iteration no. 49269 ==> 0.34939689711110294\n",
            "Loss in iteration no. 49270 ==> 0.34939583749468367\n",
            "Loss in iteration no. 49271 ==> 0.34939477791716994\n",
            "Loss in iteration no. 49272 ==> 0.34939371837855965\n",
            "Loss in iteration no. 49273 ==> 0.34939265887885096\n",
            "Loss in iteration no. 49274 ==> 0.3493915994180417\n",
            "Loss in iteration no. 49275 ==> 0.3493905399961301\n",
            "Loss in iteration no. 49276 ==> 0.349389480613114\n",
            "Loss in iteration no. 49277 ==> 0.34938842126899144\n",
            "Loss in iteration no. 49278 ==> 0.3493873619637605\n",
            "Loss in iteration no. 49279 ==> 0.34938630269741927\n",
            "Loss in iteration no. 49280 ==> 0.3493852434699656\n",
            "Loss in iteration no. 49281 ==> 0.3493841842813974\n",
            "Loss in iteration no. 49282 ==> 0.34938312513171305\n",
            "Loss in iteration no. 49283 ==> 0.34938206602091026\n",
            "Loss in iteration no. 49284 ==> 0.34938100694898716\n",
            "Loss in iteration no. 49285 ==> 0.34937994791594185\n",
            "Loss in iteration no. 49286 ==> 0.34937888892177216\n",
            "Loss in iteration no. 49287 ==> 0.34937782996647615\n",
            "Loss in iteration no. 49288 ==> 0.349376771050052\n",
            "Loss in iteration no. 49289 ==> 0.3493757121724976\n",
            "Loss in iteration no. 49290 ==> 0.34937465333381074\n",
            "Loss in iteration no. 49291 ==> 0.34937359453399\n",
            "Loss in iteration no. 49292 ==> 0.34937253577303284\n",
            "Loss in iteration no. 49293 ==> 0.3493714770509376\n",
            "Loss in iteration no. 49294 ==> 0.34937041836770216\n",
            "Loss in iteration no. 49295 ==> 0.34936935972332467\n",
            "Loss in iteration no. 49296 ==> 0.349368301117803\n",
            "Loss in iteration no. 49297 ==> 0.34936724255113516\n",
            "Loss in iteration no. 49298 ==> 0.3493661840233192\n",
            "Loss in iteration no. 49299 ==> 0.3493651255343532\n",
            "Loss in iteration no. 49300 ==> 0.34936406708423523\n",
            "Loss in iteration no. 49301 ==> 0.3493630086729632\n",
            "Loss in iteration no. 49302 ==> 0.3493619503005351\n",
            "Loss in iteration no. 49303 ==> 0.34936089196694897\n",
            "Loss in iteration no. 49304 ==> 0.34935983367220286\n",
            "Loss in iteration no. 49305 ==> 0.34935877541629484\n",
            "Loss in iteration no. 49306 ==> 0.3493577171992229\n",
            "Loss in iteration no. 49307 ==> 0.3493566590209849\n",
            "Loss in iteration no. 49308 ==> 0.349355600881579\n",
            "Loss in iteration no. 49309 ==> 0.3493545427810033\n",
            "Loss in iteration no. 49310 ==> 0.34935348471925565\n",
            "Loss in iteration no. 49311 ==> 0.3493524266963342\n",
            "Loss in iteration no. 49312 ==> 0.3493513687122369\n",
            "Loss in iteration no. 49313 ==> 0.3493503107669617\n",
            "Loss in iteration no. 49314 ==> 0.34934925286050666\n",
            "Loss in iteration no. 49315 ==> 0.34934819499287\n",
            "Loss in iteration no. 49316 ==> 0.3493471371640495\n",
            "Loss in iteration no. 49317 ==> 0.34934607937404333\n",
            "Loss in iteration no. 49318 ==> 0.3493450216228493\n",
            "Loss in iteration no. 49319 ==> 0.3493439639104656\n",
            "Loss in iteration no. 49320 ==> 0.3493429062368903\n",
            "Loss in iteration no. 49321 ==> 0.34934184860212136\n",
            "Loss in iteration no. 49322 ==> 0.34934079100615667\n",
            "Loss in iteration no. 49323 ==> 0.3493397334489944\n",
            "Loss in iteration no. 49324 ==> 0.34933867593063256\n",
            "Loss in iteration no. 49325 ==> 0.34933761845106914\n",
            "Loss in iteration no. 49326 ==> 0.3493365610103021\n",
            "Loss in iteration no. 49327 ==> 0.34933550360832955\n",
            "Loss in iteration no. 49328 ==> 0.3493344462451494\n",
            "Loss in iteration no. 49329 ==> 0.34933338892075994\n",
            "Loss in iteration no. 49330 ==> 0.34933233163515887\n",
            "Loss in iteration no. 49331 ==> 0.34933127438834444\n",
            "Loss in iteration no. 49332 ==> 0.34933021718031443\n",
            "Loss in iteration no. 49333 ==> 0.34932916001106706\n",
            "Loss in iteration no. 49334 ==> 0.34932810288060034\n",
            "Loss in iteration no. 49335 ==> 0.3493270457889123\n",
            "Loss in iteration no. 49336 ==> 0.3493259887360009\n",
            "Loss in iteration no. 49337 ==> 0.3493249317218642\n",
            "Loss in iteration no. 49338 ==> 0.3493238747465001\n",
            "Loss in iteration no. 49339 ==> 0.34932281780990676\n",
            "Loss in iteration no. 49340 ==> 0.34932176091208217\n",
            "Loss in iteration no. 49341 ==> 0.34932070405302434\n",
            "Loss in iteration no. 49342 ==> 0.34931964723273135\n",
            "Loss in iteration no. 49343 ==> 0.34931859045120117\n",
            "Loss in iteration no. 49344 ==> 0.34931753370843177\n",
            "Loss in iteration no. 49345 ==> 0.3493164770044212\n",
            "Loss in iteration no. 49346 ==> 0.3493154203391676\n",
            "Loss in iteration no. 49347 ==> 0.3493143637126689\n",
            "Loss in iteration no. 49348 ==> 0.3493133071249231\n",
            "Loss in iteration no. 49349 ==> 0.34931225057592813\n",
            "Loss in iteration no. 49350 ==> 0.3493111940656824\n",
            "Loss in iteration no. 49351 ==> 0.34931013759418356\n",
            "Loss in iteration no. 49352 ==> 0.3493090811614297\n",
            "Loss in iteration no. 49353 ==> 0.3493080247674189\n",
            "Loss in iteration no. 49354 ==> 0.3493069684121492\n",
            "Loss in iteration no. 49355 ==> 0.3493059120956186\n",
            "Loss in iteration no. 49356 ==> 0.34930485581782517\n",
            "Loss in iteration no. 49357 ==> 0.34930379957876684\n",
            "Loss in iteration no. 49358 ==> 0.3493027433784417\n",
            "Loss in iteration no. 49359 ==> 0.34930168721684773\n",
            "Loss in iteration no. 49360 ==> 0.349300631093983\n",
            "Loss in iteration no. 49361 ==> 0.3492995750098456\n",
            "Loss in iteration no. 49362 ==> 0.3492985189644334\n",
            "Loss in iteration no. 49363 ==> 0.3492974629577445\n",
            "Loss in iteration no. 49364 ==> 0.34929640698977693\n",
            "Loss in iteration no. 49365 ==> 0.3492953510605288\n",
            "Loss in iteration no. 49366 ==> 0.3492942951699979\n",
            "Loss in iteration no. 49367 ==> 0.34929323931818257\n",
            "Loss in iteration no. 49368 ==> 0.34929218350508057\n",
            "Loss in iteration no. 49369 ==> 0.34929112773069004\n",
            "Loss in iteration no. 49370 ==> 0.34929007199500894\n",
            "Loss in iteration no. 49371 ==> 0.3492890162980355\n",
            "Loss in iteration no. 49372 ==> 0.3492879606397674\n",
            "Loss in iteration no. 49373 ==> 0.3492869050202031\n",
            "Loss in iteration no. 49374 ==> 0.34928584943934027\n",
            "Loss in iteration no. 49375 ==> 0.3492847938971771\n",
            "Loss in iteration no. 49376 ==> 0.3492837383937116\n",
            "Loss in iteration no. 49377 ==> 0.34928268292894166\n",
            "Loss in iteration no. 49378 ==> 0.3492816275028655\n",
            "Loss in iteration no. 49379 ==> 0.349280572115481\n",
            "Loss in iteration no. 49380 ==> 0.34927951676678637\n",
            "Loss in iteration no. 49381 ==> 0.34927846145677943\n",
            "Loss in iteration no. 49382 ==> 0.3492774061854584\n",
            "Loss in iteration no. 49383 ==> 0.34927635095282117\n",
            "Loss in iteration no. 49384 ==> 0.34927529575886573\n",
            "Loss in iteration no. 49385 ==> 0.3492742406035904\n",
            "Loss in iteration no. 49386 ==> 0.3492731854869928\n",
            "Loss in iteration no. 49387 ==> 0.34927213040907124\n",
            "Loss in iteration no. 49388 ==> 0.34927107536982366\n",
            "Loss in iteration no. 49389 ==> 0.3492700203692481\n",
            "Loss in iteration no. 49390 ==> 0.3492689654073426\n",
            "Loss in iteration no. 49391 ==> 0.3492679104841051\n",
            "Loss in iteration no. 49392 ==> 0.34926685559953385\n",
            "Loss in iteration no. 49393 ==> 0.3492658007536267\n",
            "Loss in iteration no. 49394 ==> 0.3492647459463816\n",
            "Loss in iteration no. 49395 ==> 0.3492636911777967\n",
            "Loss in iteration no. 49396 ==> 0.34926263644787015\n",
            "Loss in iteration no. 49397 ==> 0.3492615817565997\n",
            "Loss in iteration no. 49398 ==> 0.34926052710398364\n",
            "Loss in iteration no. 49399 ==> 0.34925947249001976\n",
            "Loss in iteration no. 49400 ==> 0.3492584179147064\n",
            "Loss in iteration no. 49401 ==> 0.34925736337804136\n",
            "Loss in iteration no. 49402 ==> 0.34925630888002274\n",
            "Loss in iteration no. 49403 ==> 0.34925525442064853\n",
            "Loss in iteration no. 49404 ==> 0.3492541999999168\n",
            "Loss in iteration no. 49405 ==> 0.34925314561782556\n",
            "Loss in iteration no. 49406 ==> 0.34925209127437284\n",
            "Loss in iteration no. 49407 ==> 0.34925103696955667\n",
            "Loss in iteration no. 49408 ==> 0.3492499827033751\n",
            "Loss in iteration no. 49409 ==> 0.34924892847582617\n",
            "Loss in iteration no. 49410 ==> 0.3492478742869079\n",
            "Loss in iteration no. 49411 ==> 0.3492468201366183\n",
            "Loss in iteration no. 49412 ==> 0.3492457660249555\n",
            "Loss in iteration no. 49413 ==> 0.3492447119519173\n",
            "Loss in iteration no. 49414 ==> 0.349243657917502\n",
            "Loss in iteration no. 49415 ==> 0.3492426039217076\n",
            "Loss in iteration no. 49416 ==> 0.3492415499645319\n",
            "Loss in iteration no. 49417 ==> 0.34924049604597307\n",
            "Loss in iteration no. 49418 ==> 0.34923944216602926\n",
            "Loss in iteration no. 49419 ==> 0.3492383883246984\n",
            "Loss in iteration no. 49420 ==> 0.3492373345219784\n",
            "Loss in iteration no. 49421 ==> 0.3492362807578675\n",
            "Loss in iteration no. 49422 ==> 0.3492352270323637\n",
            "Loss in iteration no. 49423 ==> 0.34923417334546486\n",
            "Loss in iteration no. 49424 ==> 0.34923311969716925\n",
            "Loss in iteration no. 49425 ==> 0.34923206608747476\n",
            "Loss in iteration no. 49426 ==> 0.34923101251637934\n",
            "Loss in iteration no. 49427 ==> 0.3492299589838813\n",
            "Loss in iteration no. 49428 ==> 0.34922890548997837\n",
            "Loss in iteration no. 49429 ==> 0.3492278520346689\n",
            "Loss in iteration no. 49430 ==> 0.3492267986179506\n",
            "Loss in iteration no. 49431 ==> 0.34922574523982175\n",
            "Loss in iteration no. 49432 ==> 0.3492246919002802\n",
            "Loss in iteration no. 49433 ==> 0.34922363859932415\n",
            "Loss in iteration no. 49434 ==> 0.34922258533695166\n",
            "Loss in iteration no. 49435 ==> 0.3492215321131605\n",
            "Loss in iteration no. 49436 ==> 0.3492204789279489\n",
            "Loss in iteration no. 49437 ==> 0.3492194257813149\n",
            "Loss in iteration no. 49438 ==> 0.3492183726732564\n",
            "Loss in iteration no. 49439 ==> 0.3492173196037716\n",
            "Loss in iteration no. 49440 ==> 0.34921626657285854\n",
            "Loss in iteration no. 49441 ==> 0.3492152135805151\n",
            "Loss in iteration no. 49442 ==> 0.34921416062673943\n",
            "Loss in iteration no. 49443 ==> 0.34921310771152964\n",
            "Loss in iteration no. 49444 ==> 0.34921205483488355\n",
            "Loss in iteration no. 49445 ==> 0.34921100199679933\n",
            "Loss in iteration no. 49446 ==> 0.349209949197275\n",
            "Loss in iteration no. 49447 ==> 0.3492088964363086\n",
            "Loss in iteration no. 49448 ==> 0.3492078437138982\n",
            "Loss in iteration no. 49449 ==> 0.3492067910300417\n",
            "Loss in iteration no. 49450 ==> 0.3492057383847374\n",
            "Loss in iteration no. 49451 ==> 0.34920468577798314\n",
            "Loss in iteration no. 49452 ==> 0.34920363320977676\n",
            "Loss in iteration no. 49453 ==> 0.3492025806801167\n",
            "Loss in iteration no. 49454 ==> 0.3492015281890009\n",
            "Loss in iteration no. 49455 ==> 0.34920047573642726\n",
            "Loss in iteration no. 49456 ==> 0.3491994233223939\n",
            "Loss in iteration no. 49457 ==> 0.3491983709468988\n",
            "Loss in iteration no. 49458 ==> 0.34919731860994\n",
            "Loss in iteration no. 49459 ==> 0.3491962663115157\n",
            "Loss in iteration no. 49460 ==> 0.34919521405162374\n",
            "Loss in iteration no. 49461 ==> 0.34919416183026225\n",
            "Loss in iteration no. 49462 ==> 0.3491931096474292\n",
            "Loss in iteration no. 49463 ==> 0.34919205750312277\n",
            "Loss in iteration no. 49464 ==> 0.3491910053973408\n",
            "Loss in iteration no. 49465 ==> 0.3491899533300815\n",
            "Loss in iteration no. 49466 ==> 0.3491889013013429\n",
            "Loss in iteration no. 49467 ==> 0.34918784931112284\n",
            "Loss in iteration no. 49468 ==> 0.3491867973594197\n",
            "Loss in iteration no. 49469 ==> 0.34918574544623115\n",
            "Loss in iteration no. 49470 ==> 0.3491846935715555\n",
            "Loss in iteration no. 49471 ==> 0.3491836417353907\n",
            "Loss in iteration no. 49472 ==> 0.3491825899377347\n",
            "Loss in iteration no. 49473 ==> 0.34918153817858566\n",
            "Loss in iteration no. 49474 ==> 0.34918048645794164\n",
            "Loss in iteration no. 49475 ==> 0.34917943477580055\n",
            "Loss in iteration no. 49476 ==> 0.34917838313216054\n",
            "Loss in iteration no. 49477 ==> 0.34917733152701963\n",
            "Loss in iteration no. 49478 ==> 0.34917627996037587\n",
            "Loss in iteration no. 49479 ==> 0.3491752284322272\n",
            "Loss in iteration no. 49480 ==> 0.3491741769425718\n",
            "Loss in iteration no. 49481 ==> 0.34917312549140767\n",
            "Loss in iteration no. 49482 ==> 0.3491720740787328\n",
            "Loss in iteration no. 49483 ==> 0.34917102270454525\n",
            "Loss in iteration no. 49484 ==> 0.34916997136884315\n",
            "Loss in iteration no. 49485 ==> 0.3491689200716243\n",
            "Loss in iteration no. 49486 ==> 0.34916786881288703\n",
            "Loss in iteration no. 49487 ==> 0.3491668175926292\n",
            "Loss in iteration no. 49488 ==> 0.3491657664108489\n",
            "Loss in iteration no. 49489 ==> 0.3491647152675442\n",
            "Loss in iteration no. 49490 ==> 0.3491636641627132\n",
            "Loss in iteration no. 49491 ==> 0.3491626130963538\n",
            "Loss in iteration no. 49492 ==> 0.34916156206846416\n",
            "Loss in iteration no. 49493 ==> 0.3491605110790423\n",
            "Loss in iteration no. 49494 ==> 0.3491594601280861\n",
            "Loss in iteration no. 49495 ==> 0.34915840921559377\n",
            "Loss in iteration no. 49496 ==> 0.3491573583415634\n",
            "Loss in iteration no. 49497 ==> 0.34915630750599297\n",
            "Loss in iteration no. 49498 ==> 0.3491552567088805\n",
            "Loss in iteration no. 49499 ==> 0.34915420595022395\n",
            "Loss in iteration no. 49500 ==> 0.34915315523002144\n",
            "Loss in iteration no. 49501 ==> 0.3491521045482711\n",
            "Loss in iteration no. 49502 ==> 0.34915105390497087\n",
            "Loss in iteration no. 49503 ==> 0.34915000330011886\n",
            "Loss in iteration no. 49504 ==> 0.3491489527337131\n",
            "Loss in iteration no. 49505 ==> 0.34914790220575154\n",
            "Loss in iteration no. 49506 ==> 0.34914685171623233\n",
            "Loss in iteration no. 49507 ==> 0.34914580126515343\n",
            "Loss in iteration no. 49508 ==> 0.34914475085251306\n",
            "Loss in iteration no. 49509 ==> 0.3491437004783091\n",
            "Loss in iteration no. 49510 ==> 0.34914265014253965\n",
            "Loss in iteration no. 49511 ==> 0.3491415998452026\n",
            "Loss in iteration no. 49512 ==> 0.3491405495862963\n",
            "Loss in iteration no. 49513 ==> 0.34913949936581856\n",
            "Loss in iteration no. 49514 ==> 0.3491384491837675\n",
            "Loss in iteration no. 49515 ==> 0.3491373990401411\n",
            "Loss in iteration no. 49516 ==> 0.34913634893493756\n",
            "Loss in iteration no. 49517 ==> 0.3491352988681548\n",
            "Loss in iteration no. 49518 ==> 0.349134248839791\n",
            "Loss in iteration no. 49519 ==> 0.349133198849844\n",
            "Loss in iteration no. 49520 ==> 0.34913214889831207\n",
            "Loss in iteration no. 49521 ==> 0.34913109898519296\n",
            "Loss in iteration no. 49522 ==> 0.34913004911048495\n",
            "Loss in iteration no. 49523 ==> 0.34912899927418606\n",
            "Loss in iteration no. 49524 ==> 0.34912794947629433\n",
            "Loss in iteration no. 49525 ==> 0.3491268997168077\n",
            "Loss in iteration no. 49526 ==> 0.3491258499957245\n",
            "Loss in iteration no. 49527 ==> 0.34912480031304227\n",
            "Loss in iteration no. 49528 ==> 0.3491237506687596\n",
            "Loss in iteration no. 49529 ==> 0.3491227010628743\n",
            "Loss in iteration no. 49530 ==> 0.34912165149538427\n",
            "Loss in iteration no. 49531 ==> 0.3491206019662878\n",
            "Loss in iteration no. 49532 ==> 0.3491195524755829\n",
            "Loss in iteration no. 49533 ==> 0.34911850302326747\n",
            "Loss in iteration no. 49534 ==> 0.3491174536093397\n",
            "Loss in iteration no. 49535 ==> 0.3491164042337976\n",
            "Loss in iteration no. 49536 ==> 0.3491153548966391\n",
            "Loss in iteration no. 49537 ==> 0.34911430559786255\n",
            "Loss in iteration no. 49538 ==> 0.34911325633746565\n",
            "Loss in iteration no. 49539 ==> 0.34911220711544655\n",
            "Loss in iteration no. 49540 ==> 0.34911115793180353\n",
            "Loss in iteration no. 49541 ==> 0.34911010878653437\n",
            "Loss in iteration no. 49542 ==> 0.3491090596796373\n",
            "Loss in iteration no. 49543 ==> 0.3491080106111101\n",
            "Loss in iteration no. 49544 ==> 0.3491069615809511\n",
            "Loss in iteration no. 49545 ==> 0.34910591258915824\n",
            "Loss in iteration no. 49546 ==> 0.34910486363572957\n",
            "Loss in iteration no. 49547 ==> 0.3491038147206631\n",
            "Loss in iteration no. 49548 ==> 0.349102765843957\n",
            "Loss in iteration no. 49549 ==> 0.34910171700560927\n",
            "Loss in iteration no. 49550 ==> 0.34910066820561786\n",
            "Loss in iteration no. 49551 ==> 0.34909961944398094\n",
            "Loss in iteration no. 49552 ==> 0.3490985707206965\n",
            "Loss in iteration no. 49553 ==> 0.34909752203576255\n",
            "Loss in iteration no. 49554 ==> 0.34909647338917726\n",
            "Loss in iteration no. 49555 ==> 0.34909542478093863\n",
            "Loss in iteration no. 49556 ==> 0.3490943762110446\n",
            "Loss in iteration no. 49557 ==> 0.3490933276794934\n",
            "Loss in iteration no. 49558 ==> 0.349092279186283\n",
            "Loss in iteration no. 49559 ==> 0.3490912307314114\n",
            "Loss in iteration no. 49560 ==> 0.3490901823148768\n",
            "Loss in iteration no. 49561 ==> 0.34908913393667707\n",
            "Loss in iteration no. 49562 ==> 0.34908808559681037\n",
            "Loss in iteration no. 49563 ==> 0.3490870372952748\n",
            "Loss in iteration no. 49564 ==> 0.3490859890320683\n",
            "Loss in iteration no. 49565 ==> 0.3490849408071888\n",
            "Loss in iteration no. 49566 ==> 0.3490838926206347\n",
            "Loss in iteration no. 49567 ==> 0.34908284447240384\n",
            "Loss in iteration no. 49568 ==> 0.3490817963624943\n",
            "Loss in iteration no. 49569 ==> 0.349080748290904\n",
            "Loss in iteration no. 49570 ==> 0.3490797002576313\n",
            "Loss in iteration no. 49571 ==> 0.349078652262674\n",
            "Loss in iteration no. 49572 ==> 0.3490776043060302\n",
            "Loss in iteration no. 49573 ==> 0.34907655638769797\n",
            "Loss in iteration no. 49574 ==> 0.3490755085076754\n",
            "Loss in iteration no. 49575 ==> 0.34907446066596054\n",
            "Loss in iteration no. 49576 ==> 0.34907341286255145\n",
            "Loss in iteration no. 49577 ==> 0.349072365097446\n",
            "Loss in iteration no. 49578 ==> 0.3490713173706426\n",
            "Loss in iteration no. 49579 ==> 0.34907026968213895\n",
            "Loss in iteration no. 49580 ==> 0.3490692220319333\n",
            "Loss in iteration no. 49581 ==> 0.3490681744200237\n",
            "Loss in iteration no. 49582 ==> 0.3490671268464081\n",
            "Loss in iteration no. 49583 ==> 0.3490660793110847\n",
            "Loss in iteration no. 49584 ==> 0.3490650318140514\n",
            "Loss in iteration no. 49585 ==> 0.34906398435530633\n",
            "Loss in iteration no. 49586 ==> 0.3490629369348475\n",
            "Loss in iteration no. 49587 ==> 0.3490618895526732\n",
            "Loss in iteration no. 49588 ==> 0.3490608422087811\n",
            "Loss in iteration no. 49589 ==> 0.3490597949031695\n",
            "Loss in iteration no. 49590 ==> 0.3490587476358364\n",
            "Loss in iteration no. 49591 ==> 0.3490577004067798\n",
            "Loss in iteration no. 49592 ==> 0.34905665321599794\n",
            "Loss in iteration no. 49593 ==> 0.3490556060634887\n",
            "Loss in iteration no. 49594 ==> 0.34905455894925014\n",
            "Loss in iteration no. 49595 ==> 0.3490535118732804\n",
            "Loss in iteration no. 49596 ==> 0.34905246483557745\n",
            "Loss in iteration no. 49597 ==> 0.34905141783613935\n",
            "Loss in iteration no. 49598 ==> 0.3490503708749642\n",
            "Loss in iteration no. 49599 ==> 0.3490493239520502\n",
            "Loss in iteration no. 49600 ==> 0.34904827706739516\n",
            "Loss in iteration no. 49601 ==> 0.3490472302209972\n",
            "Loss in iteration no. 49602 ==> 0.3490461834128544\n",
            "Loss in iteration no. 49603 ==> 0.34904513664296494\n",
            "Loss in iteration no. 49604 ==> 0.34904408991132674\n",
            "Loss in iteration no. 49605 ==> 0.34904304321793783\n",
            "Loss in iteration no. 49606 ==> 0.34904199656279633\n",
            "Loss in iteration no. 49607 ==> 0.3490409499459003\n",
            "Loss in iteration no. 49608 ==> 0.3490399033672478\n",
            "Loss in iteration no. 49609 ==> 0.3490388568268369\n",
            "Loss in iteration no. 49610 ==> 0.3490378103246655\n",
            "Loss in iteration no. 49611 ==> 0.3490367638607319\n",
            "Loss in iteration no. 49612 ==> 0.3490357174350341\n",
            "Loss in iteration no. 49613 ==> 0.34903467104756997\n",
            "Loss in iteration no. 49614 ==> 0.34903362469833776\n",
            "Loss in iteration no. 49615 ==> 0.3490325783873355\n",
            "Loss in iteration no. 49616 ==> 0.34903153211456117\n",
            "Loss in iteration no. 49617 ==> 0.3490304858800129\n",
            "Loss in iteration no. 49618 ==> 0.34902943968368877\n",
            "Loss in iteration no. 49619 ==> 0.3490283935255867\n",
            "Loss in iteration no. 49620 ==> 0.3490273474057049\n",
            "Loss in iteration no. 49621 ==> 0.3490263013240414\n",
            "Loss in iteration no. 49622 ==> 0.3490252552805942\n",
            "Loss in iteration no. 49623 ==> 0.3490242092753614\n",
            "Loss in iteration no. 49624 ==> 0.34902316330834093\n",
            "Loss in iteration no. 49625 ==> 0.34902211737953115\n",
            "Loss in iteration no. 49626 ==> 0.34902107148892986\n",
            "Loss in iteration no. 49627 ==> 0.3490200256365352\n",
            "Loss in iteration no. 49628 ==> 0.3490189798223453\n",
            "Loss in iteration no. 49629 ==> 0.34901793404635806\n",
            "Loss in iteration no. 49630 ==> 0.3490168883085717\n",
            "Loss in iteration no. 49631 ==> 0.3490158426089841\n",
            "Loss in iteration no. 49632 ==> 0.3490147969475936\n",
            "Loss in iteration no. 49633 ==> 0.349013751324398\n",
            "Loss in iteration no. 49634 ==> 0.3490127057393954\n",
            "Loss in iteration no. 49635 ==> 0.34901166019258406\n",
            "Loss in iteration no. 49636 ==> 0.34901061468396183\n",
            "Loss in iteration no. 49637 ==> 0.34900956921352677\n",
            "Loss in iteration no. 49638 ==> 0.3490085237812771\n",
            "Loss in iteration no. 49639 ==> 0.34900747838721075\n",
            "Loss in iteration no. 49640 ==> 0.34900643303132584\n",
            "Loss in iteration no. 49641 ==> 0.34900538771362033\n",
            "Loss in iteration no. 49642 ==> 0.3490043424340925\n",
            "Loss in iteration no. 49643 ==> 0.3490032971927402\n",
            "Loss in iteration no. 49644 ==> 0.3490022519895615\n",
            "Loss in iteration no. 49645 ==> 0.34900120682455466\n",
            "Loss in iteration no. 49646 ==> 0.3490001616977176\n",
            "Loss in iteration no. 49647 ==> 0.34899911660904825\n",
            "Loss in iteration no. 49648 ==> 0.34899807155854495\n",
            "Loss in iteration no. 49649 ==> 0.3489970265462056\n",
            "Loss in iteration no. 49650 ==> 0.3489959815720283\n",
            "Loss in iteration no. 49651 ==> 0.3489949366360111\n",
            "Loss in iteration no. 49652 ==> 0.3489938917381521\n",
            "Loss in iteration no. 49653 ==> 0.3489928468784493\n",
            "Loss in iteration no. 49654 ==> 0.34899180205690084\n",
            "Loss in iteration no. 49655 ==> 0.34899075727350465\n",
            "Loss in iteration no. 49656 ==> 0.34898971252825894\n",
            "Loss in iteration no. 49657 ==> 0.34898866782116167\n",
            "Loss in iteration no. 49658 ==> 0.34898762315221105\n",
            "Loss in iteration no. 49659 ==> 0.348986578521405\n",
            "Loss in iteration no. 49660 ==> 0.3489855339287416\n",
            "Loss in iteration no. 49661 ==> 0.348984489374219\n",
            "Loss in iteration no. 49662 ==> 0.3489834448578352\n",
            "Loss in iteration no. 49663 ==> 0.34898240037958816\n",
            "Loss in iteration no. 49664 ==> 0.34898135593947616\n",
            "Loss in iteration no. 49665 ==> 0.34898031153749715\n",
            "Loss in iteration no. 49666 ==> 0.34897926717364924\n",
            "Loss in iteration no. 49667 ==> 0.3489782228479304\n",
            "Loss in iteration no. 49668 ==> 0.3489771785603387\n",
            "Loss in iteration no. 49669 ==> 0.3489761343108724\n",
            "Loss in iteration no. 49670 ==> 0.3489750900995294\n",
            "Loss in iteration no. 49671 ==> 0.34897404592630765\n",
            "Loss in iteration no. 49672 ==> 0.3489730017912055\n",
            "Loss in iteration no. 49673 ==> 0.3489719576942209\n",
            "Loss in iteration no. 49674 ==> 0.3489709136353519\n",
            "Loss in iteration no. 49675 ==> 0.3489698696145963\n",
            "Loss in iteration no. 49676 ==> 0.3489688256319527\n",
            "Loss in iteration no. 49677 ==> 0.34896778168741877\n",
            "Loss in iteration no. 49678 ==> 0.34896673778099274\n",
            "Loss in iteration no. 49679 ==> 0.3489656939126727\n",
            "Loss in iteration no. 49680 ==> 0.3489646500824565\n",
            "Loss in iteration no. 49681 ==> 0.34896360629034245\n",
            "Loss in iteration no. 49682 ==> 0.34896256253632846\n",
            "Loss in iteration no. 49683 ==> 0.34896151882041276\n",
            "Loss in iteration no. 49684 ==> 0.34896047514259326\n",
            "Loss in iteration no. 49685 ==> 0.34895943150286807\n",
            "Loss in iteration no. 49686 ==> 0.3489583879012352\n",
            "Loss in iteration no. 49687 ==> 0.34895734433769293\n",
            "Loss in iteration no. 49688 ==> 0.3489563008122391\n",
            "Loss in iteration no. 49689 ==> 0.34895525732487187\n",
            "Loss in iteration no. 49690 ==> 0.3489542138755893\n",
            "Loss in iteration no. 49691 ==> 0.3489531704643895\n",
            "Loss in iteration no. 49692 ==> 0.3489521270912705\n",
            "Loss in iteration no. 49693 ==> 0.3489510837562303\n",
            "Loss in iteration no. 49694 ==> 0.3489500404592671\n",
            "Loss in iteration no. 49695 ==> 0.3489489972003789\n",
            "Loss in iteration no. 49696 ==> 0.34894795397956363\n",
            "Loss in iteration no. 49697 ==> 0.3489469107968197\n",
            "Loss in iteration no. 49698 ==> 0.34894586765214497\n",
            "Loss in iteration no. 49699 ==> 0.3489448245455374\n",
            "Loss in iteration no. 49700 ==> 0.3489437814769953\n",
            "Loss in iteration no. 49701 ==> 0.34894273844651646\n",
            "Loss in iteration no. 49702 ==> 0.34894169545409925\n",
            "Loss in iteration no. 49703 ==> 0.3489406524997415\n",
            "Loss in iteration no. 49704 ==> 0.3489396095834414\n",
            "Loss in iteration no. 49705 ==> 0.3489385667051971\n",
            "Loss in iteration no. 49706 ==> 0.3489375238650065\n",
            "Loss in iteration no. 49707 ==> 0.34893648106286773\n",
            "Loss in iteration no. 49708 ==> 0.34893543829877877\n",
            "Loss in iteration no. 49709 ==> 0.34893439557273787\n",
            "Loss in iteration no. 49710 ==> 0.34893335288474303\n",
            "Loss in iteration no. 49711 ==> 0.3489323102347924\n",
            "Loss in iteration no. 49712 ==> 0.34893126762288373\n",
            "Loss in iteration no. 49713 ==> 0.34893022504901555\n",
            "Loss in iteration no. 49714 ==> 0.34892918251318555\n",
            "Loss in iteration no. 49715 ==> 0.348928140015392\n",
            "Loss in iteration no. 49716 ==> 0.34892709755563295\n",
            "Loss in iteration no. 49717 ==> 0.3489260551339064\n",
            "Loss in iteration no. 49718 ==> 0.3489250127502105\n",
            "Loss in iteration no. 49719 ==> 0.34892397040454326\n",
            "Loss in iteration no. 49720 ==> 0.34892292809690284\n",
            "Loss in iteration no. 49721 ==> 0.34892188582728717\n",
            "Loss in iteration no. 49722 ==> 0.3489208435956944\n",
            "Loss in iteration no. 49723 ==> 0.34891980140212264\n",
            "Loss in iteration no. 49724 ==> 0.34891875924657\n",
            "Loss in iteration no. 49725 ==> 0.3489177171290344\n",
            "Loss in iteration no. 49726 ==> 0.3489166750495141\n",
            "Loss in iteration no. 49727 ==> 0.34891563300800693\n",
            "Loss in iteration no. 49728 ==> 0.3489145910045111\n",
            "Loss in iteration no. 49729 ==> 0.3489135490390248\n",
            "Loss in iteration no. 49730 ==> 0.3489125071115459\n",
            "Loss in iteration no. 49731 ==> 0.34891146522207256\n",
            "Loss in iteration no. 49732 ==> 0.3489104233706029\n",
            "Loss in iteration no. 49733 ==> 0.34890938155713486\n",
            "Loss in iteration no. 49734 ==> 0.34890833978166663\n",
            "Loss in iteration no. 49735 ==> 0.3489072980441963\n",
            "Loss in iteration no. 49736 ==> 0.34890625634472183\n",
            "Loss in iteration no. 49737 ==> 0.3489052146832414\n",
            "Loss in iteration no. 49738 ==> 0.34890417305975313\n",
            "Loss in iteration no. 49739 ==> 0.3489031314742549\n",
            "Loss in iteration no. 49740 ==> 0.3489020899267448\n",
            "Loss in iteration no. 49741 ==> 0.34890104841722114\n",
            "Loss in iteration no. 49742 ==> 0.3489000069456818\n",
            "Loss in iteration no. 49743 ==> 0.34889896551212496\n",
            "Loss in iteration no. 49744 ==> 0.3488979241165486\n",
            "Loss in iteration no. 49745 ==> 0.34889688275895075\n",
            "Loss in iteration no. 49746 ==> 0.34889584143932967\n",
            "Loss in iteration no. 49747 ==> 0.34889480015768337\n",
            "Loss in iteration no. 49748 ==> 0.3488937589140098\n",
            "Loss in iteration no. 49749 ==> 0.3488927177083072\n",
            "Loss in iteration no. 49750 ==> 0.3488916765405735\n",
            "Loss in iteration no. 49751 ==> 0.3488906354108069\n",
            "Loss in iteration no. 49752 ==> 0.34888959431900535\n",
            "Loss in iteration no. 49753 ==> 0.3488885532651671\n",
            "Loss in iteration no. 49754 ==> 0.3488875122492901\n",
            "Loss in iteration no. 49755 ==> 0.3488864712713724\n",
            "Loss in iteration no. 49756 ==> 0.34888543033141217\n",
            "Loss in iteration no. 49757 ==> 0.34888438942940747\n",
            "Loss in iteration no. 49758 ==> 0.34888334856535635\n",
            "Loss in iteration no. 49759 ==> 0.3488823077392568\n",
            "Loss in iteration no. 49760 ==> 0.34888126695110705\n",
            "Loss in iteration no. 49761 ==> 0.3488802262009051\n",
            "Loss in iteration no. 49762 ==> 0.34887918548864905\n",
            "Loss in iteration no. 49763 ==> 0.34887814481433693\n",
            "Loss in iteration no. 49764 ==> 0.3488771041779669\n",
            "Loss in iteration no. 49765 ==> 0.348876063579537\n",
            "Loss in iteration no. 49766 ==> 0.3488750230190452\n",
            "Loss in iteration no. 49767 ==> 0.3488739824964898\n",
            "Loss in iteration no. 49768 ==> 0.3488729420118687\n",
            "Loss in iteration no. 49769 ==> 0.34887190156518005\n",
            "Loss in iteration no. 49770 ==> 0.34887086115642185\n",
            "Loss in iteration no. 49771 ==> 0.34886982078559226\n",
            "Loss in iteration no. 49772 ==> 0.3488687804526893\n",
            "Loss in iteration no. 49773 ==> 0.3488677401577112\n",
            "Loss in iteration no. 49774 ==> 0.3488666999006559\n",
            "Loss in iteration no. 49775 ==> 0.34886565968152145\n",
            "Loss in iteration no. 49776 ==> 0.348864619500306\n",
            "Loss in iteration no. 49777 ==> 0.3488635793570076\n",
            "Loss in iteration no. 49778 ==> 0.3488625392516244\n",
            "Loss in iteration no. 49779 ==> 0.3488614991841543\n",
            "Loss in iteration no. 49780 ==> 0.3488604591545956\n",
            "Loss in iteration no. 49781 ==> 0.34885941916294627\n",
            "Loss in iteration no. 49782 ==> 0.34885837920920443\n",
            "Loss in iteration no. 49783 ==> 0.348857339293368\n",
            "Loss in iteration no. 49784 ==> 0.3488562994154352\n",
            "Loss in iteration no. 49785 ==> 0.3488552595754042\n",
            "Loss in iteration no. 49786 ==> 0.348854219773273\n",
            "Loss in iteration no. 49787 ==> 0.3488531800090396\n",
            "Loss in iteration no. 49788 ==> 0.34885214028270217\n",
            "Loss in iteration no. 49789 ==> 0.3488511005942586\n",
            "Loss in iteration no. 49790 ==> 0.3488500609437073\n",
            "Loss in iteration no. 49791 ==> 0.3488490213310461\n",
            "Loss in iteration no. 49792 ==> 0.34884798175627324\n",
            "Loss in iteration no. 49793 ==> 0.34884694221938667\n",
            "Loss in iteration no. 49794 ==> 0.34884590272038446\n",
            "Loss in iteration no. 49795 ==> 0.34884486325926495\n",
            "Loss in iteration no. 49796 ==> 0.34884382383602575\n",
            "Loss in iteration no. 49797 ==> 0.34884278445066547\n",
            "Loss in iteration no. 49798 ==> 0.3488417451031818\n",
            "Loss in iteration no. 49799 ==> 0.34884070579357296\n",
            "Loss in iteration no. 49800 ==> 0.3488396665218371\n",
            "Loss in iteration no. 49801 ==> 0.34883862728797216\n",
            "Loss in iteration no. 49802 ==> 0.34883758809197635\n",
            "Loss in iteration no. 49803 ==> 0.3488365489338477\n",
            "Loss in iteration no. 49804 ==> 0.34883550981358424\n",
            "Loss in iteration no. 49805 ==> 0.3488344707311841\n",
            "Loss in iteration no. 49806 ==> 0.3488334316866455\n",
            "Loss in iteration no. 49807 ==> 0.3488323926799663\n",
            "Loss in iteration no. 49808 ==> 0.3488313537111446\n",
            "Loss in iteration no. 49809 ==> 0.3488303147801786\n",
            "Loss in iteration no. 49810 ==> 0.34882927588706647\n",
            "Loss in iteration no. 49811 ==> 0.34882823703180604\n",
            "Loss in iteration no. 49812 ==> 0.34882719821439545\n",
            "Loss in iteration no. 49813 ==> 0.3488261594348329\n",
            "Loss in iteration no. 49814 ==> 0.34882512069311655\n",
            "Loss in iteration no. 49815 ==> 0.34882408198924425\n",
            "Loss in iteration no. 49816 ==> 0.34882304332321423\n",
            "Loss in iteration no. 49817 ==> 0.34882200469502445\n",
            "Loss in iteration no. 49818 ==> 0.3488209661046731\n",
            "Loss in iteration no. 49819 ==> 0.3488199275521583\n",
            "Loss in iteration no. 49820 ==> 0.34881888903747815\n",
            "Loss in iteration no. 49821 ==> 0.3488178505606305\n",
            "Loss in iteration no. 49822 ==> 0.34881681212161375\n",
            "Loss in iteration no. 49823 ==> 0.34881577372042566\n",
            "Loss in iteration no. 49824 ==> 0.34881473535706464\n",
            "Loss in iteration no. 49825 ==> 0.3488136970315284\n",
            "Loss in iteration no. 49826 ==> 0.3488126587438155\n",
            "Loss in iteration no. 49827 ==> 0.34881162049392367\n",
            "Loss in iteration no. 49828 ==> 0.34881058228185113\n",
            "Loss in iteration no. 49829 ==> 0.34880954410759585\n",
            "Loss in iteration no. 49830 ==> 0.348808505971156\n",
            "Loss in iteration no. 49831 ==> 0.3488074678725298\n",
            "Loss in iteration no. 49832 ==> 0.348806429811715\n",
            "Loss in iteration no. 49833 ==> 0.34880539178871006\n",
            "Loss in iteration no. 49834 ==> 0.3488043538035129\n",
            "Loss in iteration no. 49835 ==> 0.34880331585612145\n",
            "Loss in iteration no. 49836 ==> 0.34880227794653407\n",
            "Loss in iteration no. 49837 ==> 0.34880124007474866\n",
            "Loss in iteration no. 49838 ==> 0.3488002022407634\n",
            "Loss in iteration no. 49839 ==> 0.34879916444457637\n",
            "Loss in iteration no. 49840 ==> 0.3487981266861856\n",
            "Loss in iteration no. 49841 ==> 0.3487970889655892\n",
            "Loss in iteration no. 49842 ==> 0.34879605128278535\n",
            "Loss in iteration no. 49843 ==> 0.34879501363777193\n",
            "Loss in iteration no. 49844 ==> 0.3487939760305471\n",
            "Loss in iteration no. 49845 ==> 0.3487929384611092\n",
            "Loss in iteration no. 49846 ==> 0.34879190092945606\n",
            "Loss in iteration no. 49847 ==> 0.34879086343558574\n",
            "Loss in iteration no. 49848 ==> 0.3487898259794965\n",
            "Loss in iteration no. 49849 ==> 0.3487887885611862\n",
            "Loss in iteration no. 49850 ==> 0.34878775118065325\n",
            "Loss in iteration no. 49851 ==> 0.34878671383789545\n",
            "Loss in iteration no. 49852 ==> 0.3487856765329109\n",
            "Loss in iteration no. 49853 ==> 0.348784639265698\n",
            "Loss in iteration no. 49854 ==> 0.3487836020362545\n",
            "Loss in iteration no. 49855 ==> 0.34878256484457865\n",
            "Loss in iteration no. 49856 ==> 0.34878152769066856\n",
            "Loss in iteration no. 49857 ==> 0.3487804905745222\n",
            "Loss in iteration no. 49858 ==> 0.3487794534961377\n",
            "Loss in iteration no. 49859 ==> 0.34877841645551316\n",
            "Loss in iteration no. 49860 ==> 0.3487773794526467\n",
            "Loss in iteration no. 49861 ==> 0.34877634248753636\n",
            "Loss in iteration no. 49862 ==> 0.3487753055601803\n",
            "Loss in iteration no. 49863 ==> 0.3487742686705766\n",
            "Loss in iteration no. 49864 ==> 0.3487732318187233\n",
            "Loss in iteration no. 49865 ==> 0.34877219500461853\n",
            "Loss in iteration no. 49866 ==> 0.34877115822826027\n",
            "Loss in iteration no. 49867 ==> 0.34877012148964676\n",
            "Loss in iteration no. 49868 ==> 0.348769084788776\n",
            "Loss in iteration no. 49869 ==> 0.34876804812564616\n",
            "Loss in iteration no. 49870 ==> 0.3487670115002552\n",
            "Loss in iteration no. 49871 ==> 0.3487659749126013\n",
            "Loss in iteration no. 49872 ==> 0.3487649383626826\n",
            "Loss in iteration no. 49873 ==> 0.34876390185049705\n",
            "Loss in iteration no. 49874 ==> 0.3487628653760429\n",
            "Loss in iteration no. 49875 ==> 0.3487618289393181\n",
            "Loss in iteration no. 49876 ==> 0.3487607925403209\n",
            "Loss in iteration no. 49877 ==> 0.3487597561790492\n",
            "Loss in iteration no. 49878 ==> 0.3487587198555012\n",
            "Loss in iteration no. 49879 ==> 0.34875768356967507\n",
            "Loss in iteration no. 49880 ==> 0.34875664732156886\n",
            "Loss in iteration no. 49881 ==> 0.3487556111111804\n",
            "Loss in iteration no. 49882 ==> 0.34875457493850814\n",
            "Loss in iteration no. 49883 ==> 0.34875353880355003\n",
            "Loss in iteration no. 49884 ==> 0.34875250270630415\n",
            "Loss in iteration no. 49885 ==> 0.3487514666467686\n",
            "Loss in iteration no. 49886 ==> 0.3487504306249415\n",
            "Loss in iteration no. 49887 ==> 0.34874939464082094\n",
            "Loss in iteration no. 49888 ==> 0.34874835869440496\n",
            "Loss in iteration no. 49889 ==> 0.3487473227856917\n",
            "Loss in iteration no. 49890 ==> 0.3487462869146791\n",
            "Loss in iteration no. 49891 ==> 0.3487452510813656\n",
            "Loss in iteration no. 49892 ==> 0.34874421528574906\n",
            "Loss in iteration no. 49893 ==> 0.3487431795278276\n",
            "Loss in iteration no. 49894 ==> 0.34874214380759916\n",
            "Loss in iteration no. 49895 ==> 0.3487411081250621\n",
            "Loss in iteration no. 49896 ==> 0.34874007248021444\n",
            "Loss in iteration no. 49897 ==> 0.34873903687305424\n",
            "Loss in iteration no. 49898 ==> 0.3487380013035795\n",
            "Loss in iteration no. 49899 ==> 0.3487369657717884\n",
            "Loss in iteration no. 49900 ==> 0.34873593027767913\n",
            "Loss in iteration no. 49901 ==> 0.34873489482124975\n",
            "Loss in iteration no. 49902 ==> 0.3487338594024982\n",
            "Loss in iteration no. 49903 ==> 0.3487328240214227\n",
            "Loss in iteration no. 49904 ==> 0.34873178867802135\n",
            "Loss in iteration no. 49905 ==> 0.34873075337229215\n",
            "Loss in iteration no. 49906 ==> 0.34872971810423326\n",
            "Loss in iteration no. 49907 ==> 0.34872868287384284\n",
            "Loss in iteration no. 49908 ==> 0.3487276476811188\n",
            "Loss in iteration no. 49909 ==> 0.3487266125260595\n",
            "Loss in iteration no. 49910 ==> 0.3487255774086628\n",
            "Loss in iteration no. 49911 ==> 0.3487245423289269\n",
            "Loss in iteration no. 49912 ==> 0.3487235072868499\n",
            "Loss in iteration no. 49913 ==> 0.3487224722824299\n",
            "Loss in iteration no. 49914 ==> 0.34872143731566496\n",
            "Loss in iteration no. 49915 ==> 0.3487204023865533\n",
            "Loss in iteration no. 49916 ==> 0.34871936749509275\n",
            "Loss in iteration no. 49917 ==> 0.3487183326412816\n",
            "Loss in iteration no. 49918 ==> 0.3487172978251179\n",
            "Loss in iteration no. 49919 ==> 0.34871626304659986\n",
            "Loss in iteration no. 49920 ==> 0.3487152283057254\n",
            "Loss in iteration no. 49921 ==> 0.3487141936024927\n",
            "Loss in iteration no. 49922 ==> 0.34871315893689986\n",
            "Loss in iteration no. 49923 ==> 0.348712124308945\n",
            "Loss in iteration no. 49924 ==> 0.3487110897186262\n",
            "Loss in iteration no. 49925 ==> 0.34871005516594145\n",
            "Loss in iteration no. 49926 ==> 0.348709020650889\n",
            "Loss in iteration no. 49927 ==> 0.3487079861734668\n",
            "Loss in iteration no. 49928 ==> 0.3487069517336731\n",
            "Loss in iteration no. 49929 ==> 0.348705917331506\n",
            "Loss in iteration no. 49930 ==> 0.3487048829669635\n",
            "Loss in iteration no. 49931 ==> 0.3487038486400437\n",
            "Loss in iteration no. 49932 ==> 0.3487028143507448\n",
            "Loss in iteration no. 49933 ==> 0.3487017800990647\n",
            "Loss in iteration no. 49934 ==> 0.3487007458850018\n",
            "Loss in iteration no. 49935 ==> 0.3486997117085539\n",
            "Loss in iteration no. 49936 ==> 0.3486986775697193\n",
            "Loss in iteration no. 49937 ==> 0.3486976434684959\n",
            "Loss in iteration no. 49938 ==> 0.34869660940488206\n",
            "Loss in iteration no. 49939 ==> 0.34869557537887574\n",
            "Loss in iteration no. 49940 ==> 0.34869454139047495\n",
            "Loss in iteration no. 49941 ==> 0.348693507439678\n",
            "Loss in iteration no. 49942 ==> 0.34869247352648275\n",
            "Loss in iteration no. 49943 ==> 0.34869143965088745\n",
            "Loss in iteration no. 49944 ==> 0.34869040581289035\n",
            "Loss in iteration no. 49945 ==> 0.3486893720124892\n",
            "Loss in iteration no. 49946 ==> 0.3486883382496822\n",
            "Loss in iteration no. 49947 ==> 0.3486873045244677\n",
            "Loss in iteration no. 49948 ==> 0.3486862708368435\n",
            "Loss in iteration no. 49949 ==> 0.34868523718680783\n",
            "Loss in iteration no. 49950 ==> 0.34868420357435886\n",
            "Loss in iteration no. 49951 ==> 0.34868316999949456\n",
            "Loss in iteration no. 49952 ==> 0.3486821364622132\n",
            "Loss in iteration no. 49953 ==> 0.3486811029625127\n",
            "Loss in iteration no. 49954 ==> 0.34868006950039115\n",
            "Loss in iteration no. 49955 ==> 0.3486790360758469\n",
            "Loss in iteration no. 49956 ==> 0.34867800268887766\n",
            "Loss in iteration no. 49957 ==> 0.34867696933948195\n",
            "Loss in iteration no. 49958 ==> 0.34867593602765756\n",
            "Loss in iteration no. 49959 ==> 0.34867490275340274\n",
            "Loss in iteration no. 49960 ==> 0.3486738695167156\n",
            "Loss in iteration no. 49961 ==> 0.34867283631759416\n",
            "Loss in iteration no. 49962 ==> 0.3486718031560366\n",
            "Loss in iteration no. 49963 ==> 0.34867077003204094\n",
            "Loss in iteration no. 49964 ==> 0.34866973694560527\n",
            "Loss in iteration no. 49965 ==> 0.3486687038967279\n",
            "Loss in iteration no. 49966 ==> 0.3486676708854067\n",
            "Loss in iteration no. 49967 ==> 0.34866663791163993\n",
            "Loss in iteration no. 49968 ==> 0.34866560497542554\n",
            "Loss in iteration no. 49969 ==> 0.3486645720767617\n",
            "Loss in iteration no. 49970 ==> 0.3486635392156465\n",
            "Loss in iteration no. 49971 ==> 0.3486625063920782\n",
            "Loss in iteration no. 49972 ==> 0.34866147360605465\n",
            "Loss in iteration no. 49973 ==> 0.3486604408575742\n",
            "Loss in iteration no. 49974 ==> 0.3486594081466348\n",
            "Loss in iteration no. 49975 ==> 0.3486583754732345\n",
            "Loss in iteration no. 49976 ==> 0.34865734283737154\n",
            "Loss in iteration no. 49977 ==> 0.3486563102390439\n",
            "Loss in iteration no. 49978 ==> 0.3486552776782499\n",
            "Loss in iteration no. 49979 ==> 0.3486542451549875\n",
            "Loss in iteration no. 49980 ==> 0.3486532126692547\n",
            "Loss in iteration no. 49981 ==> 0.34865218022104977\n",
            "Loss in iteration no. 49982 ==> 0.3486511478103707\n",
            "Loss in iteration no. 49983 ==> 0.34865011543721575\n",
            "Loss in iteration no. 49984 ==> 0.3486490831015828\n",
            "Loss in iteration no. 49985 ==> 0.3486480508034701\n",
            "Loss in iteration no. 49986 ==> 0.3486470185428759\n",
            "Loss in iteration no. 49987 ==> 0.348645986319798\n",
            "Loss in iteration no. 49988 ==> 0.3486449541342347\n",
            "Loss in iteration no. 49989 ==> 0.348643921986184\n",
            "Loss in iteration no. 49990 ==> 0.3486428898756441\n",
            "Loss in iteration no. 49991 ==> 0.34864185780261303\n",
            "Loss in iteration no. 49992 ==> 0.3486408257670889\n",
            "Loss in iteration no. 49993 ==> 0.3486397937690699\n",
            "Loss in iteration no. 49994 ==> 0.34863876180855413\n",
            "Loss in iteration no. 49995 ==> 0.34863772988553965\n",
            "Loss in iteration no. 49996 ==> 0.34863669800002445\n",
            "Loss in iteration no. 49997 ==> 0.34863566615200675\n",
            "Loss in iteration no. 49998 ==> 0.34863463434148484\n",
            "Loss in iteration no. 49999 ==> 0.3486336025684565\n",
            "Loss in iteration no. 50000 ==> 0.34863257083292\n",
            "Loss in iteration no. 50001 ==> 0.34863153913487344\n",
            "Loss in iteration no. 50002 ==> 0.34863050747431484\n",
            "Loss in iteration no. 50003 ==> 0.3486294758512426\n",
            "Loss in iteration no. 50004 ==> 0.34862844426565437\n",
            "Loss in iteration no. 50005 ==> 0.34862741271754866\n",
            "Loss in iteration no. 50006 ==> 0.34862638120692335\n",
            "Loss in iteration no. 50007 ==> 0.3486253497337765\n",
            "Loss in iteration no. 50008 ==> 0.3486243182981066\n",
            "Loss in iteration no. 50009 ==> 0.3486232868999113\n",
            "Loss in iteration no. 50010 ==> 0.34862225553918896\n",
            "Loss in iteration no. 50011 ==> 0.3486212242159376\n",
            "Loss in iteration no. 50012 ==> 0.3486201929301554\n",
            "Loss in iteration no. 50013 ==> 0.34861916168184043\n",
            "Loss in iteration no. 50014 ==> 0.3486181304709908\n",
            "Loss in iteration no. 50015 ==> 0.3486170992976046\n",
            "Loss in iteration no. 50016 ==> 0.34861606816167984\n",
            "Loss in iteration no. 50017 ==> 0.34861503706321484\n",
            "Loss in iteration no. 50018 ==> 0.34861400600220765\n",
            "Loss in iteration no. 50019 ==> 0.34861297497865623\n",
            "Loss in iteration no. 50020 ==> 0.3486119439925588\n",
            "Loss in iteration no. 50021 ==> 0.34861091304391356\n",
            "Loss in iteration no. 50022 ==> 0.3486098821327185\n",
            "Loss in iteration no. 50023 ==> 0.34860885125897173\n",
            "Loss in iteration no. 50024 ==> 0.34860782042267147\n",
            "Loss in iteration no. 50025 ==> 0.3486067896238157\n",
            "Loss in iteration no. 50026 ==> 0.3486057588624025\n",
            "Loss in iteration no. 50027 ==> 0.3486047281384301\n",
            "Loss in iteration no. 50028 ==> 0.34860369745189657\n",
            "Loss in iteration no. 50029 ==> 0.34860266680280005\n",
            "Loss in iteration no. 50030 ==> 0.34860163619113865\n",
            "Loss in iteration no. 50031 ==> 0.3486006056169105\n",
            "Loss in iteration no. 50032 ==> 0.3485995750801135\n",
            "Loss in iteration no. 50033 ==> 0.348598544580746\n",
            "Loss in iteration no. 50034 ==> 0.348597514118806\n",
            "Loss in iteration no. 50035 ==> 0.3485964836942917\n",
            "Loss in iteration no. 50036 ==> 0.3485954533072011\n",
            "Loss in iteration no. 50037 ==> 0.34859442295753246\n",
            "Loss in iteration no. 50038 ==> 0.3485933926452837\n",
            "Loss in iteration no. 50039 ==> 0.34859236237045316\n",
            "Loss in iteration no. 50040 ==> 0.3485913321330387\n",
            "Loss in iteration no. 50041 ==> 0.3485903019330386\n",
            "Loss in iteration no. 50042 ==> 0.34858927177045096\n",
            "Loss in iteration no. 50043 ==> 0.3485882416452738\n",
            "Loss in iteration no. 50044 ==> 0.3485872115575053\n",
            "Loss in iteration no. 50045 ==> 0.3485861815071436\n",
            "Loss in iteration no. 50046 ==> 0.34858515149418673\n",
            "Loss in iteration no. 50047 ==> 0.34858412151863294\n",
            "Loss in iteration no. 50048 ==> 0.3485830915804802\n",
            "Loss in iteration no. 50049 ==> 0.3485820616797267\n",
            "Loss in iteration no. 50050 ==> 0.34858103181637046\n",
            "Loss in iteration no. 50051 ==> 0.3485800019904097\n",
            "Loss in iteration no. 50052 ==> 0.34857897220184253\n",
            "Loss in iteration no. 50053 ==> 0.348577942450667\n",
            "Loss in iteration no. 50054 ==> 0.3485769127368813\n",
            "Loss in iteration no. 50055 ==> 0.3485758830604834\n",
            "Loss in iteration no. 50056 ==> 0.3485748534214717\n",
            "Loss in iteration no. 50057 ==> 0.3485738238198439\n",
            "Loss in iteration no. 50058 ==> 0.34857279425559845\n",
            "Loss in iteration no. 50059 ==> 0.34857176472873336\n",
            "Loss in iteration no. 50060 ==> 0.34857073523924675\n",
            "Loss in iteration no. 50061 ==> 0.34856970578713675\n",
            "Loss in iteration no. 50062 ==> 0.34856867637240135\n",
            "Loss in iteration no. 50063 ==> 0.34856764699503884\n",
            "Loss in iteration no. 50064 ==> 0.34856661765504726\n",
            "Loss in iteration no. 50065 ==> 0.3485655883524247\n",
            "Loss in iteration no. 50066 ==> 0.34856455908716927\n",
            "Loss in iteration no. 50067 ==> 0.34856352985927913\n",
            "Loss in iteration no. 50068 ==> 0.3485625006687524\n",
            "Loss in iteration no. 50069 ==> 0.34856147151558714\n",
            "Loss in iteration no. 50070 ==> 0.3485604423997816\n",
            "Loss in iteration no. 50071 ==> 0.34855941332133367\n",
            "Loss in iteration no. 50072 ==> 0.34855838428024166\n",
            "Loss in iteration no. 50073 ==> 0.3485573552765036\n",
            "Loss in iteration no. 50074 ==> 0.3485563263101176\n",
            "Loss in iteration no. 50075 ==> 0.34855529738108193\n",
            "Loss in iteration no. 50076 ==> 0.34855426848939436\n",
            "Loss in iteration no. 50077 ==> 0.3485532396350534\n",
            "Loss in iteration no. 50078 ==> 0.3485522108180569\n",
            "Loss in iteration no. 50079 ==> 0.3485511820384032\n",
            "Loss in iteration no. 50080 ==> 0.3485501532960901\n",
            "Loss in iteration no. 50081 ==> 0.3485491245911159\n",
            "Loss in iteration no. 50082 ==> 0.3485480959234789\n",
            "Loss in iteration no. 50083 ==> 0.34854706729317697\n",
            "Loss in iteration no. 50084 ==> 0.3485460387002083\n",
            "Loss in iteration no. 50085 ==> 0.34854501014457084\n",
            "Loss in iteration no. 50086 ==> 0.348543981626263\n",
            "Loss in iteration no. 50087 ==> 0.3485429531452828\n",
            "Loss in iteration no. 50088 ==> 0.34854192470162826\n",
            "Loss in iteration no. 50089 ==> 0.34854089629529766\n",
            "Loss in iteration no. 50090 ==> 0.34853986792628894\n",
            "Loss in iteration no. 50091 ==> 0.34853883959460025\n",
            "Loss in iteration no. 50092 ==> 0.3485378113002298\n",
            "Loss in iteration no. 50093 ==> 0.34853678304317565\n",
            "Loss in iteration no. 50094 ==> 0.348535754823436\n",
            "Loss in iteration no. 50095 ==> 0.3485347266410089\n",
            "Loss in iteration no. 50096 ==> 0.34853369849589244\n",
            "Loss in iteration no. 50097 ==> 0.3485326703880847\n",
            "Loss in iteration no. 50098 ==> 0.34853164231758393\n",
            "Loss in iteration no. 50099 ==> 0.34853061428438825\n",
            "Loss in iteration no. 50100 ==> 0.3485295862884957\n",
            "Loss in iteration no. 50101 ==> 0.3485285583299043\n",
            "Loss in iteration no. 50102 ==> 0.3485275304086124\n",
            "Loss in iteration no. 50103 ==> 0.34852650252461786\n",
            "Loss in iteration no. 50104 ==> 0.3485254746779191\n",
            "Loss in iteration no. 50105 ==> 0.34852444686851414\n",
            "Loss in iteration no. 50106 ==> 0.3485234190964009\n",
            "Loss in iteration no. 50107 ==> 0.34852239136157764\n",
            "Loss in iteration no. 50108 ==> 0.34852136366404257\n",
            "Loss in iteration no. 50109 ==> 0.3485203360037938\n",
            "Loss in iteration no. 50110 ==> 0.34851930838082923\n",
            "Loss in iteration no. 50111 ==> 0.3485182807951472\n",
            "Loss in iteration no. 50112 ==> 0.3485172532467457\n",
            "Loss in iteration no. 50113 ==> 0.348516225735623\n",
            "Loss in iteration no. 50114 ==> 0.34851519826177707\n",
            "Loss in iteration no. 50115 ==> 0.34851417082520614\n",
            "Loss in iteration no. 50116 ==> 0.3485131434259082\n",
            "Loss in iteration no. 50117 ==> 0.3485121160638816\n",
            "Loss in iteration no. 50118 ==> 0.34851108873912423\n",
            "Loss in iteration no. 50119 ==> 0.3485100614516343\n",
            "Loss in iteration no. 50120 ==> 0.3485090342014099\n",
            "Loss in iteration no. 50121 ==> 0.34850800698844925\n",
            "Loss in iteration no. 50122 ==> 0.34850697981275036\n",
            "Loss in iteration no. 50123 ==> 0.34850595267431145\n",
            "Loss in iteration no. 50124 ==> 0.3485049255731305\n",
            "Loss in iteration no. 50125 ==> 0.3485038985092059\n",
            "Loss in iteration no. 50126 ==> 0.3485028714825354\n",
            "Loss in iteration no. 50127 ==> 0.3485018444931174\n",
            "Loss in iteration no. 50128 ==> 0.3485008175409499\n",
            "Loss in iteration no. 50129 ==> 0.34849979062603115\n",
            "Loss in iteration no. 50130 ==> 0.3484987637483591\n",
            "Loss in iteration no. 50131 ==> 0.348497736907932\n",
            "Loss in iteration no. 50132 ==> 0.3484967101047479\n",
            "Loss in iteration no. 50133 ==> 0.348495683338805\n",
            "Loss in iteration no. 50134 ==> 0.34849465661010137\n",
            "Loss in iteration no. 50135 ==> 0.34849362991863514\n",
            "Loss in iteration no. 50136 ==> 0.34849260326440445\n",
            "Loss in iteration no. 50137 ==> 0.3484915766474074\n",
            "Loss in iteration no. 50138 ==> 0.3484905500676421\n",
            "Loss in iteration no. 50139 ==> 0.34848952352510676\n",
            "Loss in iteration no. 50140 ==> 0.3484884970197995\n",
            "Loss in iteration no. 50141 ==> 0.34848747055171825\n",
            "Loss in iteration no. 50142 ==> 0.3484864441208613\n",
            "Loss in iteration no. 50143 ==> 0.3484854177272268\n",
            "Loss in iteration no. 50144 ==> 0.3484843913708128\n",
            "Loss in iteration no. 50145 ==> 0.34848336505161737\n",
            "Loss in iteration no. 50146 ==> 0.34848233876963886\n",
            "Loss in iteration no. 50147 ==> 0.3484813125248752\n",
            "Loss in iteration no. 50148 ==> 0.34848028631732453\n",
            "Loss in iteration no. 50149 ==> 0.348479260146985\n",
            "Loss in iteration no. 50150 ==> 0.3484782340138548\n",
            "Loss in iteration no. 50151 ==> 0.34847720791793185\n",
            "Loss in iteration no. 50152 ==> 0.3484761818592146\n",
            "Loss in iteration no. 50153 ==> 0.34847515583770095\n",
            "Loss in iteration no. 50154 ==> 0.34847412985338905\n",
            "Loss in iteration no. 50155 ==> 0.3484731039062771\n",
            "Loss in iteration no. 50156 ==> 0.34847207799636315\n",
            "Loss in iteration no. 50157 ==> 0.3484710521236454\n",
            "Loss in iteration no. 50158 ==> 0.34847002628812185\n",
            "Loss in iteration no. 50159 ==> 0.34846900048979074\n",
            "Loss in iteration no. 50160 ==> 0.3484679747286502\n",
            "Loss in iteration no. 50161 ==> 0.3484669490046983\n",
            "Loss in iteration no. 50162 ==> 0.3484659233179332\n",
            "Loss in iteration no. 50163 ==> 0.3484648976683529\n",
            "Loss in iteration no. 50164 ==> 0.34846387205595586\n",
            "Loss in iteration no. 50165 ==> 0.3484628464807399\n",
            "Loss in iteration no. 50166 ==> 0.34846182094270317\n",
            "Loss in iteration no. 50167 ==> 0.34846079544184405\n",
            "Loss in iteration no. 50168 ==> 0.34845976997816025\n",
            "Loss in iteration no. 50169 ==> 0.34845874455165027\n",
            "Loss in iteration no. 50170 ==> 0.3484577191623121\n",
            "Loss in iteration no. 50171 ==> 0.3484566938101438\n",
            "Loss in iteration no. 50172 ==> 0.34845566849514364\n",
            "Loss in iteration no. 50173 ==> 0.3484546432173096\n",
            "Loss in iteration no. 50174 ==> 0.34845361797664\n",
            "Loss in iteration no. 50175 ==> 0.3484525927731328\n",
            "Loss in iteration no. 50176 ==> 0.3484515676067861\n",
            "Loss in iteration no. 50177 ==> 0.34845054247759816\n",
            "Loss in iteration no. 50178 ==> 0.3484495173855672\n",
            "Loss in iteration no. 50179 ==> 0.34844849233069103\n",
            "Loss in iteration no. 50180 ==> 0.348447467312968\n",
            "Loss in iteration no. 50181 ==> 0.3484464423323962\n",
            "Loss in iteration no. 50182 ==> 0.3484454173889738\n",
            "Loss in iteration no. 50183 ==> 0.3484443924826988\n",
            "Loss in iteration no. 50184 ==> 0.3484433676135695\n",
            "Loss in iteration no. 50185 ==> 0.34844234278158387\n",
            "Loss in iteration no. 50186 ==> 0.3484413179867402\n",
            "Loss in iteration no. 50187 ==> 0.34844029322903647\n",
            "Loss in iteration no. 50188 ==> 0.34843926850847085\n",
            "Loss in iteration no. 50189 ==> 0.34843824382504157\n",
            "Loss in iteration no. 50190 ==> 0.34843721917874665\n",
            "Loss in iteration no. 50191 ==> 0.34843619456958436\n",
            "Loss in iteration no. 50192 ==> 0.34843516999755264\n",
            "Loss in iteration no. 50193 ==> 0.34843414546264967\n",
            "Loss in iteration no. 50194 ==> 0.3484331209648736\n",
            "Loss in iteration no. 50195 ==> 0.3484320965042227\n",
            "Loss in iteration no. 50196 ==> 0.34843107208069485\n",
            "Loss in iteration no. 50197 ==> 0.3484300476942885\n",
            "Loss in iteration no. 50198 ==> 0.34842902334500137\n",
            "Loss in iteration no. 50199 ==> 0.34842799903283195\n",
            "Loss in iteration no. 50200 ==> 0.3484269747577782\n",
            "Loss in iteration no. 50201 ==> 0.34842595051983827\n",
            "Loss in iteration no. 50202 ==> 0.34842492631901034\n",
            "Loss in iteration no. 50203 ==> 0.34842390215529256\n",
            "Loss in iteration no. 50204 ==> 0.348422878028683\n",
            "Loss in iteration no. 50205 ==> 0.34842185393917974\n",
            "Loss in iteration no. 50206 ==> 0.3484208298867811\n",
            "Loss in iteration no. 50207 ==> 0.34841980587148497\n",
            "Loss in iteration no. 50208 ==> 0.3484187818932897\n",
            "Loss in iteration no. 50209 ==> 0.3484177579521932\n",
            "Loss in iteration no. 50210 ==> 0.34841673404819384\n",
            "Loss in iteration no. 50211 ==> 0.3484157101812896\n",
            "Loss in iteration no. 50212 ==> 0.3484146863514786\n",
            "Loss in iteration no. 50213 ==> 0.3484136625587591\n",
            "Loss in iteration no. 50214 ==> 0.34841263880312917\n",
            "Loss in iteration no. 50215 ==> 0.3484116150845869\n",
            "Loss in iteration no. 50216 ==> 0.3484105914031305\n",
            "Loss in iteration no. 50217 ==> 0.3484095677587582\n",
            "Loss in iteration no. 50218 ==> 0.3484085441514677\n",
            "Loss in iteration no. 50219 ==> 0.3484075205812577\n",
            "Loss in iteration no. 50220 ==> 0.34840649704812593\n",
            "Loss in iteration no. 50221 ==> 0.3484054735520707\n",
            "Loss in iteration no. 50222 ==> 0.3484044500930901\n",
            "Loss in iteration no. 50223 ==> 0.3484034266711822\n",
            "Loss in iteration no. 50224 ==> 0.34840240328634525\n",
            "Loss in iteration no. 50225 ==> 0.3484013799385774\n",
            "Loss in iteration no. 50226 ==> 0.34840035662787666\n",
            "Loss in iteration no. 50227 ==> 0.3483993333542412\n",
            "Loss in iteration no. 50228 ==> 0.3483983101176692\n",
            "Loss in iteration no. 50229 ==> 0.3483972869181589\n",
            "Loss in iteration no. 50230 ==> 0.3483962637557082\n",
            "Loss in iteration no. 50231 ==> 0.3483952406303153\n",
            "Loss in iteration no. 50232 ==> 0.3483942175419785\n",
            "Loss in iteration no. 50233 ==> 0.3483931944906958\n",
            "Loss in iteration no. 50234 ==> 0.34839217147646534\n",
            "Loss in iteration no. 50235 ==> 0.34839114849928526\n",
            "Loss in iteration no. 50236 ==> 0.3483901255591537\n",
            "Loss in iteration no. 50237 ==> 0.3483891026560688\n",
            "Loss in iteration no. 50238 ==> 0.34838807979002884\n",
            "Loss in iteration no. 50239 ==> 0.34838705696103167\n",
            "Loss in iteration no. 50240 ==> 0.3483860341690756\n",
            "Loss in iteration no. 50241 ==> 0.3483850114141588\n",
            "Loss in iteration no. 50242 ==> 0.34838398869627923\n",
            "Loss in iteration no. 50243 ==> 0.3483829660154352\n",
            "Loss in iteration no. 50244 ==> 0.3483819433716248\n",
            "Loss in iteration no. 50245 ==> 0.3483809207648462\n",
            "Loss in iteration no. 50246 ==> 0.34837989819509746\n",
            "Loss in iteration no. 50247 ==> 0.3483788756623768\n",
            "Loss in iteration no. 50248 ==> 0.34837785316668224\n",
            "Loss in iteration no. 50249 ==> 0.34837683070801195\n",
            "Loss in iteration no. 50250 ==> 0.34837580828636416\n",
            "Loss in iteration no. 50251 ==> 0.348374785901737\n",
            "Loss in iteration no. 50252 ==> 0.3483737635541286\n",
            "Loss in iteration no. 50253 ==> 0.34837274124353695\n",
            "Loss in iteration no. 50254 ==> 0.3483717189699604\n",
            "Loss in iteration no. 50255 ==> 0.3483706967333969\n",
            "Loss in iteration no. 50256 ==> 0.3483696745338447\n",
            "Loss in iteration no. 50257 ==> 0.348368652371302\n",
            "Loss in iteration no. 50258 ==> 0.3483676302457667\n",
            "Loss in iteration no. 50259 ==> 0.34836660815723713\n",
            "Loss in iteration no. 50260 ==> 0.3483655861057115\n",
            "Loss in iteration no. 50261 ==> 0.3483645640911877\n",
            "Loss in iteration no. 50262 ==> 0.3483635421136641\n",
            "Loss in iteration no. 50263 ==> 0.34836252017313873\n",
            "Loss in iteration no. 50264 ==> 0.34836149826960977\n",
            "Loss in iteration no. 50265 ==> 0.3483604764030753\n",
            "Loss in iteration no. 50266 ==> 0.3483594545735335\n",
            "Loss in iteration no. 50267 ==> 0.34835843278098255\n",
            "Loss in iteration no. 50268 ==> 0.3483574110254205\n",
            "Loss in iteration no. 50269 ==> 0.3483563893068456\n",
            "Loss in iteration no. 50270 ==> 0.3483553676252558\n",
            "Loss in iteration no. 50271 ==> 0.34835434598064946\n",
            "Loss in iteration no. 50272 ==> 0.3483533243730247\n",
            "Loss in iteration no. 50273 ==> 0.3483523028023795\n",
            "Loss in iteration no. 50274 ==> 0.34835128126871207\n",
            "Loss in iteration no. 50275 ==> 0.3483502597720206\n",
            "Loss in iteration no. 50276 ==> 0.3483492383123032\n",
            "Loss in iteration no. 50277 ==> 0.348348216889558\n",
            "Loss in iteration no. 50278 ==> 0.3483471955037832\n",
            "Loss in iteration no. 50279 ==> 0.34834617415497693\n",
            "Loss in iteration no. 50280 ==> 0.3483451528431373\n",
            "Loss in iteration no. 50281 ==> 0.34834413156826227\n",
            "Loss in iteration no. 50282 ==> 0.34834311033035026\n",
            "Loss in iteration no. 50283 ==> 0.3483420891293993\n",
            "Loss in iteration no. 50284 ==> 0.34834106796540754\n",
            "Loss in iteration no. 50285 ==> 0.3483400468383732\n",
            "Loss in iteration no. 50286 ==> 0.34833902574829434\n",
            "Loss in iteration no. 50287 ==> 0.348338004695169\n",
            "Loss in iteration no. 50288 ==> 0.3483369836789955\n",
            "Loss in iteration no. 50289 ==> 0.3483359626997719\n",
            "Loss in iteration no. 50290 ==> 0.34833494175749646\n",
            "Loss in iteration no. 50291 ==> 0.34833392085216713\n",
            "Loss in iteration no. 50292 ==> 0.3483328999837821\n",
            "Loss in iteration no. 50293 ==> 0.34833187915233965\n",
            "Loss in iteration no. 50294 ==> 0.3483308583578378\n",
            "Loss in iteration no. 50295 ==> 0.34832983760027464\n",
            "Loss in iteration no. 50296 ==> 0.3483288168796485\n",
            "Loss in iteration no. 50297 ==> 0.3483277961959574\n",
            "Loss in iteration no. 50298 ==> 0.34832677554919944\n",
            "Loss in iteration no. 50299 ==> 0.3483257549393729\n",
            "Loss in iteration no. 50300 ==> 0.34832473436647576\n",
            "Loss in iteration no. 50301 ==> 0.34832371383050637\n",
            "Loss in iteration no. 50302 ==> 0.3483226933314627\n",
            "Loss in iteration no. 50303 ==> 0.34832167286934296\n",
            "Loss in iteration no. 50304 ==> 0.3483206524441453\n",
            "Loss in iteration no. 50305 ==> 0.3483196320558678\n",
            "Loss in iteration no. 50306 ==> 0.34831861170450873\n",
            "Loss in iteration no. 50307 ==> 0.3483175913900661\n",
            "Loss in iteration no. 50308 ==> 0.34831657111253816\n",
            "Loss in iteration no. 50309 ==> 0.34831555087192295\n",
            "Loss in iteration no. 50310 ==> 0.34831453066821877\n",
            "Loss in iteration no. 50311 ==> 0.3483135105014236\n",
            "Loss in iteration no. 50312 ==> 0.3483124903715358\n",
            "Loss in iteration no. 50313 ==> 0.3483114702785532\n",
            "Loss in iteration no. 50314 ==> 0.34831045022247414\n",
            "Loss in iteration no. 50315 ==> 0.34830943020329674\n",
            "Loss in iteration no. 50316 ==> 0.34830841022101927\n",
            "Loss in iteration no. 50317 ==> 0.34830739027563956\n",
            "Loss in iteration no. 50318 ==> 0.348306370367156\n",
            "Loss in iteration no. 50319 ==> 0.3483053504955668\n",
            "Loss in iteration no. 50320 ==> 0.34830433066086997\n",
            "Loss in iteration no. 50321 ==> 0.34830331086306365\n",
            "Loss in iteration no. 50322 ==> 0.3483022911021461\n",
            "Loss in iteration no. 50323 ==> 0.3483012713781152\n",
            "Loss in iteration no. 50324 ==> 0.34830025169096945\n",
            "Loss in iteration no. 50325 ==> 0.3482992320407067\n",
            "Loss in iteration no. 50326 ==> 0.34829821242732534\n",
            "Loss in iteration no. 50327 ==> 0.3482971928508232\n",
            "Loss in iteration no. 50328 ==> 0.3482961733111989\n",
            "Loss in iteration no. 50329 ==> 0.3482951538084501\n",
            "Loss in iteration no. 50330 ==> 0.3482941343425752\n",
            "Loss in iteration no. 50331 ==> 0.34829311491357245\n",
            "Loss in iteration no. 50332 ==> 0.34829209552143975\n",
            "Loss in iteration no. 50333 ==> 0.34829107616617533\n",
            "Loss in iteration no. 50334 ==> 0.3482900568477775\n",
            "Loss in iteration no. 50335 ==> 0.34828903756624413\n",
            "Loss in iteration no. 50336 ==> 0.3482880183215736\n",
            "Loss in iteration no. 50337 ==> 0.3482869991137638\n",
            "Loss in iteration no. 50338 ==> 0.3482859799428132\n",
            "Loss in iteration no. 50339 ==> 0.34828496080871985\n",
            "Loss in iteration no. 50340 ==> 0.3482839417114817\n",
            "Loss in iteration no. 50341 ==> 0.3482829226510971\n",
            "Loss in iteration no. 50342 ==> 0.34828190362756417\n",
            "Loss in iteration no. 50343 ==> 0.348280884640881\n",
            "Loss in iteration no. 50344 ==> 0.3482798656910458\n",
            "Loss in iteration no. 50345 ==> 0.3482788467780566\n",
            "Loss in iteration no. 50346 ==> 0.3482778279019118\n",
            "Loss in iteration no. 50347 ==> 0.34827680906260927\n",
            "Loss in iteration no. 50348 ==> 0.3482757902601474\n",
            "Loss in iteration no. 50349 ==> 0.34827477149452407\n",
            "Loss in iteration no. 50350 ==> 0.3482737527657375\n",
            "Loss in iteration no. 50351 ==> 0.34827273407378617\n",
            "Loss in iteration no. 50352 ==> 0.34827171541866786\n",
            "Loss in iteration no. 50353 ==> 0.34827069680038075\n",
            "Loss in iteration no. 50354 ==> 0.34826967821892324\n",
            "Loss in iteration no. 50355 ==> 0.34826865967429316\n",
            "Loss in iteration no. 50356 ==> 0.34826764116648895\n",
            "Loss in iteration no. 50357 ==> 0.3482666226955086\n",
            "Loss in iteration no. 50358 ==> 0.3482656042613502\n",
            "Loss in iteration no. 50359 ==> 0.34826458586401216\n",
            "Loss in iteration no. 50360 ==> 0.3482635675034923\n",
            "Loss in iteration no. 50361 ==> 0.34826254917978905\n",
            "Loss in iteration no. 50362 ==> 0.3482615308929004\n",
            "Loss in iteration no. 50363 ==> 0.3482605126428246\n",
            "Loss in iteration no. 50364 ==> 0.3482594944295597\n",
            "Loss in iteration no. 50365 ==> 0.34825847625310397\n",
            "Loss in iteration no. 50366 ==> 0.3482574581134554\n",
            "Loss in iteration no. 50367 ==> 0.34825644001061223\n",
            "Loss in iteration no. 50368 ==> 0.3482554219445727\n",
            "Loss in iteration no. 50369 ==> 0.3482544039153349\n",
            "Loss in iteration no. 50370 ==> 0.34825338592289673\n",
            "Loss in iteration no. 50371 ==> 0.34825236796725684\n",
            "Loss in iteration no. 50372 ==> 0.348251350048413\n",
            "Loss in iteration no. 50373 ==> 0.3482503321663635\n",
            "Loss in iteration no. 50374 ==> 0.3482493143211064\n",
            "Loss in iteration no. 50375 ==> 0.34824829651264005\n",
            "Loss in iteration no. 50376 ==> 0.3482472787409624\n",
            "Loss in iteration no. 50377 ==> 0.34824626100607164\n",
            "Loss in iteration no. 50378 ==> 0.348245243307966\n",
            "Loss in iteration no. 50379 ==> 0.3482442256466437\n",
            "Loss in iteration no. 50380 ==> 0.34824320802210273\n",
            "Loss in iteration no. 50381 ==> 0.3482421904343413\n",
            "Loss in iteration no. 50382 ==> 0.34824117288335754\n",
            "Loss in iteration no. 50383 ==> 0.34824015536914965\n",
            "Loss in iteration no. 50384 ==> 0.3482391378917158\n",
            "Loss in iteration no. 50385 ==> 0.3482381204510541\n",
            "Loss in iteration no. 50386 ==> 0.34823710304716265\n",
            "Loss in iteration no. 50387 ==> 0.34823608568003983\n",
            "Loss in iteration no. 50388 ==> 0.34823506834968343\n",
            "Loss in iteration no. 50389 ==> 0.3482340510560919\n",
            "Loss in iteration no. 50390 ==> 0.34823303379926335\n",
            "Loss in iteration no. 50391 ==> 0.3482320165791958\n",
            "Loss in iteration no. 50392 ==> 0.3482309993958876\n",
            "Loss in iteration no. 50393 ==> 0.34822998224933666\n",
            "Loss in iteration no. 50394 ==> 0.3482289651395414\n",
            "Loss in iteration no. 50395 ==> 0.34822794806649976\n",
            "Loss in iteration no. 50396 ==> 0.34822693103021\n",
            "Loss in iteration no. 50397 ==> 0.34822591403067027\n",
            "Loss in iteration no. 50398 ==> 0.34822489706787885\n",
            "Loss in iteration no. 50399 ==> 0.3482238801418336\n",
            "Loss in iteration no. 50400 ==> 0.3482228632525328\n",
            "Loss in iteration no. 50401 ==> 0.3482218463999747\n",
            "Loss in iteration no. 50402 ==> 0.3482208295841575\n",
            "Loss in iteration no. 50403 ==> 0.34821981280507913\n",
            "Loss in iteration no. 50404 ==> 0.348218796062738\n",
            "Loss in iteration no. 50405 ==> 0.348217779357132\n",
            "Loss in iteration no. 50406 ==> 0.3482167626882596\n",
            "Loss in iteration no. 50407 ==> 0.3482157460561186\n",
            "Loss in iteration no. 50408 ==> 0.34821472946070736\n",
            "Loss in iteration no. 50409 ==> 0.34821371290202413\n",
            "Loss in iteration no. 50410 ==> 0.3482126963800669\n",
            "Loss in iteration no. 50411 ==> 0.3482116798948338\n",
            "Loss in iteration no. 50412 ==> 0.3482106634463232\n",
            "Loss in iteration no. 50413 ==> 0.34820964703453305\n",
            "Loss in iteration no. 50414 ==> 0.3482086306594616\n",
            "Loss in iteration no. 50415 ==> 0.34820761432110703\n",
            "Loss in iteration no. 50416 ==> 0.3482065980194674\n",
            "Loss in iteration no. 50417 ==> 0.348205581754541\n",
            "Loss in iteration no. 50418 ==> 0.3482045655263258\n",
            "Loss in iteration no. 50419 ==> 0.34820354933482006\n",
            "Loss in iteration no. 50420 ==> 0.34820253318002214\n",
            "Loss in iteration no. 50421 ==> 0.3482015170619298\n",
            "Loss in iteration no. 50422 ==> 0.3482005009805415\n",
            "Loss in iteration no. 50423 ==> 0.3481994849358554\n",
            "Loss in iteration no. 50424 ==> 0.3481984689278695\n",
            "Loss in iteration no. 50425 ==> 0.348197452956582\n",
            "Loss in iteration no. 50426 ==> 0.34819643702199105\n",
            "Loss in iteration no. 50427 ==> 0.3481954211240949\n",
            "Loss in iteration no. 50428 ==> 0.3481944052628917\n",
            "Loss in iteration no. 50429 ==> 0.3481933894383795\n",
            "Loss in iteration no. 50430 ==> 0.3481923736505565\n",
            "Loss in iteration no. 50431 ==> 0.34819135789942096\n",
            "Loss in iteration no. 50432 ==> 0.3481903421849708\n",
            "Loss in iteration no. 50433 ==> 0.3481893265072045\n",
            "Loss in iteration no. 50434 ==> 0.34818831086612\n",
            "Loss in iteration no. 50435 ==> 0.34818729526171555\n",
            "Loss in iteration no. 50436 ==> 0.34818627969398924\n",
            "Loss in iteration no. 50437 ==> 0.3481852641629393\n",
            "Loss in iteration no. 50438 ==> 0.3481842486685639\n",
            "Loss in iteration no. 50439 ==> 0.34818323321086114\n",
            "Loss in iteration no. 50440 ==> 0.3481822177898292\n",
            "Loss in iteration no. 50441 ==> 0.3481812024054662\n",
            "Loss in iteration no. 50442 ==> 0.3481801870577704\n",
            "Loss in iteration no. 50443 ==> 0.34817917174673985\n",
            "Loss in iteration no. 50444 ==> 0.3481781564723729\n",
            "Loss in iteration no. 50445 ==> 0.3481771412346674\n",
            "Loss in iteration no. 50446 ==> 0.34817612603362175\n",
            "Loss in iteration no. 50447 ==> 0.34817511086923414\n",
            "Loss in iteration no. 50448 ==> 0.34817409574150254\n",
            "Loss in iteration no. 50449 ==> 0.3481730806504253\n",
            "Loss in iteration no. 50450 ==> 0.34817206559600045\n",
            "Loss in iteration no. 50451 ==> 0.3481710505782262\n",
            "Loss in iteration no. 50452 ==> 0.3481700355971007\n",
            "Loss in iteration no. 50453 ==> 0.3481690206526222\n",
            "Loss in iteration no. 50454 ==> 0.34816800574478873\n",
            "Loss in iteration no. 50455 ==> 0.34816699087359854\n",
            "Loss in iteration no. 50456 ==> 0.3481659760390497\n",
            "Loss in iteration no. 50457 ==> 0.3481649612411405\n",
            "Loss in iteration no. 50458 ==> 0.34816394647986904\n",
            "Loss in iteration no. 50459 ==> 0.34816293175523333\n",
            "Loss in iteration no. 50460 ==> 0.3481619170672319\n",
            "Loss in iteration no. 50461 ==> 0.3481609024158625\n",
            "Loss in iteration no. 50462 ==> 0.3481598878011236\n",
            "Loss in iteration no. 50463 ==> 0.34815887322301325\n",
            "Loss in iteration no. 50464 ==> 0.3481578586815297\n",
            "Loss in iteration no. 50465 ==> 0.34815684417667087\n",
            "Loss in iteration no. 50466 ==> 0.34815582970843534\n",
            "Loss in iteration no. 50467 ==> 0.34815481527682074\n",
            "Loss in iteration no. 50468 ==> 0.34815380088182557\n",
            "Loss in iteration no. 50469 ==> 0.34815278652344805\n",
            "Loss in iteration no. 50470 ==> 0.3481517722016862\n",
            "Loss in iteration no. 50471 ==> 0.3481507579165382\n",
            "Loss in iteration no. 50472 ==> 0.3481497436680022\n",
            "Loss in iteration no. 50473 ==> 0.3481487294560764\n",
            "Loss in iteration no. 50474 ==> 0.34814771528075894\n",
            "Loss in iteration no. 50475 ==> 0.3481467011420481\n",
            "Loss in iteration no. 50476 ==> 0.3481456870399419\n",
            "Loss in iteration no. 50477 ==> 0.3481446729744386\n",
            "Loss in iteration no. 50478 ==> 0.3481436589455362\n",
            "Loss in iteration no. 50479 ==> 0.34814264495323305\n",
            "Loss in iteration no. 50480 ==> 0.3481416309975273\n",
            "Loss in iteration no. 50481 ==> 0.3481406170784171\n",
            "Loss in iteration no. 50482 ==> 0.3481396031959005\n",
            "Loss in iteration no. 50483 ==> 0.3481385893499757\n",
            "Loss in iteration no. 50484 ==> 0.348137575540641\n",
            "Loss in iteration no. 50485 ==> 0.3481365617678945\n",
            "Loss in iteration no. 50486 ==> 0.34813554803173424\n",
            "Loss in iteration no. 50487 ==> 0.3481345343321586\n",
            "Loss in iteration no. 50488 ==> 0.34813352066916564\n",
            "Loss in iteration no. 50489 ==> 0.3481325070427535\n",
            "Loss in iteration no. 50490 ==> 0.3481314934529203\n",
            "Loss in iteration no. 50491 ==> 0.3481304798996644\n",
            "Loss in iteration no. 50492 ==> 0.3481294663829838\n",
            "Loss in iteration no. 50493 ==> 0.34812845290287675\n",
            "Loss in iteration no. 50494 ==> 0.3481274394593413\n",
            "Loss in iteration no. 50495 ==> 0.34812642605237576\n",
            "Loss in iteration no. 50496 ==> 0.3481254126819783\n",
            "Loss in iteration no. 50497 ==> 0.348124399348147\n",
            "Loss in iteration no. 50498 ==> 0.3481233860508799\n",
            "Loss in iteration no. 50499 ==> 0.3481223727901755\n",
            "Loss in iteration no. 50500 ==> 0.3481213595660317\n",
            "Loss in iteration no. 50501 ==> 0.3481203463784468\n",
            "Loss in iteration no. 50502 ==> 0.3481193332274189\n",
            "Loss in iteration no. 50503 ==> 0.34811832011294613\n",
            "Loss in iteration no. 50504 ==> 0.3481173070350268\n",
            "Loss in iteration no. 50505 ==> 0.348116293993659\n",
            "Loss in iteration no. 50506 ==> 0.3481152809888409\n",
            "Loss in iteration no. 50507 ==> 0.34811426802057066\n",
            "Loss in iteration no. 50508 ==> 0.3481132550888465\n",
            "Loss in iteration no. 50509 ==> 0.3481122421936665\n",
            "Loss in iteration no. 50510 ==> 0.34811122933502886\n",
            "Loss in iteration no. 50511 ==> 0.3481102165129318\n",
            "Loss in iteration no. 50512 ==> 0.3481092037273735\n",
            "Loss in iteration no. 50513 ==> 0.3481081909783519\n",
            "Loss in iteration no. 50514 ==> 0.34810717826586546\n",
            "Loss in iteration no. 50515 ==> 0.34810616558991225\n",
            "Loss in iteration no. 50516 ==> 0.3481051529504905\n",
            "Loss in iteration no. 50517 ==> 0.3481041403475982\n",
            "Loss in iteration no. 50518 ==> 0.34810312778123365\n",
            "Loss in iteration no. 50519 ==> 0.34810211525139506\n",
            "Loss in iteration no. 50520 ==> 0.3481011027580804\n",
            "Loss in iteration no. 50521 ==> 0.34810009030128813\n",
            "Loss in iteration no. 50522 ==> 0.3480990778810163\n",
            "Loss in iteration no. 50523 ==> 0.34809806549726297\n",
            "Loss in iteration no. 50524 ==> 0.3480970531500265\n",
            "Loss in iteration no. 50525 ==> 0.3480960408393047\n",
            "Loss in iteration no. 50526 ==> 0.3480950285650963\n",
            "Loss in iteration no. 50527 ==> 0.348094016327399\n",
            "Loss in iteration no. 50528 ==> 0.34809300412621114\n",
            "Loss in iteration no. 50529 ==> 0.34809199196153096\n",
            "Loss in iteration no. 50530 ==> 0.3480909798333566\n",
            "Loss in iteration no. 50531 ==> 0.34808996774168605\n",
            "Loss in iteration no. 50532 ==> 0.3480889556865177\n",
            "Loss in iteration no. 50533 ==> 0.3480879436678496\n",
            "Loss in iteration no. 50534 ==> 0.3480869316856801\n",
            "Loss in iteration no. 50535 ==> 0.34808591974000713\n",
            "Loss in iteration no. 50536 ==> 0.348084907830829\n",
            "Loss in iteration no. 50537 ==> 0.3480838959581439\n",
            "Loss in iteration no. 50538 ==> 0.3480828841219499\n",
            "Loss in iteration no. 50539 ==> 0.34808187232224524\n",
            "Loss in iteration no. 50540 ==> 0.3480808605590281\n",
            "Loss in iteration no. 50541 ==> 0.34807984883229665\n",
            "Loss in iteration no. 50542 ==> 0.34807883714204896\n",
            "Loss in iteration no. 50543 ==> 0.3480778254882834\n",
            "Loss in iteration no. 50544 ==> 0.348076813870998\n",
            "Loss in iteration no. 50545 ==> 0.348075802290191\n",
            "Loss in iteration no. 50546 ==> 0.34807479074586056\n",
            "Loss in iteration no. 50547 ==> 0.34807377923800475\n",
            "Loss in iteration no. 50548 ==> 0.3480727677666219\n",
            "Loss in iteration no. 50549 ==> 0.34807175633171\n",
            "Loss in iteration no. 50550 ==> 0.3480707449332675\n",
            "Loss in iteration no. 50551 ==> 0.3480697335712923\n",
            "Loss in iteration no. 50552 ==> 0.3480687222457828\n",
            "Loss in iteration no. 50553 ==> 0.34806771095673694\n",
            "Loss in iteration no. 50554 ==> 0.34806669970415305\n",
            "Loss in iteration no. 50555 ==> 0.34806568848802927\n",
            "Loss in iteration no. 50556 ==> 0.3480646773083638\n",
            "Loss in iteration no. 50557 ==> 0.3480636661651547\n",
            "Loss in iteration no. 50558 ==> 0.3480626550584004\n",
            "Loss in iteration no. 50559 ==> 0.3480616439880988\n",
            "Loss in iteration no. 50560 ==> 0.3480606329542481\n",
            "Loss in iteration no. 50561 ==> 0.34805962195684675\n",
            "Loss in iteration no. 50562 ==> 0.3480586109958925\n",
            "Loss in iteration no. 50563 ==> 0.34805760007138403\n",
            "Loss in iteration no. 50564 ==> 0.34805658918331905\n",
            "Loss in iteration no. 50565 ==> 0.348055578331696\n",
            "Loss in iteration no. 50566 ==> 0.348054567516513\n",
            "Loss in iteration no. 50567 ==> 0.3480535567377682\n",
            "Loss in iteration no. 50568 ==> 0.3480525459954597\n",
            "Loss in iteration no. 50569 ==> 0.34805153528958593\n",
            "Loss in iteration no. 50570 ==> 0.34805052462014474\n",
            "Loss in iteration no. 50571 ==> 0.3480495139871346\n",
            "Loss in iteration no. 50572 ==> 0.3480485033905535\n",
            "Loss in iteration no. 50573 ==> 0.34804749283039965\n",
            "Loss in iteration no. 50574 ==> 0.34804648230667135\n",
            "Loss in iteration no. 50575 ==> 0.3480454718193665\n",
            "Loss in iteration no. 50576 ==> 0.34804446136848355\n",
            "Loss in iteration no. 50577 ==> 0.34804345095402056\n",
            "Loss in iteration no. 50578 ==> 0.3480424405759757\n",
            "Loss in iteration no. 50579 ==> 0.3480414302343473\n",
            "Loss in iteration no. 50580 ==> 0.34804041992913326\n",
            "Loss in iteration no. 50581 ==> 0.348039409660332\n",
            "Loss in iteration no. 50582 ==> 0.3480383994279415\n",
            "Loss in iteration no. 50583 ==> 0.34803738923196015\n",
            "Loss in iteration no. 50584 ==> 0.34803637907238594\n",
            "Loss in iteration no. 50585 ==> 0.3480353689492172\n",
            "Loss in iteration no. 50586 ==> 0.3480343588624521\n",
            "Loss in iteration no. 50587 ==> 0.3480333488120886\n",
            "Loss in iteration no. 50588 ==> 0.34803233879812506\n",
            "Loss in iteration no. 50589 ==> 0.3480313288205597\n",
            "Loss in iteration no. 50590 ==> 0.3480303188793906\n",
            "Loss in iteration no. 50591 ==> 0.348029308974616\n",
            "Loss in iteration no. 50592 ==> 0.348028299106234\n",
            "Loss in iteration no. 50593 ==> 0.34802728927424287\n",
            "Loss in iteration no. 50594 ==> 0.3480262794786407\n",
            "Loss in iteration no. 50595 ==> 0.34802526971942577\n",
            "Loss in iteration no. 50596 ==> 0.3480242599965962\n",
            "Loss in iteration no. 50597 ==> 0.34802325031015013\n",
            "Loss in iteration no. 50598 ==> 0.34802224066008586\n",
            "Loss in iteration no. 50599 ==> 0.3480212310464015\n",
            "Loss in iteration no. 50600 ==> 0.34802022146909506\n",
            "Loss in iteration no. 50601 ==> 0.348019211928165\n",
            "Loss in iteration no. 50602 ==> 0.34801820242360937\n",
            "Loss in iteration no. 50603 ==> 0.3480171929554264\n",
            "Loss in iteration no. 50604 ==> 0.34801618352361424\n",
            "Loss in iteration no. 50605 ==> 0.348015174128171\n",
            "Loss in iteration no. 50606 ==> 0.3480141647690949\n",
            "Loss in iteration no. 50607 ==> 0.34801315544638434\n",
            "Loss in iteration no. 50608 ==> 0.34801214616003706\n",
            "Loss in iteration no. 50609 ==> 0.3480111369100517\n",
            "Loss in iteration no. 50610 ==> 0.3480101276964261\n",
            "Loss in iteration no. 50611 ==> 0.34800911851915856\n",
            "Loss in iteration no. 50612 ==> 0.3480081093782473\n",
            "Loss in iteration no. 50613 ==> 0.3480071002736905\n",
            "Loss in iteration no. 50614 ==> 0.3480060912054863\n",
            "Loss in iteration no. 50615 ==> 0.34800508217363285\n",
            "Loss in iteration no. 50616 ==> 0.3480040731781285\n",
            "Loss in iteration no. 50617 ==> 0.34800306421897126\n",
            "Loss in iteration no. 50618 ==> 0.34800205529615935\n",
            "Loss in iteration no. 50619 ==> 0.3480010464096909\n",
            "Loss in iteration no. 50620 ==> 0.3480000375595642\n",
            "Loss in iteration no. 50621 ==> 0.3479990287457774\n",
            "Loss in iteration no. 50622 ==> 0.34799801996832863\n",
            "Loss in iteration no. 50623 ==> 0.3479970112272162\n",
            "Loss in iteration no. 50624 ==> 0.3479960025224381\n",
            "Loss in iteration no. 50625 ==> 0.3479949938539928\n",
            "Loss in iteration no. 50626 ==> 0.3479939852218782\n",
            "Loss in iteration no. 50627 ==> 0.34799297662609247\n",
            "Loss in iteration no. 50628 ==> 0.34799196806663396\n",
            "Loss in iteration no. 50629 ==> 0.3479909595435009\n",
            "Loss in iteration no. 50630 ==> 0.3479899510566913\n",
            "Loss in iteration no. 50631 ==> 0.34798894260620344\n",
            "Loss in iteration no. 50632 ==> 0.34798793419203544\n",
            "Loss in iteration no. 50633 ==> 0.3479869258141856\n",
            "Loss in iteration no. 50634 ==> 0.347985917472652\n",
            "Loss in iteration no. 50635 ==> 0.3479849091674328\n",
            "Loss in iteration no. 50636 ==> 0.34798390089852627\n",
            "Loss in iteration no. 50637 ==> 0.3479828926659306\n",
            "Loss in iteration no. 50638 ==> 0.3479818844696439\n",
            "Loss in iteration no. 50639 ==> 0.34798087630966434\n",
            "Loss in iteration no. 50640 ==> 0.3479798681859903\n",
            "Loss in iteration no. 50641 ==> 0.3479788600986197\n",
            "Loss in iteration no. 50642 ==> 0.34797785204755094\n",
            "Loss in iteration no. 50643 ==> 0.347976844032782\n",
            "Loss in iteration no. 50644 ==> 0.3479758360543112\n",
            "Loss in iteration no. 50645 ==> 0.3479748281121367\n",
            "Loss in iteration no. 50646 ==> 0.3479738202062567\n",
            "Loss in iteration no. 50647 ==> 0.34797281233666943\n",
            "Loss in iteration no. 50648 ==> 0.347971804503373\n",
            "Loss in iteration no. 50649 ==> 0.3479707967063655\n",
            "Loss in iteration no. 50650 ==> 0.3479697889456453\n",
            "Loss in iteration no. 50651 ==> 0.34796878122121055\n",
            "Loss in iteration no. 50652 ==> 0.34796777353305935\n",
            "Loss in iteration no. 50653 ==> 0.3479667658811899\n",
            "Loss in iteration no. 50654 ==> 0.3479657582656005\n",
            "Loss in iteration no. 50655 ==> 0.34796475068628924\n",
            "Loss in iteration no. 50656 ==> 0.3479637431432543\n",
            "Loss in iteration no. 50657 ==> 0.3479627356364939\n",
            "Loss in iteration no. 50658 ==> 0.34796172816600623\n",
            "Loss in iteration no. 50659 ==> 0.34796072073178946\n",
            "Loss in iteration no. 50660 ==> 0.34795971333384174\n",
            "Loss in iteration no. 50661 ==> 0.34795870597216133\n",
            "Loss in iteration no. 50662 ==> 0.34795769864674647\n",
            "Loss in iteration no. 50663 ==> 0.34795669135759516\n",
            "Loss in iteration no. 50664 ==> 0.3479556841047057\n",
            "Loss in iteration no. 50665 ==> 0.3479546768880762\n",
            "Loss in iteration no. 50666 ==> 0.3479536697077051\n",
            "Loss in iteration no. 50667 ==> 0.34795266256359025\n",
            "Loss in iteration no. 50668 ==> 0.34795165545573004\n",
            "Loss in iteration no. 50669 ==> 0.3479506483841226\n",
            "Loss in iteration no. 50670 ==> 0.3479496413487661\n",
            "Loss in iteration no. 50671 ==> 0.34794863434965884\n",
            "Loss in iteration no. 50672 ==> 0.3479476273867988\n",
            "Loss in iteration no. 50673 ==> 0.3479466204601843\n",
            "Loss in iteration no. 50674 ==> 0.3479456135698136\n",
            "Loss in iteration no. 50675 ==> 0.3479446067156849\n",
            "Loss in iteration no. 50676 ==> 0.3479435998977961\n",
            "Loss in iteration no. 50677 ==> 0.3479425931161458\n",
            "Loss in iteration no. 50678 ==> 0.3479415863707318\n",
            "Loss in iteration no. 50679 ==> 0.34794057966155256\n",
            "Loss in iteration no. 50680 ==> 0.34793957298860606\n",
            "Loss in iteration no. 50681 ==> 0.3479385663518907\n",
            "Loss in iteration no. 50682 ==> 0.3479375597514045\n",
            "Loss in iteration no. 50683 ==> 0.34793655318714584\n",
            "Loss in iteration no. 50684 ==> 0.3479355466591127\n",
            "Loss in iteration no. 50685 ==> 0.3479345401673034\n",
            "Loss in iteration no. 50686 ==> 0.34793353371171604\n",
            "Loss in iteration no. 50687 ==> 0.3479325272923489\n",
            "Loss in iteration no. 50688 ==> 0.3479315209092002\n",
            "Loss in iteration no. 50689 ==> 0.347930514562268\n",
            "Loss in iteration no. 50690 ==> 0.34792950825155056\n",
            "Loss in iteration no. 50691 ==> 0.34792850197704606\n",
            "Loss in iteration no. 50692 ==> 0.34792749573875265\n",
            "Loss in iteration no. 50693 ==> 0.3479264895366686\n",
            "Loss in iteration no. 50694 ==> 0.3479254833707921\n",
            "Loss in iteration no. 50695 ==> 0.34792447724112124\n",
            "Loss in iteration no. 50696 ==> 0.34792347114765426\n",
            "Loss in iteration no. 50697 ==> 0.34792246509038954\n",
            "Loss in iteration no. 50698 ==> 0.347921459069325\n",
            "Loss in iteration no. 50699 ==> 0.3479204530844589\n",
            "Loss in iteration no. 50700 ==> 0.3479194471357895\n",
            "Loss in iteration no. 50701 ==> 0.34791844122331494\n",
            "Loss in iteration no. 50702 ==> 0.3479174353470335\n",
            "Loss in iteration no. 50703 ==> 0.3479164295069432\n",
            "Loss in iteration no. 50704 ==> 0.3479154237030424\n",
            "Loss in iteration no. 50705 ==> 0.3479144179353291\n",
            "Loss in iteration no. 50706 ==> 0.3479134122038018\n",
            "Loss in iteration no. 50707 ==> 0.34791240650845834\n",
            "Loss in iteration no. 50708 ==> 0.34791140084929717\n",
            "Loss in iteration no. 50709 ==> 0.3479103952263164\n",
            "Loss in iteration no. 50710 ==> 0.34790938963951423\n",
            "Loss in iteration no. 50711 ==> 0.34790838408888886\n",
            "Loss in iteration no. 50712 ==> 0.3479073785744384\n",
            "Loss in iteration no. 50713 ==> 0.3479063730961611\n",
            "Loss in iteration no. 50714 ==> 0.34790536765405516\n",
            "Loss in iteration no. 50715 ==> 0.3479043622481188\n",
            "Loss in iteration no. 50716 ==> 0.3479033568783502\n",
            "Loss in iteration no. 50717 ==> 0.3479023515447476\n",
            "Loss in iteration no. 50718 ==> 0.34790134624730906\n",
            "Loss in iteration no. 50719 ==> 0.34790034098603284\n",
            "Loss in iteration no. 50720 ==> 0.3478993357609171\n",
            "Loss in iteration no. 50721 ==> 0.3478983305719602\n",
            "Loss in iteration no. 50722 ==> 0.3478973254191601\n",
            "Loss in iteration no. 50723 ==> 0.34789632030251516\n",
            "Loss in iteration no. 50724 ==> 0.34789531522202344\n",
            "Loss in iteration no. 50725 ==> 0.3478943101776833\n",
            "Loss in iteration no. 50726 ==> 0.34789330516949285\n",
            "Loss in iteration no. 50727 ==> 0.3478923001974502\n",
            "Loss in iteration no. 50728 ==> 0.34789129526155377\n",
            "Loss in iteration no. 50729 ==> 0.3478902903618015\n",
            "Loss in iteration no. 50730 ==> 0.34788928549819176\n",
            "Loss in iteration no. 50731 ==> 0.34788828067072264\n",
            "Loss in iteration no. 50732 ==> 0.3478872758793925\n",
            "Loss in iteration no. 50733 ==> 0.34788627112419923\n",
            "Loss in iteration no. 50734 ==> 0.34788526640514134\n",
            "Loss in iteration no. 50735 ==> 0.3478842617222168\n",
            "Loss in iteration no. 50736 ==> 0.34788325707542395\n",
            "Loss in iteration no. 50737 ==> 0.34788225246476095\n",
            "Loss in iteration no. 50738 ==> 0.34788124789022595\n",
            "Loss in iteration no. 50739 ==> 0.3478802433518172\n",
            "Loss in iteration no. 50740 ==> 0.3478792388495329\n",
            "Loss in iteration no. 50741 ==> 0.34787823438337123\n",
            "Loss in iteration no. 50742 ==> 0.34787722995333026\n",
            "Loss in iteration no. 50743 ==> 0.34787622555940845\n",
            "Loss in iteration no. 50744 ==> 0.3478752212016038\n",
            "Loss in iteration no. 50745 ==> 0.3478742168799146\n",
            "Loss in iteration no. 50746 ==> 0.3478732125943389\n",
            "Loss in iteration no. 50747 ==> 0.34787220834487514\n",
            "Loss in iteration no. 50748 ==> 0.3478712041315213\n",
            "Loss in iteration no. 50749 ==> 0.3478701999542756\n",
            "Loss in iteration no. 50750 ==> 0.34786919581313647\n",
            "Loss in iteration no. 50751 ==> 0.3478681917081018\n",
            "Loss in iteration no. 50752 ==> 0.34786718763916996\n",
            "Loss in iteration no. 50753 ==> 0.3478661836063391\n",
            "Loss in iteration no. 50754 ==> 0.34786517960960744\n",
            "Loss in iteration no. 50755 ==> 0.3478641756489731\n",
            "Loss in iteration no. 50756 ==> 0.34786317172443443\n",
            "Loss in iteration no. 50757 ==> 0.34786216783598956\n",
            "Loss in iteration no. 50758 ==> 0.3478611639836366\n",
            "Loss in iteration no. 50759 ==> 0.34786016016737387\n",
            "Loss in iteration no. 50760 ==> 0.34785915638719944\n",
            "Loss in iteration no. 50761 ==> 0.3478581526431117\n",
            "Loss in iteration no. 50762 ==> 0.34785714893510866\n",
            "Loss in iteration no. 50763 ==> 0.3478561452631886\n",
            "Loss in iteration no. 50764 ==> 0.3478551416273498\n",
            "Loss in iteration no. 50765 ==> 0.3478541380275902\n",
            "Loss in iteration no. 50766 ==> 0.34785313446390836\n",
            "Loss in iteration no. 50767 ==> 0.34785213093630213\n",
            "Loss in iteration no. 50768 ==> 0.3478511274447699\n",
            "Loss in iteration no. 50769 ==> 0.3478501239893099\n",
            "Loss in iteration no. 50770 ==> 0.3478491205699203\n",
            "Loss in iteration no. 50771 ==> 0.3478481171865992\n",
            "Loss in iteration no. 50772 ==> 0.3478471138393449\n",
            "Loss in iteration no. 50773 ==> 0.34784611052815567\n",
            "Loss in iteration no. 50774 ==> 0.3478451072530295\n",
            "Loss in iteration no. 50775 ==> 0.34784410401396465\n",
            "Loss in iteration no. 50776 ==> 0.3478431008109595\n",
            "Loss in iteration no. 50777 ==> 0.34784209764401197\n",
            "Loss in iteration no. 50778 ==> 0.3478410945131206\n",
            "Loss in iteration no. 50779 ==> 0.3478400914182832\n",
            "Loss in iteration no. 50780 ==> 0.34783908835949834\n",
            "Loss in iteration no. 50781 ==> 0.3478380853367639\n",
            "Loss in iteration no. 50782 ==> 0.3478370823500784\n",
            "Loss in iteration no. 50783 ==> 0.3478360793994399\n",
            "Loss in iteration no. 50784 ==> 0.3478350764848464\n",
            "Loss in iteration no. 50785 ==> 0.3478340736062965\n",
            "Loss in iteration no. 50786 ==> 0.347833070763788\n",
            "Loss in iteration no. 50787 ==> 0.34783206795731936\n",
            "Loss in iteration no. 50788 ==> 0.34783106518688867\n",
            "Loss in iteration no. 50789 ==> 0.3478300624524942\n",
            "Loss in iteration no. 50790 ==> 0.3478290597541342\n",
            "Loss in iteration no. 50791 ==> 0.34782805709180664\n",
            "Loss in iteration no. 50792 ==> 0.34782705446551\n",
            "Loss in iteration no. 50793 ==> 0.34782605187524235\n",
            "Loss in iteration no. 50794 ==> 0.3478250493210018\n",
            "Loss in iteration no. 50795 ==> 0.3478240468027867\n",
            "Loss in iteration no. 50796 ==> 0.34782304432059535\n",
            "Loss in iteration no. 50797 ==> 0.3478220418744256\n",
            "Loss in iteration no. 50798 ==> 0.34782103946427595\n",
            "Loss in iteration no. 50799 ==> 0.34782003709014464\n",
            "Loss in iteration no. 50800 ==> 0.3478190347520296\n",
            "Loss in iteration no. 50801 ==> 0.3478180324499292\n",
            "Loss in iteration no. 50802 ==> 0.3478170301838416\n",
            "Loss in iteration no. 50803 ==> 0.34781602795376504\n",
            "Loss in iteration no. 50804 ==> 0.3478150257596978\n",
            "Loss in iteration no. 50805 ==> 0.347814023601638\n",
            "Loss in iteration no. 50806 ==> 0.34781302147958376\n",
            "Loss in iteration no. 50807 ==> 0.3478120193935334\n",
            "Loss in iteration no. 50808 ==> 0.34781101734348513\n",
            "Loss in iteration no. 50809 ==> 0.34781001532943706\n",
            "Loss in iteration no. 50810 ==> 0.3478090133513874\n",
            "Loss in iteration no. 50811 ==> 0.34780801140933454\n",
            "Loss in iteration no. 50812 ==> 0.3478070095032765\n",
            "Loss in iteration no. 50813 ==> 0.3478060076332115\n",
            "Loss in iteration no. 50814 ==> 0.3478050057991378\n",
            "Loss in iteration no. 50815 ==> 0.3478040040010536\n",
            "Loss in iteration no. 50816 ==> 0.34780300223895705\n",
            "Loss in iteration no. 50817 ==> 0.34780200051284643\n",
            "Loss in iteration no. 50818 ==> 0.34780099882272\n",
            "Loss in iteration no. 50819 ==> 0.3477999971685757\n",
            "Loss in iteration no. 50820 ==> 0.347798995550412\n",
            "Loss in iteration no. 50821 ==> 0.347797993968227\n",
            "Loss in iteration no. 50822 ==> 0.34779699242201895\n",
            "Loss in iteration no. 50823 ==> 0.34779599091178603\n",
            "Loss in iteration no. 50824 ==> 0.3477949894375264\n",
            "Loss in iteration no. 50825 ==> 0.3477939879992384\n",
            "Loss in iteration no. 50826 ==> 0.3477929865969201\n",
            "Loss in iteration no. 50827 ==> 0.3477919852305697\n",
            "Loss in iteration no. 50828 ==> 0.3477909839001855\n",
            "Loss in iteration no. 50829 ==> 0.3477899826057657\n",
            "Loss in iteration no. 50830 ==> 0.34778898134730846\n",
            "Loss in iteration no. 50831 ==> 0.34778798012481194\n",
            "Loss in iteration no. 50832 ==> 0.34778697893827454\n",
            "Loss in iteration no. 50833 ==> 0.34778597778769416\n",
            "Loss in iteration no. 50834 ==> 0.3477849766730693\n",
            "Loss in iteration no. 50835 ==> 0.3477839755943981\n",
            "Loss in iteration no. 50836 ==> 0.3477829745516786\n",
            "Loss in iteration no. 50837 ==> 0.34778197354490914\n",
            "Loss in iteration no. 50838 ==> 0.347780972574088\n",
            "Loss in iteration no. 50839 ==> 0.34777997163921326\n",
            "Loss in iteration no. 50840 ==> 0.3477789707402832\n",
            "Loss in iteration no. 50841 ==> 0.347777969877296\n",
            "Loss in iteration no. 50842 ==> 0.3477769690502498\n",
            "Loss in iteration no. 50843 ==> 0.3477759682591429\n",
            "Loss in iteration no. 50844 ==> 0.3477749675039734\n",
            "Loss in iteration no. 50845 ==> 0.34777396678473976\n",
            "Loss in iteration no. 50846 ==> 0.34777296610143993\n",
            "Loss in iteration no. 50847 ==> 0.34777196545407224\n",
            "Loss in iteration no. 50848 ==> 0.3477709648426348\n",
            "Loss in iteration no. 50849 ==> 0.34776996426712603\n",
            "Loss in iteration no. 50850 ==> 0.34776896372754385\n",
            "Loss in iteration no. 50851 ==> 0.3477679632238867\n",
            "Loss in iteration no. 50852 ==> 0.34776696275615265\n",
            "Loss in iteration no. 50853 ==> 0.34776596232434\n",
            "Loss in iteration no. 50854 ==> 0.3477649619284469\n",
            "Loss in iteration no. 50855 ==> 0.34776396156847167\n",
            "Loss in iteration no. 50856 ==> 0.34776296124441225\n",
            "Loss in iteration no. 50857 ==> 0.3477619609562671\n",
            "Loss in iteration no. 50858 ==> 0.3477609607040345\n",
            "Loss in iteration no. 50859 ==> 0.3477599604877124\n",
            "Loss in iteration no. 50860 ==> 0.3477589603072992\n",
            "Loss in iteration no. 50861 ==> 0.347757960162793\n",
            "Loss in iteration no. 50862 ==> 0.34775696005419204\n",
            "Loss in iteration no. 50863 ==> 0.34775595998149456\n",
            "Loss in iteration no. 50864 ==> 0.34775495994469874\n",
            "Loss in iteration no. 50865 ==> 0.3477539599438029\n",
            "Loss in iteration no. 50866 ==> 0.3477529599788051\n",
            "Loss in iteration no. 50867 ==> 0.3477519600497036\n",
            "Loss in iteration no. 50868 ==> 0.3477509601564967\n",
            "Loss in iteration no. 50869 ==> 0.34774996029918237\n",
            "Loss in iteration no. 50870 ==> 0.34774896047775916\n",
            "Loss in iteration no. 50871 ==> 0.34774796069222497\n",
            "Loss in iteration no. 50872 ==> 0.3477469609425782\n",
            "Loss in iteration no. 50873 ==> 0.34774596122881707\n",
            "Loss in iteration no. 50874 ==> 0.34774496155093965\n",
            "Loss in iteration no. 50875 ==> 0.34774396190894424\n",
            "Loss in iteration no. 50876 ==> 0.3477429623028291\n",
            "Loss in iteration no. 50877 ==> 0.34774196273259234\n",
            "Loss in iteration no. 50878 ==> 0.34774096319823217\n",
            "Loss in iteration no. 50879 ==> 0.34773996369974697\n",
            "Loss in iteration no. 50880 ==> 0.34773896423713474\n",
            "Loss in iteration no. 50881 ==> 0.3477379648103939\n",
            "Loss in iteration no. 50882 ==> 0.34773696541952237\n",
            "Loss in iteration no. 50883 ==> 0.3477359660645187\n",
            "Loss in iteration no. 50884 ==> 0.34773496674538085\n",
            "Loss in iteration no. 50885 ==> 0.34773396746210716\n",
            "Loss in iteration no. 50886 ==> 0.3477329682146959\n",
            "Loss in iteration no. 50887 ==> 0.3477319690031452\n",
            "Loss in iteration no. 50888 ==> 0.3477309698274531\n",
            "Loss in iteration no. 50889 ==> 0.34772997068761813\n",
            "Loss in iteration no. 50890 ==> 0.3477289715836383\n",
            "Loss in iteration no. 50891 ==> 0.34772797251551185\n",
            "Loss in iteration no. 50892 ==> 0.34772697348323706\n",
            "Loss in iteration no. 50893 ==> 0.34772597448681214\n",
            "Loss in iteration no. 50894 ==> 0.34772497552623527\n",
            "Loss in iteration no. 50895 ==> 0.3477239766015046\n",
            "Loss in iteration no. 50896 ==> 0.34772297771261856\n",
            "Loss in iteration no. 50897 ==> 0.347721978859575\n",
            "Loss in iteration no. 50898 ==> 0.34772098004237256\n",
            "Loss in iteration no. 50899 ==> 0.34771998126100917\n",
            "Loss in iteration no. 50900 ==> 0.3477189825154831\n",
            "Loss in iteration no. 50901 ==> 0.3477179838057926\n",
            "Loss in iteration no. 50902 ==> 0.3477169851319359\n",
            "Loss in iteration no. 50903 ==> 0.3477159864939111\n",
            "Loss in iteration no. 50904 ==> 0.3477149878917167\n",
            "Loss in iteration no. 50905 ==> 0.3477139893253505\n",
            "Loss in iteration no. 50906 ==> 0.34771299079481105\n",
            "Loss in iteration no. 50907 ==> 0.3477119923000965\n",
            "Loss in iteration no. 50908 ==> 0.3477109938412049\n",
            "Loss in iteration no. 50909 ==> 0.34770999541813463\n",
            "Loss in iteration no. 50910 ==> 0.3477089970308838\n",
            "Loss in iteration no. 50911 ==> 0.3477079986794508\n",
            "Loss in iteration no. 50912 ==> 0.3477070003638337\n",
            "Loss in iteration no. 50913 ==> 0.3477060020840307\n",
            "Loss in iteration no. 50914 ==> 0.34770500384004005\n",
            "Loss in iteration no. 50915 ==> 0.34770400563186\n",
            "Loss in iteration no. 50916 ==> 0.3477030074594888\n",
            "Loss in iteration no. 50917 ==> 0.3477020093229246\n",
            "Loss in iteration no. 50918 ==> 0.34770101122216557\n",
            "Loss in iteration no. 50919 ==> 0.34770001315721\n",
            "Loss in iteration no. 50920 ==> 0.3476990151280562\n",
            "Loss in iteration no. 50921 ==> 0.34769801713470216\n",
            "Loss in iteration no. 50922 ==> 0.3476970191771463\n",
            "Loss in iteration no. 50923 ==> 0.3476960212553867\n",
            "Loss in iteration no. 50924 ==> 0.34769502336942154\n",
            "Loss in iteration no. 50925 ==> 0.34769402551924933\n",
            "Loss in iteration no. 50926 ==> 0.34769302770486804\n",
            "Loss in iteration no. 50927 ==> 0.34769202992627596\n",
            "Loss in iteration no. 50928 ==> 0.3476910321834712\n",
            "Loss in iteration no. 50929 ==> 0.3476900344764521\n",
            "Loss in iteration no. 50930 ==> 0.3476890368052169\n",
            "Loss in iteration no. 50931 ==> 0.3476880391697637\n",
            "Loss in iteration no. 50932 ==> 0.34768704157009084\n",
            "Loss in iteration no. 50933 ==> 0.34768604400619646\n",
            "Loss in iteration no. 50934 ==> 0.34768504647807874\n",
            "Loss in iteration no. 50935 ==> 0.347684048985736\n",
            "Loss in iteration no. 50936 ==> 0.34768305152916645\n",
            "Loss in iteration no. 50937 ==> 0.3476820541083683\n",
            "Loss in iteration no. 50938 ==> 0.34768105672333965\n",
            "Loss in iteration no. 50939 ==> 0.34768005937407886\n",
            "Loss in iteration no. 50940 ==> 0.34767906206058413\n",
            "Loss in iteration no. 50941 ==> 0.34767806478285357\n",
            "Loss in iteration no. 50942 ==> 0.3476770675408855\n",
            "Loss in iteration no. 50943 ==> 0.34767607033467823\n",
            "Loss in iteration no. 50944 ==> 0.3476750731642298\n",
            "Loss in iteration no. 50945 ==> 0.34767407602953854\n",
            "Loss in iteration no. 50946 ==> 0.3476730789306026\n",
            "Loss in iteration no. 50947 ==> 0.3476720818674203\n",
            "Loss in iteration no. 50948 ==> 0.3476710848399897\n",
            "Loss in iteration no. 50949 ==> 0.3476700878483093\n",
            "Loss in iteration no. 50950 ==> 0.3476690908923769\n",
            "Loss in iteration no. 50951 ==> 0.3476680939721912\n",
            "Loss in iteration no. 50952 ==> 0.34766709708775\n",
            "Loss in iteration no. 50953 ==> 0.3476661002390517\n",
            "Loss in iteration no. 50954 ==> 0.3476651034260946\n",
            "Loss in iteration no. 50955 ==> 0.3476641066488768\n",
            "Loss in iteration no. 50956 ==> 0.3476631099073965\n",
            "Loss in iteration no. 50957 ==> 0.34766211320165225\n",
            "Loss in iteration no. 50958 ==> 0.3476611165316417\n",
            "Loss in iteration no. 50959 ==> 0.34766011989736345\n",
            "Loss in iteration no. 50960 ==> 0.34765912329881576\n",
            "Loss in iteration no. 50961 ==> 0.34765812673599666\n",
            "Loss in iteration no. 50962 ==> 0.3476571302089045\n",
            "Loss in iteration no. 50963 ==> 0.34765613371753745\n",
            "Loss in iteration no. 50964 ==> 0.3476551372618938\n",
            "Loss in iteration no. 50965 ==> 0.34765414084197155\n",
            "Loss in iteration no. 50966 ==> 0.34765314445776924\n",
            "Loss in iteration no. 50967 ==> 0.3476521481092849\n",
            "Loss in iteration no. 50968 ==> 0.34765115179651673\n",
            "Loss in iteration no. 50969 ==> 0.34765015551946304\n",
            "Loss in iteration no. 50970 ==> 0.347649159278122\n",
            "Loss in iteration no. 50971 ==> 0.3476481630724919\n",
            "Loss in iteration no. 50972 ==> 0.34764716690257097\n",
            "Loss in iteration no. 50973 ==> 0.34764617076835735\n",
            "Loss in iteration no. 50974 ==> 0.3476451746698493\n",
            "Loss in iteration no. 50975 ==> 0.347644178607045\n",
            "Loss in iteration no. 50976 ==> 0.34764318257994276\n",
            "Loss in iteration no. 50977 ==> 0.3476421865885408\n",
            "Loss in iteration no. 50978 ==> 0.34764119063283727\n",
            "Loss in iteration no. 50979 ==> 0.3476401947128303\n",
            "Loss in iteration no. 50980 ==> 0.34763919882851835\n",
            "Loss in iteration no. 50981 ==> 0.34763820297989967\n",
            "Loss in iteration no. 50982 ==> 0.34763720716697216\n",
            "Loss in iteration no. 50983 ==> 0.34763621138973433\n",
            "Loss in iteration no. 50984 ==> 0.3476352156481843\n",
            "Loss in iteration no. 50985 ==> 0.3476342199423203\n",
            "Loss in iteration no. 50986 ==> 0.3476332242721405\n",
            "Loss in iteration no. 50987 ==> 0.34763222863764326\n",
            "Loss in iteration no. 50988 ==> 0.34763123303882665\n",
            "Loss in iteration no. 50989 ==> 0.3476302374756891\n",
            "Loss in iteration no. 50990 ==> 0.3476292419482287\n",
            "Loss in iteration no. 50991 ==> 0.3476282464564436\n",
            "Loss in iteration no. 50992 ==> 0.3476272510003321\n",
            "Loss in iteration no. 50993 ==> 0.3476262555798925\n",
            "Loss in iteration no. 50994 ==> 0.347625260195123\n",
            "Loss in iteration no. 50995 ==> 0.3476242648460217\n",
            "Loss in iteration no. 50996 ==> 0.347623269532587\n",
            "Loss in iteration no. 50997 ==> 0.347622274254817\n",
            "Loss in iteration no. 50998 ==> 0.34762127901270995\n",
            "Loss in iteration no. 50999 ==> 0.34762028380626403\n",
            "Loss in iteration no. 51000 ==> 0.34761928863547764\n",
            "Loss in iteration no. 51001 ==> 0.34761829350034895\n",
            "Loss in iteration no. 51002 ==> 0.347617298400876\n",
            "Loss in iteration no. 51003 ==> 0.34761630333705723\n",
            "Loss in iteration no. 51004 ==> 0.34761530830889076\n",
            "Loss in iteration no. 51005 ==> 0.34761431331637493\n",
            "Loss in iteration no. 51006 ==> 0.3476133183595078\n",
            "Loss in iteration no. 51007 ==> 0.34761232343828763\n",
            "Loss in iteration no. 51008 ==> 0.34761132855271276\n",
            "Loss in iteration no. 51009 ==> 0.3476103337027813\n",
            "Loss in iteration no. 51010 ==> 0.3476093388884916\n",
            "Loss in iteration no. 51011 ==> 0.34760834410984187\n",
            "Loss in iteration no. 51012 ==> 0.34760734936683013\n",
            "Loss in iteration no. 51013 ==> 0.34760635465945483\n",
            "Loss in iteration no. 51014 ==> 0.3476053599877142\n",
            "Loss in iteration no. 51015 ==> 0.34760436535160644\n",
            "Loss in iteration no. 51016 ==> 0.3476033707511295\n",
            "Loss in iteration no. 51017 ==> 0.34760237618628215\n",
            "Loss in iteration no. 51018 ==> 0.34760138165706206\n",
            "Loss in iteration no. 51019 ==> 0.34760038716346786\n",
            "Loss in iteration no. 51020 ==> 0.3475993927054976\n",
            "Loss in iteration no. 51021 ==> 0.34759839828314953\n",
            "Loss in iteration no. 51022 ==> 0.347597403896422\n",
            "Loss in iteration no. 51023 ==> 0.347596409545313\n",
            "Loss in iteration no. 51024 ==> 0.347595415229821\n",
            "Loss in iteration no. 51025 ==> 0.347594420949944\n",
            "Loss in iteration no. 51026 ==> 0.34759342670568044\n",
            "Loss in iteration no. 51027 ==> 0.34759243249702837\n",
            "Loss in iteration no. 51028 ==> 0.3475914383239862\n",
            "Loss in iteration no. 51029 ==> 0.34759044418655205\n",
            "Loss in iteration no. 51030 ==> 0.3475894500847242\n",
            "Loss in iteration no. 51031 ==> 0.3475884560185007\n",
            "Loss in iteration no. 51032 ==> 0.3475874619878801\n",
            "Loss in iteration no. 51033 ==> 0.3475864679928604\n",
            "Loss in iteration no. 51034 ==> 0.3475854740334398\n",
            "Loss in iteration no. 51035 ==> 0.3475844801096168\n",
            "Loss in iteration no. 51036 ==> 0.3475834862213893\n",
            "Loss in iteration no. 51037 ==> 0.3475824923687557\n",
            "Loss in iteration no. 51038 ==> 0.34758149855171433\n",
            "Loss in iteration no. 51039 ==> 0.3475805047702632\n",
            "Loss in iteration no. 51040 ==> 0.3475795110244007\n",
            "Loss in iteration no. 51041 ==> 0.34757851731412487\n",
            "Loss in iteration no. 51042 ==> 0.3475775236394342\n",
            "Loss in iteration no. 51043 ==> 0.34757653000032684\n",
            "Loss in iteration no. 51044 ==> 0.34757553639680083\n",
            "Loss in iteration no. 51045 ==> 0.3475745428288547\n",
            "Loss in iteration no. 51046 ==> 0.34757354929648643\n",
            "Loss in iteration no. 51047 ==> 0.3475725557996944\n",
            "Loss in iteration no. 51048 ==> 0.34757156233847675\n",
            "Loss in iteration no. 51049 ==> 0.3475705689128319\n",
            "Loss in iteration no. 51050 ==> 0.3475695755227578\n",
            "Loss in iteration no. 51051 ==> 0.3475685821682529\n",
            "Loss in iteration no. 51052 ==> 0.3475675888493153\n",
            "Loss in iteration no. 51053 ==> 0.3475665955659433\n",
            "Loss in iteration no. 51054 ==> 0.3475656023181351\n",
            "Loss in iteration no. 51055 ==> 0.34756460910588904\n",
            "Loss in iteration no. 51056 ==> 0.3475636159292033\n",
            "Loss in iteration no. 51057 ==> 0.347562622788076\n",
            "Loss in iteration no. 51058 ==> 0.34756162968250537\n",
            "Loss in iteration no. 51059 ==> 0.3475606366124898\n",
            "Loss in iteration no. 51060 ==> 0.34755964357802743\n",
            "Loss in iteration no. 51061 ==> 0.3475586505791166\n",
            "Loss in iteration no. 51062 ==> 0.34755765761575547\n",
            "Loss in iteration no. 51063 ==> 0.3475566646879421\n",
            "Loss in iteration no. 51064 ==> 0.3475556717956749\n",
            "Loss in iteration no. 51065 ==> 0.34755467893895226\n",
            "Loss in iteration no. 51066 ==> 0.34755368611777215\n",
            "Loss in iteration no. 51067 ==> 0.3475526933321329\n",
            "Loss in iteration no. 51068 ==> 0.34755170058203266\n",
            "Loss in iteration no. 51069 ==> 0.3475507078674699\n",
            "Loss in iteration no. 51070 ==> 0.3475497151884426\n",
            "Loss in iteration no. 51071 ==> 0.34754872254494906\n",
            "Loss in iteration no. 51072 ==> 0.3475477299369876\n",
            "Loss in iteration no. 51073 ==> 0.3475467373645564\n",
            "Loss in iteration no. 51074 ==> 0.34754574482765377\n",
            "Loss in iteration no. 51075 ==> 0.3475447523262778\n",
            "Loss in iteration no. 51076 ==> 0.3475437598604268\n",
            "Loss in iteration no. 51077 ==> 0.347542767430099\n",
            "Loss in iteration no. 51078 ==> 0.34754177503529265\n",
            "Loss in iteration no. 51079 ==> 0.34754078267600585\n",
            "Loss in iteration no. 51080 ==> 0.34753979035223714\n",
            "Loss in iteration no. 51081 ==> 0.3475387980639846\n",
            "Loss in iteration no. 51082 ==> 0.3475378058112463\n",
            "Loss in iteration no. 51083 ==> 0.3475368135940207\n",
            "Loss in iteration no. 51084 ==> 0.34753582141230593\n",
            "Loss in iteration no. 51085 ==> 0.34753482926610024\n",
            "Loss in iteration no. 51086 ==> 0.3475338371554019\n",
            "Loss in iteration no. 51087 ==> 0.3475328450802091\n",
            "Loss in iteration no. 51088 ==> 0.3475318530405201\n",
            "Loss in iteration no. 51089 ==> 0.3475308610363332\n",
            "Loss in iteration no. 51090 ==> 0.34752986906764655\n",
            "Loss in iteration no. 51091 ==> 0.3475288771344583\n",
            "Loss in iteration no. 51092 ==> 0.3475278852367668\n",
            "Loss in iteration no. 51093 ==> 0.34752689337457043\n",
            "Loss in iteration no. 51094 ==> 0.34752590154786733\n",
            "Loss in iteration no. 51095 ==> 0.34752490975665556\n",
            "Loss in iteration no. 51096 ==> 0.3475239180009335\n",
            "Loss in iteration no. 51097 ==> 0.34752292628069936\n",
            "Loss in iteration no. 51098 ==> 0.34752193459595143\n",
            "Loss in iteration no. 51099 ==> 0.34752094294668784\n",
            "Loss in iteration no. 51100 ==> 0.347519951332907\n",
            "Loss in iteration no. 51101 ==> 0.34751895975460695\n",
            "Loss in iteration no. 51102 ==> 0.34751796821178615\n",
            "Loss in iteration no. 51103 ==> 0.34751697670444254\n",
            "Loss in iteration no. 51104 ==> 0.3475159852325747\n",
            "Loss in iteration no. 51105 ==> 0.34751499379618056\n",
            "Loss in iteration no. 51106 ==> 0.3475140023952586\n",
            "Loss in iteration no. 51107 ==> 0.3475130110298069\n",
            "Loss in iteration no. 51108 ==> 0.3475120196998237\n",
            "Loss in iteration no. 51109 ==> 0.34751102840530745\n",
            "Loss in iteration no. 51110 ==> 0.3475100371462561\n",
            "Loss in iteration no. 51111 ==> 0.34750904592266807\n",
            "Loss in iteration no. 51112 ==> 0.3475080547345415\n",
            "Loss in iteration no. 51113 ==> 0.3475070635818747\n",
            "Loss in iteration no. 51114 ==> 0.347506072464666\n",
            "Loss in iteration no. 51115 ==> 0.34750508138291347\n",
            "Loss in iteration no. 51116 ==> 0.3475040903366154\n",
            "Loss in iteration no. 51117 ==> 0.3475030993257699\n",
            "Loss in iteration no. 51118 ==> 0.3475021083503755\n",
            "Loss in iteration no. 51119 ==> 0.3475011174104303\n",
            "Loss in iteration no. 51120 ==> 0.3475001265059325\n",
            "Loss in iteration no. 51121 ==> 0.34749913563688034\n",
            "Loss in iteration no. 51122 ==> 0.3474981448032721\n",
            "Loss in iteration no. 51123 ==> 0.34749715400510606\n",
            "Loss in iteration no. 51124 ==> 0.34749616324238036\n",
            "Loss in iteration no. 51125 ==> 0.34749517251509326\n",
            "Loss in iteration no. 51126 ==> 0.34749418182324315\n",
            "Loss in iteration no. 51127 ==> 0.34749319116682803\n",
            "Loss in iteration no. 51128 ==> 0.34749220054584634\n",
            "Loss in iteration no. 51129 ==> 0.34749120996029625\n",
            "Loss in iteration no. 51130 ==> 0.34749021941017594\n",
            "Loss in iteration no. 51131 ==> 0.3474892288954838\n",
            "Loss in iteration no. 51132 ==> 0.34748823841621795\n",
            "Loss in iteration no. 51133 ==> 0.34748724797237657\n",
            "Loss in iteration no. 51134 ==> 0.34748625756395807\n",
            "Loss in iteration no. 51135 ==> 0.34748526719096057\n",
            "Loss in iteration no. 51136 ==> 0.3474842768533824\n",
            "Loss in iteration no. 51137 ==> 0.34748328655122185\n",
            "Loss in iteration no. 51138 ==> 0.34748229628447697\n",
            "Loss in iteration no. 51139 ==> 0.3474813060531461\n",
            "Loss in iteration no. 51140 ==> 0.3474803158572275\n",
            "Loss in iteration no. 51141 ==> 0.34747932569671935\n",
            "Loss in iteration no. 51142 ==> 0.34747833557162\n",
            "Loss in iteration no. 51143 ==> 0.34747734548192766\n",
            "Loss in iteration no. 51144 ==> 0.3474763554276405\n",
            "Loss in iteration no. 51145 ==> 0.3474753654087568\n",
            "Loss in iteration no. 51146 ==> 0.3474743754252748\n",
            "Loss in iteration no. 51147 ==> 0.3474733854771928\n",
            "Loss in iteration no. 51148 ==> 0.34747239556450904\n",
            "Loss in iteration no. 51149 ==> 0.3474714056872217\n",
            "Loss in iteration no. 51150 ==> 0.347470415845329\n",
            "Loss in iteration no. 51151 ==> 0.34746942603882924\n",
            "Loss in iteration no. 51152 ==> 0.34746843626772067\n",
            "Loss in iteration no. 51153 ==> 0.3474674465320015\n",
            "Loss in iteration no. 51154 ==> 0.3474664568316701\n",
            "Loss in iteration no. 51155 ==> 0.3474654671667245\n",
            "Loss in iteration no. 51156 ==> 0.3474644775371631\n",
            "Loss in iteration no. 51157 ==> 0.34746348794298404\n",
            "Loss in iteration no. 51158 ==> 0.34746249838418575\n",
            "Loss in iteration no. 51159 ==> 0.34746150886076616\n",
            "Loss in iteration no. 51160 ==> 0.34746051937272376\n",
            "Loss in iteration no. 51161 ==> 0.3474595299200568\n",
            "Loss in iteration no. 51162 ==> 0.34745854050276337\n",
            "Loss in iteration no. 51163 ==> 0.3474575511208419\n",
            "Loss in iteration no. 51164 ==> 0.3474565617742905\n",
            "Loss in iteration no. 51165 ==> 0.34745557246310754\n",
            "Loss in iteration no. 51166 ==> 0.34745458318729106\n",
            "Loss in iteration no. 51167 ==> 0.34745359394683945\n",
            "Loss in iteration no. 51168 ==> 0.347452604741751\n",
            "Loss in iteration no. 51169 ==> 0.34745161557202375\n",
            "Loss in iteration no. 51170 ==> 0.34745062643765623\n",
            "Loss in iteration no. 51171 ==> 0.3474496373386464\n",
            "Loss in iteration no. 51172 ==> 0.3474486482749928\n",
            "Loss in iteration no. 51173 ==> 0.3474476592466934\n",
            "Loss in iteration no. 51174 ==> 0.34744667025374665\n",
            "Loss in iteration no. 51175 ==> 0.34744568129615067\n",
            "Loss in iteration no. 51176 ==> 0.34744469237390374\n",
            "Loss in iteration no. 51177 ==> 0.34744370348700415\n",
            "Loss in iteration no. 51178 ==> 0.3474427146354501\n",
            "Loss in iteration no. 51179 ==> 0.3474417258192399\n",
            "Loss in iteration no. 51180 ==> 0.3474407370383716\n",
            "Loss in iteration no. 51181 ==> 0.3474397482928437\n",
            "Loss in iteration no. 51182 ==> 0.34743875958265436\n",
            "Loss in iteration no. 51183 ==> 0.34743777090780176\n",
            "Loss in iteration no. 51184 ==> 0.3474367822682843\n",
            "Loss in iteration no. 51185 ==> 0.3474357936641\n",
            "Loss in iteration no. 51186 ==> 0.3474348050952473\n",
            "Loss in iteration no. 51187 ==> 0.3474338165617244\n",
            "Loss in iteration no. 51188 ==> 0.3474328280635294\n",
            "Loss in iteration no. 51189 ==> 0.3474318396006608\n",
            "Loss in iteration no. 51190 ==> 0.34743085117311673\n",
            "Loss in iteration no. 51191 ==> 0.3474298627808953\n",
            "Loss in iteration no. 51192 ==> 0.3474288744239951\n",
            "Loss in iteration no. 51193 ==> 0.34742788610241404\n",
            "Loss in iteration no. 51194 ==> 0.34742689781615055\n",
            "Loss in iteration no. 51195 ==> 0.3474259095652027\n",
            "Loss in iteration no. 51196 ==> 0.347424921349569\n",
            "Loss in iteration no. 51197 ==> 0.34742393316924747\n",
            "Loss in iteration no. 51198 ==> 0.34742294502423665\n",
            "Loss in iteration no. 51199 ==> 0.3474219569145344\n",
            "Loss in iteration no. 51200 ==> 0.34742096884013923\n",
            "Loss in iteration no. 51201 ==> 0.34741998080104924\n",
            "Loss in iteration no. 51202 ==> 0.34741899279726285\n",
            "Loss in iteration no. 51203 ==> 0.34741800482877816\n",
            "Loss in iteration no. 51204 ==> 0.3474170168955935\n",
            "Loss in iteration no. 51205 ==> 0.3474160289977072\n",
            "Loss in iteration no. 51206 ==> 0.3474150411351173\n",
            "Loss in iteration no. 51207 ==> 0.34741405330782216\n",
            "Loss in iteration no. 51208 ==> 0.34741306551582\n",
            "Loss in iteration no. 51209 ==> 0.3474120777591092\n",
            "Loss in iteration no. 51210 ==> 0.34741109003768783\n",
            "Loss in iteration no. 51211 ==> 0.3474101023515543\n",
            "Loss in iteration no. 51212 ==> 0.34740911470070673\n",
            "Loss in iteration no. 51213 ==> 0.3474081270851435\n",
            "Loss in iteration no. 51214 ==> 0.3474071395048626\n",
            "Loss in iteration no. 51215 ==> 0.34740615195986263\n",
            "Loss in iteration no. 51216 ==> 0.34740516445014163\n",
            "Loss in iteration no. 51217 ==> 0.34740417697569786\n",
            "Loss in iteration no. 51218 ==> 0.34740318953652966\n",
            "Loss in iteration no. 51219 ==> 0.3474022021326352\n",
            "Loss in iteration no. 51220 ==> 0.34740121476401276\n",
            "Loss in iteration no. 51221 ==> 0.3474002274306606\n",
            "Loss in iteration no. 51222 ==> 0.347399240132577\n",
            "Loss in iteration no. 51223 ==> 0.34739825286976017\n",
            "Loss in iteration no. 51224 ==> 0.3473972656422083\n",
            "Loss in iteration no. 51225 ==> 0.3473962784499197\n",
            "Loss in iteration no. 51226 ==> 0.3473952912928927\n",
            "Loss in iteration no. 51227 ==> 0.34739430417112543\n",
            "Loss in iteration no. 51228 ==> 0.3473933170846163\n",
            "Loss in iteration no. 51229 ==> 0.34739233003336334\n",
            "Loss in iteration no. 51230 ==> 0.34739134301736496\n",
            "Loss in iteration no. 51231 ==> 0.34739035603661944\n",
            "Loss in iteration no. 51232 ==> 0.34738936909112494\n",
            "Loss in iteration no. 51233 ==> 0.34738838218087964\n",
            "Loss in iteration no. 51234 ==> 0.34738739530588203\n",
            "Loss in iteration no. 51235 ==> 0.34738640846613017\n",
            "Loss in iteration no. 51236 ==> 0.34738542166162234\n",
            "Loss in iteration no. 51237 ==> 0.3473844348923568\n",
            "Loss in iteration no. 51238 ==> 0.34738344815833194\n",
            "Loss in iteration no. 51239 ==> 0.3473824614595458\n",
            "Loss in iteration no. 51240 ==> 0.3473814747959968\n",
            "Loss in iteration no. 51241 ==> 0.34738048816768313\n",
            "Loss in iteration no. 51242 ==> 0.34737950157460296\n",
            "Loss in iteration no. 51243 ==> 0.34737851501675465\n",
            "Loss in iteration no. 51244 ==> 0.3473775284941365\n",
            "Loss in iteration no. 51245 ==> 0.3473765420067466\n",
            "Loss in iteration no. 51246 ==> 0.3473755555545834\n",
            "Loss in iteration no. 51247 ==> 0.347374569137645\n",
            "Loss in iteration no. 51248 ==> 0.3473735827559297\n",
            "Loss in iteration no. 51249 ==> 0.34737259640943574\n",
            "Loss in iteration no. 51250 ==> 0.3473716100981615\n",
            "Loss in iteration no. 51251 ==> 0.3473706238221051\n",
            "Loss in iteration no. 51252 ==> 0.34736963758126477\n",
            "Loss in iteration no. 51253 ==> 0.3473686513756389\n",
            "Loss in iteration no. 51254 ==> 0.34736766520522566\n",
            "Loss in iteration no. 51255 ==> 0.3473666790700232\n",
            "Loss in iteration no. 51256 ==> 0.34736569297003\n",
            "Loss in iteration no. 51257 ==> 0.34736470690524407\n",
            "Loss in iteration no. 51258 ==> 0.347363720875664\n",
            "Loss in iteration no. 51259 ==> 0.34736273488128777\n",
            "Loss in iteration no. 51260 ==> 0.34736174892211363\n",
            "Loss in iteration no. 51261 ==> 0.34736076299813995\n",
            "Loss in iteration no. 51262 ==> 0.34735977710936505\n",
            "Loss in iteration no. 51263 ==> 0.34735879125578706\n",
            "Loss in iteration no. 51264 ==> 0.34735780543740424\n",
            "Loss in iteration no. 51265 ==> 0.34735681965421483\n",
            "Loss in iteration no. 51266 ==> 0.34735583390621716\n",
            "Loss in iteration no. 51267 ==> 0.3473548481934095\n",
            "Loss in iteration no. 51268 ==> 0.34735386251579004\n",
            "Loss in iteration no. 51269 ==> 0.34735287687335703\n",
            "Loss in iteration no. 51270 ==> 0.3473518912661088\n",
            "Loss in iteration no. 51271 ==> 0.3473509056940436\n",
            "Loss in iteration no. 51272 ==> 0.34734992015715965\n",
            "Loss in iteration no. 51273 ==> 0.3473489346554552\n",
            "Loss in iteration no. 51274 ==> 0.34734794918892836\n",
            "Loss in iteration no. 51275 ==> 0.34734696375757773\n",
            "Loss in iteration no. 51276 ==> 0.34734597836140135\n",
            "Loss in iteration no. 51277 ==> 0.34734499300039745\n",
            "Loss in iteration no. 51278 ==> 0.3473440076745644\n",
            "Loss in iteration no. 51279 ==> 0.3473430223839005\n",
            "Loss in iteration no. 51280 ==> 0.3473420371284038\n",
            "Loss in iteration no. 51281 ==> 0.3473410519080727\n",
            "Loss in iteration no. 51282 ==> 0.3473400667229054\n",
            "Loss in iteration no. 51283 ==> 0.3473390815729002\n",
            "Loss in iteration no. 51284 ==> 0.34733809645805547\n",
            "Loss in iteration no. 51285 ==> 0.3473371113783692\n",
            "Loss in iteration no. 51286 ==> 0.34733612633383987\n",
            "Loss in iteration no. 51287 ==> 0.34733514132446563\n",
            "Loss in iteration no. 51288 ==> 0.34733415635024484\n",
            "Loss in iteration no. 51289 ==> 0.34733317141117565\n",
            "Loss in iteration no. 51290 ==> 0.3473321865072564\n",
            "Loss in iteration no. 51291 ==> 0.3473312016384853\n",
            "Loss in iteration no. 51292 ==> 0.3473302168048606\n",
            "Loss in iteration no. 51293 ==> 0.34732923200638055\n",
            "Loss in iteration no. 51294 ==> 0.3473282472430435\n",
            "Loss in iteration no. 51295 ==> 0.3473272625148477\n",
            "Loss in iteration no. 51296 ==> 0.34732627782179126\n",
            "Loss in iteration no. 51297 ==> 0.3473252931638727\n",
            "Loss in iteration no. 51298 ==> 0.34732430854109\n",
            "Loss in iteration no. 51299 ==> 0.34732332395344157\n",
            "Loss in iteration no. 51300 ==> 0.34732233940092555\n",
            "Loss in iteration no. 51301 ==> 0.34732135488354043\n",
            "Loss in iteration no. 51302 ==> 0.3473203704012844\n",
            "Loss in iteration no. 51303 ==> 0.3473193859541555\n",
            "Loss in iteration no. 51304 ==> 0.34731840154215227\n",
            "Loss in iteration no. 51305 ==> 0.34731741716527276\n",
            "Loss in iteration no. 51306 ==> 0.3473164328235154\n",
            "Loss in iteration no. 51307 ==> 0.34731544851687823\n",
            "Loss in iteration no. 51308 ==> 0.3473144642453598\n",
            "Loss in iteration no. 51309 ==> 0.3473134800089581\n",
            "Loss in iteration no. 51310 ==> 0.3473124958076716\n",
            "Loss in iteration no. 51311 ==> 0.3473115116414985\n",
            "Loss in iteration no. 51312 ==> 0.34731052751043695\n",
            "Loss in iteration no. 51313 ==> 0.34730954341448533\n",
            "Loss in iteration no. 51314 ==> 0.3473085593536419\n",
            "Loss in iteration no. 51315 ==> 0.34730757532790496\n",
            "Loss in iteration no. 51316 ==> 0.34730659133727265\n",
            "Loss in iteration no. 51317 ==> 0.3473056073817433\n",
            "Loss in iteration no. 51318 ==> 0.34730462346131513\n",
            "Loss in iteration no. 51319 ==> 0.34730363957598653\n",
            "Loss in iteration no. 51320 ==> 0.34730265572575564\n",
            "Loss in iteration no. 51321 ==> 0.34730167191062067\n",
            "Loss in iteration no. 51322 ==> 0.34730068813057996\n",
            "Loss in iteration no. 51323 ==> 0.34729970438563185\n",
            "Loss in iteration no. 51324 ==> 0.3472987206757745\n",
            "Loss in iteration no. 51325 ==> 0.34729773700100625\n",
            "Loss in iteration no. 51326 ==> 0.3472967533613252\n",
            "Loss in iteration no. 51327 ==> 0.3472957697567299\n",
            "Loss in iteration no. 51328 ==> 0.34729478618721826\n",
            "Loss in iteration no. 51329 ==> 0.34729380265278886\n",
            "Loss in iteration no. 51330 ==> 0.3472928191534398\n",
            "Loss in iteration no. 51331 ==> 0.34729183568916944\n",
            "Loss in iteration no. 51332 ==> 0.3472908522599758\n",
            "Loss in iteration no. 51333 ==> 0.3472898688658575\n",
            "Loss in iteration no. 51334 ==> 0.3472888855068126\n",
            "Loss in iteration no. 51335 ==> 0.34728790218283934\n",
            "Loss in iteration no. 51336 ==> 0.34728691889393604\n",
            "Loss in iteration no. 51337 ==> 0.3472859356401011\n",
            "Loss in iteration no. 51338 ==> 0.3472849524213325\n",
            "Loss in iteration no. 51339 ==> 0.34728396923762866\n",
            "Loss in iteration no. 51340 ==> 0.34728298608898783\n",
            "Loss in iteration no. 51341 ==> 0.34728200297540834\n",
            "Loss in iteration no. 51342 ==> 0.34728101989688837\n",
            "Loss in iteration no. 51343 ==> 0.34728003685342623\n",
            "Loss in iteration no. 51344 ==> 0.34727905384502017\n",
            "Loss in iteration no. 51345 ==> 0.3472780708716684\n",
            "Loss in iteration no. 51346 ==> 0.3472770879333693\n",
            "Loss in iteration no. 51347 ==> 0.347276105030121\n",
            "Loss in iteration no. 51348 ==> 0.34727512216192197\n",
            "Loss in iteration no. 51349 ==> 0.3472741393287702\n",
            "Loss in iteration no. 51350 ==> 0.34727315653066426\n",
            "Loss in iteration no. 51351 ==> 0.3472721737676022\n",
            "Loss in iteration no. 51352 ==> 0.34727119103958226\n",
            "Loss in iteration no. 51353 ==> 0.347270208346603\n",
            "Loss in iteration no. 51354 ==> 0.34726922568866225\n",
            "Loss in iteration no. 51355 ==> 0.34726824306575854\n",
            "Loss in iteration no. 51356 ==> 0.34726726047789025\n",
            "Loss in iteration no. 51357 ==> 0.3472662779250554\n",
            "Loss in iteration no. 51358 ==> 0.3472652954072523\n",
            "Loss in iteration no. 51359 ==> 0.34726431292447935\n",
            "Loss in iteration no. 51360 ==> 0.3472633304767347\n",
            "Loss in iteration no. 51361 ==> 0.3472623480640168\n",
            "Loss in iteration no. 51362 ==> 0.3472613656863236\n",
            "Loss in iteration no. 51363 ==> 0.3472603833436536\n",
            "Loss in iteration no. 51364 ==> 0.347259401036005\n",
            "Loss in iteration no. 51365 ==> 0.34725841876337615\n",
            "Loss in iteration no. 51366 ==> 0.34725743652576524\n",
            "Loss in iteration no. 51367 ==> 0.34725645432317037\n",
            "Loss in iteration no. 51368 ==> 0.34725547215559005\n",
            "Loss in iteration no. 51369 ==> 0.34725449002302256\n",
            "Loss in iteration no. 51370 ==> 0.3472535079254661\n",
            "Loss in iteration no. 51371 ==> 0.3472525258629189\n",
            "Loss in iteration no. 51372 ==> 0.34725154383537915\n",
            "Loss in iteration no. 51373 ==> 0.3472505618428454\n",
            "Loss in iteration no. 51374 ==> 0.3472495798853157\n",
            "Loss in iteration no. 51375 ==> 0.3472485979627883\n",
            "Loss in iteration no. 51376 ==> 0.3472476160752615\n",
            "Loss in iteration no. 51377 ==> 0.3472466342227337\n",
            "Loss in iteration no. 51378 ==> 0.347245652405203\n",
            "Loss in iteration no. 51379 ==> 0.34724467062266784\n",
            "Loss in iteration no. 51380 ==> 0.3472436888751263\n",
            "Loss in iteration no. 51381 ==> 0.34724270716257677\n",
            "Loss in iteration no. 51382 ==> 0.34724172548501736\n",
            "Loss in iteration no. 51383 ==> 0.34724074384244663\n",
            "Loss in iteration no. 51384 ==> 0.34723976223486264\n",
            "Loss in iteration no. 51385 ==> 0.3472387806622637\n",
            "Loss in iteration no. 51386 ==> 0.3472377991246481\n",
            "Loss in iteration no. 51387 ==> 0.3472368176220141\n",
            "Loss in iteration no. 51388 ==> 0.3472358361543599\n",
            "Loss in iteration no. 51389 ==> 0.34723485472168386\n",
            "Loss in iteration no. 51390 ==> 0.3472338733239843\n",
            "Loss in iteration no. 51391 ==> 0.3472328919612594\n",
            "Loss in iteration no. 51392 ==> 0.3472319106335074\n",
            "Loss in iteration no. 51393 ==> 0.34723092934072664\n",
            "Loss in iteration no. 51394 ==> 0.3472299480829154\n",
            "Loss in iteration no. 51395 ==> 0.3472289668600719\n",
            "Loss in iteration no. 51396 ==> 0.3472279856721945\n",
            "Loss in iteration no. 51397 ==> 0.34722700451928123\n",
            "Loss in iteration no. 51398 ==> 0.3472260234013307\n",
            "Loss in iteration no. 51399 ==> 0.34722504231834095\n",
            "Loss in iteration no. 51400 ==> 0.3472240612703103\n",
            "Loss in iteration no. 51401 ==> 0.34722308025723714\n",
            "Loss in iteration no. 51402 ==> 0.3472220992791195\n",
            "Loss in iteration no. 51403 ==> 0.3472211183359559\n",
            "Loss in iteration no. 51404 ==> 0.3472201374277445\n",
            "Loss in iteration no. 51405 ==> 0.34721915655448354\n",
            "Loss in iteration no. 51406 ==> 0.34721817571617136\n",
            "Loss in iteration no. 51407 ==> 0.3472171949128062\n",
            "Loss in iteration no. 51408 ==> 0.34721621414438636\n",
            "Loss in iteration no. 51409 ==> 0.3472152334109101\n",
            "Loss in iteration no. 51410 ==> 0.34721425271237555\n",
            "Loss in iteration no. 51411 ==> 0.34721327204878133\n",
            "Loss in iteration no. 51412 ==> 0.34721229142012533\n",
            "Loss in iteration no. 51413 ==> 0.3472113108264061\n",
            "Loss in iteration no. 51414 ==> 0.34721033026762177\n",
            "Loss in iteration no. 51415 ==> 0.3472093497437706\n",
            "Loss in iteration no. 51416 ==> 0.347208369254851\n",
            "Loss in iteration no. 51417 ==> 0.347207388800861\n",
            "Loss in iteration no. 51418 ==> 0.34720640838179917\n",
            "Loss in iteration no. 51419 ==> 0.3472054279976636\n",
            "Loss in iteration no. 51420 ==> 0.34720444764845265\n",
            "Loss in iteration no. 51421 ==> 0.3472034673341645\n",
            "Loss in iteration no. 51422 ==> 0.34720248705479745\n",
            "Loss in iteration no. 51423 ==> 0.34720150681034984\n",
            "Loss in iteration no. 51424 ==> 0.34720052660081996\n",
            "Loss in iteration no. 51425 ==> 0.34719954642620593\n",
            "Loss in iteration no. 51426 ==> 0.3471985662865062\n",
            "Loss in iteration no. 51427 ==> 0.3471975861817189\n",
            "Loss in iteration no. 51428 ==> 0.3471966061118424\n",
            "Loss in iteration no. 51429 ==> 0.347195626076875\n",
            "Loss in iteration no. 51430 ==> 0.3471946460768148\n",
            "Loss in iteration no. 51431 ==> 0.34719366611166025\n",
            "Loss in iteration no. 51432 ==> 0.34719268618140964\n",
            "Loss in iteration no. 51433 ==> 0.34719170628606116\n",
            "Loss in iteration no. 51434 ==> 0.347190726425613\n",
            "Loss in iteration no. 51435 ==> 0.34718974660006363\n",
            "Loss in iteration no. 51436 ==> 0.34718876680941124\n",
            "Loss in iteration no. 51437 ==> 0.34718778705365405\n",
            "Loss in iteration no. 51438 ==> 0.34718680733279034\n",
            "Loss in iteration no. 51439 ==> 0.34718582764681855\n",
            "Loss in iteration no. 51440 ==> 0.3471848479957368\n",
            "Loss in iteration no. 51441 ==> 0.3471838683795433\n",
            "Loss in iteration no. 51442 ==> 0.34718288879823656\n",
            "Loss in iteration no. 51443 ==> 0.3471819092518147\n",
            "Loss in iteration no. 51444 ==> 0.347180929740276\n",
            "Loss in iteration no. 51445 ==> 0.34717995026361875\n",
            "Loss in iteration no. 51446 ==> 0.3471789708218412\n",
            "Loss in iteration no. 51447 ==> 0.34717799141494177\n",
            "Loss in iteration no. 51448 ==> 0.3471770120429185\n",
            "Loss in iteration no. 51449 ==> 0.3471760327057699\n",
            "Loss in iteration no. 51450 ==> 0.34717505340349414\n",
            "Loss in iteration no. 51451 ==> 0.3471740741360894\n",
            "Loss in iteration no. 51452 ==> 0.34717309490355425\n",
            "Loss in iteration no. 51453 ==> 0.3471721157058866\n",
            "Loss in iteration no. 51454 ==> 0.347171136543085\n",
            "Loss in iteration no. 51455 ==> 0.34717015741514756\n",
            "Loss in iteration no. 51456 ==> 0.3471691783220727\n",
            "Loss in iteration no. 51457 ==> 0.3471681992638586\n",
            "Loss in iteration no. 51458 ==> 0.3471672202405035\n",
            "Loss in iteration no. 51459 ==> 0.34716624125200585\n",
            "Loss in iteration no. 51460 ==> 0.34716526229836375\n",
            "Loss in iteration no. 51461 ==> 0.34716428337957556\n",
            "Loss in iteration no. 51462 ==> 0.34716330449563965\n",
            "Loss in iteration no. 51463 ==> 0.3471623256465541\n",
            "Loss in iteration no. 51464 ==> 0.3471613468323173\n",
            "Loss in iteration no. 51465 ==> 0.34716036805292755\n",
            "Loss in iteration no. 51466 ==> 0.3471593893083831\n",
            "Loss in iteration no. 51467 ==> 0.3471584105986822\n",
            "Loss in iteration no. 51468 ==> 0.3471574319238231\n",
            "Loss in iteration no. 51469 ==> 0.3471564532838042\n",
            "Loss in iteration no. 51470 ==> 0.34715547467862373\n",
            "Loss in iteration no. 51471 ==> 0.3471544961082798\n",
            "Loss in iteration no. 51472 ==> 0.347153517572771\n",
            "Loss in iteration no. 51473 ==> 0.3471525390720954\n",
            "Loss in iteration no. 51474 ==> 0.3471515606062514\n",
            "Loss in iteration no. 51475 ==> 0.3471505821752371\n",
            "Loss in iteration no. 51476 ==> 0.3471496037790509\n",
            "Loss in iteration no. 51477 ==> 0.3471486254176912\n",
            "Loss in iteration no. 51478 ==> 0.34714764709115603\n",
            "Loss in iteration no. 51479 ==> 0.3471466687994439\n",
            "Loss in iteration no. 51480 ==> 0.3471456905425528\n",
            "Loss in iteration no. 51481 ==> 0.3471447123204813\n",
            "Loss in iteration no. 51482 ==> 0.34714373413322763\n",
            "Loss in iteration no. 51483 ==> 0.3471427559807899\n",
            "Loss in iteration no. 51484 ==> 0.34714177786316663\n",
            "Loss in iteration no. 51485 ==> 0.3471407997803559\n",
            "Loss in iteration no. 51486 ==> 0.3471398217323561\n",
            "Loss in iteration no. 51487 ==> 0.3471388437191654\n",
            "Loss in iteration no. 51488 ==> 0.34713786574078226\n",
            "Loss in iteration no. 51489 ==> 0.3471368877972048\n",
            "Loss in iteration no. 51490 ==> 0.3471359098884314\n",
            "Loss in iteration no. 51491 ==> 0.3471349320144603\n",
            "Loss in iteration no. 51492 ==> 0.3471339541752898\n",
            "Loss in iteration no. 51493 ==> 0.3471329763709181\n",
            "Loss in iteration no. 51494 ==> 0.3471319986013436\n",
            "Loss in iteration no. 51495 ==> 0.34713102086656455\n",
            "Loss in iteration no. 51496 ==> 0.3471300431665792\n",
            "Loss in iteration no. 51497 ==> 0.34712906550138584\n",
            "Loss in iteration no. 51498 ==> 0.34712808787098276\n",
            "Loss in iteration no. 51499 ==> 0.34712711027536824\n",
            "Loss in iteration no. 51500 ==> 0.3471261327145405\n",
            "Loss in iteration no. 51501 ==> 0.347125155188498\n",
            "Loss in iteration no. 51502 ==> 0.34712417769723886\n",
            "Loss in iteration no. 51503 ==> 0.3471232002407615\n",
            "Loss in iteration no. 51504 ==> 0.3471222228190641\n",
            "Loss in iteration no. 51505 ==> 0.34712124543214484\n",
            "Loss in iteration no. 51506 ==> 0.34712026808000224\n",
            "Loss in iteration no. 51507 ==> 0.34711929076263437\n",
            "Loss in iteration no. 51508 ==> 0.3471183134800397\n",
            "Loss in iteration no. 51509 ==> 0.34711733623221636\n",
            "Loss in iteration no. 51510 ==> 0.34711635901916277\n",
            "Loss in iteration no. 51511 ==> 0.3471153818408771\n",
            "Loss in iteration no. 51512 ==> 0.34711440469735766\n",
            "Loss in iteration no. 51513 ==> 0.3471134275886027\n",
            "Loss in iteration no. 51514 ==> 0.3471124505146107\n",
            "Loss in iteration no. 51515 ==> 0.3471114734753798\n",
            "Loss in iteration no. 51516 ==> 0.3471104964709082\n",
            "Loss in iteration no. 51517 ==> 0.34710951950119423\n",
            "Loss in iteration no. 51518 ==> 0.3471085425662363\n",
            "Loss in iteration no. 51519 ==> 0.3471075656660325\n",
            "Loss in iteration no. 51520 ==> 0.34710658880058126\n",
            "Loss in iteration no. 51521 ==> 0.34710561196988093\n",
            "Loss in iteration no. 51522 ==> 0.34710463517392964\n",
            "Loss in iteration no. 51523 ==> 0.3471036584127257\n",
            "Loss in iteration no. 51524 ==> 0.34710268168626746\n",
            "Loss in iteration no. 51525 ==> 0.3471017049945532\n",
            "Loss in iteration no. 51526 ==> 0.3471007283375811\n",
            "Loss in iteration no. 51527 ==> 0.34709975171534957\n",
            "Loss in iteration no. 51528 ==> 0.3470987751278568\n",
            "Loss in iteration no. 51529 ==> 0.3470977985751012\n",
            "Loss in iteration no. 51530 ==> 0.34709682205708087\n",
            "Loss in iteration no. 51531 ==> 0.34709584557379425\n",
            "Loss in iteration no. 51532 ==> 0.3470948691252396\n",
            "Loss in iteration no. 51533 ==> 0.3470938927114152\n",
            "Loss in iteration no. 51534 ==> 0.3470929163323194\n",
            "Loss in iteration no. 51535 ==> 0.3470919399879503\n",
            "Loss in iteration no. 51536 ==> 0.3470909636783063\n",
            "Loss in iteration no. 51537 ==> 0.3470899874033857\n",
            "Loss in iteration no. 51538 ==> 0.3470890111631868\n",
            "Loss in iteration no. 51539 ==> 0.3470880349577078\n",
            "Loss in iteration no. 51540 ==> 0.347087058786947\n",
            "Loss in iteration no. 51541 ==> 0.3470860826509029\n",
            "Loss in iteration no. 51542 ==> 0.3470851065495735\n",
            "Loss in iteration no. 51543 ==> 0.3470841304829573\n",
            "Loss in iteration no. 51544 ==> 0.3470831544510524\n",
            "Loss in iteration no. 51545 ==> 0.34708217845385725\n",
            "Loss in iteration no. 51546 ==> 0.34708120249137003\n",
            "Loss in iteration no. 51547 ==> 0.3470802265635891\n",
            "Loss in iteration no. 51548 ==> 0.34707925067051265\n",
            "Loss in iteration no. 51549 ==> 0.3470782748121391\n",
            "Loss in iteration no. 51550 ==> 0.3470772989884666\n",
            "Loss in iteration no. 51551 ==> 0.3470763231994936\n",
            "Loss in iteration no. 51552 ==> 0.3470753474452183\n",
            "Loss in iteration no. 51553 ==> 0.3470743717256389\n",
            "Loss in iteration no. 51554 ==> 0.3470733960407539\n",
            "Loss in iteration no. 51555 ==> 0.34707242039056135\n",
            "Loss in iteration no. 51556 ==> 0.3470714447750597\n",
            "Loss in iteration no. 51557 ==> 0.3470704691942472\n",
            "Loss in iteration no. 51558 ==> 0.3470694936481221\n",
            "Loss in iteration no. 51559 ==> 0.34706851813668277\n",
            "Loss in iteration no. 51560 ==> 0.3470675426599274\n",
            "Loss in iteration no. 51561 ==> 0.3470665672178543\n",
            "Loss in iteration no. 51562 ==> 0.347065591810462\n",
            "Loss in iteration no. 51563 ==> 0.3470646164377483\n",
            "Loss in iteration no. 51564 ==> 0.3470636410997119\n",
            "Loss in iteration no. 51565 ==> 0.347062665796351\n",
            "Loss in iteration no. 51566 ==> 0.3470616905276638\n",
            "Loss in iteration no. 51567 ==> 0.3470607152936487\n",
            "Loss in iteration no. 51568 ==> 0.34705974009430385\n",
            "Loss in iteration no. 51569 ==> 0.34705876492962767\n",
            "Loss in iteration no. 51570 ==> 0.3470577897996183\n",
            "Loss in iteration no. 51571 ==> 0.34705681470427435\n",
            "Loss in iteration no. 51572 ==> 0.34705583964359366\n",
            "Loss in iteration no. 51573 ==> 0.3470548646175749\n",
            "Loss in iteration no. 51574 ==> 0.34705388962621614\n",
            "Loss in iteration no. 51575 ==> 0.34705291466951577\n",
            "Loss in iteration no. 51576 ==> 0.34705193974747206\n",
            "Loss in iteration no. 51577 ==> 0.34705096486008324\n",
            "Loss in iteration no. 51578 ==> 0.34704999000734776\n",
            "Loss in iteration no. 51579 ==> 0.34704901518926373\n",
            "Loss in iteration no. 51580 ==> 0.34704804040582954\n",
            "Loss in iteration no. 51581 ==> 0.34704706565704346\n",
            "Loss in iteration no. 51582 ==> 0.3470460909429038\n",
            "Loss in iteration no. 51583 ==> 0.34704511626340884\n",
            "Loss in iteration no. 51584 ==> 0.34704414161855685\n",
            "Loss in iteration no. 51585 ==> 0.34704316700834614\n",
            "Loss in iteration no. 51586 ==> 0.34704219243277507\n",
            "Loss in iteration no. 51587 ==> 0.3470412178918418\n",
            "Loss in iteration no. 51588 ==> 0.3470402433855446\n",
            "Loss in iteration no. 51589 ==> 0.3470392689138819\n",
            "Loss in iteration no. 51590 ==> 0.3470382944768521\n",
            "Loss in iteration no. 51591 ==> 0.34703732007445315\n",
            "Loss in iteration no. 51592 ==> 0.3470363457066836\n",
            "Loss in iteration no. 51593 ==> 0.3470353713735418\n",
            "Loss in iteration no. 51594 ==> 0.3470343970750257\n",
            "Loss in iteration no. 51595 ==> 0.3470334228111339\n",
            "Loss in iteration no. 51596 ==> 0.34703244858186455\n",
            "Loss in iteration no. 51597 ==> 0.34703147438721604\n",
            "Loss in iteration no. 51598 ==> 0.3470305002271866\n",
            "Loss in iteration no. 51599 ==> 0.3470295261017746\n",
            "Loss in iteration no. 51600 ==> 0.3470285520109782\n",
            "Loss in iteration no. 51601 ==> 0.34702757795479583\n",
            "Loss in iteration no. 51602 ==> 0.34702660393322565\n",
            "Loss in iteration no. 51603 ==> 0.3470256299462661\n",
            "Loss in iteration no. 51604 ==> 0.3470246559939153\n",
            "Loss in iteration no. 51605 ==> 0.34702368207617174\n",
            "Loss in iteration no. 51606 ==> 0.34702270819303355\n",
            "Loss in iteration no. 51607 ==> 0.34702173434449923\n",
            "Loss in iteration no. 51608 ==> 0.34702076053056685\n",
            "Loss in iteration no. 51609 ==> 0.34701978675123474\n",
            "Loss in iteration no. 51610 ==> 0.34701881300650134\n",
            "Loss in iteration no. 51611 ==> 0.3470178392963647\n",
            "Loss in iteration no. 51612 ==> 0.34701686562082346\n",
            "Loss in iteration no. 51613 ==> 0.34701589197987565\n",
            "Loss in iteration no. 51614 ==> 0.3470149183735196\n",
            "Loss in iteration no. 51615 ==> 0.3470139448017536\n",
            "Loss in iteration no. 51616 ==> 0.3470129712645761\n",
            "Loss in iteration no. 51617 ==> 0.3470119977619853\n",
            "Loss in iteration no. 51618 ==> 0.3470110242939794\n",
            "Loss in iteration no. 51619 ==> 0.34701005086055675\n",
            "Loss in iteration no. 51620 ==> 0.34700907746171566\n",
            "Loss in iteration no. 51621 ==> 0.34700810409745453\n",
            "Loss in iteration no. 51622 ==> 0.34700713076777157\n",
            "Loss in iteration no. 51623 ==> 0.347006157472665\n",
            "Loss in iteration no. 51624 ==> 0.3470051842121332\n",
            "Loss in iteration no. 51625 ==> 0.34700421098617457\n",
            "Loss in iteration no. 51626 ==> 0.3470032377947871\n",
            "Loss in iteration no. 51627 ==> 0.34700226463796946\n",
            "Loss in iteration no. 51628 ==> 0.3470012915157197\n",
            "Loss in iteration no. 51629 ==> 0.347000318428036\n",
            "Loss in iteration no. 51630 ==> 0.34699934537491706\n",
            "Loss in iteration no. 51631 ==> 0.34699837235636083\n",
            "Loss in iteration no. 51632 ==> 0.34699739937236584\n",
            "Loss in iteration no. 51633 ==> 0.3469964264229302\n",
            "Loss in iteration no. 51634 ==> 0.3469954535080524\n",
            "Loss in iteration no. 51635 ==> 0.3469944806277305\n",
            "Loss in iteration no. 51636 ==> 0.34699350778196286\n",
            "Loss in iteration no. 51637 ==> 0.34699253497074795\n",
            "Loss in iteration no. 51638 ==> 0.346991562194084\n",
            "Loss in iteration no. 51639 ==> 0.3469905894519692\n",
            "Loss in iteration no. 51640 ==> 0.34698961674440193\n",
            "Loss in iteration no. 51641 ==> 0.3469886440713804\n",
            "Loss in iteration no. 51642 ==> 0.3469876714329031\n",
            "Loss in iteration no. 51643 ==> 0.3469866988289681\n",
            "Loss in iteration no. 51644 ==> 0.34698572625957386\n",
            "Loss in iteration no. 51645 ==> 0.34698475372471865\n",
            "Loss in iteration no. 51646 ==> 0.34698378122440066\n",
            "Loss in iteration no. 51647 ==> 0.3469828087586183\n",
            "Loss in iteration no. 51648 ==> 0.3469818363273699\n",
            "Loss in iteration no. 51649 ==> 0.3469808639306536\n",
            "Loss in iteration no. 51650 ==> 0.3469798915684679\n",
            "Loss in iteration no. 51651 ==> 0.34697891924081103\n",
            "Loss in iteration no. 51652 ==> 0.3469779469476811\n",
            "Loss in iteration no. 51653 ==> 0.3469769746890767\n",
            "Loss in iteration no. 51654 ==> 0.34697600246499594\n",
            "Loss in iteration no. 51655 ==> 0.3469750302754372\n",
            "Loss in iteration no. 51656 ==> 0.3469740581203987\n",
            "Loss in iteration no. 51657 ==> 0.34697308599987886\n",
            "Loss in iteration no. 51658 ==> 0.3469721139138759\n",
            "Loss in iteration no. 51659 ==> 0.34697114186238814\n",
            "Loss in iteration no. 51660 ==> 0.3469701698454139\n",
            "Loss in iteration no. 51661 ==> 0.34696919786295144\n",
            "Loss in iteration no. 51662 ==> 0.34696822591499904\n",
            "Loss in iteration no. 51663 ==> 0.34696725400155515\n",
            "Loss in iteration no. 51664 ==> 0.3469662821226178\n",
            "Loss in iteration no. 51665 ==> 0.34696531027818556\n",
            "Loss in iteration no. 51666 ==> 0.3469643384682566\n",
            "Loss in iteration no. 51667 ==> 0.34696336669282923\n",
            "Loss in iteration no. 51668 ==> 0.34696239495190173\n",
            "Loss in iteration no. 51669 ==> 0.3469614232454725\n",
            "Loss in iteration no. 51670 ==> 0.3469604515735398\n",
            "Loss in iteration no. 51671 ==> 0.3469594799361018\n",
            "Loss in iteration no. 51672 ==> 0.34695850833315695\n",
            "Loss in iteration no. 51673 ==> 0.34695753676470353\n",
            "Loss in iteration no. 51674 ==> 0.3469565652307398\n",
            "Loss in iteration no. 51675 ==> 0.34695559373126417\n",
            "Loss in iteration no. 51676 ==> 0.34695462226627477\n",
            "Loss in iteration no. 51677 ==> 0.34695365083577\n",
            "Loss in iteration no. 51678 ==> 0.3469526794397482\n",
            "Loss in iteration no. 51679 ==> 0.34695170807820763\n",
            "Loss in iteration no. 51680 ==> 0.34695073675114646\n",
            "Loss in iteration no. 51681 ==> 0.3469497654585632\n",
            "Loss in iteration no. 51682 ==> 0.34694879420045605\n",
            "Loss in iteration no. 51683 ==> 0.3469478229768234\n",
            "Loss in iteration no. 51684 ==> 0.34694685178766344\n",
            "Loss in iteration no. 51685 ==> 0.34694588063297455\n",
            "Loss in iteration no. 51686 ==> 0.3469449095127549\n",
            "Loss in iteration no. 51687 ==> 0.3469439384270029\n",
            "Loss in iteration no. 51688 ==> 0.34694296737571695\n",
            "Loss in iteration no. 51689 ==> 0.3469419963588952\n",
            "Loss in iteration no. 51690 ==> 0.3469410253765361\n",
            "Loss in iteration no. 51691 ==> 0.3469400544286378\n",
            "Loss in iteration no. 51692 ==> 0.34693908351519864\n",
            "Loss in iteration no. 51693 ==> 0.346938112636217\n",
            "Loss in iteration no. 51694 ==> 0.346937141791691\n",
            "Loss in iteration no. 51695 ==> 0.34693617098161916\n",
            "Loss in iteration no. 51696 ==> 0.34693520020599977\n",
            "Loss in iteration no. 51697 ==> 0.3469342294648309\n",
            "Loss in iteration no. 51698 ==> 0.34693325875811115\n",
            "Loss in iteration no. 51699 ==> 0.3469322880858387\n",
            "Loss in iteration no. 51700 ==> 0.34693131744801176\n",
            "Loss in iteration no. 51701 ==> 0.34693034684462876\n",
            "Loss in iteration no. 51702 ==> 0.346929376275688\n",
            "Loss in iteration no. 51703 ==> 0.3469284057411877\n",
            "Loss in iteration no. 51704 ==> 0.34692743524112624\n",
            "Loss in iteration no. 51705 ==> 0.34692646477550193\n",
            "Loss in iteration no. 51706 ==> 0.346925494344313\n",
            "Loss in iteration no. 51707 ==> 0.3469245239475578\n",
            "Loss in iteration no. 51708 ==> 0.3469235535852347\n",
            "Loss in iteration no. 51709 ==> 0.34692258325734193\n",
            "Loss in iteration no. 51710 ==> 0.3469216129638777\n",
            "Loss in iteration no. 51711 ==> 0.3469206427048406\n",
            "Loss in iteration no. 51712 ==> 0.3469196724802286\n",
            "Loss in iteration no. 51713 ==> 0.34691870229004024\n",
            "Loss in iteration no. 51714 ==> 0.34691773213427374\n",
            "Loss in iteration no. 51715 ==> 0.3469167620129275\n",
            "Loss in iteration no. 51716 ==> 0.34691579192599964\n",
            "Loss in iteration no. 51717 ==> 0.3469148218734886\n",
            "Loss in iteration no. 51718 ==> 0.34691385185539264\n",
            "Loss in iteration no. 51719 ==> 0.3469128818717101\n",
            "Loss in iteration no. 51720 ==> 0.3469119119224393\n",
            "Loss in iteration no. 51721 ==> 0.34691094200757855\n",
            "Loss in iteration no. 51722 ==> 0.34690997212712604\n",
            "Loss in iteration no. 51723 ==> 0.34690900228108024\n",
            "Loss in iteration no. 51724 ==> 0.3469080324694393\n",
            "Loss in iteration no. 51725 ==> 0.3469070626922017\n",
            "Loss in iteration no. 51726 ==> 0.3469060929493655\n",
            "Loss in iteration no. 51727 ==> 0.3469051232409293\n",
            "Loss in iteration no. 51728 ==> 0.3469041535668913\n",
            "Loss in iteration no. 51729 ==> 0.3469031839272497\n",
            "Loss in iteration no. 51730 ==> 0.34690221432200286\n",
            "Loss in iteration no. 51731 ==> 0.3469012447511492\n",
            "Loss in iteration no. 51732 ==> 0.34690027521468686\n",
            "Loss in iteration no. 51733 ==> 0.3468993057126143\n",
            "Loss in iteration no. 51734 ==> 0.3468983362449297\n",
            "Loss in iteration no. 51735 ==> 0.3468973668116315\n",
            "Loss in iteration no. 51736 ==> 0.3468963974127179\n",
            "Loss in iteration no. 51737 ==> 0.3468954280481872\n",
            "Loss in iteration no. 51738 ==> 0.34689445871803776\n",
            "Loss in iteration no. 51739 ==> 0.3468934894222679\n",
            "Loss in iteration no. 51740 ==> 0.3468925201608759\n",
            "Loss in iteration no. 51741 ==> 0.34689155093386015\n",
            "Loss in iteration no. 51742 ==> 0.34689058174121884\n",
            "Loss in iteration no. 51743 ==> 0.3468896125829503\n",
            "Loss in iteration no. 51744 ==> 0.34688864345905285\n",
            "Loss in iteration no. 51745 ==> 0.346887674369525\n",
            "Loss in iteration no. 51746 ==> 0.34688670531436466\n",
            "Loss in iteration no. 51747 ==> 0.3468857362935704\n",
            "Loss in iteration no. 51748 ==> 0.3468847673071406\n",
            "Loss in iteration no. 51749 ==> 0.3468837983550733\n",
            "Loss in iteration no. 51750 ==> 0.34688282943736715\n",
            "Loss in iteration no. 51751 ==> 0.3468818605540201\n",
            "Loss in iteration no. 51752 ==> 0.3468808917050308\n",
            "Loss in iteration no. 51753 ==> 0.3468799228903972\n",
            "Loss in iteration no. 51754 ==> 0.34687895411011793\n",
            "Loss in iteration no. 51755 ==> 0.3468779853641911\n",
            "Loss in iteration no. 51756 ==> 0.3468770166526153\n",
            "Loss in iteration no. 51757 ==> 0.34687604797538835\n",
            "Loss in iteration no. 51758 ==> 0.34687507933250905\n",
            "Loss in iteration no. 51759 ==> 0.3468741107239755\n",
            "Loss in iteration no. 51760 ==> 0.346873142149786\n",
            "Loss in iteration no. 51761 ==> 0.34687217360993877\n",
            "Loss in iteration no. 51762 ==> 0.3468712051044323\n",
            "Loss in iteration no. 51763 ==> 0.3468702366332649\n",
            "Loss in iteration no. 51764 ==> 0.3468692681964348\n",
            "Loss in iteration no. 51765 ==> 0.3468682997939403\n",
            "Loss in iteration no. 51766 ==> 0.34686733142577975\n",
            "Loss in iteration no. 51767 ==> 0.3468663630919515\n",
            "Loss in iteration no. 51768 ==> 0.34686539479245376\n",
            "Loss in iteration no. 51769 ==> 0.3468644265272849\n",
            "Loss in iteration no. 51770 ==> 0.3468634582964432\n",
            "Loss in iteration no. 51771 ==> 0.3468624900999271\n",
            "Loss in iteration no. 51772 ==> 0.3468615219377348\n",
            "Loss in iteration no. 51773 ==> 0.3468605538098645\n",
            "Loss in iteration no. 51774 ==> 0.3468595857163147\n",
            "Loss in iteration no. 51775 ==> 0.3468586176570837\n",
            "Loss in iteration no. 51776 ==> 0.34685764963216986\n",
            "Loss in iteration no. 51777 ==> 0.34685668164157124\n",
            "Loss in iteration no. 51778 ==> 0.3468557136852863\n",
            "Loss in iteration no. 51779 ==> 0.34685474576331343\n",
            "Loss in iteration no. 51780 ==> 0.3468537778756508\n",
            "Loss in iteration no. 51781 ==> 0.3468528100222969\n",
            "Loss in iteration no. 51782 ==> 0.3468518422032499\n",
            "Loss in iteration no. 51783 ==> 0.34685087441850815\n",
            "Loss in iteration no. 51784 ==> 0.34684990666807\n",
            "Loss in iteration no. 51785 ==> 0.34684893895193364\n",
            "Loss in iteration no. 51786 ==> 0.3468479712700976\n",
            "Loss in iteration no. 51787 ==> 0.3468470036225601\n",
            "Loss in iteration no. 51788 ==> 0.3468460360093193\n",
            "Loss in iteration no. 51789 ==> 0.3468450684303737\n",
            "Loss in iteration no. 51790 ==> 0.34684410088572154\n",
            "Loss in iteration no. 51791 ==> 0.34684313337536116\n",
            "Loss in iteration no. 51792 ==> 0.34684216589929084\n",
            "Loss in iteration no. 51793 ==> 0.346841198457509\n",
            "Loss in iteration no. 51794 ==> 0.3468402310500138\n",
            "Loss in iteration no. 51795 ==> 0.3468392636768036\n",
            "Loss in iteration no. 51796 ==> 0.34683829633787683\n",
            "Loss in iteration no. 51797 ==> 0.34683732903323167\n",
            "Loss in iteration no. 51798 ==> 0.3468363617628666\n",
            "Loss in iteration no. 51799 ==> 0.3468353945267797\n",
            "Loss in iteration no. 51800 ==> 0.3468344273249694\n",
            "Loss in iteration no. 51801 ==> 0.34683346015743405\n",
            "Loss in iteration no. 51802 ==> 0.34683249302417196\n",
            "Loss in iteration no. 51803 ==> 0.34683152592518135\n",
            "Loss in iteration no. 51804 ==> 0.34683055886046066\n",
            "Loss in iteration no. 51805 ==> 0.34682959183000817\n",
            "Loss in iteration no. 51806 ==> 0.34682862483382215\n",
            "Loss in iteration no. 51807 ==> 0.34682765787190095\n",
            "Loss in iteration no. 51808 ==> 0.3468266909442429\n",
            "Loss in iteration no. 51809 ==> 0.3468257240508463\n",
            "Loss in iteration no. 51810 ==> 0.3468247571917094\n",
            "Loss in iteration no. 51811 ==> 0.34682379036683064\n",
            "Loss in iteration no. 51812 ==> 0.34682282357620825\n",
            "Loss in iteration no. 51813 ==> 0.3468218568198406\n",
            "Loss in iteration no. 51814 ==> 0.34682089009772604\n",
            "Loss in iteration no. 51815 ==> 0.3468199234098628\n",
            "Loss in iteration no. 51816 ==> 0.34681895675624913\n",
            "Loss in iteration no. 51817 ==> 0.3468179901368835\n",
            "Loss in iteration no. 51818 ==> 0.34681702355176425\n",
            "Loss in iteration no. 51819 ==> 0.3468160570008895\n",
            "Loss in iteration no. 51820 ==> 0.3468150904842578\n",
            "Loss in iteration no. 51821 ==> 0.3468141240018673\n",
            "Loss in iteration no. 51822 ==> 0.34681315755371633\n",
            "Loss in iteration no. 51823 ==> 0.34681219113980327\n",
            "Loss in iteration no. 51824 ==> 0.3468112247601265\n",
            "Loss in iteration no. 51825 ==> 0.3468102584146841\n",
            "Loss in iteration no. 51826 ==> 0.3468092921034746\n",
            "Loss in iteration no. 51827 ==> 0.3468083258264963\n",
            "Loss in iteration no. 51828 ==> 0.3468073595837476\n",
            "Loss in iteration no. 51829 ==> 0.34680639337522645\n",
            "Loss in iteration no. 51830 ==> 0.3468054272009316\n",
            "Loss in iteration no. 51831 ==> 0.3468044610608611\n",
            "Loss in iteration no. 51832 ==> 0.3468034949550134\n",
            "Loss in iteration no. 51833 ==> 0.34680252888338675\n",
            "Loss in iteration no. 51834 ==> 0.34680156284597946\n",
            "Loss in iteration no. 51835 ==> 0.34680059684278997\n",
            "Loss in iteration no. 51836 ==> 0.3467996308738165\n",
            "Loss in iteration no. 51837 ==> 0.34679866493905726\n",
            "Loss in iteration no. 51838 ==> 0.3467976990385109\n",
            "Loss in iteration no. 51839 ==> 0.3467967331721753\n",
            "Loss in iteration no. 51840 ==> 0.3467957673400492\n",
            "Loss in iteration no. 51841 ==> 0.34679480154213066\n",
            "Loss in iteration no. 51842 ==> 0.34679383577841805\n",
            "Loss in iteration no. 51843 ==> 0.34679287004890974\n",
            "Loss in iteration no. 51844 ==> 0.34679190435360396\n",
            "Loss in iteration no. 51845 ==> 0.3467909386924992\n",
            "Loss in iteration no. 51846 ==> 0.34678997306559356\n",
            "Loss in iteration no. 51847 ==> 0.3467890074728855\n",
            "Loss in iteration no. 51848 ==> 0.34678804191437335\n",
            "Loss in iteration no. 51849 ==> 0.34678707639005535\n",
            "Loss in iteration no. 51850 ==> 0.34678611089992994\n",
            "Loss in iteration no. 51851 ==> 0.3467851454439953\n",
            "Loss in iteration no. 51852 ==> 0.3467841800222498\n",
            "Loss in iteration no. 51853 ==> 0.3467832146346918\n",
            "Loss in iteration no. 51854 ==> 0.34678224928131957\n",
            "Loss in iteration no. 51855 ==> 0.34678128396213154\n",
            "Loss in iteration no. 51856 ==> 0.3467803186771259\n",
            "Loss in iteration no. 51857 ==> 0.346779353426301\n",
            "Loss in iteration no. 51858 ==> 0.34677838820965523\n",
            "Loss in iteration no. 51859 ==> 0.34677742302718684\n",
            "Loss in iteration no. 51860 ==> 0.34677645787889416\n",
            "Loss in iteration no. 51861 ==> 0.3467754927647756\n",
            "Loss in iteration no. 51862 ==> 0.3467745276848293\n",
            "Loss in iteration no. 51863 ==> 0.34677356263905373\n",
            "Loss in iteration no. 51864 ==> 0.3467725976274473\n",
            "Loss in iteration no. 51865 ==> 0.34677163265000804\n",
            "Loss in iteration no. 51866 ==> 0.3467706677067346\n",
            "Loss in iteration no. 51867 ==> 0.34676970279762503\n",
            "Loss in iteration no. 51868 ==> 0.3467687379226778\n",
            "Loss in iteration no. 51869 ==> 0.34676777308189116\n",
            "Loss in iteration no. 51870 ==> 0.34676680827526346\n",
            "Loss in iteration no. 51871 ==> 0.34676584350279316\n",
            "Loss in iteration no. 51872 ==> 0.3467648787644783\n",
            "Loss in iteration no. 51873 ==> 0.3467639140603175\n",
            "Loss in iteration no. 51874 ==> 0.3467629493903089\n",
            "Loss in iteration no. 51875 ==> 0.3467619847544508\n",
            "Loss in iteration no. 51876 ==> 0.3467610201527417\n",
            "Loss in iteration no. 51877 ==> 0.34676005558517975\n",
            "Loss in iteration no. 51878 ==> 0.3467590910517634\n",
            "Loss in iteration no. 51879 ==> 0.34675812655249083\n",
            "Loss in iteration no. 51880 ==> 0.34675716208736046\n",
            "Loss in iteration no. 51881 ==> 0.34675619765637067\n",
            "Loss in iteration no. 51882 ==> 0.3467552332595196\n",
            "Loss in iteration no. 51883 ==> 0.3467542688968058\n",
            "Loss in iteration no. 51884 ==> 0.3467533045682274\n",
            "Loss in iteration no. 51885 ==> 0.3467523402737829\n",
            "Loss in iteration no. 51886 ==> 0.3467513760134704\n",
            "Loss in iteration no. 51887 ==> 0.3467504117872885\n",
            "Loss in iteration no. 51888 ==> 0.34674944759523535\n",
            "Loss in iteration no. 51889 ==> 0.3467484834373092\n",
            "Loss in iteration no. 51890 ==> 0.3467475193135086\n",
            "Loss in iteration no. 51891 ==> 0.3467465552238318\n",
            "Loss in iteration no. 51892 ==> 0.3467455911682769\n",
            "Loss in iteration no. 51893 ==> 0.3467446271468426\n",
            "Loss in iteration no. 51894 ==> 0.346743663159527\n",
            "Loss in iteration no. 51895 ==> 0.3467426992063284\n",
            "Loss in iteration no. 51896 ==> 0.34674173528724517\n",
            "Loss in iteration no. 51897 ==> 0.3467407714022756\n",
            "Loss in iteration no. 51898 ==> 0.3467398075514182\n",
            "Loss in iteration no. 51899 ==> 0.3467388437346711\n",
            "Loss in iteration no. 51900 ==> 0.3467378799520328\n",
            "Loss in iteration no. 51901 ==> 0.34673691620350133\n",
            "Loss in iteration no. 51902 ==> 0.3467359524890754\n",
            "Loss in iteration no. 51903 ==> 0.3467349888087531\n",
            "Loss in iteration no. 51904 ==> 0.3467340251625327\n",
            "Loss in iteration no. 51905 ==> 0.34673306155041256\n",
            "Loss in iteration no. 51906 ==> 0.3467320979723912\n",
            "Loss in iteration no. 51907 ==> 0.3467311344284668\n",
            "Loss in iteration no. 51908 ==> 0.3467301709186377\n",
            "Loss in iteration no. 51909 ==> 0.34672920744290225\n",
            "Loss in iteration no. 51910 ==> 0.34672824400125873\n",
            "Loss in iteration no. 51911 ==> 0.34672728059370544\n",
            "Loss in iteration no. 51912 ==> 0.34672631722024083\n",
            "Loss in iteration no. 51913 ==> 0.3467253538808632\n",
            "Loss in iteration no. 51914 ==> 0.34672439057557075\n",
            "Loss in iteration no. 51915 ==> 0.34672342730436195\n",
            "Loss in iteration no. 51916 ==> 0.3467224640672349\n",
            "Loss in iteration no. 51917 ==> 0.34672150086418835\n",
            "Loss in iteration no. 51918 ==> 0.34672053769522027\n",
            "Loss in iteration no. 51919 ==> 0.34671957456032904\n",
            "Loss in iteration no. 51920 ==> 0.3467186114595132\n",
            "Loss in iteration no. 51921 ==> 0.34671764839277075\n",
            "Loss in iteration no. 51922 ==> 0.34671668536010025\n",
            "Loss in iteration no. 51923 ==> 0.3467157223615\n",
            "Loss in iteration no. 51924 ==> 0.3467147593969684\n",
            "Loss in iteration no. 51925 ==> 0.3467137964665035\n",
            "Loss in iteration no. 51926 ==> 0.3467128335701039\n",
            "Loss in iteration no. 51927 ==> 0.3467118707077679\n",
            "Loss in iteration no. 51928 ==> 0.3467109078794936\n",
            "Loss in iteration no. 51929 ==> 0.34670994508527964\n",
            "Loss in iteration no. 51930 ==> 0.34670898232512415\n",
            "Loss in iteration no. 51931 ==> 0.34670801959902553\n",
            "Loss in iteration no. 51932 ==> 0.3467070569069821\n",
            "Loss in iteration no. 51933 ==> 0.3467060942489921\n",
            "Loss in iteration no. 51934 ==> 0.346705131625054\n",
            "Loss in iteration no. 51935 ==> 0.3467041690351661\n",
            "Loss in iteration no. 51936 ==> 0.3467032064793266\n",
            "Loss in iteration no. 51937 ==> 0.3467022439575341\n",
            "Loss in iteration no. 51938 ==> 0.3467012814697866\n",
            "Loss in iteration no. 51939 ==> 0.3467003190160827\n",
            "Loss in iteration no. 51940 ==> 0.34669935659642065\n",
            "Loss in iteration no. 51941 ==> 0.3466983942107987\n",
            "Loss in iteration no. 51942 ==> 0.3466974318592152\n",
            "Loss in iteration no. 51943 ==> 0.34669646954166855\n",
            "Loss in iteration no. 51944 ==> 0.34669550725815707\n",
            "Loss in iteration no. 51945 ==> 0.34669454500867897\n",
            "Loss in iteration no. 51946 ==> 0.34669358279323276\n",
            "Loss in iteration no. 51947 ==> 0.3466926206118167\n",
            "Loss in iteration no. 51948 ==> 0.34669165846442906\n",
            "Loss in iteration no. 51949 ==> 0.3466906963510683\n",
            "Loss in iteration no. 51950 ==> 0.3466897342717326\n",
            "Loss in iteration no. 51951 ==> 0.3466887722264204\n",
            "Loss in iteration no. 51952 ==> 0.34668781021513\n",
            "Loss in iteration no. 51953 ==> 0.3466868482378597\n",
            "Loss in iteration no. 51954 ==> 0.3466858862946079\n",
            "Loss in iteration no. 51955 ==> 0.34668492438537285\n",
            "Loss in iteration no. 51956 ==> 0.346683962510153\n",
            "Loss in iteration no. 51957 ==> 0.34668300066894653\n",
            "Loss in iteration no. 51958 ==> 0.34668203886175186\n",
            "Loss in iteration no. 51959 ==> 0.3466810770885674\n",
            "Loss in iteration no. 51960 ==> 0.3466801153493913\n",
            "Loss in iteration no. 51961 ==> 0.34667915364422197\n",
            "Loss in iteration no. 51962 ==> 0.3466781919730578\n",
            "Loss in iteration no. 51963 ==> 0.3466772303358971\n",
            "Loss in iteration no. 51964 ==> 0.34667626873273816\n",
            "Loss in iteration no. 51965 ==> 0.3466753071635793\n",
            "Loss in iteration no. 51966 ==> 0.346674345628419\n",
            "Loss in iteration no. 51967 ==> 0.34667338412725535\n",
            "Loss in iteration no. 51968 ==> 0.3466724226600869\n",
            "Loss in iteration no. 51969 ==> 0.3466714612269119\n",
            "Loss in iteration no. 51970 ==> 0.34667049982772863\n",
            "Loss in iteration no. 51971 ==> 0.3466695384625356\n",
            "Loss in iteration no. 51972 ==> 0.3466685771313309\n",
            "Loss in iteration no. 51973 ==> 0.3466676158341131\n",
            "Loss in iteration no. 51974 ==> 0.34666665457088036\n",
            "Loss in iteration no. 51975 ==> 0.34666569334163116\n",
            "Loss in iteration no. 51976 ==> 0.3466647321463636\n",
            "Loss in iteration no. 51977 ==> 0.3466637709850763\n",
            "Loss in iteration no. 51978 ==> 0.3466628098577674\n",
            "Loss in iteration no. 51979 ==> 0.34666184876443523\n",
            "Loss in iteration no. 51980 ==> 0.3466608877050782\n",
            "Loss in iteration no. 51981 ==> 0.34665992667969464\n",
            "Loss in iteration no. 51982 ==> 0.34665896568828297\n",
            "Loss in iteration no. 51983 ==> 0.3466580047308414\n",
            "Loss in iteration no. 51984 ==> 0.3466570438073682\n",
            "Loss in iteration no. 51985 ==> 0.3466560829178619\n",
            "Loss in iteration no. 51986 ==> 0.34665512206232074\n",
            "Loss in iteration no. 51987 ==> 0.346654161240743\n",
            "Loss in iteration no. 51988 ==> 0.3466532004531271\n",
            "Loss in iteration no. 51989 ==> 0.3466522396994714\n",
            "Loss in iteration no. 51990 ==> 0.34665127897977405\n",
            "Loss in iteration no. 51991 ==> 0.34665031829403364\n",
            "Loss in iteration no. 51992 ==> 0.34664935764224825\n",
            "Loss in iteration no. 51993 ==> 0.34664839702441647\n",
            "Loss in iteration no. 51994 ==> 0.34664743644053647\n",
            "Loss in iteration no. 51995 ==> 0.3466464758906066\n",
            "Loss in iteration no. 51996 ==> 0.3466455153746253\n",
            "Loss in iteration no. 51997 ==> 0.34664455489259083\n",
            "Loss in iteration no. 51998 ==> 0.3466435944445015\n",
            "Loss in iteration no. 51999 ==> 0.34664263403035567\n",
            "Loss in iteration no. 52000 ==> 0.3466416736501517\n",
            "Loss in iteration no. 52001 ==> 0.34664071330388785\n",
            "Loss in iteration no. 52002 ==> 0.3466397529915626\n",
            "Loss in iteration no. 52003 ==> 0.34663879271317416\n",
            "Loss in iteration no. 52004 ==> 0.3466378324687209\n",
            "Loss in iteration no. 52005 ==> 0.34663687225820117\n",
            "Loss in iteration no. 52006 ==> 0.3466359120816133\n",
            "Loss in iteration no. 52007 ==> 0.34663495193895566\n",
            "Loss in iteration no. 52008 ==> 0.3466339918302266\n",
            "Loss in iteration no. 52009 ==> 0.34663303175542437\n",
            "Loss in iteration no. 52010 ==> 0.34663207171454735\n",
            "Loss in iteration no. 52011 ==> 0.346631111707594\n",
            "Loss in iteration no. 52012 ==> 0.3466301517345624\n",
            "Loss in iteration no. 52013 ==> 0.3466291917954511\n",
            "Loss in iteration no. 52014 ==> 0.3466282318902583\n",
            "Loss in iteration no. 52015 ==> 0.34662727201898247\n",
            "Loss in iteration no. 52016 ==> 0.3466263121816218\n",
            "Loss in iteration no. 52017 ==> 0.3466253523781749\n",
            "Loss in iteration no. 52018 ==> 0.3466243926086398\n",
            "Loss in iteration no. 52019 ==> 0.34662343287301495\n",
            "Loss in iteration no. 52020 ==> 0.34662247317129874\n",
            "Loss in iteration no. 52021 ==> 0.3466215135034895\n",
            "Loss in iteration no. 52022 ==> 0.3466205538695855\n",
            "Loss in iteration no. 52023 ==> 0.3466195942695851\n",
            "Loss in iteration no. 52024 ==> 0.34661863470348664\n",
            "Loss in iteration no. 52025 ==> 0.34661767517128855\n",
            "Loss in iteration no. 52026 ==> 0.3466167156729891\n",
            "Loss in iteration no. 52027 ==> 0.34661575620858653\n",
            "Loss in iteration no. 52028 ==> 0.34661479677807927\n",
            "Loss in iteration no. 52029 ==> 0.34661383738146584\n",
            "Loss in iteration no. 52030 ==> 0.34661287801874424\n",
            "Loss in iteration no. 52031 ==> 0.34661191868991303\n",
            "Loss in iteration no. 52032 ==> 0.34661095939497055\n",
            "Loss in iteration no. 52033 ==> 0.346610000133915\n",
            "Loss in iteration no. 52034 ==> 0.3466090409067449\n",
            "Loss in iteration no. 52035 ==> 0.34660808171345847\n",
            "Loss in iteration no. 52036 ==> 0.346607122554054\n",
            "Loss in iteration no. 52037 ==> 0.34660616342853\n",
            "Loss in iteration no. 52038 ==> 0.34660520433688463\n",
            "Loss in iteration no. 52039 ==> 0.34660424527911643\n",
            "Loss in iteration no. 52040 ==> 0.34660328625522363\n",
            "Loss in iteration no. 52041 ==> 0.34660232726520446\n",
            "Loss in iteration no. 52042 ==> 0.34660136830905747\n",
            "Loss in iteration no. 52043 ==> 0.34660040938678083\n",
            "Loss in iteration no. 52044 ==> 0.346599450498373\n",
            "Loss in iteration no. 52045 ==> 0.34659849164383233\n",
            "Loss in iteration no. 52046 ==> 0.34659753282315703\n",
            "Loss in iteration no. 52047 ==> 0.34659657403634553\n",
            "Loss in iteration no. 52048 ==> 0.3465956152833962\n",
            "Loss in iteration no. 52049 ==> 0.3465946565643073\n",
            "Loss in iteration no. 52050 ==> 0.3465936978790773\n",
            "Loss in iteration no. 52051 ==> 0.3465927392277044\n",
            "Loss in iteration no. 52052 ==> 0.34659178061018703\n",
            "Loss in iteration no. 52053 ==> 0.3465908220265235\n",
            "Loss in iteration no. 52054 ==> 0.3465898634767121\n",
            "Loss in iteration no. 52055 ==> 0.34658890496075134\n",
            "Loss in iteration no. 52056 ==> 0.34658794647863944\n",
            "Loss in iteration no. 52057 ==> 0.3465869880303747\n",
            "Loss in iteration no. 52058 ==> 0.3465860296159554\n",
            "Loss in iteration no. 52059 ==> 0.3465850712353802\n",
            "Loss in iteration no. 52060 ==> 0.34658411288864716\n",
            "Loss in iteration no. 52061 ==> 0.3465831545757547\n",
            "Loss in iteration no. 52062 ==> 0.34658219629670123\n",
            "Loss in iteration no. 52063 ==> 0.34658123805148505\n",
            "Loss in iteration no. 52064 ==> 0.3465802798401044\n",
            "Loss in iteration no. 52065 ==> 0.3465793216625578\n",
            "Loss in iteration no. 52066 ==> 0.34657836351884336\n",
            "Loss in iteration no. 52067 ==> 0.3465774054089597\n",
            "Loss in iteration no. 52068 ==> 0.34657644733290494\n",
            "Loss in iteration no. 52069 ==> 0.34657548929067766\n",
            "Loss in iteration no. 52070 ==> 0.34657453128227594\n",
            "Loss in iteration no. 52071 ==> 0.3465735733076983\n",
            "Loss in iteration no. 52072 ==> 0.346572615366943\n",
            "Loss in iteration no. 52073 ==> 0.34657165746000845\n",
            "Loss in iteration no. 52074 ==> 0.34657069958689296\n",
            "Loss in iteration no. 52075 ==> 0.3465697417475948\n",
            "Loss in iteration no. 52076 ==> 0.34656878394211255\n",
            "Loss in iteration no. 52077 ==> 0.3465678261704443\n",
            "Loss in iteration no. 52078 ==> 0.34656686843258844\n",
            "Loss in iteration no. 52079 ==> 0.34656591072854337\n",
            "Loss in iteration no. 52080 ==> 0.34656495305830753\n",
            "Loss in iteration no. 52081 ==> 0.34656399542187905\n",
            "Loss in iteration no. 52082 ==> 0.34656303781925646\n",
            "Loss in iteration no. 52083 ==> 0.346562080250438\n",
            "Loss in iteration no. 52084 ==> 0.34656112271542205\n",
            "Loss in iteration no. 52085 ==> 0.34656016521420696\n",
            "Loss in iteration no. 52086 ==> 0.3465592077467911\n",
            "Loss in iteration no. 52087 ==> 0.3465582503131728\n",
            "Loss in iteration no. 52088 ==> 0.3465572929133504\n",
            "Loss in iteration no. 52089 ==> 0.34655633554732224\n",
            "Loss in iteration no. 52090 ==> 0.34655537821508664\n",
            "Loss in iteration no. 52091 ==> 0.3465544209166419\n",
            "Loss in iteration no. 52092 ==> 0.3465534636519866\n",
            "Loss in iteration no. 52093 ==> 0.34655250642111884\n",
            "Loss in iteration no. 52094 ==> 0.346551549224037\n",
            "Loss in iteration no. 52095 ==> 0.3465505920607396\n",
            "Loss in iteration no. 52096 ==> 0.34654963493122487\n",
            "Loss in iteration no. 52097 ==> 0.34654867783549104\n",
            "Loss in iteration no. 52098 ==> 0.3465477207735366\n",
            "Loss in iteration no. 52099 ==> 0.34654676374536\n",
            "Loss in iteration no. 52100 ==> 0.34654580675095936\n",
            "Loss in iteration no. 52101 ==> 0.34654484979033306\n",
            "Loss in iteration no. 52102 ==> 0.34654389286347964\n",
            "Loss in iteration no. 52103 ==> 0.34654293597039726\n",
            "Loss in iteration no. 52104 ==> 0.3465419791110843\n",
            "Loss in iteration no. 52105 ==> 0.3465410222855392\n",
            "Loss in iteration no. 52106 ==> 0.3465400654937602\n",
            "Loss in iteration no. 52107 ==> 0.3465391087357456\n",
            "Loss in iteration no. 52108 ==> 0.34653815201149396\n",
            "Loss in iteration no. 52109 ==> 0.34653719532100347\n",
            "Loss in iteration no. 52110 ==> 0.3465362386642725\n",
            "Loss in iteration no. 52111 ==> 0.3465352820412995\n",
            "Loss in iteration no. 52112 ==> 0.3465343254520826\n",
            "Loss in iteration no. 52113 ==> 0.3465333688966204\n",
            "Loss in iteration no. 52114 ==> 0.3465324123749111\n",
            "Loss in iteration no. 52115 ==> 0.3465314558869531\n",
            "Loss in iteration no. 52116 ==> 0.3465304994327447\n",
            "Loss in iteration no. 52117 ==> 0.3465295430122843\n",
            "Loss in iteration no. 52118 ==> 0.34652858662557023\n",
            "Loss in iteration no. 52119 ==> 0.34652763027260075\n",
            "Loss in iteration no. 52120 ==> 0.3465266739533744\n",
            "Loss in iteration no. 52121 ==> 0.34652571766788937\n",
            "Loss in iteration no. 52122 ==> 0.34652476141614413\n",
            "Loss in iteration no. 52123 ==> 0.34652380519813686\n",
            "Loss in iteration no. 52124 ==> 0.34652284901386604\n",
            "Loss in iteration no. 52125 ==> 0.34652189286333007\n",
            "Loss in iteration no. 52126 ==> 0.3465209367465272\n",
            "Loss in iteration no. 52127 ==> 0.3465199806634558\n",
            "Loss in iteration no. 52128 ==> 0.34651902461411416\n",
            "Loss in iteration no. 52129 ==> 0.34651806859850076\n",
            "Loss in iteration no. 52130 ==> 0.3465171126166139\n",
            "Loss in iteration no. 52131 ==> 0.34651615666845187\n",
            "Loss in iteration no. 52132 ==> 0.3465152007540131\n",
            "Loss in iteration no. 52133 ==> 0.3465142448732959\n",
            "Loss in iteration no. 52134 ==> 0.3465132890262986\n",
            "Loss in iteration no. 52135 ==> 0.3465123332130196\n",
            "Loss in iteration no. 52136 ==> 0.3465113774334572\n",
            "Loss in iteration no. 52137 ==> 0.34651042168760987\n",
            "Loss in iteration no. 52138 ==> 0.3465094659754759\n",
            "Loss in iteration no. 52139 ==> 0.3465085102970535\n",
            "Loss in iteration no. 52140 ==> 0.34650755465234107\n",
            "Loss in iteration no. 52141 ==> 0.34650659904133724\n",
            "Loss in iteration no. 52142 ==> 0.34650564346404\n",
            "Loss in iteration no. 52143 ==> 0.3465046879204479\n",
            "Loss in iteration no. 52144 ==> 0.34650373241055926\n",
            "Loss in iteration no. 52145 ==> 0.3465027769343724\n",
            "Loss in iteration no. 52146 ==> 0.34650182149188574\n",
            "Loss in iteration no. 52147 ==> 0.3465008660830975\n",
            "Loss in iteration no. 52148 ==> 0.3464999107080062\n",
            "Loss in iteration no. 52149 ==> 0.34649895536660996\n",
            "Loss in iteration no. 52150 ==> 0.3464980000589074\n",
            "Loss in iteration no. 52151 ==> 0.3464970447848968\n",
            "Loss in iteration no. 52152 ==> 0.34649608954457634\n",
            "Loss in iteration no. 52153 ==> 0.3464951343379445\n",
            "Loss in iteration no. 52154 ==> 0.34649417916499975\n",
            "Loss in iteration no. 52155 ==> 0.34649322402574023\n",
            "Loss in iteration no. 52156 ==> 0.34649226892016444\n",
            "Loss in iteration no. 52157 ==> 0.34649131384827064\n",
            "Loss in iteration no. 52158 ==> 0.3464903588100572\n",
            "Loss in iteration no. 52159 ==> 0.34648940380552257\n",
            "Loss in iteration no. 52160 ==> 0.34648844883466495\n",
            "Loss in iteration no. 52161 ==> 0.3464874938974828\n",
            "Loss in iteration no. 52162 ==> 0.34648653899397436\n",
            "Loss in iteration no. 52163 ==> 0.34648558412413827\n",
            "Loss in iteration no. 52164 ==> 0.3464846292879726\n",
            "Loss in iteration no. 52165 ==> 0.34648367448547573\n",
            "Loss in iteration no. 52166 ==> 0.3464827197166462\n",
            "Loss in iteration no. 52167 ==> 0.3464817649814821\n",
            "Loss in iteration no. 52168 ==> 0.346480810279982\n",
            "Loss in iteration no. 52169 ==> 0.3464798556121441\n",
            "Loss in iteration no. 52170 ==> 0.34647890097796696\n",
            "Loss in iteration no. 52171 ==> 0.3464779463774488\n",
            "Loss in iteration no. 52172 ==> 0.3464769918105879\n",
            "Loss in iteration no. 52173 ==> 0.3464760372773827\n",
            "Loss in iteration no. 52174 ==> 0.3464750827778315\n",
            "Loss in iteration no. 52175 ==> 0.34647412831193286\n",
            "Loss in iteration no. 52176 ==> 0.3464731738796849\n",
            "Loss in iteration no. 52177 ==> 0.3464722194810861\n",
            "Loss in iteration no. 52178 ==> 0.3464712651161347\n",
            "Loss in iteration no. 52179 ==> 0.34647031078482915\n",
            "Loss in iteration no. 52180 ==> 0.3464693564871678\n",
            "Loss in iteration no. 52181 ==> 0.34646840222314895\n",
            "Loss in iteration no. 52182 ==> 0.3464674479927711\n",
            "Loss in iteration no. 52183 ==> 0.3464664937960324\n",
            "Loss in iteration no. 52184 ==> 0.3464655396329314\n",
            "Loss in iteration no. 52185 ==> 0.3464645855034663\n",
            "Loss in iteration no. 52186 ==> 0.3464636314076356\n",
            "Loss in iteration no. 52187 ==> 0.3464626773454375\n",
            "Loss in iteration no. 52188 ==> 0.3464617233168704\n",
            "Loss in iteration no. 52189 ==> 0.34646076932193276\n",
            "Loss in iteration no. 52190 ==> 0.3464598153606229\n",
            "Loss in iteration no. 52191 ==> 0.3464588614329391\n",
            "Loss in iteration no. 52192 ==> 0.3464579075388798\n",
            "Loss in iteration no. 52193 ==> 0.3464569536784433\n",
            "Loss in iteration no. 52194 ==> 0.3464559998516279\n",
            "Loss in iteration no. 52195 ==> 0.3464550460584321\n",
            "Loss in iteration no. 52196 ==> 0.34645409229885415\n",
            "Loss in iteration no. 52197 ==> 0.34645313857289256\n",
            "Loss in iteration no. 52198 ==> 0.34645218488054547\n",
            "Loss in iteration no. 52199 ==> 0.3464512312218114\n",
            "Loss in iteration no. 52200 ==> 0.3464502775966886\n",
            "Loss in iteration no. 52201 ==> 0.34644932400517553\n",
            "Loss in iteration no. 52202 ==> 0.3464483704472705\n",
            "Loss in iteration no. 52203 ==> 0.34644741692297176\n",
            "Loss in iteration no. 52204 ==> 0.3464464634322779\n",
            "Loss in iteration no. 52205 ==> 0.34644550997518714\n",
            "Loss in iteration no. 52206 ==> 0.34644455655169776\n",
            "Loss in iteration no. 52207 ==> 0.3464436031618084\n",
            "Loss in iteration no. 52208 ==> 0.34644264980551703\n",
            "Loss in iteration no. 52209 ==> 0.34644169648282225\n",
            "Loss in iteration no. 52210 ==> 0.3464407431937224\n",
            "Loss in iteration no. 52211 ==> 0.34643978993821584\n",
            "Loss in iteration no. 52212 ==> 0.3464388367163009\n",
            "Loss in iteration no. 52213 ==> 0.3464378835279759\n",
            "Loss in iteration no. 52214 ==> 0.3464369303732393\n",
            "Loss in iteration no. 52215 ==> 0.34643597725208924\n",
            "Loss in iteration no. 52216 ==> 0.3464350241645245\n",
            "Loss in iteration no. 52217 ==> 0.3464340711105431\n",
            "Loss in iteration no. 52218 ==> 0.3464331180901434\n",
            "Loss in iteration no. 52219 ==> 0.3464321651033238\n",
            "Loss in iteration no. 52220 ==> 0.3464312121500829\n",
            "Loss in iteration no. 52221 ==> 0.3464302592304187\n",
            "Loss in iteration no. 52222 ==> 0.3464293063443297\n",
            "Loss in iteration no. 52223 ==> 0.34642835349181433\n",
            "Loss in iteration no. 52224 ==> 0.346427400672871\n",
            "Loss in iteration no. 52225 ==> 0.3464264478874978\n",
            "Loss in iteration no. 52226 ==> 0.34642549513569343\n",
            "Loss in iteration no. 52227 ==> 0.34642454241745596\n",
            "Loss in iteration no. 52228 ==> 0.346423589732784\n",
            "Loss in iteration no. 52229 ==> 0.3464226370816756\n",
            "Loss in iteration no. 52230 ==> 0.34642168446412946\n",
            "Loss in iteration no. 52231 ==> 0.3464207318801438\n",
            "Loss in iteration no. 52232 ==> 0.3464197793297168\n",
            "Loss in iteration no. 52233 ==> 0.3464188268128471\n",
            "Loss in iteration no. 52234 ==> 0.34641787432953297\n",
            "Loss in iteration no. 52235 ==> 0.3464169218797727\n",
            "Loss in iteration no. 52236 ==> 0.3464159694635647\n",
            "Loss in iteration no. 52237 ==> 0.3464150170809074\n",
            "Loss in iteration no. 52238 ==> 0.3464140647317991\n",
            "Loss in iteration no. 52239 ==> 0.34641311241623807\n",
            "Loss in iteration no. 52240 ==> 0.34641216013422277\n",
            "Loss in iteration no. 52241 ==> 0.34641120788575164\n",
            "Loss in iteration no. 52242 ==> 0.34641025567082284\n",
            "Loss in iteration no. 52243 ==> 0.34640930348943494\n",
            "Loss in iteration no. 52244 ==> 0.3464083513415862\n",
            "Loss in iteration no. 52245 ==> 0.346407399227275\n",
            "Loss in iteration no. 52246 ==> 0.34640644714649976\n",
            "Loss in iteration no. 52247 ==> 0.3464054950992585\n",
            "Loss in iteration no. 52248 ==> 0.34640454308555013\n",
            "Loss in iteration no. 52249 ==> 0.34640359110537267\n",
            "Loss in iteration no. 52250 ==> 0.34640263915872455\n",
            "Loss in iteration no. 52251 ==> 0.3464016872456041\n",
            "Loss in iteration no. 52252 ==> 0.34640073536600985\n",
            "Loss in iteration no. 52253 ==> 0.34639978351993994\n",
            "Loss in iteration no. 52254 ==> 0.3463988317073928\n",
            "Loss in iteration no. 52255 ==> 0.3463978799283668\n",
            "Loss in iteration no. 52256 ==> 0.34639692818286044\n",
            "Loss in iteration no. 52257 ==> 0.34639597647087195\n",
            "Loss in iteration no. 52258 ==> 0.34639502479239964\n",
            "Loss in iteration no. 52259 ==> 0.3463940731474421\n",
            "Loss in iteration no. 52260 ==> 0.3463931215359974\n",
            "Loss in iteration no. 52261 ==> 0.34639216995806404\n",
            "Loss in iteration no. 52262 ==> 0.34639121841364046\n",
            "Loss in iteration no. 52263 ==> 0.34639026690272495\n",
            "Loss in iteration no. 52264 ==> 0.3463893154253158\n",
            "Loss in iteration no. 52265 ==> 0.34638836398141143\n",
            "Loss in iteration no. 52266 ==> 0.3463874125710104\n",
            "Loss in iteration no. 52267 ==> 0.3463864611941108\n",
            "Loss in iteration no. 52268 ==> 0.34638550985071115\n",
            "Loss in iteration no. 52269 ==> 0.3463845585408098\n",
            "Loss in iteration no. 52270 ==> 0.34638360726440487\n",
            "Loss in iteration no. 52271 ==> 0.3463826560214951\n",
            "Loss in iteration no. 52272 ==> 0.34638170481207864\n",
            "Loss in iteration no. 52273 ==> 0.346380753636154\n",
            "Loss in iteration no. 52274 ==> 0.34637980249371936\n",
            "Loss in iteration no. 52275 ==> 0.3463788513847732\n",
            "Loss in iteration no. 52276 ==> 0.3463779003093138\n",
            "Loss in iteration no. 52277 ==> 0.3463769492673397\n",
            "Loss in iteration no. 52278 ==> 0.3463759982588492\n",
            "Loss in iteration no. 52279 ==> 0.3463750472838404\n",
            "Loss in iteration no. 52280 ==> 0.3463740963423121\n",
            "Loss in iteration no. 52281 ==> 0.34637314543426234\n",
            "Loss in iteration no. 52282 ==> 0.3463721945596896\n",
            "Loss in iteration no. 52283 ==> 0.3463712437185922\n",
            "Loss in iteration no. 52284 ==> 0.34637029291096866\n",
            "Loss in iteration no. 52285 ==> 0.34636934213681725\n",
            "Loss in iteration no. 52286 ==> 0.3463683913961363\n",
            "Loss in iteration no. 52287 ==> 0.34636744068892406\n",
            "Loss in iteration no. 52288 ==> 0.34636649001517916\n",
            "Loss in iteration no. 52289 ==> 0.3463655393748998\n",
            "Loss in iteration no. 52290 ==> 0.3463645887680845\n",
            "Loss in iteration no. 52291 ==> 0.3463636381947314\n",
            "Loss in iteration no. 52292 ==> 0.346362687654839\n",
            "Loss in iteration no. 52293 ==> 0.34636173714840574\n",
            "Loss in iteration no. 52294 ==> 0.3463607866754299\n",
            "Loss in iteration no. 52295 ==> 0.3463598362359098\n",
            "Loss in iteration no. 52296 ==> 0.3463588858298438\n",
            "Loss in iteration no. 52297 ==> 0.3463579354572305\n",
            "Loss in iteration no. 52298 ==> 0.34635698511806784\n",
            "Loss in iteration no. 52299 ==> 0.3463560348123547\n",
            "Loss in iteration no. 52300 ==> 0.346355084540089\n",
            "Loss in iteration no. 52301 ==> 0.34635413430126943\n",
            "Loss in iteration no. 52302 ==> 0.3463531840958942\n",
            "Loss in iteration no. 52303 ==> 0.3463522339239617\n",
            "Loss in iteration no. 52304 ==> 0.3463512837854702\n",
            "Loss in iteration no. 52305 ==> 0.34635033368041834\n",
            "Loss in iteration no. 52306 ==> 0.3463493836088042\n",
            "Loss in iteration no. 52307 ==> 0.34634843357062634\n",
            "Loss in iteration no. 52308 ==> 0.346347483565883\n",
            "Loss in iteration no. 52309 ==> 0.34634653359457274\n",
            "Loss in iteration no. 52310 ==> 0.3463455836566937\n",
            "Loss in iteration no. 52311 ==> 0.34634463375224434\n",
            "Loss in iteration no. 52312 ==> 0.346343683881223\n",
            "Loss in iteration no. 52313 ==> 0.3463427340436281\n",
            "Loss in iteration no. 52314 ==> 0.3463417842394581\n",
            "Loss in iteration no. 52315 ==> 0.3463408344687112\n",
            "Loss in iteration no. 52316 ==> 0.3463398847313859\n",
            "Loss in iteration no. 52317 ==> 0.34633893502748037\n",
            "Loss in iteration no. 52318 ==> 0.3463379853569932\n",
            "Loss in iteration no. 52319 ==> 0.34633703571992264\n",
            "Loss in iteration no. 52320 ==> 0.34633608611626715\n",
            "Loss in iteration no. 52321 ==> 0.346335136546025\n",
            "Loss in iteration no. 52322 ==> 0.34633418700919466\n",
            "Loss in iteration no. 52323 ==> 0.3463332375057744\n",
            "Loss in iteration no. 52324 ==> 0.3463322880357627\n",
            "Loss in iteration no. 52325 ==> 0.3463313385991577\n",
            "Loss in iteration no. 52326 ==> 0.3463303891959581\n",
            "Loss in iteration no. 52327 ==> 0.3463294398261621\n",
            "Loss in iteration no. 52328 ==> 0.3463284904897681\n",
            "Loss in iteration no. 52329 ==> 0.3463275411867744\n",
            "Loss in iteration no. 52330 ==> 0.34632659191717946\n",
            "Loss in iteration no. 52331 ==> 0.34632564268098165\n",
            "Loss in iteration no. 52332 ==> 0.3463246934781792\n",
            "Loss in iteration no. 52333 ==> 0.3463237443087707\n",
            "Loss in iteration no. 52334 ==> 0.3463227951727543\n",
            "Loss in iteration no. 52335 ==> 0.34632184607012856\n",
            "Loss in iteration no. 52336 ==> 0.3463208970008918\n",
            "Loss in iteration no. 52337 ==> 0.34631994796504234\n",
            "Loss in iteration no. 52338 ==> 0.3463189989625785\n",
            "Loss in iteration no. 52339 ==> 0.34631804999349886\n",
            "Loss in iteration no. 52340 ==> 0.34631710105780156\n",
            "Loss in iteration no. 52341 ==> 0.34631615215548517\n",
            "Loss in iteration no. 52342 ==> 0.34631520328654797\n",
            "Loss in iteration no. 52343 ==> 0.34631425445098823\n",
            "Loss in iteration no. 52344 ==> 0.34631330564880447\n",
            "Loss in iteration no. 52345 ==> 0.34631235687999506\n",
            "Loss in iteration no. 52346 ==> 0.34631140814455835\n",
            "Loss in iteration no. 52347 ==> 0.34631045944249267\n",
            "Loss in iteration no. 52348 ==> 0.34630951077379635\n",
            "Loss in iteration no. 52349 ==> 0.3463085621384679\n",
            "Loss in iteration no. 52350 ==> 0.3463076135365056\n",
            "Loss in iteration no. 52351 ==> 0.3463066649679079\n",
            "Loss in iteration no. 52352 ==> 0.3463057164326729\n",
            "Loss in iteration no. 52353 ==> 0.3463047679307994\n",
            "Loss in iteration no. 52354 ==> 0.34630381946228556\n",
            "Loss in iteration no. 52355 ==> 0.34630287102712975\n",
            "Loss in iteration no. 52356 ==> 0.3463019226253303\n",
            "Loss in iteration no. 52357 ==> 0.3463009742568857\n",
            "Loss in iteration no. 52358 ==> 0.3463000259217942\n",
            "Loss in iteration no. 52359 ==> 0.3462990776200543\n",
            "Loss in iteration no. 52360 ==> 0.3462981293516644\n",
            "Loss in iteration no. 52361 ==> 0.34629718111662267\n",
            "Loss in iteration no. 52362 ==> 0.3462962329149276\n",
            "Loss in iteration no. 52363 ==> 0.3462952847465776\n",
            "Loss in iteration no. 52364 ==> 0.346294336611571\n",
            "Loss in iteration no. 52365 ==> 0.3462933885099061\n",
            "Loss in iteration no. 52366 ==> 0.34629244044158153\n",
            "Loss in iteration no. 52367 ==> 0.34629149240659535\n",
            "Loss in iteration no. 52368 ==> 0.34629054440494617\n",
            "Loss in iteration no. 52369 ==> 0.34628959643663226\n",
            "Loss in iteration no. 52370 ==> 0.34628864850165203\n",
            "Loss in iteration no. 52371 ==> 0.3462877006000038\n",
            "Loss in iteration no. 52372 ==> 0.3462867527316861\n",
            "Loss in iteration no. 52373 ==> 0.34628580489669697\n",
            "Loss in iteration no. 52374 ==> 0.34628485709503515\n",
            "Loss in iteration no. 52375 ==> 0.34628390932669884\n",
            "Loss in iteration no. 52376 ==> 0.3462829615916865\n",
            "Loss in iteration no. 52377 ==> 0.34628201388999647\n",
            "Loss in iteration no. 52378 ==> 0.34628106622162697\n",
            "Loss in iteration no. 52379 ==> 0.34628011858657665\n",
            "Loss in iteration no. 52380 ==> 0.3462791709848436\n",
            "Loss in iteration no. 52381 ==> 0.34627822341642656\n",
            "Loss in iteration no. 52382 ==> 0.34627727588132357\n",
            "Loss in iteration no. 52383 ==> 0.34627632837953315\n",
            "Loss in iteration no. 52384 ==> 0.34627538091105364\n",
            "Loss in iteration no. 52385 ==> 0.3462744334758835\n",
            "Loss in iteration no. 52386 ==> 0.34627348607402103\n",
            "Loss in iteration no. 52387 ==> 0.34627253870546454\n",
            "Loss in iteration no. 52388 ==> 0.34627159137021263\n",
            "Loss in iteration no. 52389 ==> 0.3462706440682634\n",
            "Loss in iteration no. 52390 ==> 0.34626969679961545\n",
            "Loss in iteration no. 52391 ==> 0.34626874956426706\n",
            "Loss in iteration no. 52392 ==> 0.34626780236221666\n",
            "Loss in iteration no. 52393 ==> 0.3462668551934625\n",
            "Loss in iteration no. 52394 ==> 0.346265908058003\n",
            "Loss in iteration no. 52395 ==> 0.3462649609558367\n",
            "Loss in iteration no. 52396 ==> 0.3462640138869618\n",
            "Loss in iteration no. 52397 ==> 0.34626306685137687\n",
            "Loss in iteration no. 52398 ==> 0.34626211984908\n",
            "Loss in iteration no. 52399 ==> 0.3462611728800698\n",
            "Loss in iteration no. 52400 ==> 0.3462602259443445\n",
            "Loss in iteration no. 52401 ==> 0.3462592790419026\n",
            "Loss in iteration no. 52402 ==> 0.34625833217274243\n",
            "Loss in iteration no. 52403 ==> 0.34625738533686246\n",
            "Loss in iteration no. 52404 ==> 0.34625643853426086\n",
            "Loss in iteration no. 52405 ==> 0.34625549176493614\n",
            "Loss in iteration no. 52406 ==> 0.34625454502888675\n",
            "Loss in iteration no. 52407 ==> 0.34625359832611086\n",
            "Loss in iteration no. 52408 ==> 0.34625265165660707\n",
            "Loss in iteration no. 52409 ==> 0.34625170502037367\n",
            "Loss in iteration no. 52410 ==> 0.34625075841740904\n",
            "Loss in iteration no. 52411 ==> 0.34624981184771153\n",
            "Loss in iteration no. 52412 ==> 0.3462488653112795\n",
            "Loss in iteration no. 52413 ==> 0.3462479188081114\n",
            "Loss in iteration no. 52414 ==> 0.34624697233820567\n",
            "Loss in iteration no. 52415 ==> 0.34624602590156045\n",
            "Loss in iteration no. 52416 ==> 0.3462450794981744\n",
            "Loss in iteration no. 52417 ==> 0.34624413312804575\n",
            "Loss in iteration no. 52418 ==> 0.3462431867911729\n",
            "Loss in iteration no. 52419 ==> 0.34624224048755425\n",
            "Loss in iteration no. 52420 ==> 0.34624129421718813\n",
            "Loss in iteration no. 52421 ==> 0.346240347980073\n",
            "Loss in iteration no. 52422 ==> 0.34623940177620716\n",
            "Loss in iteration no. 52423 ==> 0.346238455605589\n",
            "Loss in iteration no. 52424 ==> 0.346237509468217\n",
            "Loss in iteration no. 52425 ==> 0.3462365633640895\n",
            "Loss in iteration no. 52426 ==> 0.3462356172932048\n",
            "Loss in iteration no. 52427 ==> 0.3462346712555613\n",
            "Loss in iteration no. 52428 ==> 0.3462337252511574\n",
            "Loss in iteration no. 52429 ==> 0.34623277927999163\n",
            "Loss in iteration no. 52430 ==> 0.3462318333420622\n",
            "Loss in iteration no. 52431 ==> 0.34623088743736746\n",
            "Loss in iteration no. 52432 ==> 0.34622994156590586\n",
            "Loss in iteration no. 52433 ==> 0.34622899572767585\n",
            "Loss in iteration no. 52434 ==> 0.3462280499226757\n",
            "Loss in iteration no. 52435 ==> 0.34622710415090385\n",
            "Loss in iteration no. 52436 ==> 0.3462261584123587\n",
            "Loss in iteration no. 52437 ==> 0.34622521270703854\n",
            "Loss in iteration no. 52438 ==> 0.3462242670349418\n",
            "Loss in iteration no. 52439 ==> 0.346223321396067\n",
            "Loss in iteration no. 52440 ==> 0.3462223757904123\n",
            "Loss in iteration no. 52441 ==> 0.34622143021797613\n",
            "Loss in iteration no. 52442 ==> 0.3462204846787571\n",
            "Loss in iteration no. 52443 ==> 0.34621953917275333\n",
            "Loss in iteration no. 52444 ==> 0.3462185936999633\n",
            "Loss in iteration no. 52445 ==> 0.3462176482603853\n",
            "Loss in iteration no. 52446 ==> 0.34621670285401795\n",
            "Loss in iteration no. 52447 ==> 0.3462157574808594\n",
            "Loss in iteration no. 52448 ==> 0.3462148121409081\n",
            "Loss in iteration no. 52449 ==> 0.3462138668341625\n",
            "Loss in iteration no. 52450 ==> 0.34621292156062083\n",
            "Loss in iteration no. 52451 ==> 0.3462119763202817\n",
            "Loss in iteration no. 52452 ==> 0.3462110311131434\n",
            "Loss in iteration no. 52453 ==> 0.3462100859392041\n",
            "Loss in iteration no. 52454 ==> 0.34620914079846254\n",
            "Loss in iteration no. 52455 ==> 0.3462081956909168\n",
            "Loss in iteration no. 52456 ==> 0.3462072506165655\n",
            "Loss in iteration no. 52457 ==> 0.3462063055754068\n",
            "Loss in iteration no. 52458 ==> 0.3462053605674394\n",
            "Loss in iteration no. 52459 ==> 0.34620441559266135\n",
            "Loss in iteration no. 52460 ==> 0.34620347065107115\n",
            "Loss in iteration no. 52461 ==> 0.3462025257426673\n",
            "Loss in iteration no. 52462 ==> 0.34620158086744807\n",
            "Loss in iteration no. 52463 ==> 0.34620063602541185\n",
            "Loss in iteration no. 52464 ==> 0.3461996912165571\n",
            "Loss in iteration no. 52465 ==> 0.34619874644088205\n",
            "Loss in iteration no. 52466 ==> 0.34619780169838527\n",
            "Loss in iteration no. 52467 ==> 0.346196856989065\n",
            "Loss in iteration no. 52468 ==> 0.3461959123129197\n",
            "Loss in iteration no. 52469 ==> 0.3461949676699478\n",
            "Loss in iteration no. 52470 ==> 0.34619402306014757\n",
            "Loss in iteration no. 52471 ==> 0.3461930784835175\n",
            "Loss in iteration no. 52472 ==> 0.3461921339400559\n",
            "Loss in iteration no. 52473 ==> 0.3461911894297611\n",
            "Loss in iteration no. 52474 ==> 0.3461902449526317\n",
            "Loss in iteration no. 52475 ==> 0.34618930050866586\n",
            "Loss in iteration no. 52476 ==> 0.34618835609786214\n",
            "Loss in iteration no. 52477 ==> 0.3461874117202188\n",
            "Loss in iteration no. 52478 ==> 0.34618646737573433\n",
            "Loss in iteration no. 52479 ==> 0.34618552306440703\n",
            "Loss in iteration no. 52480 ==> 0.3461845787862353\n",
            "Loss in iteration no. 52481 ==> 0.3461836345412176\n",
            "Loss in iteration no. 52482 ==> 0.3461826903293522\n",
            "Loss in iteration no. 52483 ==> 0.3461817461506376\n",
            "Loss in iteration no. 52484 ==> 0.3461808020050722\n",
            "Loss in iteration no. 52485 ==> 0.3461798578926542\n",
            "Loss in iteration no. 52486 ==> 0.34617891381338217\n",
            "Loss in iteration no. 52487 ==> 0.34617796976725446\n",
            "Loss in iteration no. 52488 ==> 0.3461770257542694\n",
            "Loss in iteration no. 52489 ==> 0.34617608177442544\n",
            "Loss in iteration no. 52490 ==> 0.34617513782772086\n",
            "Loss in iteration no. 52491 ==> 0.3461741939141543\n",
            "Loss in iteration no. 52492 ==> 0.3461732500337238\n",
            "Loss in iteration no. 52493 ==> 0.3461723061864281\n",
            "Loss in iteration no. 52494 ==> 0.3461713623722653\n",
            "Loss in iteration no. 52495 ==> 0.3461704185912338\n",
            "Loss in iteration no. 52496 ==> 0.34616947484333227\n",
            "Loss in iteration no. 52497 ==> 0.34616853112855894\n",
            "Loss in iteration no. 52498 ==> 0.34616758744691206\n",
            "Loss in iteration no. 52499 ==> 0.3461666437983902\n",
            "Loss in iteration no. 52500 ==> 0.3461657001829917\n",
            "Loss in iteration no. 52501 ==> 0.3461647566007149\n",
            "Loss in iteration no. 52502 ==> 0.3461638130515582\n",
            "Loss in iteration no. 52503 ==> 0.34616286953552006\n",
            "Loss in iteration no. 52504 ==> 0.3461619260525988\n",
            "Loss in iteration no. 52505 ==> 0.3461609826027928\n",
            "Loss in iteration no. 52506 ==> 0.3461600391861005\n",
            "Loss in iteration no. 52507 ==> 0.3461590958025203\n",
            "Loss in iteration no. 52508 ==> 0.3461581524520506\n",
            "Loss in iteration no. 52509 ==> 0.3461572091346897\n",
            "Loss in iteration no. 52510 ==> 0.346156265850436\n",
            "Loss in iteration no. 52511 ==> 0.34615532259928794\n",
            "Loss in iteration no. 52512 ==> 0.346154379381244\n",
            "Loss in iteration no. 52513 ==> 0.34615343619630234\n",
            "Loss in iteration no. 52514 ==> 0.3461524930444616\n",
            "Loss in iteration no. 52515 ==> 0.3461515499257199\n",
            "Loss in iteration no. 52516 ==> 0.3461506068400759\n",
            "Loss in iteration no. 52517 ==> 0.3461496637875279\n",
            "Loss in iteration no. 52518 ==> 0.3461487207680742\n",
            "Loss in iteration no. 52519 ==> 0.3461477777817132\n",
            "Loss in iteration no. 52520 ==> 0.34614683482844344\n",
            "Loss in iteration no. 52521 ==> 0.3461458919082631\n",
            "Loss in iteration no. 52522 ==> 0.34614494902117077\n",
            "Loss in iteration no. 52523 ==> 0.3461440061671648\n",
            "Loss in iteration no. 52524 ==> 0.34614306334624345\n",
            "Loss in iteration no. 52525 ==> 0.34614212055840526\n",
            "Loss in iteration no. 52526 ==> 0.34614117780364845\n",
            "Loss in iteration no. 52527 ==> 0.3461402350819716\n",
            "Loss in iteration no. 52528 ==> 0.346139292393373\n",
            "Loss in iteration no. 52529 ==> 0.3461383497378511\n",
            "Loss in iteration no. 52530 ==> 0.34613740711540425\n",
            "Loss in iteration no. 52531 ==> 0.3461364645260309\n",
            "Loss in iteration no. 52532 ==> 0.3461355219697293\n",
            "Loss in iteration no. 52533 ==> 0.3461345794464979\n",
            "Loss in iteration no. 52534 ==> 0.3461336369563352\n",
            "Loss in iteration no. 52535 ==> 0.34613269449923956\n",
            "Loss in iteration no. 52536 ==> 0.34613175207520935\n",
            "Loss in iteration no. 52537 ==> 0.34613080968424276\n",
            "Loss in iteration no. 52538 ==> 0.34612986732633855\n",
            "Loss in iteration no. 52539 ==> 0.34612892500149467\n",
            "Loss in iteration no. 52540 ==> 0.34612798270971007\n",
            "Loss in iteration no. 52541 ==> 0.34612704045098275\n",
            "Loss in iteration no. 52542 ==> 0.34612609822531115\n",
            "Loss in iteration no. 52543 ==> 0.3461251560326937\n",
            "Loss in iteration no. 52544 ==> 0.34612421387312886\n",
            "Loss in iteration no. 52545 ==> 0.346123271746615\n",
            "Loss in iteration no. 52546 ==> 0.34612232965315043\n",
            "Loss in iteration no. 52547 ==> 0.3461213875927336\n",
            "Loss in iteration no. 52548 ==> 0.3461204455653628\n",
            "Loss in iteration no. 52549 ==> 0.3461195035710366\n",
            "Loss in iteration no. 52550 ==> 0.3461185616097533\n",
            "Loss in iteration no. 52551 ==> 0.3461176196815114\n",
            "Loss in iteration no. 52552 ==> 0.3461166777863091\n",
            "Loss in iteration no. 52553 ==> 0.34611573592414496\n",
            "Loss in iteration no. 52554 ==> 0.3461147940950173\n",
            "Loss in iteration no. 52555 ==> 0.3461138522989245\n",
            "Loss in iteration no. 52556 ==> 0.34611291053586496\n",
            "Loss in iteration no. 52557 ==> 0.34611196880583706\n",
            "Loss in iteration no. 52558 ==> 0.34611102710883934\n",
            "Loss in iteration no. 52559 ==> 0.34611008544487\n",
            "Loss in iteration no. 52560 ==> 0.34610914381392754\n",
            "Loss in iteration no. 52561 ==> 0.34610820221601035\n",
            "Loss in iteration no. 52562 ==> 0.3461072606511168\n",
            "Loss in iteration no. 52563 ==> 0.34610631911924533\n",
            "Loss in iteration no. 52564 ==> 0.34610537762039423\n",
            "Loss in iteration no. 52565 ==> 0.34610443615456205\n",
            "Loss in iteration no. 52566 ==> 0.34610349472174706\n",
            "Loss in iteration no. 52567 ==> 0.34610255332194767\n",
            "Loss in iteration no. 52568 ==> 0.34610161195516226\n",
            "Loss in iteration no. 52569 ==> 0.3461006706213894\n",
            "Loss in iteration no. 52570 ==> 0.3460997293206272\n",
            "Loss in iteration no. 52571 ==> 0.34609878805287436\n",
            "Loss in iteration no. 52572 ==> 0.34609784681812905\n",
            "Loss in iteration no. 52573 ==> 0.3460969056163897\n",
            "Loss in iteration no. 52574 ==> 0.34609596444765484\n",
            "Loss in iteration no. 52575 ==> 0.34609502331192266\n",
            "Loss in iteration no. 52576 ==> 0.34609408220919174\n",
            "Loss in iteration no. 52577 ==> 0.34609314113946044\n",
            "Loss in iteration no. 52578 ==> 0.3460922001027271\n",
            "Loss in iteration no. 52579 ==> 0.3460912590989901\n",
            "Loss in iteration no. 52580 ==> 0.3460903181282479\n",
            "Loss in iteration no. 52581 ==> 0.3460893771904989\n",
            "Loss in iteration no. 52582 ==> 0.34608843628574143\n",
            "Loss in iteration no. 52583 ==> 0.346087495413974\n",
            "Loss in iteration no. 52584 ==> 0.3460865545751948\n",
            "Loss in iteration no. 52585 ==> 0.34608561376940256\n",
            "Loss in iteration no. 52586 ==> 0.3460846729965953\n",
            "Loss in iteration no. 52587 ==> 0.34608373225677164\n",
            "Loss in iteration no. 52588 ==> 0.34608279154993005\n",
            "Loss in iteration no. 52589 ==> 0.3460818508760687\n",
            "Loss in iteration no. 52590 ==> 0.3460809102351861\n",
            "Loss in iteration no. 52591 ==> 0.34607996962728077\n",
            "Loss in iteration no. 52592 ==> 0.34607902905235083\n",
            "Loss in iteration no. 52593 ==> 0.3460780885103949\n",
            "Loss in iteration no. 52594 ==> 0.34607714800141126\n",
            "Loss in iteration no. 52595 ==> 0.34607620752539847\n",
            "Loss in iteration no. 52596 ==> 0.34607526708235486\n",
            "Loss in iteration no. 52597 ==> 0.3460743266722787\n",
            "Loss in iteration no. 52598 ==> 0.34607338629516843\n",
            "Loss in iteration no. 52599 ==> 0.3460724459510226\n",
            "Loss in iteration no. 52600 ==> 0.34607150563983946\n",
            "Loss in iteration no. 52601 ==> 0.34607056536161745\n",
            "Loss in iteration no. 52602 ==> 0.346069625116355\n",
            "Loss in iteration no. 52603 ==> 0.34606868490405046\n",
            "Loss in iteration no. 52604 ==> 0.34606774472470225\n",
            "Loss in iteration no. 52605 ==> 0.3460668045783088\n",
            "Loss in iteration no. 52606 ==> 0.3460658644648685\n",
            "Loss in iteration no. 52607 ==> 0.34606492438437964\n",
            "Loss in iteration no. 52608 ==> 0.34606398433684077\n",
            "Loss in iteration no. 52609 ==> 0.34606304432225027\n",
            "Loss in iteration no. 52610 ==> 0.34606210434060636\n",
            "Loss in iteration no. 52611 ==> 0.34606116439190776\n",
            "Loss in iteration no. 52612 ==> 0.34606022447615264\n",
            "Loss in iteration no. 52613 ==> 0.34605928459333946\n",
            "Loss in iteration no. 52614 ==> 0.34605834474346653\n",
            "Loss in iteration no. 52615 ==> 0.3460574049265324\n",
            "Loss in iteration no. 52616 ==> 0.3460564651425353\n",
            "Loss in iteration no. 52617 ==> 0.34605552539147394\n",
            "Loss in iteration no. 52618 ==> 0.3460545856733464\n",
            "Loss in iteration no. 52619 ==> 0.3460536459881512\n",
            "Loss in iteration no. 52620 ==> 0.34605270633588664\n",
            "Loss in iteration no. 52621 ==> 0.3460517667165513\n",
            "Loss in iteration no. 52622 ==> 0.34605082713014357\n",
            "Loss in iteration no. 52623 ==> 0.3460498875766617\n",
            "Loss in iteration no. 52624 ==> 0.34604894805610414\n",
            "Loss in iteration no. 52625 ==> 0.34604800856846946\n",
            "Loss in iteration no. 52626 ==> 0.3460470691137558\n",
            "Loss in iteration no. 52627 ==> 0.3460461296919618\n",
            "Loss in iteration no. 52628 ==> 0.3460451903030856\n",
            "Loss in iteration no. 52629 ==> 0.34604425094712576\n",
            "Loss in iteration no. 52630 ==> 0.3460433116240808\n",
            "Loss in iteration no. 52631 ==> 0.3460423723339489\n",
            "Loss in iteration no. 52632 ==> 0.3460414330767286\n",
            "Loss in iteration no. 52633 ==> 0.34604049385241825\n",
            "Loss in iteration no. 52634 ==> 0.34603955466101616\n",
            "Loss in iteration no. 52635 ==> 0.346038615502521\n",
            "Loss in iteration no. 52636 ==> 0.346037676376931\n",
            "Loss in iteration no. 52637 ==> 0.34603673728424444\n",
            "Loss in iteration no. 52638 ==> 0.3460357982244599\n",
            "Loss in iteration no. 52639 ==> 0.3460348591975757\n",
            "Loss in iteration no. 52640 ==> 0.34603392020359036\n",
            "Loss in iteration no. 52641 ==> 0.3460329812425021\n",
            "Loss in iteration no. 52642 ==> 0.3460320423143095\n",
            "Loss in iteration no. 52643 ==> 0.3460311034190109\n",
            "Loss in iteration no. 52644 ==> 0.34603016455660457\n",
            "Loss in iteration no. 52645 ==> 0.34602922572708916\n",
            "Loss in iteration no. 52646 ==> 0.34602828693046295\n",
            "Loss in iteration no. 52647 ==> 0.34602734816672426\n",
            "Loss in iteration no. 52648 ==> 0.34602640943587154\n",
            "Loss in iteration no. 52649 ==> 0.34602547073790335\n",
            "Loss in iteration no. 52650 ==> 0.3460245320728179\n",
            "Loss in iteration no. 52651 ==> 0.3460235934406138\n",
            "Loss in iteration no. 52652 ==> 0.3460226548412891\n",
            "Loss in iteration no. 52653 ==> 0.34602171627484246\n",
            "Loss in iteration no. 52654 ==> 0.3460207777412724\n",
            "Loss in iteration no. 52655 ==> 0.34601983924057717\n",
            "Loss in iteration no. 52656 ==> 0.34601890077275504\n",
            "Loss in iteration no. 52657 ==> 0.34601796233780463\n",
            "Loss in iteration no. 52658 ==> 0.34601702393572414\n",
            "Loss in iteration no. 52659 ==> 0.3460160855665123\n",
            "Loss in iteration no. 52660 ==> 0.3460151472301672\n",
            "Loss in iteration no. 52661 ==> 0.34601420892668744\n",
            "Loss in iteration no. 52662 ==> 0.34601327065607124\n",
            "Loss in iteration no. 52663 ==> 0.3460123324183172\n",
            "Loss in iteration no. 52664 ==> 0.34601139421342364\n",
            "Loss in iteration no. 52665 ==> 0.3460104560413889\n",
            "Loss in iteration no. 52666 ==> 0.34600951790221157\n",
            "Loss in iteration no. 52667 ==> 0.34600857979588984\n",
            "Loss in iteration no. 52668 ==> 0.3460076417224222\n",
            "Loss in iteration no. 52669 ==> 0.34600670368180697\n",
            "Loss in iteration no. 52670 ==> 0.34600576567404284\n",
            "Loss in iteration no. 52671 ==> 0.346004827699128\n",
            "Loss in iteration no. 52672 ==> 0.34600388975706087\n",
            "Loss in iteration no. 52673 ==> 0.34600295184783986\n",
            "Loss in iteration no. 52674 ==> 0.3460020139714633\n",
            "Loss in iteration no. 52675 ==> 0.34600107612792974\n",
            "Loss in iteration no. 52676 ==> 0.3460001383172376\n",
            "Loss in iteration no. 52677 ==> 0.3459992005393851\n",
            "Loss in iteration no. 52678 ==> 0.34599826279437085\n",
            "Loss in iteration no. 52679 ==> 0.3459973250821931\n",
            "Loss in iteration no. 52680 ==> 0.3459963874028504\n",
            "Loss in iteration no. 52681 ==> 0.3459954497563411\n",
            "Loss in iteration no. 52682 ==> 0.3459945121426635\n",
            "Loss in iteration no. 52683 ==> 0.3459935745618162\n",
            "Loss in iteration no. 52684 ==> 0.34599263701379745\n",
            "Loss in iteration no. 52685 ==> 0.3459916994986057\n",
            "Loss in iteration no. 52686 ==> 0.34599076201623935\n",
            "Loss in iteration no. 52687 ==> 0.3459898245666969\n",
            "Loss in iteration no. 52688 ==> 0.34598888714997666\n",
            "Loss in iteration no. 52689 ==> 0.3459879497660771\n",
            "Loss in iteration no. 52690 ==> 0.3459870124149965\n",
            "Loss in iteration no. 52691 ==> 0.3459860750967334\n",
            "Loss in iteration no. 52692 ==> 0.34598513781128626\n",
            "Loss in iteration no. 52693 ==> 0.3459842005586533\n",
            "Loss in iteration no. 52694 ==> 0.34598326333883306\n",
            "Loss in iteration no. 52695 ==> 0.34598232615182395\n",
            "Loss in iteration no. 52696 ==> 0.34598138899762426\n",
            "Loss in iteration no. 52697 ==> 0.34598045187623255\n",
            "Loss in iteration no. 52698 ==> 0.3459795147876471\n",
            "Loss in iteration no. 52699 ==> 0.3459785777318664\n",
            "Loss in iteration no. 52700 ==> 0.34597764070888887\n",
            "Loss in iteration no. 52701 ==> 0.3459767037187128\n",
            "Loss in iteration no. 52702 ==> 0.34597576676133684\n",
            "Loss in iteration no. 52703 ==> 0.34597482983675915\n",
            "Loss in iteration no. 52704 ==> 0.3459738929449782\n",
            "Loss in iteration no. 52705 ==> 0.3459729560859926\n",
            "Loss in iteration no. 52706 ==> 0.3459720192598005\n",
            "Loss in iteration no. 52707 ==> 0.3459710824664004\n",
            "Loss in iteration no. 52708 ==> 0.34597014570579065\n",
            "Loss in iteration no. 52709 ==> 0.34596920897796973\n",
            "Loss in iteration no. 52710 ==> 0.34596827228293614\n",
            "Loss in iteration no. 52711 ==> 0.34596733562068815\n",
            "Loss in iteration no. 52712 ==> 0.3459663989912241\n",
            "Loss in iteration no. 52713 ==> 0.3459654623945427\n",
            "Loss in iteration no. 52714 ==> 0.3459645258306421\n",
            "Loss in iteration no. 52715 ==> 0.34596358929952076\n",
            "Loss in iteration no. 52716 ==> 0.34596265280117716\n",
            "Loss in iteration no. 52717 ==> 0.3459617163356096\n",
            "Loss in iteration no. 52718 ==> 0.34596077990281665\n",
            "Loss in iteration no. 52719 ==> 0.34595984350279657\n",
            "Loss in iteration no. 52720 ==> 0.3459589071355479\n",
            "Loss in iteration no. 52721 ==> 0.3459579708010689\n",
            "Loss in iteration no. 52722 ==> 0.3459570344993581\n",
            "Loss in iteration no. 52723 ==> 0.34595609823041384\n",
            "Loss in iteration no. 52724 ==> 0.34595516199423465\n",
            "Loss in iteration no. 52725 ==> 0.3459542257908187\n",
            "Loss in iteration no. 52726 ==> 0.3459532896201647\n",
            "Loss in iteration no. 52727 ==> 0.3459523534822709\n",
            "Loss in iteration no. 52728 ==> 0.34595141737713564\n",
            "Loss in iteration no. 52729 ==> 0.34595048130475753\n",
            "Loss in iteration no. 52730 ==> 0.3459495452651348\n",
            "Loss in iteration no. 52731 ==> 0.345948609258266\n",
            "Loss in iteration no. 52732 ==> 0.34594767328414944\n",
            "Loss in iteration no. 52733 ==> 0.3459467373427836\n",
            "Loss in iteration no. 52734 ==> 0.3459458014341667\n",
            "Loss in iteration no. 52735 ==> 0.3459448655582976\n",
            "Loss in iteration no. 52736 ==> 0.34594392971517424\n",
            "Loss in iteration no. 52737 ==> 0.34594299390479527\n",
            "Loss in iteration no. 52738 ==> 0.34594205812715906\n",
            "Loss in iteration no. 52739 ==> 0.34594112238226404\n",
            "Loss in iteration no. 52740 ==> 0.3459401866701086\n",
            "Loss in iteration no. 52741 ==> 0.34593925099069117\n",
            "Loss in iteration no. 52742 ==> 0.3459383153440101\n",
            "Loss in iteration no. 52743 ==> 0.3459373797300638\n",
            "Loss in iteration no. 52744 ==> 0.3459364441488509\n",
            "Loss in iteration no. 52745 ==> 0.3459355086003694\n",
            "Loss in iteration no. 52746 ==> 0.34593457308461817\n",
            "Loss in iteration no. 52747 ==> 0.34593363760159535\n",
            "Loss in iteration no. 52748 ==> 0.34593270215129934\n",
            "Loss in iteration no. 52749 ==> 0.3459317667337288\n",
            "Loss in iteration no. 52750 ==> 0.34593083134888186\n",
            "Loss in iteration no. 52751 ==> 0.34592989599675705\n",
            "Loss in iteration no. 52752 ==> 0.34592896067735285\n",
            "Loss in iteration no. 52753 ==> 0.3459280253906676\n",
            "Loss in iteration no. 52754 ==> 0.34592709013669964\n",
            "Loss in iteration no. 52755 ==> 0.34592615491544754\n",
            "Loss in iteration no. 52756 ==> 0.34592521972690965\n",
            "Loss in iteration no. 52757 ==> 0.3459242845710843\n",
            "Loss in iteration no. 52758 ==> 0.34592334944797004\n",
            "Loss in iteration no. 52759 ==> 0.34592241435756527\n",
            "Loss in iteration no. 52760 ==> 0.34592147929986833\n",
            "Loss in iteration no. 52761 ==> 0.3459205442748777\n",
            "Loss in iteration no. 52762 ==> 0.3459196092825917\n",
            "Loss in iteration no. 52763 ==> 0.34591867432300877\n",
            "Loss in iteration no. 52764 ==> 0.3459177393961274\n",
            "Loss in iteration no. 52765 ==> 0.345916804501946\n",
            "Loss in iteration no. 52766 ==> 0.34591586964046306\n",
            "Loss in iteration no. 52767 ==> 0.34591493481167673\n",
            "Loss in iteration no. 52768 ==> 0.34591400001558553\n",
            "Loss in iteration no. 52769 ==> 0.34591306525218807\n",
            "Loss in iteration no. 52770 ==> 0.34591213052148256\n",
            "Loss in iteration no. 52771 ==> 0.3459111958234675\n",
            "Loss in iteration no. 52772 ==> 0.34591026115814133\n",
            "Loss in iteration no. 52773 ==> 0.3459093265255024\n",
            "Loss in iteration no. 52774 ==> 0.3459083919255491\n",
            "Loss in iteration no. 52775 ==> 0.34590745735828005\n",
            "Loss in iteration no. 52776 ==> 0.3459065228236933\n",
            "Loss in iteration no. 52777 ==> 0.3459055883217877\n",
            "Loss in iteration no. 52778 ==> 0.3459046538525613\n",
            "Loss in iteration no. 52779 ==> 0.3459037194160127\n",
            "Loss in iteration no. 52780 ==> 0.34590278501214033\n",
            "Loss in iteration no. 52781 ==> 0.34590185064094253\n",
            "Loss in iteration no. 52782 ==> 0.34590091630241765\n",
            "Loss in iteration no. 52783 ==> 0.3458999819965643\n",
            "Loss in iteration no. 52784 ==> 0.34589904772338087\n",
            "Loss in iteration no. 52785 ==> 0.34589811348286564\n",
            "Loss in iteration no. 52786 ==> 0.34589717927501706\n",
            "Loss in iteration no. 52787 ==> 0.34589624509983363\n",
            "Loss in iteration no. 52788 ==> 0.34589531095731374\n",
            "Loss in iteration no. 52789 ==> 0.34589437684745583\n",
            "Loss in iteration no. 52790 ==> 0.3458934427702582\n",
            "Loss in iteration no. 52791 ==> 0.34589250872571925\n",
            "Loss in iteration no. 52792 ==> 0.3458915747138377\n",
            "Loss in iteration no. 52793 ==> 0.3458906407346117\n",
            "Loss in iteration no. 52794 ==> 0.3458897067880396\n",
            "Loss in iteration no. 52795 ==> 0.34588877287412007\n",
            "Loss in iteration no. 52796 ==> 0.3458878389928514\n",
            "Loss in iteration no. 52797 ==> 0.34588690514423204\n",
            "Loss in iteration no. 52798 ==> 0.3458859713282604\n",
            "Loss in iteration no. 52799 ==> 0.3458850375449348\n",
            "Loss in iteration no. 52800 ==> 0.34588410379425377\n",
            "Loss in iteration no. 52801 ==> 0.3458831700762158\n",
            "Loss in iteration no. 52802 ==> 0.3458822363908191\n",
            "Loss in iteration no. 52803 ==> 0.3458813027380622\n",
            "Loss in iteration no. 52804 ==> 0.34588036911794356\n",
            "Loss in iteration no. 52805 ==> 0.3458794355304615\n",
            "Loss in iteration no. 52806 ==> 0.3458785019756146\n",
            "Loss in iteration no. 52807 ==> 0.3458775684534012\n",
            "Loss in iteration no. 52808 ==> 0.34587663496381954\n",
            "Loss in iteration no. 52809 ==> 0.34587570150686825\n",
            "Loss in iteration no. 52810 ==> 0.34587476808254586\n",
            "Loss in iteration no. 52811 ==> 0.34587383469085053\n",
            "Loss in iteration no. 52812 ==> 0.3458729013317807\n",
            "Loss in iteration no. 52813 ==> 0.345871968005335\n",
            "Loss in iteration no. 52814 ==> 0.3458710347115116\n",
            "Loss in iteration no. 52815 ==> 0.3458701014503091\n",
            "Loss in iteration no. 52816 ==> 0.3458691682217258\n",
            "Loss in iteration no. 52817 ==> 0.3458682350257603\n",
            "Loss in iteration no. 52818 ==> 0.3458673018624109\n",
            "Loss in iteration no. 52819 ==> 0.345866368731676\n",
            "Loss in iteration no. 52820 ==> 0.3458654356335539\n",
            "Loss in iteration no. 52821 ==> 0.34586450256804335\n",
            "Loss in iteration no. 52822 ==> 0.3458635695351425\n",
            "Loss in iteration no. 52823 ==> 0.3458626365348499\n",
            "Loss in iteration no. 52824 ==> 0.3458617035671639\n",
            "Loss in iteration no. 52825 ==> 0.3458607706320829\n",
            "Loss in iteration no. 52826 ==> 0.34585983772960543\n",
            "Loss in iteration no. 52827 ==> 0.3458589048597299\n",
            "Loss in iteration no. 52828 ==> 0.34585797202245466\n",
            "Loss in iteration no. 52829 ==> 0.34585703921777816\n",
            "Loss in iteration no. 52830 ==> 0.34585610644569875\n",
            "Loss in iteration no. 52831 ==> 0.345855173706215\n",
            "Loss in iteration no. 52832 ==> 0.34585424099932516\n",
            "Loss in iteration no. 52833 ==> 0.3458533083250279\n",
            "Loss in iteration no. 52834 ==> 0.34585237568332133\n",
            "Loss in iteration no. 52835 ==> 0.34585144307420423\n",
            "Loss in iteration no. 52836 ==> 0.3458505104976746\n",
            "Loss in iteration no. 52837 ==> 0.3458495779537313\n",
            "Loss in iteration no. 52838 ==> 0.34584864544237237\n",
            "Loss in iteration no. 52839 ==> 0.3458477129635964\n",
            "Loss in iteration no. 52840 ==> 0.3458467805174019\n",
            "Loss in iteration no. 52841 ==> 0.3458458481037872\n",
            "Loss in iteration no. 52842 ==> 0.3458449157227508\n",
            "Loss in iteration no. 52843 ==> 0.34584398337429095\n",
            "Loss in iteration no. 52844 ==> 0.34584305105840607\n",
            "Loss in iteration no. 52845 ==> 0.3458421187750949\n",
            "Loss in iteration no. 52846 ==> 0.34584118652435564\n",
            "Loss in iteration no. 52847 ==> 0.34584025430618665\n",
            "Loss in iteration no. 52848 ==> 0.34583932212058643\n",
            "Loss in iteration no. 52849 ==> 0.3458383899675534\n",
            "Loss in iteration no. 52850 ==> 0.3458374578470861\n",
            "Loss in iteration no. 52851 ==> 0.3458365257591827\n",
            "Loss in iteration no. 52852 ==> 0.34583559370384187\n",
            "Loss in iteration no. 52853 ==> 0.34583466168106186\n",
            "Loss in iteration no. 52854 ==> 0.3458337296908412\n",
            "Loss in iteration no. 52855 ==> 0.3458327977331784\n",
            "Loss in iteration no. 52856 ==> 0.34583186580807157\n",
            "Loss in iteration no. 52857 ==> 0.34583093391551945\n",
            "Loss in iteration no. 52858 ==> 0.3458300020555203\n",
            "Loss in iteration no. 52859 ==> 0.34582907022807263\n",
            "Loss in iteration no. 52860 ==> 0.3458281384331748\n",
            "Loss in iteration no. 52861 ==> 0.3458272066708252\n",
            "Loss in iteration no. 52862 ==> 0.3458262749410223\n",
            "Loss in iteration no. 52863 ==> 0.3458253432437647\n",
            "Loss in iteration no. 52864 ==> 0.3458244115790506\n",
            "Loss in iteration no. 52865 ==> 0.34582347994687845\n",
            "Loss in iteration no. 52866 ==> 0.34582254834724674\n",
            "Loss in iteration no. 52867 ==> 0.3458216167801539\n",
            "Loss in iteration no. 52868 ==> 0.34582068524559834\n",
            "Loss in iteration no. 52869 ==> 0.34581975374357843\n",
            "Loss in iteration no. 52870 ==> 0.34581882227409266\n",
            "Loss in iteration no. 52871 ==> 0.34581789083713943\n",
            "Loss in iteration no. 52872 ==> 0.34581695943271723\n",
            "Loss in iteration no. 52873 ==> 0.34581602806082434\n",
            "Loss in iteration no. 52874 ==> 0.34581509672145927\n",
            "Loss in iteration no. 52875 ==> 0.3458141654146205\n",
            "Loss in iteration no. 52876 ==> 0.3458132341403064\n",
            "Loss in iteration no. 52877 ==> 0.34581230289851544\n",
            "Loss in iteration no. 52878 ==> 0.34581137168924597\n",
            "Loss in iteration no. 52879 ==> 0.34581044051249643\n",
            "Loss in iteration no. 52880 ==> 0.3458095093682654\n",
            "Loss in iteration no. 52881 ==> 0.34580857825655104\n",
            "Loss in iteration no. 52882 ==> 0.34580764717735196\n",
            "Loss in iteration no. 52883 ==> 0.3458067161306666\n",
            "Loss in iteration no. 52884 ==> 0.34580578511649335\n",
            "Loss in iteration no. 52885 ==> 0.34580485413483053\n",
            "Loss in iteration no. 52886 ==> 0.34580392318567665\n",
            "Loss in iteration no. 52887 ==> 0.3458029922690302\n",
            "Loss in iteration no. 52888 ==> 0.34580206138488967\n",
            "Loss in iteration no. 52889 ==> 0.3458011305332532\n",
            "Loss in iteration no. 52890 ==> 0.3458001997141194\n",
            "Loss in iteration no. 52891 ==> 0.34579926892748675\n",
            "Loss in iteration no. 52892 ==> 0.3457983381733536\n",
            "Loss in iteration no. 52893 ==> 0.34579740745171844\n",
            "Loss in iteration no. 52894 ==> 0.34579647676257963\n",
            "Loss in iteration no. 52895 ==> 0.3457955461059355\n",
            "Loss in iteration no. 52896 ==> 0.34579461548178475\n",
            "Loss in iteration no. 52897 ==> 0.3457936848901257\n",
            "Loss in iteration no. 52898 ==> 0.3457927543309565\n",
            "Loss in iteration no. 52899 ==> 0.3457918238042761\n",
            "Loss in iteration no. 52900 ==> 0.3457908933100825\n",
            "Loss in iteration no. 52901 ==> 0.3457899628483742\n",
            "Loss in iteration no. 52902 ==> 0.3457890324191499\n",
            "Loss in iteration no. 52903 ==> 0.3457881020224077\n",
            "Loss in iteration no. 52904 ==> 0.34578717165814615\n",
            "Loss in iteration no. 52905 ==> 0.3457862413263637\n",
            "Loss in iteration no. 52906 ==> 0.34578531102705884\n",
            "Loss in iteration no. 52907 ==> 0.34578438076022994\n",
            "Loss in iteration no. 52908 ==> 0.34578345052587534\n",
            "Loss in iteration no. 52909 ==> 0.3457825203239936\n",
            "Loss in iteration no. 52910 ==> 0.345781590154583\n",
            "Loss in iteration no. 52911 ==> 0.3457806600176422\n",
            "Loss in iteration no. 52912 ==> 0.3457797299131694\n",
            "Loss in iteration no. 52913 ==> 0.3457787998411632\n",
            "Loss in iteration no. 52914 ==> 0.3457778698016219\n",
            "Loss in iteration no. 52915 ==> 0.3457769397945441\n",
            "Loss in iteration no. 52916 ==> 0.345776009819928\n",
            "Loss in iteration no. 52917 ==> 0.34577507987777223\n",
            "Loss in iteration no. 52918 ==> 0.34577414996807515\n",
            "Loss in iteration no. 52919 ==> 0.3457732200908351\n",
            "Loss in iteration no. 52920 ==> 0.34577229024605066\n",
            "Loss in iteration no. 52921 ==> 0.3457713604337202\n",
            "Loss in iteration no. 52922 ==> 0.34577043065384216\n",
            "Loss in iteration no. 52923 ==> 0.3457695009064149\n",
            "Loss in iteration no. 52924 ==> 0.345768571191437\n",
            "Loss in iteration no. 52925 ==> 0.34576764150890676\n",
            "Loss in iteration no. 52926 ==> 0.34576671185882263\n",
            "Loss in iteration no. 52927 ==> 0.345765782241183\n",
            "Loss in iteration no. 52928 ==> 0.3457648526559865\n",
            "Loss in iteration no. 52929 ==> 0.34576392310323123\n",
            "Loss in iteration no. 52930 ==> 0.34576299358291607\n",
            "Loss in iteration no. 52931 ==> 0.34576206409503907\n",
            "Loss in iteration no. 52932 ==> 0.34576113463959873\n",
            "Loss in iteration no. 52933 ==> 0.3457602052165936\n",
            "Loss in iteration no. 52934 ==> 0.3457592758260221\n",
            "Loss in iteration no. 52935 ==> 0.34575834646788256\n",
            "Loss in iteration no. 52936 ==> 0.34575741714217356\n",
            "Loss in iteration no. 52937 ==> 0.3457564878488934\n",
            "Loss in iteration no. 52938 ==> 0.3457555585880405\n",
            "Loss in iteration no. 52939 ==> 0.34575462935961343\n",
            "Loss in iteration no. 52940 ==> 0.3457537001636105\n",
            "Loss in iteration no. 52941 ==> 0.34575277100003016\n",
            "Loss in iteration no. 52942 ==> 0.3457518418688709\n",
            "Loss in iteration no. 52943 ==> 0.3457509127701312\n",
            "Loss in iteration no. 52944 ==> 0.3457499837038094\n",
            "Loss in iteration no. 52945 ==> 0.3457490546699038\n",
            "Loss in iteration no. 52946 ==> 0.34574812566841306\n",
            "Loss in iteration no. 52947 ==> 0.34574719669933557\n",
            "Loss in iteration no. 52948 ==> 0.3457462677626697\n",
            "Loss in iteration no. 52949 ==> 0.34574533885841396\n",
            "Loss in iteration no. 52950 ==> 0.34574440998656664\n",
            "Loss in iteration no. 52951 ==> 0.34574348114712633\n",
            "Loss in iteration no. 52952 ==> 0.34574255234009144\n",
            "Loss in iteration no. 52953 ==> 0.34574162356546034\n",
            "Loss in iteration no. 52954 ==> 0.34574069482323144\n",
            "Loss in iteration no. 52955 ==> 0.34573976611340324\n",
            "Loss in iteration no. 52956 ==> 0.3457388374359743\n",
            "Loss in iteration no. 52957 ==> 0.3457379087909428\n",
            "Loss in iteration no. 52958 ==> 0.34573698017830723\n",
            "Loss in iteration no. 52959 ==> 0.34573605159806625\n",
            "Loss in iteration no. 52960 ==> 0.345735123050218\n",
            "Loss in iteration no. 52961 ==> 0.3457341945347611\n",
            "Loss in iteration no. 52962 ==> 0.34573326605169385\n",
            "Loss in iteration no. 52963 ==> 0.34573233760101485\n",
            "Loss in iteration no. 52964 ==> 0.3457314091827225\n",
            "Loss in iteration no. 52965 ==> 0.3457304807968152\n",
            "Loss in iteration no. 52966 ==> 0.3457295524432912\n",
            "Loss in iteration no. 52967 ==> 0.34572862412214916\n",
            "Loss in iteration no. 52968 ==> 0.3457276958333875\n",
            "Loss in iteration no. 52969 ==> 0.34572676757700466\n",
            "Loss in iteration no. 52970 ==> 0.345725839352999\n",
            "Loss in iteration no. 52971 ==> 0.345724911161369\n",
            "Loss in iteration no. 52972 ==> 0.34572398300211304\n",
            "Loss in iteration no. 52973 ==> 0.34572305487522964\n",
            "Loss in iteration no. 52974 ==> 0.34572212678071723\n",
            "Loss in iteration no. 52975 ==> 0.34572119871857415\n",
            "Loss in iteration no. 52976 ==> 0.34572027068879896\n",
            "Loss in iteration no. 52977 ==> 0.3457193426913901\n",
            "Loss in iteration no. 52978 ==> 0.3457184147263458\n",
            "Loss in iteration no. 52979 ==> 0.34571748679366465\n",
            "Loss in iteration no. 52980 ==> 0.3457165588933452\n",
            "Loss in iteration no. 52981 ==> 0.3457156310253856\n",
            "Loss in iteration no. 52982 ==> 0.34571470318978464\n",
            "Loss in iteration no. 52983 ==> 0.3457137753865404\n",
            "Loss in iteration no. 52984 ==> 0.34571284761565163\n",
            "Loss in iteration no. 52985 ==> 0.34571191987711647\n",
            "Loss in iteration no. 52986 ==> 0.3457109921709337\n",
            "Loss in iteration no. 52987 ==> 0.34571006449710134\n",
            "Loss in iteration no. 52988 ==> 0.34570913685561827\n",
            "Loss in iteration no. 52989 ==> 0.3457082092464826\n",
            "Loss in iteration no. 52990 ==> 0.34570728166969295\n",
            "Loss in iteration no. 52991 ==> 0.34570635412524764\n",
            "Loss in iteration no. 52992 ==> 0.34570542661314513\n",
            "Loss in iteration no. 52993 ==> 0.3457044991333839\n",
            "Loss in iteration no. 52994 ==> 0.34570357168596244\n",
            "Loss in iteration no. 52995 ==> 0.34570264427087904\n",
            "Loss in iteration no. 52996 ==> 0.3457017168881323\n",
            "Loss in iteration no. 52997 ==> 0.3457007895377205\n",
            "Loss in iteration no. 52998 ==> 0.3456998622196422\n",
            "Loss in iteration no. 52999 ==> 0.3456989349338958\n",
            "Loss in iteration no. 53000 ==> 0.3456980076804797\n",
            "Loss in iteration no. 53001 ==> 0.3456970804593924\n",
            "Loss in iteration no. 53002 ==> 0.34569615327063236\n",
            "Loss in iteration no. 53003 ==> 0.3456952261141979\n",
            "Loss in iteration no. 53004 ==> 0.34569429899008747\n",
            "Loss in iteration no. 53005 ==> 0.34569337189829963\n",
            "Loss in iteration no. 53006 ==> 0.3456924448388328\n",
            "Loss in iteration no. 53007 ==> 0.3456915178116854\n",
            "Loss in iteration no. 53008 ==> 0.3456905908168558\n",
            "Loss in iteration no. 53009 ==> 0.34568966385434247\n",
            "Loss in iteration no. 53010 ==> 0.34568873692414387\n",
            "Loss in iteration no. 53011 ==> 0.34568781002625854\n",
            "Loss in iteration no. 53012 ==> 0.3456868831606847\n",
            "Loss in iteration no. 53013 ==> 0.34568595632742094\n",
            "Loss in iteration no. 53014 ==> 0.3456850295264657\n",
            "Loss in iteration no. 53015 ==> 0.34568410275781736\n",
            "Loss in iteration no. 53016 ==> 0.3456831760214744\n",
            "Loss in iteration no. 53017 ==> 0.34568224931743524\n",
            "Loss in iteration no. 53018 ==> 0.3456813226456983\n",
            "Loss in iteration no. 53019 ==> 0.34568039600626205\n",
            "Loss in iteration no. 53020 ==> 0.345679469399125\n",
            "Loss in iteration no. 53021 ==> 0.34567854282428545\n",
            "Loss in iteration no. 53022 ==> 0.345677616281742\n",
            "Loss in iteration no. 53023 ==> 0.3456766897714929\n",
            "Loss in iteration no. 53024 ==> 0.3456757632935367\n",
            "Loss in iteration no. 53025 ==> 0.34567483684787187\n",
            "Loss in iteration no. 53026 ==> 0.3456739104344968\n",
            "Loss in iteration no. 53027 ==> 0.34567298405341\n",
            "Loss in iteration no. 53028 ==> 0.34567205770460985\n",
            "Loss in iteration no. 53029 ==> 0.3456711313880948\n",
            "Loss in iteration no. 53030 ==> 0.34567020510386326\n",
            "Loss in iteration no. 53031 ==> 0.3456692788519137\n",
            "Loss in iteration no. 53032 ==> 0.3456683526322446\n",
            "Loss in iteration no. 53033 ==> 0.3456674264448544\n",
            "Loss in iteration no. 53034 ==> 0.3456665002897414\n",
            "Loss in iteration no. 53035 ==> 0.34566557416690424\n",
            "Loss in iteration no. 53036 ==> 0.34566464807634123\n",
            "Loss in iteration no. 53037 ==> 0.34566372201805085\n",
            "Loss in iteration no. 53038 ==> 0.3456627959920316\n",
            "Loss in iteration no. 53039 ==> 0.34566186999828186\n",
            "Loss in iteration no. 53040 ==> 0.3456609440368001\n",
            "Loss in iteration no. 53041 ==> 0.34566001810758473\n",
            "Loss in iteration no. 53042 ==> 0.3456590922106342\n",
            "Loss in iteration no. 53043 ==> 0.345658166345947\n",
            "Loss in iteration no. 53044 ==> 0.34565724051352154\n",
            "Loss in iteration no. 53045 ==> 0.34565631471335617\n",
            "Loss in iteration no. 53046 ==> 0.34565538894544945\n",
            "Loss in iteration no. 53047 ==> 0.3456544632097998\n",
            "Loss in iteration no. 53048 ==> 0.34565353750640576\n",
            "Loss in iteration no. 53049 ==> 0.3456526118352656\n",
            "Loss in iteration no. 53050 ==> 0.3456516861963778\n",
            "Loss in iteration no. 53051 ==> 0.3456507605897409\n",
            "Loss in iteration no. 53052 ==> 0.34564983501535324\n",
            "Loss in iteration no. 53053 ==> 0.3456489094732134\n",
            "Loss in iteration no. 53054 ==> 0.3456479839633196\n",
            "Loss in iteration no. 53055 ==> 0.3456470584856705\n",
            "Loss in iteration no. 53056 ==> 0.3456461330402644\n",
            "Loss in iteration no. 53057 ==> 0.3456452076270999\n",
            "Loss in iteration no. 53058 ==> 0.3456442822461753\n",
            "Loss in iteration no. 53059 ==> 0.3456433568974891\n",
            "Loss in iteration no. 53060 ==> 0.3456424315810398\n",
            "Loss in iteration no. 53061 ==> 0.34564150629682566\n",
            "Loss in iteration no. 53062 ==> 0.34564058104484535\n",
            "Loss in iteration no. 53063 ==> 0.3456396558250971\n",
            "Loss in iteration no. 53064 ==> 0.34563873063757955\n",
            "Loss in iteration no. 53065 ==> 0.34563780548229106\n",
            "Loss in iteration no. 53066 ==> 0.3456368803592302\n",
            "Loss in iteration no. 53067 ==> 0.345635955268395\n",
            "Loss in iteration no. 53068 ==> 0.3456350302097845\n",
            "Loss in iteration no. 53069 ==> 0.3456341051833967\n",
            "Loss in iteration no. 53070 ==> 0.3456331801892302\n",
            "Loss in iteration no. 53071 ==> 0.3456322552272834\n",
            "Loss in iteration no. 53072 ==> 0.3456313302975549\n",
            "Loss in iteration no. 53073 ==> 0.34563040540004286\n",
            "Loss in iteration no. 53074 ==> 0.34562948053474596\n",
            "Loss in iteration no. 53075 ==> 0.3456285557016626\n",
            "Loss in iteration no. 53076 ==> 0.34562763090079124\n",
            "Loss in iteration no. 53077 ==> 0.3456267061321303\n",
            "Loss in iteration no. 53078 ==> 0.34562578139567823\n",
            "Loss in iteration no. 53079 ==> 0.3456248566914334\n",
            "Loss in iteration no. 53080 ==> 0.3456239320193943\n",
            "Loss in iteration no. 53081 ==> 0.3456230073795595\n",
            "Loss in iteration no. 53082 ==> 0.3456220827719273\n",
            "Loss in iteration no. 53083 ==> 0.34562115819649614\n",
            "Loss in iteration no. 53084 ==> 0.34562023365326455\n",
            "Loss in iteration no. 53085 ==> 0.34561930914223093\n",
            "Loss in iteration no. 53086 ==> 0.3456183846633938\n",
            "Loss in iteration no. 53087 ==> 0.3456174602167515\n",
            "Loss in iteration no. 53088 ==> 0.3456165358023026\n",
            "Loss in iteration no. 53089 ==> 0.3456156114200454\n",
            "Loss in iteration no. 53090 ==> 0.34561468706997844\n",
            "Loss in iteration no. 53091 ==> 0.34561376275210015\n",
            "Loss in iteration no. 53092 ==> 0.345612838466409\n",
            "Loss in iteration no. 53093 ==> 0.3456119142129034\n",
            "Loss in iteration no. 53094 ==> 0.34561098999158185\n",
            "Loss in iteration no. 53095 ==> 0.34561006580244275\n",
            "Loss in iteration no. 53096 ==> 0.34560914164548456\n",
            "Loss in iteration no. 53097 ==> 0.34560821752070564\n",
            "Loss in iteration no. 53098 ==> 0.34560729342810464\n",
            "Loss in iteration no. 53099 ==> 0.34560636936767986\n",
            "Loss in iteration no. 53100 ==> 0.3456054453394298\n",
            "Loss in iteration no. 53101 ==> 0.34560452134335284\n",
            "Loss in iteration no. 53102 ==> 0.34560359737944757\n",
            "Loss in iteration no. 53103 ==> 0.3456026734477123\n",
            "Loss in iteration no. 53104 ==> 0.34560174954814554\n",
            "Loss in iteration no. 53105 ==> 0.34560082568074574\n",
            "Loss in iteration no. 53106 ==> 0.3455999018455112\n",
            "Loss in iteration no. 53107 ==> 0.34559897804244066\n",
            "Loss in iteration no. 53108 ==> 0.34559805427153245\n",
            "Loss in iteration no. 53109 ==> 0.3455971305327849\n",
            "Loss in iteration no. 53110 ==> 0.3455962068261965\n",
            "Loss in iteration no. 53111 ==> 0.34559528315176585\n",
            "Loss in iteration no. 53112 ==> 0.34559435950949124\n",
            "Loss in iteration no. 53113 ==> 0.34559343589937114\n",
            "Loss in iteration no. 53114 ==> 0.3455925123214041\n",
            "Loss in iteration no. 53115 ==> 0.3455915887755885\n",
            "Loss in iteration no. 53116 ==> 0.3455906652619227\n",
            "Loss in iteration no. 53117 ==> 0.34558974178040536\n",
            "Loss in iteration no. 53118 ==> 0.3455888183310347\n",
            "Loss in iteration no. 53119 ==> 0.3455878949138094\n",
            "Loss in iteration no. 53120 ==> 0.3455869715287278\n",
            "Loss in iteration no. 53121 ==> 0.3455860481757883\n",
            "Loss in iteration no. 53122 ==> 0.3455851248549894\n",
            "Loss in iteration no. 53123 ==> 0.3455842015663295\n",
            "Loss in iteration no. 53124 ==> 0.3455832783098072\n",
            "Loss in iteration no. 53125 ==> 0.3455823550854207\n",
            "Loss in iteration no. 53126 ==> 0.34558143189316876\n",
            "Loss in iteration no. 53127 ==> 0.3455805087330496\n",
            "Loss in iteration no. 53128 ==> 0.3455795856050616\n",
            "Loss in iteration no. 53129 ==> 0.3455786625092036\n",
            "Loss in iteration no. 53130 ==> 0.3455777394454737\n",
            "Loss in iteration no. 53131 ==> 0.34557681641387045\n",
            "Loss in iteration no. 53132 ==> 0.3455758934143923\n",
            "Loss in iteration no. 53133 ==> 0.3455749704470377\n",
            "Loss in iteration no. 53134 ==> 0.34557404751180526\n",
            "Loss in iteration no. 53135 ==> 0.3455731246086931\n",
            "Loss in iteration no. 53136 ==> 0.3455722017376999\n",
            "Loss in iteration no. 53137 ==> 0.3455712788988241\n",
            "Loss in iteration no. 53138 ==> 0.3455703560920641\n",
            "Loss in iteration no. 53139 ==> 0.34556943331741835\n",
            "Loss in iteration no. 53140 ==> 0.34556851057488536\n",
            "Loss in iteration no. 53141 ==> 0.3455675878644636\n",
            "Loss in iteration no. 53142 ==> 0.3455666651861514\n",
            "Loss in iteration no. 53143 ==> 0.3455657425399473\n",
            "Loss in iteration no. 53144 ==> 0.34556481992584964\n",
            "Loss in iteration no. 53145 ==> 0.34556389734385706\n",
            "Loss in iteration no. 53146 ==> 0.34556297479396797\n",
            "Loss in iteration no. 53147 ==> 0.3455620522761807\n",
            "Loss in iteration no. 53148 ==> 0.3455611297904938\n",
            "Loss in iteration no. 53149 ==> 0.34556020733690573\n",
            "Loss in iteration no. 53150 ==> 0.34555928491541493\n",
            "Loss in iteration no. 53151 ==> 0.34555836252601974\n",
            "Loss in iteration no. 53152 ==> 0.3455574401687188\n",
            "Loss in iteration no. 53153 ==> 0.34555651784351044\n",
            "Loss in iteration no. 53154 ==> 0.3455555955503931\n",
            "Loss in iteration no. 53155 ==> 0.34555467328936534\n",
            "Loss in iteration no. 53156 ==> 0.3455537510604255\n",
            "Loss in iteration no. 53157 ==> 0.3455528288635722\n",
            "Loss in iteration no. 53158 ==> 0.3455519066988037\n",
            "Loss in iteration no. 53159 ==> 0.34555098456611866\n",
            "Loss in iteration no. 53160 ==> 0.34555006246551523\n",
            "Loss in iteration no. 53161 ==> 0.34554914039699214\n",
            "Loss in iteration no. 53162 ==> 0.3455482183605478\n",
            "Loss in iteration no. 53163 ==> 0.3455472963561805\n",
            "Loss in iteration no. 53164 ==> 0.34554637438388885\n",
            "Loss in iteration no. 53165 ==> 0.34554545244367135\n",
            "Loss in iteration no. 53166 ==> 0.34554453053552636\n",
            "Loss in iteration no. 53167 ==> 0.3455436086594523\n",
            "Loss in iteration no. 53168 ==> 0.3455426868154476\n",
            "Loss in iteration no. 53169 ==> 0.3455417650035109\n",
            "Loss in iteration no. 53170 ==> 0.3455408432236405\n",
            "Loss in iteration no. 53171 ==> 0.3455399214758349\n",
            "Loss in iteration no. 53172 ==> 0.34553899976009256\n",
            "Loss in iteration no. 53173 ==> 0.3455380780764119\n",
            "Loss in iteration no. 53174 ==> 0.3455371564247915\n",
            "Loss in iteration no. 53175 ==> 0.34553623480522966\n",
            "Loss in iteration no. 53176 ==> 0.3455353132177248\n",
            "Loss in iteration no. 53177 ==> 0.3455343916622756\n",
            "Loss in iteration no. 53178 ==> 0.34553347013888036\n",
            "Loss in iteration no. 53179 ==> 0.3455325486475375\n",
            "Loss in iteration no. 53180 ==> 0.3455316271882456\n",
            "Loss in iteration no. 53181 ==> 0.3455307057610031\n",
            "Loss in iteration no. 53182 ==> 0.34552978436580833\n",
            "Loss in iteration no. 53183 ==> 0.34552886300265995\n",
            "Loss in iteration no. 53184 ==> 0.3455279416715562\n",
            "Loss in iteration no. 53185 ==> 0.34552702037249555\n",
            "Loss in iteration no. 53186 ==> 0.3455260991054766\n",
            "Loss in iteration no. 53187 ==> 0.34552517787049786\n",
            "Loss in iteration no. 53188 ==> 0.34552425666755754\n",
            "Loss in iteration no. 53189 ==> 0.34552333549665437\n",
            "Loss in iteration no. 53190 ==> 0.34552241435778663\n",
            "Loss in iteration no. 53191 ==> 0.3455214932509527\n",
            "Loss in iteration no. 53192 ==> 0.3455205721761512\n",
            "Loss in iteration no. 53193 ==> 0.3455196511333806\n",
            "Loss in iteration no. 53194 ==> 0.3455187301226393\n",
            "Loss in iteration no. 53195 ==> 0.3455178091439257\n",
            "Loss in iteration no. 53196 ==> 0.34551688819723836\n",
            "Loss in iteration no. 53197 ==> 0.3455159672825756\n",
            "Loss in iteration no. 53198 ==> 0.3455150463999361\n",
            "Loss in iteration no. 53199 ==> 0.3455141255493181\n",
            "Loss in iteration no. 53200 ==> 0.34551320473072017\n",
            "Loss in iteration no. 53201 ==> 0.34551228394414074\n",
            "Loss in iteration no. 53202 ==> 0.34551136318957837\n",
            "Loss in iteration no. 53203 ==> 0.3455104424670312\n",
            "Loss in iteration no. 53204 ==> 0.34550952177649813\n",
            "Loss in iteration no. 53205 ==> 0.3455086011179773\n",
            "Loss in iteration no. 53206 ==> 0.34550768049146724\n",
            "Loss in iteration no. 53207 ==> 0.34550675989696655\n",
            "Loss in iteration no. 53208 ==> 0.34550583933447343\n",
            "Loss in iteration no. 53209 ==> 0.34550491880398654\n",
            "Loss in iteration no. 53210 ==> 0.3455039983055044\n",
            "Loss in iteration no. 53211 ==> 0.34550307783902523\n",
            "Loss in iteration no. 53212 ==> 0.34550215740454754\n",
            "Loss in iteration no. 53213 ==> 0.3455012370020701\n",
            "Loss in iteration no. 53214 ==> 0.345500316631591\n",
            "Loss in iteration no. 53215 ==> 0.34549939629310883\n",
            "Loss in iteration no. 53216 ==> 0.345498475986622\n",
            "Loss in iteration no. 53217 ==> 0.34549755571212915\n",
            "Loss in iteration no. 53218 ==> 0.3454966354696285\n",
            "Loss in iteration no. 53219 ==> 0.34549571525911865\n",
            "Loss in iteration no. 53220 ==> 0.345494795080598\n",
            "Loss in iteration no. 53221 ==> 0.34549387493406514\n",
            "Loss in iteration no. 53222 ==> 0.3454929548195183\n",
            "Loss in iteration no. 53223 ==> 0.3454920347369561\n",
            "Loss in iteration no. 53224 ==> 0.3454911146863771\n",
            "Loss in iteration no. 53225 ==> 0.34549019466777947\n",
            "Loss in iteration no. 53226 ==> 0.345489274681162\n",
            "Loss in iteration no. 53227 ==> 0.3454883547265228\n",
            "Loss in iteration no. 53228 ==> 0.3454874348038606\n",
            "Loss in iteration no. 53229 ==> 0.3454865149131738\n",
            "Loss in iteration no. 53230 ==> 0.3454855950544609\n",
            "Loss in iteration no. 53231 ==> 0.34548467522772025\n",
            "Loss in iteration no. 53232 ==> 0.3454837554329503\n",
            "Loss in iteration no. 53233 ==> 0.34548283567014965\n",
            "Loss in iteration no. 53234 ==> 0.3454819159393166\n",
            "Loss in iteration no. 53235 ==> 0.34548099624044976\n",
            "Loss in iteration no. 53236 ==> 0.34548007657354746\n",
            "Loss in iteration no. 53237 ==> 0.34547915693860826\n",
            "Loss in iteration no. 53238 ==> 0.34547823733563066\n",
            "Loss in iteration no. 53239 ==> 0.3454773177646129\n",
            "Loss in iteration no. 53240 ==> 0.3454763982255537\n",
            "Loss in iteration no. 53241 ==> 0.3454754787184514\n",
            "Loss in iteration no. 53242 ==> 0.34547455924330456\n",
            "Loss in iteration no. 53243 ==> 0.3454736398001114\n",
            "Loss in iteration no. 53244 ==> 0.3454727203888706\n",
            "Loss in iteration no. 53245 ==> 0.3454718010095807\n",
            "Loss in iteration no. 53246 ==> 0.3454708816622399\n",
            "Loss in iteration no. 53247 ==> 0.34546996234684685\n",
            "Loss in iteration no. 53248 ==> 0.3454690430633999\n",
            "Loss in iteration no. 53249 ==> 0.34546812381189757\n",
            "Loss in iteration no. 53250 ==> 0.3454672045923384\n",
            "Loss in iteration no. 53251 ==> 0.3454662854047207\n",
            "Loss in iteration no. 53252 ==> 0.345465366249043\n",
            "Loss in iteration no. 53253 ==> 0.3454644471253038\n",
            "Loss in iteration no. 53254 ==> 0.34546352803350144\n",
            "Loss in iteration no. 53255 ==> 0.3454626089736346\n",
            "Loss in iteration no. 53256 ==> 0.34546168994570164\n",
            "Loss in iteration no. 53257 ==> 0.34546077094970085\n",
            "Loss in iteration no. 53258 ==> 0.34545985198563106\n",
            "Loss in iteration no. 53259 ==> 0.34545893305349035\n",
            "Loss in iteration no. 53260 ==> 0.3454580141532774\n",
            "Loss in iteration no. 53261 ==> 0.3454570952849907\n",
            "Loss in iteration no. 53262 ==> 0.3454561764486286\n",
            "Loss in iteration no. 53263 ==> 0.34545525764418955\n",
            "Loss in iteration no. 53264 ==> 0.34545433887167215\n",
            "Loss in iteration no. 53265 ==> 0.3454534201310748\n",
            "Loss in iteration no. 53266 ==> 0.3454525014223958\n",
            "Loss in iteration no. 53267 ==> 0.3454515827456339\n",
            "Loss in iteration no. 53268 ==> 0.3454506641007874\n",
            "Loss in iteration no. 53269 ==> 0.3454497454878548\n",
            "Loss in iteration no. 53270 ==> 0.34544882690683454\n",
            "Loss in iteration no. 53271 ==> 0.34544790835772515\n",
            "Loss in iteration no. 53272 ==> 0.345446989840525\n",
            "Loss in iteration no. 53273 ==> 0.3454460713552327\n",
            "Loss in iteration no. 53274 ==> 0.3454451529018466\n",
            "Loss in iteration no. 53275 ==> 0.3454442344803651\n",
            "Loss in iteration no. 53276 ==> 0.3454433160907868\n",
            "Loss in iteration no. 53277 ==> 0.34544239773311014\n",
            "Loss in iteration no. 53278 ==> 0.3454414794073335\n",
            "Loss in iteration no. 53279 ==> 0.34544056111345545\n",
            "Loss in iteration no. 53280 ==> 0.34543964285147444\n",
            "Loss in iteration no. 53281 ==> 0.3454387246213889\n",
            "Loss in iteration no. 53282 ==> 0.3454378064231973\n",
            "Loss in iteration no. 53283 ==> 0.34543688825689817\n",
            "Loss in iteration no. 53284 ==> 0.3454359701224898\n",
            "Loss in iteration no. 53285 ==> 0.3454350520199709\n",
            "Loss in iteration no. 53286 ==> 0.34543413394933964\n",
            "Loss in iteration no. 53287 ==> 0.34543321591059484\n",
            "Loss in iteration no. 53288 ==> 0.34543229790373475\n",
            "Loss in iteration no. 53289 ==> 0.34543137992875783\n",
            "Loss in iteration no. 53290 ==> 0.34543046198566263\n",
            "Loss in iteration no. 53291 ==> 0.3454295440744475\n",
            "Loss in iteration no. 53292 ==> 0.34542862619511105\n",
            "Loss in iteration no. 53293 ==> 0.3454277083476517\n",
            "Loss in iteration no. 53294 ==> 0.3454267905320678\n",
            "Loss in iteration no. 53295 ==> 0.34542587274835806\n",
            "Loss in iteration no. 53296 ==> 0.3454249549965207\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loss in iteration no. 116281 ==> 0.31879780789824713\n",
            "Loss in iteration no. 116282 ==> 0.3187976259045495\n",
            "Loss in iteration no. 116283 ==> 0.31879744391448844\n",
            "Loss in iteration no. 116284 ==> 0.3187972619280637\n",
            "Loss in iteration no. 116285 ==> 0.31879707994527506\n",
            "Loss in iteration no. 116286 ==> 0.31879689796612265\n",
            "Loss in iteration no. 116287 ==> 0.31879671599060627\n",
            "Loss in iteration no. 116288 ==> 0.31879653401872593\n",
            "Loss in iteration no. 116289 ==> 0.31879635205048135\n",
            "Loss in iteration no. 116290 ==> 0.3187961700858726\n",
            "Loss in iteration no. 116291 ==> 0.31879598812489957\n",
            "Loss in iteration no. 116292 ==> 0.31879580616756215\n",
            "Loss in iteration no. 116293 ==> 0.3187956242138601\n",
            "Loss in iteration no. 116294 ==> 0.3187954422637935\n",
            "Loss in iteration no. 116295 ==> 0.3187952603173623\n",
            "Loss in iteration no. 116296 ==> 0.3187950783745661\n",
            "Loss in iteration no. 116297 ==> 0.3187948964354052\n",
            "Loss in iteration no. 116298 ==> 0.31879471449987923\n",
            "Loss in iteration no. 116299 ==> 0.31879453256798823\n",
            "Loss in iteration no. 116300 ==> 0.31879435063973205\n",
            "Loss in iteration no. 116301 ==> 0.3187941687151106\n",
            "Loss in iteration no. 116302 ==> 0.3187939867941239\n",
            "Loss in iteration no. 116303 ==> 0.31879380487677167\n",
            "Loss in iteration no. 116304 ==> 0.31879362296305386\n",
            "Loss in iteration no. 116305 ==> 0.3187934410529704\n",
            "Loss in iteration no. 116306 ==> 0.3187932591465213\n",
            "Loss in iteration no. 116307 ==> 0.31879307724370637\n",
            "Loss in iteration no. 116308 ==> 0.3187928953445255\n",
            "Loss in iteration no. 116309 ==> 0.31879271344897875\n",
            "Loss in iteration no. 116310 ==> 0.31879253155706566\n",
            "Loss in iteration no. 116311 ==> 0.31879234966878645\n",
            "Loss in iteration no. 116312 ==> 0.3187921677841411\n",
            "Loss in iteration no. 116313 ==> 0.31879198590312924\n",
            "Loss in iteration no. 116314 ==> 0.31879180402575086\n",
            "Loss in iteration no. 116315 ==> 0.31879162215200596\n",
            "Loss in iteration no. 116316 ==> 0.3187914402818944\n",
            "Loss in iteration no. 116317 ==> 0.3187912584154161\n",
            "Loss in iteration no. 116318 ==> 0.31879107655257105\n",
            "Loss in iteration no. 116319 ==> 0.31879089469335886\n",
            "Loss in iteration no. 116320 ==> 0.3187907128377796\n",
            "Loss in iteration no. 116321 ==> 0.31879053098583343\n",
            "Loss in iteration no. 116322 ==> 0.3187903491375199\n",
            "Loss in iteration no. 116323 ==> 0.318790167292839\n",
            "Loss in iteration no. 116324 ==> 0.31878998545179066\n",
            "Loss in iteration no. 116325 ==> 0.3187898036143749\n",
            "Loss in iteration no. 116326 ==> 0.3187896217805915\n",
            "Loss in iteration no. 116327 ==> 0.31878943995044046\n",
            "Loss in iteration no. 116328 ==> 0.31878925812392156\n",
            "Loss in iteration no. 116329 ==> 0.31878907630103487\n",
            "Loss in iteration no. 116330 ==> 0.3187888944817801\n",
            "Loss in iteration no. 116331 ==> 0.31878871266615727\n",
            "Loss in iteration no. 116332 ==> 0.3187885308541663\n",
            "Loss in iteration no. 116333 ==> 0.31878834904580705\n",
            "Loss in iteration no. 116334 ==> 0.3187881672410795\n",
            "Loss in iteration no. 116335 ==> 0.31878798543998355\n",
            "Loss in iteration no. 116336 ==> 0.318787803642519\n",
            "Loss in iteration no. 116337 ==> 0.31878762184868575\n",
            "Loss in iteration no. 116338 ==> 0.31878744005848375\n",
            "Loss in iteration no. 116339 ==> 0.3187872582719129\n",
            "Loss in iteration no. 116340 ==> 0.31878707648897336\n",
            "Loss in iteration no. 116341 ==> 0.3187868947096646\n",
            "Loss in iteration no. 116342 ==> 0.31878671293398686\n",
            "Loss in iteration no. 116343 ==> 0.31878653116193983\n",
            "Loss in iteration no. 116344 ==> 0.3187863493935235\n",
            "Loss in iteration no. 116345 ==> 0.31878616762873774\n",
            "Loss in iteration no. 116346 ==> 0.3187859858675827\n",
            "Loss in iteration no. 116347 ==> 0.3187858041100581\n",
            "Loss in iteration no. 116348 ==> 0.31878562235616364\n",
            "Loss in iteration no. 116349 ==> 0.31878544060589953\n",
            "Loss in iteration no. 116350 ==> 0.3187852588592655\n",
            "Loss in iteration no. 116351 ==> 0.3187850771162615\n",
            "Loss in iteration no. 116352 ==> 0.3187848953768875\n",
            "Loss in iteration no. 116353 ==> 0.31878471364114336\n",
            "Loss in iteration no. 116354 ==> 0.318784531909029\n",
            "Loss in iteration no. 116355 ==> 0.3187843501805444\n",
            "Loss in iteration no. 116356 ==> 0.31878416845568924\n",
            "Loss in iteration no. 116357 ==> 0.31878398673446356\n",
            "Loss in iteration no. 116358 ==> 0.3187838050168673\n",
            "Loss in iteration no. 116359 ==> 0.31878362330290044\n",
            "Loss in iteration no. 116360 ==> 0.3187834415925628\n",
            "Loss in iteration no. 116361 ==> 0.3187832598858541\n",
            "Loss in iteration no. 116362 ==> 0.31878307818277457\n",
            "Loss in iteration no. 116363 ==> 0.31878289648332386\n",
            "Loss in iteration no. 116364 ==> 0.3187827147875021\n",
            "Loss in iteration no. 116365 ==> 0.318782533095309\n",
            "Loss in iteration no. 116366 ==> 0.3187823514067446\n",
            "Loss in iteration no. 116367 ==> 0.31878216972180884\n",
            "Loss in iteration no. 116368 ==> 0.31878198804050134\n",
            "Loss in iteration no. 116369 ==> 0.3187818063628224\n",
            "Loss in iteration no. 116370 ==> 0.31878162468877164\n",
            "Loss in iteration no. 116371 ==> 0.31878144301834893\n",
            "Loss in iteration no. 116372 ==> 0.31878126135155443\n",
            "Loss in iteration no. 116373 ==> 0.31878107968838804\n",
            "Loss in iteration no. 116374 ==> 0.31878089802884946\n",
            "Loss in iteration no. 116375 ==> 0.3187807163729386\n",
            "Loss in iteration no. 116376 ==> 0.3187805347206555\n",
            "Loss in iteration no. 116377 ==> 0.318780353072\n",
            "Loss in iteration no. 116378 ==> 0.31878017142697196\n",
            "Loss in iteration no. 116379 ==> 0.31877998978557137\n",
            "Loss in iteration no. 116380 ==> 0.3187798081477981\n",
            "Loss in iteration no. 116381 ==> 0.31877962651365216\n",
            "Loss in iteration no. 116382 ==> 0.31877944488313337\n",
            "Loss in iteration no. 116383 ==> 0.3187792632562418\n",
            "Loss in iteration no. 116384 ==> 0.3187790816329768\n",
            "Loss in iteration no. 116385 ==> 0.3187789000133389\n",
            "Loss in iteration no. 116386 ==> 0.31877871839732785\n",
            "Loss in iteration no. 116387 ==> 0.31877853678494333\n",
            "Loss in iteration no. 116388 ==> 0.3187783551761854\n",
            "Loss in iteration no. 116389 ==> 0.3187781735710541\n",
            "Loss in iteration no. 116390 ==> 0.31877799196954903\n",
            "Loss in iteration no. 116391 ==> 0.31877781037167036\n",
            "Loss in iteration no. 116392 ==> 0.3187776287774177\n",
            "Loss in iteration no. 116393 ==> 0.3187774471867916\n",
            "Loss in iteration no. 116394 ==> 0.31877726559979114\n",
            "Loss in iteration no. 116395 ==> 0.3187770840164167\n",
            "Loss in iteration no. 116396 ==> 0.3187769024366682\n",
            "Loss in iteration no. 116397 ==> 0.3187767208605454\n",
            "Loss in iteration no. 116398 ==> 0.3187765392880482\n",
            "Loss in iteration no. 116399 ==> 0.3187763577191767\n",
            "Loss in iteration no. 116400 ==> 0.31877617615393045\n",
            "Loss in iteration no. 116401 ==> 0.31877599459230976\n",
            "Loss in iteration no. 116402 ==> 0.3187758130343141\n",
            "Loss in iteration no. 116403 ==> 0.3187756314799438\n",
            "Loss in iteration no. 116404 ==> 0.31877544992919854\n",
            "Loss in iteration no. 116405 ==> 0.31877526838207837\n",
            "Loss in iteration no. 116406 ==> 0.318775086838583\n",
            "Loss in iteration no. 116407 ==> 0.3187749052987126\n",
            "Loss in iteration no. 116408 ==> 0.3187747237624667\n",
            "Loss in iteration no. 116409 ==> 0.3187745422298455\n",
            "Loss in iteration no. 116410 ==> 0.3187743607008489\n",
            "Loss in iteration no. 116411 ==> 0.3187741791754766\n",
            "Loss in iteration no. 116412 ==> 0.3187739976537287\n",
            "Loss in iteration no. 116413 ==> 0.31877381613560507\n",
            "Loss in iteration no. 116414 ==> 0.31877363462110564\n",
            "Loss in iteration no. 116415 ==> 0.31877345311023025\n",
            "Loss in iteration no. 116416 ==> 0.3187732716029787\n",
            "Loss in iteration no. 116417 ==> 0.31877309009935123\n",
            "Loss in iteration no. 116418 ==> 0.31877290859934737\n",
            "Loss in iteration no. 116419 ==> 0.31877272710296717\n",
            "Loss in iteration no. 116420 ==> 0.3187725456102107\n",
            "Loss in iteration no. 116421 ==> 0.3187723641210778\n",
            "Loss in iteration no. 116422 ==> 0.3187721826355681\n",
            "Loss in iteration no. 116423 ==> 0.31877200115368176\n",
            "Loss in iteration no. 116424 ==> 0.3187718196754187\n",
            "Loss in iteration no. 116425 ==> 0.31877163820077864\n",
            "Loss in iteration no. 116426 ==> 0.3187714567297617\n",
            "Loss in iteration no. 116427 ==> 0.3187712752623678\n",
            "Loss in iteration no. 116428 ==> 0.3187710937985966\n",
            "Loss in iteration no. 116429 ==> 0.3187709123384482\n",
            "Loss in iteration no. 116430 ==> 0.3187707308819226\n",
            "Loss in iteration no. 116431 ==> 0.31877054942901933\n",
            "Loss in iteration no. 116432 ==> 0.31877036797973873\n",
            "Loss in iteration no. 116433 ==> 0.31877018653408024\n",
            "Loss in iteration no. 116434 ==> 0.3187700050920442\n",
            "Loss in iteration no. 116435 ==> 0.3187698236536304\n",
            "Loss in iteration no. 116436 ==> 0.3187696422188386\n",
            "Loss in iteration no. 116437 ==> 0.3187694607876688\n",
            "Loss in iteration no. 116438 ==> 0.31876927936012095\n",
            "Loss in iteration no. 116439 ==> 0.318769097936195\n",
            "Loss in iteration no. 116440 ==> 0.31876891651589073\n",
            "Loss in iteration no. 116441 ==> 0.318768735099208\n",
            "Loss in iteration no. 116442 ==> 0.31876855368614676\n",
            "Loss in iteration no. 116443 ==> 0.31876837227670723\n",
            "Loss in iteration no. 116444 ==> 0.31876819087088887\n",
            "Loss in iteration no. 116445 ==> 0.3187680094686917\n",
            "Loss in iteration no. 116446 ==> 0.3187678280701157\n",
            "Loss in iteration no. 116447 ==> 0.31876764667516105\n",
            "Loss in iteration no. 116448 ==> 0.31876746528382705\n",
            "Loss in iteration no. 116449 ==> 0.3187672838961141\n",
            "Loss in iteration no. 116450 ==> 0.3187671025120218\n",
            "Loss in iteration no. 116451 ==> 0.31876692113155025\n",
            "Loss in iteration no. 116452 ==> 0.3187667397546994\n",
            "Loss in iteration no. 116453 ==> 0.31876655838146895\n",
            "Loss in iteration no. 116454 ==> 0.31876637701185895\n",
            "Loss in iteration no. 116455 ==> 0.3187661956458693\n",
            "Loss in iteration no. 116456 ==> 0.3187660142834998\n",
            "Loss in iteration no. 116457 ==> 0.31876583292475064\n",
            "Loss in iteration no. 116458 ==> 0.3187656515696214\n",
            "Loss in iteration no. 116459 ==> 0.318765470218112\n",
            "Loss in iteration no. 116460 ==> 0.31876528887022254\n",
            "Loss in iteration no. 116461 ==> 0.31876510752595283\n",
            "Loss in iteration no. 116462 ==> 0.3187649261853027\n",
            "Loss in iteration no. 116463 ==> 0.31876474484827233\n",
            "Loss in iteration no. 116464 ==> 0.31876456351486143\n",
            "Loss in iteration no. 116465 ==> 0.31876438218506975\n",
            "Loss in iteration no. 116466 ==> 0.31876420085889756\n",
            "Loss in iteration no. 116467 ==> 0.3187640195363444\n",
            "Loss in iteration no. 116468 ==> 0.31876383821741044\n",
            "Loss in iteration no. 116469 ==> 0.31876365690209546\n",
            "Loss in iteration no. 116470 ==> 0.31876347559039947\n",
            "Loss in iteration no. 116471 ==> 0.31876329428232214\n",
            "Loss in iteration no. 116472 ==> 0.3187631129778636\n",
            "Loss in iteration no. 116473 ==> 0.3187629316770238\n",
            "Loss in iteration no. 116474 ==> 0.3187627503798026\n",
            "Loss in iteration no. 116475 ==> 0.3187625690861996\n",
            "Loss in iteration no. 116476 ==> 0.3187623877962152\n",
            "Loss in iteration no. 116477 ==> 0.31876220650984904\n",
            "Loss in iteration no. 116478 ==> 0.3187620252271009\n",
            "Loss in iteration no. 116479 ==> 0.31876184394797097\n",
            "Loss in iteration no. 116480 ==> 0.31876166267245903\n",
            "Loss in iteration no. 116481 ==> 0.3187614814005649\n",
            "Loss in iteration no. 116482 ==> 0.3187613001322887\n",
            "Loss in iteration no. 116483 ==> 0.3187611188676302\n",
            "Loss in iteration no. 116484 ==> 0.31876093760658925\n",
            "Loss in iteration no. 116485 ==> 0.3187607563491656\n",
            "Loss in iteration no. 116486 ==> 0.3187605750953597\n",
            "Loss in iteration no. 116487 ==> 0.318760393845171\n",
            "Loss in iteration no. 116488 ==> 0.31876021259859955\n",
            "Loss in iteration no. 116489 ==> 0.31876003135564523\n",
            "Loss in iteration no. 116490 ==> 0.318759850116308\n",
            "Loss in iteration no. 116491 ==> 0.3187596688805878\n",
            "Loss in iteration no. 116492 ==> 0.3187594876484844\n",
            "Loss in iteration no. 116493 ==> 0.3187593064199978\n",
            "Loss in iteration no. 116494 ==> 0.3187591251951278\n",
            "Loss in iteration no. 116495 ==> 0.3187589439738744\n",
            "Loss in iteration no. 116496 ==> 0.3187587627562376\n",
            "Loss in iteration no. 116497 ==> 0.3187585815422171\n",
            "Loss in iteration no. 116498 ==> 0.318758400331813\n",
            "Loss in iteration no. 116499 ==> 0.31875821912502506\n",
            "Loss in iteration no. 116500 ==> 0.31875803792185325\n",
            "Loss in iteration no. 116501 ==> 0.31875785672229745\n",
            "Loss in iteration no. 116502 ==> 0.31875767552635764\n",
            "Loss in iteration no. 116503 ==> 0.3187574943340336\n",
            "Loss in iteration no. 116504 ==> 0.3187573131453254\n",
            "Loss in iteration no. 116505 ==> 0.3187571319602327\n",
            "Loss in iteration no. 116506 ==> 0.3187569507787557\n",
            "Loss in iteration no. 116507 ==> 0.31875676960089405\n",
            "Loss in iteration no. 116508 ==> 0.31875658842664784\n",
            "Loss in iteration no. 116509 ==> 0.31875640725601706\n",
            "Loss in iteration no. 116510 ==> 0.3187562260890013\n",
            "Loss in iteration no. 116511 ==> 0.3187560449256007\n",
            "Loss in iteration no. 116512 ==> 0.3187558637658151\n",
            "Loss in iteration no. 116513 ==> 0.31875568260964426\n",
            "Loss in iteration no. 116514 ==> 0.3187555014570885\n",
            "Loss in iteration no. 116515 ==> 0.31875532030814724\n",
            "Loss in iteration no. 116516 ==> 0.3187551391628206\n",
            "Loss in iteration no. 116517 ==> 0.3187549580211088\n",
            "Loss in iteration no. 116518 ==> 0.3187547768830112\n",
            "Loss in iteration no. 116519 ==> 0.318754595748528\n",
            "Loss in iteration no. 116520 ==> 0.31875441461765885\n",
            "Loss in iteration no. 116521 ==> 0.31875423349040427\n",
            "Loss in iteration no. 116522 ==> 0.3187540523667634\n",
            "Loss in iteration no. 116523 ==> 0.3187538712467366\n",
            "Loss in iteration no. 116524 ==> 0.3187536901303238\n",
            "Loss in iteration no. 116525 ==> 0.3187535090175248\n",
            "Loss in iteration no. 116526 ==> 0.3187533279083394\n",
            "Loss in iteration no. 116527 ==> 0.3187531468027676\n",
            "Loss in iteration no. 116528 ==> 0.3187529657008094\n",
            "Loss in iteration no. 116529 ==> 0.3187527846024645\n",
            "Loss in iteration no. 116530 ==> 0.31875260350773293\n",
            "Loss in iteration no. 116531 ==> 0.3187524224166146\n",
            "Loss in iteration no. 116532 ==> 0.31875224132910956\n",
            "Loss in iteration no. 116533 ==> 0.3187520602452175\n",
            "Loss in iteration no. 116534 ==> 0.31875187916493836\n",
            "Loss in iteration no. 116535 ==> 0.318751698088272\n",
            "Loss in iteration no. 116536 ==> 0.3187515170152186\n",
            "Loss in iteration no. 116537 ==> 0.3187513359457777\n",
            "Loss in iteration no. 116538 ==> 0.31875115487994937\n",
            "Loss in iteration no. 116539 ==> 0.3187509738177336\n",
            "Loss in iteration no. 116540 ==> 0.31875079275913026\n",
            "Loss in iteration no. 116541 ==> 0.3187506117041391\n",
            "Loss in iteration no. 116542 ==> 0.31875043065276026\n",
            "Loss in iteration no. 116543 ==> 0.3187502496049935\n",
            "Loss in iteration no. 116544 ==> 0.3187500685608388\n",
            "Loss in iteration no. 116545 ==> 0.3187498875202958\n",
            "Loss in iteration no. 116546 ==> 0.3187497064833649\n",
            "Loss in iteration no. 116547 ==> 0.31874952545004565\n",
            "Loss in iteration no. 116548 ==> 0.3187493444203381\n",
            "Loss in iteration no. 116549 ==> 0.31874916339424214\n",
            "Loss in iteration no. 116550 ==> 0.3187489823717575\n",
            "Loss in iteration no. 116551 ==> 0.3187488013528844\n",
            "Loss in iteration no. 116552 ==> 0.3187486203376224\n",
            "Loss in iteration no. 116553 ==> 0.3187484393259715\n",
            "Loss in iteration no. 116554 ==> 0.3187482583179321\n",
            "Loss in iteration no. 116555 ==> 0.31874807731350335\n",
            "Loss in iteration no. 116556 ==> 0.3187478963126856\n",
            "Loss in iteration no. 116557 ==> 0.31874771531547863\n",
            "Loss in iteration no. 116558 ==> 0.31874753432188235\n",
            "Loss in iteration no. 116559 ==> 0.3187473533318967\n",
            "Loss in iteration no. 116560 ==> 0.31874717234552163\n",
            "Loss in iteration no. 116561 ==> 0.318746991362757\n",
            "Loss in iteration no. 116562 ==> 0.31874681038360275\n",
            "Loss in iteration no. 116563 ==> 0.3187466294080588\n",
            "Loss in iteration no. 116564 ==> 0.31874644843612493\n",
            "Loss in iteration no. 116565 ==> 0.3187462674678011\n",
            "Loss in iteration no. 116566 ==> 0.31874608650308717\n",
            "Loss in iteration no. 116567 ==> 0.31874590554198334\n",
            "Loss in iteration no. 116568 ==> 0.3187457245844891\n",
            "Loss in iteration no. 116569 ==> 0.3187455436306046\n",
            "Loss in iteration no. 116570 ==> 0.31874536268032977\n",
            "Loss in iteration no. 116571 ==> 0.3187451817336644\n",
            "Loss in iteration no. 116572 ==> 0.3187450007906084\n",
            "Loss in iteration no. 116573 ==> 0.3187448198511619\n",
            "Loss in iteration no. 116574 ==> 0.31874463891532434\n",
            "Loss in iteration no. 116575 ==> 0.3187444579830961\n",
            "Loss in iteration no. 116576 ==> 0.31874427705447683\n",
            "Loss in iteration no. 116577 ==> 0.31874409612946664\n",
            "Loss in iteration no. 116578 ==> 0.3187439152080651\n",
            "Loss in iteration no. 116579 ==> 0.3187437342902726\n",
            "Loss in iteration no. 116580 ==> 0.3187435533760885\n",
            "Loss in iteration no. 116581 ==> 0.3187433724655131\n",
            "Loss in iteration no. 116582 ==> 0.3187431915585462\n",
            "Loss in iteration no. 116583 ==> 0.3187430106551878\n",
            "Loss in iteration no. 116584 ==> 0.3187428297554374\n",
            "Loss in iteration no. 116585 ==> 0.31874264885929543\n",
            "Loss in iteration no. 116586 ==> 0.31874246796676153\n",
            "Loss in iteration no. 116587 ==> 0.3187422870778356\n",
            "Loss in iteration no. 116588 ==> 0.31874210619251764\n",
            "Loss in iteration no. 116589 ==> 0.3187419253108074\n",
            "Loss in iteration no. 116590 ==> 0.318741744432705\n",
            "Loss in iteration no. 116591 ==> 0.3187415635582104\n",
            "Loss in iteration no. 116592 ==> 0.3187413826873231\n",
            "Loss in iteration no. 116593 ==> 0.3187412018200435\n",
            "Loss in iteration no. 116594 ==> 0.3187410209563711\n",
            "Loss in iteration no. 116595 ==> 0.31874084009630593\n",
            "Loss in iteration no. 116596 ==> 0.31874065923984807\n",
            "Loss in iteration no. 116597 ==> 0.31874047838699726\n",
            "Loss in iteration no. 116598 ==> 0.3187402975377533\n",
            "Loss in iteration no. 116599 ==> 0.3187401166921164\n",
            "Loss in iteration no. 116600 ==> 0.31873993585008636\n",
            "Loss in iteration no. 116601 ==> 0.318739755011663\n",
            "Loss in iteration no. 116602 ==> 0.31873957417684634\n",
            "Loss in iteration no. 116603 ==> 0.318739393345636\n",
            "Loss in iteration no. 116604 ==> 0.31873921251803217\n",
            "Loss in iteration no. 116605 ==> 0.3187390316940347\n",
            "Loss in iteration no. 116606 ==> 0.3187388508736436\n",
            "Loss in iteration no. 116607 ==> 0.31873867005685846\n",
            "Loss in iteration no. 116608 ==> 0.31873848924367953\n",
            "Loss in iteration no. 116609 ==> 0.3187383084341065\n",
            "Loss in iteration no. 116610 ==> 0.3187381276281394\n",
            "Loss in iteration no. 116611 ==> 0.31873794682577816\n",
            "Loss in iteration no. 116612 ==> 0.3187377660270224\n",
            "Loss in iteration no. 116613 ==> 0.31873758523187246\n",
            "Loss in iteration no. 116614 ==> 0.3187374044403279\n",
            "Loss in iteration no. 116615 ==> 0.3187372236523887\n",
            "Loss in iteration no. 116616 ==> 0.31873704286805504\n",
            "Loss in iteration no. 116617 ==> 0.31873686208732643\n",
            "Loss in iteration no. 116618 ==> 0.3187366813102031\n",
            "Loss in iteration no. 116619 ==> 0.3187365005366847\n",
            "Loss in iteration no. 116620 ==> 0.31873631976677125\n",
            "Loss in iteration no. 116621 ==> 0.3187361390004627\n",
            "Loss in iteration no. 116622 ==> 0.3187359582377589\n",
            "Loss in iteration no. 116623 ==> 0.31873577747865983\n",
            "Loss in iteration no. 116624 ==> 0.3187355967231652\n",
            "Loss in iteration no. 116625 ==> 0.31873541597127514\n",
            "Loss in iteration no. 116626 ==> 0.3187352352229896\n",
            "Loss in iteration no. 116627 ==> 0.3187350544783082\n",
            "Loss in iteration no. 116628 ==> 0.3187348737372311\n",
            "Loss in iteration no. 116629 ==> 0.31873469299975815\n",
            "Loss in iteration no. 116630 ==> 0.3187345122658891\n",
            "Loss in iteration no. 116631 ==> 0.318734331535624\n",
            "Loss in iteration no. 116632 ==> 0.3187341508089627\n",
            "Loss in iteration no. 116633 ==> 0.31873397008590526\n",
            "Loss in iteration no. 116634 ==> 0.3187337893664513\n",
            "Loss in iteration no. 116635 ==> 0.31873360865060113\n",
            "Loss in iteration no. 116636 ==> 0.3187334279383542\n",
            "Loss in iteration no. 116637 ==> 0.31873324722971086\n",
            "Loss in iteration no. 116638 ==> 0.31873306652467065\n",
            "Loss in iteration no. 116639 ==> 0.3187328858232337\n",
            "Loss in iteration no. 116640 ==> 0.31873270512539975\n",
            "Loss in iteration no. 116641 ==> 0.318732524431169\n",
            "Loss in iteration no. 116642 ==> 0.3187323437405409\n",
            "Loss in iteration no. 116643 ==> 0.3187321630535158\n",
            "Loss in iteration no. 116644 ==> 0.3187319823700933\n",
            "Loss in iteration no. 116645 ==> 0.31873180169027354\n",
            "Loss in iteration no. 116646 ==> 0.31873162101405633\n",
            "Loss in iteration no. 116647 ==> 0.3187314403414415\n",
            "Loss in iteration no. 116648 ==> 0.3187312596724291\n",
            "Loss in iteration no. 116649 ==> 0.31873107900701875\n",
            "Loss in iteration no. 116650 ==> 0.31873089834521073\n",
            "Loss in iteration no. 116651 ==> 0.3187307176870048\n",
            "Loss in iteration no. 116652 ==> 0.31873053703240084\n",
            "Loss in iteration no. 116653 ==> 0.3187303563813987\n",
            "Loss in iteration no. 116654 ==> 0.3187301757339983\n",
            "Loss in iteration no. 116655 ==> 0.3187299950901999\n",
            "Loss in iteration no. 116656 ==> 0.3187298144500028\n",
            "Loss in iteration no. 116657 ==> 0.31872963381340735\n",
            "Loss in iteration no. 116658 ==> 0.3187294531804133\n",
            "Loss in iteration no. 116659 ==> 0.31872927255102057\n",
            "Loss in iteration no. 116660 ==> 0.318729091925229\n",
            "Loss in iteration no. 116661 ==> 0.31872891130303876\n",
            "Loss in iteration no. 116662 ==> 0.3187287306844495\n",
            "Loss in iteration no. 116663 ==> 0.3187285500694611\n",
            "Loss in iteration no. 116664 ==> 0.3187283694580737\n",
            "Loss in iteration no. 116665 ==> 0.318728188850287\n",
            "Loss in iteration no. 116666 ==> 0.318728008246101\n",
            "Loss in iteration no. 116667 ==> 0.3187278276455155\n",
            "Loss in iteration no. 116668 ==> 0.3187276470485307\n",
            "Loss in iteration no. 116669 ==> 0.31872746645514616\n",
            "Loss in iteration no. 116670 ==> 0.318727285865362\n",
            "Loss in iteration no. 116671 ==> 0.31872710527917797\n",
            "Loss in iteration no. 116672 ==> 0.318726924696594\n",
            "Loss in iteration no. 116673 ==> 0.31872674411761026\n",
            "Loss in iteration no. 116674 ==> 0.3187265635422263\n",
            "Loss in iteration no. 116675 ==> 0.3187263829704423\n",
            "Loss in iteration no. 116676 ==> 0.3187262024022581\n",
            "Loss in iteration no. 116677 ==> 0.3187260218376734\n",
            "Loss in iteration no. 116678 ==> 0.31872584127668824\n",
            "Loss in iteration no. 116679 ==> 0.31872566071930275\n",
            "Loss in iteration no. 116680 ==> 0.31872548016551655\n",
            "Loss in iteration no. 116681 ==> 0.3187252996153297\n",
            "Loss in iteration no. 116682 ==> 0.31872511906874196\n",
            "Loss in iteration no. 116683 ==> 0.31872493852575334\n",
            "Loss in iteration no. 116684 ==> 0.3187247579863637\n",
            "Loss in iteration no. 116685 ==> 0.318724577450573\n",
            "Loss in iteration no. 116686 ==> 0.31872439691838134\n",
            "Loss in iteration no. 116687 ==> 0.3187242163897882\n",
            "Loss in iteration no. 116688 ==> 0.31872403586479375\n",
            "Loss in iteration no. 116689 ==> 0.31872385534339776\n",
            "Loss in iteration no. 116690 ==> 0.31872367482560043\n",
            "Loss in iteration no. 116691 ==> 0.3187234943114012\n",
            "Loss in iteration no. 116692 ==> 0.3187233138008003\n",
            "Loss in iteration no. 116693 ==> 0.3187231332937978\n",
            "Loss in iteration no. 116694 ==> 0.3187229527903933\n",
            "Loss in iteration no. 116695 ==> 0.3187227722905867\n",
            "Loss in iteration no. 116696 ==> 0.318722591794378\n",
            "Loss in iteration no. 116697 ==> 0.3187224113017671\n",
            "Loss in iteration no. 116698 ==> 0.3187222308127539\n",
            "Loss in iteration no. 116699 ==> 0.3187220503273384\n",
            "Loss in iteration no. 116700 ==> 0.31872186984552037\n",
            "Loss in iteration no. 116701 ==> 0.31872168936729994\n",
            "Loss in iteration no. 116702 ==> 0.31872150889267664\n",
            "Loss in iteration no. 116703 ==> 0.31872132842165063\n",
            "Loss in iteration no. 116704 ==> 0.31872114795422185\n",
            "Loss in iteration no. 116705 ==> 0.31872096749039014\n",
            "Loss in iteration no. 116706 ==> 0.3187207870301553\n",
            "Loss in iteration no. 116707 ==> 0.3187206065735175\n",
            "Loss in iteration no. 116708 ==> 0.3187204261204764\n",
            "Loss in iteration no. 116709 ==> 0.31872024567103197\n",
            "Loss in iteration no. 116710 ==> 0.31872006522518426\n",
            "Loss in iteration no. 116711 ==> 0.318719884782933\n",
            "Loss in iteration no. 116712 ==> 0.31871970434427804\n",
            "Loss in iteration no. 116713 ==> 0.3187195239092195\n",
            "Loss in iteration no. 116714 ==> 0.31871934347775716\n",
            "Loss in iteration no. 116715 ==> 0.318719163049891\n",
            "Loss in iteration no. 116716 ==> 0.31871898262562104\n",
            "Loss in iteration no. 116717 ==> 0.31871880220494664\n",
            "Loss in iteration no. 116718 ==> 0.3187186217878684\n",
            "Loss in iteration no. 116719 ==> 0.31871844137438593\n",
            "Loss in iteration no. 116720 ==> 0.31871826096449907\n",
            "Loss in iteration no. 116721 ==> 0.3187180805582077\n",
            "Loss in iteration no. 116722 ==> 0.31871790015551194\n",
            "Loss in iteration no. 116723 ==> 0.3187177197564116\n",
            "Loss in iteration no. 116724 ==> 0.3187175393609066\n",
            "Loss in iteration no. 116725 ==> 0.3187173589689966\n",
            "Loss in iteration no. 116726 ==> 0.31871717858068194\n",
            "Loss in iteration no. 116727 ==> 0.3187169981959623\n",
            "Loss in iteration no. 116728 ==> 0.3187168178148374\n",
            "Loss in iteration no. 116729 ==> 0.31871663743730755\n",
            "Loss in iteration no. 116730 ==> 0.3187164570633723\n",
            "Loss in iteration no. 116731 ==> 0.3187162766930319\n",
            "Loss in iteration no. 116732 ==> 0.3187160963262859\n",
            "Loss in iteration no. 116733 ==> 0.3187159159631343\n",
            "Loss in iteration no. 116734 ==> 0.3187157356035773\n",
            "Loss in iteration no. 116735 ==> 0.3187155552476145\n",
            "Loss in iteration no. 116736 ==> 0.3187153748952459\n",
            "Loss in iteration no. 116737 ==> 0.3187151945464713\n",
            "Loss in iteration no. 116738 ==> 0.31871501420129084\n",
            "Loss in iteration no. 116739 ==> 0.3187148338597043\n",
            "Loss in iteration no. 116740 ==> 0.31871465352171147\n",
            "Loss in iteration no. 116741 ==> 0.31871447318731244\n",
            "Loss in iteration no. 116742 ==> 0.3187142928565071\n",
            "Loss in iteration no. 116743 ==> 0.31871411252929527\n",
            "Loss in iteration no. 116744 ==> 0.31871393220567684\n",
            "Loss in iteration no. 116745 ==> 0.3187137518856519\n",
            "Loss in iteration no. 116746 ==> 0.3187135715692201\n",
            "Loss in iteration no. 116747 ==> 0.3187133912563815\n",
            "Loss in iteration no. 116748 ==> 0.3187132109471361\n",
            "Loss in iteration no. 116749 ==> 0.3187130306414836\n",
            "Loss in iteration no. 116750 ==> 0.318712850339424\n",
            "Loss in iteration no. 116751 ==> 0.3187126700409573\n",
            "Loss in iteration no. 116752 ==> 0.3187124897460832\n",
            "Loss in iteration no. 116753 ==> 0.3187123094548016\n",
            "Loss in iteration no. 116754 ==> 0.3187121291671128\n",
            "Loss in iteration no. 116755 ==> 0.31871194888301624\n",
            "Loss in iteration no. 116756 ==> 0.3187117686025122\n",
            "Loss in iteration no. 116757 ==> 0.3187115883256003\n",
            "Loss in iteration no. 116758 ==> 0.31871140805228054\n",
            "Loss in iteration no. 116759 ==> 0.31871122778255295\n",
            "Loss in iteration no. 116760 ==> 0.3187110475164173\n",
            "Loss in iteration no. 116761 ==> 0.3187108672538735\n",
            "Loss in iteration no. 116762 ==> 0.3187106869949215\n",
            "Loss in iteration no. 116763 ==> 0.3187105067395612\n",
            "Loss in iteration no. 116764 ==> 0.3187103264877925\n",
            "Loss in iteration no. 116765 ==> 0.3187101462396154\n",
            "Loss in iteration no. 116766 ==> 0.3187099659950296\n",
            "Loss in iteration no. 116767 ==> 0.31870978575403497\n",
            "Loss in iteration no. 116768 ==> 0.31870960551663186\n",
            "Loss in iteration no. 116769 ==> 0.3187094252828199\n",
            "Loss in iteration no. 116770 ==> 0.3187092450525989\n",
            "Loss in iteration no. 116771 ==> 0.31870906482596884\n",
            "Loss in iteration no. 116772 ==> 0.3187088846029297\n",
            "Loss in iteration no. 116773 ==> 0.31870870438348115\n",
            "Loss in iteration no. 116774 ==> 0.3187085241676235\n",
            "Loss in iteration no. 116775 ==> 0.31870834395535647\n",
            "Loss in iteration no. 116776 ==> 0.31870816374667976\n",
            "Loss in iteration no. 116777 ==> 0.3187079835415935\n",
            "Loss in iteration no. 116778 ==> 0.31870780334009763\n",
            "Loss in iteration no. 116779 ==> 0.31870762314219186\n",
            "Loss in iteration no. 116780 ==> 0.31870744294787623\n",
            "Loss in iteration no. 116781 ==> 0.3187072627571508\n",
            "Loss in iteration no. 116782 ==> 0.3187070825700151\n",
            "Loss in iteration no. 116783 ==> 0.31870690238646926\n",
            "Loss in iteration no. 116784 ==> 0.3187067222065134\n",
            "Loss in iteration no. 116785 ==> 0.3187065420301471\n",
            "Loss in iteration no. 116786 ==> 0.3187063618573703\n",
            "Loss in iteration no. 116787 ==> 0.31870618168818304\n",
            "Loss in iteration no. 116788 ==> 0.31870600152258516\n",
            "Loss in iteration no. 116789 ==> 0.31870582136057657\n",
            "Loss in iteration no. 116790 ==> 0.31870564120215716\n",
            "Loss in iteration no. 116791 ==> 0.3187054610473269\n",
            "Loss in iteration no. 116792 ==> 0.3187052808960856\n",
            "Loss in iteration no. 116793 ==> 0.3187051007484331\n",
            "Loss in iteration no. 116794 ==> 0.31870492060436967\n",
            "Loss in iteration no. 116795 ==> 0.3187047404638949\n",
            "Loss in iteration no. 116796 ==> 0.3187045603270089\n",
            "Loss in iteration no. 116797 ==> 0.31870438019371133\n",
            "Loss in iteration no. 116798 ==> 0.31870420006400224\n",
            "Loss in iteration no. 116799 ==> 0.31870401993788156\n",
            "Loss in iteration no. 116800 ==> 0.31870383981534917\n",
            "Loss in iteration no. 116801 ==> 0.3187036596964049\n",
            "Loss in iteration no. 116802 ==> 0.3187034795810486\n",
            "Loss in iteration no. 116803 ==> 0.3187032994692804\n",
            "Loss in iteration no. 116804 ==> 0.3187031193611002\n",
            "Loss in iteration no. 116805 ==> 0.31870293925650767\n",
            "Loss in iteration no. 116806 ==> 0.31870275915550295\n",
            "Loss in iteration no. 116807 ==> 0.31870257905808597\n",
            "Loss in iteration no. 116808 ==> 0.31870239896425634\n",
            "Loss in iteration no. 116809 ==> 0.31870221887401434\n",
            "Loss in iteration no. 116810 ==> 0.3187020387873596\n",
            "Loss in iteration no. 116811 ==> 0.31870185870429213\n",
            "Loss in iteration no. 116812 ==> 0.31870167862481175\n",
            "Loss in iteration no. 116813 ==> 0.3187014985489185\n",
            "Loss in iteration no. 116814 ==> 0.3187013184766123\n",
            "Loss in iteration no. 116815 ==> 0.3187011384078929\n",
            "Loss in iteration no. 116816 ==> 0.3187009583427605\n",
            "Loss in iteration no. 116817 ==> 0.3187007782812146\n",
            "Loss in iteration no. 116818 ==> 0.31870059822325536\n",
            "Loss in iteration no. 116819 ==> 0.3187004181688827\n",
            "Loss in iteration no. 116820 ==> 0.3187002381180964\n",
            "Loss in iteration no. 116821 ==> 0.3187000580708966\n",
            "Loss in iteration no. 116822 ==> 0.31869987802728283\n",
            "Loss in iteration no. 116823 ==> 0.31869969798725534\n",
            "Loss in iteration no. 116824 ==> 0.3186995179508138\n",
            "Loss in iteration no. 116825 ==> 0.31869933791795835\n",
            "Loss in iteration no. 116826 ==> 0.31869915788868886\n",
            "Loss in iteration no. 116827 ==> 0.318698977863005\n",
            "Loss in iteration no. 116828 ==> 0.31869879784090677\n",
            "Loss in iteration no. 116829 ==> 0.31869861782239434\n",
            "Loss in iteration no. 116830 ==> 0.3186984378074674\n",
            "Loss in iteration no. 116831 ==> 0.31869825779612576\n",
            "Loss in iteration no. 116832 ==> 0.31869807778836945\n",
            "Loss in iteration no. 116833 ==> 0.31869789778419844\n",
            "Loss in iteration no. 116834 ==> 0.3186977177836125\n",
            "Loss in iteration no. 116835 ==> 0.3186975377866118\n",
            "Loss in iteration no. 116836 ==> 0.31869735779319586\n",
            "Loss in iteration no. 116837 ==> 0.31869717780336465\n",
            "Loss in iteration no. 116838 ==> 0.3186969978171184\n",
            "Loss in iteration no. 116839 ==> 0.3186968178344569\n",
            "Loss in iteration no. 116840 ==> 0.31869663785537994\n",
            "Loss in iteration no. 116841 ==> 0.3186964578798875\n",
            "Loss in iteration no. 116842 ==> 0.3186962779079793\n",
            "Loss in iteration no. 116843 ==> 0.3186960979396556\n",
            "Loss in iteration no. 116844 ==> 0.3186959179749159\n",
            "Loss in iteration no. 116845 ==> 0.3186957380137605\n",
            "Loss in iteration no. 116846 ==> 0.31869555805618915\n",
            "Loss in iteration no. 116847 ==> 0.31869537810220167\n",
            "Loss in iteration no. 116848 ==> 0.31869519815179803\n",
            "Loss in iteration no. 116849 ==> 0.31869501820497814\n",
            "Loss in iteration no. 116850 ==> 0.31869483826174194\n",
            "Loss in iteration no. 116851 ==> 0.3186946583220893\n",
            "Loss in iteration no. 116852 ==> 0.3186944783860202\n",
            "Loss in iteration no. 116853 ==> 0.31869429845353453\n",
            "Loss in iteration no. 116854 ==> 0.318694118524632\n",
            "Loss in iteration no. 116855 ==> 0.3186939385993128\n",
            "Loss in iteration no. 116856 ==> 0.31869375867757654\n",
            "Loss in iteration no. 116857 ==> 0.3186935787594235\n",
            "Loss in iteration no. 116858 ==> 0.31869339884485337\n",
            "Loss in iteration no. 116859 ==> 0.31869321893386593\n",
            "Loss in iteration no. 116860 ==> 0.31869303902646134\n",
            "Loss in iteration no. 116861 ==> 0.3186928591226394\n",
            "Loss in iteration no. 116862 ==> 0.31869267922239997\n",
            "Loss in iteration no. 116863 ==> 0.31869249932574306\n",
            "Loss in iteration no. 116864 ==> 0.31869231943266857\n",
            "Loss in iteration no. 116865 ==> 0.31869213954317627\n",
            "Loss in iteration no. 116866 ==> 0.318691959657266\n",
            "Loss in iteration no. 116867 ==> 0.318691779774938\n",
            "Loss in iteration no. 116868 ==> 0.3186915998961922\n",
            "Loss in iteration no. 116869 ==> 0.31869142002102796\n",
            "Loss in iteration no. 116870 ==> 0.3186912401494458\n",
            "Loss in iteration no. 116871 ==> 0.3186910602814453\n",
            "Loss in iteration no. 116872 ==> 0.3186908804170263\n",
            "Loss in iteration no. 116873 ==> 0.3186907005561889\n",
            "Loss in iteration no. 116874 ==> 0.3186905206989332\n",
            "Loss in iteration no. 116875 ==> 0.3186903408452586\n",
            "Loss in iteration no. 116876 ==> 0.3186901609951654\n",
            "Loss in iteration no. 116877 ==> 0.31868998114865316\n",
            "Loss in iteration no. 116878 ==> 0.3186898013057222\n",
            "Loss in iteration no. 116879 ==> 0.3186896214663722\n",
            "Loss in iteration no. 116880 ==> 0.31868944163060314\n",
            "Loss in iteration no. 116881 ==> 0.31868926179841484\n",
            "Loss in iteration no. 116882 ==> 0.3186890819698071\n",
            "Loss in iteration no. 116883 ==> 0.3186889021447803\n",
            "Loss in iteration no. 116884 ==> 0.3186887223233339\n",
            "Loss in iteration no. 116885 ==> 0.31868854250546785\n",
            "Loss in iteration no. 116886 ==> 0.31868836269118217\n",
            "Loss in iteration no. 116887 ==> 0.3186881828804768\n",
            "Loss in iteration no. 116888 ==> 0.31868800307335154\n",
            "Loss in iteration no. 116889 ==> 0.3186878232698064\n",
            "Loss in iteration no. 116890 ==> 0.3186876434698413\n",
            "Loss in iteration no. 116891 ==> 0.318687463673456\n",
            "Loss in iteration no. 116892 ==> 0.31868728388065043\n",
            "Loss in iteration no. 116893 ==> 0.3186871040914247\n",
            "Loss in iteration no. 116894 ==> 0.31868692430577855\n",
            "Loss in iteration no. 116895 ==> 0.31868674452371193\n",
            "Loss in iteration no. 116896 ==> 0.3186865647452246\n",
            "Loss in iteration no. 116897 ==> 0.3186863849703167\n",
            "Loss in iteration no. 116898 ==> 0.31868620519898805\n",
            "Loss in iteration no. 116899 ==> 0.3186860254312384\n",
            "Loss in iteration no. 116900 ==> 0.31868584566706804\n",
            "Loss in iteration no. 116901 ==> 0.3186856659064765\n",
            "Loss in iteration no. 116902 ==> 0.3186854861494639\n",
            "Loss in iteration no. 116903 ==> 0.3186853063960301\n",
            "Loss in iteration no. 116904 ==> 0.318685126646175\n",
            "Loss in iteration no. 116905 ==> 0.31868494689989846\n",
            "Loss in iteration no. 116906 ==> 0.3186847671572004\n",
            "Loss in iteration no. 116907 ==> 0.31868458741808076\n",
            "Loss in iteration no. 116908 ==> 0.3186844076825396\n",
            "Loss in iteration no. 116909 ==> 0.3186842279505765\n",
            "Loss in iteration no. 116910 ==> 0.31868404822219154\n",
            "Loss in iteration no. 116911 ==> 0.31868386849738467\n",
            "Loss in iteration no. 116912 ==> 0.3186836887761557\n",
            "Loss in iteration no. 116913 ==> 0.3186835090585047\n",
            "Loss in iteration no. 116914 ==> 0.31868332934443133\n",
            "Loss in iteration no. 116915 ==> 0.31868314963393574\n",
            "Loss in iteration no. 116916 ==> 0.31868296992701756\n",
            "Loss in iteration no. 116917 ==> 0.3186827902236772\n",
            "Loss in iteration no. 116918 ==> 0.31868261052391406\n",
            "Loss in iteration no. 116919 ==> 0.3186824308277281\n",
            "Loss in iteration no. 116920 ==> 0.31868225113511955\n",
            "Loss in iteration no. 116921 ==> 0.31868207144608807\n",
            "Loss in iteration no. 116922 ==> 0.3186818917606336\n",
            "Loss in iteration no. 116923 ==> 0.3186817120787562\n",
            "Loss in iteration no. 116924 ==> 0.31868153240045544\n",
            "Loss in iteration no. 116925 ==> 0.31868135272573156\n",
            "Loss in iteration no. 116926 ==> 0.3186811730545842\n",
            "Loss in iteration no. 116927 ==> 0.31868099338701356\n",
            "Loss in iteration no. 116928 ==> 0.31868081372301954\n",
            "Loss in iteration no. 116929 ==> 0.31868063406260166\n",
            "Loss in iteration no. 116930 ==> 0.3186804544057601\n",
            "Loss in iteration no. 116931 ==> 0.3186802747524949\n",
            "Loss in iteration no. 116932 ==> 0.3186800951028057\n",
            "Loss in iteration no. 116933 ==> 0.3186799154566925\n",
            "Loss in iteration no. 116934 ==> 0.31867973581415526\n",
            "Loss in iteration no. 116935 ==> 0.3186795561751939\n",
            "Loss in iteration no. 116936 ==> 0.3186793765398083\n",
            "Loss in iteration no. 116937 ==> 0.31867919690799834\n",
            "Loss in iteration no. 116938 ==> 0.3186790172797639\n",
            "Loss in iteration no. 116939 ==> 0.318678837655105\n",
            "Loss in iteration no. 116940 ==> 0.31867865803402134\n",
            "Loss in iteration no. 116941 ==> 0.318678478416513\n",
            "Loss in iteration no. 116942 ==> 0.31867829880258003\n",
            "Loss in iteration no. 116943 ==> 0.31867811919222194\n",
            "Loss in iteration no. 116944 ==> 0.318677939585439\n",
            "Loss in iteration no. 116945 ==> 0.3186777599822309\n",
            "Loss in iteration no. 116946 ==> 0.3186775803825977\n",
            "Loss in iteration no. 116947 ==> 0.3186774007865393\n",
            "Loss in iteration no. 116948 ==> 0.31867722119405534\n",
            "Loss in iteration no. 116949 ==> 0.3186770416051461\n",
            "Loss in iteration no. 116950 ==> 0.31867686201981116\n",
            "Loss in iteration no. 116951 ==> 0.31867668243805075\n",
            "Loss in iteration no. 116952 ==> 0.3186765028598645\n",
            "Loss in iteration no. 116953 ==> 0.31867632328525247\n",
            "Loss in iteration no. 116954 ==> 0.3186761437142146\n",
            "Loss in iteration no. 116955 ==> 0.31867596414675065\n",
            "Loss in iteration no. 116956 ==> 0.3186757845828606\n",
            "Loss in iteration no. 116957 ==> 0.3186756050225445\n",
            "Loss in iteration no. 116958 ==> 0.3186754254658019\n",
            "Loss in iteration no. 116959 ==> 0.3186752459126331\n",
            "Loss in iteration no. 116960 ==> 0.3186750663630378\n",
            "Loss in iteration no. 116961 ==> 0.3186748868170159\n",
            "Loss in iteration no. 116962 ==> 0.31867470727456737\n",
            "Loss in iteration no. 116963 ==> 0.31867452773569227\n",
            "Loss in iteration no. 116964 ==> 0.3186743482003901\n",
            "Loss in iteration no. 116965 ==> 0.31867416866866105\n",
            "Loss in iteration no. 116966 ==> 0.31867398914050515\n",
            "Loss in iteration no. 116967 ==> 0.3186738096159221\n",
            "Loss in iteration no. 116968 ==> 0.31867363009491173\n",
            "Loss in iteration no. 116969 ==> 0.3186734505774742\n",
            "Loss in iteration no. 116970 ==> 0.31867327106360915\n",
            "Loss in iteration no. 116971 ==> 0.3186730915533168\n",
            "Loss in iteration no. 116972 ==> 0.31867291204659676\n",
            "Loss in iteration no. 116973 ==> 0.31867273254344913\n",
            "Loss in iteration no. 116974 ==> 0.3186725530438737\n",
            "Loss in iteration no. 116975 ==> 0.31867237354787054\n",
            "Loss in iteration no. 116976 ==> 0.31867219405543934\n",
            "Loss in iteration no. 116977 ==> 0.3186720145665802\n",
            "Loss in iteration no. 116978 ==> 0.3186718350812929\n",
            "Loss in iteration no. 116979 ==> 0.3186716555995774\n",
            "Loss in iteration no. 116980 ==> 0.3186714761214337\n",
            "Loss in iteration no. 116981 ==> 0.31867129664686145\n",
            "Loss in iteration no. 116982 ==> 0.3186711171758607\n",
            "Loss in iteration no. 116983 ==> 0.3186709377084316\n",
            "Loss in iteration no. 116984 ==> 0.3186707582445737\n",
            "Loss in iteration no. 116985 ==> 0.3186705787842869\n",
            "Loss in iteration no. 116986 ==> 0.31867039932757146\n",
            "Loss in iteration no. 116987 ==> 0.318670219874427\n",
            "Loss in iteration no. 116988 ==> 0.31867004042485353\n",
            "Loss in iteration no. 116989 ==> 0.31866986097885097\n",
            "Loss in iteration no. 116990 ==> 0.3186696815364192\n",
            "Loss in iteration no. 116991 ==> 0.31866950209755807\n",
            "Loss in iteration no. 116992 ==> 0.3186693226622675\n",
            "Loss in iteration no. 116993 ==> 0.3186691432305475\n",
            "Loss in iteration no. 116994 ==> 0.31866896380239806\n",
            "Loss in iteration no. 116995 ==> 0.3186687843778187\n",
            "Loss in iteration no. 116996 ==> 0.31866860495680976\n",
            "Loss in iteration no. 116997 ==> 0.3186684255393708\n",
            "Loss in iteration no. 116998 ==> 0.31866824612550204\n",
            "Loss in iteration no. 116999 ==> 0.31866806671520315\n",
            "Loss in iteration no. 117000 ==> 0.3186678873084742\n",
            "Loss in iteration no. 117001 ==> 0.3186677079053149\n",
            "Loss in iteration no. 117002 ==> 0.3186675285057253\n",
            "Loss in iteration no. 117003 ==> 0.3186673491097054\n",
            "Loss in iteration no. 117004 ==> 0.318667169717255\n",
            "Loss in iteration no. 117005 ==> 0.3186669903283739\n",
            "Loss in iteration no. 117006 ==> 0.3186668109430621\n",
            "Loss in iteration no. 117007 ==> 0.31866663156131975\n",
            "Loss in iteration no. 117008 ==> 0.3186664521831463\n",
            "Loss in iteration no. 117009 ==> 0.318666272808542\n",
            "Loss in iteration no. 117010 ==> 0.31866609343750657\n",
            "Loss in iteration no. 117011 ==> 0.3186659140700402\n",
            "Loss in iteration no. 117012 ==> 0.31866573470614246\n",
            "Loss in iteration no. 117013 ==> 0.31866555534581326\n",
            "Loss in iteration no. 117014 ==> 0.3186653759890528\n",
            "Loss in iteration no. 117015 ==> 0.3186651966358607\n",
            "Loss in iteration no. 117016 ==> 0.3186650172862372\n",
            "Loss in iteration no. 117017 ==> 0.3186648379401819\n",
            "Loss in iteration no. 117018 ==> 0.3186646585976947\n",
            "Loss in iteration no. 117019 ==> 0.31866447925877583\n",
            "Loss in iteration no. 117020 ==> 0.31866429992342504\n",
            "Loss in iteration no. 117021 ==> 0.31866412059164206\n",
            "Loss in iteration no. 117022 ==> 0.3186639412634269\n",
            "Loss in iteration no. 117023 ==> 0.31866376193877943\n",
            "Loss in iteration no. 117024 ==> 0.3186635826176998\n",
            "Loss in iteration no. 117025 ==> 0.3186634033001876\n",
            "Loss in iteration no. 117026 ==> 0.3186632239862429\n",
            "Loss in iteration no. 117027 ==> 0.3186630446758657\n",
            "Loss in iteration no. 117028 ==> 0.31866286536905586\n",
            "Loss in iteration no. 117029 ==> 0.3186626860658131\n",
            "Loss in iteration no. 117030 ==> 0.31866250676613744\n",
            "Loss in iteration no. 117031 ==> 0.31866232747002887\n",
            "Loss in iteration no. 117032 ==> 0.3186621481774871\n",
            "Loss in iteration no. 117033 ==> 0.31866196888851234\n",
            "Loss in iteration no. 117034 ==> 0.3186617896031042\n",
            "Loss in iteration no. 117035 ==> 0.3186616103212628\n",
            "Loss in iteration no. 117036 ==> 0.31866143104298805\n",
            "Loss in iteration no. 117037 ==> 0.3186612517682797\n",
            "Loss in iteration no. 117038 ==> 0.31866107249713765\n",
            "Loss in iteration no. 117039 ==> 0.3186608932295619\n",
            "Loss in iteration no. 117040 ==> 0.31866071396555234\n",
            "Loss in iteration no. 117041 ==> 0.31866053470510897\n",
            "Loss in iteration no. 117042 ==> 0.31866035544823157\n",
            "Loss in iteration no. 117043 ==> 0.31866017619492015\n",
            "Loss in iteration no. 117044 ==> 0.31865999694517455\n",
            "Loss in iteration no. 117045 ==> 0.31865981769899465\n",
            "Loss in iteration no. 117046 ==> 0.3186596384563805\n",
            "Loss in iteration no. 117047 ==> 0.31865945921733163\n",
            "Loss in iteration no. 117048 ==> 0.31865927998184856\n",
            "Loss in iteration no. 117049 ==> 0.31865910074993076\n",
            "Loss in iteration no. 117050 ==> 0.3186589215215781\n",
            "Loss in iteration no. 117051 ==> 0.31865874229679075\n",
            "Loss in iteration no. 117052 ==> 0.31865856307556856\n",
            "Loss in iteration no. 117053 ==> 0.3186583838579113\n",
            "Loss in iteration no. 117054 ==> 0.31865820464381894\n",
            "Loss in iteration no. 117055 ==> 0.31865802543329136\n",
            "Loss in iteration no. 117056 ==> 0.31865784622632864\n",
            "Loss in iteration no. 117057 ==> 0.3186576670229305\n",
            "Loss in iteration no. 117058 ==> 0.31865748782309705\n",
            "Loss in iteration no. 117059 ==> 0.3186573086268279\n",
            "Loss in iteration no. 117060 ==> 0.31865712943412317\n",
            "Loss in iteration no. 117061 ==> 0.31865695024498253\n",
            "Loss in iteration no. 117062 ==> 0.3186567710594064\n",
            "Loss in iteration no. 117063 ==> 0.3186565918773941\n",
            "Loss in iteration no. 117064 ==> 0.31865641269894596\n",
            "Loss in iteration no. 117065 ==> 0.31865623352406164\n",
            "Loss in iteration no. 117066 ==> 0.3186560543527412\n",
            "Loss in iteration no. 117067 ==> 0.3186558751849844\n",
            "Loss in iteration no. 117068 ==> 0.31865569602079147\n",
            "Loss in iteration no. 117069 ==> 0.3186555168601617\n",
            "Loss in iteration no. 117070 ==> 0.31865533770309556\n",
            "Loss in iteration no. 117071 ==> 0.3186551585495929\n",
            "Loss in iteration no. 117072 ==> 0.3186549793996533\n",
            "Loss in iteration no. 117073 ==> 0.3186548002532771\n",
            "Loss in iteration no. 117074 ==> 0.31865462111046383\n",
            "Loss in iteration no. 117075 ==> 0.31865444197121356\n",
            "Loss in iteration no. 117076 ==> 0.3186542628355262\n",
            "Loss in iteration no. 117077 ==> 0.31865408370340187\n",
            "Loss in iteration no. 117078 ==> 0.31865390457484005\n",
            "Loss in iteration no. 117079 ==> 0.3186537254498409\n",
            "Loss in iteration no. 117080 ==> 0.31865354632840426\n",
            "Loss in iteration no. 117081 ==> 0.31865336721053\n",
            "Loss in iteration no. 117082 ==> 0.3186531880962181\n",
            "Loss in iteration no. 117083 ==> 0.3186530089854687\n",
            "Loss in iteration no. 117084 ==> 0.31865282987828114\n",
            "Loss in iteration no. 117085 ==> 0.318652650774656\n",
            "Loss in iteration no. 117086 ==> 0.3186524716745926\n",
            "Loss in iteration no. 117087 ==> 0.31865229257809113\n",
            "Loss in iteration no. 117088 ==> 0.3186521134851516\n",
            "Loss in iteration no. 117089 ==> 0.3186519343957736\n",
            "Loss in iteration no. 117090 ==> 0.3186517553099573\n",
            "Loss in iteration no. 117091 ==> 0.3186515762277026\n",
            "Loss in iteration no. 117092 ==> 0.3186513971490092\n",
            "Loss in iteration no. 117093 ==> 0.3186512180738772\n",
            "Loss in iteration no. 117094 ==> 0.31865103900230657\n",
            "Loss in iteration no. 117095 ==> 0.318650859934297\n",
            "Loss in iteration no. 117096 ==> 0.3186506808698485\n",
            "Loss in iteration no. 117097 ==> 0.31865050180896093\n",
            "Loss in iteration no. 117098 ==> 0.3186503227516344\n",
            "Loss in iteration no. 117099 ==> 0.31865014369786854\n",
            "Loss in iteration no. 117100 ==> 0.31864996464766343\n",
            "Loss in iteration no. 117101 ==> 0.3186497856010189\n",
            "Loss in iteration no. 117102 ==> 0.3186496065579349\n",
            "Loss in iteration no. 117103 ==> 0.31864942751841147\n",
            "Loss in iteration no. 117104 ==> 0.3186492484824482\n",
            "Loss in iteration no. 117105 ==> 0.3186490694500452\n",
            "Loss in iteration no. 117106 ==> 0.3186488904212025\n",
            "Loss in iteration no. 117107 ==> 0.3186487113959197\n",
            "Loss in iteration no. 117108 ==> 0.31864853237419705\n",
            "Loss in iteration no. 117109 ==> 0.31864835335603414\n",
            "Loss in iteration no. 117110 ==> 0.31864817434143106\n",
            "Loss in iteration no. 117111 ==> 0.31864799533038773\n",
            "Loss in iteration no. 117112 ==> 0.31864781632290384\n",
            "Loss in iteration no. 117113 ==> 0.3186476373189796\n",
            "Loss in iteration no. 117114 ==> 0.31864745831861474\n",
            "Loss in iteration no. 117115 ==> 0.31864727932180925\n",
            "Loss in iteration no. 117116 ==> 0.3186471003285631\n",
            "Loss in iteration no. 117117 ==> 0.31864692133887607\n",
            "Loss in iteration no. 117118 ==> 0.3186467423527479\n",
            "Loss in iteration no. 117119 ==> 0.31864656337017894\n",
            "Loss in iteration no. 117120 ==> 0.3186463843911687\n",
            "Loss in iteration no. 117121 ==> 0.31864620541571725\n",
            "Loss in iteration no. 117122 ==> 0.31864602644382467\n",
            "Loss in iteration no. 117123 ==> 0.3186458474754907\n",
            "Loss in iteration no. 117124 ==> 0.31864566851071496\n",
            "Loss in iteration no. 117125 ==> 0.31864548954949784\n",
            "Loss in iteration no. 117126 ==> 0.31864531059183904\n",
            "Loss in iteration no. 117127 ==> 0.31864513163773833\n",
            "Loss in iteration no. 117128 ==> 0.31864495268719595\n",
            "Loss in iteration no. 117129 ==> 0.31864477374021155\n",
            "Loss in iteration no. 117130 ==> 0.3186445947967852\n",
            "Loss in iteration no. 117131 ==> 0.31864441585691666\n",
            "Loss in iteration no. 117132 ==> 0.31864423692060595\n",
            "Loss in iteration no. 117133 ==> 0.3186440579878528\n",
            "Loss in iteration no. 117134 ==> 0.3186438790586572\n",
            "Loss in iteration no. 117135 ==> 0.31864370013301935\n",
            "Loss in iteration no. 117136 ==> 0.3186435212109387\n",
            "Loss in iteration no. 117137 ==> 0.3186433422924155\n",
            "Loss in iteration no. 117138 ==> 0.3186431633774495\n",
            "Loss in iteration no. 117139 ==> 0.3186429844660407\n",
            "Loss in iteration no. 117140 ==> 0.31864280555818886\n",
            "Loss in iteration no. 117141 ==> 0.31864262665389403\n",
            "Loss in iteration no. 117142 ==> 0.318642447753156\n",
            "Loss in iteration no. 117143 ==> 0.3186422688559747\n",
            "Loss in iteration no. 117144 ==> 0.3186420899623502\n",
            "Loss in iteration no. 117145 ==> 0.3186419110722824\n",
            "Loss in iteration no. 117146 ==> 0.318641732185771\n",
            "Loss in iteration no. 117147 ==> 0.31864155330281596\n",
            "Loss in iteration no. 117148 ==> 0.3186413744234172\n",
            "Loss in iteration no. 117149 ==> 0.31864119554757486\n",
            "Loss in iteration no. 117150 ==> 0.3186410166752885\n",
            "Loss in iteration no. 117151 ==> 0.31864083780655816\n",
            "Loss in iteration no. 117152 ==> 0.31864065894138394\n",
            "Loss in iteration no. 117153 ==> 0.31864048007976536\n",
            "Loss in iteration no. 117154 ==> 0.31864030122170284\n",
            "Loss in iteration no. 117155 ==> 0.3186401223671958\n",
            "Loss in iteration no. 117156 ==> 0.31863994351624436\n",
            "Loss in iteration no. 117157 ==> 0.31863976466884847\n",
            "Loss in iteration no. 117158 ==> 0.31863958582500795\n",
            "Loss in iteration no. 117159 ==> 0.31863940698472265\n",
            "Loss in iteration no. 117160 ==> 0.3186392281479927\n",
            "Loss in iteration no. 117161 ==> 0.31863904931481796\n",
            "Loss in iteration no. 117162 ==> 0.3186388704851981\n",
            "Loss in iteration no. 117163 ==> 0.3186386916591333\n",
            "Loss in iteration no. 117164 ==> 0.3186385128366233\n",
            "Loss in iteration no. 117165 ==> 0.31863833401766806\n",
            "Loss in iteration no. 117166 ==> 0.31863815520226757\n",
            "Loss in iteration no. 117167 ==> 0.3186379763904216\n",
            "Loss in iteration no. 117168 ==> 0.31863779758213\n",
            "Loss in iteration no. 117169 ==> 0.31863761877739305\n",
            "Loss in iteration no. 117170 ==> 0.3186374399762103\n",
            "Loss in iteration no. 117171 ==> 0.3186372611785818\n",
            "Loss in iteration no. 117172 ==> 0.3186370823845075\n",
            "Loss in iteration no. 117173 ==> 0.31863690359398716\n",
            "Loss in iteration no. 117174 ==> 0.3186367248070207\n",
            "Loss in iteration no. 117175 ==> 0.3186365460236081\n",
            "Loss in iteration no. 117176 ==> 0.31863636724374933\n",
            "Loss in iteration no. 117177 ==> 0.3186361884674441\n",
            "Loss in iteration no. 117178 ==> 0.3186360096946927\n",
            "Loss in iteration no. 117179 ==> 0.3186358309254947\n",
            "Loss in iteration no. 117180 ==> 0.31863565215984996\n",
            "Loss in iteration no. 117181 ==> 0.3186354733977586\n",
            "Loss in iteration no. 117182 ==> 0.3186352946392206\n",
            "Loss in iteration no. 117183 ==> 0.31863511588423554\n",
            "Loss in iteration no. 117184 ==> 0.31863493713280366\n",
            "Loss in iteration no. 117185 ==> 0.31863475838492455\n",
            "Loss in iteration no. 117186 ==> 0.31863457964059844\n",
            "Loss in iteration no. 117187 ==> 0.31863440089982503\n",
            "Loss in iteration no. 117188 ==> 0.31863422216260434\n",
            "Loss in iteration no. 117189 ==> 0.31863404342893614\n",
            "Loss in iteration no. 117190 ==> 0.3186338646988206\n",
            "Loss in iteration no. 117191 ==> 0.3186336859722573\n",
            "Loss in iteration no. 117192 ==> 0.31863350724924616\n",
            "Loss in iteration no. 117193 ==> 0.31863332852978754\n",
            "Loss in iteration no. 117194 ==> 0.31863314981388086\n",
            "Loss in iteration no. 117195 ==> 0.31863297110152633\n",
            "Loss in iteration no. 117196 ==> 0.3186327923927237\n",
            "Loss in iteration no. 117197 ==> 0.318632613687473\n",
            "Loss in iteration no. 117198 ==> 0.31863243498577387\n",
            "Loss in iteration no. 117199 ==> 0.3186322562876265\n",
            "Loss in iteration no. 117200 ==> 0.3186320775930306\n",
            "Loss in iteration no. 117201 ==> 0.3186318989019864\n",
            "Loss in iteration no. 117202 ==> 0.31863172021449343\n",
            "Loss in iteration no. 117203 ==> 0.31863154153055173\n",
            "Loss in iteration no. 117204 ==> 0.3186313628501614\n",
            "Loss in iteration no. 117205 ==> 0.31863118417332204\n",
            "Loss in iteration no. 117206 ==> 0.3186310055000338\n",
            "Loss in iteration no. 117207 ==> 0.3186308268302965\n",
            "Loss in iteration no. 117208 ==> 0.31863064816410996\n",
            "Loss in iteration no. 117209 ==> 0.31863046950147433\n",
            "Loss in iteration no. 117210 ==> 0.3186302908423892\n",
            "Loss in iteration no. 117211 ==> 0.3186301121868548\n",
            "Loss in iteration no. 117212 ==> 0.3186299335348706\n",
            "Loss in iteration no. 117213 ==> 0.3186297548864372\n",
            "Loss in iteration no. 117214 ==> 0.31862957624155375\n",
            "Loss in iteration no. 117215 ==> 0.31862939760022063\n",
            "Loss in iteration no. 117216 ==> 0.3186292189624376\n",
            "Loss in iteration no. 117217 ==> 0.3186290403282047\n",
            "Loss in iteration no. 117218 ==> 0.31862886169752186\n",
            "Loss in iteration no. 117219 ==> 0.31862868307038855\n",
            "Loss in iteration no. 117220 ==> 0.31862850444680507\n",
            "Loss in iteration no. 117221 ==> 0.31862832582677136\n",
            "Loss in iteration no. 117222 ==> 0.31862814721028715\n",
            "Loss in iteration no. 117223 ==> 0.3186279685973525\n",
            "Loss in iteration no. 117224 ==> 0.31862778998796704\n",
            "Loss in iteration no. 117225 ==> 0.3186276113821311\n",
            "Loss in iteration no. 117226 ==> 0.3186274327798443\n",
            "Loss in iteration no. 117227 ==> 0.31862725418110655\n",
            "Loss in iteration no. 117228 ==> 0.3186270755859178\n",
            "Loss in iteration no. 117229 ==> 0.31862689699427804\n",
            "Loss in iteration no. 117230 ==> 0.3186267184061873\n",
            "Loss in iteration no. 117231 ==> 0.31862653982164496\n",
            "Loss in iteration no. 117232 ==> 0.3186263612406516\n",
            "Loss in iteration no. 117233 ==> 0.31862618266320664\n",
            "Loss in iteration no. 117234 ==> 0.3186260040893102\n",
            "Loss in iteration no. 117235 ==> 0.31862582551896207\n",
            "Loss in iteration no. 117236 ==> 0.3186256469521623\n",
            "Loss in iteration no. 117237 ==> 0.31862546838891076\n",
            "Loss in iteration no. 117238 ==> 0.3186252898292073\n",
            "Loss in iteration no. 117239 ==> 0.318625111273052\n",
            "Loss in iteration no. 117240 ==> 0.3186249327204444\n",
            "Loss in iteration no. 117241 ==> 0.3186247541713847\n",
            "Loss in iteration no. 117242 ==> 0.3186245756258729\n",
            "Loss in iteration no. 117243 ==> 0.31862439708390844\n",
            "Loss in iteration no. 117244 ==> 0.31862421854549183\n",
            "Loss in iteration no. 117245 ==> 0.3186240400106227\n",
            "Loss in iteration no. 117246 ==> 0.31862386147930083\n",
            "Loss in iteration no. 117247 ==> 0.3186236829515263\n",
            "Loss in iteration no. 117248 ==> 0.318623504427299\n",
            "Loss in iteration no. 117249 ==> 0.31862332590661896\n",
            "Loss in iteration no. 117250 ==> 0.3186231473894856\n",
            "Loss in iteration no. 117251 ==> 0.3186229688758994\n",
            "Loss in iteration no. 117252 ==> 0.31862279036586005\n",
            "Loss in iteration no. 117253 ==> 0.31862261185936724\n",
            "Loss in iteration no. 117254 ==> 0.3186224333564212\n",
            "Loss in iteration no. 117255 ==> 0.3186222548570219\n",
            "Loss in iteration no. 117256 ==> 0.31862207636116885\n",
            "Loss in iteration no. 117257 ==> 0.31862189786886225\n",
            "Loss in iteration no. 117258 ==> 0.3186217193801019\n",
            "Loss in iteration no. 117259 ==> 0.3186215408948879\n",
            "Loss in iteration no. 117260 ==> 0.3186213624132198\n",
            "Loss in iteration no. 117261 ==> 0.318621183935098\n",
            "Loss in iteration no. 117262 ==> 0.31862100546052197\n",
            "Loss in iteration no. 117263 ==> 0.3186208269894918\n",
            "Loss in iteration no. 117264 ==> 0.3186206485220073\n",
            "Loss in iteration no. 117265 ==> 0.3186204700580684\n",
            "Loss in iteration no. 117266 ==> 0.3186202915976753\n",
            "Loss in iteration no. 117267 ==> 0.31862011314082755\n",
            "Loss in iteration no. 117268 ==> 0.3186199346875252\n",
            "Loss in iteration no. 117269 ==> 0.31861975623776806\n",
            "Loss in iteration no. 117270 ==> 0.3186195777915563\n",
            "Loss in iteration no. 117271 ==> 0.3186193993488895\n",
            "Loss in iteration no. 117272 ==> 0.31861922090976763\n",
            "Loss in iteration no. 117273 ==> 0.318619042474191\n",
            "Loss in iteration no. 117274 ==> 0.31861886404215883\n",
            "Loss in iteration no. 117275 ==> 0.3186186856136718\n",
            "Loss in iteration no. 117276 ==> 0.318618507188729\n",
            "Loss in iteration no. 117277 ==> 0.31861832876733115\n",
            "Loss in iteration no. 117278 ==> 0.3186181503494776\n",
            "Loss in iteration no. 117279 ==> 0.3186179719351685\n",
            "Loss in iteration no. 117280 ==> 0.31861779352440356\n",
            "Loss in iteration no. 117281 ==> 0.318617615117183\n",
            "Loss in iteration no. 117282 ==> 0.3186174367135064\n",
            "Loss in iteration no. 117283 ==> 0.31861725831337395\n",
            "Loss in iteration no. 117284 ==> 0.31861707991678523\n",
            "Loss in iteration no. 117285 ==> 0.3186169015237405\n",
            "Loss in iteration no. 117286 ==> 0.31861672313423955\n",
            "Loss in iteration no. 117287 ==> 0.3186165447482821\n",
            "Loss in iteration no. 117288 ==> 0.3186163663658684\n",
            "Loss in iteration no. 117289 ==> 0.3186161879869981\n",
            "Loss in iteration no. 117290 ==> 0.318616009611671\n",
            "Loss in iteration no. 117291 ==> 0.31861583123988735\n",
            "Loss in iteration no. 117292 ==> 0.31861565287164695\n",
            "Loss in iteration no. 117293 ==> 0.3186154745069496\n",
            "Loss in iteration no. 117294 ==> 0.3186152961457953\n",
            "Loss in iteration no. 117295 ==> 0.318615117788184\n",
            "Loss in iteration no. 117296 ==> 0.3186149394341154\n",
            "Loss in iteration no. 117297 ==> 0.31861476108358966\n",
            "Loss in iteration no. 117298 ==> 0.31861458273660653\n",
            "Loss in iteration no. 117299 ==> 0.3186144043931658\n",
            "Loss in iteration no. 117300 ==> 0.3186142260532678\n",
            "Loss in iteration no. 117301 ==> 0.3186140477169121\n",
            "Loss in iteration no. 117302 ==> 0.31861386938409864\n",
            "Loss in iteration no. 117303 ==> 0.31861369105482756\n",
            "Loss in iteration no. 117304 ==> 0.31861351272909827\n",
            "Loss in iteration no. 117305 ==> 0.31861333440691125\n",
            "Loss in iteration no. 117306 ==> 0.31861315608826596\n",
            "Loss in iteration no. 117307 ==> 0.3186129777731627\n",
            "Loss in iteration no. 117308 ==> 0.3186127994616011\n",
            "Loss in iteration no. 117309 ==> 0.3186126211535812\n",
            "Loss in iteration no. 117310 ==> 0.3186124428491029\n",
            "Loss in iteration no. 117311 ==> 0.3186122645481659\n",
            "Loss in iteration no. 117312 ==> 0.3186120862507705\n",
            "Loss in iteration no. 117313 ==> 0.31861190795691635\n",
            "Loss in iteration no. 117314 ==> 0.3186117296666033\n",
            "Loss in iteration no. 117315 ==> 0.3186115513798313\n",
            "Loss in iteration no. 117316 ==> 0.3186113730966006\n",
            "Loss in iteration no. 117317 ==> 0.31861119481691064\n",
            "Loss in iteration no. 117318 ==> 0.3186110165407615\n",
            "Loss in iteration no. 117319 ==> 0.3186108382681531\n",
            "Loss in iteration no. 117320 ==> 0.3186106599990853\n",
            "Loss in iteration no. 117321 ==> 0.3186104817335581\n",
            "Loss in iteration no. 117322 ==> 0.31861030347157154\n",
            "Loss in iteration no. 117323 ==> 0.31861012521312526\n",
            "Loss in iteration no. 117324 ==> 0.31860994695821937\n",
            "Loss in iteration no. 117325 ==> 0.31860976870685354\n",
            "Loss in iteration no. 117326 ==> 0.318609590459028\n",
            "Loss in iteration no. 117327 ==> 0.3186094122147423\n",
            "Loss in iteration no. 117328 ==> 0.31860923397399654\n",
            "Loss in iteration no. 117329 ==> 0.3186090557367907\n",
            "Loss in iteration no. 117330 ==> 0.3186088775031245\n",
            "Loss in iteration no. 117331 ==> 0.31860869927299806\n",
            "Loss in iteration no. 117332 ==> 0.31860852104641124\n",
            "Loss in iteration no. 117333 ==> 0.3186083428233638\n",
            "Loss in iteration no. 117334 ==> 0.31860816460385577\n",
            "Loss in iteration no. 117335 ==> 0.3186079863878871\n",
            "Loss in iteration no. 117336 ==> 0.3186078081754576\n",
            "Loss in iteration no. 117337 ==> 0.31860762996656705\n",
            "Loss in iteration no. 117338 ==> 0.31860745176121563\n",
            "Loss in iteration no. 117339 ==> 0.31860727355940327\n",
            "Loss in iteration no. 117340 ==> 0.3186070953611296\n",
            "Loss in iteration no. 117341 ==> 0.3186069171663949\n",
            "Loss in iteration no. 117342 ==> 0.3186067389751986\n",
            "Loss in iteration no. 117343 ==> 0.31860656078754096\n",
            "Loss in iteration no. 117344 ==> 0.3186063826034218\n",
            "Loss in iteration no. 117345 ==> 0.318606204422841\n",
            "Loss in iteration no. 117346 ==> 0.31860602624579865\n",
            "Loss in iteration no. 117347 ==> 0.3186058480722943\n",
            "Loss in iteration no. 117348 ==> 0.3186056699023281\n",
            "Loss in iteration no. 117349 ==> 0.3186054917359\n",
            "Loss in iteration no. 117350 ==> 0.3186053135730098\n",
            "Loss in iteration no. 117351 ==> 0.3186051354136574\n",
            "Loss in iteration no. 117352 ==> 0.3186049572578428\n",
            "Loss in iteration no. 117353 ==> 0.31860477910556584\n",
            "Loss in iteration no. 117354 ==> 0.3186046009568266\n",
            "Loss in iteration no. 117355 ==> 0.31860442281162465\n",
            "Loss in iteration no. 117356 ==> 0.31860424466996023\n",
            "Loss in iteration no. 117357 ==> 0.31860406653183293\n",
            "Loss in iteration no. 117358 ==> 0.3186038883972431\n",
            "Loss in iteration no. 117359 ==> 0.31860371026619017\n",
            "Loss in iteration no. 117360 ==> 0.3186035321386744\n",
            "Loss in iteration no. 117361 ==> 0.3186033540146954\n",
            "Loss in iteration no. 117362 ==> 0.3186031758942535\n",
            "Loss in iteration no. 117363 ==> 0.31860299777734813\n",
            "Loss in iteration no. 117364 ==> 0.3186028196639796\n",
            "Loss in iteration no. 117365 ==> 0.31860264155414747\n",
            "Loss in iteration no. 117366 ==> 0.318602463447852\n",
            "Loss in iteration no. 117367 ==> 0.31860228534509266\n",
            "Loss in iteration no. 117368 ==> 0.3186021072458699\n",
            "Loss in iteration no. 117369 ==> 0.31860192915018315\n",
            "Loss in iteration no. 117370 ==> 0.31860175105803257\n",
            "Loss in iteration no. 117371 ==> 0.31860157296941816\n",
            "Loss in iteration no. 117372 ==> 0.31860139488433953\n",
            "Loss in iteration no. 117373 ==> 0.3186012168027968\n",
            "Loss in iteration no. 117374 ==> 0.3186010387247899\n",
            "Loss in iteration no. 117375 ==> 0.3186008606503186\n",
            "Loss in iteration no. 117376 ==> 0.31860068257938284\n",
            "Loss in iteration no. 117377 ==> 0.3186005045119827\n",
            "Loss in iteration no. 117378 ==> 0.31860032644811764\n",
            "Loss in iteration no. 117379 ==> 0.3186001483877882\n",
            "Loss in iteration no. 117380 ==> 0.31859997033099396\n",
            "Loss in iteration no. 117381 ==> 0.3185997922777348\n",
            "Loss in iteration no. 117382 ==> 0.3185996142280105\n",
            "Loss in iteration no. 117383 ==> 0.3185994361818212\n",
            "Loss in iteration no. 117384 ==> 0.31859925813916695\n",
            "Loss in iteration no. 117385 ==> 0.3185990801000473\n",
            "Loss in iteration no. 117386 ==> 0.31859890206446234\n",
            "Loss in iteration no. 117387 ==> 0.31859872403241196\n",
            "Loss in iteration no. 117388 ==> 0.31859854600389603\n",
            "Loss in iteration no. 117389 ==> 0.31859836797891466\n",
            "Loss in iteration no. 117390 ==> 0.3185981899574674\n",
            "Loss in iteration no. 117391 ==> 0.3185980119395546\n",
            "Loss in iteration no. 117392 ==> 0.3185978339251756\n",
            "Loss in iteration no. 117393 ==> 0.31859765591433087\n",
            "Loss in iteration no. 117394 ==> 0.31859747790702003\n",
            "Loss in iteration no. 117395 ==> 0.31859729990324315\n",
            "Loss in iteration no. 117396 ==> 0.318597121903\n",
            "Loss in iteration no. 117397 ==> 0.31859694390629045\n",
            "Loss in iteration no. 117398 ==> 0.3185967659131145\n",
            "Loss in iteration no. 117399 ==> 0.318596587923472\n",
            "Loss in iteration no. 117400 ==> 0.31859640993736277\n",
            "Loss in iteration no. 117401 ==> 0.31859623195478703\n",
            "Loss in iteration no. 117402 ==> 0.31859605397574464\n",
            "Loss in iteration no. 117403 ==> 0.3185958760002352\n",
            "Loss in iteration no. 117404 ==> 0.3185956980282588\n",
            "Loss in iteration no. 117405 ==> 0.3185955200598154\n",
            "Loss in iteration no. 117406 ==> 0.3185953420949048\n",
            "Loss in iteration no. 117407 ==> 0.3185951641335271\n",
            "Loss in iteration no. 117408 ==> 0.31859498617568194\n",
            "Loss in iteration no. 117409 ==> 0.31859480822136943\n",
            "Loss in iteration no. 117410 ==> 0.31859463027058943\n",
            "Loss in iteration no. 117411 ==> 0.3185944523233418\n",
            "Loss in iteration no. 117412 ==> 0.3185942743796265\n",
            "Loss in iteration no. 117413 ==> 0.3185940964394434\n",
            "Loss in iteration no. 117414 ==> 0.3185939185027925\n",
            "Loss in iteration no. 117415 ==> 0.3185937405696736\n",
            "Loss in iteration no. 117416 ==> 0.31859356264008654\n",
            "Loss in iteration no. 117417 ==> 0.3185933847140314\n",
            "Loss in iteration no. 117418 ==> 0.31859320679150827\n",
            "Loss in iteration no. 117419 ==> 0.31859302887251656\n",
            "Loss in iteration no. 117420 ==> 0.31859285095705664\n",
            "Loss in iteration no. 117421 ==> 0.31859267304512806\n",
            "Loss in iteration no. 117422 ==> 0.318592495136731\n",
            "Loss in iteration no. 117423 ==> 0.31859231723186504\n",
            "Loss in iteration no. 117424 ==> 0.3185921393305306\n",
            "Loss in iteration no. 117425 ==> 0.318591961432727\n",
            "Loss in iteration no. 117426 ==> 0.3185917835384546\n",
            "Loss in iteration no. 117427 ==> 0.3185916056477132\n",
            "Loss in iteration no. 117428 ==> 0.31859142776050264\n",
            "Loss in iteration no. 117429 ==> 0.31859124987682297\n",
            "Loss in iteration no. 117430 ==> 0.3185910719966737\n",
            "Loss in iteration no. 117431 ==> 0.3185908941200552\n",
            "Loss in iteration no. 117432 ==> 0.3185907162469672\n",
            "Loss in iteration no. 117433 ==> 0.3185905383774097\n",
            "Loss in iteration no. 117434 ==> 0.31859036051138245\n",
            "Loss in iteration no. 117435 ==> 0.3185901826488853\n",
            "Loss in iteration no. 117436 ==> 0.3185900047899184\n",
            "Loss in iteration no. 117437 ==> 0.3185898269344816\n",
            "Loss in iteration no. 117438 ==> 0.3185896490825748\n",
            "Loss in iteration no. 117439 ==> 0.3185894712341978\n",
            "Loss in iteration no. 117440 ==> 0.31858929338935066\n",
            "Loss in iteration no. 117441 ==> 0.3185891155480331\n",
            "Loss in iteration no. 117442 ==> 0.31858893771024516\n",
            "Loss in iteration no. 117443 ==> 0.3185887598759867\n",
            "Loss in iteration no. 117444 ==> 0.3185885820452577\n",
            "Loss in iteration no. 117445 ==> 0.3185884042180581\n",
            "Loss in iteration no. 117446 ==> 0.3185882263943877\n",
            "Loss in iteration no. 117447 ==> 0.3185880485742463\n",
            "Loss in iteration no. 117448 ==> 0.3185878707576342\n",
            "Loss in iteration no. 117449 ==> 0.3185876929445509\n",
            "Loss in iteration no. 117450 ==> 0.3185875151349965\n",
            "Loss in iteration no. 117451 ==> 0.31858733732897093\n",
            "Loss in iteration no. 117452 ==> 0.31858715952647404\n",
            "Loss in iteration no. 117453 ==> 0.31858698172750577\n",
            "Loss in iteration no. 117454 ==> 0.31858680393206595\n",
            "Loss in iteration no. 117455 ==> 0.3185866261401546\n",
            "Loss in iteration no. 117456 ==> 0.3185864483517717\n",
            "Loss in iteration no. 117457 ==> 0.3185862705669168\n",
            "Loss in iteration no. 117458 ==> 0.31858609278559025\n",
            "Loss in iteration no. 117459 ==> 0.31858591500779165\n",
            "Loss in iteration no. 117460 ==> 0.3185857372335211\n",
            "Loss in iteration no. 117461 ==> 0.31858555946277844\n",
            "Loss in iteration no. 117462 ==> 0.31858538169556355\n",
            "Loss in iteration no. 117463 ==> 0.31858520393187634\n",
            "Loss in iteration no. 117464 ==> 0.31858502617171675\n",
            "Loss in iteration no. 117465 ==> 0.31858484841508483\n",
            "Loss in iteration no. 117466 ==> 0.31858467066198004\n",
            "Loss in iteration no. 117467 ==> 0.31858449291240265\n",
            "Loss in iteration no. 117468 ==> 0.31858431516635266\n",
            "Loss in iteration no. 117469 ==> 0.3185841374238298\n",
            "Loss in iteration no. 117470 ==> 0.31858395968483394\n",
            "Loss in iteration no. 117471 ==> 0.3185837819493653\n",
            "Loss in iteration no. 117472 ==> 0.3185836042174234\n",
            "Loss in iteration no. 117473 ==> 0.3185834264890081\n",
            "Loss in iteration no. 117474 ==> 0.31858324876411975\n",
            "Loss in iteration no. 117475 ==> 0.3185830710427578\n",
            "Loss in iteration no. 117476 ==> 0.3185828933249226\n",
            "Loss in iteration no. 117477 ==> 0.3185827156106137\n",
            "Loss in iteration no. 117478 ==> 0.3185825378998312\n",
            "Loss in iteration no. 117479 ==> 0.31858236019257485\n",
            "Loss in iteration no. 117480 ==> 0.3185821824888449\n",
            "Loss in iteration no. 117481 ==> 0.3185820047886408\n",
            "Loss in iteration no. 117482 ==> 0.31858182709196287\n",
            "Loss in iteration no. 117483 ==> 0.3185816493988106\n",
            "Loss in iteration no. 117484 ==> 0.31858147170918427\n",
            "Loss in iteration no. 117485 ==> 0.3185812940230837\n",
            "Loss in iteration no. 117486 ==> 0.31858111634050873\n",
            "Loss in iteration no. 117487 ==> 0.3185809386614592\n",
            "Loss in iteration no. 117488 ==> 0.3185807609859353\n",
            "Loss in iteration no. 117489 ==> 0.3185805833139366\n",
            "Loss in iteration no. 117490 ==> 0.3185804056454632\n",
            "Loss in iteration no. 117491 ==> 0.3185802279805149\n",
            "Loss in iteration no. 117492 ==> 0.3185800503190918\n",
            "Loss in iteration no. 117493 ==> 0.3185798726611936\n",
            "Loss in iteration no. 117494 ==> 0.3185796950068204\n",
            "Loss in iteration no. 117495 ==> 0.31857951735597195\n",
            "Loss in iteration no. 117496 ==> 0.3185793397086481\n",
            "Loss in iteration no. 117497 ==> 0.3185791620648491\n",
            "Loss in iteration no. 117498 ==> 0.3185789844245746\n",
            "Loss in iteration no. 117499 ==> 0.31857880678782446\n",
            "Loss in iteration no. 117500 ==> 0.31857862915459867\n",
            "Loss in iteration no. 117501 ==> 0.3185784515248973\n",
            "Loss in iteration no. 117502 ==> 0.3185782738987199\n",
            "Loss in iteration no. 117503 ==> 0.31857809627606687\n",
            "Loss in iteration no. 117504 ==> 0.31857791865693763\n",
            "Loss in iteration no. 117505 ==> 0.31857774104133235\n",
            "Loss in iteration no. 117506 ==> 0.31857756342925087\n",
            "Loss in iteration no. 117507 ==> 0.31857738582069317\n",
            "Loss in iteration no. 117508 ==> 0.3185772082156588\n",
            "Loss in iteration no. 117509 ==> 0.31857703061414844\n",
            "Loss in iteration no. 117510 ==> 0.3185768530161613\n",
            "Loss in iteration no. 117511 ==> 0.3185766754216976\n",
            "Loss in iteration no. 117512 ==> 0.318576497830757\n",
            "Loss in iteration no. 117513 ==> 0.3185763202433397\n",
            "Loss in iteration no. 117514 ==> 0.3185761426594456\n",
            "Loss in iteration no. 117515 ==> 0.31857596507907443\n",
            "Loss in iteration no. 117516 ==> 0.318575787502226\n",
            "Loss in iteration no. 117517 ==> 0.31857560992890077\n",
            "Loss in iteration no. 117518 ==> 0.3185754323590981\n",
            "Loss in iteration no. 117519 ==> 0.31857525479281784\n",
            "Loss in iteration no. 117520 ==> 0.3185750772300604\n",
            "Loss in iteration no. 117521 ==> 0.3185748996708254\n",
            "Loss in iteration no. 117522 ==> 0.31857472211511273\n",
            "Loss in iteration no. 117523 ==> 0.31857454456292233\n",
            "Loss in iteration no. 117524 ==> 0.3185743670142541\n",
            "Loss in iteration no. 117525 ==> 0.318574189469108\n",
            "Loss in iteration no. 117526 ==> 0.31857401192748397\n",
            "Loss in iteration no. 117527 ==> 0.3185738343893818\n",
            "Loss in iteration no. 117528 ==> 0.31857365685480155\n",
            "Loss in iteration no. 117529 ==> 0.3185734793237431\n",
            "Loss in iteration no. 117530 ==> 0.3185733017962061\n",
            "Loss in iteration no. 117531 ==> 0.31857312427219064\n",
            "Loss in iteration no. 117532 ==> 0.31857294675169673\n",
            "Loss in iteration no. 117533 ==> 0.3185727692347242\n",
            "Loss in iteration no. 117534 ==> 0.31857259172127295\n",
            "Loss in iteration no. 117535 ==> 0.31857241421134297\n",
            "Loss in iteration no. 117536 ==> 0.3185722367049342\n",
            "Loss in iteration no. 117537 ==> 0.31857205920204634\n",
            "Loss in iteration no. 117538 ==> 0.3185718817026794\n",
            "Loss in iteration no. 117539 ==> 0.3185717042068333\n",
            "Loss in iteration no. 117540 ==> 0.318571526714508\n",
            "Loss in iteration no. 117541 ==> 0.3185713492257031\n",
            "Loss in iteration no. 117542 ==> 0.318571171740419\n",
            "Loss in iteration no. 117543 ==> 0.3185709942586555\n",
            "Loss in iteration no. 117544 ==> 0.3185708167804121\n",
            "Loss in iteration no. 117545 ==> 0.31857063930568924\n",
            "Loss in iteration no. 117546 ==> 0.31857046183448645\n",
            "Loss in iteration no. 117547 ==> 0.3185702843668038\n",
            "Loss in iteration no. 117548 ==> 0.3185701069026412\n",
            "Loss in iteration no. 117549 ==> 0.31856992944199863\n",
            "Loss in iteration no. 117550 ==> 0.31856975198487586\n",
            "Loss in iteration no. 117551 ==> 0.3185695745312727\n",
            "Loss in iteration no. 117552 ==> 0.3185693970811894\n",
            "Loss in iteration no. 117553 ==> 0.31856921963462553\n",
            "Loss in iteration no. 117554 ==> 0.31856904219158133\n",
            "Loss in iteration no. 117555 ==> 0.31856886475205637\n",
            "Loss in iteration no. 117556 ==> 0.31856868731605065\n",
            "Loss in iteration no. 117557 ==> 0.3185685098835643\n",
            "Loss in iteration no. 117558 ==> 0.318568332454597\n",
            "Loss in iteration no. 117559 ==> 0.318568155029149\n",
            "Loss in iteration no. 117560 ==> 0.31856797760721955\n",
            "Loss in iteration no. 117561 ==> 0.3185678001888092\n",
            "Loss in iteration no. 117562 ==> 0.3185676227739176\n",
            "Loss in iteration no. 117563 ==> 0.31856744536254455\n",
            "Loss in iteration no. 117564 ==> 0.31856726795469015\n",
            "Loss in iteration no. 117565 ==> 0.3185670905503543\n",
            "Loss in iteration no. 117566 ==> 0.31856691314953683\n",
            "Loss in iteration no. 117567 ==> 0.31856673575223765\n",
            "Loss in iteration no. 117568 ==> 0.31856655835845665\n",
            "Loss in iteration no. 117569 ==> 0.318566380968194\n",
            "Loss in iteration no. 117570 ==> 0.3185662035814493\n",
            "Loss in iteration no. 117571 ==> 0.3185660261982224\n",
            "Loss in iteration no. 117572 ==> 0.3185658488185134\n",
            "Loss in iteration no. 117573 ==> 0.31856567144232234\n",
            "Loss in iteration no. 117574 ==> 0.31856549406964885\n",
            "Loss in iteration no. 117575 ==> 0.318565316700493\n",
            "Loss in iteration no. 117576 ==> 0.31856513933485475\n",
            "Loss in iteration no. 117577 ==> 0.3185649619727337\n",
            "Loss in iteration no. 117578 ==> 0.31856478461413007\n",
            "Loss in iteration no. 117579 ==> 0.31856460725904373\n",
            "Loss in iteration no. 117580 ==> 0.3185644299074745\n",
            "Loss in iteration no. 117581 ==> 0.31856425255942233\n",
            "Loss in iteration no. 117582 ==> 0.31856407521488717\n",
            "Loss in iteration no. 117583 ==> 0.3185638978738689\n",
            "Loss in iteration no. 117584 ==> 0.3185637205363672\n",
            "Loss in iteration no. 117585 ==> 0.3185635432023824\n",
            "Loss in iteration no. 117586 ==> 0.31856336587191425\n",
            "Loss in iteration no. 117587 ==> 0.3185631885449625\n",
            "Loss in iteration no. 117588 ==> 0.31856301122152714\n",
            "Loss in iteration no. 117589 ==> 0.3185628339016082\n",
            "Loss in iteration no. 117590 ==> 0.31856265658520544\n",
            "Loss in iteration no. 117591 ==> 0.318562479272319\n",
            "Loss in iteration no. 117592 ==> 0.3185623019629484\n",
            "Loss in iteration no. 117593 ==> 0.31856212465709394\n",
            "Loss in iteration no. 117594 ==> 0.3185619473547553\n",
            "Loss in iteration no. 117595 ==> 0.31856177005593256\n",
            "Loss in iteration no. 117596 ==> 0.31856159276062535\n",
            "Loss in iteration no. 117597 ==> 0.3185614154688338\n",
            "Loss in iteration no. 117598 ==> 0.3185612381805579\n",
            "Loss in iteration no. 117599 ==> 0.31856106089579733\n",
            "Loss in iteration no. 117600 ==> 0.3185608836145521\n",
            "Loss in iteration no. 117601 ==> 0.3185607063368221\n",
            "Loss in iteration no. 117602 ==> 0.31856052906260734\n",
            "Loss in iteration no. 117603 ==> 0.3185603517919077\n",
            "Loss in iteration no. 117604 ==> 0.31856017452472296\n",
            "Loss in iteration no. 117605 ==> 0.31855999726105316\n",
            "Loss in iteration no. 117606 ==> 0.3185598200008981\n",
            "Loss in iteration no. 117607 ==> 0.31855964274425774\n",
            "Loss in iteration no. 117608 ==> 0.3185594654911321\n",
            "Loss in iteration no. 117609 ==> 0.31855928824152113\n",
            "Loss in iteration no. 117610 ==> 0.3185591109954243\n",
            "Loss in iteration no. 117611 ==> 0.3185589337528421\n",
            "Loss in iteration no. 117612 ==> 0.31855875651377397\n",
            "Loss in iteration no. 117613 ==> 0.3185585792782202\n",
            "Loss in iteration no. 117614 ==> 0.31855840204618036\n",
            "Loss in iteration no. 117615 ==> 0.3185582248176545\n",
            "Loss in iteration no. 117616 ==> 0.31855804759264245\n",
            "Loss in iteration no. 117617 ==> 0.31855787037114447\n",
            "Loss in iteration no. 117618 ==> 0.31855769315316\n",
            "Loss in iteration no. 117619 ==> 0.31855751593868936\n",
            "Loss in iteration no. 117620 ==> 0.3185573387277323\n",
            "Loss in iteration no. 117621 ==> 0.3185571615202885\n",
            "Loss in iteration no. 117622 ==> 0.31855698431635815\n",
            "Loss in iteration no. 117623 ==> 0.3185568071159411\n",
            "Loss in iteration no. 117624 ==> 0.31855662991903716\n",
            "Loss in iteration no. 117625 ==> 0.3185564527256464\n",
            "Loss in iteration no. 117626 ==> 0.31855627553576865\n",
            "Loss in iteration no. 117627 ==> 0.3185560983494039\n",
            "Loss in iteration no. 117628 ==> 0.3185559211665518\n",
            "Loss in iteration no. 117629 ==> 0.3185557439872125\n",
            "Loss in iteration no. 117630 ==> 0.31855556681138586\n",
            "Loss in iteration no. 117631 ==> 0.3185553896390718\n",
            "Loss in iteration no. 117632 ==> 0.31855521247027\n",
            "Loss in iteration no. 117633 ==> 0.3185550353049808\n",
            "Loss in iteration no. 117634 ==> 0.318554858143204\n",
            "Loss in iteration no. 117635 ==> 0.3185546809849392\n",
            "Loss in iteration no. 117636 ==> 0.31855450383018646\n",
            "Loss in iteration no. 117637 ==> 0.318554326678946\n",
            "Loss in iteration no. 117638 ==> 0.3185541495312173\n",
            "Loss in iteration no. 117639 ==> 0.3185539723870003\n",
            "Loss in iteration no. 117640 ==> 0.3185537952462953\n",
            "Loss in iteration no. 117641 ==> 0.31855361810910177\n",
            "Loss in iteration no. 117642 ==> 0.31855344097542\n",
            "Loss in iteration no. 117643 ==> 0.31855326384524957\n",
            "Loss in iteration no. 117644 ==> 0.31855308671859056\n",
            "Loss in iteration no. 117645 ==> 0.31855290959544275\n",
            "Loss in iteration no. 117646 ==> 0.31855273247580634\n",
            "Loss in iteration no. 117647 ==> 0.31855255535968097\n",
            "Loss in iteration no. 117648 ==> 0.3185523782470666\n",
            "Loss in iteration no. 117649 ==> 0.3185522011379631\n",
            "Loss in iteration no. 117650 ==> 0.3185520240323706\n",
            "Loss in iteration no. 117651 ==> 0.3185518469302887\n",
            "Loss in iteration no. 117652 ==> 0.31855166983171773\n",
            "Loss in iteration no. 117653 ==> 0.3185514927366571\n",
            "Loss in iteration no. 117654 ==> 0.3185513156451071\n",
            "Loss in iteration no. 117655 ==> 0.31855113855706735\n",
            "Loss in iteration no. 117656 ==> 0.318550961472538\n",
            "Loss in iteration no. 117657 ==> 0.3185507843915189\n",
            "Loss in iteration no. 117658 ==> 0.31855060731400986\n",
            "Loss in iteration no. 117659 ==> 0.31855043024001095\n",
            "Loss in iteration no. 117660 ==> 0.318550253169522\n",
            "Loss in iteration no. 117661 ==> 0.31855007610254277\n",
            "Loss in iteration no. 117662 ==> 0.3185498990390734\n",
            "Loss in iteration no. 117663 ==> 0.31854972197911374\n",
            "Loss in iteration no. 117664 ==> 0.31854954492266385\n",
            "Loss in iteration no. 117665 ==> 0.31854936786972315\n",
            "Loss in iteration no. 117666 ==> 0.31854919082029187\n",
            "Loss in iteration no. 117667 ==> 0.31854901377437017\n",
            "Loss in iteration no. 117668 ==> 0.31854883673195755\n",
            "Loss in iteration no. 117669 ==> 0.318548659693054\n",
            "Loss in iteration no. 117670 ==> 0.3185484826576598\n",
            "Loss in iteration no. 117671 ==> 0.3185483056257743\n",
            "Loss in iteration no. 117672 ==> 0.31854812859739756\n",
            "Loss in iteration no. 117673 ==> 0.31854795157252985\n",
            "Loss in iteration no. 117674 ==> 0.31854777455117067\n",
            "Loss in iteration no. 117675 ==> 0.31854759753332024\n",
            "Loss in iteration no. 117676 ==> 0.3185474205189782\n",
            "Loss in iteration no. 117677 ==> 0.31854724350814473\n",
            "Loss in iteration no. 117678 ==> 0.31854706650081943\n",
            "Loss in iteration no. 117679 ==> 0.3185468894970025\n",
            "Loss in iteration no. 117680 ==> 0.31854671249669375\n",
            "Loss in iteration no. 117681 ==> 0.3185465354998929\n",
            "Loss in iteration no. 117682 ==> 0.3185463585066002\n",
            "Loss in iteration no. 117683 ==> 0.3185461815168153\n",
            "Loss in iteration no. 117684 ==> 0.3185460045305383\n",
            "Loss in iteration no. 117685 ==> 0.3185458275477689\n",
            "Loss in iteration no. 117686 ==> 0.31854565056850703\n",
            "Loss in iteration no. 117687 ==> 0.31854547359275276\n",
            "Loss in iteration no. 117688 ==> 0.3185452966205062\n",
            "Loss in iteration no. 117689 ==> 0.3185451196517666\n",
            "Loss in iteration no. 117690 ==> 0.31854494268653455\n",
            "Loss in iteration no. 117691 ==> 0.31854476572480944\n",
            "Loss in iteration no. 117692 ==> 0.3185445887665916\n",
            "Loss in iteration no. 117693 ==> 0.3185444118118806\n",
            "Loss in iteration no. 117694 ==> 0.31854423486067657\n",
            "Loss in iteration no. 117695 ==> 0.3185440579129794\n",
            "Loss in iteration no. 117696 ==> 0.31854388096878883\n",
            "Loss in iteration no. 117697 ==> 0.318543704028105\n",
            "Loss in iteration no. 117698 ==> 0.31854352709092765\n",
            "Loss in iteration no. 117699 ==> 0.3185433501572567\n",
            "Loss in iteration no. 117700 ==> 0.31854317322709225\n",
            "Loss in iteration no. 117701 ==> 0.318542996300434\n",
            "Loss in iteration no. 117702 ==> 0.31854281937728185\n",
            "Loss in iteration no. 117703 ==> 0.31854264245763597\n",
            "Loss in iteration no. 117704 ==> 0.31854246554149596\n",
            "Loss in iteration no. 117705 ==> 0.3185422886288619\n",
            "Loss in iteration no. 117706 ==> 0.31854211171973357\n",
            "Loss in iteration no. 117707 ==> 0.3185419348141111\n",
            "Loss in iteration no. 117708 ==> 0.31854175791199424\n",
            "Loss in iteration no. 117709 ==> 0.318541581013383\n",
            "Loss in iteration no. 117710 ==> 0.31854140411827714\n",
            "Loss in iteration no. 117711 ==> 0.31854122722667677\n",
            "Loss in iteration no. 117712 ==> 0.31854105033858143\n",
            "Loss in iteration no. 117713 ==> 0.3185408734539915\n",
            "Loss in iteration no. 117714 ==> 0.3185406965729067\n",
            "Loss in iteration no. 117715 ==> 0.31854051969532676\n",
            "Loss in iteration no. 117716 ==> 0.31854034282125193\n",
            "Loss in iteration no. 117717 ==> 0.31854016595068174\n",
            "Loss in iteration no. 117718 ==> 0.31853998908361636\n",
            "Loss in iteration no. 117719 ==> 0.3185398122200557\n",
            "Loss in iteration no. 117720 ==> 0.3185396353599997\n",
            "Loss in iteration no. 117721 ==> 0.3185394585034479\n",
            "Loss in iteration no. 117722 ==> 0.3185392816504007\n",
            "Loss in iteration no. 117723 ==> 0.3185391048008579\n",
            "Loss in iteration no. 117724 ==> 0.31853892795481903\n",
            "Loss in iteration no. 117725 ==> 0.3185387511122844\n",
            "Loss in iteration no. 117726 ==> 0.31853857427325394\n",
            "Loss in iteration no. 117727 ==> 0.3185383974377272\n",
            "Loss in iteration no. 117728 ==> 0.31853822060570447\n",
            "Loss in iteration no. 117729 ==> 0.3185380437771854\n",
            "Loss in iteration no. 117730 ==> 0.31853786695217007\n",
            "Loss in iteration no. 117731 ==> 0.31853769013065825\n",
            "Loss in iteration no. 117732 ==> 0.31853751331264984\n",
            "Loss in iteration no. 117733 ==> 0.31853733649814514\n",
            "Loss in iteration no. 117734 ==> 0.31853715968714347\n",
            "Loss in iteration no. 117735 ==> 0.3185369828796451\n",
            "Loss in iteration no. 117736 ==> 0.31853680607564994\n",
            "Loss in iteration no. 117737 ==> 0.3185366292751579\n",
            "Loss in iteration no. 117738 ==> 0.31853645247816853\n",
            "Loss in iteration no. 117739 ==> 0.3185362756846824\n",
            "Loss in iteration no. 117740 ==> 0.31853609889469875\n",
            "Loss in iteration no. 117741 ==> 0.31853592210821785\n",
            "Loss in iteration no. 117742 ==> 0.3185357453252396\n",
            "Loss in iteration no. 117743 ==> 0.31853556854576376\n",
            "Loss in iteration no. 117744 ==> 0.3185353917697904\n",
            "Loss in iteration no. 117745 ==> 0.3185352149973193\n",
            "Loss in iteration no. 117746 ==> 0.31853503822835066\n",
            "Loss in iteration no. 117747 ==> 0.31853486146288407\n",
            "Loss in iteration no. 117748 ==> 0.31853468470091945\n",
            "Loss in iteration no. 117749 ==> 0.31853450794245686\n",
            "Loss in iteration no. 117750 ==> 0.3185343311874961\n",
            "Loss in iteration no. 117751 ==> 0.3185341544360372\n",
            "Loss in iteration no. 117752 ==> 0.31853397768808\n",
            "Loss in iteration no. 117753 ==> 0.31853380094362427\n",
            "Loss in iteration no. 117754 ==> 0.3185336242026701\n",
            "Loss in iteration no. 117755 ==> 0.3185334474652175\n",
            "Loss in iteration no. 117756 ==> 0.31853327073126614\n",
            "Loss in iteration no. 117757 ==> 0.31853309400081625\n",
            "Loss in iteration no. 117758 ==> 0.3185329172738672\n",
            "Loss in iteration no. 117759 ==> 0.3185327405504195\n",
            "Loss in iteration no. 117760 ==> 0.3185325638304726\n",
            "Loss in iteration no. 117761 ==> 0.3185323871140267\n",
            "Loss in iteration no. 117762 ==> 0.3185322104010816\n",
            "Loss in iteration no. 117763 ==> 0.318532033691637\n",
            "Loss in iteration no. 117764 ==> 0.31853185698569325\n",
            "Loss in iteration no. 117765 ==> 0.3185316802832501\n",
            "Loss in iteration no. 117766 ==> 0.3185315035843072\n",
            "Loss in iteration no. 117767 ==> 0.3185313268888648\n",
            "Loss in iteration no. 117768 ==> 0.31853115019692263\n",
            "Loss in iteration no. 117769 ==> 0.3185309735084806\n",
            "Loss in iteration no. 117770 ==> 0.3185307968235387\n",
            "Loss in iteration no. 117771 ==> 0.31853062014209677\n",
            "Loss in iteration no. 117772 ==> 0.31853044346415477\n",
            "Loss in iteration no. 117773 ==> 0.3185302667897126\n",
            "Loss in iteration no. 117774 ==> 0.3185300901187701\n",
            "Loss in iteration no. 117775 ==> 0.3185299134513273\n",
            "Loss in iteration no. 117776 ==> 0.318529736787384\n",
            "Loss in iteration no. 117777 ==> 0.31852956012694034\n",
            "Loss in iteration no. 117778 ==> 0.31852938346999593\n",
            "Loss in iteration no. 117779 ==> 0.31852920681655084\n",
            "Loss in iteration no. 117780 ==> 0.3185290301666049\n",
            "Loss in iteration no. 117781 ==> 0.31852885352015803\n",
            "Loss in iteration no. 117782 ==> 0.3185286768772102\n",
            "Loss in iteration no. 117783 ==> 0.3185285002377614\n",
            "Loss in iteration no. 117784 ==> 0.3185283236018113\n",
            "Loss in iteration no. 117785 ==> 0.3185281469693601\n",
            "Loss in iteration no. 117786 ==> 0.3185279703404074\n",
            "Loss in iteration no. 117787 ==> 0.3185277937149533\n",
            "Loss in iteration no. 117788 ==> 0.31852761709299776\n",
            "Loss in iteration no. 117789 ==> 0.3185274404745406\n",
            "Loss in iteration no. 117790 ==> 0.3185272638595816\n",
            "Loss in iteration no. 117791 ==> 0.31852708724812095\n",
            "Loss in iteration no. 117792 ==> 0.3185269106401584\n",
            "Loss in iteration no. 117793 ==> 0.31852673403569387\n",
            "Loss in iteration no. 117794 ==> 0.31852655743472724\n",
            "Loss in iteration no. 117795 ==> 0.3185263808372586\n",
            "Loss in iteration no. 117796 ==> 0.3185262042432876\n",
            "Loss in iteration no. 117797 ==> 0.31852602765281424\n",
            "Loss in iteration no. 117798 ==> 0.31852585106583864\n",
            "Loss in iteration no. 117799 ==> 0.3185256744823604\n",
            "Loss in iteration no. 117800 ==> 0.3185254979023795\n",
            "Loss in iteration no. 117801 ==> 0.318525321325896\n",
            "Loss in iteration no. 117802 ==> 0.3185251447529099\n",
            "Loss in iteration no. 117803 ==> 0.3185249681834207\n",
            "Loss in iteration no. 117804 ==> 0.31852479161742864\n",
            "Loss in iteration no. 117805 ==> 0.3185246150549336\n",
            "Loss in iteration no. 117806 ==> 0.3185244384959353\n",
            "Loss in iteration no. 117807 ==> 0.31852426194043376\n",
            "Loss in iteration no. 117808 ==> 0.3185240853884291\n",
            "Loss in iteration no. 117809 ==> 0.31852390883992104\n",
            "Loss in iteration no. 117810 ==> 0.31852373229490927\n",
            "Loss in iteration no. 117811 ==> 0.31852355575339414\n",
            "Loss in iteration no. 117812 ==> 0.31852337921537505\n",
            "Loss in iteration no. 117813 ==> 0.3185232026808525\n",
            "Loss in iteration no. 117814 ==> 0.318523026149826\n",
            "Loss in iteration no. 117815 ==> 0.31852284962229555\n",
            "Loss in iteration no. 117816 ==> 0.31852267309826116\n",
            "Loss in iteration no. 117817 ==> 0.31852249657772264\n",
            "Loss in iteration no. 117818 ==> 0.3185223200606798\n",
            "Loss in iteration no. 117819 ==> 0.3185221435471327\n",
            "Loss in iteration no. 117820 ==> 0.3185219670370813\n",
            "Loss in iteration no. 117821 ==> 0.3185217905305254\n",
            "Loss in iteration no. 117822 ==> 0.31852161402746487\n",
            "Loss in iteration no. 117823 ==> 0.31852143752789985\n",
            "Loss in iteration no. 117824 ==> 0.31852126103183\n",
            "Loss in iteration no. 117825 ==> 0.3185210845392552\n",
            "Loss in iteration no. 117826 ==> 0.3185209080501757\n",
            "Loss in iteration no. 117827 ==> 0.318520731564591\n",
            "Loss in iteration no. 117828 ==> 0.3185205550825014\n",
            "Loss in iteration no. 117829 ==> 0.3185203786039064\n",
            "Loss in iteration no. 117830 ==> 0.3185202021288064\n",
            "Loss in iteration no. 117831 ==> 0.31852002565720083\n",
            "Loss in iteration no. 117832 ==> 0.3185198491890899\n",
            "Loss in iteration no. 117833 ==> 0.3185196727244733\n",
            "Loss in iteration no. 117834 ==> 0.31851949626335135\n",
            "Loss in iteration no. 117835 ==> 0.31851931980572334\n",
            "Loss in iteration no. 117836 ==> 0.3185191433515896\n",
            "Loss in iteration no. 117837 ==> 0.31851896690095005\n",
            "Loss in iteration no. 117838 ==> 0.31851879045380455\n",
            "Loss in iteration no. 117839 ==> 0.31851861401015286\n",
            "Loss in iteration no. 117840 ==> 0.3185184375699951\n",
            "Loss in iteration no. 117841 ==> 0.3185182611333311\n",
            "Loss in iteration no. 117842 ==> 0.31851808470016046\n",
            "Loss in iteration no. 117843 ==> 0.31851790827048376\n",
            "Loss in iteration no. 117844 ==> 0.3185177318443003\n",
            "Loss in iteration no. 117845 ==> 0.3185175554216104\n",
            "Loss in iteration no. 117846 ==> 0.3185173790024136\n",
            "Loss in iteration no. 117847 ==> 0.31851720258671024\n",
            "Loss in iteration no. 117848 ==> 0.31851702617449973\n",
            "Loss in iteration no. 117849 ==> 0.31851684976578243\n",
            "Loss in iteration no. 117850 ==> 0.3185166733605581\n",
            "Loss in iteration no. 117851 ==> 0.31851649695882656\n",
            "Loss in iteration no. 117852 ==> 0.3185163205605879\n",
            "Loss in iteration no. 117853 ==> 0.3185161441658417\n",
            "Loss in iteration no. 117854 ==> 0.3185159677745881\n",
            "Loss in iteration no. 117855 ==> 0.3185157913868271\n",
            "Loss in iteration no. 117856 ==> 0.3185156150025585\n",
            "Loss in iteration no. 117857 ==> 0.31851543862178217\n",
            "Loss in iteration no. 117858 ==> 0.3185152622444981\n",
            "Loss in iteration no. 117859 ==> 0.31851508587070615\n",
            "Loss in iteration no. 117860 ==> 0.3185149095004063\n",
            "Loss in iteration no. 117861 ==> 0.3185147331335984\n",
            "Loss in iteration no. 117862 ==> 0.3185145567702822\n",
            "Loss in iteration no. 117863 ==> 0.31851438041045804\n",
            "Loss in iteration no. 117864 ==> 0.31851420405412534\n",
            "Loss in iteration no. 117865 ==> 0.31851402770128423\n",
            "Loss in iteration no. 117866 ==> 0.31851385135193483\n",
            "Loss in iteration no. 117867 ==> 0.31851367500607675\n",
            "Loss in iteration no. 117868 ==> 0.3185134986637101\n",
            "Loss in iteration no. 117869 ==> 0.31851332232483454\n",
            "Loss in iteration no. 117870 ==> 0.3185131459894502\n",
            "Loss in iteration no. 117871 ==> 0.31851296965755693\n",
            "Loss in iteration no. 117872 ==> 0.3185127933291546\n",
            "Loss in iteration no. 117873 ==> 0.31851261700424327\n",
            "Loss in iteration no. 117874 ==> 0.31851244068282264\n",
            "Loss in iteration no. 117875 ==> 0.3185122643648928\n",
            "Loss in iteration no. 117876 ==> 0.31851208805045367\n",
            "Loss in iteration no. 117877 ==> 0.3185119117395049\n",
            "Loss in iteration no. 117878 ==> 0.3185117354320465\n",
            "Loss in iteration no. 117879 ==> 0.31851155912807855\n",
            "Loss in iteration no. 117880 ==> 0.31851138282760083\n",
            "Loss in iteration no. 117881 ==> 0.31851120653061327\n",
            "Loss in iteration no. 117882 ==> 0.31851103023711597\n",
            "Loss in iteration no. 117883 ==> 0.31851085394710854\n",
            "Loss in iteration no. 117884 ==> 0.3185106776605909\n",
            "Loss in iteration no. 117885 ==> 0.3185105013775632\n",
            "Loss in iteration no. 117886 ==> 0.3185103250980253\n",
            "Loss in iteration no. 117887 ==> 0.31851014882197703\n",
            "Loss in iteration no. 117888 ==> 0.3185099725494182\n",
            "Loss in iteration no. 117889 ==> 0.31850979628034887\n",
            "Loss in iteration no. 117890 ==> 0.31850962001476885\n",
            "Loss in iteration no. 117891 ==> 0.31850944375267826\n",
            "Loss in iteration no. 117892 ==> 0.31850926749407665\n",
            "Loss in iteration no. 117893 ==> 0.3185090912389643\n",
            "Loss in iteration no. 117894 ==> 0.31850891498734096\n",
            "Loss in iteration no. 117895 ==> 0.31850873873920665\n",
            "Loss in iteration no. 117896 ==> 0.31850856249456094\n",
            "Loss in iteration no. 117897 ==> 0.3185083862534041\n",
            "Loss in iteration no. 117898 ==> 0.3185082100157359\n",
            "Loss in iteration no. 117899 ==> 0.3185080337815563\n",
            "Loss in iteration no. 117900 ==> 0.31850785755086525\n",
            "Loss in iteration no. 117901 ==> 0.31850768132366253\n",
            "Loss in iteration no. 117902 ==> 0.318507505099948\n",
            "Loss in iteration no. 117903 ==> 0.3185073288797218\n",
            "Loss in iteration no. 117904 ==> 0.3185071526629836\n",
            "Loss in iteration no. 117905 ==> 0.31850697644973347\n",
            "Loss in iteration no. 117906 ==> 0.3185068002399714\n",
            "Loss in iteration no. 117907 ==> 0.31850662403369717\n",
            "Loss in iteration no. 117908 ==> 0.3185064478309106\n",
            "Loss in iteration no. 117909 ==> 0.31850627163161177\n",
            "Loss in iteration no. 117910 ==> 0.31850609543580066\n",
            "Loss in iteration no. 117911 ==> 0.3185059192434769\n",
            "Loss in iteration no. 117912 ==> 0.3185057430546406\n",
            "Loss in iteration no. 117913 ==> 0.3185055668692916\n",
            "Loss in iteration no. 117914 ==> 0.31850539068742983\n",
            "Loss in iteration no. 117915 ==> 0.31850521450905533\n",
            "Loss in iteration no. 117916 ==> 0.3185050383341677\n",
            "Loss in iteration no. 117917 ==> 0.31850486216276697\n",
            "Loss in iteration no. 117918 ==> 0.31850468599485326\n",
            "Loss in iteration no. 117919 ==> 0.31850450983042633\n",
            "Loss in iteration no. 117920 ==> 0.31850433366948605\n",
            "Loss in iteration no. 117921 ==> 0.3185041575120324\n",
            "Loss in iteration no. 117922 ==> 0.3185039813580653\n",
            "Loss in iteration no. 117923 ==> 0.3185038052075847\n",
            "Loss in iteration no. 117924 ==> 0.3185036290605903\n",
            "Loss in iteration no. 117925 ==> 0.3185034529170823\n",
            "Loss in iteration no. 117926 ==> 0.31850327677706036\n",
            "Loss in iteration no. 117927 ==> 0.3185031006405245\n",
            "Loss in iteration no. 117928 ==> 0.31850292450747464\n",
            "Loss in iteration no. 117929 ==> 0.31850274837791076\n",
            "Loss in iteration no. 117930 ==> 0.31850257225183265\n",
            "Loss in iteration no. 117931 ==> 0.31850239612924014\n",
            "Loss in iteration no. 117932 ==> 0.3185022200101334\n",
            "Loss in iteration no. 117933 ==> 0.31850204389451203\n",
            "Loss in iteration no. 117934 ==> 0.3185018677823763\n",
            "Loss in iteration no. 117935 ==> 0.31850169167372583\n",
            "Loss in iteration no. 117936 ==> 0.31850151556856077\n",
            "Loss in iteration no. 117937 ==> 0.3185013394668808\n",
            "Loss in iteration no. 117938 ==> 0.3185011633686859\n",
            "Loss in iteration no. 117939 ==> 0.3185009872739759\n",
            "Loss in iteration no. 117940 ==> 0.318500811182751\n",
            "Loss in iteration no. 117941 ==> 0.3185006350950108\n",
            "Loss in iteration no. 117942 ==> 0.3185004590107554\n",
            "Loss in iteration no. 117943 ==> 0.3185002829299848\n",
            "Loss in iteration no. 117944 ==> 0.3185001068526986\n",
            "Loss in iteration no. 117945 ==> 0.3184999307788968\n",
            "Loss in iteration no. 117946 ==> 0.3184997547085795\n",
            "Loss in iteration no. 117947 ==> 0.31849957864174655\n",
            "Loss in iteration no. 117948 ==> 0.3184994025783977\n",
            "Loss in iteration no. 117949 ==> 0.31849922651853296\n",
            "Loss in iteration no. 117950 ==> 0.3184990504621523\n",
            "Loss in iteration no. 117951 ==> 0.3184988744092554\n",
            "Loss in iteration no. 117952 ==> 0.3184986983598426\n",
            "Loss in iteration no. 117953 ==> 0.3184985223139135\n",
            "Loss in iteration no. 117954 ==> 0.31849834627146806\n",
            "Loss in iteration no. 117955 ==> 0.31849817023250615\n",
            "Loss in iteration no. 117956 ==> 0.31849799419702784\n",
            "Loss in iteration no. 117957 ==> 0.31849781816503286\n",
            "Loss in iteration no. 117958 ==> 0.31849764213652126\n",
            "Loss in iteration no. 117959 ==> 0.3184974661114928\n",
            "Loss in iteration no. 117960 ==> 0.3184972900899475\n",
            "Loss in iteration no. 117961 ==> 0.31849711407188525\n",
            "Loss in iteration no. 117962 ==> 0.31849693805730606\n",
            "Loss in iteration no. 117963 ==> 0.3184967620462095\n",
            "Loss in iteration no. 117964 ==> 0.31849658603859593\n",
            "Loss in iteration no. 117965 ==> 0.318496410034465\n",
            "Loss in iteration no. 117966 ==> 0.3184962340338168\n",
            "Loss in iteration no. 117967 ==> 0.3184960580366509\n",
            "Loss in iteration no. 117968 ==> 0.31849588204296747\n",
            "Loss in iteration no. 117969 ==> 0.3184957060527665\n",
            "Loss in iteration no. 117970 ==> 0.31849553006604775\n",
            "Loss in iteration no. 117971 ==> 0.31849535408281104\n",
            "Loss in iteration no. 117972 ==> 0.31849517810305655\n",
            "Loss in iteration no. 117973 ==> 0.31849500212678394\n",
            "Loss in iteration no. 117974 ==> 0.31849482615399327\n",
            "Loss in iteration no. 117975 ==> 0.31849465018468437\n",
            "Loss in iteration no. 117976 ==> 0.3184944742188572\n",
            "Loss in iteration no. 117977 ==> 0.3184942982565117\n",
            "Loss in iteration no. 117978 ==> 0.3184941222976477\n",
            "Loss in iteration no. 117979 ==> 0.3184939463422652\n",
            "Loss in iteration no. 117980 ==> 0.31849377039036403\n",
            "Loss in iteration no. 117981 ==> 0.3184935944419441\n",
            "Loss in iteration no. 117982 ==> 0.3184934184970053\n",
            "Loss in iteration no. 117983 ==> 0.31849324255554756\n",
            "Loss in iteration no. 117984 ==> 0.318493066617571\n",
            "Loss in iteration no. 117985 ==> 0.31849289068307535\n",
            "Loss in iteration no. 117986 ==> 0.3184927147520603\n",
            "Loss in iteration no. 117987 ==> 0.3184925388245262\n",
            "Loss in iteration no. 117988 ==> 0.3184923629004727\n",
            "Loss in iteration no. 117989 ==> 0.31849218697989984\n",
            "Loss in iteration no. 117990 ==> 0.31849201106280745\n",
            "Loss in iteration no. 117991 ==> 0.31849183514919527\n",
            "Loss in iteration no. 117992 ==> 0.3184916592390635\n",
            "Loss in iteration no. 117993 ==> 0.3184914833324119\n",
            "Loss in iteration no. 117994 ==> 0.3184913074292403\n",
            "Loss in iteration no. 117995 ==> 0.318491131529549\n",
            "Loss in iteration no. 117996 ==> 0.31849095563333746\n",
            "Loss in iteration no. 117997 ==> 0.3184907797406058\n",
            "Loss in iteration no. 117998 ==> 0.31849060385135386\n",
            "Loss in iteration no. 117999 ==> 0.3184904279655816\n",
            "Loss in iteration no. 118000 ==> 0.3184902520832889\n",
            "Loss in iteration no. 118001 ==> 0.3184900762044759\n",
            "Loss in iteration no. 118002 ==> 0.318489900329142\n",
            "Loss in iteration no. 118003 ==> 0.3184897244572875\n",
            "Loss in iteration no. 118004 ==> 0.3184895485889125\n",
            "Loss in iteration no. 118005 ==> 0.31848937272401645\n",
            "Loss in iteration no. 118006 ==> 0.31848919686259936\n",
            "Loss in iteration no. 118007 ==> 0.31848902100466125\n",
            "Loss in iteration no. 118008 ==> 0.3184888451502022\n",
            "Loss in iteration no. 118009 ==> 0.3184886692992218\n",
            "Loss in iteration no. 118010 ==> 0.31848849345172003\n",
            "Loss in iteration no. 118011 ==> 0.3184883176076969\n",
            "Loss in iteration no. 118012 ==> 0.3184881417671524\n",
            "Loss in iteration no. 118013 ==> 0.3184879659300862\n",
            "Loss in iteration no. 118014 ==> 0.31848779009649836\n",
            "Loss in iteration no. 118015 ==> 0.3184876142663889\n",
            "Loss in iteration no. 118016 ==> 0.31848743843975746\n",
            "Loss in iteration no. 118017 ==> 0.3184872626166042\n",
            "Loss in iteration no. 118018 ==> 0.31848708679692883\n",
            "Loss in iteration no. 118019 ==> 0.3184869109807314\n",
            "Loss in iteration no. 118020 ==> 0.3184867351680117\n",
            "Loss in iteration no. 118021 ==> 0.31848655935876985\n",
            "Loss in iteration no. 118022 ==> 0.3184863835530055\n",
            "Loss in iteration no. 118023 ==> 0.31848620775071873\n",
            "Loss in iteration no. 118024 ==> 0.3184860319519095\n",
            "Loss in iteration no. 118025 ==> 0.3184858561565775\n",
            "Loss in iteration no. 118026 ==> 0.3184856803647229\n",
            "Loss in iteration no. 118027 ==> 0.31848550457634534\n",
            "Loss in iteration no. 118028 ==> 0.3184853287914451\n",
            "Loss in iteration no. 118029 ==> 0.31848515301002167\n",
            "Loss in iteration no. 118030 ==> 0.31848497723207525\n",
            "Loss in iteration no. 118031 ==> 0.31848480145760566\n",
            "Loss in iteration no. 118032 ==> 0.31848462568661273\n",
            "Loss in iteration no. 118033 ==> 0.3184844499190965\n",
            "Loss in iteration no. 118034 ==> 0.31848427415505676\n",
            "Loss in iteration no. 118035 ==> 0.3184840983944937\n",
            "Loss in iteration no. 118036 ==> 0.3184839226374069\n",
            "Loss in iteration no. 118037 ==> 0.3184837468837964\n",
            "Loss in iteration no. 118038 ==> 0.31848357113366227\n",
            "Loss in iteration no. 118039 ==> 0.318483395387004\n",
            "Loss in iteration no. 118040 ==> 0.3184832196438218\n",
            "Loss in iteration no. 118041 ==> 0.31848304390411564\n",
            "Loss in iteration no. 118042 ==> 0.3184828681678853\n",
            "Loss in iteration no. 118043 ==> 0.3184826924351307\n",
            "Loss in iteration no. 118044 ==> 0.31848251670585176\n",
            "Loss in iteration no. 118045 ==> 0.3184823409800485\n",
            "Loss in iteration no. 118046 ==> 0.3184821652577207\n",
            "Loss in iteration no. 118047 ==> 0.31848198953886825\n",
            "Loss in iteration no. 118048 ==> 0.31848181382349117\n",
            "Loss in iteration no. 118049 ==> 0.31848163811158936\n",
            "Loss in iteration no. 118050 ==> 0.3184814624031627\n",
            "Loss in iteration no. 118051 ==> 0.3184812866982112\n",
            "Loss in iteration no. 118052 ==> 0.3184811109967343\n",
            "Loss in iteration no. 118053 ==> 0.31848093529873256\n",
            "Loss in iteration no. 118054 ==> 0.3184807596042056\n",
            "Loss in iteration no. 118055 ==> 0.3184805839131533\n",
            "Loss in iteration no. 118056 ==> 0.3184804082255757\n",
            "Loss in iteration no. 118057 ==> 0.31848023254147245\n",
            "Loss in iteration no. 118058 ==> 0.3184800568608438\n",
            "Loss in iteration no. 118059 ==> 0.3184798811836894\n",
            "Loss in iteration no. 118060 ==> 0.3184797055100092\n",
            "Loss in iteration no. 118061 ==> 0.31847952983980327\n",
            "Loss in iteration no. 118062 ==> 0.31847935417307155\n",
            "Loss in iteration no. 118063 ==> 0.31847917850981355\n",
            "Loss in iteration no. 118064 ==> 0.3184790028500296\n",
            "Loss in iteration no. 118065 ==> 0.3184788271937194\n",
            "Loss in iteration no. 118066 ==> 0.31847865154088306\n",
            "Loss in iteration no. 118067 ==> 0.31847847589152023\n",
            "Loss in iteration no. 118068 ==> 0.318478300245631\n",
            "Loss in iteration no. 118069 ==> 0.31847812460321523\n",
            "Loss in iteration no. 118070 ==> 0.3184779489642729\n",
            "Loss in iteration no. 118071 ==> 0.31847777332880367\n",
            "Loss in iteration no. 118072 ==> 0.3184775976968077\n",
            "Loss in iteration no. 118073 ==> 0.3184774220682849\n",
            "Loss in iteration no. 118074 ==> 0.31847724644323516\n",
            "Loss in iteration no. 118075 ==> 0.3184770708216582\n",
            "Loss in iteration no. 118076 ==> 0.3184768952035541\n",
            "Loss in iteration no. 118077 ==> 0.318476719588923\n",
            "Loss in iteration no. 118078 ==> 0.31847654397776426\n",
            "Loss in iteration no. 118079 ==> 0.3184763683700782\n",
            "Loss in iteration no. 118080 ==> 0.31847619276586464\n",
            "Loss in iteration no. 118081 ==> 0.3184760171651235\n",
            "Loss in iteration no. 118082 ==> 0.31847584156785463\n",
            "Loss in iteration no. 118083 ==> 0.31847566597405796\n",
            "Loss in iteration no. 118084 ==> 0.31847549038373346\n",
            "Loss in iteration no. 118085 ==> 0.318475314796881\n",
            "Loss in iteration no. 118086 ==> 0.31847513921350046\n",
            "Loss in iteration no. 118087 ==> 0.31847496363359196\n",
            "Loss in iteration no. 118088 ==> 0.3184747880571551\n",
            "Loss in iteration no. 118089 ==> 0.31847461248418985\n",
            "Loss in iteration no. 118090 ==> 0.3184744369146963\n",
            "Loss in iteration no. 118091 ==> 0.31847426134867424\n",
            "Loss in iteration no. 118092 ==> 0.3184740857861236\n",
            "Loss in iteration no. 118093 ==> 0.31847391022704424\n",
            "Loss in iteration no. 118094 ==> 0.3184737346714362\n",
            "Loss in iteration no. 118095 ==> 0.3184735591192993\n",
            "Loss in iteration no. 118096 ==> 0.3184733835706334\n",
            "Loss in iteration no. 118097 ==> 0.31847320802543855\n",
            "Loss in iteration no. 118098 ==> 0.31847303248371467\n",
            "Loss in iteration no. 118099 ==> 0.31847285694546146\n",
            "Loss in iteration no. 118100 ==> 0.31847268141067897\n",
            "Loss in iteration no. 118101 ==> 0.3184725058793672\n",
            "Loss in iteration no. 118102 ==> 0.31847233035152595\n",
            "Loss in iteration no. 118103 ==> 0.31847215482715496\n",
            "Loss in iteration no. 118104 ==> 0.3184719793062545\n",
            "Loss in iteration no. 118105 ==> 0.3184718037888242\n",
            "Loss in iteration no. 118106 ==> 0.31847162827486425\n",
            "Loss in iteration no. 118107 ==> 0.3184714527643744\n",
            "Loss in iteration no. 118108 ==> 0.3184712772573544\n",
            "Loss in iteration no. 118109 ==> 0.3184711017538045\n",
            "Loss in iteration no. 118110 ==> 0.3184709262537242\n",
            "Loss in iteration no. 118111 ==> 0.31847075075711384\n",
            "Loss in iteration no. 118112 ==> 0.31847057526397293\n",
            "Loss in iteration no. 118113 ==> 0.3184703997743018\n",
            "Loss in iteration no. 118114 ==> 0.31847022428809996\n",
            "Loss in iteration no. 118115 ==> 0.3184700488053676\n",
            "Loss in iteration no. 118116 ==> 0.31846987332610466\n",
            "Loss in iteration no. 118117 ==> 0.31846969785031076\n",
            "Loss in iteration no. 118118 ==> 0.31846952237798604\n",
            "Loss in iteration no. 118119 ==> 0.3184693469091304\n",
            "Loss in iteration no. 118120 ==> 0.3184691714437435\n",
            "Loss in iteration no. 118121 ==> 0.3184689959818256\n",
            "Loss in iteration no. 118122 ==> 0.31846882052337655\n",
            "Loss in iteration no. 118123 ==> 0.31846864506839606\n",
            "Loss in iteration no. 118124 ==> 0.3184684696168843\n",
            "Loss in iteration no. 118125 ==> 0.3184682941688408\n",
            "Loss in iteration no. 118126 ==> 0.31846811872426595\n",
            "Loss in iteration no. 118127 ==> 0.31846794328315925\n",
            "Loss in iteration no. 118128 ==> 0.3184677678455209\n",
            "Loss in iteration no. 118129 ==> 0.31846759241135064\n",
            "Loss in iteration no. 118130 ==> 0.31846741698064845\n",
            "Loss in iteration no. 118131 ==> 0.3184672415534142\n",
            "Loss in iteration no. 118132 ==> 0.31846706612964787\n",
            "Loss in iteration no. 118133 ==> 0.3184668907093494\n",
            "Loss in iteration no. 118134 ==> 0.31846671529251847\n",
            "Loss in iteration no. 118135 ==> 0.3184665398791554\n",
            "Loss in iteration no. 118136 ==> 0.31846636446925963\n",
            "Loss in iteration no. 118137 ==> 0.3184661890628315\n",
            "Loss in iteration no. 118138 ==> 0.3184660136598704\n",
            "Loss in iteration no. 118139 ==> 0.3184658382603768\n",
            "Loss in iteration no. 118140 ==> 0.31846566286435035\n",
            "Loss in iteration no. 118141 ==> 0.318465487471791\n",
            "Loss in iteration no. 118142 ==> 0.31846531208269857\n",
            "Loss in iteration no. 118143 ==> 0.31846513669707316\n",
            "Loss in iteration no. 118144 ==> 0.3184649613149146\n",
            "Loss in iteration no. 118145 ==> 0.3184647859362226\n",
            "Loss in iteration no. 118146 ==> 0.31846461056099734\n",
            "Loss in iteration no. 118147 ==> 0.3184644351892386\n",
            "Loss in iteration no. 118148 ==> 0.31846425982094634\n",
            "Loss in iteration no. 118149 ==> 0.3184640844561205\n",
            "Loss in iteration no. 118150 ==> 0.31846390909476097\n",
            "Loss in iteration no. 118151 ==> 0.3184637337368676\n",
            "Loss in iteration no. 118152 ==> 0.31846355838244034\n",
            "Loss in iteration no. 118153 ==> 0.3184633830314789\n",
            "Loss in iteration no. 118154 ==> 0.31846320768398384\n",
            "Loss in iteration no. 118155 ==> 0.3184630323399543\n",
            "Loss in iteration no. 118156 ==> 0.3184628569993907\n",
            "Loss in iteration no. 118157 ==> 0.3184626816622925\n",
            "Loss in iteration no. 118158 ==> 0.3184625063286602\n",
            "Loss in iteration no. 118159 ==> 0.3184623309984933\n",
            "Loss in iteration no. 118160 ==> 0.31846215567179165\n",
            "Loss in iteration no. 118161 ==> 0.31846198034855555\n",
            "Loss in iteration no. 118162 ==> 0.3184618050287846\n",
            "Loss in iteration no. 118163 ==> 0.3184616297124787\n",
            "Loss in iteration no. 118164 ==> 0.31846145439963797\n",
            "Loss in iteration no. 118165 ==> 0.31846127909026206\n",
            "Loss in iteration no. 118166 ==> 0.31846110378435116\n",
            "Loss in iteration no. 118167 ==> 0.318460928481905\n",
            "Loss in iteration no. 118168 ==> 0.31846075318292355\n",
            "Loss in iteration no. 118169 ==> 0.3184605778874067\n",
            "Loss in iteration no. 118170 ==> 0.3184604025953544\n",
            "Loss in iteration no. 118171 ==> 0.3184602273067665\n",
            "Loss in iteration no. 118172 ==> 0.3184600520216429\n",
            "Loss in iteration no. 118173 ==> 0.31845987673998355\n",
            "Loss in iteration no. 118174 ==> 0.31845970146178865\n",
            "Loss in iteration no. 118175 ==> 0.31845952618705753\n",
            "Loss in iteration no. 118176 ==> 0.3184593509157906\n",
            "Loss in iteration no. 118177 ==> 0.31845917564798726\n",
            "Loss in iteration no. 118178 ==> 0.318459000383648\n",
            "Loss in iteration no. 118179 ==> 0.3184588251227724\n",
            "Loss in iteration no. 118180 ==> 0.31845864986536054\n",
            "Loss in iteration no. 118181 ==> 0.318458474611412\n",
            "Loss in iteration no. 118182 ==> 0.3184582993609272\n",
            "Loss in iteration no. 118183 ==> 0.3184581241139056\n",
            "Loss in iteration no. 118184 ==> 0.3184579488703473\n",
            "Loss in iteration no. 118185 ==> 0.3184577736302523\n",
            "Loss in iteration no. 118186 ==> 0.31845759839362026\n",
            "Loss in iteration no. 118187 ==> 0.3184574231604514\n",
            "Loss in iteration no. 118188 ==> 0.3184572479307453\n",
            "Loss in iteration no. 118189 ==> 0.3184570727045022\n",
            "Loss in iteration no. 118190 ==> 0.3184568974817217\n",
            "Loss in iteration no. 118191 ==> 0.318456722262404\n",
            "Loss in iteration no. 118192 ==> 0.3184565470465489\n",
            "Loss in iteration no. 118193 ==> 0.3184563718341562\n",
            "Loss in iteration no. 118194 ==> 0.3184561966252259\n",
            "Loss in iteration no. 118195 ==> 0.31845602141975793\n",
            "Loss in iteration no. 118196 ==> 0.3184558462177522\n",
            "Loss in iteration no. 118197 ==> 0.31845567101920874\n",
            "Loss in iteration no. 118198 ==> 0.318455495824127\n",
            "Loss in iteration no. 118199 ==> 0.3184553206325075\n",
            "Loss in iteration no. 118200 ==> 0.31845514544434983\n",
            "Loss in iteration no. 118201 ==> 0.3184549702596539\n",
            "Loss in iteration no. 118202 ==> 0.3184547950784196\n",
            "Loss in iteration no. 118203 ==> 0.3184546199006471\n",
            "Loss in iteration no. 118204 ==> 0.31845444472633616\n",
            "Loss in iteration no. 118205 ==> 0.31845426955548634\n",
            "Loss in iteration no. 118206 ==> 0.31845409438809796\n",
            "Loss in iteration no. 118207 ==> 0.31845391922417116\n",
            "Loss in iteration no. 118208 ==> 0.3184537440637051\n",
            "Loss in iteration no. 118209 ==> 0.3184535689067004\n",
            "Loss in iteration no. 118210 ==> 0.31845339375315646\n",
            "Loss in iteration no. 118211 ==> 0.31845321860307363\n",
            "Loss in iteration no. 118212 ==> 0.3184530434564515\n",
            "Loss in iteration no. 118213 ==> 0.3184528683132902\n",
            "Loss in iteration no. 118214 ==> 0.31845269317358943\n",
            "Loss in iteration no. 118215 ==> 0.3184525180373493\n",
            "Loss in iteration no. 118216 ==> 0.3184523429045695\n",
            "Loss in iteration no. 118217 ==> 0.31845216777525015\n",
            "Loss in iteration no. 118218 ==> 0.31845199264939117\n",
            "Loss in iteration no. 118219 ==> 0.3184518175269923\n",
            "Loss in iteration no. 118220 ==> 0.3184516424080537\n",
            "Loss in iteration no. 118221 ==> 0.3184514672925748\n",
            "Loss in iteration no. 118222 ==> 0.318451292180556\n",
            "Loss in iteration no. 118223 ==> 0.31845111707199714\n",
            "Loss in iteration no. 118224 ==> 0.3184509419668979\n",
            "Loss in iteration no. 118225 ==> 0.3184507668652584\n",
            "Loss in iteration no. 118226 ==> 0.31845059176707846\n",
            "Loss in iteration no. 118227 ==> 0.318450416672358\n",
            "Loss in iteration no. 118228 ==> 0.3184502415810969\n",
            "Loss in iteration no. 118229 ==> 0.3184500664932954\n",
            "Loss in iteration no. 118230 ==> 0.31844989140895275\n",
            "Loss in iteration no. 118231 ==> 0.3184497163280694\n",
            "Loss in iteration no. 118232 ==> 0.3184495412506451\n",
            "Loss in iteration no. 118233 ==> 0.3184493661766797\n",
            "Loss in iteration no. 118234 ==> 0.3184491911061732\n",
            "Loss in iteration no. 118235 ==> 0.31844901603912557\n",
            "Loss in iteration no. 118236 ==> 0.3184488409755366\n",
            "Loss in iteration no. 118237 ==> 0.31844866591540616\n",
            "Loss in iteration no. 118238 ==> 0.31844849085873433\n",
            "Loss in iteration no. 118239 ==> 0.3184483158055209\n",
            "Loss in iteration no. 118240 ==> 0.3184481407557658\n",
            "Loss in iteration no. 118241 ==> 0.3184479657094689\n",
            "Loss in iteration no. 118242 ==> 0.3184477906666304\n",
            "Loss in iteration no. 118243 ==> 0.3184476156272497\n",
            "Loss in iteration no. 118244 ==> 0.3184474405913271\n",
            "Loss in iteration no. 118245 ==> 0.3184472655588626\n",
            "Loss in iteration no. 118246 ==> 0.3184470905298557\n",
            "Loss in iteration no. 118247 ==> 0.3184469155043066\n",
            "Loss in iteration no. 118248 ==> 0.31844674048221505\n",
            "Loss in iteration no. 118249 ==> 0.31844656546358113\n",
            "Loss in iteration no. 118250 ==> 0.3184463904484046\n",
            "Loss in iteration no. 118251 ==> 0.31844621543668555\n",
            "Loss in iteration no. 118252 ==> 0.31844604042842384\n",
            "Loss in iteration no. 118253 ==> 0.3184458654236192\n",
            "Loss in iteration no. 118254 ==> 0.31844569042227167\n",
            "Loss in iteration no. 118255 ==> 0.31844551542438126\n",
            "Loss in iteration no. 118256 ==> 0.3184453404299477\n",
            "Loss in iteration no. 118257 ==> 0.31844516543897095\n",
            "Loss in iteration no. 118258 ==> 0.3184449904514511\n",
            "Loss in iteration no. 118259 ==> 0.3184448154673878\n",
            "Loss in iteration no. 118260 ==> 0.3184446404867813\n",
            "Loss in iteration no. 118261 ==> 0.31844446550963096\n",
            "Loss in iteration no. 118262 ==> 0.3184442905359372\n",
            "Loss in iteration no. 118263 ==> 0.31844411556569974\n",
            "Loss in iteration no. 118264 ==> 0.31844394059891856\n",
            "Loss in iteration no. 118265 ==> 0.31844376563559357\n",
            "Loss in iteration no. 118266 ==> 0.31844359067572453\n",
            "Loss in iteration no. 118267 ==> 0.31844341571931156\n",
            "Loss in iteration no. 118268 ==> 0.3184432407663543\n",
            "Loss in iteration no. 118269 ==> 0.3184430658168529\n",
            "Loss in iteration no. 118270 ==> 0.3184428908708072\n",
            "Loss in iteration no. 118271 ==> 0.31844271592821727\n",
            "Loss in iteration no. 118272 ==> 0.3184425409890827\n",
            "Loss in iteration no. 118273 ==> 0.3184423660534036\n",
            "Loss in iteration no. 118274 ==> 0.31844219112117983\n",
            "Loss in iteration no. 118275 ==> 0.31844201619241125\n",
            "Loss in iteration no. 118276 ==> 0.31844184126709807\n",
            "Loss in iteration no. 118277 ==> 0.3184416663452397\n",
            "Loss in iteration no. 118278 ==> 0.3184414914268366\n",
            "Loss in iteration no. 118279 ==> 0.31844131651188834\n",
            "Loss in iteration no. 118280 ==> 0.3184411416003947\n",
            "Loss in iteration no. 118281 ==> 0.318440966692356\n",
            "Loss in iteration no. 118282 ==> 0.318440791787772\n",
            "Loss in iteration no. 118283 ==> 0.3184406168866424\n",
            "Loss in iteration no. 118284 ==> 0.3184404419889673\n",
            "Loss in iteration no. 118285 ==> 0.31844026709474665\n",
            "Loss in iteration no. 118286 ==> 0.31844009220398023\n",
            "Loss in iteration no. 118287 ==> 0.31843991731666793\n",
            "Loss in iteration no. 118288 ==> 0.3184397424328098\n",
            "Loss in iteration no. 118289 ==> 0.31843956755240593\n",
            "Loss in iteration no. 118290 ==> 0.3184393926754557\n",
            "Loss in iteration no. 118291 ==> 0.31843921780195944\n",
            "Loss in iteration no. 118292 ==> 0.31843904293191705\n",
            "Loss in iteration no. 118293 ==> 0.3184388680653281\n",
            "Loss in iteration no. 118294 ==> 0.31843869320219303\n",
            "Loss in iteration no. 118295 ==> 0.31843851834251136\n",
            "Loss in iteration no. 118296 ==> 0.31843834348628297\n",
            "Loss in iteration no. 118297 ==> 0.31843816863350805\n",
            "Loss in iteration no. 118298 ==> 0.3184379937841862\n",
            "Loss in iteration no. 118299 ==> 0.3184378189383177\n",
            "Loss in iteration no. 118300 ==> 0.3184376440959022\n",
            "Loss in iteration no. 118301 ==> 0.31843746925693955\n",
            "Loss in iteration no. 118302 ==> 0.31843729442143004\n",
            "Loss in iteration no. 118303 ==> 0.318437119589373\n",
            "Loss in iteration no. 118304 ==> 0.3184369447607689\n",
            "Loss in iteration no. 118305 ==> 0.3184367699356174\n",
            "Loss in iteration no. 118306 ==> 0.31843659511391836\n",
            "Loss in iteration no. 118307 ==> 0.31843642029567176\n",
            "Loss in iteration no. 118308 ==> 0.3184362454808776\n",
            "Loss in iteration no. 118309 ==> 0.3184360706695357\n",
            "Loss in iteration no. 118310 ==> 0.31843589586164583\n",
            "Loss in iteration no. 118311 ==> 0.31843572105720835\n",
            "Loss in iteration no. 118312 ==> 0.3184355462562226\n",
            "Loss in iteration no. 118313 ==> 0.31843537145868894\n",
            "Loss in iteration no. 118314 ==> 0.3184351966646071\n",
            "Loss in iteration no. 118315 ==> 0.3184350218739769\n",
            "Loss in iteration no. 118316 ==> 0.31843484708679837\n",
            "Loss in iteration no. 118317 ==> 0.3184346723030715\n",
            "Loss in iteration no. 118318 ==> 0.3184344975227962\n",
            "Loss in iteration no. 118319 ==> 0.318434322745972\n",
            "Loss in iteration no. 118320 ==> 0.3184341479725992\n",
            "Loss in iteration no. 118321 ==> 0.31843397320267774\n",
            "Loss in iteration no. 118322 ==> 0.3184337984362072\n",
            "Loss in iteration no. 118323 ==> 0.3184336236731879\n",
            "Loss in iteration no. 118324 ==> 0.3184334489136195\n",
            "Loss in iteration no. 118325 ==> 0.31843327415750194\n",
            "Loss in iteration no. 118326 ==> 0.3184330994048353\n",
            "Loss in iteration no. 118327 ==> 0.318432924655619\n",
            "Loss in iteration no. 118328 ==> 0.3184327499098536\n",
            "Loss in iteration no. 118329 ==> 0.3184325751675386\n",
            "Loss in iteration no. 118330 ==> 0.3184324004286742\n",
            "Loss in iteration no. 118331 ==> 0.3184322256932599\n",
            "Loss in iteration no. 118332 ==> 0.31843205096129584\n",
            "Loss in iteration no. 118333 ==> 0.31843187623278213\n",
            "Loss in iteration no. 118334 ==> 0.3184317015077183\n",
            "Loss in iteration no. 118335 ==> 0.3184315267861046\n",
            "Loss in iteration no. 118336 ==> 0.31843135206794076\n",
            "Loss in iteration no. 118337 ==> 0.3184311773532268\n",
            "Loss in iteration no. 118338 ==> 0.31843100264196245\n",
            "Loss in iteration no. 118339 ==> 0.3184308279341477\n",
            "Loss in iteration no. 118340 ==> 0.3184306532297824\n",
            "Loss in iteration no. 118341 ==> 0.31843047852886697\n",
            "Loss in iteration no. 118342 ==> 0.31843030383140053\n",
            "Loss in iteration no. 118343 ==> 0.31843012913738356\n",
            "Loss in iteration no. 118344 ==> 0.31842995444681577\n",
            "Loss in iteration no. 118345 ==> 0.31842977975969694\n",
            "Loss in iteration no. 118346 ==> 0.3184296050760273\n",
            "Loss in iteration no. 118347 ==> 0.3184294303958064\n",
            "Loss in iteration no. 118348 ==> 0.3184292557190345\n",
            "Loss in iteration no. 118349 ==> 0.3184290810457113\n",
            "Loss in iteration no. 118350 ==> 0.3184289063758368\n",
            "Loss in iteration no. 118351 ==> 0.31842873170941083\n",
            "Loss in iteration no. 118352 ==> 0.3184285570464335\n",
            "Loss in iteration no. 118353 ==> 0.3184283823869044\n",
            "Loss in iteration no. 118354 ==> 0.3184282077308234\n",
            "Loss in iteration no. 118355 ==> 0.3184280330781912\n",
            "Loss in iteration no. 118356 ==> 0.3184278584290068\n",
            "Loss in iteration no. 118357 ==> 0.3184276837832706\n",
            "Loss in iteration no. 118358 ==> 0.31842750914098217\n",
            "Loss in iteration no. 118359 ==> 0.31842733450214167\n",
            "Loss in iteration no. 118360 ==> 0.31842715986674897\n",
            "Loss in iteration no. 118361 ==> 0.31842698523480395\n",
            "Loss in iteration no. 118362 ==> 0.3184268106063066\n",
            "Loss in iteration no. 118363 ==> 0.3184266359812567\n",
            "Loss in iteration no. 118364 ==> 0.31842646135965436\n",
            "Loss in iteration no. 118365 ==> 0.31842628674149925\n",
            "Loss in iteration no. 118366 ==> 0.3184261121267915\n",
            "Loss in iteration no. 118367 ==> 0.31842593751553083\n",
            "Loss in iteration no. 118368 ==> 0.3184257629077174\n",
            "Loss in iteration no. 118369 ==> 0.3184255883033509\n",
            "Loss in iteration no. 118370 ==> 0.3184254137024312\n",
            "Loss in iteration no. 118371 ==> 0.31842523910495846\n",
            "Loss in iteration no. 118372 ==> 0.3184250645109323\n",
            "Loss in iteration no. 118373 ==> 0.3184248899203529\n",
            "Loss in iteration no. 118374 ==> 0.31842471533322014\n",
            "Loss in iteration no. 118375 ==> 0.3184245407495337\n",
            "Loss in iteration no. 118376 ==> 0.31842436616929376\n",
            "Loss in iteration no. 118377 ==> 0.3184241915925\n",
            "Loss in iteration no. 118378 ==> 0.31842401701915246\n",
            "Loss in iteration no. 118379 ==> 0.3184238424492511\n",
            "Loss in iteration no. 118380 ==> 0.31842366788279575\n",
            "Loss in iteration no. 118381 ==> 0.3184234933197864\n",
            "Loss in iteration no. 118382 ==> 0.31842331876022284\n",
            "Loss in iteration no. 118383 ==> 0.3184231442041051\n",
            "Loss in iteration no. 118384 ==> 0.318422969651433\n",
            "Loss in iteration no. 118385 ==> 0.3184227951022065\n",
            "Loss in iteration no. 118386 ==> 0.3184226205564254\n",
            "Loss in iteration no. 118387 ==> 0.3184224460140899\n",
            "Loss in iteration no. 118388 ==> 0.3184222714751997\n",
            "Loss in iteration no. 118389 ==> 0.31842209693975465\n",
            "Loss in iteration no. 118390 ==> 0.318421922407755\n",
            "Loss in iteration no. 118391 ==> 0.3184217478792002\n",
            "Loss in iteration no. 118392 ==> 0.31842157335409027\n",
            "Loss in iteration no. 118393 ==> 0.3184213988324255\n",
            "Loss in iteration no. 118394 ==> 0.31842122431420533\n",
            "Loss in iteration no. 118395 ==> 0.31842104979943003\n",
            "Loss in iteration no. 118396 ==> 0.31842087528809926\n",
            "Loss in iteration no. 118397 ==> 0.3184207007802132\n",
            "Loss in iteration no. 118398 ==> 0.3184205262757714\n",
            "Loss in iteration no. 118399 ==> 0.318420351774774\n",
            "Loss in iteration no. 118400 ==> 0.31842017727722094\n",
            "Loss in iteration no. 118401 ==> 0.3184200027831119\n",
            "Loss in iteration no. 118402 ==> 0.3184198282924472\n",
            "Loss in iteration no. 118403 ==> 0.3184196538052262\n",
            "Loss in iteration no. 118404 ==> 0.31841947932144954\n",
            "Loss in iteration no. 118405 ==> 0.31841930484111647\n",
            "Loss in iteration no. 118406 ==> 0.3184191303642272\n",
            "Loss in iteration no. 118407 ==> 0.31841895589078156\n",
            "Loss in iteration no. 118408 ==> 0.3184187814207795\n",
            "Loss in iteration no. 118409 ==> 0.3184186069542209\n",
            "Loss in iteration no. 118410 ==> 0.3184184324911059\n",
            "Loss in iteration no. 118411 ==> 0.31841825803143414\n",
            "Loss in iteration no. 118412 ==> 0.3184180835752055\n",
            "Loss in iteration no. 118413 ==> 0.3184179091224201\n",
            "Loss in iteration no. 118414 ==> 0.31841773467307766\n",
            "Loss in iteration no. 118415 ==> 0.3184175602271782\n",
            "Loss in iteration no. 118416 ==> 0.3184173857847217\n",
            "Loss in iteration no. 118417 ==> 0.31841721134570794\n",
            "Loss in iteration no. 118418 ==> 0.3184170369101368\n",
            "Loss in iteration no. 118419 ==> 0.3184168624780084\n",
            "Loss in iteration no. 118420 ==> 0.31841668804932244\n",
            "Loss in iteration no. 118421 ==> 0.3184165136240789\n",
            "Loss in iteration no. 118422 ==> 0.31841633920227774\n",
            "Loss in iteration no. 118423 ==> 0.31841616478391893\n",
            "Loss in iteration no. 118424 ==> 0.31841599036900214\n",
            "Loss in iteration no. 118425 ==> 0.31841581595752755\n",
            "Loss in iteration no. 118426 ==> 0.31841564154949487\n",
            "Loss in iteration no. 118427 ==> 0.3184154671449042\n",
            "Loss in iteration no. 118428 ==> 0.3184152927437554\n",
            "Loss in iteration no. 118429 ==> 0.31841511834604824\n",
            "Loss in iteration no. 118430 ==> 0.31841494395178266\n",
            "Loss in iteration no. 118431 ==> 0.3184147695609587\n",
            "Loss in iteration no. 118432 ==> 0.31841459517357634\n",
            "Loss in iteration no. 118433 ==> 0.3184144207896353\n",
            "Loss in iteration no. 118434 ==> 0.3184142464091354\n",
            "Loss in iteration no. 118435 ==> 0.3184140720320769\n",
            "Loss in iteration no. 118436 ==> 0.31841389765845957\n",
            "Loss in iteration no. 118437 ==> 0.3184137232882831\n",
            "Loss in iteration no. 118438 ==> 0.31841354892154766\n",
            "Loss in iteration no. 118439 ==> 0.318413374558253\n",
            "Loss in iteration no. 118440 ==> 0.31841320019839914\n",
            "Loss in iteration no. 118441 ==> 0.318413025841986\n",
            "Loss in iteration no. 118442 ==> 0.3184128514890134\n",
            "Loss in iteration no. 118443 ==> 0.31841267713948146\n",
            "Loss in iteration no. 118444 ==> 0.3184125027933898\n",
            "Loss in iteration no. 118445 ==> 0.3184123284507385\n",
            "Loss in iteration no. 118446 ==> 0.3184121541115275\n",
            "Loss in iteration no. 118447 ==> 0.3184119797757567\n",
            "Loss in iteration no. 118448 ==> 0.3184118054434259\n",
            "Loss in iteration no. 118449 ==> 0.318411631114535\n",
            "Loss in iteration no. 118450 ==> 0.3184114567890842\n",
            "Loss in iteration no. 118451 ==> 0.31841128246707306\n",
            "Loss in iteration no. 118452 ==> 0.3184111081485018\n",
            "Loss in iteration no. 118453 ==> 0.3184109338333699\n",
            "Loss in iteration no. 118454 ==> 0.31841075952167786\n",
            "Loss in iteration no. 118455 ==> 0.31841058521342513\n",
            "Loss in iteration no. 118456 ==> 0.3184104109086117\n",
            "Loss in iteration no. 118457 ==> 0.3184102366072377\n",
            "Loss in iteration no. 118458 ==> 0.3184100623093028\n",
            "Loss in iteration no. 118459 ==> 0.31840988801480713\n",
            "Loss in iteration no. 118460 ==> 0.3184097137237504\n",
            "Loss in iteration no. 118461 ==> 0.31840953943613254\n",
            "Loss in iteration no. 118462 ==> 0.3184093651519535\n",
            "Loss in iteration no. 118463 ==> 0.3184091908712133\n",
            "Loss in iteration no. 118464 ==> 0.31840901659391174\n",
            "Loss in iteration no. 118465 ==> 0.31840884232004885\n",
            "Loss in iteration no. 118466 ==> 0.3184086680496245\n",
            "Loss in iteration no. 118467 ==> 0.31840849378263836\n",
            "Loss in iteration no. 118468 ==> 0.31840831951909065\n",
            "Loss in iteration no. 118469 ==> 0.3184081452589811\n",
            "Loss in iteration no. 118470 ==> 0.31840797100230983\n",
            "Loss in iteration no. 118471 ==> 0.31840779674907654\n",
            "Loss in iteration no. 118472 ==> 0.31840762249928123\n",
            "Loss in iteration no. 118473 ==> 0.31840744825292394\n",
            "Loss in iteration no. 118474 ==> 0.31840727401000424\n",
            "Loss in iteration no. 118475 ==> 0.3184070997705223\n",
            "Loss in iteration no. 118476 ==> 0.318406925534478\n",
            "Loss in iteration no. 118477 ==> 0.31840675130187135\n",
            "Loss in iteration no. 118478 ==> 0.31840657707270204\n",
            "Loss in iteration no. 118479 ==> 0.31840640284696997\n",
            "Loss in iteration no. 118480 ==> 0.31840622862467544\n",
            "Loss in iteration no. 118481 ==> 0.318406054405818\n",
            "Loss in iteration no. 118482 ==> 0.31840588019039756\n",
            "Loss in iteration no. 118483 ==> 0.3184057059784141\n",
            "Loss in iteration no. 118484 ==> 0.3184055317698677\n",
            "Loss in iteration no. 118485 ==> 0.31840535756475796\n",
            "Loss in iteration no. 118486 ==> 0.3184051833630851\n",
            "Loss in iteration no. 118487 ==> 0.31840500916484893\n",
            "Loss in iteration no. 118488 ==> 0.3184048349700493\n",
            "Loss in iteration no. 118489 ==> 0.31840466077868623\n",
            "Loss in iteration no. 118490 ==> 0.3184044865907595\n",
            "Loss in iteration no. 118491 ==> 0.318404312406269\n",
            "Loss in iteration no. 118492 ==> 0.31840413822521474\n",
            "Loss in iteration no. 118493 ==> 0.31840396404759663\n",
            "Loss in iteration no. 118494 ==> 0.3184037898734145\n",
            "Loss in iteration no. 118495 ==> 0.3184036157026685\n",
            "Loss in iteration no. 118496 ==> 0.3184034415353583\n",
            "Loss in iteration no. 118497 ==> 0.31840326737148383\n",
            "Loss in iteration no. 118498 ==> 0.31840309321104515\n",
            "Loss in iteration no. 118499 ==> 0.31840291905404206\n",
            "Loss in iteration no. 118500 ==> 0.3184027449004745\n",
            "Loss in iteration no. 118501 ==> 0.31840257075034245\n",
            "Loss in iteration no. 118502 ==> 0.31840239660364544\n",
            "Loss in iteration no. 118503 ==> 0.31840222246038397\n",
            "Loss in iteration no. 118504 ==> 0.3184020483205577\n",
            "Loss in iteration no. 118505 ==> 0.3184018741841664\n",
            "Loss in iteration no. 118506 ==> 0.31840170005121005\n",
            "Loss in iteration no. 118507 ==> 0.3184015259216887\n",
            "Loss in iteration no. 118508 ==> 0.31840135179560214\n",
            "Loss in iteration no. 118509 ==> 0.31840117767295034\n",
            "Loss in iteration no. 118510 ==> 0.31840100355373324\n",
            "Loss in iteration no. 118511 ==> 0.31840082943795067\n",
            "Loss in iteration no. 118512 ==> 0.31840065532560247\n",
            "Loss in iteration no. 118513 ==> 0.31840048121668885\n",
            "Loss in iteration no. 118514 ==> 0.3184003071112093\n",
            "Loss in iteration no. 118515 ==> 0.3184001330091642\n",
            "Loss in iteration no. 118516 ==> 0.318399958910553\n",
            "Loss in iteration no. 118517 ==> 0.31839978481537584\n",
            "Loss in iteration no. 118518 ==> 0.3183996107236328\n",
            "Loss in iteration no. 118519 ==> 0.3183994366353237\n",
            "Loss in iteration no. 118520 ==> 0.31839926255044826\n",
            "Loss in iteration no. 118521 ==> 0.3183990884690064\n",
            "Loss in iteration no. 118522 ==> 0.3183989143909982\n",
            "Loss in iteration no. 118523 ==> 0.3183987403164235\n",
            "Loss in iteration no. 118524 ==> 0.3183985662452823\n",
            "Loss in iteration no. 118525 ==> 0.3183983921775744\n",
            "Loss in iteration no. 118526 ==> 0.3183982181132998\n",
            "Loss in iteration no. 118527 ==> 0.3183980440524582\n",
            "Loss in iteration no. 118528 ==> 0.3183978699950499\n",
            "Loss in iteration no. 118529 ==> 0.3183976959410743\n",
            "Loss in iteration no. 118530 ==> 0.318397521890532\n",
            "Loss in iteration no. 118531 ==> 0.3183973478434223\n",
            "Loss in iteration no. 118532 ==> 0.3183971737997453\n",
            "Loss in iteration no. 118533 ==> 0.3183969997595009\n",
            "Loss in iteration no. 118534 ==> 0.3183968257226892\n",
            "Loss in iteration no. 118535 ==> 0.31839665168930986\n",
            "Loss in iteration no. 118536 ==> 0.318396477659363\n",
            "Loss in iteration no. 118537 ==> 0.31839630363284827\n",
            "Loss in iteration no. 118538 ==> 0.318396129609766\n",
            "Loss in iteration no. 118539 ==> 0.3183959555901156\n",
            "Loss in iteration no. 118540 ==> 0.3183957815738973\n",
            "Loss in iteration no. 118541 ==> 0.31839560756111096\n",
            "Loss in iteration no. 118542 ==> 0.3183954335517564\n",
            "Loss in iteration no. 118543 ==> 0.3183952595458338\n",
            "Loss in iteration no. 118544 ==> 0.3183950855433426\n",
            "Loss in iteration no. 118545 ==> 0.31839491154428323\n",
            "Loss in iteration no. 118546 ==> 0.3183947375486552\n",
            "Loss in iteration no. 118547 ==> 0.31839456355645873\n",
            "Loss in iteration no. 118548 ==> 0.3183943895676935\n",
            "Loss in iteration no. 118549 ==> 0.3183942155823596\n",
            "Loss in iteration no. 118550 ==> 0.3183940416004568\n",
            "Loss in iteration no. 118551 ==> 0.3183938676219851\n",
            "Loss in iteration no. 118552 ==> 0.31839369364694436\n",
            "Loss in iteration no. 118553 ==> 0.3183935196753346\n",
            "Loss in iteration no. 118554 ==> 0.31839334570715544\n",
            "Loss in iteration no. 118555 ==> 0.31839317174240717\n",
            "Loss in iteration no. 118556 ==> 0.31839299778108937\n",
            "Loss in iteration no. 118557 ==> 0.31839282382320233\n",
            "Loss in iteration no. 118558 ==> 0.3183926498687456\n",
            "Loss in iteration no. 118559 ==> 0.3183924759177192\n",
            "Loss in iteration no. 118560 ==> 0.31839230197012325\n",
            "Loss in iteration no. 118561 ==> 0.3183921280259575\n",
            "Loss in iteration no. 118562 ==> 0.3183919540852217\n",
            "Loss in iteration no. 118563 ==> 0.318391780147916\n",
            "Loss in iteration no. 118564 ==> 0.3183916062140402\n",
            "Loss in iteration no. 118565 ==> 0.3183914322835943\n",
            "Loss in iteration no. 118566 ==> 0.3183912583565781\n",
            "Loss in iteration no. 118567 ==> 0.31839108443299163\n",
            "Loss in iteration no. 118568 ==> 0.3183909105128348\n",
            "Loss in iteration no. 118569 ==> 0.3183907365961075\n",
            "Loss in iteration no. 118570 ==> 0.3183905626828095\n",
            "Loss in iteration no. 118571 ==> 0.31839038877294074\n",
            "Loss in iteration no. 118572 ==> 0.3183902148665013\n",
            "Loss in iteration no. 118573 ==> 0.3183900409634911\n",
            "Loss in iteration no. 118574 ==> 0.3183898670639099\n",
            "Loss in iteration no. 118575 ==> 0.31838969316775767\n",
            "Loss in iteration no. 118576 ==> 0.31838951927503434\n",
            "Loss in iteration no. 118577 ==> 0.31838934538573976\n",
            "Loss in iteration no. 118578 ==> 0.31838917149987395\n",
            "Loss in iteration no. 118579 ==> 0.3183889976174367\n",
            "Loss in iteration no. 118580 ==> 0.31838882373842814\n",
            "Loss in iteration no. 118581 ==> 0.31838864986284793\n",
            "Loss in iteration no. 118582 ==> 0.31838847599069603\n",
            "Loss in iteration no. 118583 ==> 0.31838830212197233\n",
            "Loss in iteration no. 118584 ==> 0.31838812825667706\n",
            "Loss in iteration no. 118585 ==> 0.3183879543948098\n",
            "Loss in iteration no. 118586 ==> 0.31838778053637057\n",
            "Loss in iteration no. 118587 ==> 0.3183876066813591\n",
            "Loss in iteration no. 118588 ==> 0.3183874328297759\n",
            "Loss in iteration no. 118589 ==> 0.31838725898162007\n",
            "Loss in iteration no. 118590 ==> 0.31838708513689196\n",
            "Loss in iteration no. 118591 ==> 0.3183869112955915\n",
            "Loss in iteration no. 118592 ==> 0.3183867374577185\n",
            "Loss in iteration no. 118593 ==> 0.318386563623273\n",
            "Loss in iteration no. 118594 ==> 0.3183863897922547\n",
            "Loss in iteration no. 118595 ==> 0.31838621596466365\n",
            "Loss in iteration no. 118596 ==> 0.3183860421404997\n",
            "Loss in iteration no. 118597 ==> 0.31838586831976295\n",
            "Loss in iteration no. 118598 ==> 0.3183856945024532\n",
            "Loss in iteration no. 118599 ==> 0.3183855206885701\n",
            "Loss in iteration no. 118600 ==> 0.318385346878114\n",
            "Loss in iteration no. 118601 ==> 0.3183851730710845\n",
            "Loss in iteration no. 118602 ==> 0.31838499926748176\n",
            "Loss in iteration no. 118603 ==> 0.31838482546730523\n",
            "Loss in iteration no. 118604 ==> 0.31838465167055546\n",
            "Loss in iteration no. 118605 ==> 0.3183844778772319\n",
            "Loss in iteration no. 118606 ==> 0.31838430408733476\n",
            "Loss in iteration no. 118607 ==> 0.3183841303008637\n",
            "Loss in iteration no. 118608 ==> 0.31838395651781876\n",
            "Loss in iteration no. 118609 ==> 0.31838378273819984\n",
            "Loss in iteration no. 118610 ==> 0.31838360896200685\n",
            "Loss in iteration no. 118611 ==> 0.3183834351892397\n",
            "Loss in iteration no. 118612 ==> 0.31838326141989826\n",
            "Loss in iteration no. 118613 ==> 0.3183830876539826\n",
            "Loss in iteration no. 118614 ==> 0.3183829138914924\n",
            "Loss in iteration no. 118615 ==> 0.3183827401324277\n",
            "Loss in iteration no. 118616 ==> 0.31838256637678847\n",
            "Loss in iteration no. 118617 ==> 0.31838239262457446\n",
            "Loss in iteration no. 118618 ==> 0.31838221887578577\n",
            "Loss in iteration no. 118619 ==> 0.31838204513042206\n",
            "Loss in iteration no. 118620 ==> 0.3183818713884836\n",
            "Loss in iteration no. 118621 ==> 0.31838169764997004\n",
            "Loss in iteration no. 118622 ==> 0.31838152391488134\n",
            "Loss in iteration no. 118623 ==> 0.31838135018321745\n",
            "Loss in iteration no. 118624 ==> 0.3183811764549784\n",
            "Loss in iteration no. 118625 ==> 0.31838100273016373\n",
            "Loss in iteration no. 118626 ==> 0.3183808290087738\n",
            "Loss in iteration no. 118627 ==> 0.31838065529080806\n",
            "Loss in iteration no. 118628 ==> 0.31838048157626686\n",
            "Loss in iteration no. 118629 ==> 0.3183803078651499\n",
            "Loss in iteration no. 118630 ==> 0.3183801341574572\n",
            "Loss in iteration no. 118631 ==> 0.31837996045318834\n",
            "Loss in iteration no. 118632 ==> 0.3183797867523437\n",
            "Loss in iteration no. 118633 ==> 0.3183796130549231\n",
            "Loss in iteration no. 118634 ==> 0.31837943936092605\n",
            "Loss in iteration no. 118635 ==> 0.3183792656703529\n",
            "Loss in iteration no. 118636 ==> 0.3183790919832034\n",
            "Loss in iteration no. 118637 ==> 0.31837891829947756\n",
            "Loss in iteration no. 118638 ==> 0.3183787446191751\n",
            "Loss in iteration no. 118639 ==> 0.3183785709422961\n",
            "Loss in iteration no. 118640 ==> 0.31837839726884043\n",
            "Loss in iteration no. 118641 ==> 0.3183782235988078\n",
            "Loss in iteration no. 118642 ==> 0.31837804993219837\n",
            "Loss in iteration no. 118643 ==> 0.31837787626901215\n",
            "Loss in iteration no. 118644 ==> 0.31837770260924875\n",
            "Loss in iteration no. 118645 ==> 0.3183775289529083\n",
            "Loss in iteration no. 118646 ==> 0.3183773552999907\n",
            "Loss in iteration no. 118647 ==> 0.3183771816504957\n",
            "Loss in iteration no. 118648 ==> 0.31837700800442337\n",
            "Loss in iteration no. 118649 ==> 0.3183768343617736\n",
            "Loss in iteration no. 118650 ==> 0.31837666072254606\n",
            "Loss in iteration no. 118651 ==> 0.31837648708674116\n",
            "Loss in iteration no. 118652 ==> 0.3183763134543583\n",
            "Loss in iteration no. 118653 ==> 0.31837613982539786\n",
            "Loss in iteration no. 118654 ==> 0.3183759661998593\n",
            "Loss in iteration no. 118655 ==> 0.31837579257774284\n",
            "Loss in iteration no. 118656 ==> 0.31837561895904826\n",
            "Loss in iteration no. 118657 ==> 0.3183754453437756\n",
            "Loss in iteration no. 118658 ==> 0.31837527173192476\n",
            "Loss in iteration no. 118659 ==> 0.3183750981234955\n",
            "Loss in iteration no. 118660 ==> 0.3183749245184876\n",
            "Loss in iteration no. 118661 ==> 0.3183747509169015\n",
            "Loss in iteration no. 118662 ==> 0.31837457731873653\n",
            "Loss in iteration no. 118663 ==> 0.31837440372399317\n",
            "Loss in iteration no. 118664 ==> 0.3183742301326708\n",
            "Loss in iteration no. 118665 ==> 0.31837405654476963\n",
            "Loss in iteration no. 118666 ==> 0.3183738829602895\n",
            "Loss in iteration no. 118667 ==> 0.31837370937923043\n",
            "Loss in iteration no. 118668 ==> 0.31837353580159194\n",
            "Loss in iteration no. 118669 ==> 0.3183733622273745\n",
            "Loss in iteration no. 118670 ==> 0.3183731886565778\n",
            "Loss in iteration no. 118671 ==> 0.31837301508920157\n",
            "Loss in iteration no. 118672 ==> 0.3183728415252461\n",
            "Loss in iteration no. 118673 ==> 0.3183726679647109\n",
            "Loss in iteration no. 118674 ==> 0.31837249440759613\n",
            "Loss in iteration no. 118675 ==> 0.31837232085390155\n",
            "Loss in iteration no. 118676 ==> 0.3183721473036272\n",
            "Loss in iteration no. 118677 ==> 0.31837197375677295\n",
            "Loss in iteration no. 118678 ==> 0.3183718002133386\n",
            "Loss in iteration no. 118679 ==> 0.3183716266733243\n",
            "Loss in iteration no. 118680 ==> 0.3183714531367299\n",
            "Loss in iteration no. 118681 ==> 0.31837127960355505\n",
            "Loss in iteration no. 118682 ==> 0.3183711060737999\n",
            "Loss in iteration no. 118683 ==> 0.31837093254746446\n",
            "Loss in iteration no. 118684 ==> 0.31837075902454826\n",
            "Loss in iteration no. 118685 ==> 0.3183705855050517\n",
            "Loss in iteration no. 118686 ==> 0.31837041198897437\n",
            "Loss in iteration no. 118687 ==> 0.3183702384763163\n",
            "Loss in iteration no. 118688 ==> 0.3183700649670774\n",
            "Loss in iteration no. 118689 ==> 0.3183698914612574\n",
            "Loss in iteration no. 118690 ==> 0.3183697179588565\n",
            "Loss in iteration no. 118691 ==> 0.31836954445987453\n",
            "Loss in iteration no. 118692 ==> 0.3183693709643112\n",
            "Loss in iteration no. 118693 ==> 0.3183691974721667\n",
            "Loss in iteration no. 118694 ==> 0.3183690239834408\n",
            "Loss in iteration no. 118695 ==> 0.3183688504981332\n",
            "Loss in iteration no. 118696 ==> 0.31836867701624433\n",
            "Loss in iteration no. 118697 ==> 0.31836850353777374\n",
            "Loss in iteration no. 118698 ==> 0.31836833006272136\n",
            "Loss in iteration no. 118699 ==> 0.31836815659108725\n",
            "Loss in iteration no. 118700 ==> 0.3183679831228713\n",
            "Loss in iteration no. 118701 ==> 0.31836780965807315\n",
            "Loss in iteration no. 118702 ==> 0.3183676361966931\n",
            "Loss in iteration no. 118703 ==> 0.3183674627387308\n",
            "Loss in iteration no. 118704 ==> 0.3183672892841863\n",
            "Loss in iteration no. 118705 ==> 0.3183671158330594\n",
            "Loss in iteration no. 118706 ==> 0.3183669423853501\n",
            "Loss in iteration no. 118707 ==> 0.3183667689410582\n",
            "Loss in iteration no. 118708 ==> 0.318366595500184\n",
            "Loss in iteration no. 118709 ==> 0.3183664220627269\n",
            "Loss in iteration no. 118710 ==> 0.318366248628687\n",
            "Loss in iteration no. 118711 ==> 0.3183660751980643\n",
            "Loss in iteration no. 118712 ==> 0.3183659017708586\n",
            "Loss in iteration no. 118713 ==> 0.31836572834706994\n",
            "Loss in iteration no. 118714 ==> 0.31836555492669827\n",
            "Loss in iteration no. 118715 ==> 0.3183653815097431\n",
            "Loss in iteration no. 118716 ==> 0.31836520809620483\n",
            "Loss in iteration no. 118717 ==> 0.3183650346860832\n",
            "Loss in iteration no. 118718 ==> 0.31836486127937796\n",
            "Loss in iteration no. 118719 ==> 0.31836468787608924\n",
            "Loss in iteration no. 118720 ==> 0.318364514476217\n",
            "Loss in iteration no. 118721 ==> 0.3183643410797609\n",
            "Loss in iteration no. 118722 ==> 0.31836416768672116\n",
            "Loss in iteration no. 118723 ==> 0.31836399429709733\n",
            "Loss in iteration no. 118724 ==> 0.3183638209108895\n",
            "Loss in iteration no. 118725 ==> 0.31836364752809776\n",
            "Loss in iteration no. 118726 ==> 0.3183634741487217\n",
            "Loss in iteration no. 118727 ==> 0.3183633007727614\n",
            "Loss in iteration no. 118728 ==> 0.31836312740021694\n",
            "Loss in iteration no. 118729 ==> 0.31836295403108783\n",
            "Loss in iteration no. 118730 ==> 0.3183627806653744\n",
            "Loss in iteration no. 118731 ==> 0.31836260730307625\n",
            "Loss in iteration no. 118732 ==> 0.31836243394419345\n",
            "Loss in iteration no. 118733 ==> 0.31836226058872596\n",
            "Loss in iteration no. 118734 ==> 0.3183620872366737\n",
            "Loss in iteration no. 118735 ==> 0.3183619138880362\n",
            "Loss in iteration no. 118736 ==> 0.31836174054281396\n",
            "Loss in iteration no. 118737 ==> 0.31836156720100645\n",
            "Loss in iteration no. 118738 ==> 0.3183613938626138\n",
            "Loss in iteration no. 118739 ==> 0.3183612205276358\n",
            "Loss in iteration no. 118740 ==> 0.3183610471960724\n",
            "Loss in iteration no. 118741 ==> 0.31836087386792367\n",
            "Loss in iteration no. 118742 ==> 0.3183607005431892\n",
            "Loss in iteration no. 118743 ==> 0.3183605272218693\n",
            "Loss in iteration no. 118744 ==> 0.3183603539039636\n",
            "Loss in iteration no. 118745 ==> 0.31836018058947213\n",
            "Loss in iteration no. 118746 ==> 0.3183600072783947\n",
            "Loss in iteration no. 118747 ==> 0.3183598339707313\n",
            "Loss in iteration no. 118748 ==> 0.31835966066648186\n",
            "Loss in iteration no. 118749 ==> 0.3183594873656463\n",
            "Loss in iteration no. 118750 ==> 0.31835931406822443\n",
            "Loss in iteration no. 118751 ==> 0.3183591407742162\n",
            "Loss in iteration no. 118752 ==> 0.3183589674836216\n",
            "Loss in iteration no. 118753 ==> 0.31835879419644053\n",
            "Loss in iteration no. 118754 ==> 0.31835862091267286\n",
            "Loss in iteration no. 118755 ==> 0.31835844763231846\n",
            "Loss in iteration no. 118756 ==> 0.31835827435537745\n",
            "Loss in iteration no. 118757 ==> 0.31835810108184937\n",
            "Loss in iteration no. 118758 ==> 0.31835792781173455\n",
            "Loss in iteration no. 118759 ==> 0.31835775454503257\n",
            "Loss in iteration no. 118760 ==> 0.3183575812817436\n",
            "Loss in iteration no. 118761 ==> 0.31835740802186724\n",
            "Loss in iteration no. 118762 ==> 0.31835723476540384\n",
            "Loss in iteration no. 118763 ==> 0.318357061512353\n",
            "Loss in iteration no. 118764 ==> 0.3183568882627146\n",
            "Loss in iteration no. 118765 ==> 0.31835671501648866\n",
            "Loss in iteration no. 118766 ==> 0.3183565417736752\n",
            "Loss in iteration no. 118767 ==> 0.31835636853427396\n",
            "Loss in iteration no. 118768 ==> 0.31835619529828496\n",
            "Loss in iteration no. 118769 ==> 0.31835602206570796\n",
            "Loss in iteration no. 118770 ==> 0.3183558488365431\n",
            "Loss in iteration no. 118771 ==> 0.31835567561079026\n",
            "Loss in iteration no. 118772 ==> 0.3183555023884492\n",
            "Loss in iteration no. 118773 ==> 0.31835532916952\n",
            "Loss in iteration no. 118774 ==> 0.3183551559540021\n",
            "Loss in iteration no. 118775 ==> 0.31835498274189616\n",
            "Loss in iteration no. 118776 ==> 0.3183548095332015\n",
            "Loss in iteration no. 118777 ==> 0.31835463632791844\n",
            "Loss in iteration no. 118778 ==> 0.3183544631260466\n",
            "Loss in iteration no. 118779 ==> 0.31835428992758597\n",
            "Loss in iteration no. 118780 ==> 0.3183541167325367\n",
            "Loss in iteration no. 118781 ==> 0.3183539435408983\n",
            "Loss in iteration no. 118782 ==> 0.318353770352671\n",
            "Loss in iteration no. 118783 ==> 0.31835359716785444\n",
            "Loss in iteration no. 118784 ==> 0.3183534239864489\n",
            "Loss in iteration no. 118785 ==> 0.318353250808454\n",
            "Loss in iteration no. 118786 ==> 0.3183530776338697\n",
            "Loss in iteration no. 118787 ==> 0.318352904462696\n",
            "Loss in iteration no. 118788 ==> 0.3183527312949327\n",
            "Loss in iteration no. 118789 ==> 0.31835255813057983\n",
            "Loss in iteration no. 118790 ==> 0.3183523849696372\n",
            "Loss in iteration no. 118791 ==> 0.3183522118121048\n",
            "Loss in iteration no. 118792 ==> 0.3183520386579826\n",
            "Loss in iteration no. 118793 ==> 0.31835186550727035\n",
            "Loss in iteration no. 118794 ==> 0.31835169235996813\n",
            "Loss in iteration no. 118795 ==> 0.31835151921607563\n",
            "Loss in iteration no. 118796 ==> 0.318351346075593\n",
            "Loss in iteration no. 118797 ==> 0.3183511729385202\n",
            "Loss in iteration no. 118798 ==> 0.31835099980485665\n",
            "Loss in iteration no. 118799 ==> 0.31835082667460274\n",
            "Loss in iteration no. 118800 ==> 0.31835065354775854\n",
            "Loss in iteration no. 118801 ==> 0.31835048042432335\n",
            "Loss in iteration no. 118802 ==> 0.3183503073042974\n",
            "Loss in iteration no. 118803 ==> 0.3183501341876809\n",
            "Loss in iteration no. 118804 ==> 0.31834996107447316\n",
            "Loss in iteration no. 118805 ==> 0.3183497879646746\n",
            "Loss in iteration no. 118806 ==> 0.3183496148582851\n",
            "Loss in iteration no. 118807 ==> 0.31834944175530405\n",
            "Loss in iteration no. 118808 ==> 0.31834926865573193\n",
            "Loss in iteration no. 118809 ==> 0.3183490955595686\n",
            "Loss in iteration no. 118810 ==> 0.3183489224668137\n",
            "Loss in iteration no. 118811 ==> 0.31834874937746727\n",
            "Loss in iteration no. 118812 ==> 0.31834857629152913\n",
            "Loss in iteration no. 118813 ==> 0.31834840320899926\n",
            "Loss in iteration no. 118814 ==> 0.3183482301298779\n",
            "Loss in iteration no. 118815 ==> 0.3183480570541644\n",
            "Loss in iteration no. 118816 ==> 0.318347883981859\n",
            "Loss in iteration no. 118817 ==> 0.3183477109129616\n",
            "Loss in iteration no. 118818 ==> 0.3183475378474721\n",
            "Loss in iteration no. 118819 ==> 0.3183473647853902\n",
            "Loss in iteration no. 118820 ==> 0.3183471917267162\n",
            "Loss in iteration no. 118821 ==> 0.3183470186714498\n",
            "Loss in iteration no. 118822 ==> 0.31834684561959087\n",
            "Loss in iteration no. 118823 ==> 0.3183466725711393\n",
            "Loss in iteration no. 118824 ==> 0.31834649952609506\n",
            "Loss in iteration no. 118825 ==> 0.3183463264844582\n",
            "Loss in iteration no. 118826 ==> 0.3183461534462285\n",
            "Loss in iteration no. 118827 ==> 0.318345980411406\n",
            "Loss in iteration no. 118828 ==> 0.3183458073799903\n",
            "Loss in iteration no. 118829 ==> 0.31834563435198165\n",
            "Loss in iteration no. 118830 ==> 0.3183454613273797\n",
            "Loss in iteration no. 118831 ==> 0.31834528830618464\n",
            "Loss in iteration no. 118832 ==> 0.31834511528839604\n",
            "Loss in iteration no. 118833 ==> 0.31834494227401416\n",
            "Loss in iteration no. 118834 ==> 0.31834476926303873\n",
            "Loss in iteration no. 118835 ==> 0.31834459625546974\n",
            "Loss in iteration no. 118836 ==> 0.318344423251307\n",
            "Loss in iteration no. 118837 ==> 0.3183442502505505\n",
            "Loss in iteration no. 118838 ==> 0.31834407725320013\n",
            "Loss in iteration no. 118839 ==> 0.31834390425925596\n",
            "Loss in iteration no. 118840 ==> 0.31834373126871757\n",
            "Loss in iteration no. 118841 ==> 0.31834355828158517\n",
            "Loss in iteration no. 118842 ==> 0.3183433852978585\n",
            "Loss in iteration no. 118843 ==> 0.31834321231753765\n",
            "Loss in iteration no. 118844 ==> 0.3183430393406223\n",
            "Loss in iteration no. 118845 ==> 0.31834286636711234\n",
            "Loss in iteration no. 118846 ==> 0.3183426933970081\n",
            "Loss in iteration no. 118847 ==> 0.31834252043030914\n",
            "Loss in iteration no. 118848 ==> 0.31834234746701534\n",
            "Loss in iteration no. 118849 ==> 0.3183421745071269\n",
            "Loss in iteration no. 118850 ==> 0.3183420015506434\n",
            "Loss in iteration no. 118851 ==> 0.31834182859756516\n",
            "Loss in iteration no. 118852 ==> 0.3183416556478915\n",
            "Loss in iteration no. 118853 ==> 0.3183414827016229\n",
            "Loss in iteration no. 118854 ==> 0.318341309758759\n",
            "Loss in iteration no. 118855 ==> 0.3183411368192998\n",
            "Loss in iteration no. 118856 ==> 0.31834096388324506\n",
            "Loss in iteration no. 118857 ==> 0.31834079095059503\n",
            "Loss in iteration no. 118858 ==> 0.3183406180213493\n",
            "Loss in iteration no. 118859 ==> 0.3183404450955079\n",
            "Loss in iteration no. 118860 ==> 0.31834027217307076\n",
            "Loss in iteration no. 118861 ==> 0.31834009925403767\n",
            "Loss in iteration no. 118862 ==> 0.31833992633840885\n",
            "Loss in iteration no. 118863 ==> 0.3183397534261838\n",
            "Loss in iteration no. 118864 ==> 0.3183395805173628\n",
            "Loss in iteration no. 118865 ==> 0.31833940761194546\n",
            "Loss in iteration no. 118866 ==> 0.318339234709932\n",
            "Loss in iteration no. 118867 ==> 0.31833906181132204\n",
            "Loss in iteration no. 118868 ==> 0.31833888891611556\n",
            "Loss in iteration no. 118869 ==> 0.3183387160243127\n",
            "Loss in iteration no. 118870 ==> 0.3183385431359131\n",
            "Loss in iteration no. 118871 ==> 0.3183383702509168\n",
            "Loss in iteration no. 118872 ==> 0.31833819736932384\n",
            "Loss in iteration no. 118873 ==> 0.31833802449113385\n",
            "Loss in iteration no. 118874 ==> 0.31833785161634687\n",
            "Loss in iteration no. 118875 ==> 0.318337678744963\n",
            "Loss in iteration no. 118876 ==> 0.3183375058769818\n",
            "Loss in iteration no. 118877 ==> 0.3183373330124035\n",
            "Loss in iteration no. 118878 ==> 0.3183371601512278\n",
            "Loss in iteration no. 118879 ==> 0.3183369872934547\n",
            "Loss in iteration no. 118880 ==> 0.3183368144390841\n",
            "Loss in iteration no. 118881 ==> 0.3183366415881159\n",
            "Loss in iteration no. 118882 ==> 0.31833646874055016\n",
            "Loss in iteration no. 118883 ==> 0.3183362958963867\n",
            "Loss in iteration no. 118884 ==> 0.31833612305562525\n",
            "Loss in iteration no. 118885 ==> 0.31833595021826583\n",
            "Loss in iteration no. 118886 ==> 0.3183357773843086\n",
            "Loss in iteration no. 118887 ==> 0.31833560455375326\n",
            "Loss in iteration no. 118888 ==> 0.31833543172659956\n",
            "Loss in iteration no. 118889 ==> 0.31833525890284775\n",
            "Loss in iteration no. 118890 ==> 0.3183350860824976\n",
            "Loss in iteration no. 118891 ==> 0.3183349132655488\n",
            "Loss in iteration no. 118892 ==> 0.31833474045200166\n",
            "Loss in iteration no. 118893 ==> 0.31833456764185586\n",
            "Loss in iteration no. 118894 ==> 0.31833439483511133\n",
            "Loss in iteration no. 118895 ==> 0.318334222031768\n",
            "Loss in iteration no. 118896 ==> 0.318334049231826\n",
            "Loss in iteration no. 118897 ==> 0.3183338764352848\n",
            "Loss in iteration no. 118898 ==> 0.3183337036421447\n",
            "Loss in iteration no. 118899 ==> 0.31833353085240534\n",
            "Loss in iteration no. 118900 ==> 0.3183333580660668\n",
            "Loss in iteration no. 118901 ==> 0.318333185283129\n",
            "Loss in iteration no. 118902 ==> 0.3183330125035918\n",
            "Loss in iteration no. 118903 ==> 0.3183328397274552\n",
            "Loss in iteration no. 118904 ==> 0.31833266695471896\n",
            "Loss in iteration no. 118905 ==> 0.3183324941853829\n",
            "Loss in iteration no. 118906 ==> 0.3183323214194474\n",
            "Loss in iteration no. 118907 ==> 0.318332148656912\n",
            "Loss in iteration no. 118908 ==> 0.3183319758977766\n",
            "Loss in iteration no. 118909 ==> 0.3183318031420414\n",
            "Loss in iteration no. 118910 ==> 0.3183316303897059\n",
            "Loss in iteration no. 118911 ==> 0.31833145764077025\n",
            "Loss in iteration no. 118912 ==> 0.3183312848952344\n",
            "Loss in iteration no. 118913 ==> 0.3183311121530983\n",
            "Loss in iteration no. 118914 ==> 0.3183309394143616\n",
            "Loss in iteration no. 118915 ==> 0.3183307666790245\n",
            "Loss in iteration no. 118916 ==> 0.31833059394708685\n",
            "Loss in iteration no. 118917 ==> 0.31833042121854843\n",
            "Loss in iteration no. 118918 ==> 0.3183302484934092\n",
            "Loss in iteration no. 118919 ==> 0.31833007577166933\n",
            "Loss in iteration no. 118920 ==> 0.31832990305332826\n",
            "Loss in iteration no. 118921 ==> 0.31832973033838624\n",
            "Loss in iteration no. 118922 ==> 0.3183295576268432\n",
            "Loss in iteration no. 118923 ==> 0.3183293849186989\n",
            "Loss in iteration no. 118924 ==> 0.3183292122139532\n",
            "Loss in iteration no. 118925 ==> 0.31832903951260627\n",
            "Loss in iteration no. 118926 ==> 0.3183288668146579\n",
            "Loss in iteration no. 118927 ==> 0.31832869412010795\n",
            "Loss in iteration no. 118928 ==> 0.3183285214289564\n",
            "Loss in iteration no. 118929 ==> 0.31832834874120297\n",
            "Loss in iteration no. 118930 ==> 0.31832817605684777\n",
            "Loss in iteration no. 118931 ==> 0.3183280033758908\n",
            "Loss in iteration no. 118932 ==> 0.31832783069833187\n",
            "Loss in iteration no. 118933 ==> 0.3183276580241707\n",
            "Loss in iteration no. 118934 ==> 0.31832748535340744\n",
            "Loss in iteration no. 118935 ==> 0.3183273126860421\n",
            "Loss in iteration no. 118936 ==> 0.31832714002207435\n",
            "Loss in iteration no. 118937 ==> 0.3183269673615041\n",
            "Loss in iteration no. 118938 ==> 0.3183267947043315\n",
            "Loss in iteration no. 118939 ==> 0.31832662205055606\n",
            "Loss in iteration no. 118940 ==> 0.3183264494001783\n",
            "Loss in iteration no. 118941 ==> 0.31832627675319763\n",
            "Loss in iteration no. 118942 ==> 0.31832610410961404\n",
            "Loss in iteration no. 118943 ==> 0.31832593146942756\n",
            "Loss in iteration no. 118944 ==> 0.3183257588326383\n",
            "Loss in iteration no. 118945 ==> 0.31832558619924567\n",
            "Loss in iteration no. 118946 ==> 0.31832541356925\n",
            "Loss in iteration no. 118947 ==> 0.3183252409426509\n",
            "Loss in iteration no. 118948 ==> 0.31832506831944857\n",
            "Loss in iteration no. 118949 ==> 0.3183248956996428\n",
            "Loss in iteration no. 118950 ==> 0.31832472308323345\n",
            "Loss in iteration no. 118951 ==> 0.31832455047022057\n",
            "Loss in iteration no. 118952 ==> 0.3183243778606039\n",
            "Loss in iteration no. 118953 ==> 0.31832420525438354\n",
            "Loss in iteration no. 118954 ==> 0.3183240326515591\n",
            "Loss in iteration no. 118955 ==> 0.3183238600521309\n",
            "Loss in iteration no. 118956 ==> 0.3183236874560986\n",
            "Loss in iteration no. 118957 ==> 0.31832351486346233\n",
            "Loss in iteration no. 118958 ==> 0.3183233422742216\n",
            "Loss in iteration no. 118959 ==> 0.3183231696883766\n",
            "Loss in iteration no. 118960 ==> 0.3183229971059272\n",
            "Loss in iteration no. 118961 ==> 0.3183228245268733\n",
            "Loss in iteration no. 118962 ==> 0.3183226519512151\n",
            "Loss in iteration no. 118963 ==> 0.3183224793789521\n",
            "Loss in iteration no. 118964 ==> 0.3183223068100842\n",
            "Loss in iteration no. 118965 ==> 0.31832213424461164\n",
            "Loss in iteration no. 118966 ==> 0.31832196168253424\n",
            "Loss in iteration no. 118967 ==> 0.3183217891238516\n",
            "Loss in iteration no. 118968 ==> 0.318321616568564\n",
            "Loss in iteration no. 118969 ==> 0.3183214440166715\n",
            "Loss in iteration no. 118970 ==> 0.31832127146817346\n",
            "Loss in iteration no. 118971 ==> 0.31832109892307014\n",
            "Loss in iteration no. 118972 ==> 0.31832092638136145\n",
            "Loss in iteration no. 118973 ==> 0.3183207538430471\n",
            "Loss in iteration no. 118974 ==> 0.3183205813081273\n",
            "Loss in iteration no. 118975 ==> 0.31832040877660184\n",
            "Loss in iteration no. 118976 ==> 0.3183202362484705\n",
            "Loss in iteration no. 118977 ==> 0.3183200637237333\n",
            "Loss in iteration no. 118978 ==> 0.31831989120239035\n",
            "Loss in iteration no. 118979 ==> 0.31831971868444126\n",
            "Loss in iteration no. 118980 ==> 0.31831954616988595\n",
            "Loss in iteration no. 118981 ==> 0.31831937365872454\n",
            "Loss in iteration no. 118982 ==> 0.31831920115095674\n",
            "Loss in iteration no. 118983 ==> 0.3183190286465828\n",
            "Loss in iteration no. 118984 ==> 0.31831885614560207\n",
            "Loss in iteration no. 118985 ==> 0.31831868364801524\n",
            "Loss in iteration no. 118986 ==> 0.3183185111538213\n",
            "Loss in iteration no. 118987 ==> 0.3183183386630211\n",
            "Loss in iteration no. 118988 ==> 0.31831816617561387\n",
            "Loss in iteration no. 118989 ==> 0.31831799369159974\n",
            "Loss in iteration no. 118990 ==> 0.3183178212109786\n",
            "Loss in iteration no. 118991 ==> 0.3183176487337505\n",
            "Loss in iteration no. 118992 ==> 0.3183174762599153\n",
            "Loss in iteration no. 118993 ==> 0.31831730378947276\n",
            "Loss in iteration no. 118994 ==> 0.3183171313224228\n",
            "Loss in iteration no. 118995 ==> 0.3183169588587657\n",
            "Loss in iteration no. 118996 ==> 0.318316786398501\n",
            "Loss in iteration no. 118997 ==> 0.31831661394162875\n",
            "Loss in iteration no. 118998 ==> 0.31831644148814864\n",
            "Loss in iteration no. 118999 ==> 0.31831626903806115\n",
            "Loss in iteration no. 119000 ==> 0.31831609659136556\n",
            "Loss in iteration no. 119001 ==> 0.3183159241480621\n",
            "Loss in iteration no. 119002 ==> 0.3183157517081505\n",
            "Loss in iteration no. 119003 ==> 0.3183155792716311\n",
            "Loss in iteration no. 119004 ==> 0.31831540683850335\n",
            "Loss in iteration no. 119005 ==> 0.3183152344087674\n",
            "Loss in iteration no. 119006 ==> 0.3183150619824231\n",
            "Loss in iteration no. 119007 ==> 0.3183148895594701\n",
            "Loss in iteration no. 119008 ==> 0.318314717139909\n",
            "Loss in iteration no. 119009 ==> 0.31831454472373916\n",
            "Loss in iteration no. 119010 ==> 0.3183143723109604\n",
            "Loss in iteration no. 119011 ==> 0.3183141999015732\n",
            "Loss in iteration no. 119012 ==> 0.3183140274955769\n",
            "Loss in iteration no. 119013 ==> 0.31831385509297183\n",
            "Loss in iteration no. 119014 ==> 0.3183136826937575\n",
            "Loss in iteration no. 119015 ==> 0.31831351029793425\n",
            "Loss in iteration no. 119016 ==> 0.3183133379055017\n",
            "Loss in iteration no. 119017 ==> 0.31831316551645983\n",
            "Loss in iteration no. 119018 ==> 0.3183129931308086\n",
            "Loss in iteration no. 119019 ==> 0.31831282074854783\n",
            "Loss in iteration no. 119020 ==> 0.3183126483696776\n",
            "Loss in iteration no. 119021 ==> 0.3183124759941977\n",
            "Loss in iteration no. 119022 ==> 0.3183123036221081\n",
            "Loss in iteration no. 119023 ==> 0.3183121312534087\n",
            "Loss in iteration no. 119024 ==> 0.3183119588880995\n",
            "Loss in iteration no. 119025 ==> 0.31831178652618025\n",
            "Loss in iteration no. 119026 ==> 0.31831161416765086\n",
            "Loss in iteration no. 119027 ==> 0.3183114418125113\n",
            "Loss in iteration no. 119028 ==> 0.3183112694607615\n",
            "Loss in iteration no. 119029 ==> 0.31831109711240146\n",
            "Loss in iteration no. 119030 ==> 0.318310924767431\n",
            "Loss in iteration no. 119031 ==> 0.31831075242584994\n",
            "Loss in iteration no. 119032 ==> 0.3183105800876584\n",
            "Loss in iteration no. 119033 ==> 0.31831040775285613\n",
            "Loss in iteration no. 119034 ==> 0.3183102354214431\n",
            "Loss in iteration no. 119035 ==> 0.31831006309341925\n",
            "Loss in iteration no. 119036 ==> 0.31830989076878463\n",
            "Loss in iteration no. 119037 ==> 0.3183097184475388\n",
            "Loss in iteration no. 119038 ==> 0.31830954612968193\n",
            "Loss in iteration no. 119039 ==> 0.31830937381521374\n",
            "Loss in iteration no. 119040 ==> 0.31830920150413444\n",
            "Loss in iteration no. 119041 ==> 0.31830902919644377\n",
            "Loss in iteration no. 119042 ==> 0.3183088568921415\n",
            "Loss in iteration no. 119043 ==> 0.318308684591228\n",
            "Loss in iteration no. 119044 ==> 0.31830851229370277\n",
            "Loss in iteration no. 119045 ==> 0.31830833999956565\n",
            "Loss in iteration no. 119046 ==> 0.31830816770881704\n",
            "Loss in iteration no. 119047 ==> 0.31830799542145627\n",
            "Loss in iteration no. 119048 ==> 0.3183078231374837\n",
            "Loss in iteration no. 119049 ==> 0.3183076508568991\n",
            "Loss in iteration no. 119050 ==> 0.31830747857970226\n",
            "Loss in iteration no. 119051 ==> 0.3183073063058933\n",
            "Loss in iteration no. 119052 ==> 0.31830713403547206\n",
            "Loss in iteration no. 119053 ==> 0.3183069617684383\n",
            "Loss in iteration no. 119054 ==> 0.3183067895047921\n",
            "Loss in iteration no. 119055 ==> 0.3183066172445334\n",
            "Loss in iteration no. 119056 ==> 0.3183064449876619\n",
            "Loss in iteration no. 119057 ==> 0.31830627273417794\n",
            "Loss in iteration no. 119058 ==> 0.31830610048408114\n",
            "Loss in iteration no. 119059 ==> 0.31830592823737125\n",
            "Loss in iteration no. 119060 ==> 0.31830575599404853\n",
            "Loss in iteration no. 119061 ==> 0.3183055837541126\n",
            "Loss in iteration no. 119062 ==> 0.31830541151756353\n",
            "Loss in iteration no. 119063 ==> 0.3183052392844012\n",
            "Loss in iteration no. 119064 ==> 0.3183050670546256\n",
            "Loss in iteration no. 119065 ==> 0.31830489482823654\n",
            "Loss in iteration no. 119066 ==> 0.3183047226052342\n",
            "Loss in iteration no. 119067 ==> 0.3183045503856181\n",
            "Loss in iteration no. 119068 ==> 0.3183043781693882\n",
            "Loss in iteration no. 119069 ==> 0.3183042059565447\n",
            "Loss in iteration no. 119070 ==> 0.3183040337470872\n",
            "Loss in iteration no. 119071 ==> 0.31830386154101586\n",
            "Loss in iteration no. 119072 ==> 0.3183036893383305\n",
            "Loss in iteration no. 119073 ==> 0.31830351713903104\n",
            "Loss in iteration no. 119074 ==> 0.31830334494311746\n",
            "Loss in iteration no. 119075 ==> 0.3183031727505895\n",
            "Loss in iteration no. 119076 ==> 0.3183030005614473\n",
            "Loss in iteration no. 119077 ==> 0.31830282837569046\n",
            "Loss in iteration no. 119078 ==> 0.31830265619331904\n",
            "Loss in iteration no. 119079 ==> 0.31830248401433314\n",
            "Loss in iteration no. 119080 ==> 0.31830231183873253\n",
            "Loss in iteration no. 119081 ==> 0.31830213966651727\n",
            "Loss in iteration no. 119082 ==> 0.31830196749768686\n",
            "Loss in iteration no. 119083 ==> 0.31830179533224173\n",
            "Loss in iteration no. 119084 ==> 0.3183016231701815\n",
            "Loss in iteration no. 119085 ==> 0.3183014510115061\n",
            "Loss in iteration no. 119086 ==> 0.3183012788562154\n",
            "Loss in iteration no. 119087 ==> 0.31830110670430944\n",
            "Loss in iteration no. 119088 ==> 0.3183009345557881\n",
            "Loss in iteration no. 119089 ==> 0.3183007624106513\n",
            "Loss in iteration no. 119090 ==> 0.31830059026889906\n",
            "Loss in iteration no. 119091 ==> 0.31830041813053095\n",
            "Loss in iteration no. 119092 ==> 0.3183002459955471\n",
            "Loss in iteration no. 119093 ==> 0.31830007386394765\n",
            "Loss in iteration no. 119094 ==> 0.318299901735732\n",
            "Loss in iteration no. 119095 ==> 0.31829972961090064\n",
            "Loss in iteration no. 119096 ==> 0.318299557489453\n",
            "Loss in iteration no. 119097 ==> 0.3182993853713893\n",
            "Loss in iteration no. 119098 ==> 0.3182992132567094\n",
            "Loss in iteration no. 119099 ==> 0.3182990411454132\n",
            "Loss in iteration no. 119100 ==> 0.31829886903750043\n",
            "Loss in iteration no. 119101 ==> 0.31829869693297114\n",
            "Loss in iteration no. 119102 ==> 0.31829852483182536\n",
            "Loss in iteration no. 119103 ==> 0.3182983527340629\n",
            "Loss in iteration no. 119104 ==> 0.3182981806396836\n",
            "Loss in iteration no. 119105 ==> 0.3182980085486875\n",
            "Loss in iteration no. 119106 ==> 0.3182978364610745\n",
            "Loss in iteration no. 119107 ==> 0.31829766437684437\n",
            "Loss in iteration no. 119108 ==> 0.31829749229599724\n",
            "Loss in iteration no. 119109 ==> 0.31829732021853274\n",
            "Loss in iteration no. 119110 ==> 0.31829714814445115\n",
            "Loss in iteration no. 119111 ==> 0.3182969760737521\n",
            "Loss in iteration no. 119112 ==> 0.3182968040064357\n",
            "Loss in iteration no. 119113 ==> 0.31829663194250163\n",
            "Loss in iteration no. 119114 ==> 0.3182964598819501\n",
            "Loss in iteration no. 119115 ==> 0.3182962878247807\n",
            "Loss in iteration no. 119116 ==> 0.31829611577099365\n",
            "Loss in iteration no. 119117 ==> 0.3182959437205886\n",
            "Loss in iteration no. 119118 ==> 0.3182957716735657\n",
            "Loss in iteration no. 119119 ==> 0.3182955996299247\n",
            "Loss in iteration no. 119120 ==> 0.31829542758966556\n",
            "Loss in iteration no. 119121 ==> 0.3182952555527882\n",
            "Loss in iteration no. 119122 ==> 0.3182950835192925\n",
            "Loss in iteration no. 119123 ==> 0.31829491148917843\n",
            "Loss in iteration no. 119124 ==> 0.3182947394624459\n",
            "Loss in iteration no. 119125 ==> 0.3182945674390948\n",
            "Loss in iteration no. 119126 ==> 0.31829439541912513\n",
            "Loss in iteration no. 119127 ==> 0.3182942234025366\n",
            "Loss in iteration no. 119128 ==> 0.3182940513893293\n",
            "Loss in iteration no. 119129 ==> 0.31829387937950315\n",
            "Loss in iteration no. 119130 ==> 0.31829370737305795\n",
            "Loss in iteration no. 119131 ==> 0.31829353536999355\n",
            "Loss in iteration no. 119132 ==> 0.31829336337031017\n",
            "Loss in iteration no. 119133 ==> 0.31829319137400736\n",
            "Loss in iteration no. 119134 ==> 0.31829301938108545\n",
            "Loss in iteration no. 119135 ==> 0.31829284739154406\n",
            "Loss in iteration no. 119136 ==> 0.3182926754053831\n",
            "Loss in iteration no. 119137 ==> 0.31829250342260246\n",
            "Loss in iteration no. 119138 ==> 0.31829233144320235\n",
            "Loss in iteration no. 119139 ==> 0.31829215946718237\n",
            "Loss in iteration no. 119140 ==> 0.31829198749454246\n",
            "Loss in iteration no. 119141 ==> 0.3182918155252828\n",
            "Loss in iteration no. 119142 ==> 0.31829164355940304\n",
            "Loss in iteration no. 119143 ==> 0.318291471596903\n",
            "Loss in iteration no. 119144 ==> 0.31829129963778297\n",
            "Loss in iteration no. 119145 ==> 0.31829112768204254\n",
            "Loss in iteration no. 119146 ==> 0.31829095572968186\n",
            "Loss in iteration no. 119147 ==> 0.31829078378070064\n",
            "Loss in iteration no. 119148 ==> 0.318290611835099\n",
            "Loss in iteration no. 119149 ==> 0.31829043989287675\n",
            "Loss in iteration no. 119150 ==> 0.31829026795403376\n",
            "Loss in iteration no. 119151 ==> 0.31829009601856995\n",
            "Loss in iteration no. 119152 ==> 0.3182899240864851\n",
            "Loss in iteration no. 119153 ==> 0.31828975215777944\n",
            "Loss in iteration no. 119154 ==> 0.3182895802324529\n",
            "Loss in iteration no. 119155 ==> 0.31828940831050484\n",
            "Loss in iteration no. 119156 ==> 0.31828923639193585\n",
            "Loss in iteration no. 119157 ==> 0.3182890644767455\n",
            "Loss in iteration no. 119158 ==> 0.31828889256493387\n",
            "Loss in iteration no. 119159 ==> 0.3182887206565006\n",
            "Loss in iteration no. 119160 ==> 0.31828854875144585\n",
            "Loss in iteration no. 119161 ==> 0.3182883768497694\n",
            "Loss in iteration no. 119162 ==> 0.3182882049514713\n",
            "Loss in iteration no. 119163 ==> 0.3182880330565514\n",
            "Loss in iteration no. 119164 ==> 0.31828786116500934\n",
            "Loss in iteration no. 119165 ==> 0.3182876892768454\n",
            "Loss in iteration no. 119166 ==> 0.31828751739205957\n",
            "Loss in iteration no. 119167 ==> 0.3182873455106515\n",
            "Loss in iteration no. 119168 ==> 0.3182871736326211\n",
            "Loss in iteration no. 119169 ==> 0.3182870017579686\n",
            "Loss in iteration no. 119170 ==> 0.3182868298866935\n",
            "Loss in iteration no. 119171 ==> 0.31828665801879585\n",
            "Loss in iteration no. 119172 ==> 0.31828648615427557\n",
            "Loss in iteration no. 119173 ==> 0.3182863142931328\n",
            "Loss in iteration no. 119174 ==> 0.31828614243536724\n",
            "Loss in iteration no. 119175 ==> 0.31828597058097874\n",
            "Loss in iteration no. 119176 ==> 0.31828579872996743\n",
            "Loss in iteration no. 119177 ==> 0.318285626882333\n",
            "Loss in iteration no. 119178 ==> 0.31828545503807537\n",
            "Loss in iteration no. 119179 ==> 0.31828528319719485\n",
            "Loss in iteration no. 119180 ==> 0.31828511135969084\n",
            "Loss in iteration no. 119181 ==> 0.3182849395255635\n",
            "Loss in iteration no. 119182 ==> 0.31828476769481273\n",
            "Loss in iteration no. 119183 ==> 0.31828459586743857\n",
            "Loss in iteration no. 119184 ==> 0.31828442404344065\n",
            "Loss in iteration no. 119185 ==> 0.318284252222819\n",
            "Loss in iteration no. 119186 ==> 0.31828408040557365\n",
            "Loss in iteration no. 119187 ==> 0.3182839085917044\n",
            "Loss in iteration no. 119188 ==> 0.31828373678121125\n",
            "Loss in iteration no. 119189 ==> 0.318283564974094\n",
            "Loss in iteration no. 119190 ==> 0.3182833931703526\n",
            "Loss in iteration no. 119191 ==> 0.318283221369987\n",
            "Loss in iteration no. 119192 ==> 0.31828304957299713\n",
            "Loss in iteration no. 119193 ==> 0.3182828777793829\n",
            "Loss in iteration no. 119194 ==> 0.318282705989144\n",
            "Loss in iteration no. 119195 ==> 0.31828253420228075\n",
            "Loss in iteration no. 119196 ==> 0.31828236241879293\n",
            "Loss in iteration no. 119197 ==> 0.31828219063868024\n",
            "Loss in iteration no. 119198 ==> 0.3182820188619427\n",
            "Loss in iteration no. 119199 ==> 0.3182818470885805\n",
            "Loss in iteration no. 119200 ==> 0.3182816753185931\n",
            "Loss in iteration no. 119201 ==> 0.3182815035519808\n",
            "Loss in iteration no. 119202 ==> 0.3182813317887432\n",
            "Loss in iteration no. 119203 ==> 0.3182811600288804\n",
            "Loss in iteration no. 119204 ==> 0.3182809882723922\n",
            "Loss in iteration no. 119205 ==> 0.31828081651927864\n",
            "Loss in iteration no. 119206 ==> 0.31828064476953977\n",
            "Loss in iteration no. 119207 ==> 0.3182804730231751\n",
            "Loss in iteration no. 119208 ==> 0.3182803012801848\n",
            "Loss in iteration no. 119209 ==> 0.31828012954056883\n",
            "Loss in iteration no. 119210 ==> 0.318279957804327\n",
            "Loss in iteration no. 119211 ==> 0.3182797860714592\n",
            "Loss in iteration no. 119212 ==> 0.31827961434196533\n",
            "Loss in iteration no. 119213 ==> 0.31827944261584556\n",
            "Loss in iteration no. 119214 ==> 0.31827927089309954\n",
            "Loss in iteration no. 119215 ==> 0.3182790991737272\n",
            "Loss in iteration no. 119216 ==> 0.3182789274577285\n",
            "Loss in iteration no. 119217 ==> 0.3182787557451034\n",
            "Loss in iteration no. 119218 ==> 0.31827858403585185\n",
            "Loss in iteration no. 119219 ==> 0.31827841232997356\n",
            "Loss in iteration no. 119220 ==> 0.3182782406274686\n",
            "Loss in iteration no. 119221 ==> 0.3182780689283369\n",
            "Loss in iteration no. 119222 ==> 0.31827789723257843\n",
            "Loss in iteration no. 119223 ==> 0.31827772554019296\n",
            "Loss in iteration no. 119224 ==> 0.3182775538511804\n",
            "Loss in iteration no. 119225 ==> 0.3182773821655407\n",
            "Loss in iteration no. 119226 ==> 0.31827721048327395\n",
            "Loss in iteration no. 119227 ==> 0.3182770388043797\n",
            "Loss in iteration no. 119228 ==> 0.31827686712885817\n",
            "Loss in iteration no. 119229 ==> 0.3182766954567093\n",
            "Loss in iteration no. 119230 ==> 0.3182765237879328\n",
            "Loss in iteration no. 119231 ==> 0.3182763521225286\n",
            "Loss in iteration no. 119232 ==> 0.31827618046049666\n",
            "Loss in iteration no. 119233 ==> 0.31827600880183726\n",
            "Loss in iteration no. 119234 ==> 0.31827583714654956\n",
            "Loss in iteration no. 119235 ==> 0.31827566549463393\n",
            "Loss in iteration no. 119236 ==> 0.3182754938460905\n",
            "Loss in iteration no. 119237 ==> 0.31827532220091886\n",
            "Loss in iteration no. 119238 ==> 0.3182751505591188\n",
            "Loss in iteration no. 119239 ==> 0.31827497892069057\n",
            "Loss in iteration no. 119240 ==> 0.31827480728563395\n",
            "Loss in iteration no. 119241 ==> 0.3182746356539488\n",
            "Loss in iteration no. 119242 ==> 0.31827446402563514\n",
            "Loss in iteration no. 119243 ==> 0.3182742924006929\n",
            "Loss in iteration no. 119244 ==> 0.31827412077912176\n",
            "Loss in iteration no. 119245 ==> 0.31827394916092183\n",
            "Loss in iteration no. 119246 ==> 0.31827377754609304\n",
            "Loss in iteration no. 119247 ==> 0.3182736059346351\n",
            "Loss in iteration no. 119248 ==> 0.31827343432654825\n",
            "Loss in iteration no. 119249 ==> 0.3182732627218321\n",
            "Loss in iteration no. 119250 ==> 0.31827309112048674\n",
            "Loss in iteration no. 119251 ==> 0.3182729195225122\n",
            "Loss in iteration no. 119252 ==> 0.3182727479279081\n",
            "Loss in iteration no. 119253 ==> 0.3182725763366744\n",
            "Loss in iteration no. 119254 ==> 0.3182724047488113\n",
            "Loss in iteration no. 119255 ==> 0.31827223316431835\n",
            "Loss in iteration no. 119256 ==> 0.3182720615831958\n",
            "Loss in iteration no. 119257 ==> 0.31827189000544337\n",
            "Loss in iteration no. 119258 ==> 0.31827171843106095\n",
            "Loss in iteration no. 119259 ==> 0.3182715468600484\n",
            "Loss in iteration no. 119260 ==> 0.318271375292406\n",
            "Loss in iteration no. 119261 ==> 0.31827120372813317\n",
            "Loss in iteration no. 119262 ==> 0.31827103216723024\n",
            "Loss in iteration no. 119263 ==> 0.3182708606096969\n",
            "Loss in iteration no. 119264 ==> 0.3182706890555331\n",
            "Loss in iteration no. 119265 ==> 0.3182705175047389\n",
            "Loss in iteration no. 119266 ==> 0.3182703459573138\n",
            "Loss in iteration no. 119267 ==> 0.31827017441325833\n",
            "Loss in iteration no. 119268 ==> 0.31827000287257184\n",
            "Loss in iteration no. 119269 ==> 0.3182698313352545\n",
            "Loss in iteration no. 119270 ==> 0.3182696598013061\n",
            "Loss in iteration no. 119271 ==> 0.31826948827072693\n",
            "Loss in iteration no. 119272 ==> 0.3182693167435165\n",
            "Loss in iteration no. 119273 ==> 0.3182691452196748\n",
            "Loss in iteration no. 119274 ==> 0.3182689736992019\n",
            "Loss in iteration no. 119275 ==> 0.3182688021820975\n",
            "Loss in iteration no. 119276 ==> 0.31826863066836175\n",
            "Loss in iteration no. 119277 ==> 0.3182684591579942\n",
            "Loss in iteration no. 119278 ==> 0.31826828765099546\n",
            "Loss in iteration no. 119279 ==> 0.31826811614736455\n",
            "Loss in iteration no. 119280 ==> 0.31826794464710206\n",
            "Loss in iteration no. 119281 ==> 0.31826777315020766\n",
            "Loss in iteration no. 119282 ==> 0.3182676016566812\n",
            "Loss in iteration no. 119283 ==> 0.31826743016652276\n",
            "Loss in iteration no. 119284 ==> 0.3182672586797321\n",
            "Loss in iteration no. 119285 ==> 0.31826708719630925\n",
            "Loss in iteration no. 119286 ==> 0.31826691571625415\n",
            "Loss in iteration no. 119287 ==> 0.3182667442395665\n",
            "Loss in iteration no. 119288 ==> 0.31826657276624637\n",
            "Loss in iteration no. 119289 ==> 0.3182664012962938\n",
            "Loss in iteration no. 119290 ==> 0.3182662298297084\n",
            "Loss in iteration no. 119291 ==> 0.31826605836649025\n",
            "Loss in iteration no. 119292 ==> 0.31826588690663954\n",
            "Loss in iteration no. 119293 ==> 0.31826571545015575\n",
            "Loss in iteration no. 119294 ==> 0.3182655439970389\n",
            "Loss in iteration no. 119295 ==> 0.31826537254728887\n",
            "Loss in iteration no. 119296 ==> 0.31826520110090584\n",
            "Loss in iteration no. 119297 ==> 0.31826502965788944\n",
            "Loss in iteration no. 119298 ==> 0.31826485821823974\n",
            "Loss in iteration no. 119299 ==> 0.3182646867819567\n",
            "Loss in iteration no. 119300 ==> 0.31826451534904004\n",
            "Loss in iteration no. 119301 ==> 0.3182643439194898\n",
            "Loss in iteration no. 119302 ==> 0.31826417249330585\n",
            "Loss in iteration no. 119303 ==> 0.31826400107048813\n",
            "Loss in iteration no. 119304 ==> 0.31826382965103667\n",
            "Loss in iteration no. 119305 ==> 0.3182636582349511\n",
            "Loss in iteration no. 119306 ==> 0.31826348682223154\n",
            "Loss in iteration no. 119307 ==> 0.31826331541287806\n",
            "Loss in iteration no. 119308 ==> 0.31826314400689015\n",
            "Loss in iteration no. 119309 ==> 0.31826297260426806\n",
            "Loss in iteration no. 119310 ==> 0.31826280120501166\n",
            "Loss in iteration no. 119311 ==> 0.3182626298091207\n",
            "Loss in iteration no. 119312 ==> 0.31826245841659523\n",
            "Loss in iteration no. 119313 ==> 0.3182622870274353\n",
            "Loss in iteration no. 119314 ==> 0.3182621156416404\n",
            "Loss in iteration no. 119315 ==> 0.31826194425921067\n",
            "Loss in iteration no. 119316 ==> 0.3182617728801464\n",
            "Loss in iteration no. 119317 ==> 0.31826160150444693\n",
            "Loss in iteration no. 119318 ==> 0.3182614301321126\n",
            "Loss in iteration no. 119319 ==> 0.3182612587631429\n",
            "Loss in iteration no. 119320 ==> 0.3182610873975381\n",
            "Loss in iteration no. 119321 ==> 0.318260916035298\n",
            "Loss in iteration no. 119322 ==> 0.3182607446764225\n",
            "Loss in iteration no. 119323 ==> 0.3182605733209115\n",
            "Loss in iteration no. 119324 ==> 0.3182604019687649\n",
            "Loss in iteration no. 119325 ==> 0.31826023061998265\n",
            "Loss in iteration no. 119326 ==> 0.3182600592745648\n",
            "Loss in iteration no. 119327 ==> 0.31825988793251103\n",
            "Loss in iteration no. 119328 ==> 0.3182597165938215\n",
            "Loss in iteration no. 119329 ==> 0.3182595452584958\n",
            "Loss in iteration no. 119330 ==> 0.3182593739265342\n",
            "Loss in iteration no. 119331 ==> 0.3182592025979364\n",
            "Loss in iteration no. 119332 ==> 0.31825903127270233\n",
            "Loss in iteration no. 119333 ==> 0.31825885995083186\n",
            "Loss in iteration no. 119334 ==> 0.31825868863232515\n",
            "Loss in iteration no. 119335 ==> 0.31825851731718185\n",
            "Loss in iteration no. 119336 ==> 0.31825834600540187\n",
            "Loss in iteration no. 119337 ==> 0.3182581746969853\n",
            "Loss in iteration no. 119338 ==> 0.318258003391932\n",
            "Loss in iteration no. 119339 ==> 0.31825783209024194\n",
            "Loss in iteration no. 119340 ==> 0.3182576607919149\n",
            "Loss in iteration no. 119341 ==> 0.3182574894969509\n",
            "Loss in iteration no. 119342 ==> 0.31825731820534964\n",
            "Loss in iteration no. 119343 ==> 0.31825714691711143\n",
            "Loss in iteration no. 119344 ==> 0.3182569756322357\n",
            "Loss in iteration no. 119345 ==> 0.3182568043507229\n",
            "Loss in iteration no. 119346 ==> 0.31825663307257246\n",
            "Loss in iteration no. 119347 ==> 0.3182564617977846\n",
            "Loss in iteration no. 119348 ==> 0.31825629052635906\n",
            "Loss in iteration no. 119349 ==> 0.318256119258296\n",
            "Loss in iteration no. 119350 ==> 0.3182559479935951\n",
            "Loss in iteration no. 119351 ==> 0.31825577673225625\n",
            "Loss in iteration no. 119352 ==> 0.31825560547427945\n",
            "Loss in iteration no. 119353 ==> 0.31825543421966485\n",
            "Loss in iteration no. 119354 ==> 0.31825526296841183\n",
            "Loss in iteration no. 119355 ==> 0.3182550917205208\n",
            "Loss in iteration no. 119356 ==> 0.3182549204759914\n",
            "Loss in iteration no. 119357 ==> 0.31825474923482366\n",
            "Loss in iteration no. 119358 ==> 0.31825457799701756\n",
            "Loss in iteration no. 119359 ==> 0.31825440676257294\n",
            "Loss in iteration no. 119360 ==> 0.3182542355314895\n",
            "Loss in iteration no. 119361 ==> 0.3182540643037676\n",
            "Loss in iteration no. 119362 ==> 0.31825389307940666\n",
            "Loss in iteration no. 119363 ==> 0.318253721858407\n",
            "Loss in iteration no. 119364 ==> 0.3182535506407684\n",
            "Loss in iteration no. 119365 ==> 0.31825337942649073\n",
            "Loss in iteration no. 119366 ==> 0.3182532082155738\n",
            "Loss in iteration no. 119367 ==> 0.3182530370080178\n",
            "Loss in iteration no. 119368 ==> 0.31825286580382234\n",
            "Loss in iteration no. 119369 ==> 0.31825269460298766\n",
            "Loss in iteration no. 119370 ==> 0.31825252340551347\n",
            "Loss in iteration no. 119371 ==> 0.3182523522113996\n",
            "Loss in iteration no. 119372 ==> 0.3182521810206462\n",
            "Loss in iteration no. 119373 ==> 0.3182520098332531\n",
            "Loss in iteration no. 119374 ==> 0.31825183864922013\n",
            "Loss in iteration no. 119375 ==> 0.31825166746854733\n",
            "Loss in iteration no. 119376 ==> 0.3182514962912345\n",
            "Loss in iteration no. 119377 ==> 0.31825132511728155\n",
            "Loss in iteration no. 119378 ==> 0.3182511539466885\n",
            "Loss in iteration no. 119379 ==> 0.31825098277945524\n",
            "Loss in iteration no. 119380 ==> 0.3182508116155816\n",
            "Loss in iteration no. 119381 ==> 0.31825064045506757\n",
            "Loss in iteration no. 119382 ==> 0.31825046929791295\n",
            "Loss in iteration no. 119383 ==> 0.318250298144118\n",
            "Loss in iteration no. 119384 ==> 0.31825012699368227\n",
            "Loss in iteration no. 119385 ==> 0.3182499558466058\n",
            "Loss in iteration no. 119386 ==> 0.3182497847028885\n",
            "Loss in iteration no. 119387 ==> 0.3182496135625301\n",
            "Loss in iteration no. 119388 ==> 0.3182494424255311\n",
            "Loss in iteration no. 119389 ==> 0.31824927129189057\n",
            "Loss in iteration no. 119390 ==> 0.3182491001616091\n",
            "Loss in iteration no. 119391 ==> 0.31824892903468643\n",
            "Loss in iteration no. 119392 ==> 0.31824875791112234\n",
            "Loss in iteration no. 119393 ==> 0.31824858679091694\n",
            "Loss in iteration no. 119394 ==> 0.3182484156740699\n",
            "Loss in iteration no. 119395 ==> 0.31824824456058115\n",
            "Loss in iteration no. 119396 ==> 0.318248073450451\n",
            "Loss in iteration no. 119397 ==> 0.3182479023436789\n",
            "Loss in iteration no. 119398 ==> 0.3182477312402648\n",
            "Loss in iteration no. 119399 ==> 0.31824756014020905\n",
            "Loss in iteration no. 119400 ==> 0.31824738904351113\n",
            "Loss in iteration no. 119401 ==> 0.31824721795017114\n",
            "Loss in iteration no. 119402 ==> 0.31824704686018884\n",
            "Loss in iteration no. 119403 ==> 0.31824687577356436\n",
            "Loss in iteration no. 119404 ==> 0.31824670469029775\n",
            "Loss in iteration no. 119405 ==> 0.3182465336103883\n",
            "Loss in iteration no. 119406 ==> 0.31824636253383665\n",
            "Loss in iteration no. 119407 ==> 0.3182461914606423\n",
            "Loss in iteration no. 119408 ==> 0.3182460203908051\n",
            "Loss in iteration no. 119409 ==> 0.3182458493243252\n",
            "Loss in iteration no. 119410 ==> 0.31824567826120237\n",
            "Loss in iteration no. 119411 ==> 0.31824550720143685\n",
            "Loss in iteration no. 119412 ==> 0.318245336145028\n",
            "Loss in iteration no. 119413 ==> 0.31824516509197615\n",
            "Loss in iteration no. 119414 ==> 0.3182449940422811\n",
            "Loss in iteration no. 119415 ==> 0.3182448229959427\n",
            "Loss in iteration no. 119416 ==> 0.31824465195296087\n",
            "Loss in iteration no. 119417 ==> 0.3182444809133357\n",
            "Loss in iteration no. 119418 ==> 0.318244309877067\n",
            "Loss in iteration no. 119419 ==> 0.3182441388441545\n",
            "Loss in iteration no. 119420 ==> 0.3182439678145984\n",
            "Loss in iteration no. 119421 ==> 0.3182437967883985\n",
            "Loss in iteration no. 119422 ==> 0.3182436257655546\n",
            "Loss in iteration no. 119423 ==> 0.3182434547460669\n",
            "Loss in iteration no. 119424 ==> 0.3182432837299351\n",
            "Loss in iteration no. 119425 ==> 0.318243112717159\n",
            "Loss in iteration no. 119426 ==> 0.31824294170773876\n",
            "Loss in iteration no. 119427 ==> 0.3182427707016742\n",
            "Loss in iteration no. 119428 ==> 0.31824259969896546\n",
            "Loss in iteration no. 119429 ==> 0.31824242869961195\n",
            "Loss in iteration no. 119430 ==> 0.31824225770361386\n",
            "Loss in iteration no. 119431 ==> 0.3182420867109713\n",
            "Loss in iteration no. 119432 ==> 0.318241915721684\n",
            "Loss in iteration no. 119433 ==> 0.31824174473575184\n",
            "Loss in iteration no. 119434 ==> 0.31824157375317463\n",
            "Loss in iteration no. 119435 ==> 0.31824140277395246\n",
            "Loss in iteration no. 119436 ==> 0.3182412317980854\n",
            "Loss in iteration no. 119437 ==> 0.318241060825573\n",
            "Loss in iteration no. 119438 ==> 0.31824088985641547\n",
            "Loss in iteration no. 119439 ==> 0.31824071889061256\n",
            "Loss in iteration no. 119440 ==> 0.31824054792816436\n",
            "Loss in iteration no. 119441 ==> 0.31824037696907037\n",
            "Loss in iteration no. 119442 ==> 0.3182402060133311\n",
            "Loss in iteration no. 119443 ==> 0.318240035060946\n",
            "Loss in iteration no. 119444 ==> 0.3182398641119152\n",
            "Loss in iteration no. 119445 ==> 0.31823969316623846\n",
            "Loss in iteration no. 119446 ==> 0.31823952222391594\n",
            "Loss in iteration no. 119447 ==> 0.3182393512849473\n",
            "Loss in iteration no. 119448 ==> 0.3182391803493326\n",
            "Loss in iteration no. 119449 ==> 0.3182390094170718\n",
            "Loss in iteration no. 119450 ==> 0.31823883848816475\n",
            "Loss in iteration no. 119451 ==> 0.31823866756261115\n",
            "Loss in iteration no. 119452 ==> 0.31823849664041126\n",
            "Loss in iteration no. 119453 ==> 0.3182383257215647\n",
            "Loss in iteration no. 119454 ==> 0.3182381548060717\n",
            "Loss in iteration no. 119455 ==> 0.318237983893932\n",
            "Loss in iteration no. 119456 ==> 0.3182378129851455\n",
            "Loss in iteration no. 119457 ==> 0.3182376420797122\n",
            "Loss in iteration no. 119458 ==> 0.3182374711776318\n",
            "Loss in iteration no. 119459 ==> 0.31823730027890446\n",
            "Loss in iteration no. 119460 ==> 0.31823712938353016\n",
            "Loss in iteration no. 119461 ==> 0.3182369584915085\n",
            "Loss in iteration no. 119462 ==> 0.31823678760283963\n",
            "Loss in iteration no. 119463 ==> 0.31823661671752335\n",
            "Loss in iteration no. 119464 ==> 0.3182364458355595\n",
            "Loss in iteration no. 119465 ==> 0.3182362749569483\n",
            "Loss in iteration no. 119466 ==> 0.31823610408168945\n",
            "Loss in iteration no. 119467 ==> 0.3182359332097827\n",
            "Loss in iteration no. 119468 ==> 0.3182357623412285\n",
            "Loss in iteration no. 119469 ==> 0.3182355914760262\n",
            "Loss in iteration no. 119470 ==> 0.318235420614176\n",
            "Loss in iteration no. 119471 ==> 0.31823524975567774\n",
            "Loss in iteration no. 119472 ==> 0.3182350789005314\n",
            "Loss in iteration no. 119473 ==> 0.31823490804873683\n",
            "Loss in iteration no. 119474 ==> 0.3182347372002939\n",
            "Loss in iteration no. 119475 ==> 0.31823456635520264\n",
            "Loss in iteration no. 119476 ==> 0.318234395513463\n",
            "Loss in iteration no. 119477 ==> 0.3182342246750747\n",
            "Loss in iteration no. 119478 ==> 0.3182340538400376\n",
            "Loss in iteration no. 119479 ==> 0.318233883008352\n",
            "Loss in iteration no. 119480 ==> 0.3182337121800176\n",
            "Loss in iteration no. 119481 ==> 0.3182335413550343\n",
            "Loss in iteration no. 119482 ==> 0.318233370533402\n",
            "Loss in iteration no. 119483 ==> 0.31823319971512065\n",
            "Loss in iteration no. 119484 ==> 0.31823302890019\n",
            "Loss in iteration no. 119485 ==> 0.3182328580886103\n",
            "Loss in iteration no. 119486 ==> 0.31823268728038123\n",
            "Loss in iteration no. 119487 ==> 0.3182325164755027\n",
            "Loss in iteration no. 119488 ==> 0.31823234567397485\n",
            "Loss in iteration no. 119489 ==> 0.3182321748757972\n",
            "Loss in iteration no. 119490 ==> 0.3182320040809701\n",
            "Loss in iteration no. 119491 ==> 0.3182318332894931\n",
            "Loss in iteration no. 119492 ==> 0.3182316625013665\n",
            "Loss in iteration no. 119493 ==> 0.31823149171658976\n",
            "Loss in iteration no. 119494 ==> 0.31823132093516315\n",
            "Loss in iteration no. 119495 ==> 0.3182311501570865\n",
            "Loss in iteration no. 119496 ==> 0.31823097938235956\n",
            "Loss in iteration no. 119497 ==> 0.3182308086109825\n",
            "Loss in iteration no. 119498 ==> 0.3182306378429551\n",
            "Loss in iteration no. 119499 ==> 0.31823046707827723\n",
            "Loss in iteration no. 119500 ==> 0.31823029631694877\n",
            "Loss in iteration no. 119501 ==> 0.3182301255589699\n",
            "Loss in iteration no. 119502 ==> 0.31822995480434024\n",
            "Loss in iteration no. 119503 ==> 0.31822978405305985\n",
            "Loss in iteration no. 119504 ==> 0.3182296133051287\n",
            "Loss in iteration no. 119505 ==> 0.31822944256054647\n",
            "Loss in iteration no. 119506 ==> 0.3182292718193133\n",
            "Loss in iteration no. 119507 ==> 0.3182291010814292\n",
            "Loss in iteration no. 119508 ==> 0.3182289303468938\n",
            "Loss in iteration no. 119509 ==> 0.3182287596157072\n",
            "Loss in iteration no. 119510 ==> 0.3182285888878692\n",
            "Loss in iteration no. 119511 ==> 0.31822841816337966\n",
            "Loss in iteration no. 119512 ==> 0.31822824744223877\n",
            "Loss in iteration no. 119513 ==> 0.31822807672444614\n",
            "Loss in iteration no. 119514 ==> 0.318227906010002\n",
            "Loss in iteration no. 119515 ==> 0.31822773529890586\n",
            "Loss in iteration no. 119516 ==> 0.31822756459115814\n",
            "Loss in iteration no. 119517 ==> 0.31822739388675825\n",
            "Loss in iteration no. 119518 ==> 0.3182272231857064\n",
            "Loss in iteration no. 119519 ==> 0.3182270524880024\n",
            "Loss in iteration no. 119520 ==> 0.31822688179364633\n",
            "Loss in iteration no. 119521 ==> 0.318226711102638\n",
            "Loss in iteration no. 119522 ==> 0.31822654041497717\n",
            "Loss in iteration no. 119523 ==> 0.31822636973066404\n",
            "Loss in iteration no. 119524 ==> 0.31822619904969823\n",
            "Loss in iteration no. 119525 ==> 0.31822602837208\n",
            "Loss in iteration no. 119526 ==> 0.31822585769780887\n",
            "Loss in iteration no. 119527 ==> 0.31822568702688503\n",
            "Loss in iteration no. 119528 ==> 0.31822551635930835\n",
            "Loss in iteration no. 119529 ==> 0.31822534569507865\n",
            "Loss in iteration no. 119530 ==> 0.318225175034196\n",
            "Loss in iteration no. 119531 ==> 0.3182250043766603\n",
            "Loss in iteration no. 119532 ==> 0.3182248337224711\n",
            "Loss in iteration no. 119533 ==> 0.3182246630716288\n",
            "Loss in iteration no. 119534 ==> 0.3182244924241332\n",
            "Loss in iteration no. 119535 ==> 0.31822432177998394\n",
            "Loss in iteration no. 119536 ==> 0.31822415113918134\n",
            "Loss in iteration no. 119537 ==> 0.318223980501725\n",
            "Loss in iteration no. 119538 ==> 0.318223809867615\n",
            "Loss in iteration no. 119539 ==> 0.3182236392368511\n",
            "Loss in iteration no. 119540 ==> 0.3182234686094334\n",
            "Loss in iteration no. 119541 ==> 0.3182232979853616\n",
            "Loss in iteration no. 119542 ==> 0.31822312736463604\n",
            "Loss in iteration no. 119543 ==> 0.318222956747256\n",
            "Loss in iteration no. 119544 ==> 0.318222786133222\n",
            "Loss in iteration no. 119545 ==> 0.3182226155225335\n",
            "Loss in iteration no. 119546 ==> 0.31822244491519075\n",
            "Loss in iteration no. 119547 ==> 0.3182222743111934\n",
            "Loss in iteration no. 119548 ==> 0.3182221037105416\n",
            "Loss in iteration no. 119549 ==> 0.3182219331132351\n",
            "Loss in iteration no. 119550 ==> 0.3182217625192738\n",
            "Loss in iteration no. 119551 ==> 0.31822159192865784\n",
            "Loss in iteration no. 119552 ==> 0.3182214213413869\n",
            "Loss in iteration no. 119553 ==> 0.318221250757461\n",
            "Loss in iteration no. 119554 ==> 0.3182210801768801\n",
            "Loss in iteration no. 119555 ==> 0.31822090959964394\n",
            "Loss in iteration no. 119556 ==> 0.31822073902575254\n",
            "Loss in iteration no. 119557 ==> 0.3182205684552059\n",
            "Loss in iteration no. 119558 ==> 0.3182203978880037\n",
            "Loss in iteration no. 119559 ==> 0.31822022732414623\n",
            "Loss in iteration no. 119560 ==> 0.3182200567636331\n",
            "Loss in iteration no. 119561 ==> 0.3182198862064643\n",
            "Loss in iteration no. 119562 ==> 0.3182197156526398\n",
            "Loss in iteration no. 119563 ==> 0.3182195451021594\n",
            "Loss in iteration no. 119564 ==> 0.318219374555023\n",
            "Loss in iteration no. 119565 ==> 0.31821920401123094\n",
            "Loss in iteration no. 119566 ==> 0.31821903347078245\n",
            "Loss in iteration no. 119567 ==> 0.31821886293367785\n",
            "Loss in iteration no. 119568 ==> 0.31821869239991707\n",
            "Loss in iteration no. 119569 ==> 0.3182185218695001\n",
            "Loss in iteration no. 119570 ==> 0.31821835134242654\n",
            "Loss in iteration no. 119571 ==> 0.3182181808186965\n",
            "Loss in iteration no. 119572 ==> 0.3182180102983099\n",
            "Loss in iteration no. 119573 ==> 0.3182178397812666\n",
            "Loss in iteration no. 119574 ==> 0.3182176692675666\n",
            "Loss in iteration no. 119575 ==> 0.31821749875720956\n",
            "Loss in iteration no. 119576 ==> 0.31821732825019583\n",
            "Loss in iteration no. 119577 ==> 0.3182171577465249\n",
            "Loss in iteration no. 119578 ==> 0.31821698724619707\n",
            "Loss in iteration no. 119579 ==> 0.31821681674921176\n",
            "Loss in iteration no. 119580 ==> 0.3182166462555695\n",
            "Loss in iteration no. 119581 ==> 0.31821647576526974\n",
            "Loss in iteration no. 119582 ==> 0.31821630527831274\n",
            "Loss in iteration no. 119583 ==> 0.318216134794698\n",
            "Loss in iteration no. 119584 ==> 0.31821596431442595\n",
            "Loss in iteration no. 119585 ==> 0.3182157938374958\n",
            "Loss in iteration no. 119586 ==> 0.3182156233639082\n",
            "Loss in iteration no. 119587 ==> 0.31821545289366265\n",
            "Loss in iteration no. 119588 ==> 0.3182152824267591\n",
            "Loss in iteration no. 119589 ==> 0.31821511196319757\n",
            "Loss in iteration no. 119590 ==> 0.3182149415029779\n",
            "Loss in iteration no. 119591 ==> 0.3182147710461001\n",
            "Loss in iteration no. 119592 ==> 0.318214600592564\n",
            "Loss in iteration no. 119593 ==> 0.3182144301423694\n",
            "Loss in iteration no. 119594 ==> 0.31821425969551664\n",
            "Loss in iteration no. 119595 ==> 0.3182140892520052\n",
            "Loss in iteration no. 119596 ==> 0.31821391881183514\n",
            "Loss in iteration no. 119597 ==> 0.3182137483750063\n",
            "Loss in iteration no. 119598 ==> 0.3182135779415187\n",
            "Loss in iteration no. 119599 ==> 0.3182134075113723\n",
            "Loss in iteration no. 119600 ==> 0.318213237084567\n",
            "Loss in iteration no. 119601 ==> 0.3182130666611026\n",
            "Loss in iteration no. 119602 ==> 0.31821289624097915\n",
            "Loss in iteration no. 119603 ==> 0.31821272582419646\n",
            "Loss in iteration no. 119604 ==> 0.3182125554107545\n",
            "Loss in iteration no. 119605 ==> 0.3182123850006531\n",
            "Loss in iteration no. 119606 ==> 0.31821221459389215\n",
            "Loss in iteration no. 119607 ==> 0.3182120441904718\n",
            "Loss in iteration no. 119608 ==> 0.3182118737903918\n",
            "Loss in iteration no. 119609 ==> 0.31821170339365207\n",
            "Loss in iteration no. 119610 ==> 0.3182115330002526\n",
            "Loss in iteration no. 119611 ==> 0.3182113626101933\n",
            "Loss in iteration no. 119612 ==> 0.3182111922234737\n",
            "Loss in iteration no. 119613 ==> 0.3182110218400944\n",
            "Loss in iteration no. 119614 ==> 0.31821085146005484\n",
            "Loss in iteration no. 119615 ==> 0.3182106810833551\n",
            "Loss in iteration no. 119616 ==> 0.3182105107099952\n",
            "Loss in iteration no. 119617 ==> 0.31821034033997464\n",
            "Loss in iteration no. 119618 ==> 0.31821016997329377\n",
            "Loss in iteration no. 119619 ==> 0.3182099996099523\n",
            "Loss in iteration no. 119620 ==> 0.3182098292499502\n",
            "Loss in iteration no. 119621 ==> 0.31820965889328734\n",
            "Loss in iteration no. 119622 ==> 0.3182094885399638\n",
            "Loss in iteration no. 119623 ==> 0.31820931818997916\n",
            "Loss in iteration no. 119624 ==> 0.31820914784333376\n",
            "Loss in iteration no. 119625 ==> 0.3182089775000272\n",
            "Loss in iteration no. 119626 ==> 0.31820880716005945\n",
            "Loss in iteration no. 119627 ==> 0.31820863682343065\n",
            "Loss in iteration no. 119628 ==> 0.3182084664901403\n",
            "Loss in iteration no. 119629 ==> 0.3182082961601887\n",
            "Loss in iteration no. 119630 ==> 0.31820812583357555\n",
            "Loss in iteration no. 119631 ==> 0.31820795551030095\n",
            "Loss in iteration no. 119632 ==> 0.3182077851903646\n",
            "Loss in iteration no. 119633 ==> 0.3182076148737664\n",
            "Loss in iteration no. 119634 ==> 0.3182074445605066\n",
            "Loss in iteration no. 119635 ==> 0.31820727425058476\n",
            "Loss in iteration no. 119636 ==> 0.31820710394400104\n",
            "Loss in iteration no. 119637 ==> 0.3182069336407551\n",
            "Loss in iteration no. 119638 ==> 0.31820676334084724\n",
            "Loss in iteration no. 119639 ==> 0.31820659304427695\n",
            "Loss in iteration no. 119640 ==> 0.3182064227510442\n",
            "Loss in iteration no. 119641 ==> 0.3182062524611493\n",
            "Loss in iteration no. 119642 ==> 0.3182060821745919\n",
            "Loss in iteration no. 119643 ==> 0.3182059118913718\n",
            "Loss in iteration no. 119644 ==> 0.3182057416114891\n",
            "Loss in iteration no. 119645 ==> 0.3182055713349436\n",
            "Loss in iteration no. 119646 ==> 0.31820540106173534\n",
            "Loss in iteration no. 119647 ==> 0.318205230791864\n",
            "Loss in iteration no. 119648 ==> 0.31820506052532976\n",
            "Loss in iteration no. 119649 ==> 0.3182048902621326\n",
            "Loss in iteration no. 119650 ==> 0.31820472000227223\n",
            "Loss in iteration no. 119651 ==> 0.31820454974574847\n",
            "Loss in iteration no. 119652 ==> 0.3182043794925615\n",
            "Loss in iteration no. 119653 ==> 0.31820420924271103\n",
            "Loss in iteration no. 119654 ==> 0.31820403899619704\n",
            "Loss in iteration no. 119655 ==> 0.31820386875301954\n",
            "Loss in iteration no. 119656 ==> 0.31820369851317826\n",
            "Loss in iteration no. 119657 ==> 0.31820352827667325\n",
            "Loss in iteration no. 119658 ==> 0.31820335804350436\n",
            "Loss in iteration no. 119659 ==> 0.31820318781367174\n",
            "Loss in iteration no. 119660 ==> 0.3182030175871749\n",
            "Loss in iteration no. 119661 ==> 0.3182028473640141\n",
            "Loss in iteration no. 119662 ==> 0.31820267714418904\n",
            "Loss in iteration no. 119663 ==> 0.3182025069276996\n",
            "Loss in iteration no. 119664 ==> 0.3182023367145461\n",
            "Loss in iteration no. 119665 ==> 0.318202166504728\n",
            "Loss in iteration no. 119666 ==> 0.31820199629824525\n",
            "Loss in iteration no. 119667 ==> 0.3182018260950983\n",
            "Loss in iteration no. 119668 ==> 0.3182016558952862\n",
            "Loss in iteration no. 119669 ==> 0.31820148569880974\n",
            "Loss in iteration no. 119670 ==> 0.31820131550566827\n",
            "Loss in iteration no. 119671 ==> 0.31820114531586186\n",
            "Loss in iteration no. 119672 ==> 0.31820097512939033\n",
            "Loss in iteration no. 119673 ==> 0.3182008049462539\n",
            "Loss in iteration no. 119674 ==> 0.3182006347664521\n",
            "Loss in iteration no. 119675 ==> 0.31820046458998513\n",
            "Loss in iteration no. 119676 ==> 0.31820029441685277\n",
            "Loss in iteration no. 119677 ==> 0.318200124247055\n",
            "Loss in iteration no. 119678 ==> 0.31819995408059154\n",
            "Loss in iteration no. 119679 ==> 0.31819978391746273\n",
            "Loss in iteration no. 119680 ==> 0.3181996137576679\n",
            "Loss in iteration no. 119681 ==> 0.3181994436012076\n",
            "Loss in iteration no. 119682 ==> 0.31819927344808124\n",
            "Loss in iteration no. 119683 ==> 0.3181991032982892\n",
            "Loss in iteration no. 119684 ==> 0.31819893315183084\n",
            "Loss in iteration no. 119685 ==> 0.3181987630087066\n",
            "Loss in iteration no. 119686 ==> 0.318198592868916\n",
            "Loss in iteration no. 119687 ==> 0.3181984227324591\n",
            "Loss in iteration no. 119688 ==> 0.3181982525993359\n",
            "Loss in iteration no. 119689 ==> 0.31819808246954623\n",
            "Loss in iteration no. 119690 ==> 0.31819791234309\n",
            "Loss in iteration no. 119691 ==> 0.3181977422199671\n",
            "Loss in iteration no. 119692 ==> 0.3181975721001776\n",
            "Loss in iteration no. 119693 ==> 0.3181974019837214\n",
            "Loss in iteration no. 119694 ==> 0.3181972318705981\n",
            "Loss in iteration no. 119695 ==> 0.3181970617608081\n",
            "Loss in iteration no. 119696 ==> 0.3181968916543509\n",
            "Loss in iteration no. 119697 ==> 0.3181967215512265\n",
            "Loss in iteration no. 119698 ==> 0.31819655145143505\n",
            "Loss in iteration no. 119699 ==> 0.31819638135497613\n",
            "Loss in iteration no. 119700 ==> 0.31819621126185005\n",
            "Loss in iteration no. 119701 ==> 0.31819604117205635\n",
            "Loss in iteration no. 119702 ==> 0.31819587108559527\n",
            "Loss in iteration no. 119703 ==> 0.31819570100246647\n",
            "Loss in iteration no. 119704 ==> 0.31819553092266994\n",
            "Loss in iteration no. 119705 ==> 0.31819536084620564\n",
            "Loss in iteration no. 119706 ==> 0.31819519077307346\n",
            "Loss in iteration no. 119707 ==> 0.3181950207032732\n",
            "Loss in iteration no. 119708 ==> 0.318194850636805\n",
            "Loss in iteration no. 119709 ==> 0.3181946805736688\n",
            "Loss in iteration no. 119710 ==> 0.3181945105138641\n",
            "Loss in iteration no. 119711 ==> 0.3181943404573913\n",
            "Loss in iteration no. 119712 ==> 0.3181941704042501\n",
            "Loss in iteration no. 119713 ==> 0.3181940003544403\n",
            "Loss in iteration no. 119714 ==> 0.318193830307962\n",
            "Loss in iteration no. 119715 ==> 0.3181936602648151\n",
            "Loss in iteration no. 119716 ==> 0.31819349022499954\n",
            "Loss in iteration no. 119717 ==> 0.31819332018851504\n",
            "Loss in iteration no. 119718 ==> 0.31819315015536165\n",
            "Loss in iteration no. 119719 ==> 0.31819298012553937\n",
            "Loss in iteration no. 119720 ==> 0.31819281009904815\n",
            "Loss in iteration no. 119721 ==> 0.31819264007588755\n",
            "Loss in iteration no. 119722 ==> 0.31819247005605783\n",
            "Loss in iteration no. 119723 ==> 0.3181923000395588\n",
            "Loss in iteration no. 119724 ==> 0.31819213002639035\n",
            "Loss in iteration no. 119725 ==> 0.3181919600165525\n",
            "Loss in iteration no. 119726 ==> 0.318191790010045\n",
            "Loss in iteration no. 119727 ==> 0.3181916200068679\n",
            "Loss in iteration no. 119728 ==> 0.31819145000702104\n",
            "Loss in iteration no. 119729 ==> 0.31819128001050434\n",
            "Loss in iteration no. 119730 ==> 0.3181911100173177\n",
            "Loss in iteration no. 119731 ==> 0.31819094002746123\n",
            "Loss in iteration no. 119732 ==> 0.3181907700409347\n",
            "Loss in iteration no. 119733 ==> 0.3181906000577379\n",
            "Loss in iteration no. 119734 ==> 0.318190430077871\n",
            "Loss in iteration no. 119735 ==> 0.31819026010133344\n",
            "Loss in iteration no. 119736 ==> 0.31819009012812577\n",
            "Loss in iteration no. 119737 ==> 0.3181899201582476\n",
            "Loss in iteration no. 119738 ==> 0.31818975019169876\n",
            "Loss in iteration no. 119739 ==> 0.3181895802284794\n",
            "Loss in iteration no. 119740 ==> 0.3181894102685892\n",
            "Loss in iteration no. 119741 ==> 0.3181892403120283\n",
            "Loss in iteration no. 119742 ==> 0.3181890703587963\n",
            "Loss in iteration no. 119743 ==> 0.3181889004088935\n",
            "Loss in iteration no. 119744 ==> 0.31818873046231955\n",
            "Loss in iteration no. 119745 ==> 0.3181885605190745\n",
            "Loss in iteration no. 119746 ==> 0.318188390579158\n",
            "Loss in iteration no. 119747 ==> 0.31818822064257035\n",
            "Loss in iteration no. 119748 ==> 0.31818805070931133\n",
            "Loss in iteration no. 119749 ==> 0.31818788077938065\n",
            "Loss in iteration no. 119750 ==> 0.3181877108527785\n",
            "Loss in iteration no. 119751 ==> 0.3181875409295046\n",
            "Loss in iteration no. 119752 ==> 0.318187371009559\n",
            "Loss in iteration no. 119753 ==> 0.3181872010929417\n",
            "Loss in iteration no. 119754 ==> 0.3181870311796523\n",
            "Loss in iteration no. 119755 ==> 0.3181868612696909\n",
            "Loss in iteration no. 119756 ==> 0.3181866913630575\n",
            "Loss in iteration no. 119757 ==> 0.318186521459752\n",
            "Loss in iteration no. 119758 ==> 0.31818635155977415\n",
            "Loss in iteration no. 119759 ==> 0.31818618166312385\n",
            "Loss in iteration no. 119760 ==> 0.31818601176980144\n",
            "Loss in iteration no. 119761 ==> 0.3181858418798062\n",
            "Loss in iteration no. 119762 ==> 0.3181856719931387\n",
            "Loss in iteration no. 119763 ==> 0.31818550210979835\n",
            "Loss in iteration no. 119764 ==> 0.3181853322297851\n",
            "Loss in iteration no. 119765 ==> 0.3181851623530993\n",
            "Loss in iteration no. 119766 ==> 0.31818499247974036\n",
            "Loss in iteration no. 119767 ==> 0.3181848226097085\n",
            "Loss in iteration no. 119768 ==> 0.31818465274300356\n",
            "Loss in iteration no. 119769 ==> 0.3181844828796256\n",
            "Loss in iteration no. 119770 ==> 0.3181843130195741\n",
            "Loss in iteration no. 119771 ==> 0.3181841431628494\n",
            "Loss in iteration no. 119772 ==> 0.3181839733094512\n",
            "Loss in iteration no. 119773 ==> 0.3181838034593795\n",
            "Loss in iteration no. 119774 ==> 0.31818363361263424\n",
            "Loss in iteration no. 119775 ==> 0.31818346376921536\n",
            "Loss in iteration no. 119776 ==> 0.3181832939291227\n",
            "Loss in iteration no. 119777 ==> 0.31818312409235605\n",
            "Loss in iteration no. 119778 ==> 0.3181829542589158\n",
            "Loss in iteration no. 119779 ==> 0.31818278442880127\n",
            "Loss in iteration no. 119780 ==> 0.3181826146020127\n",
            "Loss in iteration no. 119781 ==> 0.3181824447785499\n",
            "Loss in iteration no. 119782 ==> 0.3181822749584129\n",
            "Loss in iteration no. 119783 ==> 0.3181821051416015\n",
            "Loss in iteration no. 119784 ==> 0.31818193532811556\n",
            "Loss in iteration no. 119785 ==> 0.31818176551795546\n",
            "Loss in iteration no. 119786 ==> 0.31818159571112054\n",
            "Loss in iteration no. 119787 ==> 0.31818142590761084\n",
            "Loss in iteration no. 119788 ==> 0.3181812561074264\n",
            "Loss in iteration no. 119789 ==> 0.3181810863105673\n",
            "Loss in iteration no. 119790 ==> 0.3181809165170332\n",
            "Loss in iteration no. 119791 ==> 0.3181807467268239\n",
            "Loss in iteration no. 119792 ==> 0.31818057693993956\n",
            "Loss in iteration no. 119793 ==> 0.31818040715638024\n",
            "Loss in iteration no. 119794 ==> 0.3181802373761455\n",
            "Loss in iteration no. 119795 ==> 0.31818006759923545\n",
            "Loss in iteration no. 119796 ==> 0.3181798978256498\n",
            "Loss in iteration no. 119797 ==> 0.3181797280553887\n",
            "Loss in iteration no. 119798 ==> 0.3181795582884521\n",
            "Loss in iteration no. 119799 ==> 0.3181793885248398\n",
            "Loss in iteration no. 119800 ==> 0.3181792187645515\n",
            "Loss in iteration no. 119801 ==> 0.31817904900758753\n",
            "Loss in iteration no. 119802 ==> 0.3181788792539477\n",
            "Loss in iteration no. 119803 ==> 0.3181787095036317\n",
            "Loss in iteration no. 119804 ==> 0.3181785397566397\n",
            "Loss in iteration no. 119805 ==> 0.3181783700129714\n",
            "Loss in iteration no. 119806 ==> 0.3181782002726269\n",
            "Loss in iteration no. 119807 ==> 0.31817803053560606\n",
            "Loss in iteration no. 119808 ==> 0.3181778608019088\n",
            "Loss in iteration no. 119809 ==> 0.3181776910715348\n",
            "Loss in iteration no. 119810 ==> 0.3181775213444843\n",
            "Loss in iteration no. 119811 ==> 0.3181773516207572\n",
            "Loss in iteration no. 119812 ==> 0.31817718190035316\n",
            "Loss in iteration no. 119813 ==> 0.3181770121832724\n",
            "Loss in iteration no. 119814 ==> 0.31817684246951455\n",
            "Loss in iteration no. 119815 ==> 0.3181766727590797\n",
            "Loss in iteration no. 119816 ==> 0.3181765030519679\n",
            "Loss in iteration no. 119817 ==> 0.31817633334817874\n",
            "Loss in iteration no. 119818 ==> 0.3181761636477124\n",
            "Loss in iteration no. 119819 ==> 0.31817599395056845\n",
            "Loss in iteration no. 119820 ==> 0.3181758242567473\n",
            "Loss in iteration no. 119821 ==> 0.3181756545662485\n",
            "Loss in iteration no. 119822 ==> 0.3181754848790723\n",
            "Loss in iteration no. 119823 ==> 0.318175315195218\n",
            "Loss in iteration no. 119824 ==> 0.3181751455146863\n",
            "Loss in iteration no. 119825 ==> 0.31817497583747667\n",
            "Loss in iteration no. 119826 ==> 0.3181748061635889\n",
            "Loss in iteration no. 119827 ==> 0.31817463649302313\n",
            "Loss in iteration no. 119828 ==> 0.31817446682577943\n",
            "Loss in iteration no. 119829 ==> 0.31817429716185736\n",
            "Loss in iteration no. 119830 ==> 0.3181741275012569\n",
            "Loss in iteration no. 119831 ==> 0.31817395784397834\n",
            "Loss in iteration no. 119832 ==> 0.3181737881900211\n",
            "Loss in iteration no. 119833 ==> 0.3181736185393854\n",
            "Loss in iteration no. 119834 ==> 0.31817344889207116\n",
            "Loss in iteration no. 119835 ==> 0.318173279248078\n",
            "Loss in iteration no. 119836 ==> 0.31817310960740625\n",
            "Loss in iteration no. 119837 ==> 0.31817293997005547\n",
            "Loss in iteration no. 119838 ==> 0.31817277033602587\n",
            "Loss in iteration no. 119839 ==> 0.31817260070531717\n",
            "Loss in iteration no. 119840 ==> 0.3181724310779293\n",
            "Loss in iteration no. 119841 ==> 0.31817226145386235\n",
            "Loss in iteration no. 119842 ==> 0.318172091833116\n",
            "Loss in iteration no. 119843 ==> 0.31817192221569024\n",
            "Loss in iteration no. 119844 ==> 0.3181717526015851\n",
            "Loss in iteration no. 119845 ==> 0.3181715829908004\n",
            "Loss in iteration no. 119846 ==> 0.318171413383336\n",
            "Loss in iteration no. 119847 ==> 0.31817124377919204\n",
            "Loss in iteration no. 119848 ==> 0.31817107417836804\n",
            "Loss in iteration no. 119849 ==> 0.31817090458086444\n",
            "Loss in iteration no. 119850 ==> 0.3181707349866807\n",
            "Loss in iteration no. 119851 ==> 0.3181705653958171\n",
            "Loss in iteration no. 119852 ==> 0.31817039580827317\n",
            "Loss in iteration no. 119853 ==> 0.31817022622404906\n",
            "Loss in iteration no. 119854 ==> 0.3181700566431448\n",
            "Loss in iteration no. 119855 ==> 0.3181698870655598\n",
            "Loss in iteration no. 119856 ==> 0.31816971749129475\n",
            "Loss in iteration no. 119857 ==> 0.31816954792034885\n",
            "Loss in iteration no. 119858 ==> 0.31816937835272247\n",
            "Loss in iteration no. 119859 ==> 0.3181692087884153\n",
            "Loss in iteration no. 119860 ==> 0.31816903922742734\n",
            "Loss in iteration no. 119861 ==> 0.3181688696697586\n",
            "Loss in iteration no. 119862 ==> 0.3181687001154088\n",
            "Loss in iteration no. 119863 ==> 0.3181685305643779\n",
            "Loss in iteration no. 119864 ==> 0.3181683610166661\n",
            "Loss in iteration no. 119865 ==> 0.3181681914722729\n",
            "Loss in iteration no. 119866 ==> 0.3181680219311983\n",
            "Loss in iteration no. 119867 ==> 0.3181678523934425\n",
            "Loss in iteration no. 119868 ==> 0.3181676828590051\n",
            "Loss in iteration no. 119869 ==> 0.3181675133278863\n",
            "Loss in iteration no. 119870 ==> 0.31816734380008554\n",
            "Loss in iteration no. 119871 ==> 0.3181671742756033\n",
            "Loss in iteration no. 119872 ==> 0.3181670047544394\n",
            "Loss in iteration no. 119873 ==> 0.31816683523659345\n",
            "Loss in iteration no. 119874 ==> 0.3181666657220655\n",
            "Loss in iteration no. 119875 ==> 0.3181664962108555\n",
            "Loss in iteration no. 119876 ==> 0.3181663267029634\n",
            "Loss in iteration no. 119877 ==> 0.31816615719838914\n",
            "Loss in iteration no. 119878 ==> 0.31816598769713245\n",
            "Loss in iteration no. 119879 ==> 0.3181658181991934\n",
            "Loss in iteration no. 119880 ==> 0.31816564870457187\n",
            "Loss in iteration no. 119881 ==> 0.3181654792132678\n",
            "Loss in iteration no. 119882 ==> 0.3181653097252812\n",
            "Loss in iteration no. 119883 ==> 0.3181651402406117\n",
            "Loss in iteration no. 119884 ==> 0.3181649707592596\n",
            "Loss in iteration no. 119885 ==> 0.31816480128122426\n",
            "Loss in iteration no. 119886 ==> 0.31816463180650634\n",
            "Loss in iteration no. 119887 ==> 0.31816446233510515\n",
            "Loss in iteration no. 119888 ==> 0.3181642928670208\n",
            "Loss in iteration no. 119889 ==> 0.3181641234022532\n",
            "Loss in iteration no. 119890 ==> 0.3181639539408025\n",
            "Loss in iteration no. 119891 ==> 0.3181637844826682\n",
            "Loss in iteration no. 119892 ==> 0.31816361502785057\n",
            "Loss in iteration no. 119893 ==> 0.3181634455763492\n",
            "Loss in iteration no. 119894 ==> 0.31816327612816436\n",
            "Loss in iteration no. 119895 ==> 0.31816310668329567\n",
            "Loss in iteration no. 119896 ==> 0.31816293724174327\n",
            "Loss in iteration no. 119897 ==> 0.3181627678035069\n",
            "Loss in iteration no. 119898 ==> 0.31816259836858657\n",
            "Loss in iteration no. 119899 ==> 0.31816242893698216\n",
            "Loss in iteration no. 119900 ==> 0.31816225950869353\n",
            "Loss in iteration no. 119901 ==> 0.31816209008372076\n",
            "Loss in iteration no. 119902 ==> 0.3181619206620637\n",
            "Loss in iteration no. 119903 ==> 0.31816175124372226\n",
            "Loss in iteration no. 119904 ==> 0.31816158182869636\n",
            "Loss in iteration no. 119905 ==> 0.3181614124169859\n",
            "Loss in iteration no. 119906 ==> 0.31816124300859056\n",
            "Loss in iteration no. 119907 ==> 0.31816107360351076\n",
            "Loss in iteration no. 119908 ==> 0.31816090420174603\n",
            "Loss in iteration no. 119909 ==> 0.3181607348032965\n",
            "Loss in iteration no. 119910 ==> 0.31816056540816173\n",
            "Loss in iteration no. 119911 ==> 0.31816039601634233\n",
            "Loss in iteration no. 119912 ==> 0.3181602266278375\n",
            "Loss in iteration no. 119913 ==> 0.31816005724264734\n",
            "Loss in iteration no. 119914 ==> 0.3181598878607721\n",
            "Loss in iteration no. 119915 ==> 0.31815971848221136\n",
            "Loss in iteration no. 119916 ==> 0.3181595491069652\n",
            "Loss in iteration no. 119917 ==> 0.31815937973503333\n",
            "Loss in iteration no. 119918 ==> 0.3181592103664158\n",
            "Loss in iteration no. 119919 ==> 0.3181590410011126\n",
            "Loss in iteration no. 119920 ==> 0.31815887163912354\n",
            "Loss in iteration no. 119921 ==> 0.3181587022804489\n",
            "Loss in iteration no. 119922 ==> 0.3181585329250878\n",
            "Loss in iteration no. 119923 ==> 0.318158363573041\n",
            "Loss in iteration no. 119924 ==> 0.31815819422430774\n",
            "Loss in iteration no. 119925 ==> 0.3181580248788885\n",
            "Loss in iteration no. 119926 ==> 0.31815785553678283\n",
            "Loss in iteration no. 119927 ==> 0.31815768619799084\n",
            "Loss in iteration no. 119928 ==> 0.3181575168625122\n",
            "Loss in iteration no. 119929 ==> 0.31815734753034713\n",
            "Loss in iteration no. 119930 ==> 0.3181571782014954\n",
            "Loss in iteration no. 119931 ==> 0.3181570088759568\n",
            "Loss in iteration no. 119932 ==> 0.31815683955373164\n",
            "Loss in iteration no. 119933 ==> 0.31815667023481925\n",
            "Loss in iteration no. 119934 ==> 0.3181565009192202\n",
            "Loss in iteration no. 119935 ==> 0.31815633160693374\n",
            "Loss in iteration no. 119936 ==> 0.3181561622979605\n",
            "Loss in iteration no. 119937 ==> 0.31815599299229985\n",
            "Loss in iteration no. 119938 ==> 0.3181558236899519\n",
            "Loss in iteration no. 119939 ==> 0.3181556543909164\n",
            "Loss in iteration no. 119940 ==> 0.3181554850951937\n",
            "Loss in iteration no. 119941 ==> 0.3181553158027831\n",
            "Loss in iteration no. 119942 ==> 0.31815514651368504\n",
            "Loss in iteration no. 119943 ==> 0.31815497722789915\n",
            "Loss in iteration no. 119944 ==> 0.3181548079454255\n",
            "Loss in iteration no. 119945 ==> 0.3181546386662639\n",
            "Loss in iteration no. 119946 ==> 0.3181544693904145\n",
            "Loss in iteration no. 119947 ==> 0.3181543001178768\n",
            "Loss in iteration no. 119948 ==> 0.318154130848651\n",
            "Loss in iteration no. 119949 ==> 0.31815396158273707\n",
            "Loss in iteration no. 119950 ==> 0.3181537923201347\n",
            "Loss in iteration no. 119951 ==> 0.31815362306084394\n",
            "Loss in iteration no. 119952 ==> 0.3181534538048648\n",
            "Loss in iteration no. 119953 ==> 0.31815328455219705\n",
            "Loss in iteration no. 119954 ==> 0.3181531153028405\n",
            "Loss in iteration no. 119955 ==> 0.3181529460567954\n",
            "Loss in iteration no. 119956 ==> 0.31815277681406134\n",
            "Loss in iteration no. 119957 ==> 0.31815260757463837\n",
            "Loss in iteration no. 119958 ==> 0.3181524383385265\n",
            "Loss in iteration no. 119959 ==> 0.3181522691057257\n",
            "Loss in iteration no. 119960 ==> 0.31815209987623533\n",
            "Loss in iteration no. 119961 ==> 0.3181519306500561\n",
            "Loss in iteration no. 119962 ==> 0.3181517614271874\n",
            "Loss in iteration no. 119963 ==> 0.3181515922076291\n",
            "Loss in iteration no. 119964 ==> 0.3181514229913816\n",
            "Loss in iteration no. 119965 ==> 0.3181512537784446\n",
            "Loss in iteration no. 119966 ==> 0.31815108456881763\n",
            "Loss in iteration no. 119967 ==> 0.3181509153625011\n",
            "Loss in iteration no. 119968 ==> 0.31815074615949474\n",
            "Loss in iteration no. 119969 ==> 0.31815057695979837\n",
            "Loss in iteration no. 119970 ==> 0.31815040776341225\n",
            "Loss in iteration no. 119971 ==> 0.318150238570336\n",
            "Loss in iteration no. 119972 ==> 0.31815006938056944\n",
            "Loss in iteration no. 119973 ==> 0.31814990019411254\n",
            "Loss in iteration no. 119974 ==> 0.3181497310109656\n",
            "Loss in iteration no. 119975 ==> 0.3181495618311281\n",
            "Loss in iteration no. 119976 ==> 0.31814939265460007\n",
            "Loss in iteration no. 119977 ==> 0.3181492234813816\n",
            "Loss in iteration no. 119978 ==> 0.3181490543114724\n",
            "Loss in iteration no. 119979 ==> 0.3181488851448725\n",
            "Loss in iteration no. 119980 ==> 0.31814871598158173\n",
            "Loss in iteration no. 119981 ==> 0.3181485468216\n",
            "Loss in iteration no. 119982 ==> 0.3181483776649273\n",
            "Loss in iteration no. 119983 ==> 0.31814820851156367\n",
            "Loss in iteration no. 119984 ==> 0.31814803936150876\n",
            "Loss in iteration no. 119985 ==> 0.31814787021476276\n",
            "Loss in iteration no. 119986 ==> 0.3181477010713251\n",
            "Loss in iteration no. 119987 ==> 0.3181475319311963\n",
            "Loss in iteration no. 119988 ==> 0.31814736279437605\n",
            "Loss in iteration no. 119989 ==> 0.3181471936608641\n",
            "Loss in iteration no. 119990 ==> 0.31814702453066046\n",
            "Loss in iteration no. 119991 ==> 0.3181468554037652\n",
            "Loss in iteration no. 119992 ==> 0.318146686280178\n",
            "Loss in iteration no. 119993 ==> 0.3181465171598989\n",
            "Loss in iteration no. 119994 ==> 0.3181463480429279\n",
            "Loss in iteration no. 119995 ==> 0.31814617892926494\n",
            "Loss in iteration no. 119996 ==> 0.31814600981890956\n",
            "Loss in iteration no. 119997 ==> 0.318145840711862\n",
            "Loss in iteration no. 119998 ==> 0.31814567160812224\n",
            "Loss in iteration no. 119999 ==> 0.31814550250768997\n",
            "Loss in iteration no. 120000 ==> 0.3181453334105653\n"
          ]
        }
      ],
      "source": [
        "for i,loss in enumerate(model.model_loss):\n",
        "  print(f\"Loss in iteration no. {i+1} ==> {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV9Ubdg_O2IJ",
        "outputId": "37ee1837-18bc-4118-be6f-86e567bcda9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the Logistic Regression Model ==> 82.61%\n",
            "Number of Correct Predictions ==> 57\n",
            "Number of Wrong Predictions ==> 12\n"
          ]
        }
      ],
      "source": [
        "# SET : 3\n",
        "\n",
        "weights_latest = None\n",
        "model = LogitRegression(learning_rate = 0.06, num_of_iter = 200000)\n",
        "\n",
        "y_train = y_train.squeeze()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "accuracy_vald = np.random.rand()\n",
        "\n",
        "if accuracy_vald > accuracy:\n",
        "  accuracy = accuracy_vald\n",
        "  weights_latest = {\n",
        "      \"weights\" : model.weights.tolist(),\n",
        "      \"bias\" : model.bias\n",
        "  }\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "y_test = y_test.squeeze()\n",
        "prediction_truth_values = (predictions == y_test).astype(int)\n",
        "accuracy = np.mean(prediction_truth_values) * 100\n",
        "\n",
        "print(f\"Accuracy of the Logistic Regression Model ==> {accuracy:.2f}%\")\n",
        "print(f\"Number of Correct Predictions ==> {round((accuracy/100) * 69)}\")\n",
        "print(f\"Number of Wrong Predictions ==> {round(69 - ((accuracy/100) * 69))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO4A7phtTmbx",
        "outputId": "716c79da-c6e6-40ce-c276-b70da0a5059e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-11.123115440795031, -3.0307682591837106, 0.027828069248468246, 6.1099154025473075, 7.344389514658723, 2.888345818012927, 15.352090619246486]\n"
          ]
        }
      ],
      "source": [
        "print(model.weights.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "id": "QUYbYYsETpVV",
        "outputId": "1a2b01ca-67e7-4928-b22b-6701fbfc2abf"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "\n",
        "plt.plot(np.arange(model.num_of_iter), model.model_loss)\n",
        "\n",
        "plt.xlabel(\"No. of Iterations\")\n",
        "plt.ylabel(\"Loss Values\")\n",
        "\n",
        "plt.title(\"SET 3 : Loss values w.r.t. no. of iterations\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etAas4A7TrTR",
        "outputId": "4e7d2bff-ba35-4b67-98c9-fee9df0d181b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Loss in iteration no. 80991 ==> 0.3073522618101099\n",
            "Loss in iteration no. 80992 ==> 0.30735225115239934\n",
            "Loss in iteration no. 80993 ==> 0.3073522404953244\n",
            "Loss in iteration no. 80994 ==> 0.307352229838885\n",
            "Loss in iteration no. 80995 ==> 0.30735221918308187\n",
            "Loss in iteration no. 80996 ==> 0.3073522085279152\n",
            "Loss in iteration no. 80997 ==> 0.3073521978733839\n",
            "Loss in iteration no. 80998 ==> 0.30735218721948854\n",
            "Loss in iteration no. 80999 ==> 0.30735217656622865\n",
            "Loss in iteration no. 81000 ==> 0.3073521659136051\n",
            "Loss in iteration no. 81001 ==> 0.3073521552616167\n",
            "Loss in iteration no. 81002 ==> 0.307352144610264\n",
            "Loss in iteration no. 81003 ==> 0.30735213395954725\n",
            "Loss in iteration no. 81004 ==> 0.3073521233094662\n",
            "Loss in iteration no. 81005 ==> 0.30735211266002027\n",
            "Loss in iteration no. 81006 ==> 0.3073521020112095\n",
            "Loss in iteration no. 81007 ==> 0.3073520913630353\n",
            "Loss in iteration no. 81008 ==> 0.3073520807154956\n",
            "Loss in iteration no. 81009 ==> 0.30735207006859133\n",
            "Loss in iteration no. 81010 ==> 0.30735205942232285\n",
            "Loss in iteration no. 81011 ==> 0.30735204877669\n",
            "Loss in iteration no. 81012 ==> 0.3073520381316913\n",
            "Loss in iteration no. 81013 ==> 0.30735202748732865\n",
            "Loss in iteration no. 81014 ==> 0.30735201684360086\n",
            "Loss in iteration no. 81015 ==> 0.3073520062005084\n",
            "Loss in iteration no. 81016 ==> 0.30735199555805065\n",
            "Loss in iteration no. 81017 ==> 0.30735198491622884\n",
            "Loss in iteration no. 81018 ==> 0.3073519742750408\n",
            "Loss in iteration no. 81019 ==> 0.3073519636344893\n",
            "Loss in iteration no. 81020 ==> 0.30735195299457135\n",
            "Loss in iteration no. 81021 ==> 0.30735194235528823\n",
            "Loss in iteration no. 81022 ==> 0.307351931716641\n",
            "Loss in iteration no. 81023 ==> 0.30735192107862813\n",
            "Loss in iteration no. 81024 ==> 0.3073519104412499\n",
            "Loss in iteration no. 81025 ==> 0.3073518998045072\n",
            "Loss in iteration no. 81026 ==> 0.3073518891683988\n",
            "Loss in iteration no. 81027 ==> 0.30735187853292456\n",
            "Loss in iteration no. 81028 ==> 0.3073518678980853\n",
            "Loss in iteration no. 81029 ==> 0.3073518572638799\n",
            "Loss in iteration no. 81030 ==> 0.3073518466303107\n",
            "Loss in iteration no. 81031 ==> 0.30735183599737437\n",
            "Loss in iteration no. 81032 ==> 0.3073518253650735\n",
            "Loss in iteration no. 81033 ==> 0.3073518147334069\n",
            "Loss in iteration no. 81034 ==> 0.30735180410237406\n",
            "Loss in iteration no. 81035 ==> 0.30735179347197594\n",
            "Loss in iteration no. 81036 ==> 0.30735178284221276\n",
            "Loss in iteration no. 81037 ==> 0.30735177221308285\n",
            "Loss in iteration no. 81038 ==> 0.3073517615845882\n",
            "Loss in iteration no. 81039 ==> 0.3073517509567271\n",
            "Loss in iteration no. 81040 ==> 0.3073517403295002\n",
            "Loss in iteration no. 81041 ==> 0.30735172970290703\n",
            "Loss in iteration no. 81042 ==> 0.3073517190769489\n",
            "Loss in iteration no. 81043 ==> 0.30735170845162385\n",
            "Loss in iteration no. 81044 ==> 0.3073516978269335\n",
            "Loss in iteration no. 81045 ==> 0.30735168720287653\n",
            "Loss in iteration no. 81046 ==> 0.3073516765794537\n",
            "Loss in iteration no. 81047 ==> 0.3073516659566649\n",
            "Loss in iteration no. 81048 ==> 0.3073516553345096\n",
            "Loss in iteration no. 81049 ==> 0.307351644712989\n",
            "Loss in iteration no. 81050 ==> 0.30735163409210137\n",
            "Loss in iteration no. 81051 ==> 0.30735162347184736\n",
            "Loss in iteration no. 81052 ==> 0.3073516128522274\n",
            "Loss in iteration no. 81053 ==> 0.3073516022332405\n",
            "Loss in iteration no. 81054 ==> 0.3073515916148881\n",
            "Loss in iteration no. 81055 ==> 0.30735158099716836\n",
            "Loss in iteration no. 81056 ==> 0.30735157038008304\n",
            "Loss in iteration no. 81057 ==> 0.3073515597636304\n",
            "Loss in iteration no. 81058 ==> 0.307351549147812\n",
            "Loss in iteration no. 81059 ==> 0.30735153853262576\n",
            "Loss in iteration no. 81060 ==> 0.30735152791807413\n",
            "Loss in iteration no. 81061 ==> 0.3073515173041555\n",
            "Loss in iteration no. 81062 ==> 0.3073515066908693\n",
            "Loss in iteration no. 81063 ==> 0.30735149607821766\n",
            "Loss in iteration no. 81064 ==> 0.3073514854661985\n",
            "Loss in iteration no. 81065 ==> 0.307351474854813\n",
            "Loss in iteration no. 81066 ==> 0.3073514642440595\n",
            "Loss in iteration no. 81067 ==> 0.30735145363394023\n",
            "Loss in iteration no. 81068 ==> 0.30735144302445394\n",
            "Loss in iteration no. 81069 ==> 0.3073514324155997\n",
            "Loss in iteration no. 81070 ==> 0.30735142180737907\n",
            "Loss in iteration no. 81071 ==> 0.3073514111997914\n",
            "Loss in iteration no. 81072 ==> 0.3073514005928365\n",
            "Loss in iteration no. 81073 ==> 0.3073513899865149\n",
            "Loss in iteration no. 81074 ==> 0.3073513793808257\n",
            "Loss in iteration no. 81075 ==> 0.30735136877576885\n",
            "Loss in iteration no. 81076 ==> 0.30735135817134546\n",
            "Loss in iteration no. 81077 ==> 0.3073513475675543\n",
            "Loss in iteration no. 81078 ==> 0.307351336964396\n",
            "Loss in iteration no. 81079 ==> 0.30735132636187046\n",
            "Loss in iteration no. 81080 ==> 0.30735131575997676\n",
            "Loss in iteration no. 81081 ==> 0.3073513051587161\n",
            "Loss in iteration no. 81082 ==> 0.3073512945580881\n",
            "Loss in iteration no. 81083 ==> 0.30735128395809236\n",
            "Loss in iteration no. 81084 ==> 0.3073512733587291\n",
            "Loss in iteration no. 81085 ==> 0.30735126275999847\n",
            "Loss in iteration no. 81086 ==> 0.30735125216189957\n",
            "Loss in iteration no. 81087 ==> 0.3073512415644331\n",
            "Loss in iteration no. 81088 ==> 0.30735123096759953\n",
            "Loss in iteration no. 81089 ==> 0.3073512203713974\n",
            "Loss in iteration no. 81090 ==> 0.3073512097758276\n",
            "Loss in iteration no. 81091 ==> 0.30735119918089066\n",
            "Loss in iteration no. 81092 ==> 0.30735118858658544\n",
            "Loss in iteration no. 81093 ==> 0.3073511779929116\n",
            "Loss in iteration no. 81094 ==> 0.30735116739987006\n",
            "Loss in iteration no. 81095 ==> 0.3073511568074612\n",
            "Loss in iteration no. 81096 ==> 0.3073511462156836\n",
            "Loss in iteration no. 81097 ==> 0.30735113562453753\n",
            "Loss in iteration no. 81098 ==> 0.3073511250340243\n",
            "Loss in iteration no. 81099 ==> 0.3073511144441423\n",
            "Loss in iteration no. 81100 ==> 0.3073511038548922\n",
            "Loss in iteration no. 81101 ==> 0.3073510932662741\n",
            "Loss in iteration no. 81102 ==> 0.3073510826782876\n",
            "Loss in iteration no. 81103 ==> 0.3073510720909325\n",
            "Loss in iteration no. 81104 ==> 0.30735106150420916\n",
            "Loss in iteration no. 81105 ==> 0.30735105091811754\n",
            "Loss in iteration no. 81106 ==> 0.30735104033265753\n",
            "Loss in iteration no. 81107 ==> 0.30735102974782863\n",
            "Loss in iteration no. 81108 ==> 0.30735101916363156\n",
            "Loss in iteration no. 81109 ==> 0.3073510085800654\n",
            "Loss in iteration no. 81110 ==> 0.30735099799713145\n",
            "Loss in iteration no. 81111 ==> 0.3073509874148277\n",
            "Loss in iteration no. 81112 ==> 0.3073509768331559\n",
            "Loss in iteration no. 81113 ==> 0.3073509662521154\n",
            "Loss in iteration no. 81114 ==> 0.30735095567170656\n",
            "Loss in iteration no. 81115 ==> 0.30735094509192873\n",
            "Loss in iteration no. 81116 ==> 0.30735093451278145\n",
            "Loss in iteration no. 81117 ==> 0.3073509239342661\n",
            "Loss in iteration no. 81118 ==> 0.3073509133563808\n",
            "Loss in iteration no. 81119 ==> 0.3073509027791273\n",
            "Loss in iteration no. 81120 ==> 0.3073508922025048\n",
            "Loss in iteration no. 81121 ==> 0.3073508816265127\n",
            "Loss in iteration no. 81122 ==> 0.30735087105115144\n",
            "Loss in iteration no. 81123 ==> 0.3073508604764217\n",
            "Loss in iteration no. 81124 ==> 0.30735084990232303\n",
            "Loss in iteration no. 81125 ==> 0.30735083932885426\n",
            "Loss in iteration no. 81126 ==> 0.30735082875601705\n",
            "Loss in iteration no. 81127 ==> 0.3073508181838095\n",
            "Loss in iteration no. 81128 ==> 0.30735080761223355\n",
            "Loss in iteration no. 81129 ==> 0.3073507970412877\n",
            "Loss in iteration no. 81130 ==> 0.3073507864709737\n",
            "Loss in iteration no. 81131 ==> 0.30735077590128906\n",
            "Loss in iteration no. 81132 ==> 0.3073507653322346\n",
            "Loss in iteration no. 81133 ==> 0.3073507547638113\n",
            "Loss in iteration no. 81134 ==> 0.3073507441960184\n",
            "Loss in iteration no. 81135 ==> 0.30735073362885607\n",
            "Loss in iteration no. 81136 ==> 0.3073507230623235\n",
            "Loss in iteration no. 81137 ==> 0.3073507124964222\n",
            "Loss in iteration no. 81138 ==> 0.3073507019311509\n",
            "Loss in iteration no. 81139 ==> 0.3073506913665095\n",
            "Loss in iteration no. 81140 ==> 0.30735068080249783\n",
            "Loss in iteration no. 81141 ==> 0.3073506702391167\n",
            "Loss in iteration no. 81142 ==> 0.3073506596763665\n",
            "Loss in iteration no. 81143 ==> 0.30735064911424587\n",
            "Loss in iteration no. 81144 ==> 0.3073506385527544\n",
            "Loss in iteration no. 81145 ==> 0.3073506279918941\n",
            "Loss in iteration no. 81146 ==> 0.3073506174316635\n",
            "Loss in iteration no. 81147 ==> 0.3073506068720624\n",
            "Loss in iteration no. 81148 ==> 0.3073505963130916\n",
            "Loss in iteration no. 81149 ==> 0.30735058575475077\n",
            "Loss in iteration no. 81150 ==> 0.3073505751970394\n",
            "Loss in iteration no. 81151 ==> 0.3073505646399578\n",
            "Loss in iteration no. 81152 ==> 0.30735055408350614\n",
            "Loss in iteration no. 81153 ==> 0.3073505435276844\n",
            "Loss in iteration no. 81154 ==> 0.30735053297249154\n",
            "Loss in iteration no. 81155 ==> 0.30735052241792876\n",
            "Loss in iteration no. 81156 ==> 0.3073505118639952\n",
            "Loss in iteration no. 81157 ==> 0.30735050131069197\n",
            "Loss in iteration no. 81158 ==> 0.30735049075801807\n",
            "Loss in iteration no. 81159 ==> 0.3073504802059736\n",
            "Loss in iteration no. 81160 ==> 0.3073504696545579\n",
            "Loss in iteration no. 81161 ==> 0.3073504591037718\n",
            "Loss in iteration no. 81162 ==> 0.3073504485536151\n",
            "Loss in iteration no. 81163 ==> 0.3073504380040882\n",
            "Loss in iteration no. 81164 ==> 0.3073504274551902\n",
            "Loss in iteration no. 81165 ==> 0.307350416906921\n",
            "Loss in iteration no. 81166 ==> 0.3073504063592818\n",
            "Loss in iteration no. 81167 ==> 0.30735039581227147\n",
            "Loss in iteration no. 81168 ==> 0.30735038526588937\n",
            "Loss in iteration no. 81169 ==> 0.30735037472013726\n",
            "Loss in iteration no. 81170 ==> 0.3073503641750148\n",
            "Loss in iteration no. 81171 ==> 0.3073503536305197\n",
            "Loss in iteration no. 81172 ==> 0.3073503430866549\n",
            "Loss in iteration no. 81173 ==> 0.3073503325434189\n",
            "Loss in iteration no. 81174 ==> 0.3073503220008106\n",
            "Loss in iteration no. 81175 ==> 0.3073503114588325\n",
            "Loss in iteration no. 81176 ==> 0.3073503009174823\n",
            "Loss in iteration no. 81177 ==> 0.30735029037676065\n",
            "Loss in iteration no. 81178 ==> 0.30735027983666857\n",
            "Loss in iteration no. 81179 ==> 0.307350269297205\n",
            "Loss in iteration no. 81180 ==> 0.30735025875836963\n",
            "Loss in iteration no. 81181 ==> 0.3073502482201632\n",
            "Loss in iteration no. 81182 ==> 0.30735023768258496\n",
            "Loss in iteration no. 81183 ==> 0.3073502271456355\n",
            "Loss in iteration no. 81184 ==> 0.30735021660931444\n",
            "Loss in iteration no. 81185 ==> 0.30735020607362196\n",
            "Loss in iteration no. 81186 ==> 0.307350195538558\n",
            "Loss in iteration no. 81187 ==> 0.3073501850041217\n",
            "Loss in iteration no. 81188 ==> 0.3073501744703146\n",
            "Loss in iteration no. 81189 ==> 0.307350163937135\n",
            "Loss in iteration no. 81190 ==> 0.30735015340458405\n",
            "Loss in iteration no. 81191 ==> 0.307350142872662\n",
            "Loss in iteration no. 81192 ==> 0.3073501323413671\n",
            "Loss in iteration no. 81193 ==> 0.30735012181070015\n",
            "Loss in iteration no. 81194 ==> 0.3073501112806623\n",
            "Loss in iteration no. 81195 ==> 0.3073501007512514\n",
            "Loss in iteration no. 81196 ==> 0.3073500902224693\n",
            "Loss in iteration no. 81197 ==> 0.3073500796943148\n",
            "Loss in iteration no. 81198 ==> 0.3073500691667883\n",
            "Loss in iteration no. 81199 ==> 0.30735005863988996\n",
            "Loss in iteration no. 81200 ==> 0.3073500481136193\n",
            "Loss in iteration no. 81201 ==> 0.30735003758797624\n",
            "Loss in iteration no. 81202 ==> 0.3073500270629609\n",
            "Loss in iteration no. 81203 ==> 0.30735001653857363\n",
            "Loss in iteration no. 81204 ==> 0.3073500060148138\n",
            "Loss in iteration no. 81205 ==> 0.30734999549168174\n",
            "Loss in iteration no. 81206 ==> 0.30734998496917754\n",
            "Loss in iteration no. 81207 ==> 0.3073499744473005\n",
            "Loss in iteration no. 81208 ==> 0.30734996392605124\n",
            "Loss in iteration no. 81209 ==> 0.30734995340542903\n",
            "Loss in iteration no. 81210 ==> 0.30734994288543516\n",
            "Loss in iteration no. 81211 ==> 0.30734993236606767\n",
            "Loss in iteration no. 81212 ==> 0.30734992184732846\n",
            "Loss in iteration no. 81213 ==> 0.3073499113292166\n",
            "Loss in iteration no. 81214 ==> 0.30734990081173125\n",
            "Loss in iteration no. 81215 ==> 0.3073498902948739\n",
            "Loss in iteration no. 81216 ==> 0.3073498797786429\n",
            "Loss in iteration no. 81217 ==> 0.3073498692630401\n",
            "Loss in iteration no. 81218 ==> 0.30734985874806386\n",
            "Loss in iteration no. 81219 ==> 0.3073498482337148\n",
            "Loss in iteration no. 81220 ==> 0.30734983771999264\n",
            "Loss in iteration no. 81221 ==> 0.3073498272068979\n",
            "Loss in iteration no. 81222 ==> 0.30734981669443\n",
            "Loss in iteration no. 81223 ==> 0.3073498061825884\n",
            "Loss in iteration no. 81224 ==> 0.3073497956713751\n",
            "Loss in iteration no. 81225 ==> 0.307349785160787\n",
            "Loss in iteration no. 81226 ==> 0.3073497746508271\n",
            "Loss in iteration no. 81227 ==> 0.3073497641414934\n",
            "Loss in iteration no. 81228 ==> 0.30734975363278694\n",
            "Loss in iteration no. 81229 ==> 0.3073497431247068\n",
            "Loss in iteration no. 81230 ==> 0.3073497326172529\n",
            "Loss in iteration no. 81231 ==> 0.30734972211042616\n",
            "Loss in iteration no. 81232 ==> 0.3073497116042263\n",
            "Loss in iteration no. 81233 ==> 0.3073497010986521\n",
            "Loss in iteration no. 81234 ==> 0.3073496905937049\n",
            "Loss in iteration no. 81235 ==> 0.3073496800893844\n",
            "Loss in iteration no. 81236 ==> 0.30734966958569054\n",
            "Loss in iteration no. 81237 ==> 0.30734965908262224\n",
            "Loss in iteration no. 81238 ==> 0.3073496485801804\n",
            "Loss in iteration no. 81239 ==> 0.3073496380783656\n",
            "Loss in iteration no. 81240 ==> 0.3073496275771767\n",
            "Loss in iteration no. 81241 ==> 0.3073496170766147\n",
            "Loss in iteration no. 81242 ==> 0.3073496065766779\n",
            "Loss in iteration no. 81243 ==> 0.30734959607736745\n",
            "Loss in iteration no. 81244 ==> 0.3073495855786837\n",
            "Loss in iteration no. 81245 ==> 0.30734957508062527\n",
            "Loss in iteration no. 81246 ==> 0.3073495645831938\n",
            "Loss in iteration no. 81247 ==> 0.3073495540863874\n",
            "Loss in iteration no. 81248 ==> 0.3073495435902079\n",
            "Loss in iteration no. 81249 ==> 0.3073495330946537\n",
            "Loss in iteration no. 81250 ==> 0.3073495225997256\n",
            "Loss in iteration no. 81251 ==> 0.30734951210542283\n",
            "Loss in iteration no. 81252 ==> 0.3073495016117464\n",
            "Loss in iteration no. 81253 ==> 0.3073494911186963\n",
            "Loss in iteration no. 81254 ==> 0.3073494806262707\n",
            "Loss in iteration no. 81255 ==> 0.30734947013447117\n",
            "Loss in iteration no. 81256 ==> 0.30734945964329774\n",
            "Loss in iteration no. 81257 ==> 0.3073494491527498\n",
            "Loss in iteration no. 81258 ==> 0.3073494386628277\n",
            "Loss in iteration no. 81259 ==> 0.30734942817353006\n",
            "Loss in iteration no. 81260 ==> 0.30734941768485863\n",
            "Loss in iteration no. 81261 ==> 0.3073494071968131\n",
            "Loss in iteration no. 81262 ==> 0.30734939670939265\n",
            "Loss in iteration no. 81263 ==> 0.30734938622259755\n",
            "Loss in iteration no. 81264 ==> 0.3073493757364275\n",
            "Loss in iteration no. 81265 ==> 0.30734936525088336\n",
            "Loss in iteration no. 81266 ==> 0.30734935476596403\n",
            "Loss in iteration no. 81267 ==> 0.30734934428167\n",
            "Loss in iteration no. 81268 ==> 0.3073493337980011\n",
            "Loss in iteration no. 81269 ==> 0.30734932331495823\n",
            "Loss in iteration no. 81270 ==> 0.3073493128325389\n",
            "Loss in iteration no. 81271 ==> 0.3073493023507455\n",
            "Loss in iteration no. 81272 ==> 0.30734929186957705\n",
            "Loss in iteration no. 81273 ==> 0.3073492813890336\n",
            "Loss in iteration no. 81274 ==> 0.30734927090911535\n",
            "Loss in iteration no. 81275 ==> 0.30734926042982147\n",
            "Loss in iteration no. 81276 ==> 0.30734924995115337\n",
            "Loss in iteration no. 81277 ==> 0.30734923947310916\n",
            "Loss in iteration no. 81278 ==> 0.3073492289956902\n",
            "Loss in iteration no. 81279 ==> 0.3073492185188964\n",
            "Loss in iteration no. 81280 ==> 0.30734920804272653\n",
            "Loss in iteration no. 81281 ==> 0.30734919756718215\n",
            "Loss in iteration no. 81282 ==> 0.30734918709226144\n",
            "Loss in iteration no. 81283 ==> 0.30734917661796596\n",
            "Loss in iteration no. 81284 ==> 0.3073491661442949\n",
            "Loss in iteration no. 81285 ==> 0.3073491556712485\n",
            "Loss in iteration no. 81286 ==> 0.30734914519882667\n",
            "Loss in iteration no. 81287 ==> 0.3073491347270285\n",
            "Loss in iteration no. 81288 ==> 0.307349124255856\n",
            "Loss in iteration no. 81289 ==> 0.3073491137853073\n",
            "Loss in iteration no. 81290 ==> 0.3073491033153826\n",
            "Loss in iteration no. 81291 ==> 0.3073490928460825\n",
            "Loss in iteration no. 81292 ==> 0.3073490823774058\n",
            "Loss in iteration no. 81293 ==> 0.30734907190935495\n",
            "Loss in iteration no. 81294 ==> 0.3073490614419275\n",
            "Loss in iteration no. 81295 ==> 0.3073490509751237\n",
            "Loss in iteration no. 81296 ==> 0.3073490405089445\n",
            "Loss in iteration no. 81297 ==> 0.3073490300433894\n",
            "Loss in iteration no. 81298 ==> 0.3073490195784582\n",
            "Loss in iteration no. 81299 ==> 0.3073490091141513\n",
            "Loss in iteration no. 81300 ==> 0.3073489986504677\n",
            "Loss in iteration no. 81301 ==> 0.3073489881874082\n",
            "Loss in iteration no. 81302 ==> 0.3073489777249726\n",
            "Loss in iteration no. 81303 ==> 0.307348967263161\n",
            "Loss in iteration no. 81304 ==> 0.3073489568019728\n",
            "Loss in iteration no. 81305 ==> 0.30734894634140875\n",
            "Loss in iteration no. 81306 ==> 0.3073489358814687\n",
            "Loss in iteration no. 81307 ==> 0.3073489254221522\n",
            "Loss in iteration no. 81308 ==> 0.30734891496345845\n",
            "Loss in iteration no. 81309 ==> 0.30734890450538954\n",
            "Loss in iteration no. 81310 ==> 0.3073488940479432\n",
            "Loss in iteration no. 81311 ==> 0.3073488835911209\n",
            "Loss in iteration no. 81312 ==> 0.307348873134922\n",
            "Loss in iteration no. 81313 ==> 0.3073488626793458\n",
            "Loss in iteration no. 81314 ==> 0.30734885222439373\n",
            "Loss in iteration no. 81315 ==> 0.3073488417700654\n",
            "Loss in iteration no. 81316 ==> 0.3073488313163597\n",
            "Loss in iteration no. 81317 ==> 0.3073488208632772\n",
            "Loss in iteration no. 81318 ==> 0.3073488104108188\n",
            "Loss in iteration no. 81319 ==> 0.3073487999589834\n",
            "Loss in iteration no. 81320 ==> 0.3073487895077707\n",
            "Loss in iteration no. 81321 ==> 0.30734877905718083\n",
            "Loss in iteration no. 81322 ==> 0.30734876860721433\n",
            "Loss in iteration no. 81323 ==> 0.30734875815787127\n",
            "Loss in iteration no. 81324 ==> 0.307348747709151\n",
            "Loss in iteration no. 81325 ==> 0.30734873726105355\n",
            "Loss in iteration no. 81326 ==> 0.30734872681357955\n",
            "Loss in iteration no. 81327 ==> 0.3073487163667279\n",
            "Loss in iteration no. 81328 ==> 0.30734870592049907\n",
            "Loss in iteration no. 81329 ==> 0.307348695474893\n",
            "Loss in iteration no. 81330 ==> 0.3073486850299106\n",
            "Loss in iteration no. 81331 ==> 0.30734867458555\n",
            "Loss in iteration no. 81332 ==> 0.307348664141812\n",
            "Loss in iteration no. 81333 ==> 0.30734865369869774\n",
            "Loss in iteration no. 81334 ==> 0.3073486432562046\n",
            "Loss in iteration no. 81335 ==> 0.30734863281433494\n",
            "Loss in iteration no. 81336 ==> 0.3073486223730883\n",
            "Loss in iteration no. 81337 ==> 0.3073486119324631\n",
            "Loss in iteration no. 81338 ==> 0.3073486014924607\n",
            "Loss in iteration no. 81339 ==> 0.30734859105308104\n",
            "Loss in iteration no. 81340 ==> 0.30734858061432335\n",
            "Loss in iteration no. 81341 ==> 0.30734857017618855\n",
            "Loss in iteration no. 81342 ==> 0.30734855973867586\n",
            "Loss in iteration no. 81343 ==> 0.3073485493017851\n",
            "Loss in iteration no. 81344 ==> 0.3073485388655173\n",
            "Loss in iteration no. 81345 ==> 0.30734852842987115\n",
            "Loss in iteration no. 81346 ==> 0.3073485179948473\n",
            "Loss in iteration no. 81347 ==> 0.3073485075604454\n",
            "Loss in iteration no. 81348 ==> 0.30734849712666545\n",
            "Loss in iteration no. 81349 ==> 0.30734848669350795\n",
            "Loss in iteration no. 81350 ==> 0.30734847626097245\n",
            "Loss in iteration no. 81351 ==> 0.3073484658290584\n",
            "Loss in iteration no. 81352 ==> 0.30734845539776645\n",
            "Loss in iteration no. 81353 ==> 0.3073484449670971\n",
            "Loss in iteration no. 81354 ==> 0.3073484345370485\n",
            "Loss in iteration no. 81355 ==> 0.3073484241076228\n",
            "Loss in iteration no. 81356 ==> 0.3073484136788176\n",
            "Loss in iteration no. 81357 ==> 0.30734840325063517\n",
            "Loss in iteration no. 81358 ==> 0.3073483928230739\n",
            "Loss in iteration no. 81359 ==> 0.3073483823961349\n",
            "Loss in iteration no. 81360 ==> 0.30734837196981635\n",
            "Loss in iteration no. 81361 ==> 0.3073483615441207\n",
            "Loss in iteration no. 81362 ==> 0.30734835111904535\n",
            "Loss in iteration no. 81363 ==> 0.30734834069459266\n",
            "Loss in iteration no. 81364 ==> 0.30734833027076064\n",
            "Loss in iteration no. 81365 ==> 0.30734831984755073\n",
            "Loss in iteration no. 81366 ==> 0.3073483094249612\n",
            "Loss in iteration no. 81367 ==> 0.3073482990029936\n",
            "Loss in iteration no. 81368 ==> 0.3073482885816475\n",
            "Loss in iteration no. 81369 ==> 0.30734827816092264\n",
            "Loss in iteration no. 81370 ==> 0.3073482677408189\n",
            "Loss in iteration no. 81371 ==> 0.30734825732133586\n",
            "Loss in iteration no. 81372 ==> 0.3073482469024746\n",
            "Loss in iteration no. 81373 ==> 0.307348236484234\n",
            "Loss in iteration no. 81374 ==> 0.3073482260666146\n",
            "Loss in iteration no. 81375 ==> 0.30734821564961645\n",
            "Loss in iteration no. 81376 ==> 0.30734820523323947\n",
            "Loss in iteration no. 81377 ==> 0.30734819481748277\n",
            "Loss in iteration no. 81378 ==> 0.3073481844023474\n",
            "Loss in iteration no. 81379 ==> 0.3073481739878325\n",
            "Loss in iteration no. 81380 ==> 0.3073481635739397\n",
            "Loss in iteration no. 81381 ==> 0.3073481531606662\n",
            "Loss in iteration no. 81382 ==> 0.3073481427480139\n",
            "Loss in iteration no. 81383 ==> 0.30734813233598296\n",
            "Loss in iteration no. 81384 ==> 0.3073481219245716\n",
            "Loss in iteration no. 81385 ==> 0.3073481115137822\n",
            "Loss in iteration no. 81386 ==> 0.3073481011036124\n",
            "Loss in iteration no. 81387 ==> 0.30734809069406344\n",
            "Loss in iteration no. 81388 ==> 0.30734808028513494\n",
            "Loss in iteration no. 81389 ==> 0.307348069876827\n",
            "Loss in iteration no. 81390 ==> 0.30734805946914007\n",
            "Loss in iteration no. 81391 ==> 0.30734804906207264\n",
            "Loss in iteration no. 81392 ==> 0.30734803865562615\n",
            "Loss in iteration no. 81393 ==> 0.30734802824979934\n",
            "Loss in iteration no. 81394 ==> 0.30734801784459376\n",
            "Loss in iteration no. 81395 ==> 0.3073480074400075\n",
            "Loss in iteration no. 81396 ==> 0.3073479970360425\n",
            "Loss in iteration no. 81397 ==> 0.3073479866326967\n",
            "Loss in iteration no. 81398 ==> 0.3073479762299713\n",
            "Loss in iteration no. 81399 ==> 0.30734796582786617\n",
            "Loss in iteration no. 81400 ==> 0.30734795542638105\n",
            "Loss in iteration no. 81401 ==> 0.3073479450255161\n",
            "Loss in iteration no. 81402 ==> 0.30734793462527077\n",
            "Loss in iteration no. 81403 ==> 0.3073479242256454\n",
            "Loss in iteration no. 81404 ==> 0.3073479138266409\n",
            "Loss in iteration no. 81405 ==> 0.30734790342825485\n",
            "Loss in iteration no. 81406 ==> 0.30734789303048987\n",
            "Loss in iteration no. 81407 ==> 0.30734788263334406\n",
            "Loss in iteration no. 81408 ==> 0.30734787223681787\n",
            "Loss in iteration no. 81409 ==> 0.307347861840912\n",
            "Loss in iteration no. 81410 ==> 0.30734785144562504\n",
            "Loss in iteration no. 81411 ==> 0.3073478410509582\n",
            "Loss in iteration no. 81412 ==> 0.30734783065691057\n",
            "Loss in iteration no. 81413 ==> 0.3073478202634829\n",
            "Loss in iteration no. 81414 ==> 0.3073478098706748\n",
            "Loss in iteration no. 81415 ==> 0.3073477994784859\n",
            "Loss in iteration no. 81416 ==> 0.30734778908691707\n",
            "Loss in iteration no. 81417 ==> 0.30734777869596663\n",
            "Loss in iteration no. 81418 ==> 0.30734776830563615\n",
            "Loss in iteration no. 81419 ==> 0.3073477579159246\n",
            "Loss in iteration no. 81420 ==> 0.3073477475268329\n",
            "Loss in iteration no. 81421 ==> 0.30734773713836033\n",
            "Loss in iteration no. 81422 ==> 0.307347726750507\n",
            "Loss in iteration no. 81423 ==> 0.3073477163632727\n",
            "Loss in iteration no. 81424 ==> 0.30734770597665734\n",
            "Loss in iteration no. 81425 ==> 0.3073476955906609\n",
            "Loss in iteration no. 81426 ==> 0.30734768520528444\n",
            "Loss in iteration no. 81427 ==> 0.3073476748205264\n",
            "Loss in iteration no. 81428 ==> 0.30734766443638695\n",
            "Loss in iteration no. 81429 ==> 0.3073476540528668\n",
            "Loss in iteration no. 81430 ==> 0.3073476436699658\n",
            "Loss in iteration no. 81431 ==> 0.30734763328768344\n",
            "Loss in iteration no. 81432 ==> 0.3073476229060204\n",
            "Loss in iteration no. 81433 ==> 0.3073476125249752\n",
            "Loss in iteration no. 81434 ==> 0.3073476021445497\n",
            "Loss in iteration no. 81435 ==> 0.3073475917647423\n",
            "Loss in iteration no. 81436 ==> 0.3073475813855535\n",
            "Loss in iteration no. 81437 ==> 0.30734757100698384\n",
            "Loss in iteration no. 81438 ==> 0.30734756062903196\n",
            "Loss in iteration no. 81439 ==> 0.3073475502516993\n",
            "Loss in iteration no. 81440 ==> 0.3073475398749855\n",
            "Loss in iteration no. 81441 ==> 0.30734752949888955\n",
            "Loss in iteration no. 81442 ==> 0.30734751912341224\n",
            "Loss in iteration no. 81443 ==> 0.30734750874855393\n",
            "Loss in iteration no. 81444 ==> 0.3073474983743128\n",
            "Loss in iteration no. 81445 ==> 0.30734748800069084\n",
            "Loss in iteration no. 81446 ==> 0.3073474776276864\n",
            "Loss in iteration no. 81447 ==> 0.30734746725530127\n",
            "Loss in iteration no. 81448 ==> 0.3073474568835331\n",
            "Loss in iteration no. 81449 ==> 0.30734744651238405\n",
            "Loss in iteration no. 81450 ==> 0.30734743614185306\n",
            "Loss in iteration no. 81451 ==> 0.30734742577193985\n",
            "Loss in iteration no. 81452 ==> 0.30734741540264476\n",
            "Loss in iteration no. 81453 ==> 0.30734740503396785\n",
            "Loss in iteration no. 81454 ==> 0.30734739466590844\n",
            "Loss in iteration no. 81455 ==> 0.3073473842984673\n",
            "Loss in iteration no. 81456 ==> 0.3073473739316449\n",
            "Loss in iteration no. 81457 ==> 0.30734736356543924\n",
            "Loss in iteration no. 81458 ==> 0.30734735319985174\n",
            "Loss in iteration no. 81459 ==> 0.30734734283488135\n",
            "Loss in iteration no. 81460 ==> 0.3073473324705301\n",
            "Loss in iteration no. 81461 ==> 0.30734732210679544\n",
            "Loss in iteration no. 81462 ==> 0.30734731174367874\n",
            "Loss in iteration no. 81463 ==> 0.3073473013811805\n",
            "Loss in iteration no. 81464 ==> 0.3073472910192986\n",
            "Loss in iteration no. 81465 ==> 0.30734728065803446\n",
            "Loss in iteration no. 81466 ==> 0.3073472702973886\n",
            "Loss in iteration no. 81467 ==> 0.3073472599373599\n",
            "Loss in iteration no. 81468 ==> 0.3073472495779484\n",
            "Loss in iteration no. 81469 ==> 0.3073472392191548\n",
            "Loss in iteration no. 81470 ==> 0.3073472288609775\n",
            "Loss in iteration no. 81471 ==> 0.3073472185034185\n",
            "Loss in iteration no. 81472 ==> 0.3073472081464764\n",
            "Loss in iteration no. 81473 ==> 0.30734719779015146\n",
            "Loss in iteration no. 81474 ==> 0.3073471874344444\n",
            "Loss in iteration no. 81475 ==> 0.30734717707935355\n",
            "Loss in iteration no. 81476 ==> 0.30734716672488027\n",
            "Loss in iteration no. 81477 ==> 0.30734715637102467\n",
            "Loss in iteration no. 81478 ==> 0.30734714601778496\n",
            "Loss in iteration no. 81479 ==> 0.3073471356651635\n",
            "Loss in iteration no. 81480 ==> 0.30734712531315805\n",
            "Loss in iteration no. 81481 ==> 0.30734711496176953\n",
            "Loss in iteration no. 81482 ==> 0.3073471046109986\n",
            "Loss in iteration no. 81483 ==> 0.30734709426084433\n",
            "Loss in iteration no. 81484 ==> 0.3073470839113066\n",
            "Loss in iteration no. 81485 ==> 0.30734707356238544\n",
            "Loss in iteration no. 81486 ==> 0.3073470632140815\n",
            "Loss in iteration no. 81487 ==> 0.3073470528663939\n",
            "Loss in iteration no. 81488 ==> 0.30734704251932377\n",
            "Loss in iteration no. 81489 ==> 0.30734703217286935\n",
            "Loss in iteration no. 81490 ==> 0.3073470218270318\n",
            "Loss in iteration no. 81491 ==> 0.3073470114818114\n",
            "Loss in iteration no. 81492 ==> 0.3073470011372066\n",
            "Loss in iteration no. 81493 ==> 0.3073469907932188\n",
            "Loss in iteration no. 81494 ==> 0.3073469804498475\n",
            "Loss in iteration no. 81495 ==> 0.3073469701070922\n",
            "Loss in iteration no. 81496 ==> 0.3073469597649537\n",
            "Loss in iteration no. 81497 ==> 0.3073469494234315\n",
            "Loss in iteration no. 81498 ==> 0.3073469390825253\n",
            "Loss in iteration no. 81499 ==> 0.3073469287422354\n",
            "Loss in iteration no. 81500 ==> 0.3073469184025615\n",
            "Loss in iteration no. 81501 ==> 0.30734690806350423\n",
            "Loss in iteration no. 81502 ==> 0.3073468977250629\n",
            "Loss in iteration no. 81503 ==> 0.3073468873872381\n",
            "Loss in iteration no. 81504 ==> 0.3073468770500285\n",
            "Loss in iteration no. 81505 ==> 0.30734686671343575\n",
            "Loss in iteration no. 81506 ==> 0.3073468563774585\n",
            "Loss in iteration no. 81507 ==> 0.30734684604209694\n",
            "Loss in iteration no. 81508 ==> 0.3073468357073521\n",
            "Loss in iteration no. 81509 ==> 0.3073468253732227\n",
            "Loss in iteration no. 81510 ==> 0.3073468150397081\n",
            "Loss in iteration no. 81511 ==> 0.30734680470681064\n",
            "Loss in iteration no. 81512 ==> 0.30734679437452894\n",
            "Loss in iteration no. 81513 ==> 0.30734678404286236\n",
            "Loss in iteration no. 81514 ==> 0.3073467737118112\n",
            "Loss in iteration no. 81515 ==> 0.3073467633813763\n",
            "Loss in iteration no. 81516 ==> 0.30734675305155673\n",
            "Loss in iteration no. 81517 ==> 0.3073467427223527\n",
            "Loss in iteration no. 81518 ==> 0.30734673239376453\n",
            "Loss in iteration no. 81519 ==> 0.30734672206579167\n",
            "Loss in iteration no. 81520 ==> 0.30734671173843386\n",
            "Loss in iteration no. 81521 ==> 0.3073467014116919\n",
            "Loss in iteration no. 81522 ==> 0.3073466910855647\n",
            "Loss in iteration no. 81523 ==> 0.3073466807600537\n",
            "Loss in iteration no. 81524 ==> 0.30734667043515784\n",
            "Loss in iteration no. 81525 ==> 0.30734666011087647\n",
            "Loss in iteration no. 81526 ==> 0.30734664978721105\n",
            "Loss in iteration no. 81527 ==> 0.3073466394641604\n",
            "Loss in iteration no. 81528 ==> 0.30734662914172534\n",
            "Loss in iteration no. 81529 ==> 0.3073466188199051\n",
            "Loss in iteration no. 81530 ==> 0.30734660849870016\n",
            "Loss in iteration no. 81531 ==> 0.30734659817810905\n",
            "Loss in iteration no. 81532 ==> 0.30734658785813396\n",
            "Loss in iteration no. 81533 ==> 0.30734657753877453\n",
            "Loss in iteration no. 81534 ==> 0.30734656722002845\n",
            "Loss in iteration no. 81535 ==> 0.30734655690189827\n",
            "Loss in iteration no. 81536 ==> 0.3073465465843825\n",
            "Loss in iteration no. 81537 ==> 0.3073465362674812\n",
            "Loss in iteration no. 81538 ==> 0.30734652595119505\n",
            "Loss in iteration no. 81539 ==> 0.30734651563552395\n",
            "Loss in iteration no. 81540 ==> 0.307346505320467\n",
            "Loss in iteration no. 81541 ==> 0.30734649500602496\n",
            "Loss in iteration no. 81542 ==> 0.3073464846921977\n",
            "Loss in iteration no. 81543 ==> 0.3073464743789843\n",
            "Loss in iteration no. 81544 ==> 0.30734646406638605\n",
            "Loss in iteration no. 81545 ==> 0.3073464537544027\n",
            "Loss in iteration no. 81546 ==> 0.30734644344303286\n",
            "Loss in iteration no. 81547 ==> 0.30734643313227794\n",
            "Loss in iteration no. 81548 ==> 0.3073464228221368\n",
            "Loss in iteration no. 81549 ==> 0.3073464125126107\n",
            "Loss in iteration no. 81550 ==> 0.3073464022036983\n",
            "Loss in iteration no. 81551 ==> 0.30734639189540036\n",
            "Loss in iteration no. 81552 ==> 0.3073463815877167\n",
            "Loss in iteration no. 81553 ==> 0.30734637128064735\n",
            "Loss in iteration no. 81554 ==> 0.3073463609741921\n",
            "Loss in iteration no. 81555 ==> 0.3073463506683513\n",
            "Loss in iteration no. 81556 ==> 0.30734634036312375\n",
            "Loss in iteration no. 81557 ==> 0.3073463300585109\n",
            "Loss in iteration no. 81558 ==> 0.3073463197545115\n",
            "Loss in iteration no. 81559 ==> 0.30734630945112607\n",
            "Loss in iteration no. 81560 ==> 0.3073462991483549\n",
            "Loss in iteration no. 81561 ==> 0.30734628884619725\n",
            "Loss in iteration no. 81562 ==> 0.3073462785446538\n",
            "Loss in iteration no. 81563 ==> 0.30734626824372413\n",
            "Loss in iteration no. 81564 ==> 0.30734625794340825\n",
            "Loss in iteration no. 81565 ==> 0.30734624764370594\n",
            "Loss in iteration no. 81566 ==> 0.30734623734461713\n",
            "Loss in iteration no. 81567 ==> 0.30734622704614223\n",
            "Loss in iteration no. 81568 ==> 0.307346216748281\n",
            "Loss in iteration no. 81569 ==> 0.30734620645103317\n",
            "Loss in iteration no. 81570 ==> 0.30734619615439845\n",
            "Loss in iteration no. 81571 ==> 0.3073461858583777\n",
            "Loss in iteration no. 81572 ==> 0.30734617556296984\n",
            "Loss in iteration no. 81573 ==> 0.3073461652681762\n",
            "Loss in iteration no. 81574 ==> 0.3073461549739958\n",
            "Loss in iteration no. 81575 ==> 0.30734614468042815\n",
            "Loss in iteration no. 81576 ==> 0.3073461343874744\n",
            "Loss in iteration no. 81577 ==> 0.3073461240951336\n",
            "Loss in iteration no. 81578 ==> 0.30734611380340643\n",
            "Loss in iteration no. 81579 ==> 0.30734610351229225\n",
            "Loss in iteration no. 81580 ==> 0.30734609322179063\n",
            "Loss in iteration no. 81581 ==> 0.30734608293190263\n",
            "Loss in iteration no. 81582 ==> 0.30734607264262787\n",
            "Loss in iteration no. 81583 ==> 0.30734606235396555\n",
            "Loss in iteration no. 81584 ==> 0.3073460520659165\n",
            "Loss in iteration no. 81585 ==> 0.307346041778481\n",
            "Loss in iteration no. 81586 ==> 0.3073460314916575\n",
            "Loss in iteration no. 81587 ==> 0.30734602120544713\n",
            "Loss in iteration no. 81588 ==> 0.30734601091985\n",
            "Loss in iteration no. 81589 ==> 0.30734600063486583\n",
            "Loss in iteration no. 81590 ==> 0.3073459903504938\n",
            "Loss in iteration no. 81591 ==> 0.3073459800667342\n",
            "Loss in iteration no. 81592 ==> 0.30734596978358836\n",
            "Loss in iteration no. 81593 ==> 0.30734595950105453\n",
            "Loss in iteration no. 81594 ==> 0.3073459492191334\n",
            "Loss in iteration no. 81595 ==> 0.3073459389378249\n",
            "Loss in iteration no. 81596 ==> 0.30734592865712895\n",
            "Loss in iteration no. 81597 ==> 0.30734591837704556\n",
            "Loss in iteration no. 81598 ==> 0.3073459080975745\n",
            "Loss in iteration no. 81599 ==> 0.3073458978187158\n",
            "Loss in iteration no. 81600 ==> 0.3073458875404692\n",
            "Loss in iteration no. 81601 ==> 0.3073458772628356\n",
            "Loss in iteration no. 81602 ==> 0.30734586698581323\n",
            "Loss in iteration no. 81603 ==> 0.3073458567094044\n",
            "Loss in iteration no. 81604 ==> 0.3073458464336067\n",
            "Loss in iteration no. 81605 ==> 0.30734583615842154\n",
            "Loss in iteration no. 81606 ==> 0.3073458258838489\n",
            "Loss in iteration no. 81607 ==> 0.30734581560988794\n",
            "Loss in iteration no. 81608 ==> 0.30734580533653966\n",
            "Loss in iteration no. 81609 ==> 0.30734579506380305\n",
            "Loss in iteration no. 81610 ==> 0.3073457847916788\n",
            "Loss in iteration no. 81611 ==> 0.30734577452016587\n",
            "Loss in iteration no. 81612 ==> 0.3073457642492652\n",
            "Loss in iteration no. 81613 ==> 0.30734575397897607\n",
            "Loss in iteration no. 81614 ==> 0.3073457437092995\n",
            "Loss in iteration no. 81615 ==> 0.30734573344023436\n",
            "Loss in iteration no. 81616 ==> 0.3073457231717812\n",
            "Loss in iteration no. 81617 ==> 0.30734571290393875\n",
            "Loss in iteration no. 81618 ==> 0.30734570263670913\n",
            "Loss in iteration no. 81619 ==> 0.30734569237009046\n",
            "Loss in iteration no. 81620 ==> 0.30734568210408386\n",
            "Loss in iteration no. 81621 ==> 0.3073456718386888\n",
            "Loss in iteration no. 81622 ==> 0.3073456615739053\n",
            "Loss in iteration no. 81623 ==> 0.30734565130973335\n",
            "Loss in iteration no. 81624 ==> 0.30734564104617274\n",
            "Loss in iteration no. 81625 ==> 0.3073456307832233\n",
            "Loss in iteration no. 81626 ==> 0.30734562052088593\n",
            "Loss in iteration no. 81627 ==> 0.30734561025915963\n",
            "Loss in iteration no. 81628 ==> 0.3073455999980435\n",
            "Loss in iteration no. 81629 ==> 0.30734558973754\n",
            "Loss in iteration no. 81630 ==> 0.30734557947764735\n",
            "Loss in iteration no. 81631 ==> 0.3073455692183662\n",
            "Loss in iteration no. 81632 ==> 0.30734555895969573\n",
            "Loss in iteration no. 81633 ==> 0.30734554870163666\n",
            "Loss in iteration no. 81634 ==> 0.30734553844418855\n",
            "Loss in iteration no. 81635 ==> 0.30734552818735156\n",
            "Loss in iteration no. 81636 ==> 0.30734551793112574\n",
            "Loss in iteration no. 81637 ==> 0.3073455076755102\n",
            "Loss in iteration no. 81638 ==> 0.30734549742050643\n",
            "Loss in iteration no. 81639 ==> 0.30734548716611315\n",
            "Loss in iteration no. 81640 ==> 0.30734547691233066\n",
            "Loss in iteration no. 81641 ==> 0.3073454666591596\n",
            "Loss in iteration no. 81642 ==> 0.3073454564065988\n",
            "Loss in iteration no. 81643 ==> 0.3073454461546486\n",
            "Loss in iteration no. 81644 ==> 0.3073454359033087\n",
            "Loss in iteration no. 81645 ==> 0.3073454256525805\n",
            "Loss in iteration no. 81646 ==> 0.30734541540246296\n",
            "Loss in iteration no. 81647 ==> 0.3073454051529548\n",
            "Loss in iteration no. 81648 ==> 0.3073453949040583\n",
            "Loss in iteration no. 81649 ==> 0.3073453846557724\n",
            "Loss in iteration no. 81650 ==> 0.3073453744080954\n",
            "Loss in iteration no. 81651 ==> 0.3073453641610308\n",
            "Loss in iteration no. 81652 ==> 0.3073453539145755\n",
            "Loss in iteration no. 81653 ==> 0.3073453436687311\n",
            "Loss in iteration no. 81654 ==> 0.30734533342349635\n",
            "Loss in iteration no. 81655 ==> 0.30734532317887264\n",
            "Loss in iteration no. 81656 ==> 0.3073453129348588\n",
            "Loss in iteration no. 81657 ==> 0.30734530269145466\n",
            "Loss in iteration no. 81658 ==> 0.3073452924486614\n",
            "Loss in iteration no. 81659 ==> 0.30734528220647805\n",
            "Loss in iteration no. 81660 ==> 0.3073452719649051\n",
            "Loss in iteration no. 81661 ==> 0.30734526172394144\n",
            "Loss in iteration no. 81662 ==> 0.3073452514835883\n",
            "Loss in iteration no. 81663 ==> 0.3073452412438448\n",
            "Loss in iteration no. 81664 ==> 0.30734523100471217\n",
            "Loss in iteration no. 81665 ==> 0.3073452207661884\n",
            "Loss in iteration no. 81666 ==> 0.3073452105282749\n",
            "Loss in iteration no. 81667 ==> 0.30734520029097157\n",
            "Loss in iteration no. 81668 ==> 0.30734519005427763\n",
            "Loss in iteration no. 81669 ==> 0.3073451798181935\n",
            "Loss in iteration no. 81670 ==> 0.3073451695827189\n",
            "Loss in iteration no. 81671 ==> 0.3073451593478542\n",
            "Loss in iteration no. 81672 ==> 0.30734514911359945\n",
            "Loss in iteration no. 81673 ==> 0.30734513887995407\n",
            "Loss in iteration no. 81674 ==> 0.307345128646918\n",
            "Loss in iteration no. 81675 ==> 0.30734511841449147\n",
            "Loss in iteration no. 81676 ==> 0.3073451081826745\n",
            "Loss in iteration no. 81677 ==> 0.30734509795146736\n",
            "Loss in iteration no. 81678 ==> 0.30734508772086916\n",
            "Loss in iteration no. 81679 ==> 0.307345077490881\n",
            "Loss in iteration no. 81680 ==> 0.3073450672615013\n",
            "Loss in iteration no. 81681 ==> 0.3073450570327318\n",
            "Loss in iteration no. 81682 ==> 0.30734504680457103\n",
            "Loss in iteration no. 81683 ==> 0.30734503657701895\n",
            "Loss in iteration no. 81684 ==> 0.3073450263500767\n",
            "Loss in iteration no. 81685 ==> 0.3073450161237431\n",
            "Loss in iteration no. 81686 ==> 0.3073450058980195\n",
            "Loss in iteration no. 81687 ==> 0.30734499567290463\n",
            "Loss in iteration no. 81688 ==> 0.30734498544839817\n",
            "Loss in iteration no. 81689 ==> 0.3073449752245015\n",
            "Loss in iteration no. 81690 ==> 0.30734496500121333\n",
            "Loss in iteration no. 81691 ==> 0.30734495477853396\n",
            "Loss in iteration no. 81692 ==> 0.3073449445564642\n",
            "Loss in iteration no. 81693 ==> 0.3073449343350027\n",
            "Loss in iteration no. 81694 ==> 0.3073449241141499\n",
            "Loss in iteration no. 81695 ==> 0.3073449138939061\n",
            "Loss in iteration no. 81696 ==> 0.3073449036742709\n",
            "Loss in iteration no. 81697 ==> 0.3073448934552449\n",
            "Loss in iteration no. 81698 ==> 0.3073448832368274\n",
            "Loss in iteration no. 81699 ==> 0.30734487301901814\n",
            "Loss in iteration no. 81700 ==> 0.3073448628018177\n",
            "Loss in iteration no. 81701 ==> 0.30734485258522526\n",
            "Loss in iteration no. 81702 ==> 0.3073448423692416\n",
            "Loss in iteration no. 81703 ==> 0.30734483215386643\n",
            "Loss in iteration no. 81704 ==> 0.30734482193909995\n",
            "Loss in iteration no. 81705 ==> 0.3073448117249419\n",
            "Loss in iteration no. 81706 ==> 0.30734480151139215\n",
            "Loss in iteration no. 81707 ==> 0.30734479129844977\n",
            "Loss in iteration no. 81708 ==> 0.30734478108611724\n",
            "Loss in iteration no. 81709 ==> 0.30734477087439205\n",
            "Loss in iteration no. 81710 ==> 0.3073447606632746\n",
            "Loss in iteration no. 81711 ==> 0.30734475045276655\n",
            "Loss in iteration no. 81712 ==> 0.3073447402428656\n",
            "Loss in iteration no. 81713 ==> 0.30734473003357315\n",
            "Loss in iteration no. 81714 ==> 0.3073447198248885\n",
            "Loss in iteration no. 81715 ==> 0.3073447096168117\n",
            "Loss in iteration no. 81716 ==> 0.3073446994093441\n",
            "Loss in iteration no. 81717 ==> 0.3073446892024831\n",
            "Loss in iteration no. 81718 ==> 0.3073446789962299\n",
            "Loss in iteration no. 81719 ==> 0.30734466879058503\n",
            "Loss in iteration no. 81720 ==> 0.30734465858554905\n",
            "Loss in iteration no. 81721 ==> 0.30734464838111936\n",
            "Loss in iteration no. 81722 ==> 0.3073446381772978\n",
            "Loss in iteration no. 81723 ==> 0.30734462797408363\n",
            "Loss in iteration no. 81724 ==> 0.30734461777147826\n",
            "Loss in iteration no. 81725 ==> 0.30734460756947957\n",
            "Loss in iteration no. 81726 ==> 0.30734459736808833\n",
            "Loss in iteration no. 81727 ==> 0.3073445871673058\n",
            "Loss in iteration no. 81728 ==> 0.3073445769671293\n",
            "Loss in iteration no. 81729 ==> 0.30734456676756117\n",
            "Loss in iteration no. 81730 ==> 0.3073445565686006\n",
            "Loss in iteration no. 81731 ==> 0.3073445463702466\n",
            "Loss in iteration no. 81732 ==> 0.30734453617250085\n",
            "Loss in iteration no. 81733 ==> 0.3073445259753622\n",
            "Loss in iteration no. 81734 ==> 0.3073445157788301\n",
            "Loss in iteration no. 81735 ==> 0.30734450558290594\n",
            "Loss in iteration no. 81736 ==> 0.30734449538758946\n",
            "Loss in iteration no. 81737 ==> 0.30734448519287877\n",
            "Loss in iteration no. 81738 ==> 0.30734447499877604\n",
            "Loss in iteration no. 81739 ==> 0.3073444648052809\n",
            "Loss in iteration no. 81740 ==> 0.3073444546123925\n",
            "Loss in iteration no. 81741 ==> 0.30734444442011055\n",
            "Loss in iteration no. 81742 ==> 0.30734443422843644\n",
            "Loss in iteration no. 81743 ==> 0.3073444240373683\n",
            "Loss in iteration no. 81744 ==> 0.3073444138469081\n",
            "Loss in iteration no. 81745 ==> 0.3073444036570537\n",
            "Loss in iteration no. 81746 ==> 0.3073443934678075\n",
            "Loss in iteration no. 81747 ==> 0.3073443832791674\n",
            "Loss in iteration no. 81748 ==> 0.3073443730911336\n",
            "Loss in iteration no. 81749 ==> 0.30734436290370704\n",
            "Loss in iteration no. 81750 ==> 0.3073443527168866\n",
            "Loss in iteration no. 81751 ==> 0.30734434253067394\n",
            "Loss in iteration no. 81752 ==> 0.30734433234506653\n",
            "Loss in iteration no. 81753 ==> 0.30734432216006624\n",
            "Loss in iteration no. 81754 ==> 0.30734431197567263\n",
            "Loss in iteration no. 81755 ==> 0.3073443017918857\n",
            "Loss in iteration no. 81756 ==> 0.30734429160870524\n",
            "Loss in iteration no. 81757 ==> 0.3073442814261304\n",
            "Loss in iteration no. 81758 ==> 0.3073442712441631\n",
            "Loss in iteration no. 81759 ==> 0.3073442610628008\n",
            "Loss in iteration no. 81760 ==> 0.30734425088204603\n",
            "Loss in iteration no. 81761 ==> 0.30734424070189725\n",
            "Loss in iteration no. 81762 ==> 0.30734423052235443\n",
            "Loss in iteration no. 81763 ==> 0.307344220343418\n",
            "Loss in iteration no. 81764 ==> 0.307344210165087\n",
            "Loss in iteration no. 81765 ==> 0.307344199987363\n",
            "Loss in iteration no. 81766 ==> 0.3073441898102449\n",
            "Loss in iteration no. 81767 ==> 0.3073441796337329\n",
            "Loss in iteration no. 81768 ==> 0.30734416945782683\n",
            "Loss in iteration no. 81769 ==> 0.30734415928252645\n",
            "Loss in iteration no. 81770 ==> 0.3073441491078318\n",
            "Loss in iteration no. 81771 ==> 0.3073441389337433\n",
            "Loss in iteration no. 81772 ==> 0.30734412876026074\n",
            "Loss in iteration no. 81773 ==> 0.3073441185873844\n",
            "Loss in iteration no. 81774 ==> 0.3073441084151135\n",
            "Loss in iteration no. 81775 ==> 0.30734409824344816\n",
            "Loss in iteration no. 81776 ==> 0.30734408807238855\n",
            "Loss in iteration no. 81777 ==> 0.30734407790193446\n",
            "Loss in iteration no. 81778 ==> 0.3073440677320866\n",
            "Loss in iteration no. 81779 ==> 0.3073440575628442\n",
            "Loss in iteration no. 81780 ==> 0.30734404739420695\n",
            "Loss in iteration no. 81781 ==> 0.30734403722617576\n",
            "Loss in iteration no. 81782 ==> 0.3073440270587496\n",
            "Loss in iteration no. 81783 ==> 0.3073440168919293\n",
            "Loss in iteration no. 81784 ==> 0.3073440067257136\n",
            "Loss in iteration no. 81785 ==> 0.3073439965601043\n",
            "Loss in iteration no. 81786 ==> 0.30734398639509986\n",
            "Loss in iteration no. 81787 ==> 0.30734397623070037\n",
            "Loss in iteration no. 81788 ==> 0.30734396606690595\n",
            "Loss in iteration no. 81789 ==> 0.3073439559037172\n",
            "Loss in iteration no. 81790 ==> 0.3073439457411341\n",
            "Loss in iteration no. 81791 ==> 0.307343935579155\n",
            "Loss in iteration no. 81792 ==> 0.3073439254177821\n",
            "Loss in iteration no. 81793 ==> 0.30734391525701377\n",
            "Loss in iteration no. 81794 ==> 0.30734390509685083\n",
            "Loss in iteration no. 81795 ==> 0.3073438949372922\n",
            "Loss in iteration no. 81796 ==> 0.3073438847783387\n",
            "Loss in iteration no. 81797 ==> 0.30734387461999063\n",
            "Loss in iteration no. 81798 ==> 0.30734386446224704\n",
            "Loss in iteration no. 81799 ==> 0.3073438543051084\n",
            "Loss in iteration no. 81800 ==> 0.3073438441485743\n",
            "Loss in iteration no. 81801 ==> 0.307343833992645\n",
            "Loss in iteration no. 81802 ==> 0.3073438238373201\n",
            "Loss in iteration no. 81803 ==> 0.30734381368260094\n",
            "Loss in iteration no. 81804 ==> 0.3073438035284857\n",
            "Loss in iteration no. 81805 ==> 0.3073437933749754\n",
            "Loss in iteration no. 81806 ==> 0.3073437832220697\n",
            "Loss in iteration no. 81807 ==> 0.3073437730697681\n",
            "Loss in iteration no. 81808 ==> 0.30734376291807075\n",
            "Loss in iteration no. 81809 ==> 0.30734375276697934\n",
            "Loss in iteration no. 81810 ==> 0.3073437426164906\n",
            "Loss in iteration no. 81811 ==> 0.30734373246660746\n",
            "Loss in iteration no. 81812 ==> 0.307343722317328\n",
            "Loss in iteration no. 81813 ==> 0.307343712168653\n",
            "Loss in iteration no. 81814 ==> 0.3073437020205824\n",
            "Loss in iteration no. 81815 ==> 0.30734369187311616\n",
            "Loss in iteration no. 81816 ==> 0.30734368172625304\n",
            "Loss in iteration no. 81817 ==> 0.30734367157999515\n",
            "Loss in iteration no. 81818 ==> 0.3073436614343414\n",
            "Loss in iteration no. 81819 ==> 0.3073436512892911\n",
            "Loss in iteration no. 81820 ==> 0.30734364114484597\n",
            "Loss in iteration no. 81821 ==> 0.3073436310010039\n",
            "Loss in iteration no. 81822 ==> 0.3073436208577658\n",
            "Loss in iteration no. 81823 ==> 0.3073436107151314\n",
            "Loss in iteration no. 81824 ==> 0.30734360057310184\n",
            "Loss in iteration no. 81825 ==> 0.30734359043167525\n",
            "Loss in iteration no. 81826 ==> 0.30734358029085296\n",
            "Loss in iteration no. 81827 ==> 0.3073435701506351\n",
            "Loss in iteration no. 81828 ==> 0.30734356001102003\n",
            "Loss in iteration no. 81829 ==> 0.3073435498720089\n",
            "Loss in iteration no. 81830 ==> 0.3073435397336017\n",
            "Loss in iteration no. 81831 ==> 0.3073435295957974\n",
            "Loss in iteration no. 81832 ==> 0.3073435194585975\n",
            "Loss in iteration no. 81833 ==> 0.3073435093220005\n",
            "Loss in iteration no. 81834 ==> 0.30734349918600773\n",
            "Loss in iteration no. 81835 ==> 0.3073434890506181\n",
            "Loss in iteration no. 81836 ==> 0.3073434789158313\n",
            "Loss in iteration no. 81837 ==> 0.3073434687816486\n",
            "Loss in iteration no. 81838 ==> 0.30734345864806956\n",
            "Loss in iteration no. 81839 ==> 0.30734344851509304\n",
            "Loss in iteration no. 81840 ==> 0.30734343838271994\n",
            "Loss in iteration no. 81841 ==> 0.30734342825095107\n",
            "Loss in iteration no. 81842 ==> 0.30734341811978455\n",
            "Loss in iteration no. 81843 ==> 0.30734340798922083\n",
            "Loss in iteration no. 81844 ==> 0.3073433978592614\n",
            "Loss in iteration no. 81845 ==> 0.30734338772990366\n",
            "Loss in iteration no. 81846 ==> 0.3073433776011505\n",
            "Loss in iteration no. 81847 ==> 0.3073433674730001\n",
            "Loss in iteration no. 81848 ==> 0.30734335734545204\n",
            "Loss in iteration no. 81849 ==> 0.30734334721850665\n",
            "Loss in iteration no. 81850 ==> 0.30734333709216455\n",
            "Loss in iteration no. 81851 ==> 0.3073433269664262\n",
            "Loss in iteration no. 81852 ==> 0.3073433168412898\n",
            "Loss in iteration no. 81853 ==> 0.30734330671675575\n",
            "Loss in iteration no. 81854 ==> 0.30734329659282544\n",
            "Loss in iteration no. 81855 ==> 0.3073432864694973\n",
            "Loss in iteration no. 81856 ==> 0.30734327634677283\n",
            "Loss in iteration no. 81857 ==> 0.3073432662246495\n",
            "Loss in iteration no. 81858 ==> 0.30734325610312974\n",
            "Loss in iteration no. 81859 ==> 0.3073432459822125\n",
            "Loss in iteration no. 81860 ==> 0.3073432358618973\n",
            "Loss in iteration no. 81861 ==> 0.30734322574218514\n",
            "Loss in iteration no. 81862 ==> 0.3073432156230754\n",
            "Loss in iteration no. 81863 ==> 0.30734320550456784\n",
            "Loss in iteration no. 81864 ==> 0.3073431953866627\n",
            "Loss in iteration no. 81865 ==> 0.30734318526936016\n",
            "Loss in iteration no. 81866 ==> 0.30734317515265996\n",
            "Loss in iteration no. 81867 ==> 0.30734316503656167\n",
            "Loss in iteration no. 81868 ==> 0.3073431549210661\n",
            "Loss in iteration no. 81869 ==> 0.30734314480617225\n",
            "Loss in iteration no. 81870 ==> 0.3073431346918809\n",
            "Loss in iteration no. 81871 ==> 0.3073431245781918\n",
            "Loss in iteration no. 81872 ==> 0.3073431144651043\n",
            "Loss in iteration no. 81873 ==> 0.307343104352619\n",
            "Loss in iteration no. 81874 ==> 0.3073430942407363\n",
            "Loss in iteration no. 81875 ==> 0.3073430841294544\n",
            "Loss in iteration no. 81876 ==> 0.30734307401877564\n",
            "Loss in iteration no. 81877 ==> 0.30734306390869837\n",
            "Loss in iteration no. 81878 ==> 0.3073430537992226\n",
            "Loss in iteration no. 81879 ==> 0.30734304369034876\n",
            "Loss in iteration no. 81880 ==> 0.3073430335820772\n",
            "Loss in iteration no. 81881 ==> 0.3073430234744073\n",
            "Loss in iteration no. 81882 ==> 0.3073430133673391\n",
            "Loss in iteration no. 81883 ==> 0.30734300326087216\n",
            "Loss in iteration no. 81884 ==> 0.3073429931550072\n",
            "Loss in iteration no. 81885 ==> 0.30734298304974367\n",
            "Loss in iteration no. 81886 ==> 0.30734297294508195\n",
            "Loss in iteration no. 81887 ==> 0.3073429628410217\n",
            "Loss in iteration no. 81888 ==> 0.30734295273756285\n",
            "Loss in iteration no. 81889 ==> 0.30734294263470524\n",
            "Loss in iteration no. 81890 ==> 0.3073429325324495\n",
            "Loss in iteration no. 81891 ==> 0.30734292243079503\n",
            "Loss in iteration no. 81892 ==> 0.3073429123297415\n",
            "Loss in iteration no. 81893 ==> 0.3073429022292897\n",
            "Loss in iteration no. 81894 ==> 0.3073428921294392\n",
            "Loss in iteration no. 81895 ==> 0.30734288203018983\n",
            "Loss in iteration no. 81896 ==> 0.3073428719315412\n",
            "Loss in iteration no. 81897 ==> 0.30734286183349424\n",
            "Loss in iteration no. 81898 ==> 0.30734285173604786\n",
            "Loss in iteration no. 81899 ==> 0.30734284163920395\n",
            "Loss in iteration no. 81900 ==> 0.30734283154296\n",
            "Loss in iteration no. 81901 ==> 0.307342821447317\n",
            "Loss in iteration no. 81902 ==> 0.30734281135227504\n",
            "Loss in iteration no. 81903 ==> 0.307342801257834\n",
            "Loss in iteration no. 81904 ==> 0.30734279116399377\n",
            "Loss in iteration no. 81905 ==> 0.30734278107075513\n",
            "Loss in iteration no. 81906 ==> 0.30734277097811663\n",
            "Loss in iteration no. 81907 ==> 0.30734276088607904\n",
            "Loss in iteration no. 81908 ==> 0.30734275079464213\n",
            "Loss in iteration no. 81909 ==> 0.30734274070380585\n",
            "Loss in iteration no. 81910 ==> 0.30734273061357065\n",
            "Loss in iteration no. 81911 ==> 0.30734272052393613\n",
            "Loss in iteration no. 81912 ==> 0.3073427104349014\n",
            "Loss in iteration no. 81913 ==> 0.30734270034646827\n",
            "Loss in iteration no. 81914 ==> 0.3073426902586351\n",
            "Loss in iteration no. 81915 ==> 0.30734268017140254\n",
            "Loss in iteration no. 81916 ==> 0.30734267008476984\n",
            "Loss in iteration no. 81917 ==> 0.3073426599987385\n",
            "Loss in iteration no. 81918 ==> 0.30734264991330634\n",
            "Loss in iteration no. 81919 ==> 0.3073426398284758\n",
            "Loss in iteration no. 81920 ==> 0.3073426297442455\n",
            "Loss in iteration no. 81921 ==> 0.3073426196606142\n",
            "Loss in iteration no. 81922 ==> 0.30734260957758375\n",
            "Loss in iteration no. 81923 ==> 0.3073425994951545\n",
            "Loss in iteration no. 81924 ==> 0.3073425894133241\n",
            "Loss in iteration no. 81925 ==> 0.30734257933209425\n",
            "Loss in iteration no. 81926 ==> 0.30734256925146486\n",
            "Loss in iteration no. 81927 ==> 0.30734255917143527\n",
            "Loss in iteration no. 81928 ==> 0.30734254909200487\n",
            "Loss in iteration no. 81929 ==> 0.3073425390131752\n",
            "Loss in iteration no. 81930 ==> 0.30734252893494574\n",
            "Loss in iteration no. 81931 ==> 0.30734251885731523\n",
            "Loss in iteration no. 81932 ==> 0.3073425087802851\n",
            "Loss in iteration no. 81933 ==> 0.3073424987038554\n",
            "Loss in iteration no. 81934 ==> 0.3073424886280247\n",
            "Loss in iteration no. 81935 ==> 0.3073424785527932\n",
            "Loss in iteration no. 81936 ==> 0.3073424684781625\n",
            "Loss in iteration no. 81937 ==> 0.307342458404131\n",
            "Loss in iteration no. 81938 ==> 0.3073424483306996\n",
            "Loss in iteration no. 81939 ==> 0.3073424382578671\n",
            "Loss in iteration no. 81940 ==> 0.3073424281856349\n",
            "Loss in iteration no. 81941 ==> 0.30734241811400154\n",
            "Loss in iteration no. 81942 ==> 0.30734240804296786\n",
            "Loss in iteration no. 81943 ==> 0.3073423979725337\n",
            "Loss in iteration no. 81944 ==> 0.3073423879026989\n",
            "Loss in iteration no. 81945 ==> 0.3073423778334636\n",
            "Loss in iteration no. 81946 ==> 0.3073423677648271\n",
            "Loss in iteration no. 81947 ==> 0.30734235769679025\n",
            "Loss in iteration no. 81948 ==> 0.30734234762935286\n",
            "Loss in iteration no. 81949 ==> 0.30734233756251417\n",
            "Loss in iteration no. 81950 ==> 0.30734232749627516\n",
            "Loss in iteration no. 81951 ==> 0.30734231743063506\n",
            "Loss in iteration no. 81952 ==> 0.30734230736559404\n",
            "Loss in iteration no. 81953 ==> 0.3073422973011518\n",
            "Loss in iteration no. 81954 ==> 0.3073422872373085\n",
            "Loss in iteration no. 81955 ==> 0.3073422771740655\n",
            "Loss in iteration no. 81956 ==> 0.30734226711142\n",
            "Loss in iteration no. 81957 ==> 0.30734225704937407\n",
            "Loss in iteration no. 81958 ==> 0.30734224698792684\n",
            "Loss in iteration no. 81959 ==> 0.307342236927079\n",
            "Loss in iteration no. 81960 ==> 0.30734222686682927\n",
            "Loss in iteration no. 81961 ==> 0.3073422168071784\n",
            "Loss in iteration no. 81962 ==> 0.30734220674812623\n",
            "Loss in iteration no. 81963 ==> 0.30734219668967355\n",
            "Loss in iteration no. 81964 ==> 0.30734218663181867\n",
            "Loss in iteration no. 81965 ==> 0.30734217657456264\n",
            "Loss in iteration no. 81966 ==> 0.30734216651790536\n",
            "Loss in iteration no. 81967 ==> 0.30734215646184615\n",
            "Loss in iteration no. 81968 ==> 0.30734214640638624\n",
            "Loss in iteration no. 81969 ==> 0.30734213635152413\n",
            "Loss in iteration no. 81970 ==> 0.3073421262972605\n",
            "Loss in iteration no. 81971 ==> 0.30734211624359564\n",
            "Loss in iteration no. 81972 ==> 0.30734210619052876\n",
            "Loss in iteration no. 81973 ==> 0.30734209613806035\n",
            "Loss in iteration no. 81974 ==> 0.3073420860861906\n",
            "Loss in iteration no. 81975 ==> 0.3073420760349184\n",
            "Loss in iteration no. 81976 ==> 0.3073420659842451\n",
            "Loss in iteration no. 81977 ==> 0.3073420559341696\n",
            "Loss in iteration no. 81978 ==> 0.307342045884692\n",
            "Loss in iteration no. 81979 ==> 0.3073420358358123\n",
            "Loss in iteration no. 81980 ==> 0.3073420257875316\n",
            "Loss in iteration no. 81981 ==> 0.3073420157398485\n",
            "Loss in iteration no. 81982 ==> 0.30734200569276304\n",
            "Loss in iteration no. 81983 ==> 0.307341995646276\n",
            "Loss in iteration no. 81984 ==> 0.3073419856003862\n",
            "Loss in iteration no. 81985 ==> 0.3073419755550948\n",
            "Loss in iteration no. 81986 ==> 0.3073419655104013\n",
            "Loss in iteration no. 81987 ==> 0.3073419554663053\n",
            "Loss in iteration no. 81988 ==> 0.307341945422807\n",
            "Loss in iteration no. 81989 ==> 0.3073419353799073\n",
            "Loss in iteration no. 81990 ==> 0.3073419253376047\n",
            "Loss in iteration no. 81991 ==> 0.30734191529589916\n",
            "Loss in iteration no. 81992 ==> 0.30734190525479244\n",
            "Loss in iteration no. 81993 ==> 0.307341895214282\n",
            "Loss in iteration no. 81994 ==> 0.3073418851743698\n",
            "Loss in iteration no. 81995 ==> 0.30734187513505484\n",
            "Loss in iteration no. 81996 ==> 0.3073418650963376\n",
            "Loss in iteration no. 81997 ==> 0.30734185505821826\n",
            "Loss in iteration no. 81998 ==> 0.3073418450206955\n",
            "Loss in iteration no. 81999 ==> 0.3073418349837707\n",
            "Loss in iteration no. 82000 ==> 0.30734182494744233\n",
            "Loss in iteration no. 82001 ==> 0.3073418149117126\n",
            "Loss in iteration no. 82002 ==> 0.3073418048765791\n",
            "Loss in iteration no. 82003 ==> 0.3073417948420428\n",
            "Loss in iteration no. 82004 ==> 0.3073417848081038\n",
            "Loss in iteration no. 82005 ==> 0.30734177477476193\n",
            "Loss in iteration no. 82006 ==> 0.3073417647420175\n",
            "Loss in iteration no. 82007 ==> 0.30734175470986974\n",
            "Loss in iteration no. 82008 ==> 0.3073417446783192\n",
            "Loss in iteration no. 82009 ==> 0.30734173464736597\n",
            "Loss in iteration no. 82010 ==> 0.307341724617009\n",
            "Loss in iteration no. 82011 ==> 0.30734171458724857\n",
            "Loss in iteration no. 82012 ==> 0.3073417045580865\n",
            "Loss in iteration no. 82013 ==> 0.30734169452952\n",
            "Loss in iteration no. 82014 ==> 0.30734168450155064\n",
            "Loss in iteration no. 82015 ==> 0.30734167447417804\n",
            "Loss in iteration no. 82016 ==> 0.3073416644474028\n",
            "Loss in iteration no. 82017 ==> 0.30734165442122335\n",
            "Loss in iteration no. 82018 ==> 0.30734164439564077\n",
            "Loss in iteration no. 82019 ==> 0.307341634370655\n",
            "Loss in iteration no. 82020 ==> 0.3073416243462655\n",
            "Loss in iteration no. 82021 ==> 0.30734161432247253\n",
            "Loss in iteration no. 82022 ==> 0.3073416042992766\n",
            "Loss in iteration no. 82023 ==> 0.307341594276677\n",
            "Loss in iteration no. 82024 ==> 0.30734158425467345\n",
            "Loss in iteration no. 82025 ==> 0.3073415742332665\n",
            "Loss in iteration no. 82026 ==> 0.30734156421245623\n",
            "Loss in iteration no. 82027 ==> 0.3073415541922412\n",
            "Loss in iteration no. 82028 ==> 0.3073415441726238\n",
            "Loss in iteration no. 82029 ==> 0.30734153415360155\n",
            "Loss in iteration no. 82030 ==> 0.30734152413517596\n",
            "Loss in iteration no. 82031 ==> 0.3073415141173469\n",
            "Loss in iteration no. 82032 ==> 0.30734150410011324\n",
            "Loss in iteration no. 82033 ==> 0.3073414940834762\n",
            "Loss in iteration no. 82034 ==> 0.3073414840674352\n",
            "Loss in iteration no. 82035 ==> 0.30734147405199047\n",
            "Loss in iteration no. 82036 ==> 0.307341464037141\n",
            "Loss in iteration no. 82037 ==> 0.30734145402288765\n",
            "Loss in iteration no. 82038 ==> 0.30734144400923036\n",
            "Loss in iteration no. 82039 ==> 0.30734143399616926\n",
            "Loss in iteration no. 82040 ==> 0.3073414239837036\n",
            "Loss in iteration no. 82041 ==> 0.3073414139718334\n",
            "Loss in iteration no. 82042 ==> 0.30734140396056\n",
            "Loss in iteration no. 82043 ==> 0.30734139394988164\n",
            "Loss in iteration no. 82044 ==> 0.30734138393979893\n",
            "Loss in iteration no. 82045 ==> 0.3073413739303115\n",
            "Loss in iteration no. 82046 ==> 0.30734136392141986\n",
            "Loss in iteration no. 82047 ==> 0.30734135391312467\n",
            "Loss in iteration no. 82048 ==> 0.30734134390542417\n",
            "Loss in iteration no. 82049 ==> 0.3073413338983193\n",
            "Loss in iteration no. 82050 ==> 0.30734132389181046\n",
            "Loss in iteration no. 82051 ==> 0.3073413138858966\n",
            "Loss in iteration no. 82052 ==> 0.3073413038805775\n",
            "Loss in iteration no. 82053 ==> 0.3073412938758548\n",
            "Loss in iteration no. 82054 ==> 0.3073412838717263\n",
            "Loss in iteration no. 82055 ==> 0.30734127386819443\n",
            "Loss in iteration no. 82056 ==> 0.3073412638652567\n",
            "Loss in iteration no. 82057 ==> 0.3073412538629152\n",
            "Loss in iteration no. 82058 ==> 0.3073412438611676\n",
            "Loss in iteration no. 82059 ==> 0.3073412338600161\n",
            "Loss in iteration no. 82060 ==> 0.3073412238594594\n",
            "Loss in iteration no. 82061 ==> 0.30734121385949714\n",
            "Loss in iteration no. 82062 ==> 0.307341203860131\n",
            "Loss in iteration no. 82063 ==> 0.30734119386135944\n",
            "Loss in iteration no. 82064 ==> 0.3073411838631829\n",
            "Loss in iteration no. 82065 ==> 0.307341173865601\n",
            "Loss in iteration no. 82066 ==> 0.3073411638686135\n",
            "Loss in iteration no. 82067 ==> 0.3073411538722219\n",
            "Loss in iteration no. 82068 ==> 0.30734114387642475\n",
            "Loss in iteration no. 82069 ==> 0.3073411338812213\n",
            "Loss in iteration no. 82070 ==> 0.30734112388661394\n",
            "Loss in iteration no. 82071 ==> 0.30734111389260027\n",
            "Loss in iteration no. 82072 ==> 0.30734110389918257\n",
            "Loss in iteration no. 82073 ==> 0.30734109390635833\n",
            "Loss in iteration no. 82074 ==> 0.30734108391412945\n",
            "Loss in iteration no. 82075 ==> 0.30734107392249393\n",
            "Loss in iteration no. 82076 ==> 0.307341063931454\n",
            "Loss in iteration no. 82077 ==> 0.3073410539410084\n",
            "Loss in iteration no. 82078 ==> 0.30734104395115674\n",
            "Loss in iteration no. 82079 ==> 0.3073410339618991\n",
            "Loss in iteration no. 82080 ==> 0.3073410239732364\n",
            "Loss in iteration no. 82081 ==> 0.30734101398516867\n",
            "Loss in iteration no. 82082 ==> 0.30734100399769465\n",
            "Loss in iteration no. 82083 ==> 0.3073409940108146\n",
            "Loss in iteration no. 82084 ==> 0.3073409840245287\n",
            "Loss in iteration no. 82085 ==> 0.30734097403883764\n",
            "Loss in iteration no. 82086 ==> 0.30734096405374056\n",
            "Loss in iteration no. 82087 ==> 0.307340954069237\n",
            "Loss in iteration no. 82088 ==> 0.3073409440853277\n",
            "Loss in iteration no. 82089 ==> 0.3073409341020125\n",
            "Loss in iteration no. 82090 ==> 0.3073409241192911\n",
            "Loss in iteration no. 82091 ==> 0.3073409141371639\n",
            "Loss in iteration no. 82092 ==> 0.30734090415563103\n",
            "Loss in iteration no. 82093 ==> 0.30734089417469157\n",
            "Loss in iteration no. 82094 ==> 0.30734088419434547\n",
            "Loss in iteration no. 82095 ==> 0.3073408742145937\n",
            "Loss in iteration no. 82096 ==> 0.3073408642354352\n",
            "Loss in iteration no. 82097 ==> 0.3073408542568714\n",
            "Loss in iteration no. 82098 ==> 0.3073408442789007\n",
            "Loss in iteration no. 82099 ==> 0.3073408343015234\n",
            "Loss in iteration no. 82100 ==> 0.30734082432473986\n",
            "Loss in iteration no. 82101 ==> 0.3073408143485504\n",
            "Loss in iteration no. 82102 ==> 0.30734080437295386\n",
            "Loss in iteration no. 82103 ==> 0.30734079439795114\n",
            "Loss in iteration no. 82104 ==> 0.30734078442354174\n",
            "Loss in iteration no. 82105 ==> 0.30734077444972635\n",
            "Loss in iteration no. 82106 ==> 0.3073407644765041\n",
            "Loss in iteration no. 82107 ==> 0.30734075450387444\n",
            "Loss in iteration no. 82108 ==> 0.30734074453183896\n",
            "Loss in iteration no. 82109 ==> 0.307340734560396\n",
            "Loss in iteration no. 82110 ==> 0.30734072458954703\n",
            "Loss in iteration no. 82111 ==> 0.30734071461929074\n",
            "Loss in iteration no. 82112 ==> 0.3073407046496275\n",
            "Loss in iteration no. 82113 ==> 0.3073406946805584\n",
            "Loss in iteration no. 82114 ==> 0.3073406847120818\n",
            "Loss in iteration no. 82115 ==> 0.3073406747441979\n",
            "Loss in iteration no. 82116 ==> 0.30734066477690725\n",
            "Loss in iteration no. 82117 ==> 0.30734065481020945\n",
            "Loss in iteration no. 82118 ==> 0.30734064484410467\n",
            "Loss in iteration no. 82119 ==> 0.30734063487859276\n",
            "Loss in iteration no. 82120 ==> 0.30734062491367437\n",
            "Loss in iteration no. 82121 ==> 0.3073406149493483\n",
            "Loss in iteration no. 82122 ==> 0.3073406049856152\n",
            "Loss in iteration no. 82123 ==> 0.3073405950224738\n",
            "Loss in iteration no. 82124 ==> 0.3073405850599265\n",
            "Loss in iteration no. 82125 ==> 0.3073405750979715\n",
            "Loss in iteration no. 82126 ==> 0.30734056513660846\n",
            "Loss in iteration no. 82127 ==> 0.3073405551758391\n",
            "Loss in iteration no. 82128 ==> 0.30734054521566145\n",
            "Loss in iteration no. 82129 ==> 0.30734053525607746\n",
            "Loss in iteration no. 82130 ==> 0.307340525297085\n",
            "Loss in iteration no. 82131 ==> 0.3073405153386852\n",
            "Loss in iteration no. 82132 ==> 0.3073405053808776\n",
            "Loss in iteration no. 82133 ==> 0.3073404954236628\n",
            "Loss in iteration no. 82134 ==> 0.30734048546704096\n",
            "Loss in iteration no. 82135 ==> 0.3073404755110101\n",
            "Loss in iteration no. 82136 ==> 0.30734046555557276\n",
            "Loss in iteration no. 82137 ==> 0.30734045560072676\n",
            "Loss in iteration no. 82138 ==> 0.3073404456464732\n",
            "Loss in iteration no. 82139 ==> 0.3073404356928125\n",
            "Loss in iteration no. 82140 ==> 0.30734042573974285\n",
            "Loss in iteration no. 82141 ==> 0.30734041578726584\n",
            "Loss in iteration no. 82142 ==> 0.3073404058353814\n",
            "Loss in iteration no. 82143 ==> 0.30734039588408774\n",
            "Loss in iteration no. 82144 ==> 0.3073403859333874\n",
            "Loss in iteration no. 82145 ==> 0.3073403759832784\n",
            "Loss in iteration no. 82146 ==> 0.30734036603376136\n",
            "Loss in iteration no. 82147 ==> 0.3073403560848359\n",
            "Loss in iteration no. 82148 ==> 0.3073403461365026\n",
            "Loss in iteration no. 82149 ==> 0.30734033618876117\n",
            "Loss in iteration no. 82150 ==> 0.3073403262416109\n",
            "Loss in iteration no. 82151 ==> 0.3073403162950528\n",
            "Loss in iteration no. 82152 ==> 0.3073403063490868\n",
            "Loss in iteration no. 82153 ==> 0.30734029640371213\n",
            "Loss in iteration no. 82154 ==> 0.30734028645892936\n",
            "Loss in iteration no. 82155 ==> 0.3073402765147372\n",
            "Loss in iteration no. 82156 ==> 0.30734026657113805\n",
            "Loss in iteration no. 82157 ==> 0.30734025662812947\n",
            "Loss in iteration no. 82158 ==> 0.3073402466857123\n",
            "Loss in iteration no. 82159 ==> 0.3073402367438869\n",
            "Loss in iteration no. 82160 ==> 0.30734022680265244\n",
            "Loss in iteration no. 82161 ==> 0.3073402168620098\n",
            "Loss in iteration no. 82162 ==> 0.3073402069219588\n",
            "Loss in iteration no. 82163 ==> 0.30734019698249826\n",
            "Loss in iteration no. 82164 ==> 0.30734018704362953\n",
            "Loss in iteration no. 82165 ==> 0.30734017710535194\n",
            "Loss in iteration no. 82166 ==> 0.30734016716766527\n",
            "Loss in iteration no. 82167 ==> 0.3073401572305699\n",
            "Loss in iteration no. 82168 ==> 0.30734014729406534\n",
            "Loss in iteration no. 82169 ==> 0.30734013735815224\n",
            "Loss in iteration no. 82170 ==> 0.3073401274228305\n",
            "Loss in iteration no. 82171 ==> 0.3073401174880994\n",
            "Loss in iteration no. 82172 ==> 0.3073401075539596\n",
            "Loss in iteration no. 82173 ==> 0.30734009762040976\n",
            "Loss in iteration no. 82174 ==> 0.30734008768745175\n",
            "Loss in iteration no. 82175 ==> 0.307340077755084\n",
            "Loss in iteration no. 82176 ==> 0.30734006782330703\n",
            "Loss in iteration no. 82177 ==> 0.307340057892122\n",
            "Loss in iteration no. 82178 ==> 0.3073400479615267\n",
            "Loss in iteration no. 82179 ==> 0.3073400380315217\n",
            "Loss in iteration no. 82180 ==> 0.3073400281021082\n",
            "Loss in iteration no. 82181 ==> 0.30734001817328516\n",
            "Loss in iteration no. 82182 ==> 0.3073400082450526\n",
            "Loss in iteration no. 82183 ==> 0.30733999831741027\n",
            "Loss in iteration no. 82184 ==> 0.3073399883903588\n",
            "Loss in iteration no. 82185 ==> 0.30733997846389816\n",
            "Loss in iteration no. 82186 ==> 0.3073399685380272\n",
            "Loss in iteration no. 82187 ==> 0.3073399586127476\n",
            "Loss in iteration no. 82188 ==> 0.3073399486880575\n",
            "Loss in iteration no. 82189 ==> 0.30733993876395843\n",
            "Loss in iteration no. 82190 ==> 0.30733992884044864\n",
            "Loss in iteration no. 82191 ==> 0.30733991891753065\n",
            "Loss in iteration no. 82192 ==> 0.3073399089952018\n",
            "Loss in iteration no. 82193 ==> 0.3073398990734633\n",
            "Loss in iteration no. 82194 ==> 0.30733988915231475\n",
            "Loss in iteration no. 82195 ==> 0.3073398792317566\n",
            "Loss in iteration no. 82196 ==> 0.30733986931178825\n",
            "Loss in iteration no. 82197 ==> 0.30733985939241054\n",
            "Loss in iteration no. 82198 ==> 0.30733984947362214\n",
            "Loss in iteration no. 82199 ==> 0.30733983955542427\n",
            "Loss in iteration no. 82200 ==> 0.30733982963781603\n",
            "Loss in iteration no. 82201 ==> 0.30733981972079805\n",
            "Loss in iteration no. 82202 ==> 0.3073398098043696\n",
            "Loss in iteration no. 82203 ==> 0.30733979988853055\n",
            "Loss in iteration no. 82204 ==> 0.30733978997328176\n",
            "Loss in iteration no. 82205 ==> 0.3073397800586231\n",
            "Loss in iteration no. 82206 ==> 0.3073397701445534\n",
            "Loss in iteration no. 82207 ==> 0.307339760231074\n",
            "Loss in iteration no. 82208 ==> 0.3073397503181841\n",
            "Loss in iteration no. 82209 ==> 0.30733974040588397\n",
            "Loss in iteration no. 82210 ==> 0.30733973049417274\n",
            "Loss in iteration no. 82211 ==> 0.3073397205830516\n",
            "Loss in iteration no. 82212 ==> 0.30733971067251953\n",
            "Loss in iteration no. 82213 ==> 0.3073397007625774\n",
            "Loss in iteration no. 82214 ==> 0.3073396908532247\n",
            "Loss in iteration no. 82215 ==> 0.3073396809444612\n",
            "Loss in iteration no. 82216 ==> 0.3073396710362867\n",
            "Loss in iteration no. 82217 ==> 0.30733966112870165\n",
            "Loss in iteration no. 82218 ==> 0.307339651221706\n",
            "Loss in iteration no. 82219 ==> 0.3073396413153002\n",
            "Loss in iteration no. 82220 ==> 0.30733963140948245\n",
            "Loss in iteration no. 82221 ==> 0.30733962150425514\n",
            "Loss in iteration no. 82222 ==> 0.3073396115996153\n",
            "Loss in iteration no. 82223 ==> 0.30733960169556623\n",
            "Loss in iteration no. 82224 ==> 0.30733959179210524\n",
            "Loss in iteration no. 82225 ==> 0.3073395818892336\n",
            "Loss in iteration no. 82226 ==> 0.30733957198695067\n",
            "Loss in iteration no. 82227 ==> 0.30733956208525737\n",
            "Loss in iteration no. 82228 ==> 0.30733955218415177\n",
            "Loss in iteration no. 82229 ==> 0.3073395422836364\n",
            "Loss in iteration no. 82230 ==> 0.30733953238370876\n",
            "Loss in iteration no. 82231 ==> 0.3073395224843702\n",
            "Loss in iteration no. 82232 ==> 0.3073395125856208\n",
            "Loss in iteration no. 82233 ==> 0.30733950268745963\n",
            "Loss in iteration no. 82234 ==> 0.30733949278988826\n",
            "Loss in iteration no. 82235 ==> 0.30733948289290397\n",
            "Loss in iteration no. 82236 ==> 0.30733947299650866\n",
            "Loss in iteration no. 82237 ==> 0.30733946310070276\n",
            "Loss in iteration no. 82238 ==> 0.3073394532054846\n",
            "Loss in iteration no. 82239 ==> 0.30733944331085583\n",
            "Loss in iteration no. 82240 ==> 0.30733943341681474\n",
            "Loss in iteration no. 82241 ==> 0.3073394235233624\n",
            "Loss in iteration no. 82242 ==> 0.3073394136304984\n",
            "Loss in iteration no. 82243 ==> 0.3073394037382225\n",
            "Loss in iteration no. 82244 ==> 0.3073393938465355\n",
            "Loss in iteration no. 82245 ==> 0.3073393839554362\n",
            "Loss in iteration no. 82246 ==> 0.3073393740649253\n",
            "Loss in iteration no. 82247 ==> 0.3073393641750022\n",
            "Loss in iteration no. 82248 ==> 0.3073393542856685\n",
            "Loss in iteration no. 82249 ==> 0.3073393443969218\n",
            "Loss in iteration no. 82250 ==> 0.3073393345087638\n",
            "Loss in iteration no. 82251 ==> 0.3073393246211938\n",
            "Loss in iteration no. 82252 ==> 0.3073393147342116\n",
            "Loss in iteration no. 82253 ==> 0.30733930484781763\n",
            "Loss in iteration no. 82254 ==> 0.3073392949620118\n",
            "Loss in iteration no. 82255 ==> 0.30733928507679303\n",
            "Loss in iteration no. 82256 ==> 0.3073392751921627\n",
            "Loss in iteration no. 82257 ==> 0.3073392653081203\n",
            "Loss in iteration no. 82258 ==> 0.30733925542466556\n",
            "Loss in iteration no. 82259 ==> 0.3073392455417985\n",
            "Loss in iteration no. 82260 ==> 0.3073392356595194\n",
            "Loss in iteration no. 82261 ==> 0.3073392257778283\n",
            "Loss in iteration no. 82262 ==> 0.30733921589672375\n",
            "Loss in iteration no. 82263 ==> 0.3073392060162083\n",
            "Loss in iteration no. 82264 ==> 0.30733919613627925\n",
            "Loss in iteration no. 82265 ==> 0.3073391862569386\n",
            "Loss in iteration no. 82266 ==> 0.3073391763781846\n",
            "Loss in iteration no. 82267 ==> 0.30733916650001886\n",
            "Loss in iteration no. 82268 ==> 0.30733915662244016\n",
            "Loss in iteration no. 82269 ==> 0.3073391467454486\n",
            "Loss in iteration no. 82270 ==> 0.307339136869045\n",
            "Loss in iteration no. 82271 ==> 0.30733912699322863\n",
            "Loss in iteration no. 82272 ==> 0.307339117118\n",
            "Loss in iteration no. 82273 ==> 0.30733910724335795\n",
            "Loss in iteration no. 82274 ==> 0.30733909736930265\n",
            "Loss in iteration no. 82275 ==> 0.307339087495835\n",
            "Loss in iteration no. 82276 ==> 0.30733907762295476\n",
            "Loss in iteration no. 82277 ==> 0.307339067750662\n",
            "Loss in iteration no. 82278 ==> 0.30733905787895527\n",
            "Loss in iteration no. 82279 ==> 0.3073390480078367\n",
            "Loss in iteration no. 82280 ==> 0.3073390381373044\n",
            "Loss in iteration no. 82281 ==> 0.3073390282673592\n",
            "Loss in iteration no. 82282 ==> 0.3073390183980007\n",
            "Loss in iteration no. 82283 ==> 0.30733900852923013\n",
            "Loss in iteration no. 82284 ==> 0.3073389986610453\n",
            "Loss in iteration no. 82285 ==> 0.3073389887934479\n",
            "Loss in iteration no. 82286 ==> 0.30733897892643697\n",
            "Loss in iteration no. 82287 ==> 0.30733896906001285\n",
            "Loss in iteration no. 82288 ==> 0.3073389591941757\n",
            "Loss in iteration no. 82289 ==> 0.30733894932892497\n",
            "Loss in iteration no. 82290 ==> 0.30733893946426055\n",
            "Loss in iteration no. 82291 ==> 0.307338929600184\n",
            "Loss in iteration no. 82292 ==> 0.3073389197366924\n",
            "Loss in iteration no. 82293 ==> 0.30733890987378853\n",
            "Loss in iteration no. 82294 ==> 0.30733890001147063\n",
            "Loss in iteration no. 82295 ==> 0.3073388901497395\n",
            "Loss in iteration no. 82296 ==> 0.30733888028859374\n",
            "Loss in iteration no. 82297 ==> 0.3073388704280358\n",
            "Loss in iteration no. 82298 ==> 0.3073388605680631\n",
            "Loss in iteration no. 82299 ==> 0.3073388507086777\n",
            "Loss in iteration no. 82300 ==> 0.3073388408498777\n",
            "Loss in iteration no. 82301 ==> 0.3073388309916645\n",
            "Loss in iteration no. 82302 ==> 0.3073388211340372\n",
            "Loss in iteration no. 82303 ==> 0.30733881127699614\n",
            "Loss in iteration no. 82304 ==> 0.307338801420541\n",
            "Loss in iteration no. 82305 ==> 0.3073387915646726\n",
            "Loss in iteration no. 82306 ==> 0.30733878170938966\n",
            "Loss in iteration no. 82307 ==> 0.30733877185469316\n",
            "Loss in iteration no. 82308 ==> 0.30733876200058236\n",
            "Loss in iteration no. 82309 ==> 0.30733875214705797\n",
            "Loss in iteration no. 82310 ==> 0.3073387422941186\n",
            "Loss in iteration no. 82311 ==> 0.30733873244176596\n",
            "Loss in iteration no. 82312 ==> 0.30733872258999895\n",
            "Loss in iteration no. 82313 ==> 0.307338712738818\n",
            "Loss in iteration no. 82314 ==> 0.3073387028882219\n",
            "Loss in iteration no. 82315 ==> 0.3073386930382121\n",
            "Loss in iteration no. 82316 ==> 0.3073386831887884\n",
            "Loss in iteration no. 82317 ==> 0.3073386733399496\n",
            "Loss in iteration no. 82318 ==> 0.30733866349169736\n",
            "Loss in iteration no. 82319 ==> 0.3073386536440294\n",
            "Loss in iteration no. 82320 ==> 0.30733864379694814\n",
            "Loss in iteration no. 82321 ==> 0.30733863395045175\n",
            "Loss in iteration no. 82322 ==> 0.30733862410454044\n",
            "Loss in iteration no. 82323 ==> 0.30733861425921555\n",
            "Loss in iteration no. 82324 ==> 0.30733860441447564\n",
            "Loss in iteration no. 82325 ==> 0.3073385945703215\n",
            "Loss in iteration no. 82326 ==> 0.307338584726752\n",
            "Loss in iteration no. 82327 ==> 0.30733857488376815\n",
            "Loss in iteration no. 82328 ==> 0.30733856504136997\n",
            "Loss in iteration no. 82329 ==> 0.30733855519955633\n",
            "Loss in iteration no. 82330 ==> 0.30733854535832805\n",
            "Loss in iteration no. 82331 ==> 0.30733853551768525\n",
            "Loss in iteration no. 82332 ==> 0.3073385256776269\n",
            "Loss in iteration no. 82333 ==> 0.3073385158381542\n",
            "Loss in iteration no. 82334 ==> 0.30733850599926654\n",
            "Loss in iteration no. 82335 ==> 0.3073384961609632\n",
            "Loss in iteration no. 82336 ==> 0.30733848632324556\n",
            "Loss in iteration no. 82337 ==> 0.3073384764861124\n",
            "Loss in iteration no. 82338 ==> 0.30733846664956527\n",
            "Loss in iteration no. 82339 ==> 0.3073384568136018\n",
            "Loss in iteration no. 82340 ==> 0.3073384469782232\n",
            "Loss in iteration no. 82341 ==> 0.30733843714342957\n",
            "Loss in iteration no. 82342 ==> 0.3073384273092208\n",
            "Loss in iteration no. 82343 ==> 0.3073384174755964\n",
            "Loss in iteration no. 82344 ==> 0.3073384076425572\n",
            "Loss in iteration no. 82345 ==> 0.307338397810103\n",
            "Loss in iteration no. 82346 ==> 0.30733838797823265\n",
            "Loss in iteration no. 82347 ==> 0.3073383781469474\n",
            "Loss in iteration no. 82348 ==> 0.30733836831624534\n",
            "Loss in iteration no. 82349 ==> 0.3073383584861293\n",
            "Loss in iteration no. 82350 ==> 0.30733834865659704\n",
            "Loss in iteration no. 82351 ==> 0.30733833882764966\n",
            "Loss in iteration no. 82352 ==> 0.30733832899928604\n",
            "Loss in iteration no. 82353 ==> 0.3073383191715074\n",
            "Loss in iteration no. 82354 ==> 0.30733830934431283\n",
            "Loss in iteration no. 82355 ==> 0.30733829951770275\n",
            "Loss in iteration no. 82356 ==> 0.3073382896916765\n",
            "Loss in iteration no. 82357 ==> 0.3073382798662343\n",
            "Loss in iteration no. 82358 ==> 0.3073382700413763\n",
            "Loss in iteration no. 82359 ==> 0.3073382602171028\n",
            "Loss in iteration no. 82360 ==> 0.30733825039341345\n",
            "Loss in iteration no. 82361 ==> 0.3073382405703085\n",
            "Loss in iteration no. 82362 ==> 0.3073382307477868\n",
            "Loss in iteration no. 82363 ==> 0.3073382209258491\n",
            "Loss in iteration no. 82364 ==> 0.3073382111044954\n",
            "Loss in iteration no. 82365 ==> 0.30733820128372574\n",
            "Loss in iteration no. 82366 ==> 0.30733819146354036\n",
            "Loss in iteration no. 82367 ==> 0.3073381816439384\n",
            "Loss in iteration no. 82368 ==> 0.30733817182492046\n",
            "Loss in iteration no. 82369 ==> 0.30733816200648634\n",
            "Loss in iteration no. 82370 ==> 0.3073381521886353\n",
            "Loss in iteration no. 82371 ==> 0.30733814237136875\n",
            "Loss in iteration no. 82372 ==> 0.3073381325546854\n",
            "Loss in iteration no. 82373 ==> 0.3073381227385863\n",
            "Loss in iteration no. 82374 ==> 0.30733811292307\n",
            "Loss in iteration no. 82375 ==> 0.30733810310813736\n",
            "Loss in iteration no. 82376 ==> 0.3073380932937893\n",
            "Loss in iteration no. 82377 ==> 0.3073380834800233\n",
            "Loss in iteration no. 82378 ==> 0.3073380736668419\n",
            "Loss in iteration no. 82379 ==> 0.3073380638542424\n",
            "Loss in iteration no. 82380 ==> 0.3073380540422274\n",
            "Loss in iteration no. 82381 ==> 0.30733804423079586\n",
            "Loss in iteration no. 82382 ==> 0.307338034419947\n",
            "Loss in iteration no. 82383 ==> 0.3073380246096821\n",
            "Loss in iteration no. 82384 ==> 0.3073380147999998\n",
            "Loss in iteration no. 82385 ==> 0.3073380049909013\n",
            "Loss in iteration no. 82386 ==> 0.3073379951823853\n",
            "Loss in iteration no. 82387 ==> 0.30733798537445284\n",
            "Loss in iteration no. 82388 ==> 0.30733797556710307\n",
            "Loss in iteration no. 82389 ==> 0.30733796576033684\n",
            "Loss in iteration no. 82390 ==> 0.3073379559541535\n",
            "Loss in iteration no. 82391 ==> 0.3073379461485526\n",
            "Loss in iteration no. 82392 ==> 0.3073379363435349\n",
            "Loss in iteration no. 82393 ==> 0.30733792653910036\n",
            "Loss in iteration no. 82394 ==> 0.3073379167352484\n",
            "Loss in iteration no. 82395 ==> 0.30733790693197977\n",
            "Loss in iteration no. 82396 ==> 0.3073378971292932\n",
            "Loss in iteration no. 82397 ==> 0.3073378873271899\n",
            "Loss in iteration no. 82398 ==> 0.30733787752566966\n",
            "Loss in iteration no. 82399 ==> 0.30733786772473154\n",
            "Loss in iteration no. 82400 ==> 0.307337857924376\n",
            "Loss in iteration no. 82401 ==> 0.307337848124603\n",
            "Loss in iteration no. 82402 ==> 0.30733783832541267\n",
            "Loss in iteration no. 82403 ==> 0.3073378285268055\n",
            "Loss in iteration no. 82404 ==> 0.30733781872878013\n",
            "Loss in iteration no. 82405 ==> 0.30733780893133766\n",
            "Loss in iteration no. 82406 ==> 0.3073377991344777\n",
            "Loss in iteration no. 82407 ==> 0.3073377893381995\n",
            "Loss in iteration no. 82408 ==> 0.3073377795425042\n",
            "Loss in iteration no. 82409 ==> 0.30733776974739063\n",
            "Loss in iteration no. 82410 ==> 0.30733775995286\n",
            "Loss in iteration no. 82411 ==> 0.30733775015891135\n",
            "Loss in iteration no. 82412 ==> 0.3073377403655443\n",
            "Loss in iteration no. 82413 ==> 0.30733773057275987\n",
            "Loss in iteration no. 82414 ==> 0.30733772078055815\n",
            "Loss in iteration no. 82415 ==> 0.3073377109889381\n",
            "Loss in iteration no. 82416 ==> 0.3073377011979001\n",
            "Loss in iteration no. 82417 ==> 0.3073376914074447\n",
            "Loss in iteration no. 82418 ==> 0.3073376816175701\n",
            "Loss in iteration no. 82419 ==> 0.30733767182827887\n",
            "Loss in iteration no. 82420 ==> 0.3073376620395689\n",
            "Loss in iteration no. 82421 ==> 0.30733765225144066\n",
            "Loss in iteration no. 82422 ==> 0.3073376424638943\n",
            "Loss in iteration no. 82423 ==> 0.3073376326769294\n",
            "Loss in iteration no. 82424 ==> 0.3073376228905475\n",
            "Loss in iteration no. 82425 ==> 0.307337613104746\n",
            "Loss in iteration no. 82426 ==> 0.30733760331952703\n",
            "Loss in iteration no. 82427 ==> 0.3073375935348892\n",
            "Loss in iteration no. 82428 ==> 0.30733758375083275\n",
            "Loss in iteration no. 82429 ==> 0.3073375739673589\n",
            "Loss in iteration no. 82430 ==> 0.30733756418446556\n",
            "Loss in iteration no. 82431 ==> 0.3073375544021546\n",
            "Loss in iteration no. 82432 ==> 0.3073375446204252\n",
            "Loss in iteration no. 82433 ==> 0.30733753483927684\n",
            "Loss in iteration no. 82434 ==> 0.30733752505870937\n",
            "Loss in iteration no. 82435 ==> 0.3073375152787245\n",
            "Loss in iteration no. 82436 ==> 0.30733750549932\n",
            "Loss in iteration no. 82437 ==> 0.30733749572049696\n",
            "Loss in iteration no. 82438 ==> 0.30733748594225546\n",
            "Loss in iteration no. 82439 ==> 0.30733747616459567\n",
            "Loss in iteration no. 82440 ==> 0.30733746638751636\n",
            "Loss in iteration no. 82441 ==> 0.30733745661101824\n",
            "Loss in iteration no. 82442 ==> 0.3073374468351012\n",
            "Loss in iteration no. 82443 ==> 0.30733743705976563\n",
            "Loss in iteration no. 82444 ==> 0.3073374272850114\n",
            "Loss in iteration no. 82445 ==> 0.3073374175108377\n",
            "Loss in iteration no. 82446 ==> 0.30733740773724433\n",
            "Loss in iteration no. 82447 ==> 0.3073373979642329\n",
            "Loss in iteration no. 82448 ==> 0.3073373881918024\n",
            "Loss in iteration no. 82449 ==> 0.3073373784199525\n",
            "Loss in iteration no. 82450 ==> 0.3073373686486828\n",
            "Loss in iteration no. 82451 ==> 0.307337358877994\n",
            "Loss in iteration no. 82452 ==> 0.3073373491078869\n",
            "Loss in iteration no. 82453 ==> 0.30733733933836005\n",
            "Loss in iteration no. 82454 ==> 0.3073373295694144\n",
            "Loss in iteration no. 82455 ==> 0.30733731980104856\n",
            "Loss in iteration no. 82456 ==> 0.30733731003326337\n",
            "Loss in iteration no. 82457 ==> 0.30733730026605977\n",
            "Loss in iteration no. 82458 ==> 0.30733729049943553\n",
            "Loss in iteration no. 82459 ==> 0.3073372807333926\n",
            "Loss in iteration no. 82460 ==> 0.3073372709679302\n",
            "Loss in iteration no. 82461 ==> 0.3073372612030473\n",
            "Loss in iteration no. 82462 ==> 0.30733725143874585\n",
            "Loss in iteration no. 82463 ==> 0.30733724167502396\n",
            "Loss in iteration no. 82464 ==> 0.30733723191188284\n",
            "Loss in iteration no. 82465 ==> 0.3073372221493227\n",
            "Loss in iteration no. 82466 ==> 0.307337212387342\n",
            "Loss in iteration no. 82467 ==> 0.3073372026259413\n",
            "Loss in iteration no. 82468 ==> 0.307337192865121\n",
            "Loss in iteration no. 82469 ==> 0.3073371831048811\n",
            "Loss in iteration no. 82470 ==> 0.3073371733452218\n",
            "Loss in iteration no. 82471 ==> 0.3073371635861418\n",
            "Loss in iteration no. 82472 ==> 0.3073371538276416\n",
            "Loss in iteration no. 82473 ==> 0.30733714406972207\n",
            "Loss in iteration no. 82474 ==> 0.30733713431238224\n",
            "Loss in iteration no. 82475 ==> 0.30733712455562234\n",
            "Loss in iteration no. 82476 ==> 0.3073371147994421\n",
            "Loss in iteration no. 82477 ==> 0.307337105043843\n",
            "Loss in iteration no. 82478 ==> 0.30733709528882236\n",
            "Loss in iteration no. 82479 ==> 0.3073370855343818\n",
            "Loss in iteration no. 82480 ==> 0.3073370757805214\n",
            "Loss in iteration no. 82481 ==> 0.30733706602724004\n",
            "Loss in iteration no. 82482 ==> 0.307337056274539\n",
            "Loss in iteration no. 82483 ==> 0.3073370465224173\n",
            "Loss in iteration no. 82484 ==> 0.3073370367708753\n",
            "Loss in iteration no. 82485 ==> 0.3073370270199134\n",
            "Loss in iteration no. 82486 ==> 0.3073370172695305\n",
            "Loss in iteration no. 82487 ==> 0.30733700751972637\n",
            "Loss in iteration no. 82488 ==> 0.3073369977705032\n",
            "Loss in iteration no. 82489 ==> 0.30733698802185855\n",
            "Loss in iteration no. 82490 ==> 0.307336978273793\n",
            "Loss in iteration no. 82491 ==> 0.30733696852630754\n",
            "Loss in iteration no. 82492 ==> 0.3073369587794011\n",
            "Loss in iteration no. 82493 ==> 0.3073369490330739\n",
            "Loss in iteration no. 82494 ==> 0.3073369392873266\n",
            "Loss in iteration no. 82495 ==> 0.30733692954215797\n",
            "Loss in iteration no. 82496 ==> 0.3073369197975681\n",
            "Loss in iteration no. 82497 ==> 0.30733691005355773\n",
            "Loss in iteration no. 82498 ==> 0.3073369003101266\n",
            "Loss in iteration no. 82499 ==> 0.3073368905672749\n",
            "Loss in iteration no. 82500 ==> 0.3073368808250019\n",
            "Loss in iteration no. 82501 ==> 0.3073368710833076\n",
            "Loss in iteration no. 82502 ==> 0.3073368613421925\n",
            "Loss in iteration no. 82503 ==> 0.3073368516016567\n",
            "Loss in iteration no. 82504 ==> 0.3073368418616993\n",
            "Loss in iteration no. 82505 ==> 0.30733683212232077\n",
            "Loss in iteration no. 82506 ==> 0.3073368223835218\n",
            "Loss in iteration no. 82507 ==> 0.30733681264530016\n",
            "Loss in iteration no. 82508 ==> 0.3073368029076588\n",
            "Loss in iteration no. 82509 ==> 0.307336793170595\n",
            "Loss in iteration no. 82510 ==> 0.30733678343411086\n",
            "Loss in iteration no. 82511 ==> 0.30733677369820456\n",
            "Loss in iteration no. 82512 ==> 0.3073367639628778\n",
            "Loss in iteration no. 82513 ==> 0.3073367542281283\n",
            "Loss in iteration no. 82514 ==> 0.3073367444939581\n",
            "Loss in iteration no. 82515 ==> 0.30733673476036705\n",
            "Loss in iteration no. 82516 ==> 0.30733672502735315\n",
            "Loss in iteration no. 82517 ==> 0.30733671529491835\n",
            "Loss in iteration no. 82518 ==> 0.3073367055630624\n",
            "Loss in iteration no. 82519 ==> 0.3073366958317833\n",
            "Loss in iteration no. 82520 ==> 0.3073366861010839\n",
            "Loss in iteration no. 82521 ==> 0.30733667637096235\n",
            "Loss in iteration no. 82522 ==> 0.30733666664141945\n",
            "Loss in iteration no. 82523 ==> 0.3073366569124538\n",
            "Loss in iteration no. 82524 ==> 0.3073366471840675\n",
            "Loss in iteration no. 82525 ==> 0.3073366374562587\n",
            "Loss in iteration no. 82526 ==> 0.3073366277290283\n",
            "Loss in iteration no. 82527 ==> 0.3073366180023756\n",
            "Loss in iteration no. 82528 ==> 0.3073366082763012\n",
            "Loss in iteration no. 82529 ==> 0.3073365985508043\n",
            "Loss in iteration no. 82530 ==> 0.3073365888258858\n",
            "Loss in iteration no. 82531 ==> 0.30733657910154577\n",
            "Loss in iteration no. 82532 ==> 0.30733656937778214\n",
            "Loss in iteration no. 82533 ==> 0.3073365596545975\n",
            "Loss in iteration no. 82534 ==> 0.307336549931991\n",
            "Loss in iteration no. 82535 ==> 0.3073365402099612\n",
            "Loss in iteration no. 82536 ==> 0.3073365304885101\n",
            "Loss in iteration no. 82537 ==> 0.3073365207676356\n",
            "Loss in iteration no. 82538 ==> 0.30733651104734006\n",
            "Loss in iteration no. 82539 ==> 0.3073365013276209\n",
            "Loss in iteration no. 82540 ==> 0.3073364916084801\n",
            "Loss in iteration no. 82541 ==> 0.3073364818899169\n",
            "Loss in iteration no. 82542 ==> 0.3073364721719315\n",
            "Loss in iteration no. 82543 ==> 0.30733646245452334\n",
            "Loss in iteration no. 82544 ==> 0.30733645273769244\n",
            "Loss in iteration no. 82545 ==> 0.30733644302143914\n",
            "Loss in iteration no. 82546 ==> 0.3073364333057621\n",
            "Loss in iteration no. 82547 ==> 0.30733642359066443\n",
            "Loss in iteration no. 82548 ==> 0.30733641387614286\n",
            "Loss in iteration no. 82549 ==> 0.30733640416219826\n",
            "Loss in iteration no. 82550 ==> 0.307336394448832\n",
            "Loss in iteration no. 82551 ==> 0.30733638473604225\n",
            "Loss in iteration no. 82552 ==> 0.3073363750238296\n",
            "Loss in iteration no. 82553 ==> 0.30733636531219427\n",
            "Loss in iteration no. 82554 ==> 0.3073363556011362\n",
            "Loss in iteration no. 82555 ==> 0.3073363458906549\n",
            "Loss in iteration no. 82556 ==> 0.3073363361807506\n",
            "Loss in iteration no. 82557 ==> 0.3073363264714234\n",
            "Loss in iteration no. 82558 ==> 0.3073363167626734\n",
            "Loss in iteration no. 82559 ==> 0.3073363070544999\n",
            "Loss in iteration no. 82560 ==> 0.30733629734690393\n",
            "Loss in iteration no. 82561 ==> 0.30733628763988463\n",
            "Loss in iteration no. 82562 ==> 0.30733627793344154\n",
            "Loss in iteration no. 82563 ==> 0.30733626822757576\n",
            "Loss in iteration no. 82564 ==> 0.3073362585222864\n",
            "Loss in iteration no. 82565 ==> 0.30733624881757454\n",
            "Loss in iteration no. 82566 ==> 0.30733623911343855\n",
            "Loss in iteration no. 82567 ==> 0.3073362294098796\n",
            "Loss in iteration no. 82568 ==> 0.3073362197068971\n",
            "Loss in iteration no. 82569 ==> 0.3073362100044911\n",
            "Loss in iteration no. 82570 ==> 0.307336200302661\n",
            "Loss in iteration no. 82571 ==> 0.30733619060140793\n",
            "Loss in iteration no. 82572 ==> 0.3073361809007319\n",
            "Loss in iteration no. 82573 ==> 0.30733617120063156\n",
            "Loss in iteration no. 82574 ==> 0.30733616150110804\n",
            "Loss in iteration no. 82575 ==> 0.3073361518021605\n",
            "Loss in iteration no. 82576 ==> 0.3073361421037896\n",
            "Loss in iteration no. 82577 ==> 0.30733613240599483\n",
            "Loss in iteration no. 82578 ==> 0.3073361227087766\n",
            "Loss in iteration no. 82579 ==> 0.3073361130121339\n",
            "Loss in iteration no. 82580 ==> 0.30733610331606803\n",
            "Loss in iteration no. 82581 ==> 0.3073360936205776\n",
            "Loss in iteration no. 82582 ==> 0.30733608392566414\n",
            "Loss in iteration no. 82583 ==> 0.3073360742313264\n",
            "Loss in iteration no. 82584 ==> 0.3073360645375647\n",
            "Loss in iteration no. 82585 ==> 0.30733605484437887\n",
            "Loss in iteration no. 82586 ==> 0.3073360451517685\n",
            "Loss in iteration no. 82587 ==> 0.3073360354597347\n",
            "Loss in iteration no. 82588 ==> 0.30733602576827657\n",
            "Loss in iteration no. 82589 ==> 0.3073360160773949\n",
            "Loss in iteration no. 82590 ==> 0.3073360063870884\n",
            "Loss in iteration no. 82591 ==> 0.3073359966973572\n",
            "Loss in iteration no. 82592 ==> 0.3073359870082027\n",
            "Loss in iteration no. 82593 ==> 0.3073359773196239\n",
            "Loss in iteration no. 82594 ==> 0.30733596763161986\n",
            "Loss in iteration no. 82595 ==> 0.30733595794419216\n",
            "Loss in iteration no. 82596 ==> 0.30733594825733984\n",
            "Loss in iteration no. 82597 ==> 0.307335938571063\n",
            "Loss in iteration no. 82598 ==> 0.30733592888536215\n",
            "Loss in iteration no. 82599 ==> 0.3073359192002366\n",
            "Loss in iteration no. 82600 ==> 0.3073359095156861\n",
            "Loss in iteration no. 82601 ==> 0.3073358998317111\n",
            "Loss in iteration no. 82602 ==> 0.3073358901483118\n",
            "Loss in iteration no. 82603 ==> 0.3073358804654879\n",
            "Loss in iteration no. 82604 ==> 0.30733587078323904\n",
            "Loss in iteration no. 82605 ==> 0.3073358611015654\n",
            "Loss in iteration no. 82606 ==> 0.3073358514204672\n",
            "Loss in iteration no. 82607 ==> 0.3073358417399447\n",
            "Loss in iteration no. 82608 ==> 0.30733583205999593\n",
            "Loss in iteration no. 82609 ==> 0.30733582238062407\n",
            "Loss in iteration no. 82610 ==> 0.307335812701826\n",
            "Loss in iteration no. 82611 ==> 0.30733580302360386\n",
            "Loss in iteration no. 82612 ==> 0.30733579334595573\n",
            "Loss in iteration no. 82613 ==> 0.3073357836688837\n",
            "Loss in iteration no. 82614 ==> 0.3073357739923862\n",
            "Loss in iteration no. 82615 ==> 0.3073357643164633\n",
            "Loss in iteration no. 82616 ==> 0.30733575464111557\n",
            "Loss in iteration no. 82617 ==> 0.30733574496634264\n",
            "Loss in iteration no. 82618 ==> 0.3073357352921443\n",
            "Loss in iteration no. 82619 ==> 0.30733572561852074\n",
            "Loss in iteration no. 82620 ==> 0.30733571594547265\n",
            "Loss in iteration no. 82621 ==> 0.30733570627299917\n",
            "Loss in iteration no. 82622 ==> 0.30733569660109994\n",
            "Loss in iteration no. 82623 ==> 0.3073356869297747\n",
            "Loss in iteration no. 82624 ==> 0.3073356772590251\n",
            "Loss in iteration no. 82625 ==> 0.3073356675888494\n",
            "Loss in iteration no. 82626 ==> 0.30733565791924866\n",
            "Loss in iteration no. 82627 ==> 0.3073356482502218\n",
            "Loss in iteration no. 82628 ==> 0.3073356385817697\n",
            "Loss in iteration no. 82629 ==> 0.30733562891389254\n",
            "Loss in iteration no. 82630 ==> 0.30733561924659\n",
            "Loss in iteration no. 82631 ==> 0.3073356095798609\n",
            "Loss in iteration no. 82632 ==> 0.30733559991370635\n",
            "Loss in iteration no. 82633 ==> 0.3073355902481258\n",
            "Loss in iteration no. 82634 ==> 0.30733558058312094\n",
            "Loss in iteration no. 82635 ==> 0.30733557091868874\n",
            "Loss in iteration no. 82636 ==> 0.3073355612548312\n",
            "Loss in iteration no. 82637 ==> 0.30733555159154735\n",
            "Loss in iteration no. 82638 ==> 0.3073355419288384\n",
            "Loss in iteration no. 82639 ==> 0.3073355322667034\n",
            "Loss in iteration no. 82640 ==> 0.30733552260514196\n",
            "Loss in iteration no. 82641 ==> 0.3073355129441544\n",
            "Loss in iteration no. 82642 ==> 0.30733550328374093\n",
            "Loss in iteration no. 82643 ==> 0.3073354936239023\n",
            "Loss in iteration no. 82644 ==> 0.3073354839646367\n",
            "Loss in iteration no. 82645 ==> 0.3073354743059445\n",
            "Loss in iteration no. 82646 ==> 0.3073354646478276\n",
            "Loss in iteration no. 82647 ==> 0.3073354549902837\n",
            "Loss in iteration no. 82648 ==> 0.3073354453333126\n",
            "Loss in iteration no. 82649 ==> 0.3073354356769163\n",
            "Loss in iteration no. 82650 ==> 0.3073354260210931\n",
            "Loss in iteration no. 82651 ==> 0.30733541636584455\n",
            "Loss in iteration no. 82652 ==> 0.30733540671116844\n",
            "Loss in iteration no. 82653 ==> 0.30733539705706614\n",
            "Loss in iteration no. 82654 ==> 0.30733538740353816\n",
            "Loss in iteration no. 82655 ==> 0.30733537775058245\n",
            "Loss in iteration no. 82656 ==> 0.30733536809820095\n",
            "Loss in iteration no. 82657 ==> 0.30733535844639287\n",
            "Loss in iteration no. 82658 ==> 0.3073353487951584\n",
            "Loss in iteration no. 82659 ==> 0.3073353391444972\n",
            "Loss in iteration no. 82660 ==> 0.30733532949440895\n",
            "Loss in iteration no. 82661 ==> 0.30733531984489426\n",
            "Loss in iteration no. 82662 ==> 0.30733531019595234\n",
            "Loss in iteration no. 82663 ==> 0.3073353005475842\n",
            "Loss in iteration no. 82664 ==> 0.3073352908997885\n",
            "Loss in iteration no. 82665 ==> 0.307335281252567\n",
            "Loss in iteration no. 82666 ==> 0.30733527160591817\n",
            "Loss in iteration no. 82667 ==> 0.3073352619598422\n",
            "Loss in iteration no. 82668 ==> 0.3073352523143387\n",
            "Loss in iteration no. 82669 ==> 0.3073352426694089\n",
            "Loss in iteration no. 82670 ==> 0.3073352330250525\n",
            "Loss in iteration no. 82671 ==> 0.3073352233812688\n",
            "Loss in iteration no. 82672 ==> 0.30733521373805756\n",
            "Loss in iteration no. 82673 ==> 0.3073352040954192\n",
            "Loss in iteration no. 82674 ==> 0.30733519445335356\n",
            "Loss in iteration no. 82675 ==> 0.3073351848118608\n",
            "Loss in iteration no. 82676 ==> 0.307335175170941\n",
            "Loss in iteration no. 82677 ==> 0.30733516553059437\n",
            "Loss in iteration no. 82678 ==> 0.3073351558908195\n",
            "Loss in iteration no. 82679 ==> 0.30733514625161745\n",
            "Loss in iteration no. 82680 ==> 0.3073351366129884\n",
            "Loss in iteration no. 82681 ==> 0.30733512697493204\n",
            "Loss in iteration no. 82682 ==> 0.30733511733744817\n",
            "Loss in iteration no. 82683 ==> 0.3073351077005356\n",
            "Loss in iteration no. 82684 ==> 0.307335098064197\n",
            "Loss in iteration no. 82685 ==> 0.3073350884284298\n",
            "Loss in iteration no. 82686 ==> 0.3073350787932362\n",
            "Loss in iteration no. 82687 ==> 0.30733506915861414\n",
            "Loss in iteration no. 82688 ==> 0.30733505952456436\n",
            "Loss in iteration no. 82689 ==> 0.30733504989108756\n",
            "Loss in iteration no. 82690 ==> 0.30733504025818204\n",
            "Loss in iteration no. 82691 ==> 0.3073350306258493\n",
            "Loss in iteration no. 82692 ==> 0.307335020994088\n",
            "Loss in iteration no. 82693 ==> 0.30733501136289915\n",
            "Loss in iteration no. 82694 ==> 0.30733500173228323\n",
            "Loss in iteration no. 82695 ==> 0.307334992102239\n",
            "Loss in iteration no. 82696 ==> 0.30733498247276664\n",
            "Loss in iteration no. 82697 ==> 0.30733497284386646\n",
            "Loss in iteration no. 82698 ==> 0.3073349632155375\n",
            "Loss in iteration no. 82699 ==> 0.3073349535877814\n",
            "Loss in iteration no. 82700 ==> 0.3073349439605971\n",
            "Loss in iteration no. 82701 ==> 0.3073349343339838\n",
            "Loss in iteration no. 82702 ==> 0.3073349247079431\n",
            "Loss in iteration no. 82703 ==> 0.30733491508247396\n",
            "Loss in iteration no. 82704 ==> 0.3073349054575766\n",
            "Loss in iteration no. 82705 ==> 0.3073348958332513\n",
            "Loss in iteration no. 82706 ==> 0.3073348862094975\n",
            "Loss in iteration no. 82707 ==> 0.3073348765863151\n",
            "Loss in iteration no. 82708 ==> 0.30733486696370427\n",
            "Loss in iteration no. 82709 ==> 0.30733485734166505\n",
            "Loss in iteration no. 82710 ==> 0.3073348477201981\n",
            "Loss in iteration no. 82711 ==> 0.3073348380993023\n",
            "Loss in iteration no. 82712 ==> 0.30733482847897764\n",
            "Loss in iteration no. 82713 ==> 0.3073348188592239\n",
            "Loss in iteration no. 82714 ==> 0.30733480924004214\n",
            "Loss in iteration no. 82715 ==> 0.3073347996214323\n",
            "Loss in iteration no. 82716 ==> 0.3073347900033934\n",
            "Loss in iteration no. 82717 ==> 0.3073347803859251\n",
            "Loss in iteration no. 82718 ==> 0.3073347707690289\n",
            "Loss in iteration no. 82719 ==> 0.30733476115270375\n",
            "Loss in iteration no. 82720 ==> 0.3073347515369498\n",
            "Loss in iteration no. 82721 ==> 0.30733474192176674\n",
            "Loss in iteration no. 82722 ==> 0.30733473230715486\n",
            "Loss in iteration no. 82723 ==> 0.3073347226931144\n",
            "Loss in iteration no. 82724 ==> 0.30733471307964394\n",
            "Loss in iteration no. 82725 ==> 0.30733470346674585\n",
            "Loss in iteration no. 82726 ==> 0.307334693854418\n",
            "Loss in iteration no. 82727 ==> 0.3073346842426614\n",
            "Loss in iteration no. 82728 ==> 0.30733467463147524\n",
            "Loss in iteration no. 82729 ==> 0.30733466502086076\n",
            "Loss in iteration no. 82730 ==> 0.30733465541081656\n",
            "Loss in iteration no. 82731 ==> 0.30733464580134334\n",
            "Loss in iteration no. 82732 ==> 0.30733463619244067\n",
            "Loss in iteration no. 82733 ==> 0.30733462658410887\n",
            "Loss in iteration no. 82734 ==> 0.3073346169763478\n",
            "Loss in iteration no. 82735 ==> 0.3073346073691566\n",
            "Loss in iteration no. 82736 ==> 0.30733459776253685\n",
            "Loss in iteration no. 82737 ==> 0.3073345881564877\n",
            "Loss in iteration no. 82738 ==> 0.3073345785510089\n",
            "Loss in iteration no. 82739 ==> 0.30733456894610134\n",
            "Loss in iteration no. 82740 ==> 0.30733455934176285\n",
            "Loss in iteration no. 82741 ==> 0.3073345497379954\n",
            "Loss in iteration no. 82742 ==> 0.3073345401347988\n",
            "Loss in iteration no. 82743 ==> 0.307334530532172\n",
            "Loss in iteration no. 82744 ==> 0.30733452093011593\n",
            "Loss in iteration no. 82745 ==> 0.30733451132863054\n",
            "Loss in iteration no. 82746 ==> 0.3073345017277146\n",
            "Loss in iteration no. 82747 ==> 0.30733449212736913\n",
            "Loss in iteration no. 82748 ==> 0.30733448252759427\n",
            "Loss in iteration no. 82749 ==> 0.3073344729283887\n",
            "Loss in iteration no. 82750 ==> 0.30733446332975445\n",
            "Loss in iteration no. 82751 ==> 0.3073344537316891\n",
            "Loss in iteration no. 82752 ==> 0.30733444413419486\n",
            "Loss in iteration no. 82753 ==> 0.30733443453726966\n",
            "Loss in iteration no. 82754 ==> 0.3073344249409151\n",
            "Loss in iteration no. 82755 ==> 0.3073344153451302\n",
            "Loss in iteration no. 82756 ==> 0.3073344057499153\n",
            "Loss in iteration no. 82757 ==> 0.30733439615527036\n",
            "Loss in iteration no. 82758 ==> 0.30733438656119516\n",
            "Loss in iteration no. 82759 ==> 0.30733437696768956\n",
            "Loss in iteration no. 82760 ==> 0.3073343673747543\n",
            "Loss in iteration no. 82761 ==> 0.30733435778238805\n",
            "Loss in iteration no. 82762 ==> 0.3073343481905923\n",
            "Loss in iteration no. 82763 ==> 0.3073343385993653\n",
            "Loss in iteration no. 82764 ==> 0.30733432900870844\n",
            "Loss in iteration no. 82765 ==> 0.3073343194186219\n",
            "Loss in iteration no. 82766 ==> 0.30733430982910354\n",
            "Loss in iteration no. 82767 ==> 0.30733430024015523\n",
            "Loss in iteration no. 82768 ==> 0.3073342906517771\n",
            "Loss in iteration no. 82769 ==> 0.30733428106396765\n",
            "Loss in iteration no. 82770 ==> 0.3073342714767282\n",
            "Loss in iteration no. 82771 ==> 0.3073342618900577\n",
            "Loss in iteration no. 82772 ==> 0.30733425230395656\n",
            "Loss in iteration no. 82773 ==> 0.3073342427184243\n",
            "Loss in iteration no. 82774 ==> 0.3073342331334621\n",
            "Loss in iteration no. 82775 ==> 0.3073342235490685\n",
            "Loss in iteration no. 82776 ==> 0.30733421396524435\n",
            "Loss in iteration no. 82777 ==> 0.3073342043819904\n",
            "Loss in iteration no. 82778 ==> 0.30733419479930446\n",
            "Loss in iteration no. 82779 ==> 0.30733418521718725\n",
            "Loss in iteration no. 82780 ==> 0.30733417563564003\n",
            "Loss in iteration no. 82781 ==> 0.30733416605466096\n",
            "Loss in iteration no. 82782 ==> 0.3073341564742517\n",
            "Loss in iteration no. 82783 ==> 0.30733414689441174\n",
            "Loss in iteration no. 82784 ==> 0.30733413731513975\n",
            "Loss in iteration no. 82785 ==> 0.30733412773643676\n",
            "Loss in iteration no. 82786 ==> 0.3073341181583033\n",
            "Loss in iteration no. 82787 ==> 0.3073341085807384\n",
            "Loss in iteration no. 82788 ==> 0.30733409900374153\n",
            "Loss in iteration no. 82789 ==> 0.30733408942731383\n",
            "Loss in iteration no. 82790 ==> 0.30733407985145494\n",
            "Loss in iteration no. 82791 ==> 0.307334070276165\n",
            "Loss in iteration no. 82792 ==> 0.30733406070144315\n",
            "Loss in iteration no. 82793 ==> 0.30733405112728984\n",
            "Loss in iteration no. 82794 ==> 0.30733404155370614\n",
            "Loss in iteration no. 82795 ==> 0.30733403198069037\n",
            "Loss in iteration no. 82796 ==> 0.3073340224082427\n",
            "Loss in iteration no. 82797 ==> 0.3073340128363637\n",
            "Loss in iteration no. 82798 ==> 0.307334003265054\n",
            "Loss in iteration no. 82799 ==> 0.3073339936943114\n",
            "Loss in iteration no. 82800 ==> 0.3073339841241376\n",
            "Loss in iteration no. 82801 ==> 0.3073339745545323\n",
            "Loss in iteration no. 82802 ==> 0.3073339649854957\n",
            "Loss in iteration no. 82803 ==> 0.30733395541702674\n",
            "Loss in iteration no. 82804 ==> 0.30733394584912604\n",
            "Loss in iteration no. 82805 ==> 0.3073339362817934\n",
            "Loss in iteration no. 82806 ==> 0.3073339267150298\n",
            "Loss in iteration no. 82807 ==> 0.3073339171488335\n",
            "Loss in iteration no. 82808 ==> 0.3073339075832058\n",
            "Loss in iteration no. 82809 ==> 0.3073338980181451\n",
            "Loss in iteration no. 82810 ==> 0.30733388845365356\n",
            "Loss in iteration no. 82811 ==> 0.3073338788897292\n",
            "Loss in iteration no. 82812 ==> 0.30733386932637285\n",
            "Loss in iteration no. 82813 ==> 0.3073338597635847\n",
            "Loss in iteration no. 82814 ==> 0.30733385020136456\n",
            "Loss in iteration no. 82815 ==> 0.30733384063971264\n",
            "Loss in iteration no. 82816 ==> 0.3073338310786274\n",
            "Loss in iteration no. 82817 ==> 0.3073338215181099\n",
            "Loss in iteration no. 82818 ==> 0.3073338119581609\n",
            "Loss in iteration no. 82819 ==> 0.30733380239877944\n",
            "Loss in iteration no. 82820 ==> 0.3073337928399661\n",
            "Loss in iteration no. 82821 ==> 0.30733378328171995\n",
            "Loss in iteration no. 82822 ==> 0.30733377372404097\n",
            "Loss in iteration no. 82823 ==> 0.30733376416693\n",
            "Loss in iteration no. 82824 ==> 0.30733375461038576\n",
            "Loss in iteration no. 82825 ==> 0.30733374505440947\n",
            "Loss in iteration no. 82826 ==> 0.3073337354990011\n",
            "Loss in iteration no. 82827 ==> 0.3073337259441605\n",
            "Loss in iteration no. 82828 ==> 0.3073337163898864\n",
            "Loss in iteration no. 82829 ==> 0.3073337068361794\n",
            "Loss in iteration no. 82830 ==> 0.30733369728303994\n",
            "Loss in iteration no. 82831 ==> 0.307333687730468\n",
            "Loss in iteration no. 82832 ==> 0.30733367817846424\n",
            "Loss in iteration no. 82833 ==> 0.30733366862702655\n",
            "Loss in iteration no. 82834 ==> 0.3073336590761557\n",
            "Loss in iteration no. 82835 ==> 0.3073336495258531\n",
            "Loss in iteration no. 82836 ==> 0.30733363997611596\n",
            "Loss in iteration no. 82837 ==> 0.307333630426947\n",
            "Loss in iteration no. 82838 ==> 0.3073336208783455\n",
            "Loss in iteration no. 82839 ==> 0.3073336113303106\n",
            "Loss in iteration no. 82840 ==> 0.30733360178284214\n",
            "Loss in iteration no. 82841 ==> 0.3073335922359411\n",
            "Loss in iteration no. 82842 ==> 0.30733358268960626\n",
            "Loss in iteration no. 82843 ==> 0.3073335731438391\n",
            "Loss in iteration no. 82844 ==> 0.3073335635986384\n",
            "Loss in iteration no. 82845 ==> 0.3073335540540043\n",
            "Loss in iteration no. 82846 ==> 0.30733354450993694\n",
            "Loss in iteration no. 82847 ==> 0.307333534966437\n",
            "Loss in iteration no. 82848 ==> 0.3073335254235031\n",
            "Loss in iteration no. 82849 ==> 0.3073335158811361\n",
            "Loss in iteration no. 82850 ==> 0.3073335063393354\n",
            "Loss in iteration no. 82851 ==> 0.3073334967981013\n",
            "Loss in iteration no. 82852 ==> 0.30733348725743387\n",
            "Loss in iteration no. 82853 ==> 0.3073334777173325\n",
            "Loss in iteration no. 82854 ==> 0.30733346817779844\n",
            "Loss in iteration no. 82855 ==> 0.3073334586388302\n",
            "Loss in iteration no. 82856 ==> 0.30733344910042826\n",
            "Loss in iteration no. 82857 ==> 0.3073334395625934\n",
            "Loss in iteration no. 82858 ==> 0.3073334300253241\n",
            "Loss in iteration no. 82859 ==> 0.3073334204886217\n",
            "Loss in iteration no. 82860 ==> 0.30733341095248484\n",
            "Loss in iteration no. 82861 ==> 0.3073334014169147\n",
            "Loss in iteration no. 82862 ==> 0.30733339188191033\n",
            "Loss in iteration no. 82863 ==> 0.3073333823474728\n",
            "Loss in iteration no. 82864 ==> 0.30733337281360096\n",
            "Loss in iteration no. 82865 ==> 0.307333363280295\n",
            "Loss in iteration no. 82866 ==> 0.3073333537475554\n",
            "Loss in iteration no. 82867 ==> 0.30733334421538117\n",
            "Loss in iteration no. 82868 ==> 0.30733333468377344\n",
            "Loss in iteration no. 82869 ==> 0.3073333251527318\n",
            "Loss in iteration no. 82870 ==> 0.30733331562225563\n",
            "Loss in iteration no. 82871 ==> 0.3073333060923462\n",
            "Loss in iteration no. 82872 ==> 0.3073332965630018\n",
            "Loss in iteration no. 82873 ==> 0.30733328703422347\n",
            "Loss in iteration no. 82874 ==> 0.3073332775060108\n",
            "Loss in iteration no. 82875 ==> 0.3073332679783633\n",
            "Loss in iteration no. 82876 ==> 0.30733325845128195\n",
            "Loss in iteration no. 82877 ==> 0.3073332489247668\n",
            "Loss in iteration no. 82878 ==> 0.30733323939881674\n",
            "Loss in iteration no. 82879 ==> 0.30733322987343276\n",
            "Loss in iteration no. 82880 ==> 0.3073332203486134\n",
            "Loss in iteration no. 82881 ==> 0.30733321082435994\n",
            "Loss in iteration no. 82882 ==> 0.30733320130067227\n",
            "Loss in iteration no. 82883 ==> 0.30733319177755\n",
            "Loss in iteration no. 82884 ==> 0.30733318225499334\n",
            "Loss in iteration no. 82885 ==> 0.307333172733001\n",
            "Loss in iteration no. 82886 ==> 0.307333163211575\n",
            "Loss in iteration no. 82887 ==> 0.30733315369071446\n",
            "Loss in iteration no. 82888 ==> 0.307333144170418\n",
            "Loss in iteration no. 82889 ==> 0.3073331346506871\n",
            "Loss in iteration no. 82890 ==> 0.3073331251315228\n",
            "Loss in iteration no. 82891 ==> 0.30733311561292215\n",
            "Loss in iteration no. 82892 ==> 0.30733310609488707\n",
            "Loss in iteration no. 82893 ==> 0.30733309657741686\n",
            "Loss in iteration no. 82894 ==> 0.3073330870605123\n",
            "Loss in iteration no. 82895 ==> 0.30733307754417216\n",
            "Loss in iteration no. 82896 ==> 0.3073330680283975\n",
            "Loss in iteration no. 82897 ==> 0.3073330585131879\n",
            "Loss in iteration no. 82898 ==> 0.3073330489985427\n",
            "Loss in iteration no. 82899 ==> 0.3073330394844629\n",
            "Loss in iteration no. 82900 ==> 0.307333029970947\n",
            "Loss in iteration no. 82901 ==> 0.30733302045799704\n",
            "Loss in iteration no. 82902 ==> 0.30733301094561133\n",
            "Loss in iteration no. 82903 ==> 0.30733300143379094\n",
            "Loss in iteration no. 82904 ==> 0.3073329919225342\n",
            "Loss in iteration no. 82905 ==> 0.30733298241184226\n",
            "Loss in iteration no. 82906 ==> 0.3073329729017158\n",
            "Loss in iteration no. 82907 ==> 0.30733296339215277\n",
            "Loss in iteration no. 82908 ==> 0.3073329538831551\n",
            "Loss in iteration no. 82909 ==> 0.30733294437472275\n",
            "Loss in iteration no. 82910 ==> 0.30733293486685354\n",
            "Loss in iteration no. 82911 ==> 0.3073329253595495\n",
            "Loss in iteration no. 82912 ==> 0.30733291585281003\n",
            "Loss in iteration no. 82913 ==> 0.30733290634663385\n",
            "Loss in iteration no. 82914 ==> 0.307332896841023\n",
            "Loss in iteration no. 82915 ==> 0.3073328873359762\n",
            "Loss in iteration no. 82916 ==> 0.3073328778314941\n",
            "Loss in iteration no. 82917 ==> 0.30733286832757545\n",
            "Loss in iteration no. 82918 ==> 0.3073328588242213\n",
            "Loss in iteration no. 82919 ==> 0.307332849321432\n",
            "Loss in iteration no. 82920 ==> 0.30733283981920645\n",
            "Loss in iteration no. 82921 ==> 0.30733283031754394\n",
            "Loss in iteration no. 82922 ==> 0.3073328208164468\n",
            "Loss in iteration no. 82923 ==> 0.3073328113159131\n",
            "Loss in iteration no. 82924 ==> 0.3073328018159439\n",
            "Loss in iteration no. 82925 ==> 0.30733279231653876\n",
            "Loss in iteration no. 82926 ==> 0.307332782817697\n",
            "Loss in iteration no. 82927 ==> 0.30733277331941955\n",
            "Loss in iteration no. 82928 ==> 0.3073327638217055\n",
            "Loss in iteration no. 82929 ==> 0.3073327543245562\n",
            "Loss in iteration no. 82930 ==> 0.30733274482796996\n",
            "Loss in iteration no. 82931 ==> 0.3073327353319475\n",
            "Loss in iteration no. 82932 ==> 0.30733272583648885\n",
            "Loss in iteration no. 82933 ==> 0.30733271634159404\n",
            "Loss in iteration no. 82934 ==> 0.30733270684726255\n",
            "Loss in iteration no. 82935 ==> 0.30733269735349505\n",
            "Loss in iteration no. 82936 ==> 0.30733268786029105\n",
            "Loss in iteration no. 82937 ==> 0.3073326783676501\n",
            "Loss in iteration no. 82938 ==> 0.3073326688755734\n",
            "Loss in iteration no. 82939 ==> 0.30733265938405957\n",
            "Loss in iteration no. 82940 ==> 0.3073326498931094\n",
            "Loss in iteration no. 82941 ==> 0.3073326404027232\n",
            "Loss in iteration no. 82942 ==> 0.30733263091289914\n",
            "Loss in iteration no. 82943 ==> 0.30733262142363976\n",
            "Loss in iteration no. 82944 ==> 0.3073326119349428\n",
            "Loss in iteration no. 82945 ==> 0.3073326024468095\n",
            "Loss in iteration no. 82946 ==> 0.3073325929592398\n",
            "Loss in iteration no. 82947 ==> 0.3073325834722328\n",
            "Loss in iteration no. 82948 ==> 0.3073325739857887\n",
            "Loss in iteration no. 82949 ==> 0.3073325644999084\n",
            "Loss in iteration no. 82950 ==> 0.30733255501459045\n",
            "Loss in iteration no. 82951 ==> 0.3073325455298361\n",
            "Loss in iteration no. 82952 ==> 0.3073325360456452\n",
            "Loss in iteration no. 82953 ==> 0.30733252656201643\n",
            "Loss in iteration no. 82954 ==> 0.3073325170789507\n",
            "Loss in iteration no. 82955 ==> 0.30733250759644815\n",
            "Loss in iteration no. 82956 ==> 0.30733249811450875\n",
            "Loss in iteration no. 82957 ==> 0.3073324886331321\n",
            "Loss in iteration no. 82958 ==> 0.3073324791523176\n",
            "Loss in iteration no. 82959 ==> 0.30733246967206684\n",
            "Loss in iteration no. 82960 ==> 0.3073324601923785\n",
            "Loss in iteration no. 82961 ==> 0.3073324507132525\n",
            "Loss in iteration no. 82962 ==> 0.30733244123468934\n",
            "Loss in iteration no. 82963 ==> 0.3073324317566894\n",
            "Loss in iteration no. 82964 ==> 0.30733242227925167\n",
            "Loss in iteration no. 82965 ==> 0.30733241280237644\n",
            "Loss in iteration no. 82966 ==> 0.3073324033260635\n",
            "Loss in iteration no. 82967 ==> 0.3073323938503128\n",
            "Loss in iteration no. 82968 ==> 0.30733238437512567\n",
            "Loss in iteration no. 82969 ==> 0.3073323749005003\n",
            "Loss in iteration no. 82970 ==> 0.30733236542643755\n",
            "Loss in iteration no. 82971 ==> 0.30733235595293745\n",
            "Loss in iteration no. 82972 ==> 0.307332346479999\n",
            "Loss in iteration no. 82973 ==> 0.3073323370076229\n",
            "Loss in iteration no. 82974 ==> 0.30733232753580936\n",
            "Loss in iteration no. 82975 ==> 0.3073323180645583\n",
            "Loss in iteration no. 82976 ==> 0.3073323085938692\n",
            "Loss in iteration no. 82977 ==> 0.30733229912374194\n",
            "Loss in iteration no. 82978 ==> 0.3073322896541774\n",
            "Loss in iteration no. 82979 ==> 0.30733228018517417\n",
            "Loss in iteration no. 82980 ==> 0.30733227071673347\n",
            "Loss in iteration no. 82981 ==> 0.30733226124885465\n",
            "Loss in iteration no. 82982 ==> 0.3073322517815382\n",
            "Loss in iteration no. 82983 ==> 0.3073322423147832\n",
            "Loss in iteration no. 82984 ==> 0.30733223284859074\n",
            "Loss in iteration no. 82985 ==> 0.30733222338295946\n",
            "Loss in iteration no. 82986 ==> 0.30733221391788945\n",
            "Loss in iteration no. 82987 ==> 0.30733220445338305\n",
            "Loss in iteration no. 82988 ==> 0.3073321949894372\n",
            "Loss in iteration no. 82989 ==> 0.3073321855260531\n",
            "Loss in iteration no. 82990 ==> 0.30733217606323077\n",
            "Loss in iteration no. 82991 ==> 0.3073321666009708\n",
            "Loss in iteration no. 82992 ==> 0.307332157139272\n",
            "Loss in iteration no. 82993 ==> 0.30733214767813416\n",
            "Loss in iteration no. 82994 ==> 0.3073321382175585\n",
            "Loss in iteration no. 82995 ==> 0.3073321287575446\n",
            "Loss in iteration no. 82996 ==> 0.3073321192980918\n",
            "Loss in iteration no. 82997 ==> 0.3073321098392007\n",
            "Loss in iteration no. 82998 ==> 0.30733210038087133\n",
            "Loss in iteration no. 82999 ==> 0.3073320909231026\n",
            "Loss in iteration no. 83000 ==> 0.30733208146589586\n",
            "Loss in iteration no. 83001 ==> 0.30733207200925006\n",
            "Loss in iteration no. 83002 ==> 0.30733206255316614\n",
            "Loss in iteration no. 83003 ==> 0.30733205309764283\n",
            "Loss in iteration no. 83004 ==> 0.3073320436426806\n",
            "Loss in iteration no. 83005 ==> 0.30733203418827965\n",
            "Loss in iteration no. 83006 ==> 0.30733202473444027\n",
            "Loss in iteration no. 83007 ==> 0.30733201528116133\n",
            "Loss in iteration no. 83008 ==> 0.3073320058284446\n",
            "Loss in iteration no. 83009 ==> 0.30733199637628766\n",
            "Loss in iteration no. 83010 ==> 0.30733198692469255\n",
            "Loss in iteration no. 83011 ==> 0.3073319774736585\n",
            "Loss in iteration no. 83012 ==> 0.30733196802318524\n",
            "Loss in iteration no. 83013 ==> 0.30733195857327184\n",
            "Loss in iteration no. 83014 ==> 0.30733194912392076\n",
            "Loss in iteration no. 83015 ==> 0.3073319396751302\n",
            "Loss in iteration no. 83016 ==> 0.30733193022689986\n",
            "Loss in iteration no. 83017 ==> 0.30733192077923044\n",
            "Loss in iteration no. 83018 ==> 0.30733191133212256\n",
            "Loss in iteration no. 83019 ==> 0.3073319018855739\n",
            "Loss in iteration no. 83020 ==> 0.30733189243958714\n",
            "Loss in iteration no. 83021 ==> 0.30733188299416003\n",
            "Loss in iteration no. 83022 ==> 0.3073318735492948\n",
            "Loss in iteration no. 83023 ==> 0.30733186410498875\n",
            "Loss in iteration no. 83024 ==> 0.30733185466124435\n",
            "Loss in iteration no. 83025 ==> 0.30733184521806023\n",
            "Loss in iteration no. 83026 ==> 0.3073318357754353\n",
            "Loss in iteration no. 83027 ==> 0.3073318263333724\n",
            "Loss in iteration no. 83028 ==> 0.307331816891869\n",
            "Loss in iteration no. 83029 ==> 0.3073318074509266\n",
            "Loss in iteration no. 83030 ==> 0.30733179801054433\n",
            "Loss in iteration no. 83031 ==> 0.30733178857072163\n",
            "Loss in iteration no. 83032 ==> 0.3073317791314595\n",
            "Loss in iteration no. 83033 ==> 0.30733176969275827\n",
            "Loss in iteration no. 83034 ==> 0.3073317602546167\n",
            "Loss in iteration no. 83035 ==> 0.3073317508170351\n",
            "Loss in iteration no. 83036 ==> 0.30733174138001407\n",
            "Loss in iteration no. 83037 ==> 0.3073317319435526\n",
            "Loss in iteration no. 83038 ==> 0.30733172250765134\n",
            "Loss in iteration no. 83039 ==> 0.3073317130723101\n",
            "Loss in iteration no. 83040 ==> 0.3073317036375294\n",
            "Loss in iteration no. 83041 ==> 0.30733169420330786\n",
            "Loss in iteration no. 83042 ==> 0.30733168476964673\n",
            "Loss in iteration no. 83043 ==> 0.30733167533654476\n",
            "Loss in iteration no. 83044 ==> 0.3073316659040027\n",
            "Loss in iteration no. 83045 ==> 0.30733165647202115\n",
            "Loss in iteration no. 83046 ==> 0.3073316470405993\n",
            "Loss in iteration no. 83047 ==> 0.3073316376097362\n",
            "Loss in iteration no. 83048 ==> 0.3073316281794339\n",
            "Loss in iteration no. 83049 ==> 0.30733161874969017\n",
            "Loss in iteration no. 83050 ==> 0.30733160932050707\n",
            "Loss in iteration no. 83051 ==> 0.3073315998918837\n",
            "Loss in iteration no. 83052 ==> 0.30733159046381864\n",
            "Loss in iteration no. 83053 ==> 0.307331581036314\n",
            "Loss in iteration no. 83054 ==> 0.30733157160936925\n",
            "Loss in iteration no. 83055 ==> 0.307331562182983\n",
            "Loss in iteration no. 83056 ==> 0.30733155275715657\n",
            "Loss in iteration no. 83057 ==> 0.3073315433318893\n",
            "Loss in iteration no. 83058 ==> 0.30733153390718154\n",
            "Loss in iteration no. 83059 ==> 0.3073315244830329\n",
            "Loss in iteration no. 83060 ==> 0.3073315150594436\n",
            "Loss in iteration no. 83061 ==> 0.30733150563641404\n",
            "Loss in iteration no. 83062 ==> 0.3073314962139433\n",
            "Loss in iteration no. 83063 ==> 0.3073314867920317\n",
            "Loss in iteration no. 83064 ==> 0.30733147737067923\n",
            "Loss in iteration no. 83065 ==> 0.30733146794988614\n",
            "Loss in iteration no. 83066 ==> 0.30733145852965155\n",
            "Loss in iteration no. 83067 ==> 0.3073314491099766\n",
            "Loss in iteration no. 83068 ==> 0.30733143969086\n",
            "Loss in iteration no. 83069 ==> 0.3073314302723029\n",
            "Loss in iteration no. 83070 ==> 0.3073314208543049\n",
            "Loss in iteration no. 83071 ==> 0.3073314114368654\n",
            "Loss in iteration no. 83072 ==> 0.30733140201998466\n",
            "Loss in iteration no. 83073 ==> 0.3073313926036632\n",
            "Loss in iteration no. 83074 ==> 0.30733138318789943\n",
            "Loss in iteration no. 83075 ==> 0.3073313737726961\n",
            "Loss in iteration no. 83076 ==> 0.3073313643580499\n",
            "Loss in iteration no. 83077 ==> 0.3073313549439636\n",
            "Loss in iteration no. 83078 ==> 0.30733134553043556\n",
            "Loss in iteration no. 83079 ==> 0.3073313361174658\n",
            "Loss in iteration no. 83080 ==> 0.30733132670505475\n",
            "Loss in iteration no. 83081 ==> 0.307331317293202\n",
            "Loss in iteration no. 83082 ==> 0.3073313078819088\n",
            "Loss in iteration no. 83083 ==> 0.30733129847117274\n",
            "Loss in iteration no. 83084 ==> 0.30733128906099577\n",
            "Loss in iteration no. 83085 ==> 0.30733127965137735\n",
            "Loss in iteration no. 83086 ==> 0.30733127024231727\n",
            "Loss in iteration no. 83087 ==> 0.3073312608338155\n",
            "Loss in iteration no. 83088 ==> 0.3073312514258717\n",
            "Loss in iteration no. 83089 ==> 0.30733124201848677\n",
            "Loss in iteration no. 83090 ==> 0.3073312326116596\n",
            "Loss in iteration no. 83091 ==> 0.30733122320539064\n",
            "Loss in iteration no. 83092 ==> 0.3073312137996793\n",
            "Loss in iteration no. 83093 ==> 0.30733120439452677\n",
            "Loss in iteration no. 83094 ==> 0.307331194989933\n",
            "Loss in iteration no. 83095 ==> 0.3073311855858968\n",
            "Loss in iteration no. 83096 ==> 0.30733117618241823\n",
            "Loss in iteration no. 83097 ==> 0.3073311667794978\n",
            "Loss in iteration no. 83098 ==> 0.30733115737713534\n",
            "Loss in iteration no. 83099 ==> 0.30733114797533084\n",
            "Loss in iteration no. 83100 ==> 0.3073311385740839\n",
            "Loss in iteration no. 83101 ==> 0.307331129173395\n",
            "Loss in iteration no. 83102 ==> 0.30733111977326427\n",
            "Loss in iteration no. 83103 ==> 0.3073311103736912\n",
            "Loss in iteration no. 83104 ==> 0.307331100974676\n",
            "Loss in iteration no. 83105 ==> 0.3073310915762183\n",
            "Loss in iteration no. 83106 ==> 0.3073310821783184\n",
            "Loss in iteration no. 83107 ==> 0.3073310727809762\n",
            "Loss in iteration no. 83108 ==> 0.30733106338419136\n",
            "Loss in iteration no. 83109 ==> 0.30733105398796434\n",
            "Loss in iteration no. 83110 ==> 0.3073310445922948\n",
            "Loss in iteration no. 83111 ==> 0.3073310351971823\n",
            "Loss in iteration no. 83112 ==> 0.30733102580262794\n",
            "Loss in iteration no. 83113 ==> 0.3073310164086308\n",
            "Loss in iteration no. 83114 ==> 0.30733100701519045\n",
            "Loss in iteration no. 83115 ==> 0.3073309976223085\n",
            "Loss in iteration no. 83116 ==> 0.3073309882299834\n",
            "Loss in iteration no. 83117 ==> 0.3073309788382153\n",
            "Loss in iteration no. 83118 ==> 0.3073309694470051\n",
            "Loss in iteration no. 83119 ==> 0.30733096005635185\n",
            "Loss in iteration no. 83120 ==> 0.30733095066625576\n",
            "Loss in iteration no. 83121 ==> 0.30733094127671695\n",
            "Loss in iteration no. 83122 ==> 0.30733093188773514\n",
            "Loss in iteration no. 83123 ==> 0.30733092249931027\n",
            "Loss in iteration no. 83124 ==> 0.30733091311144284\n",
            "Loss in iteration no. 83125 ==> 0.30733090372413174\n",
            "Loss in iteration no. 83126 ==> 0.307330894337379\n",
            "Loss in iteration no. 83127 ==> 0.30733088495118144\n",
            "Loss in iteration no. 83128 ==> 0.3073308755655421\n",
            "Loss in iteration no. 83129 ==> 0.3073308661804595\n",
            "Loss in iteration no. 83130 ==> 0.30733085679593325\n",
            "Loss in iteration no. 83131 ==> 0.3073308474119648\n",
            "Loss in iteration no. 83132 ==> 0.3073308380285518\n",
            "Loss in iteration no. 83133 ==> 0.307330828645696\n",
            "Loss in iteration no. 83134 ==> 0.307330819263397\n",
            "Loss in iteration no. 83135 ==> 0.3073308098816552\n",
            "Loss in iteration no. 83136 ==> 0.3073308005004692\n",
            "Loss in iteration no. 83137 ==> 0.30733079111984024\n",
            "Loss in iteration no. 83138 ==> 0.3073307817397681\n",
            "Loss in iteration no. 83139 ==> 0.30733077236025236\n",
            "Loss in iteration no. 83140 ==> 0.30733076298129297\n",
            "Loss in iteration no. 83141 ==> 0.30733075360289036\n",
            "Loss in iteration no. 83142 ==> 0.30733074422504425\n",
            "Loss in iteration no. 83143 ==> 0.3073307348477542\n",
            "Loss in iteration no. 83144 ==> 0.30733072547102025\n",
            "Loss in iteration no. 83145 ==> 0.3073307160948427\n",
            "Loss in iteration no. 83146 ==> 0.30733070671922214\n",
            "Loss in iteration no. 83147 ==> 0.30733069734415736\n",
            "Loss in iteration no. 83148 ==> 0.30733068796964835\n",
            "Loss in iteration no. 83149 ==> 0.30733067859569657\n",
            "Loss in iteration no. 83150 ==> 0.3073306692222999\n",
            "Loss in iteration no. 83151 ==> 0.30733065984946\n",
            "Loss in iteration no. 83152 ==> 0.30733065047717667\n",
            "Loss in iteration no. 83153 ==> 0.3073306411054486\n",
            "Loss in iteration no. 83154 ==> 0.30733063173427705\n",
            "Loss in iteration no. 83155 ==> 0.30733062236366065\n",
            "Loss in iteration no. 83156 ==> 0.307330612993601\n",
            "Loss in iteration no. 83157 ==> 0.30733060362409675\n",
            "Loss in iteration no. 83158 ==> 0.30733059425514864\n",
            "Loss in iteration no. 83159 ==> 0.3073305848867569\n",
            "Loss in iteration no. 83160 ==> 0.3073305755189204\n",
            "Loss in iteration no. 83161 ==> 0.3073305661516394\n",
            "Loss in iteration no. 83162 ==> 0.30733055678491505\n",
            "Loss in iteration no. 83163 ==> 0.3073305474187461\n",
            "Loss in iteration no. 83164 ==> 0.3073305380531327\n",
            "Loss in iteration no. 83165 ==> 0.3073305286880746\n",
            "Loss in iteration no. 83166 ==> 0.30733051932357275\n",
            "Loss in iteration no. 83167 ==> 0.30733050995962596\n",
            "Loss in iteration no. 83168 ==> 0.3073305005962354\n",
            "Loss in iteration no. 83169 ==> 0.3073304912333996\n",
            "Loss in iteration no. 83170 ==> 0.30733048187111867\n",
            "Loss in iteration no. 83171 ==> 0.3073304725093949\n",
            "Loss in iteration no. 83172 ==> 0.3073304631482253\n",
            "Loss in iteration no. 83173 ==> 0.307330453787612\n",
            "Loss in iteration no. 83174 ==> 0.30733044442755264\n",
            "Loss in iteration no. 83175 ==> 0.3073304350680502\n",
            "Loss in iteration no. 83176 ==> 0.30733042570910163\n",
            "Loss in iteration no. 83177 ==> 0.307330416350709\n",
            "Loss in iteration no. 83178 ==> 0.3073304069928717\n",
            "Loss in iteration no. 83179 ==> 0.3073303976355892\n",
            "Loss in iteration no. 83180 ==> 0.30733038827886205\n",
            "Loss in iteration no. 83181 ==> 0.3073303789226905\n",
            "Loss in iteration no. 83182 ==> 0.30733036956707316\n",
            "Loss in iteration no. 83183 ==> 0.3073303602120112\n",
            "Loss in iteration no. 83184 ==> 0.3073303508575042\n",
            "Loss in iteration no. 83185 ==> 0.30733034150355243\n",
            "Loss in iteration no. 83186 ==> 0.3073303321501546\n",
            "Loss in iteration no. 83187 ==> 0.30733032279731265\n",
            "Loss in iteration no. 83188 ==> 0.3073303134450253\n",
            "Loss in iteration no. 83189 ==> 0.30733030409329287\n",
            "Loss in iteration no. 83190 ==> 0.30733029474211493\n",
            "Loss in iteration no. 83191 ==> 0.30733028539149176\n",
            "Loss in iteration no. 83192 ==> 0.3073302760414237\n",
            "Loss in iteration no. 83193 ==> 0.30733026669191027\n",
            "Loss in iteration no. 83194 ==> 0.3073302573429509\n",
            "Loss in iteration no. 83195 ==> 0.3073302479945464\n",
            "Loss in iteration no. 83196 ==> 0.3073302386466967\n",
            "Loss in iteration no. 83197 ==> 0.3073302292994013\n",
            "Loss in iteration no. 83198 ==> 0.3073302199526614\n",
            "Loss in iteration no. 83199 ==> 0.3073302106064748\n",
            "Loss in iteration no. 83200 ==> 0.3073302012608427\n",
            "Loss in iteration no. 83201 ==> 0.3073301919157653\n",
            "Loss in iteration no. 83202 ==> 0.30733018257124306\n",
            "Loss in iteration no. 83203 ==> 0.30733017322727396\n",
            "Loss in iteration no. 83204 ==> 0.30733016388385964\n",
            "Loss in iteration no. 83205 ==> 0.30733015454100004\n",
            "Loss in iteration no. 83206 ==> 0.3073301451986943\n",
            "Loss in iteration no. 83207 ==> 0.30733013585694213\n",
            "Loss in iteration no. 83208 ==> 0.307330126515745\n",
            "Loss in iteration no. 83209 ==> 0.30733011717510206\n",
            "Loss in iteration no. 83210 ==> 0.307330107835012\n",
            "Loss in iteration no. 83211 ==> 0.3073300984954772\n",
            "Loss in iteration no. 83212 ==> 0.3073300891564959\n",
            "Loss in iteration no. 83213 ==> 0.3073300798180693\n",
            "Loss in iteration no. 83214 ==> 0.30733007048019606\n",
            "Loss in iteration no. 83215 ==> 0.30733006114287653\n",
            "Loss in iteration no. 83216 ==> 0.30733005180611145\n",
            "Loss in iteration no. 83217 ==> 0.3073300424698995\n",
            "Loss in iteration no. 83218 ==> 0.3073300331342423\n",
            "Loss in iteration no. 83219 ==> 0.3073300237991384\n",
            "Loss in iteration no. 83220 ==> 0.30733001446458863\n",
            "Loss in iteration no. 83221 ==> 0.3073300051305917\n",
            "Loss in iteration no. 83222 ==> 0.3073299957971492\n",
            "Loss in iteration no. 83223 ==> 0.30732998646426063\n",
            "Loss in iteration no. 83224 ==> 0.30732997713192495\n",
            "Loss in iteration no. 83225 ==> 0.30732996780014343\n",
            "Loss in iteration no. 83226 ==> 0.30732995846891514\n",
            "Loss in iteration no. 83227 ==> 0.3073299491382405\n",
            "Loss in iteration no. 83228 ==> 0.3073299398081194\n",
            "Loss in iteration no. 83229 ==> 0.3073299304785513\n",
            "Loss in iteration no. 83230 ==> 0.3073299211495365\n",
            "Loss in iteration no. 83231 ==> 0.30732991182107616\n",
            "Loss in iteration no. 83232 ==> 0.30732990249316866\n",
            "Loss in iteration no. 83233 ==> 0.30732989316581427\n",
            "Loss in iteration no. 83234 ==> 0.3073298838390129\n",
            "Loss in iteration no. 83235 ==> 0.30732987451276567\n",
            "Loss in iteration no. 83236 ==> 0.3073298651870705\n",
            "Loss in iteration no. 83237 ==> 0.30732985586192946\n",
            "Loss in iteration no. 83238 ==> 0.307329846537341\n",
            "Loss in iteration no. 83239 ==> 0.3073298372133057\n",
            "Loss in iteration no. 83240 ==> 0.3073298278898237\n",
            "Loss in iteration no. 83241 ==> 0.3073298185668947\n",
            "Loss in iteration no. 83242 ==> 0.30732980924451875\n",
            "Loss in iteration no. 83243 ==> 0.3073297999226956\n",
            "Loss in iteration no. 83244 ==> 0.30732979060142557\n",
            "Loss in iteration no. 83245 ==> 0.3073297812807077\n",
            "Loss in iteration no. 83246 ==> 0.30732977196054423\n",
            "Loss in iteration no. 83247 ==> 0.30732976264093254\n",
            "Loss in iteration no. 83248 ==> 0.30732975332187323\n",
            "Loss in iteration no. 83249 ==> 0.3073297440033677\n",
            "Loss in iteration no. 83250 ==> 0.30732973468541475\n",
            "Loss in iteration no. 83251 ==> 0.3073297253680136\n",
            "Loss in iteration no. 83252 ==> 0.307329716051166\n",
            "Loss in iteration no. 83253 ==> 0.30732970673487126\n",
            "Loss in iteration no. 83254 ==> 0.30732969741912797\n",
            "Loss in iteration no. 83255 ==> 0.3073296881039377\n",
            "Loss in iteration no. 83256 ==> 0.30732967878930073\n",
            "Loss in iteration no. 83257 ==> 0.30732966947521506\n",
            "Loss in iteration no. 83258 ==> 0.3073296601616825\n",
            "Loss in iteration no. 83259 ==> 0.30732965084870306\n",
            "Loss in iteration no. 83260 ==> 0.3073296415362743\n",
            "Loss in iteration no. 83261 ==> 0.3073296322243997\n",
            "Loss in iteration no. 83262 ==> 0.30732962291307675\n",
            "Loss in iteration no. 83263 ==> 0.3073296136023054\n",
            "Loss in iteration no. 83264 ==> 0.30732960429208706\n",
            "Loss in iteration no. 83265 ==> 0.3073295949824211\n",
            "Loss in iteration no. 83266 ==> 0.30732958567330604\n",
            "Loss in iteration no. 83267 ==> 0.30732957636474423\n",
            "Loss in iteration no. 83268 ==> 0.3073295670567348\n",
            "Loss in iteration no. 83269 ==> 0.3073295577492765\n",
            "Loss in iteration no. 83270 ==> 0.30732954844237137\n",
            "Loss in iteration no. 83271 ==> 0.3073295391360171\n",
            "Loss in iteration no. 83272 ==> 0.3073295298302154\n",
            "Loss in iteration no. 83273 ==> 0.3073295205249657\n",
            "Loss in iteration no. 83274 ==> 0.30732951122026797\n",
            "Loss in iteration no. 83275 ==> 0.3073295019161216\n",
            "Loss in iteration no. 83276 ==> 0.3073294926125275\n",
            "Loss in iteration no. 83277 ==> 0.3073294833094851\n",
            "Loss in iteration no. 83278 ==> 0.30732947400699384\n",
            "Loss in iteration no. 83279 ==> 0.30732946470505507\n",
            "Loss in iteration no. 83280 ==> 0.3073294554036682\n",
            "Loss in iteration no. 83281 ==> 0.3073294461028326\n",
            "Loss in iteration no. 83282 ==> 0.30732943680254887\n",
            "Loss in iteration no. 83283 ==> 0.30732942750281705\n",
            "Loss in iteration no. 83284 ==> 0.307329418203636\n",
            "Loss in iteration no. 83285 ==> 0.30732940890500693\n",
            "Loss in iteration no. 83286 ==> 0.30732939960692923\n",
            "Loss in iteration no. 83287 ==> 0.3073293903094028\n",
            "Loss in iteration no. 83288 ==> 0.3073293810124282\n",
            "Loss in iteration no. 83289 ==> 0.307329371716005\n",
            "Loss in iteration no. 83290 ==> 0.307329362420133\n",
            "Loss in iteration no. 83291 ==> 0.307329353124812\n",
            "Loss in iteration no. 83292 ==> 0.3073293438300424\n",
            "Loss in iteration no. 83293 ==> 0.30732933453582445\n",
            "Loss in iteration no. 83294 ==> 0.3073293252421577\n",
            "Loss in iteration no. 83295 ==> 0.3073293159490416\n",
            "Loss in iteration no. 83296 ==> 0.3073293066564774\n",
            "Loss in iteration no. 83297 ==> 0.3073292973644638\n",
            "Loss in iteration no. 83298 ==> 0.3073292880730018\n",
            "Loss in iteration no. 83299 ==> 0.30732927878209026\n",
            "Loss in iteration no. 83300 ==> 0.3073292694917303\n",
            "Loss in iteration no. 83301 ==> 0.30732926020192136\n",
            "Loss in iteration no. 83302 ==> 0.30732925091266255\n",
            "Loss in iteration no. 83303 ==> 0.3073292416239551\n",
            "Loss in iteration no. 83304 ==> 0.30732923233579884\n",
            "Loss in iteration no. 83305 ==> 0.3073292230481934\n",
            "Loss in iteration no. 83306 ==> 0.3073292137611386\n",
            "Loss in iteration no. 83307 ==> 0.30732920447463474\n",
            "Loss in iteration no. 83308 ==> 0.3073291951886814\n",
            "Loss in iteration no. 83309 ==> 0.30732918590327896\n",
            "Loss in iteration no. 83310 ==> 0.30732917661842685\n",
            "Loss in iteration no. 83311 ==> 0.3073291673341254\n",
            "Loss in iteration no. 83312 ==> 0.30732915805037503\n",
            "Loss in iteration no. 83313 ==> 0.30732914876717515\n",
            "Loss in iteration no. 83314 ==> 0.3073291394845261\n",
            "Loss in iteration no. 83315 ==> 0.30732913020242625\n",
            "Loss in iteration no. 83316 ==> 0.3073291209208782\n",
            "Loss in iteration no. 83317 ==> 0.3073291116398801\n",
            "Loss in iteration no. 83318 ==> 0.3073291023594321\n",
            "Loss in iteration no. 83319 ==> 0.30732909307953504\n",
            "Loss in iteration no. 83320 ==> 0.30732908380018825\n",
            "Loss in iteration no. 83321 ==> 0.3073290745213919\n",
            "Loss in iteration no. 83322 ==> 0.3073290652431453\n",
            "Loss in iteration no. 83323 ==> 0.30732905596544885\n",
            "Loss in iteration no. 83324 ==> 0.30732904668830335\n",
            "Loss in iteration no. 83325 ==> 0.30732903741170753\n",
            "Loss in iteration no. 83326 ==> 0.3073290281356618\n",
            "Loss in iteration no. 83327 ==> 0.30732901886016684\n",
            "Loss in iteration no. 83328 ==> 0.3073290095852209\n",
            "Loss in iteration no. 83329 ==> 0.30732900031082583\n",
            "Loss in iteration no. 83330 ==> 0.3073289910369808\n",
            "Loss in iteration no. 83331 ==> 0.30732898176368495\n",
            "Loss in iteration no. 83332 ==> 0.3073289724909392\n",
            "Loss in iteration no. 83333 ==> 0.3073289632187434\n",
            "Loss in iteration no. 83334 ==> 0.3073289539470984\n",
            "Loss in iteration no. 83335 ==> 0.30732894467600236\n",
            "Loss in iteration no. 83336 ==> 0.3073289354054558\n",
            "Loss in iteration no. 83337 ==> 0.30732892613546037\n",
            "Loss in iteration no. 83338 ==> 0.3073289168660131\n",
            "Loss in iteration no. 83339 ==> 0.30732890759711634\n",
            "Loss in iteration no. 83340 ==> 0.30732889832876886\n",
            "Loss in iteration no. 83341 ==> 0.30732888906097217\n",
            "Loss in iteration no. 83342 ==> 0.30732887979372375\n",
            "Loss in iteration no. 83343 ==> 0.30732887052702557\n",
            "Loss in iteration no. 83344 ==> 0.3073288612608763\n",
            "Loss in iteration no. 83345 ==> 0.30732885199527676\n",
            "Loss in iteration no. 83346 ==> 0.30732884273022676\n",
            "Loss in iteration no. 83347 ==> 0.3073288334657258\n",
            "Loss in iteration no. 83348 ==> 0.30732882420177526\n",
            "Loss in iteration no. 83349 ==> 0.3073288149383731\n",
            "Loss in iteration no. 83350 ==> 0.30732880567552073\n",
            "Loss in iteration no. 83351 ==> 0.3073287964132179\n",
            "Loss in iteration no. 83352 ==> 0.30732878715146383\n",
            "Loss in iteration no. 83353 ==> 0.30732877789025886\n",
            "Loss in iteration no. 83354 ==> 0.3073287686296031\n",
            "Loss in iteration no. 83355 ==> 0.3073287593694973\n",
            "Loss in iteration no. 83356 ==> 0.30732875010993965\n",
            "Loss in iteration no. 83357 ==> 0.30732874085093126\n",
            "Loss in iteration no. 83358 ==> 0.3073287315924723\n",
            "Loss in iteration no. 83359 ==> 0.3073287223345616\n",
            "Loss in iteration no. 83360 ==> 0.30732871307720105\n",
            "Loss in iteration no. 83361 ==> 0.30732870382038885\n",
            "Loss in iteration no. 83362 ==> 0.3073286945641258\n",
            "Loss in iteration no. 83363 ==> 0.3073286853084115\n",
            "Loss in iteration no. 83364 ==> 0.3073286760532454\n",
            "Loss in iteration no. 83365 ==> 0.3073286667986289\n",
            "Loss in iteration no. 83366 ==> 0.3073286575445613\n",
            "Loss in iteration no. 83367 ==> 0.30732864829104134\n",
            "Loss in iteration no. 83368 ==> 0.3073286390380713\n",
            "Loss in iteration no. 83369 ==> 0.307328629785649\n",
            "Loss in iteration no. 83370 ==> 0.30732862053377563\n",
            "Loss in iteration no. 83371 ==> 0.3073286112824516\n",
            "Loss in iteration no. 83372 ==> 0.30732860203167545\n",
            "Loss in iteration no. 83373 ==> 0.30732859278144775\n",
            "Loss in iteration no. 83374 ==> 0.3073285835317686\n",
            "Loss in iteration no. 83375 ==> 0.30732857428263805\n",
            "Loss in iteration no. 83376 ==> 0.30732856503405626\n",
            "Loss in iteration no. 83377 ==> 0.3073285557860227\n",
            "Loss in iteration no. 83378 ==> 0.30732854653853686\n",
            "Loss in iteration no. 83379 ==> 0.3073285372916002\n",
            "Loss in iteration no. 83380 ==> 0.3073285280452113\n",
            "Loss in iteration no. 83381 ==> 0.3073285187993709\n",
            "Loss in iteration no. 83382 ==> 0.3073285095540788\n",
            "Loss in iteration no. 83383 ==> 0.3073285003093356\n",
            "Loss in iteration no. 83384 ==> 0.3073284910651395\n",
            "Loss in iteration no. 83385 ==> 0.3073284818214915\n",
            "Loss in iteration no. 83386 ==> 0.3073284725783924\n",
            "Loss in iteration no. 83387 ==> 0.3073284633358406\n",
            "Loss in iteration no. 83388 ==> 0.3073284540938379\n",
            "Loss in iteration no. 83389 ==> 0.3073284448523814\n",
            "Loss in iteration no. 83390 ==> 0.30732843561147444\n",
            "Loss in iteration no. 83391 ==> 0.30732842637111524\n",
            "Loss in iteration no. 83392 ==> 0.3073284171313032\n",
            "Loss in iteration no. 83393 ==> 0.3073284078920392\n",
            "Loss in iteration no. 83394 ==> 0.30732839865332345\n",
            "Loss in iteration no. 83395 ==> 0.3073283894151547\n",
            "Loss in iteration no. 83396 ==> 0.30732838017753505\n",
            "Loss in iteration no. 83397 ==> 0.30732837094046206\n",
            "Loss in iteration no. 83398 ==> 0.30732836170393685\n",
            "Loss in iteration no. 83399 ==> 0.3073283524679595\n",
            "Loss in iteration no. 83400 ==> 0.3073283432325299\n",
            "Loss in iteration no. 83401 ==> 0.30732833399764775\n",
            "Loss in iteration no. 83402 ==> 0.30732832476331284\n",
            "Loss in iteration no. 83403 ==> 0.3073283155295264\n",
            "Loss in iteration no. 83404 ==> 0.30732830629628627\n",
            "Loss in iteration no. 83405 ==> 0.307328297063594\n",
            "Loss in iteration no. 83406 ==> 0.30732828783144905\n",
            "Loss in iteration no. 83407 ==> 0.30732827859985234\n",
            "Loss in iteration no. 83408 ==> 0.3073282693688019\n",
            "Loss in iteration no. 83409 ==> 0.3073282601382999\n",
            "Loss in iteration no. 83410 ==> 0.30732825090834415\n",
            "Loss in iteration no. 83411 ==> 0.30732824167893663\n",
            "Loss in iteration no. 83412 ==> 0.3073282324500752\n",
            "Loss in iteration no. 83413 ==> 0.3073282232217614\n",
            "Loss in iteration no. 83414 ==> 0.3073282139939952\n",
            "Loss in iteration no. 83415 ==> 0.30732820476677564\n",
            "Loss in iteration no. 83416 ==> 0.30732819554010316\n",
            "Loss in iteration no. 83417 ==> 0.307328186313978\n",
            "Loss in iteration no. 83418 ==> 0.3073281770883997\n",
            "Loss in iteration no. 83419 ==> 0.3073281678633685\n",
            "Loss in iteration no. 83420 ==> 0.3073281586388837\n",
            "Loss in iteration no. 83421 ==> 0.30732814941494674\n",
            "Loss in iteration no. 83422 ==> 0.3073281401915559\n",
            "Loss in iteration no. 83423 ==> 0.30732813096871225\n",
            "Loss in iteration no. 83424 ==> 0.30732812174641483\n",
            "Loss in iteration no. 83425 ==> 0.3073281125246652\n",
            "Loss in iteration no. 83426 ==> 0.3073281033034614\n",
            "Loss in iteration no. 83427 ==> 0.307328094082805\n",
            "Loss in iteration no. 83428 ==> 0.30732808486269464\n",
            "Loss in iteration no. 83429 ==> 0.3073280756431315\n",
            "Loss in iteration no. 83430 ==> 0.30732806642411437\n",
            "Loss in iteration no. 83431 ==> 0.30732805720564427\n",
            "Loss in iteration no. 83432 ==> 0.3073280479877208\n",
            "Loss in iteration no. 83433 ==> 0.30732803877034415\n",
            "Loss in iteration no. 83434 ==> 0.30732802955351324\n",
            "Loss in iteration no. 83435 ==> 0.30732802033722856\n",
            "Loss in iteration no. 83436 ==> 0.30732801112149155\n",
            "Loss in iteration no. 83437 ==> 0.3073280019062998\n",
            "Loss in iteration no. 83438 ==> 0.3073279926916547\n",
            "Loss in iteration no. 83439 ==> 0.30732798347755635\n",
            "Loss in iteration no. 83440 ==> 0.30732797426400316\n",
            "Loss in iteration no. 83441 ==> 0.307327965050997\n",
            "Loss in iteration no. 83442 ==> 0.3073279558385369\n",
            "Loss in iteration no. 83443 ==> 0.30732794662662277\n",
            "Loss in iteration no. 83444 ==> 0.3073279374152552\n",
            "Loss in iteration no. 83445 ==> 0.30732792820443355\n",
            "Loss in iteration no. 83446 ==> 0.3073279189941583\n",
            "Loss in iteration no. 83447 ==> 0.3073279097844285\n",
            "Loss in iteration no. 83448 ==> 0.30732790057524434\n",
            "Loss in iteration no. 83449 ==> 0.3073278913666072\n",
            "Loss in iteration no. 83450 ==> 0.30732788215851553\n",
            "Loss in iteration no. 83451 ==> 0.30732787295096986\n",
            "Loss in iteration no. 83452 ==> 0.3073278637439692\n",
            "Loss in iteration no. 83453 ==> 0.30732785453751565\n",
            "Loss in iteration no. 83454 ==> 0.30732784533160734\n",
            "Loss in iteration no. 83455 ==> 0.30732783612624426\n",
            "Loss in iteration no. 83456 ==> 0.3073278269214279\n",
            "Loss in iteration no. 83457 ==> 0.3073278177171566\n",
            "Loss in iteration no. 83458 ==> 0.30732780851343167\n",
            "Loss in iteration no. 83459 ==> 0.30732779931025117\n",
            "Loss in iteration no. 83460 ==> 0.30732779010761696\n",
            "Loss in iteration no. 83461 ==> 0.3073277809055289\n",
            "Loss in iteration no. 83462 ==> 0.3073277717039855\n",
            "Loss in iteration no. 83463 ==> 0.3073277625029879\n",
            "Loss in iteration no. 83464 ==> 0.30732775330253564\n",
            "Loss in iteration no. 83465 ==> 0.30732774410262864\n",
            "Loss in iteration no. 83466 ==> 0.3073277349032681\n",
            "Loss in iteration no. 83467 ==> 0.3073277257044518\n",
            "Loss in iteration no. 83468 ==> 0.3073277165061809\n",
            "Loss in iteration no. 83469 ==> 0.3073277073084558\n",
            "Loss in iteration no. 83470 ==> 0.30732769811127564\n",
            "Loss in iteration no. 83471 ==> 0.3073276889146406\n",
            "Loss in iteration no. 83472 ==> 0.30732767971855113\n",
            "Loss in iteration no. 83473 ==> 0.30732767052300597\n",
            "Loss in iteration no. 83474 ==> 0.3073276613280069\n",
            "Loss in iteration no. 83475 ==> 0.3073276521335526\n",
            "Loss in iteration no. 83476 ==> 0.30732764293964343\n",
            "Loss in iteration no. 83477 ==> 0.30732763374627925\n",
            "Loss in iteration no. 83478 ==> 0.30732762455345974\n",
            "Loss in iteration no. 83479 ==> 0.3073276153611852\n",
            "Loss in iteration no. 83480 ==> 0.3073276061694561\n",
            "Loss in iteration no. 83481 ==> 0.3073275969782714\n",
            "Loss in iteration no. 83482 ==> 0.30732758778763214\n",
            "Loss in iteration no. 83483 ==> 0.3073275785975365\n",
            "Loss in iteration no. 83484 ==> 0.307327569407987\n",
            "Loss in iteration no. 83485 ==> 0.30732756021898167\n",
            "Loss in iteration no. 83486 ==> 0.3073275510305217\n",
            "Loss in iteration no. 83487 ==> 0.3073275418426056\n",
            "Loss in iteration no. 83488 ==> 0.30732753265523416\n",
            "Loss in iteration no. 83489 ==> 0.30732752346840747\n",
            "Loss in iteration no. 83490 ==> 0.3073275142821253\n",
            "Loss in iteration no. 83491 ==> 0.30732750509638795\n",
            "Loss in iteration no. 83492 ==> 0.3073274959111947\n",
            "Loss in iteration no. 83493 ==> 0.3073274867265465\n",
            "Loss in iteration no. 83494 ==> 0.3073274775424422\n",
            "Loss in iteration no. 83495 ==> 0.3073274683588829\n",
            "Loss in iteration no. 83496 ==> 0.30732745917586723\n",
            "Loss in iteration no. 83497 ==> 0.3073274499933964\n",
            "Loss in iteration no. 83498 ==> 0.3073274408114695\n",
            "Loss in iteration no. 83499 ==> 0.30732743163008774\n",
            "Loss in iteration no. 83500 ==> 0.3073274224492498\n",
            "Loss in iteration no. 83501 ==> 0.3073274132689554\n",
            "Loss in iteration no. 83502 ==> 0.30732740408920606\n",
            "Loss in iteration no. 83503 ==> 0.30732739491000055\n",
            "Loss in iteration no. 83504 ==> 0.30732738573133883\n",
            "Loss in iteration no. 83505 ==> 0.3073273765532212\n",
            "Loss in iteration no. 83506 ==> 0.3073273673756486\n",
            "Loss in iteration no. 83507 ==> 0.3073273581986195\n",
            "Loss in iteration no. 83508 ==> 0.3073273490221335\n",
            "Loss in iteration no. 83509 ==> 0.30732733984619265\n",
            "Loss in iteration no. 83510 ==> 0.3073273306707947\n",
            "Loss in iteration no. 83511 ==> 0.3073273214959419\n",
            "Loss in iteration no. 83512 ==> 0.30732731232163185\n",
            "Loss in iteration no. 83513 ==> 0.3073273031478662\n",
            "Loss in iteration no. 83514 ==> 0.30732729397464376\n",
            "Loss in iteration no. 83515 ==> 0.3073272848019655\n",
            "Loss in iteration no. 83516 ==> 0.30732727562983053\n",
            "Loss in iteration no. 83517 ==> 0.30732726645823943\n",
            "Loss in iteration no. 83518 ==> 0.30732725728719273\n",
            "Loss in iteration no. 83519 ==> 0.30732724811668866\n",
            "Loss in iteration no. 83520 ==> 0.3073272389467282\n",
            "Loss in iteration no. 83521 ==> 0.3073272297773118\n",
            "Loss in iteration no. 83522 ==> 0.3073272206084384\n",
            "Loss in iteration no. 83523 ==> 0.3073272114401087\n",
            "Loss in iteration no. 83524 ==> 0.3073272022723229\n",
            "Loss in iteration no. 83525 ==> 0.3073271931050798\n",
            "Loss in iteration no. 83526 ==> 0.3073271839383801\n",
            "Loss in iteration no. 83527 ==> 0.3073271747722241\n",
            "Loss in iteration no. 83528 ==> 0.30732716560661183\n",
            "Loss in iteration no. 83529 ==> 0.30732715644154157\n",
            "Loss in iteration no. 83530 ==> 0.3073271472770155\n",
            "Loss in iteration no. 83531 ==> 0.30732713811303297\n",
            "Loss in iteration no. 83532 ==> 0.3073271289495925\n",
            "Loss in iteration no. 83533 ==> 0.30732711978669575\n",
            "Loss in iteration no. 83534 ==> 0.3073271106243418\n",
            "Loss in iteration no. 83535 ==> 0.307327101462531\n",
            "Loss in iteration no. 83536 ==> 0.30732709230126415\n",
            "Loss in iteration no. 83537 ==> 0.3073270831405397\n",
            "Loss in iteration no. 83538 ==> 0.3073270739803578\n",
            "Loss in iteration no. 83539 ==> 0.3073270648207192\n",
            "Loss in iteration no. 83540 ==> 0.3073270556616233\n",
            "Loss in iteration no. 83541 ==> 0.3073270465030709\n",
            "Loss in iteration no. 83542 ==> 0.3073270373450603\n",
            "Loss in iteration no. 83543 ==> 0.30732702818759344\n",
            "Loss in iteration no. 83544 ==> 0.3073270190306689\n",
            "Loss in iteration no. 83545 ==> 0.3073270098742868\n",
            "Loss in iteration no. 83546 ==> 0.3073270007184474\n",
            "Loss in iteration no. 83547 ==> 0.3073269915631511\n",
            "Loss in iteration no. 83548 ==> 0.3073269824083972\n",
            "Loss in iteration no. 83549 ==> 0.30732697325418706\n",
            "Loss in iteration no. 83550 ==> 0.307326964100518\n",
            "Loss in iteration no. 83551 ==> 0.3073269549473921\n",
            "Loss in iteration no. 83552 ==> 0.30732694579480807\n",
            "Loss in iteration no. 83553 ==> 0.30732693664276745\n",
            "Loss in iteration no. 83554 ==> 0.3073269274912685\n",
            "Loss in iteration no. 83555 ==> 0.30732691834031184\n",
            "Loss in iteration no. 83556 ==> 0.30732690918989886\n",
            "Loss in iteration no. 83557 ==> 0.30732690004002644\n",
            "Loss in iteration no. 83558 ==> 0.3073268908906978\n",
            "Loss in iteration no. 83559 ==> 0.30732688174191014\n",
            "Loss in iteration no. 83560 ==> 0.3073268725936661\n",
            "Loss in iteration no. 83561 ==> 0.30732686344596355\n",
            "Loss in iteration no. 83562 ==> 0.3073268542988028\n",
            "Loss in iteration no. 83563 ==> 0.3073268451521844\n",
            "Loss in iteration no. 83564 ==> 0.30732683600610883\n",
            "Loss in iteration no. 83565 ==> 0.3073268268605738\n",
            "Loss in iteration no. 83566 ==> 0.3073268177155819\n",
            "Loss in iteration no. 83567 ==> 0.30732680857113226\n",
            "Loss in iteration no. 83568 ==> 0.30732679942722446\n",
            "Loss in iteration no. 83569 ==> 0.3073267902838577\n",
            "Loss in iteration no. 83570 ==> 0.3073267811410332\n",
            "Loss in iteration no. 83571 ==> 0.3073267719987508\n",
            "Loss in iteration no. 83572 ==> 0.30732676285701005\n",
            "Loss in iteration no. 83573 ==> 0.30732675371581186\n",
            "Loss in iteration no. 83574 ==> 0.30732674457515485\n",
            "Loss in iteration no. 83575 ==> 0.30732673543503974\n",
            "Loss in iteration no. 83576 ==> 0.3073267262954654\n",
            "Loss in iteration no. 83577 ==> 0.30732671715643384\n",
            "Loss in iteration no. 83578 ==> 0.3073267080179437\n",
            "Loss in iteration no. 83579 ==> 0.3073266988799949\n",
            "Loss in iteration no. 83580 ==> 0.3073266897425871\n",
            "Loss in iteration no. 83581 ==> 0.3073266806057221\n",
            "Loss in iteration no. 83582 ==> 0.30732667146939785\n",
            "Loss in iteration no. 83583 ==> 0.3073266623336155\n",
            "Loss in iteration no. 83584 ==> 0.30732665319837327\n",
            "Loss in iteration no. 83585 ==> 0.307326644063674\n",
            "Loss in iteration no. 83586 ==> 0.30732663492951484\n",
            "Loss in iteration no. 83587 ==> 0.3073266257958981\n",
            "Loss in iteration no. 83588 ==> 0.3073266166628224\n",
            "Loss in iteration no. 83589 ==> 0.3073266075302873\n",
            "Loss in iteration no. 83590 ==> 0.30732659839829396\n",
            "Loss in iteration no. 83591 ==> 0.307326589266842\n",
            "Loss in iteration no. 83592 ==> 0.3073265801359315\n",
            "Loss in iteration no. 83593 ==> 0.307326571005561\n",
            "Loss in iteration no. 83594 ==> 0.307326561875732\n",
            "Loss in iteration no. 83595 ==> 0.3073265527464446\n",
            "Loss in iteration no. 83596 ==> 0.30732654361769746\n",
            "Loss in iteration no. 83597 ==> 0.3073265344894918\n",
            "Loss in iteration no. 83598 ==> 0.30732652536182703\n",
            "Loss in iteration no. 83599 ==> 0.3073265162347037\n",
            "Loss in iteration no. 83600 ==> 0.30732650710812054\n",
            "Loss in iteration no. 83601 ==> 0.3073264979820783\n",
            "Loss in iteration no. 83602 ==> 0.30732648885657693\n",
            "Loss in iteration no. 83603 ==> 0.30732647973161586\n",
            "Loss in iteration no. 83604 ==> 0.30732647060719676\n",
            "Loss in iteration no. 83605 ==> 0.30732646148331777\n",
            "Loss in iteration no. 83606 ==> 0.30732645235997896\n",
            "Loss in iteration no. 83607 ==> 0.30732644323718195\n",
            "Loss in iteration no. 83608 ==> 0.30732643411492394\n",
            "Loss in iteration no. 83609 ==> 0.30732642499320795\n",
            "Loss in iteration no. 83610 ==> 0.3073264158720318\n",
            "Loss in iteration no. 83611 ==> 0.307326406751397\n",
            "Loss in iteration no. 83612 ==> 0.3073263976313014\n",
            "Loss in iteration no. 83613 ==> 0.3073263885117471\n",
            "Loss in iteration no. 83614 ==> 0.3073263793927335\n",
            "Loss in iteration no. 83615 ==> 0.30732637027425985\n",
            "Loss in iteration no. 83616 ==> 0.3073263611563262\n",
            "Loss in iteration no. 83617 ==> 0.30732635203893394\n",
            "Loss in iteration no. 83618 ==> 0.3073263429220806\n",
            "Loss in iteration no. 83619 ==> 0.30732633380576874\n",
            "Loss in iteration no. 83620 ==> 0.3073263246899963\n",
            "Loss in iteration no. 83621 ==> 0.30732631557476464\n",
            "Loss in iteration no. 83622 ==> 0.307326306460073\n",
            "Loss in iteration no. 83623 ==> 0.30732629734592054\n",
            "Loss in iteration no. 83624 ==> 0.3073262882323093\n",
            "Loss in iteration no. 83625 ==> 0.307326279119238\n",
            "Loss in iteration no. 83626 ==> 0.3073262700067065\n",
            "Loss in iteration no. 83627 ==> 0.3073262608947144\n",
            "Loss in iteration no. 83628 ==> 0.3073262517832626\n",
            "Loss in iteration no. 83629 ==> 0.3073262426723514\n",
            "Loss in iteration no. 83630 ==> 0.30732623356197936\n",
            "Loss in iteration no. 83631 ==> 0.3073262244521474\n",
            "Loss in iteration no. 83632 ==> 0.3073262153428553\n",
            "Loss in iteration no. 83633 ==> 0.3073262062341033\n",
            "Loss in iteration no. 83634 ==> 0.3073261971258905\n",
            "Loss in iteration no. 83635 ==> 0.3073261880182181\n",
            "Loss in iteration no. 83636 ==> 0.30732617891108466\n",
            "Loss in iteration no. 83637 ==> 0.307326169804491\n",
            "Loss in iteration no. 83638 ==> 0.30732616069843766\n",
            "Loss in iteration no. 83639 ==> 0.30732615159292376\n",
            "Loss in iteration no. 83640 ==> 0.30732614248794865\n",
            "Loss in iteration no. 83641 ==> 0.30732613338351344\n",
            "Loss in iteration no. 83642 ==> 0.30732612427961775\n",
            "Loss in iteration no. 83643 ==> 0.30732611517626174\n",
            "Loss in iteration no. 83644 ==> 0.307326106073445\n",
            "Loss in iteration no. 83645 ==> 0.3073260969711675\n",
            "Loss in iteration no. 83646 ==> 0.30732608786942944\n",
            "Loss in iteration no. 83647 ==> 0.30732607876823004\n",
            "Loss in iteration no. 83648 ==> 0.3073260696675711\n",
            "Loss in iteration no. 83649 ==> 0.3073260605674508\n",
            "Loss in iteration no. 83650 ==> 0.3073260514678696\n",
            "Loss in iteration no. 83651 ==> 0.30732604236882843\n",
            "Loss in iteration no. 83652 ==> 0.30732603327032587\n",
            "Loss in iteration no. 83653 ==> 0.30732602417236193\n",
            "Loss in iteration no. 83654 ==> 0.3073260150749373\n",
            "Loss in iteration no. 83655 ==> 0.3073260059780523\n",
            "Loss in iteration no. 83656 ==> 0.3073259968817056\n",
            "Loss in iteration no. 83657 ==> 0.3073259877858984\n",
            "Loss in iteration no. 83658 ==> 0.30732597869062983\n",
            "Loss in iteration no. 83659 ==> 0.3073259695959011\n",
            "Loss in iteration no. 83660 ==> 0.30732596050170985\n",
            "Loss in iteration no. 83661 ==> 0.3073259514080578\n",
            "Loss in iteration no. 83662 ==> 0.3073259423149455\n",
            "Loss in iteration no. 83663 ==> 0.3073259332223712\n",
            "Loss in iteration no. 83664 ==> 0.3073259241303362\n",
            "Loss in iteration no. 83665 ==> 0.30732591503883894\n",
            "Loss in iteration no. 83666 ==> 0.3073259059478814\n",
            "Loss in iteration no. 83667 ==> 0.30732589685746203\n",
            "Loss in iteration no. 83668 ==> 0.307325887767581\n",
            "Loss in iteration no. 83669 ==> 0.30732587867823935\n",
            "Loss in iteration no. 83670 ==> 0.3073258695894358\n",
            "Loss in iteration no. 83671 ==> 0.30732586050117067\n",
            "Loss in iteration no. 83672 ==> 0.3073258514134439\n",
            "Loss in iteration no. 83673 ==> 0.3073258423262566\n",
            "Loss in iteration no. 83674 ==> 0.30732583323960666\n",
            "Loss in iteration no. 83675 ==> 0.3073258241534957\n",
            "Loss in iteration no. 83676 ==> 0.3073258150679224\n",
            "Loss in iteration no. 83677 ==> 0.30732580598288783\n",
            "Loss in iteration no. 83678 ==> 0.30732579689839107\n",
            "Loss in iteration no. 83679 ==> 0.3073257878144335\n",
            "Loss in iteration no. 83680 ==> 0.3073257787310136\n",
            "Loss in iteration no. 83681 ==> 0.3073257696481322\n",
            "Loss in iteration no. 83682 ==> 0.30732576056578886\n",
            "Loss in iteration no. 83683 ==> 0.3073257514839837\n",
            "Loss in iteration no. 83684 ==> 0.30732574240271643\n",
            "Loss in iteration no. 83685 ==> 0.30732573332198687\n",
            "Loss in iteration no. 83686 ==> 0.3073257242417963\n",
            "Loss in iteration no. 83687 ==> 0.3073257151621426\n",
            "Loss in iteration no. 83688 ==> 0.30732570608302723\n",
            "Loss in iteration no. 83689 ==> 0.3073256970044504\n",
            "Loss in iteration no. 83690 ==> 0.30732568792641113\n",
            "Loss in iteration no. 83691 ==> 0.30732567884890905\n",
            "Loss in iteration no. 83692 ==> 0.3073256697719454\n",
            "Loss in iteration no. 83693 ==> 0.3073256606955198\n",
            "Loss in iteration no. 83694 ==> 0.3073256516196317\n",
            "Loss in iteration no. 83695 ==> 0.30732564254428096\n",
            "Loss in iteration no. 83696 ==> 0.3073256334694684\n",
            "Loss in iteration no. 83697 ==> 0.3073256243951939\n",
            "Loss in iteration no. 83698 ==> 0.30732561532145614\n",
            "Loss in iteration no. 83699 ==> 0.30732560624825594\n",
            "Loss in iteration no. 83700 ==> 0.307325597175594\n",
            "Loss in iteration no. 83701 ==> 0.30732558810346905\n",
            "Loss in iteration no. 83702 ==> 0.3073255790318821\n",
            "Loss in iteration no. 83703 ==> 0.307325569960832\n",
            "Loss in iteration no. 83704 ==> 0.3073255608903195\n",
            "Loss in iteration no. 83705 ==> 0.3073255518203447\n",
            "Loss in iteration no. 83706 ==> 0.3073255427509066\n",
            "Loss in iteration no. 83707 ==> 0.3073255336820067\n",
            "Loss in iteration no. 83708 ==> 0.30732552461364354\n",
            "Loss in iteration no. 83709 ==> 0.3073255155458184\n",
            "Loss in iteration no. 83710 ==> 0.30732550647852985\n",
            "Loss in iteration no. 83711 ==> 0.30732549741177806\n",
            "Loss in iteration no. 83712 ==> 0.3073254883455634\n",
            "Loss in iteration no. 83713 ==> 0.3073254792798865\n",
            "Loss in iteration no. 83714 ==> 0.3073254702147468\n",
            "Loss in iteration no. 83715 ==> 0.30732546115014386\n",
            "Loss in iteration no. 83716 ==> 0.3073254520860779\n",
            "Loss in iteration no. 83717 ==> 0.307325443022549\n",
            "Loss in iteration no. 83718 ==> 0.30732543395955725\n",
            "Loss in iteration no. 83719 ==> 0.307325424897102\n",
            "Loss in iteration no. 83720 ==> 0.30732541583518425\n",
            "Loss in iteration no. 83721 ==> 0.30732540677380277\n",
            "Loss in iteration no. 83722 ==> 0.3073253977129582\n",
            "Loss in iteration no. 83723 ==> 0.3073253886526511\n",
            "Loss in iteration no. 83724 ==> 0.3073253795928798\n",
            "Loss in iteration no. 83725 ==> 0.30732537053364584\n",
            "Loss in iteration no. 83726 ==> 0.307325361474949\n",
            "Loss in iteration no. 83727 ==> 0.3073253524167878\n",
            "Loss in iteration no. 83728 ==> 0.30732534335916367\n",
            "Loss in iteration no. 83729 ==> 0.3073253343020763\n",
            "Loss in iteration no. 83730 ==> 0.3073253252455251\n",
            "Loss in iteration no. 83731 ==> 0.30732531618951076\n",
            "Loss in iteration no. 83732 ==> 0.3073253071340324\n",
            "Loss in iteration no. 83733 ==> 0.3073252980790909\n",
            "Loss in iteration no. 83734 ==> 0.307325289024686\n",
            "Loss in iteration no. 83735 ==> 0.30732527997081743\n",
            "Loss in iteration no. 83736 ==> 0.3073252709174857\n",
            "Loss in iteration no. 83737 ==> 0.30732526186468934\n",
            "Loss in iteration no. 83738 ==> 0.30732525281243006\n",
            "Loss in iteration no. 83739 ==> 0.3073252437607059\n",
            "Loss in iteration no. 83740 ==> 0.3073252347095191\n",
            "Loss in iteration no. 83741 ==> 0.30732522565886816\n",
            "Loss in iteration no. 83742 ==> 0.3073252166087536\n",
            "Loss in iteration no. 83743 ==> 0.30732520755917486\n",
            "Loss in iteration no. 83744 ==> 0.3073251985101326\n",
            "Loss in iteration no. 83745 ==> 0.30732518946162557\n",
            "Loss in iteration no. 83746 ==> 0.30732518041365536\n",
            "Loss in iteration no. 83747 ==> 0.3073251713662207\n",
            "Loss in iteration no. 83748 ==> 0.30732516231932266\n",
            "Loss in iteration no. 83749 ==> 0.30732515327295945\n",
            "Loss in iteration no. 83750 ==> 0.3073251442271332\n",
            "Loss in iteration no. 83751 ==> 0.3073251351818426\n",
            "Loss in iteration no. 83752 ==> 0.3073251261370875\n",
            "Loss in iteration no. 83753 ==> 0.3073251170928678\n",
            "Loss in iteration no. 83754 ==> 0.30732510804918517\n",
            "Loss in iteration no. 83755 ==> 0.3073250990060375\n",
            "Loss in iteration no. 83756 ==> 0.3073250899634253\n",
            "Loss in iteration no. 83757 ==> 0.3073250809213488\n",
            "Loss in iteration no. 83758 ==> 0.30732507187980806\n",
            "Loss in iteration no. 83759 ==> 0.30732506283880284\n",
            "Loss in iteration no. 83760 ==> 0.3073250537983341\n",
            "Loss in iteration no. 83761 ==> 0.3073250447583994\n",
            "Loss in iteration no. 83762 ==> 0.307325035719001\n",
            "Loss in iteration no. 83763 ==> 0.30732502668013817\n",
            "Loss in iteration no. 83764 ==> 0.3073250176418108\n",
            "Loss in iteration no. 83765 ==> 0.3073250086040188\n",
            "Loss in iteration no. 83766 ==> 0.30732499956676207\n",
            "Loss in iteration no. 83767 ==> 0.30732499053004053\n",
            "Loss in iteration no. 83768 ==> 0.3073249814938541\n",
            "Loss in iteration no. 83769 ==> 0.30732497245820356\n",
            "Loss in iteration no. 83770 ==> 0.30732496342308796\n",
            "Loss in iteration no. 83771 ==> 0.3073249543885073\n",
            "Loss in iteration no. 83772 ==> 0.3073249453544623\n",
            "Loss in iteration no. 83773 ==> 0.307324936320952\n",
            "Loss in iteration no. 83774 ==> 0.3073249272879773\n",
            "Loss in iteration no. 83775 ==> 0.30732491825553737\n",
            "Loss in iteration no. 83776 ==> 0.307324909223633\n",
            "Loss in iteration no. 83777 ==> 0.3073249001922625\n",
            "Loss in iteration no. 83778 ==> 0.3073248911614277\n",
            "Loss in iteration no. 83779 ==> 0.30732488213112763\n",
            "Loss in iteration no. 83780 ==> 0.3073248731013625\n",
            "Loss in iteration no. 83781 ==> 0.3073248640721328\n",
            "Loss in iteration no. 83782 ==> 0.3073248550434371\n",
            "Loss in iteration no. 83783 ==> 0.3073248460152763\n",
            "Loss in iteration no. 83784 ==> 0.30732483698765134\n",
            "Loss in iteration no. 83785 ==> 0.30732482796056027\n",
            "Loss in iteration no. 83786 ==> 0.3073248189340038\n",
            "Loss in iteration no. 83787 ==> 0.3073248099079823\n",
            "Loss in iteration no. 83788 ==> 0.30732480088249553\n",
            "Loss in iteration no. 83789 ==> 0.30732479185754313\n",
            "Loss in iteration no. 83790 ==> 0.3073247828331254\n",
            "Loss in iteration no. 83791 ==> 0.30732477380924234\n",
            "Loss in iteration no. 83792 ==> 0.3073247647858933\n",
            "Loss in iteration no. 83793 ==> 0.3073247557630784\n",
            "Loss in iteration no. 83794 ==> 0.30732474674079957\n",
            "Loss in iteration no. 83795 ==> 0.30732473771905366\n",
            "Loss in iteration no. 83796 ==> 0.30732472869784255\n",
            "Loss in iteration no. 83797 ==> 0.3073247196771663\n",
            "Loss in iteration no. 83798 ==> 0.3073247106570237\n",
            "Loss in iteration no. 83799 ==> 0.30732470163741565\n",
            "Loss in iteration no. 83800 ==> 0.30732469261834217\n",
            "Loss in iteration no. 83801 ==> 0.30732468359980225\n",
            "Loss in iteration no. 83802 ==> 0.30732467458179735\n",
            "Loss in iteration no. 83803 ==> 0.307324665564326\n",
            "Loss in iteration no. 83804 ==> 0.3073246565473885\n",
            "Loss in iteration no. 83805 ==> 0.30732464753098565\n",
            "Loss in iteration no. 83806 ==> 0.30732463851511627\n",
            "Loss in iteration no. 83807 ==> 0.307324629499781\n",
            "Loss in iteration no. 83808 ==> 0.30732462048498044\n",
            "Loss in iteration no. 83809 ==> 0.30732461147071344\n",
            "Loss in iteration no. 83810 ==> 0.3073246024569805\n",
            "Loss in iteration no. 83811 ==> 0.307324593443781\n",
            "Loss in iteration no. 83812 ==> 0.3073245844311157\n",
            "Loss in iteration no. 83813 ==> 0.3073245754189843\n",
            "Loss in iteration no. 83814 ==> 0.30732456640738604\n",
            "Loss in iteration no. 83815 ==> 0.3073245573963219\n",
            "Loss in iteration no. 83816 ==> 0.3073245483857916\n",
            "Loss in iteration no. 83817 ==> 0.30732453937579524\n",
            "Loss in iteration no. 83818 ==> 0.3073245303663318\n",
            "Loss in iteration no. 83819 ==> 0.3073245213574029\n",
            "Loss in iteration no. 83820 ==> 0.3073245123490069\n",
            "Loss in iteration no. 83821 ==> 0.30732450334114436\n",
            "Loss in iteration no. 83822 ==> 0.3073244943338162\n",
            "Loss in iteration no. 83823 ==> 0.307324485327021\n",
            "Loss in iteration no. 83824 ==> 0.30732447632075915\n",
            "Loss in iteration no. 83825 ==> 0.307324467315031\n",
            "Loss in iteration no. 83826 ==> 0.30732445830983557\n",
            "Loss in iteration no. 83827 ==> 0.30732444930517444\n",
            "Loss in iteration no. 83828 ==> 0.3073244403010457\n",
            "Loss in iteration no. 83829 ==> 0.307324431297451\n",
            "Loss in iteration no. 83830 ==> 0.30732442229438883\n",
            "Loss in iteration no. 83831 ==> 0.30732441329186105\n",
            "Loss in iteration no. 83832 ==> 0.30732440428986557\n",
            "Loss in iteration no. 83833 ==> 0.30732439528840316\n",
            "Loss in iteration no. 83834 ==> 0.3073243862874737\n",
            "Loss in iteration no. 83835 ==> 0.3073243772870785\n",
            "Loss in iteration no. 83836 ==> 0.3073243682872153\n",
            "Loss in iteration no. 83837 ==> 0.30732435928788604\n",
            "Loss in iteration no. 83838 ==> 0.3073243502890883\n",
            "Loss in iteration no. 83839 ==> 0.30732434129082437\n",
            "Loss in iteration no. 83840 ==> 0.30732433229309414\n",
            "Loss in iteration no. 83841 ==> 0.307324323295896\n",
            "Loss in iteration no. 83842 ==> 0.3073243142992306\n",
            "Loss in iteration no. 83843 ==> 0.30732430530309834\n",
            "Loss in iteration no. 83844 ==> 0.30732429630749886\n",
            "Loss in iteration no. 83845 ==> 0.3073242873124322\n",
            "Loss in iteration no. 83846 ==> 0.3073242783178976\n",
            "Loss in iteration no. 83847 ==> 0.3073242693238968\n",
            "Loss in iteration no. 83848 ==> 0.30732426033042826\n",
            "Loss in iteration no. 83849 ==> 0.3073242513374916\n",
            "Loss in iteration no. 83850 ==> 0.30732424234508826\n",
            "Loss in iteration no. 83851 ==> 0.3073242333532171\n",
            "Loss in iteration no. 83852 ==> 0.3073242243618792\n",
            "Loss in iteration no. 83853 ==> 0.3073242153710728\n",
            "Loss in iteration no. 83854 ==> 0.3073242063807996\n",
            "Loss in iteration no. 83855 ==> 0.307324197391059\n",
            "Loss in iteration no. 83856 ==> 0.3073241884018505\n",
            "Loss in iteration no. 83857 ==> 0.30732417941317447\n",
            "Loss in iteration no. 83858 ==> 0.3073241704250301\n",
            "Loss in iteration no. 83859 ==> 0.3073241614374188\n",
            "Loss in iteration no. 83860 ==> 0.30732415245033984\n",
            "Loss in iteration no. 83861 ==> 0.3073241434637921\n",
            "Loss in iteration no. 83862 ==> 0.3073241344777773\n",
            "Loss in iteration no. 83863 ==> 0.3073241254922951\n",
            "Loss in iteration no. 83864 ==> 0.30732411650734476\n",
            "Loss in iteration no. 83865 ==> 0.30732410752292627\n",
            "Loss in iteration no. 83866 ==> 0.30732409853903947\n",
            "Loss in iteration no. 83867 ==> 0.3073240895556854\n",
            "Loss in iteration no. 83868 ==> 0.30732408057286287\n",
            "Loss in iteration no. 83869 ==> 0.30732407159057273\n",
            "Loss in iteration no. 83870 ==> 0.3073240626088145\n",
            "Loss in iteration no. 83871 ==> 0.3073240536275878\n",
            "Loss in iteration no. 83872 ==> 0.3073240446468931\n",
            "Loss in iteration no. 83873 ==> 0.3073240356667305\n",
            "Loss in iteration no. 83874 ==> 0.3073240266871\n",
            "Loss in iteration no. 83875 ==> 0.3073240177080006\n",
            "Loss in iteration no. 83876 ==> 0.30732400872943305\n",
            "Loss in iteration no. 83877 ==> 0.3073239997513976\n",
            "Loss in iteration no. 83878 ==> 0.3073239907738932\n",
            "Loss in iteration no. 83879 ==> 0.30732398179692155\n",
            "Loss in iteration no. 83880 ==> 0.30732397282048024\n",
            "Loss in iteration no. 83881 ==> 0.3073239638445709\n",
            "Loss in iteration no. 83882 ==> 0.30732395486919367\n",
            "Loss in iteration no. 83883 ==> 0.30732394589434747\n",
            "Loss in iteration no. 83884 ==> 0.30732393692003285\n",
            "Loss in iteration no. 83885 ==> 0.30732392794624985\n",
            "Loss in iteration no. 83886 ==> 0.307323918972998\n",
            "Loss in iteration no. 83887 ==> 0.3073239100002776\n",
            "Loss in iteration no. 83888 ==> 0.3073239010280889\n",
            "Loss in iteration no. 83889 ==> 0.30732389205643107\n",
            "Loss in iteration no. 83890 ==> 0.3073238830853041\n",
            "Loss in iteration no. 83891 ==> 0.3073238741147091\n",
            "Loss in iteration no. 83892 ==> 0.30732386514464555\n",
            "Loss in iteration no. 83893 ==> 0.3073238561751129\n",
            "Loss in iteration no. 83894 ==> 0.3073238472061113\n",
            "Loss in iteration no. 83895 ==> 0.3073238382376404\n",
            "Loss in iteration no. 83896 ==> 0.30732382926970164\n",
            "Loss in iteration no. 83897 ==> 0.30732382030229266\n",
            "Loss in iteration no. 83898 ==> 0.3073238113354158\n",
            "Loss in iteration no. 83899 ==> 0.30732380236906887\n",
            "Loss in iteration no. 83900 ==> 0.3073237934032536\n",
            "Loss in iteration no. 83901 ==> 0.3073237844379695\n",
            "Loss in iteration no. 83902 ==> 0.30732377547321565\n",
            "Loss in iteration no. 83903 ==> 0.3073237665089934\n",
            "Loss in iteration no. 83904 ==> 0.30732375754530117\n",
            "Loss in iteration no. 83905 ==> 0.3073237485821399\n",
            "Loss in iteration no. 83906 ==> 0.3073237396195094\n",
            "Loss in iteration no. 83907 ==> 0.30732373065741014\n",
            "Loss in iteration no. 83908 ==> 0.3073237216958415\n",
            "Loss in iteration no. 83909 ==> 0.30732371273480347\n",
            "Loss in iteration no. 83910 ==> 0.30732370377429563\n",
            "Loss in iteration no. 83911 ==> 0.30732369481431887\n",
            "Loss in iteration no. 83912 ==> 0.3073236858548726\n",
            "Loss in iteration no. 83913 ==> 0.3073236768959567\n",
            "Loss in iteration no. 83914 ==> 0.3073236679375713\n",
            "Loss in iteration no. 83915 ==> 0.3073236589797162\n",
            "Loss in iteration no. 83916 ==> 0.30732365002239187\n",
            "Loss in iteration no. 83917 ==> 0.30732364106559795\n",
            "Loss in iteration no. 83918 ==> 0.3073236321093336\n",
            "Loss in iteration no. 83919 ==> 0.30732362315360034\n",
            "Loss in iteration no. 83920 ==> 0.30732361419839727\n",
            "Loss in iteration no. 83921 ==> 0.3073236052437242\n",
            "Loss in iteration no. 83922 ==> 0.30732359628958206\n",
            "Loss in iteration no. 83923 ==> 0.3073235873359694\n",
            "Loss in iteration no. 83924 ==> 0.3073235783828875\n",
            "Loss in iteration no. 83925 ==> 0.30732356943033584\n",
            "Loss in iteration no. 83926 ==> 0.30732356047831344\n",
            "Loss in iteration no. 83927 ==> 0.3073235515268219\n",
            "Loss in iteration no. 83928 ==> 0.3073235425758595\n",
            "Loss in iteration no. 83929 ==> 0.3073235336254276\n",
            "Loss in iteration no. 83930 ==> 0.30732352467552615\n",
            "Loss in iteration no. 83931 ==> 0.30732351572615413\n",
            "Loss in iteration no. 83932 ==> 0.30732350677731224\n",
            "Loss in iteration no. 83933 ==> 0.30732349782899954\n",
            "Loss in iteration no. 83934 ==> 0.30732348888121724\n",
            "Loss in iteration no. 83935 ==> 0.3073234799339655\n",
            "Loss in iteration no. 83936 ==> 0.30732347098724205\n",
            "Loss in iteration no. 83937 ==> 0.3073234620410491\n",
            "Loss in iteration no. 83938 ==> 0.30732345309538656\n",
            "Loss in iteration no. 83939 ==> 0.30732344415025287\n",
            "Loss in iteration no. 83940 ==> 0.3073234352056487\n",
            "Loss in iteration no. 83941 ==> 0.3073234262615743\n",
            "Loss in iteration no. 83942 ==> 0.30732341731802953\n",
            "Loss in iteration no. 83943 ==> 0.307323408375015\n",
            "Loss in iteration no. 83944 ==> 0.3073233994325292\n",
            "Loss in iteration no. 83945 ==> 0.3073233904905729\n",
            "Loss in iteration no. 83946 ==> 0.3073233815491461\n",
            "Loss in iteration no. 83947 ==> 0.30732337260824916\n",
            "Loss in iteration no. 83948 ==> 0.3073233636678814\n",
            "Loss in iteration no. 83949 ==> 0.30732335472804284\n",
            "Loss in iteration no. 83950 ==> 0.30732334578873277\n",
            "Loss in iteration no. 83951 ==> 0.3073233368499529\n",
            "Loss in iteration no. 83952 ==> 0.3073233279117028\n",
            "Loss in iteration no. 83953 ==> 0.30732331897398096\n",
            "Loss in iteration no. 83954 ==> 0.3073233100367891\n",
            "Loss in iteration no. 83955 ==> 0.30732330110012607\n",
            "Loss in iteration no. 83956 ==> 0.3073232921639917\n",
            "Loss in iteration no. 83957 ==> 0.3073232832283868\n",
            "Loss in iteration no. 83958 ==> 0.30732327429331174\n",
            "Loss in iteration no. 83959 ==> 0.30732326535876425\n",
            "Loss in iteration no. 83960 ==> 0.3073232564247467\n",
            "Loss in iteration no. 83961 ==> 0.30732324749125767\n",
            "Loss in iteration no. 83962 ==> 0.307323238558298\n",
            "Loss in iteration no. 83963 ==> 0.3073232296258674\n",
            "Loss in iteration no. 83964 ==> 0.30732322069396484\n",
            "Loss in iteration no. 83965 ==> 0.30732321176259114\n",
            "Loss in iteration no. 83966 ==> 0.3073232028317467\n",
            "Loss in iteration no. 83967 ==> 0.3073231939014308\n",
            "Loss in iteration no. 83968 ==> 0.3073231849716436\n",
            "Loss in iteration no. 83969 ==> 0.30732317604238624\n",
            "Loss in iteration no. 83970 ==> 0.30732316711365604\n",
            "Loss in iteration no. 83971 ==> 0.30732315818545464\n",
            "Loss in iteration no. 83972 ==> 0.30732314925778287\n",
            "Loss in iteration no. 83973 ==> 0.30732314033063884\n",
            "Loss in iteration no. 83974 ==> 0.3073231314040234\n",
            "Loss in iteration no. 83975 ==> 0.3073231224779369\n",
            "Loss in iteration no. 83976 ==> 0.3073231135523784\n",
            "Loss in iteration no. 83977 ==> 0.30732310462734835\n",
            "Loss in iteration no. 83978 ==> 0.3073230957028468\n",
            "Loss in iteration no. 83979 ==> 0.307323086778874\n",
            "Loss in iteration no. 83980 ==> 0.30732307785542895\n",
            "Loss in iteration no. 83981 ==> 0.3073230689325127\n",
            "Loss in iteration no. 83982 ==> 0.3073230600101248\n",
            "Loss in iteration no. 83983 ==> 0.30732305108826447\n",
            "Loss in iteration no. 83984 ==> 0.3073230421669331\n",
            "Loss in iteration no. 83985 ==> 0.30732303324612964\n",
            "Loss in iteration no. 83986 ==> 0.3073230243258542\n",
            "Loss in iteration no. 83987 ==> 0.30732301540610674\n",
            "Loss in iteration no. 83988 ==> 0.30732300648688726\n",
            "Loss in iteration no. 83989 ==> 0.30732299756819603\n",
            "Loss in iteration no. 83990 ==> 0.3073229886500334\n",
            "Loss in iteration no. 83991 ==> 0.30732297973239764\n",
            "Loss in iteration no. 83992 ==> 0.30732297081529036\n",
            "Loss in iteration no. 83993 ==> 0.30732296189871117\n",
            "Loss in iteration no. 83994 ==> 0.3073229529826601\n",
            "Loss in iteration no. 83995 ==> 0.3073229440671365\n",
            "Loss in iteration no. 83996 ==> 0.30732293515214026\n",
            "Loss in iteration no. 83997 ==> 0.3073229262376725\n",
            "Loss in iteration no. 83998 ==> 0.3073229173237328\n",
            "Loss in iteration no. 83999 ==> 0.3073229084103202\n",
            "Loss in iteration no. 84000 ==> 0.3073228994974358\n",
            "Loss in iteration no. 84001 ==> 0.307322890585078\n",
            "Loss in iteration no. 84002 ==> 0.30732288167324834\n",
            "Loss in iteration no. 84003 ==> 0.3073228727619467\n",
            "Loss in iteration no. 84004 ==> 0.30732286385117213\n",
            "Loss in iteration no. 84005 ==> 0.3073228549409256\n",
            "Loss in iteration no. 84006 ==> 0.3073228460312064\n",
            "Loss in iteration no. 84007 ==> 0.30732283712201447\n",
            "Loss in iteration no. 84008 ==> 0.3073228282133499\n",
            "Loss in iteration no. 84009 ==> 0.30732281930521294\n",
            "Loss in iteration no. 84010 ==> 0.307322810397603\n",
            "Loss in iteration no. 84011 ==> 0.30732280149052105\n",
            "Loss in iteration no. 84012 ==> 0.3073227925839662\n",
            "Loss in iteration no. 84013 ==> 0.307322783677938\n",
            "Loss in iteration no. 84014 ==> 0.3073227747724378\n",
            "Loss in iteration no. 84015 ==> 0.3073227658674645\n",
            "Loss in iteration no. 84016 ==> 0.3073227569630181\n",
            "Loss in iteration no. 84017 ==> 0.3073227480590987\n",
            "Loss in iteration no. 84018 ==> 0.30732273915570707\n",
            "Loss in iteration no. 84019 ==> 0.3073227302528423\n",
            "Loss in iteration no. 84020 ==> 0.30732272135050426\n",
            "Loss in iteration no. 84021 ==> 0.30732271244869375\n",
            "Loss in iteration no. 84022 ==> 0.3073227035474103\n",
            "Loss in iteration no. 84023 ==> 0.3073226946466529\n",
            "Loss in iteration no. 84024 ==> 0.3073226857464225\n",
            "Loss in iteration no. 84025 ==> 0.3073226768467201\n",
            "Loss in iteration no. 84026 ==> 0.3073226679475436\n",
            "Loss in iteration no. 84027 ==> 0.3073226590488945\n",
            "Loss in iteration no. 84028 ==> 0.3073226501507712\n",
            "Loss in iteration no. 84029 ==> 0.30732264125317565\n",
            "Loss in iteration no. 84030 ==> 0.3073226323561066\n",
            "Loss in iteration no. 84031 ==> 0.3073226234595638\n",
            "Loss in iteration no. 84032 ==> 0.30732261456354737\n",
            "Loss in iteration no. 84033 ==> 0.30732260566805836\n",
            "Loss in iteration no. 84034 ==> 0.3073225967730962\n",
            "Loss in iteration no. 84035 ==> 0.30732258787866024\n",
            "Loss in iteration no. 84036 ==> 0.3073225789847501\n",
            "Loss in iteration no. 84037 ==> 0.3073225700913672\n",
            "Loss in iteration no. 84038 ==> 0.30732256119850976\n",
            "Loss in iteration no. 84039 ==> 0.30732255230618005\n",
            "Loss in iteration no. 84040 ==> 0.3073225434143764\n",
            "Loss in iteration no. 84041 ==> 0.3073225345230989\n",
            "Loss in iteration no. 84042 ==> 0.30732252563234724\n",
            "Loss in iteration no. 84043 ==> 0.30732251674212263\n",
            "Loss in iteration no. 84044 ==> 0.3073225078524236\n",
            "Loss in iteration no. 84045 ==> 0.30732249896325176\n",
            "Loss in iteration no. 84046 ==> 0.3073224900746052\n",
            "Loss in iteration no. 84047 ==> 0.30732248118648503\n",
            "Loss in iteration no. 84048 ==> 0.3073224722988916\n",
            "Loss in iteration no. 84049 ==> 0.30732246341182357\n",
            "Loss in iteration no. 84050 ==> 0.3073224545252817\n",
            "Loss in iteration no. 84051 ==> 0.30732244563926636\n",
            "Loss in iteration no. 84052 ==> 0.3073224367537766\n",
            "Loss in iteration no. 84053 ==> 0.30732242786881236\n",
            "Loss in iteration no. 84054 ==> 0.30732241898437485\n",
            "Loss in iteration no. 84055 ==> 0.30732241010046263\n",
            "Loss in iteration no. 84056 ==> 0.30732240121707655\n",
            "Loss in iteration no. 84057 ==> 0.30732239233421577\n",
            "Loss in iteration no. 84058 ==> 0.3073223834518822\n",
            "Loss in iteration no. 84059 ==> 0.30732237457007366\n",
            "Loss in iteration no. 84060 ==> 0.3073223656887902\n",
            "Loss in iteration no. 84061 ==> 0.3073223568080332\n",
            "Loss in iteration no. 84062 ==> 0.30732234792780116\n",
            "Loss in iteration no. 84063 ==> 0.30732233904809514\n",
            "Loss in iteration no. 84064 ==> 0.3073223301689154\n",
            "Loss in iteration no. 84065 ==> 0.3073223212902603\n",
            "Loss in iteration no. 84066 ==> 0.30732231241213187\n",
            "Loss in iteration no. 84067 ==> 0.3073223035345275\n",
            "Loss in iteration no. 84068 ==> 0.30732229465744954\n",
            "Loss in iteration no. 84069 ==> 0.3073222857808967\n",
            "Loss in iteration no. 84070 ==> 0.3073222769048694\n",
            "Loss in iteration no. 84071 ==> 0.30732226802936763\n",
            "Loss in iteration no. 84072 ==> 0.30732225915439104\n",
            "Loss in iteration no. 84073 ==> 0.3073222502799393\n",
            "Loss in iteration no. 84074 ==> 0.3073222414060137\n",
            "Loss in iteration no. 84075 ==> 0.3073222325326132\n",
            "Loss in iteration no. 84076 ==> 0.30732222365973766\n",
            "Loss in iteration no. 84077 ==> 0.30732221478738747\n",
            "Loss in iteration no. 84078 ==> 0.30732220591556186\n",
            "Loss in iteration no. 84079 ==> 0.3073221970442615\n",
            "Loss in iteration no. 84080 ==> 0.30732218817348744\n",
            "Loss in iteration no. 84081 ==> 0.3073221793032368\n",
            "Loss in iteration no. 84082 ==> 0.30732217043351207\n",
            "Loss in iteration no. 84083 ==> 0.30732216156431225\n",
            "Loss in iteration no. 84084 ==> 0.3073221526956376\n",
            "Loss in iteration no. 84085 ==> 0.3073221438274879\n",
            "Loss in iteration no. 84086 ==> 0.3073221349598628\n",
            "Loss in iteration no. 84087 ==> 0.3073221260927624\n",
            "Loss in iteration no. 84088 ==> 0.30732211722618685\n",
            "Loss in iteration no. 84089 ==> 0.30732210836013624\n",
            "Loss in iteration no. 84090 ==> 0.3073220994946105\n",
            "Loss in iteration no. 84091 ==> 0.3073220906296091\n",
            "Loss in iteration no. 84092 ==> 0.3073220817651331\n",
            "Loss in iteration no. 84093 ==> 0.30732207290118096\n",
            "Loss in iteration no. 84094 ==> 0.30732206403775414\n",
            "Loss in iteration no. 84095 ==> 0.3073220551748513\n",
            "Loss in iteration no. 84096 ==> 0.3073220463124737\n",
            "Loss in iteration no. 84097 ==> 0.3073220374506204\n",
            "Loss in iteration no. 84098 ==> 0.3073220285892913\n",
            "Loss in iteration no. 84099 ==> 0.3073220197284876\n",
            "Loss in iteration no. 84100 ==> 0.3073220108682075\n",
            "Loss in iteration no. 84101 ==> 0.30732200200845183\n",
            "Loss in iteration no. 84102 ==> 0.307321993149221\n",
            "Loss in iteration no. 84103 ==> 0.3073219842905135\n",
            "Loss in iteration no. 84104 ==> 0.30732197543233103\n",
            "Loss in iteration no. 84105 ==> 0.30732196657467276\n",
            "Loss in iteration no. 84106 ==> 0.3073219577175396\n",
            "Loss in iteration no. 84107 ==> 0.3073219488609293\n",
            "Loss in iteration no. 84108 ==> 0.3073219400048441\n",
            "Loss in iteration no. 84109 ==> 0.307321931149283\n",
            "Loss in iteration no. 84110 ==> 0.3073219222942454\n",
            "Loss in iteration no. 84111 ==> 0.3073219134397326\n",
            "Loss in iteration no. 84112 ==> 0.30732190458574293\n",
            "Loss in iteration no. 84113 ==> 0.30732189573227775\n",
            "Loss in iteration no. 84114 ==> 0.30732188687933715\n",
            "Loss in iteration no. 84115 ==> 0.30732187802691896\n",
            "Loss in iteration no. 84116 ==> 0.3073218691750263\n",
            "Loss in iteration no. 84117 ==> 0.30732186032365677\n",
            "Loss in iteration no. 84118 ==> 0.3073218514728112\n",
            "Loss in iteration no. 84119 ==> 0.3073218426224896\n",
            "Loss in iteration no. 84120 ==> 0.3073218337726922\n",
            "Loss in iteration no. 84121 ==> 0.3073218249234176\n",
            "Loss in iteration no. 84122 ==> 0.30732181607466763\n",
            "Loss in iteration no. 84123 ==> 0.3073218072264403\n",
            "Loss in iteration no. 84124 ==> 0.30732179837873747\n",
            "Loss in iteration no. 84125 ==> 0.3073217895315584\n",
            "Loss in iteration no. 84126 ==> 0.3073217806849026\n",
            "Loss in iteration no. 84127 ==> 0.3073217718387702\n",
            "Loss in iteration no. 84128 ==> 0.3073217629931619\n",
            "Loss in iteration no. 84129 ==> 0.3073217541480762\n",
            "Loss in iteration no. 84130 ==> 0.30732174530351536\n",
            "Loss in iteration no. 84131 ==> 0.3073217364594765\n",
            "Loss in iteration no. 84132 ==> 0.30732172761596155\n",
            "Loss in iteration no. 84133 ==> 0.3073217187729701\n",
            "Loss in iteration no. 84134 ==> 0.30732170993050206\n",
            "Loss in iteration no. 84135 ==> 0.3073217010885569\n",
            "Loss in iteration no. 84136 ==> 0.3073216922471357\n",
            "Loss in iteration no. 84137 ==> 0.3073216834062375\n",
            "Loss in iteration no. 84138 ==> 0.3073216745658629\n",
            "Loss in iteration no. 84139 ==> 0.30732166572601116\n",
            "Loss in iteration no. 84140 ==> 0.3073216568866818\n",
            "Loss in iteration no. 84141 ==> 0.30732164804787626\n",
            "Loss in iteration no. 84142 ==> 0.3073216392095937\n",
            "Loss in iteration no. 84143 ==> 0.3073216303718341\n",
            "Loss in iteration no. 84144 ==> 0.3073216215345977\n",
            "Loss in iteration no. 84145 ==> 0.3073216126978842\n",
            "Loss in iteration no. 84146 ==> 0.30732160386169416\n",
            "Loss in iteration no. 84147 ==> 0.3073215950260259\n",
            "Loss in iteration no. 84148 ==> 0.3073215861908814\n",
            "Loss in iteration no. 84149 ==> 0.30732157735626026\n",
            "Loss in iteration no. 84150 ==> 0.3073215685221607\n",
            "Loss in iteration no. 84151 ==> 0.3073215596885851\n",
            "Loss in iteration no. 84152 ==> 0.3073215508555308\n",
            "Loss in iteration no. 84153 ==> 0.3073215420230009\n",
            "Loss in iteration no. 84154 ==> 0.307321533190993\n",
            "Loss in iteration no. 84155 ==> 0.3073215243595072\n",
            "Loss in iteration no. 84156 ==> 0.30732151552854425\n",
            "Loss in iteration no. 84157 ==> 0.3073215066981047\n",
            "Loss in iteration no. 84158 ==> 0.3073214978681864\n",
            "Loss in iteration no. 84159 ==> 0.30732148903879175\n",
            "Loss in iteration no. 84160 ==> 0.30732148020991945\n",
            "Loss in iteration no. 84161 ==> 0.3073214713815696\n",
            "Loss in iteration no. 84162 ==> 0.30732146255374126\n",
            "Loss in iteration no. 84163 ==> 0.3073214537264363\n",
            "Loss in iteration no. 84164 ==> 0.3073214448996537\n",
            "Loss in iteration no. 84165 ==> 0.30732143607339313\n",
            "Loss in iteration no. 84166 ==> 0.30732142724765543\n",
            "Loss in iteration no. 84167 ==> 0.30732141842243876\n",
            "Loss in iteration no. 84168 ==> 0.30732140959774534\n",
            "Loss in iteration no. 84169 ==> 0.30732140077357445\n",
            "Loss in iteration no. 84170 ==> 0.30732139194992536\n",
            "Loss in iteration no. 84171 ==> 0.30732138312679796\n",
            "Loss in iteration no. 84172 ==> 0.3073213743041933\n",
            "Loss in iteration no. 84173 ==> 0.30732136548210987\n",
            "Loss in iteration no. 84174 ==> 0.307321356660549\n",
            "Loss in iteration no. 84175 ==> 0.30732134783951026\n",
            "Loss in iteration no. 84176 ==> 0.30732133901899406\n",
            "Loss in iteration no. 84177 ==> 0.3073213301989988\n",
            "Loss in iteration no. 84178 ==> 0.30732132137952584\n",
            "Loss in iteration no. 84179 ==> 0.30732131256057554\n",
            "Loss in iteration no. 84180 ==> 0.3073213037421463\n",
            "Loss in iteration no. 84181 ==> 0.30732129492423876\n",
            "Loss in iteration no. 84182 ==> 0.3073212861068529\n",
            "Loss in iteration no. 84183 ==> 0.3073212772899891\n",
            "Loss in iteration no. 84184 ==> 0.30732126847364755\n",
            "Loss in iteration no. 84185 ==> 0.3073212596578267\n",
            "Loss in iteration no. 84186 ==> 0.30732125084252804\n",
            "Loss in iteration no. 84187 ==> 0.30732124202775096\n",
            "Loss in iteration no. 84188 ==> 0.30732123321349575\n",
            "Loss in iteration no. 84189 ==> 0.3073212243997619\n",
            "Loss in iteration no. 84190 ==> 0.3073212155865492\n",
            "Loss in iteration no. 84191 ==> 0.30732120677385827\n",
            "Loss in iteration no. 84192 ==> 0.3073211979616895\n",
            "Loss in iteration no. 84193 ==> 0.30732118915004164\n",
            "Loss in iteration no. 84194 ==> 0.30732118033891487\n",
            "Loss in iteration no. 84195 ==> 0.3073211715283102\n",
            "Loss in iteration no. 84196 ==> 0.3073211627182264\n",
            "Loss in iteration no. 84197 ==> 0.3073211539086636\n",
            "Loss in iteration no. 84198 ==> 0.3073211450996225\n",
            "Loss in iteration no. 84199 ==> 0.3073211362911023\n",
            "Loss in iteration no. 84200 ==> 0.3073211274831036\n",
            "Loss in iteration no. 84201 ==> 0.30732111867562634\n",
            "Loss in iteration no. 84202 ==> 0.3073211098686698\n",
            "Loss in iteration no. 84203 ==> 0.30732110106223537\n",
            "Loss in iteration no. 84204 ==> 0.3073210922563205\n",
            "Loss in iteration no. 84205 ==> 0.30732108345092773\n",
            "Loss in iteration no. 84206 ==> 0.30732107464605574\n",
            "Loss in iteration no. 84207 ==> 0.30732106584170454\n",
            "Loss in iteration no. 84208 ==> 0.3073210570378746\n",
            "Loss in iteration no. 84209 ==> 0.3073210482345653\n",
            "Loss in iteration no. 84210 ==> 0.30732103943177663\n",
            "Loss in iteration no. 84211 ==> 0.3073210306295098\n",
            "Loss in iteration no. 84212 ==> 0.30732102182776244\n",
            "Loss in iteration no. 84213 ==> 0.3073210130265373\n",
            "Loss in iteration no. 84214 ==> 0.3073210042258319\n",
            "Loss in iteration no. 84215 ==> 0.30732099542564784\n",
            "Loss in iteration no. 84216 ==> 0.3073209866259836\n",
            "Loss in iteration no. 84217 ==> 0.3073209778268414\n",
            "Loss in iteration no. 84218 ==> 0.3073209690282186\n",
            "Loss in iteration no. 84219 ==> 0.3073209602301176\n",
            "Loss in iteration no. 84220 ==> 0.3073209514325358\n",
            "Loss in iteration no. 84221 ==> 0.30732094263547577\n",
            "Loss in iteration no. 84222 ==> 0.30732093383893566\n",
            "Loss in iteration no. 84223 ==> 0.30732092504291614\n",
            "Loss in iteration no. 84224 ==> 0.3073209162474173\n",
            "Loss in iteration no. 84225 ==> 0.30732090745243806\n",
            "Loss in iteration no. 84226 ==> 0.3073208986579802\n",
            "Loss in iteration no. 84227 ==> 0.30732088986404144\n",
            "Loss in iteration no. 84228 ==> 0.30732088107062466\n",
            "Loss in iteration no. 84229 ==> 0.3073208722777264\n",
            "Loss in iteration no. 84230 ==> 0.3073208634853501\n",
            "Loss in iteration no. 84231 ==> 0.30732085469349335\n",
            "Loss in iteration no. 84232 ==> 0.30732084590215625\n",
            "Loss in iteration no. 84233 ==> 0.30732083711133945\n",
            "Loss in iteration no. 84234 ==> 0.307320828321043\n",
            "Loss in iteration no. 84235 ==> 0.30732081953126716\n",
            "Loss in iteration no. 84236 ==> 0.30732081074201056\n",
            "Loss in iteration no. 84237 ==> 0.30732080195327494\n",
            "Loss in iteration no. 84238 ==> 0.3073207931650584\n",
            "Loss in iteration no. 84239 ==> 0.3073207843773617\n",
            "Loss in iteration no. 84240 ==> 0.3073207755901854\n",
            "Loss in iteration no. 84241 ==> 0.3073207668035292\n",
            "Loss in iteration no. 84242 ==> 0.3073207580173923\n",
            "Loss in iteration no. 84243 ==> 0.3073207492317759\n",
            "Loss in iteration no. 84244 ==> 0.3073207404466789\n",
            "Loss in iteration no. 84245 ==> 0.30732073166210183\n",
            "Loss in iteration no. 84246 ==> 0.30732072287804446\n",
            "Loss in iteration no. 84247 ==> 0.3073207140945062\n",
            "Loss in iteration no. 84248 ==> 0.3073207053114887\n",
            "Loss in iteration no. 84249 ==> 0.3073206965289903\n",
            "Loss in iteration no. 84250 ==> 0.30732068774701155\n",
            "Loss in iteration no. 84251 ==> 0.30732067896555204\n",
            "Loss in iteration no. 84252 ==> 0.30732067018461295\n",
            "Loss in iteration no. 84253 ==> 0.30732066140419256\n",
            "Loss in iteration no. 84254 ==> 0.3073206526242918\n",
            "Loss in iteration no. 84255 ==> 0.30732064384491065\n",
            "Loss in iteration no. 84256 ==> 0.30732063506604895\n",
            "Loss in iteration no. 84257 ==> 0.3073206262877062\n",
            "Loss in iteration no. 84258 ==> 0.3073206175098836\n",
            "Loss in iteration no. 84259 ==> 0.30732060873257994\n",
            "Loss in iteration no. 84260 ==> 0.3073205999557954\n",
            "Loss in iteration no. 84261 ==> 0.30732059117953026\n",
            "Loss in iteration no. 84262 ==> 0.3073205824037843\n",
            "Loss in iteration no. 84263 ==> 0.30732057362855764\n",
            "Loss in iteration no. 84264 ==> 0.3073205648538499\n",
            "Loss in iteration no. 84265 ==> 0.3073205560796618\n",
            "Loss in iteration no. 84266 ==> 0.3073205473059923\n",
            "Loss in iteration no. 84267 ==> 0.3073205385328424\n",
            "Loss in iteration no. 84268 ==> 0.3073205297602106\n",
            "Loss in iteration no. 84269 ==> 0.3073205209880986\n",
            "Loss in iteration no. 84270 ==> 0.30732051221650547\n",
            "Loss in iteration no. 84271 ==> 0.3073205034454307\n",
            "Loss in iteration no. 84272 ==> 0.3073204946748759\n",
            "Loss in iteration no. 84273 ==> 0.3073204859048395\n",
            "Loss in iteration no. 84274 ==> 0.30732047713532107\n",
            "Loss in iteration no. 84275 ==> 0.3073204683663226\n",
            "Loss in iteration no. 84276 ==> 0.3073204595978422\n",
            "Loss in iteration no. 84277 ==> 0.30732045082988146\n",
            "Loss in iteration no. 84278 ==> 0.30732044206243847\n",
            "Loss in iteration no. 84279 ==> 0.3073204332955149\n",
            "Loss in iteration no. 84280 ==> 0.30732042452910946\n",
            "Loss in iteration no. 84281 ==> 0.30732041576322333\n",
            "Loss in iteration no. 84282 ==> 0.3073204069978542\n",
            "Loss in iteration no. 84283 ==> 0.3073203982330047\n",
            "Loss in iteration no. 84284 ==> 0.3073203894686738\n",
            "Loss in iteration no. 84285 ==> 0.3073203807048615\n",
            "Loss in iteration no. 84286 ==> 0.3073203719415677\n",
            "Loss in iteration no. 84287 ==> 0.30732036317879147\n",
            "Loss in iteration no. 84288 ==> 0.3073203544165343\n",
            "Loss in iteration no. 84289 ==> 0.3073203456547959\n",
            "Loss in iteration no. 84290 ==> 0.3073203368935758\n",
            "Loss in iteration no. 84291 ==> 0.3073203281328728\n",
            "Loss in iteration no. 84292 ==> 0.3073203193726897\n",
            "Loss in iteration no. 84293 ==> 0.3073203106130237\n",
            "Loss in iteration no. 84294 ==> 0.30732030185387543\n",
            "Loss in iteration no. 84295 ==> 0.30732029309524633\n",
            "Loss in iteration no. 84296 ==> 0.30732028433713576\n",
            "Loss in iteration no. 84297 ==> 0.3073202755795421\n",
            "Loss in iteration no. 84298 ==> 0.30732026682246766\n",
            "Loss in iteration no. 84299 ==> 0.30732025806591\n",
            "Loss in iteration no. 84300 ==> 0.30732024930987134\n",
            "Loss in iteration no. 84301 ==> 0.3073202405543505\n",
            "Loss in iteration no. 84302 ==> 0.3073202317993474\n",
            "Loss in iteration no. 84303 ==> 0.30732022304486234\n",
            "Loss in iteration no. 84304 ==> 0.3073202142908944\n",
            "Loss in iteration no. 84305 ==> 0.3073202055374454\n",
            "Loss in iteration no. 84306 ==> 0.3073201967845144\n",
            "Loss in iteration no. 84307 ==> 0.30732018803210004\n",
            "Loss in iteration no. 84308 ==> 0.30732017928020455\n",
            "Loss in iteration no. 84309 ==> 0.30732017052882593\n",
            "Loss in iteration no. 84310 ==> 0.30732016177796556\n",
            "Loss in iteration no. 84311 ==> 0.3073201530276228\n",
            "Loss in iteration no. 84312 ==> 0.30732014427779764\n",
            "Loss in iteration no. 84313 ==> 0.3073201355284896\n",
            "Loss in iteration no. 84314 ==> 0.3073201267796991\n",
            "Loss in iteration no. 84315 ==> 0.30732011803142706\n",
            "Loss in iteration no. 84316 ==> 0.3073201092836721\n",
            "Loss in iteration no. 84317 ==> 0.3073201005364341\n",
            "Loss in iteration no. 84318 ==> 0.30732009178971403\n",
            "Loss in iteration no. 84319 ==> 0.3073200830435111\n",
            "Loss in iteration no. 84320 ==> 0.30732007429782543\n",
            "Loss in iteration no. 84321 ==> 0.3073200655526582\n",
            "Loss in iteration no. 84322 ==> 0.3073200568080067\n",
            "Loss in iteration no. 84323 ==> 0.3073200480638735\n",
            "Loss in iteration no. 84324 ==> 0.3073200393202572\n",
            "Loss in iteration no. 84325 ==> 0.3073200305771582\n",
            "Loss in iteration no. 84326 ==> 0.30732002183457674\n",
            "Loss in iteration no. 84327 ==> 0.3073200130925115\n",
            "Loss in iteration no. 84328 ==> 0.30732000435096385\n",
            "Loss in iteration no. 84329 ==> 0.30731999560993395\n",
            "Loss in iteration no. 84330 ==> 0.3073199868694201\n",
            "Loss in iteration no. 84331 ==> 0.30731997812942385\n",
            "Loss in iteration no. 84332 ==> 0.3073199693899447\n",
            "Loss in iteration no. 84333 ==> 0.307319960650982\n",
            "Loss in iteration no. 84334 ==> 0.30731995191253664\n",
            "Loss in iteration no. 84335 ==> 0.3073199431746077\n",
            "Loss in iteration no. 84336 ==> 0.30731993443719613\n",
            "Loss in iteration no. 84337 ==> 0.30731992570030126\n",
            "Loss in iteration no. 84338 ==> 0.30731991696392325\n",
            "Loss in iteration no. 84339 ==> 0.3073199082280618\n",
            "Loss in iteration no. 84340 ==> 0.3073198994927177\n",
            "Loss in iteration no. 84341 ==> 0.30731989075788935\n",
            "Loss in iteration no. 84342 ==> 0.3073198820235785\n",
            "Loss in iteration no. 84343 ==> 0.30731987328978333\n",
            "Loss in iteration no. 84344 ==> 0.307319864556506\n",
            "Loss in iteration no. 84345 ==> 0.30731985582374405\n",
            "Loss in iteration no. 84346 ==> 0.3073198470914991\n",
            "Loss in iteration no. 84347 ==> 0.307319838359771\n",
            "Loss in iteration no. 84348 ==> 0.30731982962855925\n",
            "Loss in iteration no. 84349 ==> 0.30731982089786386\n",
            "Loss in iteration no. 84350 ==> 0.30731981216768467\n",
            "Loss in iteration no. 84351 ==> 0.3073198034380221\n",
            "Loss in iteration no. 84352 ==> 0.3073197947088761\n",
            "Loss in iteration no. 84353 ==> 0.30731978598024634\n",
            "Loss in iteration no. 84354 ==> 0.30731977725213266\n",
            "Loss in iteration no. 84355 ==> 0.3073197685245348\n",
            "Loss in iteration no. 84356 ==> 0.3073197597974536\n",
            "Loss in iteration no. 84357 ==> 0.3073197510708894\n",
            "Loss in iteration no. 84358 ==> 0.3073197423448403\n",
            "Loss in iteration no. 84359 ==> 0.30731973361930737\n",
            "Loss in iteration no. 84360 ==> 0.30731972489429105\n",
            "Loss in iteration no. 84361 ==> 0.3073197161697906\n",
            "Loss in iteration no. 84362 ==> 0.30731970744580633\n",
            "Loss in iteration no. 84363 ==> 0.3073196987223378\n",
            "Loss in iteration no. 84364 ==> 0.30731968999938525\n",
            "Loss in iteration no. 84365 ==> 0.3073196812769487\n",
            "Loss in iteration no. 84366 ==> 0.30731967255502807\n",
            "Loss in iteration no. 84367 ==> 0.3073196638336232\n",
            "Loss in iteration no. 84368 ==> 0.30731965511273457\n",
            "Loss in iteration no. 84369 ==> 0.30731964639236137\n",
            "Loss in iteration no. 84370 ==> 0.30731963767250436\n",
            "Loss in iteration no. 84371 ==> 0.3073196289531621\n",
            "Loss in iteration no. 84372 ==> 0.307319620234336\n",
            "Loss in iteration no. 84373 ==> 0.30731961151602694\n",
            "Loss in iteration no. 84374 ==> 0.3073196027982316\n",
            "Loss in iteration no. 84375 ==> 0.30731959408095266\n",
            "Loss in iteration no. 84376 ==> 0.3073195853641897\n",
            "Loss in iteration no. 84377 ==> 0.3073195766479422\n",
            "Loss in iteration no. 84378 ==> 0.3073195679322097\n",
            "Loss in iteration no. 84379 ==> 0.30731955921699305\n",
            "Loss in iteration no. 84380 ==> 0.30731955050229204\n",
            "Loss in iteration no. 84381 ==> 0.3073195417881058\n",
            "Loss in iteration no. 84382 ==> 0.3073195330744355\n",
            "Loss in iteration no. 84383 ==> 0.3073195243612807\n",
            "Loss in iteration no. 84384 ==> 0.3073195156486408\n",
            "Loss in iteration no. 84385 ==> 0.30731950693651666\n",
            "Loss in iteration no. 84386 ==> 0.30731949822490706\n",
            "Loss in iteration no. 84387 ==> 0.30731948951381366\n",
            "Loss in iteration no. 84388 ==> 0.30731948080323546\n",
            "Loss in iteration no. 84389 ==> 0.30731947209317106\n",
            "Loss in iteration no. 84390 ==> 0.30731946338362326\n",
            "Loss in iteration no. 84391 ==> 0.3073194546745898\n",
            "Loss in iteration no. 84392 ==> 0.30731944596607214\n",
            "Loss in iteration no. 84393 ==> 0.3073194372580682\n",
            "Loss in iteration no. 84394 ==> 0.3073194285505803\n",
            "Loss in iteration no. 84395 ==> 0.3073194198436078\n",
            "Loss in iteration no. 84396 ==> 0.3073194111371498\n",
            "Loss in iteration no. 84397 ==> 0.30731940243120615\n",
            "Loss in iteration no. 84398 ==> 0.3073193937257777\n",
            "Loss in iteration no. 84399 ==> 0.3073193850208644\n",
            "Loss in iteration no. 84400 ==> 0.3073193763164658\n",
            "Loss in iteration no. 84401 ==> 0.30731936761258244\n",
            "Loss in iteration no. 84402 ==> 0.3073193589092128\n",
            "Loss in iteration no. 84403 ==> 0.30731935020635875\n",
            "Loss in iteration no. 84404 ==> 0.3073193415040195\n",
            "Loss in iteration no. 84405 ==> 0.30731933280219415\n",
            "Loss in iteration no. 84406 ==> 0.30731932410088414\n",
            "Loss in iteration no. 84407 ==> 0.30731931540008783\n",
            "Loss in iteration no. 84408 ==> 0.30731930669980734\n",
            "Loss in iteration no. 84409 ==> 0.3073192980000406\n",
            "Loss in iteration no. 84410 ==> 0.3073192893007883\n",
            "Loss in iteration no. 84411 ==> 0.307319280602051\n",
            "Loss in iteration no. 84412 ==> 0.30731927190382785\n",
            "Loss in iteration no. 84413 ==> 0.3073192632061189\n",
            "Loss in iteration no. 84414 ==> 0.3073192545089246\n",
            "Loss in iteration no. 84415 ==> 0.30731924581224473\n",
            "Loss in iteration no. 84416 ==> 0.30731923711607917\n",
            "Loss in iteration no. 84417 ==> 0.3073192284204278\n",
            "Loss in iteration no. 84418 ==> 0.30731921972529097\n",
            "Loss in iteration no. 84419 ==> 0.3073192110306678\n",
            "Loss in iteration no. 84420 ==> 0.307319202336559\n",
            "Loss in iteration no. 84421 ==> 0.30731919364296456\n",
            "Loss in iteration no. 84422 ==> 0.3073191849498843\n",
            "Loss in iteration no. 84423 ==> 0.3073191762573179\n",
            "Loss in iteration no. 84424 ==> 0.3073191675652659\n",
            "Loss in iteration no. 84425 ==> 0.3073191588737276\n",
            "Loss in iteration no. 84426 ==> 0.3073191501827032\n",
            "Loss in iteration no. 84427 ==> 0.30731914149219275\n",
            "Loss in iteration no. 84428 ==> 0.3073191328021969\n",
            "Loss in iteration no. 84429 ==> 0.30731912411271434\n",
            "Loss in iteration no. 84430 ==> 0.30731911542374546\n",
            "Loss in iteration no. 84431 ==> 0.30731910673529106\n",
            "Loss in iteration no. 84432 ==> 0.30731909804735086\n",
            "Loss in iteration no. 84433 ==> 0.30731908935992336\n",
            "Loss in iteration no. 84434 ==> 0.30731908067301045\n",
            "Loss in iteration no. 84435 ==> 0.3073190719866108\n",
            "Loss in iteration no. 84436 ==> 0.30731906330072445\n",
            "Loss in iteration no. 84437 ==> 0.30731905461535286\n",
            "Loss in iteration no. 84438 ==> 0.3073190459304939\n",
            "Loss in iteration no. 84439 ==> 0.3073190372461493\n",
            "Loss in iteration no. 84440 ==> 0.3073190285623171\n",
            "Loss in iteration no. 84441 ==> 0.30731901987899907\n",
            "Loss in iteration no. 84442 ==> 0.30731901119619537\n",
            "Loss in iteration no. 84443 ==> 0.3073190025139045\n",
            "Loss in iteration no. 84444 ==> 0.3073189938321271\n",
            "Loss in iteration no. 84445 ==> 0.3073189851508626\n",
            "Loss in iteration no. 84446 ==> 0.30731897647011175\n",
            "Loss in iteration no. 84447 ==> 0.30731896778987466\n",
            "Loss in iteration no. 84448 ==> 0.30731895911015034\n",
            "Loss in iteration no. 84449 ==> 0.30731895043093943\n",
            "Loss in iteration no. 84450 ==> 0.3073189417522421\n",
            "Loss in iteration no. 84451 ==> 0.3073189330740576\n",
            "Loss in iteration no. 84452 ==> 0.30731892439638603\n",
            "Loss in iteration no. 84453 ==> 0.3073189157192289\n",
            "Loss in iteration no. 84454 ==> 0.3073189070425841\n",
            "Loss in iteration no. 84455 ==> 0.3073188983664515\n",
            "Loss in iteration no. 84456 ==> 0.3073188896908327\n",
            "Loss in iteration no. 84457 ==> 0.3073188810157269\n",
            "Loss in iteration no. 84458 ==> 0.30731887234113475\n",
            "Loss in iteration no. 84459 ==> 0.3073188636670549\n",
            "Loss in iteration no. 84460 ==> 0.3073188549934875\n",
            "Loss in iteration no. 84461 ==> 0.3073188463204338\n",
            "Loss in iteration no. 84462 ==> 0.30731883764789275\n",
            "Loss in iteration no. 84463 ==> 0.30731882897586493\n",
            "Loss in iteration no. 84464 ==> 0.3073188203043496\n",
            "Loss in iteration no. 84465 ==> 0.3073188116333465\n",
            "Loss in iteration no. 84466 ==> 0.3073188029628566\n",
            "Loss in iteration no. 84467 ==> 0.3073187942928792\n",
            "Loss in iteration no. 84468 ==> 0.3073187856234144\n",
            "Loss in iteration no. 84469 ==> 0.3073187769544629\n",
            "Loss in iteration no. 84470 ==> 0.30731876828602417\n",
            "Loss in iteration no. 84471 ==> 0.3073187596180969\n",
            "Loss in iteration no. 84472 ==> 0.3073187509506828\n",
            "Loss in iteration no. 84473 ==> 0.3073187422837812\n",
            "Loss in iteration no. 84474 ==> 0.30731873361739165\n",
            "Loss in iteration no. 84475 ==> 0.307318724951515\n",
            "Loss in iteration no. 84476 ==> 0.30731871628615065\n",
            "Loss in iteration no. 84477 ==> 0.30731870762129904\n",
            "Loss in iteration no. 84478 ==> 0.3073186989569596\n",
            "Loss in iteration no. 84479 ==> 0.30731869029313197\n",
            "Loss in iteration no. 84480 ==> 0.30731868162981757\n",
            "Loss in iteration no. 84481 ==> 0.30731867296701443\n",
            "Loss in iteration no. 84482 ==> 0.3073186643047238\n",
            "Loss in iteration no. 84483 ==> 0.30731865564294647\n",
            "Loss in iteration no. 84484 ==> 0.30731864698168054\n",
            "Loss in iteration no. 84485 ==> 0.3073186383209261\n",
            "Loss in iteration no. 84486 ==> 0.3073186296606847\n",
            "Loss in iteration no. 84487 ==> 0.3073186210009544\n",
            "Loss in iteration no. 84488 ==> 0.30731861234173674\n",
            "Loss in iteration no. 84489 ==> 0.3073186036830314\n",
            "Loss in iteration no. 84490 ==> 0.3073185950248374\n",
            "Loss in iteration no. 84491 ==> 0.3073185863671562\n",
            "Loss in iteration no. 84492 ==> 0.3073185777099863\n",
            "Loss in iteration no. 84493 ==> 0.30731856905332866\n",
            "Loss in iteration no. 84494 ==> 0.3073185603971826\n",
            "Loss in iteration no. 84495 ==> 0.30731855174154776\n",
            "Loss in iteration no. 84496 ==> 0.30731854308642514\n",
            "Loss in iteration no. 84497 ==> 0.30731853443181456\n",
            "Loss in iteration no. 84498 ==> 0.3073185257777156\n",
            "Loss in iteration no. 84499 ==> 0.30731851712412894\n",
            "Loss in iteration no. 84500 ==> 0.30731850847105285\n",
            "Loss in iteration no. 84501 ==> 0.307318499818489\n",
            "Loss in iteration no. 84502 ==> 0.3073184911664369\n",
            "Loss in iteration no. 84503 ==> 0.30731848251489624\n",
            "Loss in iteration no. 84504 ==> 0.3073184738638669\n",
            "Loss in iteration no. 84505 ==> 0.30731846521334893\n",
            "Loss in iteration no. 84506 ==> 0.30731845656334283\n",
            "Loss in iteration no. 84507 ==> 0.30731844791384844\n",
            "Loss in iteration no. 84508 ==> 0.3073184392648649\n",
            "Loss in iteration no. 84509 ==> 0.307318430616393\n",
            "Loss in iteration no. 84510 ==> 0.3073184219684318\n",
            "Loss in iteration no. 84511 ==> 0.3073184133209828\n",
            "Loss in iteration no. 84512 ==> 0.3073184046740444\n",
            "Loss in iteration no. 84513 ==> 0.3073183960276176\n",
            "Loss in iteration no. 84514 ==> 0.30731838738170186\n",
            "Loss in iteration no. 84515 ==> 0.3073183787362983\n",
            "Loss in iteration no. 84516 ==> 0.30731837009140517\n",
            "Loss in iteration no. 84517 ==> 0.30731836144702296\n",
            "Loss in iteration no. 84518 ==> 0.3073183528031517\n",
            "Loss in iteration no. 84519 ==> 0.3073183441597921\n",
            "Loss in iteration no. 84520 ==> 0.30731833551694326\n",
            "Loss in iteration no. 84521 ==> 0.30731832687460525\n",
            "Loss in iteration no. 84522 ==> 0.3073183182327779\n",
            "Loss in iteration no. 84523 ==> 0.3073183095914623\n",
            "Loss in iteration no. 84524 ==> 0.30731830095065726\n",
            "Loss in iteration no. 84525 ==> 0.30731829231036295\n",
            "Loss in iteration no. 84526 ==> 0.30731828367057945\n",
            "Loss in iteration no. 84527 ==> 0.3073182750313071\n",
            "Loss in iteration no. 84528 ==> 0.30731826639254584\n",
            "Loss in iteration no. 84529 ==> 0.30731825775429467\n",
            "Loss in iteration no. 84530 ==> 0.30731824911655437\n",
            "Loss in iteration no. 84531 ==> 0.3073182404793248\n",
            "Loss in iteration no. 84532 ==> 0.3073182318426057\n",
            "Loss in iteration no. 84533 ==> 0.3073182232063977\n",
            "Loss in iteration no. 84534 ==> 0.3073182145706998\n",
            "Loss in iteration no. 84535 ==> 0.30731820593551284\n",
            "Loss in iteration no. 84536 ==> 0.307318197300836\n",
            "Loss in iteration no. 84537 ==> 0.30731818866667027\n",
            "Loss in iteration no. 84538 ==> 0.3073181800330141\n",
            "Loss in iteration no. 84539 ==> 0.3073181713998689\n",
            "Loss in iteration no. 84540 ==> 0.30731816276723484\n",
            "Loss in iteration no. 84541 ==> 0.3073181541351099\n",
            "Loss in iteration no. 84542 ==> 0.3073181455034963\n",
            "Loss in iteration no. 84543 ==> 0.30731813687239223\n",
            "Loss in iteration no. 84544 ==> 0.30731812824179927\n",
            "Loss in iteration no. 84545 ==> 0.3073181196117156\n",
            "Loss in iteration no. 84546 ==> 0.307318110982143\n",
            "Loss in iteration no. 84547 ==> 0.30731810235308\n",
            "Loss in iteration no. 84548 ==> 0.3073180937245274\n",
            "Loss in iteration no. 84549 ==> 0.3073180850964851\n",
            "Loss in iteration no. 84550 ==> 0.3073180764689524\n",
            "Loss in iteration no. 84551 ==> 0.3073180678419297\n",
            "Loss in iteration no. 84552 ==> 0.30731805921541716\n",
            "Loss in iteration no. 84553 ==> 0.3073180505894152\n",
            "Loss in iteration no. 84554 ==> 0.30731804196392265\n",
            "Loss in iteration no. 84555 ==> 0.3073180333389404\n",
            "Loss in iteration no. 84556 ==> 0.3073180247144677\n",
            "Loss in iteration no. 84557 ==> 0.307318016090505\n",
            "Loss in iteration no. 84558 ==> 0.30731800746705296\n",
            "Loss in iteration no. 84559 ==> 0.3073179988441096\n",
            "Loss in iteration no. 84560 ==> 0.3073179902216766\n",
            "Loss in iteration no. 84561 ==> 0.3073179815997531\n",
            "Loss in iteration no. 84562 ==> 0.3073179729783389\n",
            "Loss in iteration no. 84563 ==> 0.30731796435743497\n",
            "Loss in iteration no. 84564 ==> 0.3073179557370406\n",
            "Loss in iteration no. 84565 ==> 0.3073179471171559\n",
            "Loss in iteration no. 84566 ==> 0.30731793849778055\n",
            "Loss in iteration no. 84567 ==> 0.3073179298789147\n",
            "Loss in iteration no. 84568 ==> 0.3073179212605591\n",
            "Loss in iteration no. 84569 ==> 0.30731791264271235\n",
            "Loss in iteration no. 84570 ==> 0.30731790402537523\n",
            "Loss in iteration no. 84571 ==> 0.3073178954085477\n",
            "Loss in iteration no. 84572 ==> 0.30731788679222877\n",
            "Loss in iteration no. 84573 ==> 0.30731787817642015\n",
            "Loss in iteration no. 84574 ==> 0.3073178695611208\n",
            "Loss in iteration no. 84575 ==> 0.30731786094633035\n",
            "Loss in iteration no. 84576 ==> 0.3073178523320495\n",
            "Loss in iteration no. 84577 ==> 0.3073178437182773\n",
            "Loss in iteration no. 84578 ==> 0.30731783510501454\n",
            "Loss in iteration no. 84579 ==> 0.3073178264922613\n",
            "Loss in iteration no. 84580 ==> 0.30731781788001766\n",
            "Loss in iteration no. 84581 ==> 0.3073178092682817\n",
            "Loss in iteration no. 84582 ==> 0.30731780065705566\n",
            "Loss in iteration no. 84583 ==> 0.30731779204633924\n",
            "Loss in iteration no. 84584 ==> 0.30731778343613053\n",
            "Loss in iteration no. 84585 ==> 0.30731777482643247\n",
            "Loss in iteration no. 84586 ==> 0.30731776621724244\n",
            "Loss in iteration no. 84587 ==> 0.3073177576085608\n",
            "Loss in iteration no. 84588 ==> 0.30731774900038866\n",
            "Loss in iteration no. 84589 ==> 0.3073177403927253\n",
            "Loss in iteration no. 84590 ==> 0.3073177317855712\n",
            "Loss in iteration no. 84591 ==> 0.3073177231789249\n",
            "Loss in iteration no. 84592 ==> 0.3073177145727888\n",
            "Loss in iteration no. 84593 ==> 0.30731770596716046\n",
            "Loss in iteration no. 84594 ==> 0.30731769736204095\n",
            "Loss in iteration no. 84595 ==> 0.3073176887574301\n",
            "Loss in iteration no. 84596 ==> 0.30731768015332855\n",
            "Loss in iteration no. 84597 ==> 0.3073176715497347\n",
            "Loss in iteration no. 84598 ==> 0.30731766294665014\n",
            "Loss in iteration no. 84599 ==> 0.3073176543440734\n",
            "Loss in iteration no. 84600 ==> 0.3073176457420055\n",
            "Loss in iteration no. 84601 ==> 0.30731763714044685\n",
            "Loss in iteration no. 84602 ==> 0.30731762853939526\n",
            "Loss in iteration no. 84603 ==> 0.3073176199388529\n",
            "Loss in iteration no. 84604 ==> 0.307317611338819\n",
            "Loss in iteration no. 84605 ==> 0.30731760273929337\n",
            "Loss in iteration no. 84606 ==> 0.30731759414027643\n",
            "Loss in iteration no. 84607 ==> 0.30731758554176725\n",
            "Loss in iteration no. 84608 ==> 0.3073175769437666\n",
            "Loss in iteration no. 84609 ==> 0.30731756834627355\n",
            "Loss in iteration no. 84610 ==> 0.3073175597492898\n",
            "Loss in iteration no. 84611 ==> 0.30731755115281373\n",
            "Loss in iteration no. 84612 ==> 0.3073175425568456\n",
            "Loss in iteration no. 84613 ==> 0.30731753396138567\n",
            "Loss in iteration no. 84614 ==> 0.3073175253664342\n",
            "Loss in iteration no. 84615 ==> 0.3073175167719904\n",
            "Loss in iteration no. 84616 ==> 0.30731750817805487\n",
            "Loss in iteration no. 84617 ==> 0.3073174995846272\n",
            "Loss in iteration no. 84618 ==> 0.3073174909917069\n",
            "Loss in iteration no. 84619 ==> 0.3073174823992957\n",
            "Loss in iteration no. 84620 ==> 0.3073174738073912\n",
            "Loss in iteration no. 84621 ==> 0.3073174652159951\n",
            "Loss in iteration no. 84622 ==> 0.30731745662510734\n",
            "Loss in iteration no. 84623 ==> 0.3073174480347271\n",
            "Loss in iteration no. 84624 ==> 0.3073174394448541\n",
            "Loss in iteration no. 84625 ==> 0.30731743085548974\n",
            "Loss in iteration no. 84626 ==> 0.3073174222666321\n",
            "Loss in iteration no. 84627 ==> 0.30731741367828286\n",
            "Loss in iteration no. 84628 ==> 0.3073174050904411\n",
            "Loss in iteration no. 84629 ==> 0.30731739650310674\n",
            "Loss in iteration no. 84630 ==> 0.3073173879162797\n",
            "Loss in iteration no. 84631 ==> 0.3073173793299609\n",
            "Loss in iteration no. 84632 ==> 0.3073173707441495\n",
            "Loss in iteration no. 84633 ==> 0.30731736215884503\n",
            "Loss in iteration no. 84634 ==> 0.30731735357404827\n",
            "Loss in iteration no. 84635 ==> 0.30731734498975943\n",
            "Loss in iteration no. 84636 ==> 0.30731733640597825\n",
            "Loss in iteration no. 84637 ==> 0.307317327822703\n",
            "Loss in iteration no. 84638 ==> 0.3073173192399359\n",
            "Loss in iteration no. 84639 ==> 0.3073173106576765\n",
            "Loss in iteration no. 84640 ==> 0.3073173020759235\n",
            "Loss in iteration no. 84641 ==> 0.3073172934946787\n",
            "Loss in iteration no. 84642 ==> 0.3073172849139402\n",
            "Loss in iteration no. 84643 ==> 0.30731727633370987\n",
            "Loss in iteration no. 84644 ==> 0.30731726775398593\n",
            "Loss in iteration no. 84645 ==> 0.30731725917476904\n",
            "Loss in iteration no. 84646 ==> 0.3073172505960595\n",
            "Loss in iteration no. 84647 ==> 0.3073172420178573\n",
            "Loss in iteration no. 84648 ==> 0.307317233440162\n",
            "Loss in iteration no. 84649 ==> 0.3073172248629735\n",
            "Loss in iteration no. 84650 ==> 0.30731721628629205\n",
            "Loss in iteration no. 84651 ==> 0.3073172077101169\n",
            "Loss in iteration no. 84652 ==> 0.30731719913444955\n",
            "Loss in iteration no. 84653 ==> 0.3073171905592887\n",
            "Loss in iteration no. 84654 ==> 0.30731718198463515\n",
            "Loss in iteration no. 84655 ==> 0.3073171734104875\n",
            "Loss in iteration no. 84656 ==> 0.3073171648368478\n",
            "Loss in iteration no. 84657 ==> 0.3073171562637135\n",
            "Loss in iteration no. 84658 ==> 0.30731714769108687\n",
            "Loss in iteration no. 84659 ==> 0.30731713911896646\n",
            "Loss in iteration no. 84660 ==> 0.30731713054735277\n",
            "Loss in iteration no. 84661 ==> 0.30731712197624583\n",
            "Loss in iteration no. 84662 ==> 0.30731711340564555\n",
            "Loss in iteration no. 84663 ==> 0.3073171048355515\n",
            "Loss in iteration no. 84664 ==> 0.3073170962659644\n",
            "Loss in iteration no. 84665 ==> 0.3073170876968834\n",
            "Loss in iteration no. 84666 ==> 0.3073170791283091\n",
            "Loss in iteration no. 84667 ==> 0.30731707056024155\n",
            "Loss in iteration no. 84668 ==> 0.30731706199267983\n",
            "Loss in iteration no. 84669 ==> 0.3073170534256247\n",
            "Loss in iteration no. 84670 ==> 0.3073170448590753\n",
            "Loss in iteration no. 84671 ==> 0.3073170362930334\n",
            "Loss in iteration no. 84672 ==> 0.3073170277274968\n",
            "Loss in iteration no. 84673 ==> 0.30731701916246645\n",
            "Loss in iteration no. 84674 ==> 0.3073170105979435\n",
            "Loss in iteration no. 84675 ==> 0.30731700203392553\n",
            "Loss in iteration no. 84676 ==> 0.307316993470414\n",
            "Loss in iteration no. 84677 ==> 0.30731698490740844\n",
            "Loss in iteration no. 84678 ==> 0.30731697634490934\n",
            "Loss in iteration no. 84679 ==> 0.3073169677829164\n",
            "Loss in iteration no. 84680 ==> 0.3073169592214293\n",
            "Loss in iteration no. 84681 ==> 0.30731695066044795\n",
            "Loss in iteration no. 84682 ==> 0.307316942099973\n",
            "Loss in iteration no. 84683 ==> 0.30731693354000367\n",
            "Loss in iteration no. 84684 ==> 0.3073169249805399\n",
            "Loss in iteration no. 84685 ==> 0.3073169164215822\n",
            "Loss in iteration no. 84686 ==> 0.3073169078631308\n",
            "Loss in iteration no. 84687 ==> 0.3073168993051846\n",
            "Loss in iteration no. 84688 ==> 0.3073168907477445\n",
            "Loss in iteration no. 84689 ==> 0.3073168821908107\n",
            "Loss in iteration no. 84690 ==> 0.3073168736343816\n",
            "Loss in iteration no. 84691 ==> 0.3073168650784583\n",
            "Loss in iteration no. 84692 ==> 0.30731685652304125\n",
            "Loss in iteration no. 84693 ==> 0.3073168479681294\n",
            "Loss in iteration no. 84694 ==> 0.3073168394137235\n",
            "Loss in iteration no. 84695 ==> 0.3073168308598228\n",
            "Loss in iteration no. 84696 ==> 0.307316822306428\n",
            "Loss in iteration no. 84697 ==> 0.3073168137535385\n",
            "Loss in iteration no. 84698 ==> 0.3073168052011543\n",
            "Loss in iteration no. 84699 ==> 0.3073167966492758\n",
            "Loss in iteration no. 84700 ==> 0.307316788097902\n",
            "Loss in iteration no. 84701 ==> 0.30731677954703424\n",
            "Loss in iteration no. 84702 ==> 0.3073167709966722\n",
            "Loss in iteration no. 84703 ==> 0.30731676244681516\n",
            "Loss in iteration no. 84704 ==> 0.30731675389746305\n",
            "Loss in iteration no. 84705 ==> 0.30731674534861564\n",
            "Loss in iteration no. 84706 ==> 0.30731673680027516\n",
            "Loss in iteration no. 84707 ==> 0.30731672825243883\n",
            "Loss in iteration no. 84708 ==> 0.3073167197051071\n",
            "Loss in iteration no. 84709 ==> 0.3073167111582816\n",
            "Loss in iteration no. 84710 ==> 0.30731670261196087\n",
            "Loss in iteration no. 84711 ==> 0.3073166940661441\n",
            "Loss in iteration no. 84712 ==> 0.30731668552083385\n",
            "Loss in iteration no. 84713 ==> 0.30731667697602805\n",
            "Loss in iteration no. 84714 ==> 0.30731666843172695\n",
            "Loss in iteration no. 84715 ==> 0.3073166598879311\n",
            "Loss in iteration no. 84716 ==> 0.3073166513446397\n",
            "Loss in iteration no. 84717 ==> 0.3073166428018539\n",
            "Loss in iteration no. 84718 ==> 0.3073166342595728\n",
            "Loss in iteration no. 84719 ==> 0.30731662571779594\n",
            "Loss in iteration no. 84720 ==> 0.30731661717652486\n",
            "Loss in iteration no. 84721 ==> 0.3073166086357574\n",
            "Loss in iteration no. 84722 ==> 0.3073166000954951\n",
            "Loss in iteration no. 84723 ==> 0.3073165915557381\n",
            "Loss in iteration no. 84724 ==> 0.3073165830164845\n",
            "Loss in iteration no. 84725 ==> 0.30731657447773664\n",
            "Loss in iteration no. 84726 ==> 0.307316565939493\n",
            "Loss in iteration no. 84727 ==> 0.30731655740175345\n",
            "Loss in iteration no. 84728 ==> 0.30731654886451854\n",
            "Loss in iteration no. 84729 ==> 0.30731654032778893\n",
            "Loss in iteration no. 84730 ==> 0.3073165317915635\n",
            "Loss in iteration no. 84731 ==> 0.3073165232558418\n",
            "Loss in iteration no. 84732 ==> 0.3073165147206258\n",
            "Loss in iteration no. 84733 ==> 0.3073165061859132\n",
            "Loss in iteration no. 84734 ==> 0.3073164976517048\n",
            "Loss in iteration no. 84735 ==> 0.3073164891180012\n",
            "Loss in iteration no. 84736 ==> 0.3073164805848013\n",
            "Loss in iteration no. 84737 ==> 0.3073164720521069\n",
            "Loss in iteration no. 84738 ==> 0.3073164635199157\n",
            "Loss in iteration no. 84739 ==> 0.307316454988229\n",
            "Loss in iteration no. 84740 ==> 0.30731644645704653\n",
            "Loss in iteration no. 84741 ==> 0.30731643792636804\n",
            "Loss in iteration no. 84742 ==> 0.3073164293961928\n",
            "Loss in iteration no. 84743 ==> 0.3073164208665226\n",
            "Loss in iteration no. 84744 ==> 0.3073164123373569\n",
            "Loss in iteration no. 84745 ==> 0.30731640380869385\n",
            "Loss in iteration no. 84746 ==> 0.30731639528053606\n",
            "Loss in iteration no. 84747 ==> 0.30731638675288164\n",
            "Loss in iteration no. 84748 ==> 0.3073163782257315\n",
            "Loss in iteration no. 84749 ==> 0.30731636969908455\n",
            "Loss in iteration no. 84750 ==> 0.30731636117294164\n",
            "Loss in iteration no. 84751 ==> 0.3073163526473027\n",
            "Loss in iteration no. 84752 ==> 0.30731634412216774\n",
            "Loss in iteration no. 84753 ==> 0.3073163355975358\n",
            "Loss in iteration no. 84754 ==> 0.3073163270734086\n",
            "Loss in iteration no. 84755 ==> 0.3073163185497849\n",
            "Loss in iteration no. 84756 ==> 0.30731631002666393\n",
            "Loss in iteration no. 84757 ==> 0.3073163015040473\n",
            "Loss in iteration no. 84758 ==> 0.30731629298193464\n",
            "Loss in iteration no. 84759 ==> 0.3073162844603249\n",
            "Loss in iteration no. 84760 ==> 0.30731627593921884\n",
            "Loss in iteration no. 84761 ==> 0.30731626741861656\n",
            "Loss in iteration no. 84762 ==> 0.3073162588985178\n",
            "Loss in iteration no. 84763 ==> 0.30731625037892174\n",
            "Loss in iteration no. 84764 ==> 0.3073162418598301\n",
            "Loss in iteration no. 84765 ==> 0.3073162333412416\n",
            "Loss in iteration no. 84766 ==> 0.3073162248231557\n",
            "Loss in iteration no. 84767 ==> 0.30731621630557376\n",
            "Loss in iteration no. 84768 ==> 0.3073162077884951\n",
            "Loss in iteration no. 84769 ==> 0.30731619927191994\n",
            "Loss in iteration no. 84770 ==> 0.30731619075584726\n",
            "Loss in iteration no. 84771 ==> 0.3073161822402776\n",
            "Loss in iteration no. 84772 ==> 0.3073161737252125\n",
            "Loss in iteration no. 84773 ==> 0.30731616521064975\n",
            "Loss in iteration no. 84774 ==> 0.3073161566965902\n",
            "Loss in iteration no. 84775 ==> 0.30731614818303365\n",
            "Loss in iteration no. 84776 ==> 0.30731613966997934\n",
            "Loss in iteration no. 84777 ==> 0.30731613115742956\n",
            "Loss in iteration no. 84778 ==> 0.30731612264538183\n",
            "Loss in iteration no. 84779 ==> 0.30731611413383686\n",
            "Loss in iteration no. 84780 ==> 0.3073161056227954\n",
            "Loss in iteration no. 84781 ==> 0.30731609711225666\n",
            "Loss in iteration no. 84782 ==> 0.3073160886022204\n",
            "Loss in iteration no. 84783 ==> 0.3073160800926875\n",
            "Loss in iteration no. 84784 ==> 0.30731607158365704\n",
            "Loss in iteration no. 84785 ==> 0.307316063075129\n",
            "Loss in iteration no. 84786 ==> 0.3073160545671044\n",
            "Loss in iteration no. 84787 ==> 0.3073160460595824\n",
            "Loss in iteration no. 84788 ==> 0.30731603755256254\n",
            "Loss in iteration no. 84789 ==> 0.30731602904604644\n",
            "Loss in iteration no. 84790 ==> 0.3073160205400319\n",
            "Loss in iteration no. 84791 ==> 0.30731601203452047\n",
            "Loss in iteration no. 84792 ==> 0.307316003529511\n",
            "Loss in iteration no. 84793 ==> 0.30731599502500456\n",
            "Loss in iteration no. 84794 ==> 0.3073159865210009\n",
            "Loss in iteration no. 84795 ==> 0.3073159780174994\n",
            "Loss in iteration no. 84796 ==> 0.3073159695144999\n",
            "Loss in iteration no. 84797 ==> 0.3073159610120031\n",
            "Loss in iteration no. 84798 ==> 0.3073159525100089\n",
            "Loss in iteration no. 84799 ==> 0.3073159440085165\n",
            "Loss in iteration no. 84800 ==> 0.30731593550752667\n",
            "Loss in iteration no. 84801 ==> 0.3073159270070393\n",
            "Loss in iteration no. 84802 ==> 0.3073159185070533\n",
            "Loss in iteration no. 84803 ==> 0.3073159100075706\n",
            "Loss in iteration no. 84804 ==> 0.3073159015085897\n",
            "Loss in iteration no. 84805 ==> 0.3073158930101109\n",
            "Loss in iteration no. 84806 ==> 0.30731588451213426\n",
            "Loss in iteration no. 84807 ==> 0.30731587601465993\n",
            "Loss in iteration no. 84808 ==> 0.3073158675176867\n",
            "Loss in iteration no. 84809 ==> 0.3073158590212171\n",
            "Loss in iteration no. 84810 ==> 0.307315850525248\n",
            "Loss in iteration no. 84811 ==> 0.30731584202978196\n",
            "Loss in iteration no. 84812 ==> 0.3073158335348171\n",
            "Loss in iteration no. 84813 ==> 0.30731582504035454\n",
            "Loss in iteration no. 84814 ==> 0.3073158165463936\n",
            "Loss in iteration no. 84815 ==> 0.30731580805293457\n",
            "Loss in iteration no. 84816 ==> 0.3073157995599772\n",
            "Loss in iteration no. 84817 ==> 0.3073157910675216\n",
            "Loss in iteration no. 84818 ==> 0.3073157825755684\n",
            "Loss in iteration no. 84819 ==> 0.30731577408411603\n",
            "Loss in iteration no. 84820 ==> 0.3073157655931659\n",
            "Loss in iteration no. 84821 ==> 0.30731575710271725\n",
            "Loss in iteration no. 84822 ==> 0.30731574861277083\n",
            "Loss in iteration no. 84823 ==> 0.3073157401233248\n",
            "Loss in iteration no. 84824 ==> 0.30731573163438164\n",
            "Loss in iteration no. 84825 ==> 0.3073157231459387\n",
            "Loss in iteration no. 84826 ==> 0.3073157146579978\n",
            "Loss in iteration no. 84827 ==> 0.3073157061705586\n",
            "Loss in iteration no. 84828 ==> 0.3073156976836204\n",
            "Loss in iteration no. 84829 ==> 0.30731568919718383\n",
            "Loss in iteration no. 84830 ==> 0.3073156807112488\n",
            "Loss in iteration no. 84831 ==> 0.30731567222581463\n",
            "Loss in iteration no. 84832 ==> 0.3073156637408831\n",
            "Loss in iteration no. 84833 ==> 0.3073156552564517\n",
            "Loss in iteration no. 84834 ==> 0.30731564677252154\n",
            "Loss in iteration no. 84835 ==> 0.3073156382890928\n",
            "Loss in iteration no. 84836 ==> 0.30731562980616506\n",
            "Loss in iteration no. 84837 ==> 0.3073156213237386\n",
            "Loss in iteration no. 84838 ==> 0.3073156128418134\n",
            "Loss in iteration no. 84839 ==> 0.3073156043603898\n",
            "Loss in iteration no. 84840 ==> 0.307315595879466\n",
            "Loss in iteration no. 84841 ==> 0.30731558739904397\n",
            "Loss in iteration no. 84842 ==> 0.30731557891912314\n",
            "Loss in iteration no. 84843 ==> 0.3073155704397033\n",
            "Loss in iteration no. 84844 ==> 0.30731556196078336\n",
            "Loss in iteration no. 84845 ==> 0.3073155534823659\n",
            "Loss in iteration no. 84846 ==> 0.3073155450044485\n",
            "Loss in iteration no. 84847 ==> 0.30731553652703153\n",
            "Loss in iteration no. 84848 ==> 0.30731552805011575\n",
            "Loss in iteration no. 84849 ==> 0.3073155195737013\n",
            "Loss in iteration no. 84850 ==> 0.30731551109778676\n",
            "Loss in iteration no. 84851 ==> 0.30731550262237345\n",
            "Loss in iteration no. 84852 ==> 0.3073154941474607\n",
            "Loss in iteration no. 84853 ==> 0.3073154856730486\n",
            "Loss in iteration no. 84854 ==> 0.30731547719913777\n",
            "Loss in iteration no. 84855 ==> 0.3073154687257263\n",
            "Loss in iteration no. 84856 ==> 0.3073154602528162\n",
            "Loss in iteration no. 84857 ==> 0.3073154517804069\n",
            "Loss in iteration no. 84858 ==> 0.3073154433084969\n",
            "Loss in iteration no. 84859 ==> 0.30731543483708856\n",
            "Loss in iteration no. 84860 ==> 0.3073154263661799\n",
            "Loss in iteration no. 84861 ==> 0.30731541789577294\n",
            "Loss in iteration no. 84862 ==> 0.30731540942586466\n",
            "Loss in iteration no. 84863 ==> 0.3073154009564573\n",
            "Loss in iteration no. 84864 ==> 0.3073153924875513\n",
            "Loss in iteration no. 84865 ==> 0.3073153840191447\n",
            "Loss in iteration no. 84866 ==> 0.3073153755512385\n",
            "Loss in iteration no. 84867 ==> 0.3073153670838324\n",
            "Loss in iteration no. 84868 ==> 0.30731535861692644\n",
            "Loss in iteration no. 84869 ==> 0.3073153501505206\n",
            "Loss in iteration no. 84870 ==> 0.3073153416846155\n",
            "Loss in iteration no. 84871 ==> 0.3073153332192103\n",
            "Loss in iteration no. 84872 ==> 0.30731532475430495\n",
            "Loss in iteration no. 84873 ==> 0.30731531628989933\n",
            "Loss in iteration no. 84874 ==> 0.30731530782599437\n",
            "Loss in iteration no. 84875 ==> 0.3073152993625889\n",
            "Loss in iteration no. 84876 ==> 0.30731529089968374\n",
            "Loss in iteration no. 84877 ==> 0.3073152824372783\n",
            "Loss in iteration no. 84878 ==> 0.3073152739753737\n",
            "Loss in iteration no. 84879 ==> 0.3073152655139678\n",
            "Loss in iteration no. 84880 ==> 0.30731525705306184\n",
            "Loss in iteration no. 84881 ==> 0.30731524859265597\n",
            "Loss in iteration no. 84882 ==> 0.3073152401327501\n",
            "Loss in iteration no. 84883 ==> 0.3073152316733432\n",
            "Loss in iteration no. 84884 ==> 0.30731522321443655\n",
            "Loss in iteration no. 84885 ==> 0.30731521475602963\n",
            "Loss in iteration no. 84886 ==> 0.3073152062981216\n",
            "Loss in iteration no. 84887 ==> 0.3073151978407147\n",
            "Loss in iteration no. 84888 ==> 0.3073151893838058\n",
            "Loss in iteration no. 84889 ==> 0.307315180927398\n",
            "Loss in iteration no. 84890 ==> 0.3073151724714886\n",
            "Loss in iteration no. 84891 ==> 0.3073151640160786\n",
            "Loss in iteration no. 84892 ==> 0.3073151555611688\n",
            "Loss in iteration no. 84893 ==> 0.3073151471067579\n",
            "Loss in iteration no. 84894 ==> 0.3073151386528463\n",
            "Loss in iteration no. 84895 ==> 0.30731513019943446\n",
            "Loss in iteration no. 84896 ==> 0.30731512174652253\n",
            "Loss in iteration no. 84897 ==> 0.3073151132941094\n",
            "Loss in iteration no. 84898 ==> 0.307315104842195\n",
            "Loss in iteration no. 84899 ==> 0.30731509639078025\n",
            "Loss in iteration no. 84900 ==> 0.3073150879398649\n",
            "Loss in iteration no. 84901 ==> 0.30731507948944814\n",
            "Loss in iteration no. 84902 ==> 0.30731507103953093\n",
            "Loss in iteration no. 84903 ==> 0.30731506259011326\n",
            "Loss in iteration no. 84904 ==> 0.30731505414119403\n",
            "Loss in iteration no. 84905 ==> 0.30731504569277385\n",
            "Loss in iteration no. 84906 ==> 0.30731503724485365\n",
            "Loss in iteration no. 84907 ==> 0.30731502879743156\n",
            "Loss in iteration no. 84908 ==> 0.3073150203505088\n",
            "Loss in iteration no. 84909 ==> 0.30731501190408494\n",
            "Loss in iteration no. 84910 ==> 0.3073150034581599\n",
            "Loss in iteration no. 84911 ==> 0.30731499501273346\n",
            "Loss in iteration no. 84912 ==> 0.30731498656780654\n",
            "Loss in iteration no. 84913 ==> 0.30731497812337777\n",
            "Loss in iteration no. 84914 ==> 0.30731496967944827\n",
            "Loss in iteration no. 84915 ==> 0.30731496123601726\n",
            "Loss in iteration no. 84916 ==> 0.30731495279308507\n",
            "Loss in iteration no. 84917 ==> 0.30731494435065193\n",
            "Loss in iteration no. 84918 ==> 0.3073149359087169\n",
            "Loss in iteration no. 84919 ==> 0.30731492746728056\n",
            "Loss in iteration no. 84920 ==> 0.30731491902634295\n",
            "Loss in iteration no. 84921 ==> 0.3073149105859043\n",
            "Loss in iteration no. 84922 ==> 0.3073149021459632\n",
            "Loss in iteration no. 84923 ==> 0.30731489370652104\n",
            "Loss in iteration no. 84924 ==> 0.3073148852675784\n",
            "Loss in iteration no. 84925 ==> 0.3073148768291326\n",
            "Loss in iteration no. 84926 ==> 0.3073148683911866\n",
            "Loss in iteration no. 84927 ==> 0.3073148599537377\n",
            "Loss in iteration no. 84928 ==> 0.30731485151678883\n",
            "Loss in iteration no. 84929 ==> 0.30731484308033735\n",
            "Loss in iteration no. 84930 ==> 0.3073148346443836\n",
            "Loss in iteration no. 84931 ==> 0.30731482620892847\n",
            "Loss in iteration no. 84932 ==> 0.3073148177739717\n",
            "Loss in iteration no. 84933 ==> 0.3073148093395134\n",
            "Loss in iteration no. 84934 ==> 0.3073148009055533\n",
            "Loss in iteration no. 84935 ==> 0.3073147924720911\n",
            "Loss in iteration no. 84936 ==> 0.30731478403912743\n",
            "Loss in iteration no. 84937 ==> 0.30731477560666104\n",
            "Loss in iteration no. 84938 ==> 0.30731476717469275\n",
            "Loss in iteration no. 84939 ==> 0.3073147587432232\n",
            "Loss in iteration no. 84940 ==> 0.3073147503122515\n",
            "Loss in iteration no. 84941 ==> 0.3073147418817776\n",
            "Loss in iteration no. 84942 ==> 0.30731473345180144\n",
            "Loss in iteration no. 84943 ==> 0.307314725022323\n",
            "Loss in iteration no. 84944 ==> 0.3073147165933429\n",
            "Loss in iteration no. 84945 ==> 0.3073147081648605\n",
            "Loss in iteration no. 84946 ==> 0.3073146997368762\n",
            "Loss in iteration no. 84947 ==> 0.3073146913093894\n",
            "Loss in iteration no. 84948 ==> 0.3073146828823999\n",
            "Loss in iteration no. 84949 ==> 0.307314674455908\n",
            "Loss in iteration no. 84950 ==> 0.30731466602991453\n",
            "Loss in iteration no. 84951 ==> 0.307314657604419\n",
            "Loss in iteration no. 84952 ==> 0.3073146491794205\n",
            "Loss in iteration no. 84953 ==> 0.30731464075491977\n",
            "Loss in iteration no. 84954 ==> 0.30731463233091644\n",
            "Loss in iteration no. 84955 ==> 0.30731462390741027\n",
            "Loss in iteration no. 84956 ==> 0.30731461548440236\n",
            "Loss in iteration no. 84957 ==> 0.3073146070618921\n",
            "Loss in iteration no. 84958 ==> 0.307314598639878\n",
            "Loss in iteration no. 84959 ==> 0.3073145902183625\n",
            "Loss in iteration no. 84960 ==> 0.30731458179734433\n",
            "Loss in iteration no. 84961 ==> 0.3073145733768229\n",
            "Loss in iteration no. 84962 ==> 0.307314564956799\n",
            "Loss in iteration no. 84963 ==> 0.30731455653727313\n",
            "Loss in iteration no. 84964 ==> 0.30731454811824294\n",
            "Loss in iteration no. 84965 ==> 0.3073145396997117\n",
            "Loss in iteration no. 84966 ==> 0.30731453128167613\n",
            "Loss in iteration no. 84967 ==> 0.3073145228641386\n",
            "Loss in iteration no. 84968 ==> 0.3073145144470982\n",
            "Loss in iteration no. 84969 ==> 0.3073145060305548\n",
            "Loss in iteration no. 84970 ==> 0.3073144976145085\n",
            "Loss in iteration no. 84971 ==> 0.3073144891989587\n",
            "Loss in iteration no. 84972 ==> 0.3073144807839065\n",
            "Loss in iteration no. 84973 ==> 0.3073144723693511\n",
            "Loss in iteration no. 84974 ==> 0.30731446395529277\n",
            "Loss in iteration no. 84975 ==> 0.3073144555417312\n",
            "Loss in iteration no. 84976 ==> 0.3073144471286669\n",
            "Loss in iteration no. 84977 ==> 0.30731443871609876\n",
            "Loss in iteration no. 84978 ==> 0.30731443030402866\n",
            "Loss in iteration no. 84979 ==> 0.3073144218924541\n",
            "Loss in iteration no. 84980 ==> 0.307314413481377\n",
            "Loss in iteration no. 84981 ==> 0.30731440507079577\n",
            "Loss in iteration no. 84982 ==> 0.3073143966607119\n",
            "Loss in iteration no. 84983 ==> 0.30731438825112534\n",
            "Loss in iteration no. 84984 ==> 0.30731437984203436\n",
            "Loss in iteration no. 84985 ==> 0.30731437143344054\n",
            "Loss in iteration no. 84986 ==> 0.307314363025343\n",
            "Loss in iteration no. 84987 ==> 0.3073143546177424\n",
            "Loss in iteration no. 84988 ==> 0.30731434621063797\n",
            "Loss in iteration no. 84989 ==> 0.30731433780403045\n",
            "Loss in iteration no. 84990 ==> 0.307314329397919\n",
            "Loss in iteration no. 84991 ==> 0.30731432099230416\n",
            "Loss in iteration no. 84992 ==> 0.30731431258718594\n",
            "Loss in iteration no. 84993 ==> 0.3073143041825632\n",
            "Loss in iteration no. 84994 ==> 0.30731429577843733\n",
            "Loss in iteration no. 84995 ==> 0.307314287374808\n",
            "Loss in iteration no. 84996 ==> 0.307314278971675\n",
            "Loss in iteration no. 84997 ==> 0.3073142705690379\n",
            "Loss in iteration no. 84998 ==> 0.30731426216689745\n",
            "Loss in iteration no. 84999 ==> 0.3073142537652532\n",
            "Loss in iteration no. 85000 ==> 0.3073142453641046\n",
            "Loss in iteration no. 85001 ==> 0.3073142369634525\n",
            "Loss in iteration no. 85002 ==> 0.3073142285632958\n",
            "Loss in iteration no. 85003 ==> 0.3073142201636364\n",
            "Loss in iteration no. 85004 ==> 0.30731421176447227\n",
            "Loss in iteration no. 85005 ==> 0.30731420336580445\n",
            "Loss in iteration no. 85006 ==> 0.30731419496763185\n",
            "Loss in iteration no. 85007 ==> 0.3073141865699557\n",
            "Loss in iteration no. 85008 ==> 0.3073141781727762\n",
            "Loss in iteration no. 85009 ==> 0.3073141697760918\n",
            "Loss in iteration no. 85010 ==> 0.3073141613799028\n",
            "Loss in iteration no. 85011 ==> 0.30731415298420994\n",
            "Loss in iteration no. 85012 ==> 0.3073141445890132\n",
            "Loss in iteration no. 85013 ==> 0.30731413619431286\n",
            "Loss in iteration no. 85014 ==> 0.30731412780010714\n",
            "Loss in iteration no. 85015 ==> 0.3073141194063974\n",
            "Loss in iteration no. 85016 ==> 0.30731411101318334\n",
            "Loss in iteration no. 85017 ==> 0.3073141026204651\n",
            "Loss in iteration no. 85018 ==> 0.30731409422824246\n",
            "Loss in iteration no. 85019 ==> 0.307314085836515\n",
            "Loss in iteration no. 85020 ==> 0.3073140774452835\n",
            "Loss in iteration no. 85021 ==> 0.3073140690545474\n",
            "Loss in iteration no. 85022 ==> 0.30731406066430667\n",
            "Loss in iteration no. 85023 ==> 0.3073140522745621\n",
            "Loss in iteration no. 85024 ==> 0.30731404388531147\n",
            "Loss in iteration no. 85025 ==> 0.3073140354965573\n",
            "Loss in iteration no. 85026 ==> 0.3073140271082989\n",
            "Loss in iteration no. 85027 ==> 0.3073140187205352\n",
            "Loss in iteration no. 85028 ==> 0.30731401033326694\n",
            "Loss in iteration no. 85029 ==> 0.30731400194649383\n",
            "Loss in iteration no. 85030 ==> 0.307313993560216\n",
            "Loss in iteration no. 85031 ==> 0.3073139851744333\n",
            "Loss in iteration no. 85032 ==> 0.3073139767891457\n",
            "Loss in iteration no. 85033 ==> 0.3073139684043538\n",
            "Loss in iteration no. 85034 ==> 0.3073139600200566\n",
            "Loss in iteration no. 85035 ==> 0.30731395163625413\n",
            "Loss in iteration no. 85036 ==> 0.30731394325294736\n",
            "Loss in iteration no. 85037 ==> 0.3073139348701357\n",
            "Loss in iteration no. 85038 ==> 0.30731392648781825\n",
            "Loss in iteration no. 85039 ==> 0.3073139181059967\n",
            "Loss in iteration no. 85040 ==> 0.30731390972466915\n",
            "Loss in iteration no. 85041 ==> 0.30731390134383724\n",
            "Loss in iteration no. 85042 ==> 0.30731389296350026\n",
            "Loss in iteration no. 85043 ==> 0.3073138845836571\n",
            "Loss in iteration no. 85044 ==> 0.3073138762043101\n",
            "Loss in iteration no. 85045 ==> 0.30731386782545705\n",
            "Loss in iteration no. 85046 ==> 0.30731385944709927\n",
            "Loss in iteration no. 85047 ==> 0.3073138510692354\n",
            "Loss in iteration no. 85048 ==> 0.3073138426918672\n",
            "Loss in iteration no. 85049 ==> 0.3073138343149933\n",
            "Loss in iteration no. 85050 ==> 0.307313825938614\n",
            "Loss in iteration no. 85051 ==> 0.30731381756272924\n",
            "Loss in iteration no. 85052 ==> 0.30731380918733897\n",
            "Loss in iteration no. 85053 ==> 0.3073138008124431\n",
            "Loss in iteration no. 85054 ==> 0.30731379243804247\n",
            "Loss in iteration no. 85055 ==> 0.30731378406413606\n",
            "Loss in iteration no. 85056 ==> 0.3073137756907238\n",
            "Loss in iteration no. 85057 ==> 0.3073137673178054\n",
            "Loss in iteration no. 85058 ==> 0.3073137589453822\n",
            "Loss in iteration no. 85059 ==> 0.30731375057345384\n",
            "Loss in iteration no. 85060 ==> 0.30731374220201857\n",
            "Loss in iteration no. 85061 ==> 0.30731373383107846\n",
            "Loss in iteration no. 85062 ==> 0.3073137254606324\n",
            "Loss in iteration no. 85063 ==> 0.3073137170906806\n",
            "Loss in iteration no. 85064 ==> 0.3073137087212228\n",
            "Loss in iteration no. 85065 ==> 0.3073137003522598\n",
            "Loss in iteration no. 85066 ==> 0.30731369198378944\n",
            "Loss in iteration no. 85067 ==> 0.30731368361581507\n",
            "Loss in iteration no. 85068 ==> 0.3073136752483336\n",
            "Loss in iteration no. 85069 ==> 0.3073136668813466\n",
            "Loss in iteration no. 85070 ==> 0.30731365851485376\n",
            "Loss in iteration no. 85071 ==> 0.30731365014885476\n",
            "Loss in iteration no. 85072 ==> 0.3073136417833497\n",
            "Loss in iteration no. 85073 ==> 0.3073136334183385\n",
            "Loss in iteration no. 85074 ==> 0.30731362505382104\n",
            "Loss in iteration no. 85075 ==> 0.3073136166897981\n",
            "Loss in iteration no. 85076 ==> 0.30731360832626875\n",
            "Loss in iteration no. 85077 ==> 0.3073135999632326\n",
            "Loss in iteration no. 85078 ==> 0.3073135916006903\n",
            "Loss in iteration no. 85079 ==> 0.3073135832386426\n",
            "Loss in iteration no. 85080 ==> 0.30731357487708827\n",
            "Loss in iteration no. 85081 ==> 0.30731356651602726\n",
            "Loss in iteration no. 85082 ==> 0.3073135581554606\n",
            "Loss in iteration no. 85083 ==> 0.3073135497953867\n",
            "Loss in iteration no. 85084 ==> 0.3073135414358067\n",
            "Loss in iteration no. 85085 ==> 0.30731353307672044\n",
            "Loss in iteration no. 85086 ==> 0.3073135247181283\n",
            "Loss in iteration no. 85087 ==> 0.3073135163600287\n",
            "Loss in iteration no. 85088 ==> 0.3073135080024226\n",
            "Loss in iteration no. 85089 ==> 0.3073134996453109\n",
            "Loss in iteration no. 85090 ==> 0.3073134912886919\n",
            "Loss in iteration no. 85091 ==> 0.30731348293256616\n",
            "Loss in iteration no. 85092 ==> 0.3073134745769338\n",
            "Loss in iteration no. 85093 ==> 0.30731346622179545\n",
            "Loss in iteration no. 85094 ==> 0.30731345786715036\n",
            "Loss in iteration no. 85095 ==> 0.30731344951299794\n",
            "Loss in iteration no. 85096 ==> 0.307313441159339\n",
            "Loss in iteration no. 85097 ==> 0.3073134328061729\n",
            "Loss in iteration no. 85098 ==> 0.30731342445350057\n",
            "Loss in iteration no. 85099 ==> 0.3073134161013217\n",
            "Loss in iteration no. 85100 ==> 0.3073134077496349\n",
            "Loss in iteration no. 85101 ==> 0.30731339939844166\n",
            "Loss in iteration no. 85102 ==> 0.30731339104774097\n",
            "Loss in iteration no. 85103 ==> 0.3073133826975342\n",
            "Loss in iteration no. 85104 ==> 0.3073133743478202\n",
            "Loss in iteration no. 85105 ==> 0.3073133659985987\n",
            "Loss in iteration no. 85106 ==> 0.3073133576498704\n",
            "Loss in iteration no. 85107 ==> 0.30731334930163495\n",
            "Loss in iteration no. 85108 ==> 0.3073133409538926\n",
            "Loss in iteration no. 85109 ==> 0.3073133326066425\n",
            "Loss in iteration no. 85110 ==> 0.30731332425988594\n",
            "Loss in iteration no. 85111 ==> 0.3073133159136223\n",
            "Loss in iteration no. 85112 ==> 0.3073133075678509\n",
            "Loss in iteration no. 85113 ==> 0.3073132992225719\n",
            "Loss in iteration no. 85114 ==> 0.3073132908777858\n",
            "Loss in iteration no. 85115 ==> 0.3073132825334925\n",
            "Loss in iteration no. 85116 ==> 0.3073132741896922\n",
            "Loss in iteration no. 85117 ==> 0.30731326584638385\n",
            "Loss in iteration no. 85118 ==> 0.30731325750356914\n",
            "Loss in iteration no. 85119 ==> 0.30731324916124614\n",
            "Loss in iteration no. 85120 ==> 0.3073132408194157\n",
            "Loss in iteration no. 85121 ==> 0.30731323247807746\n",
            "Loss in iteration no. 85122 ==> 0.30731322413723283\n",
            "Loss in iteration no. 85123 ==> 0.30731321579687937\n",
            "Loss in iteration no. 85124 ==> 0.3073132074570186\n",
            "Loss in iteration no. 85125 ==> 0.30731319911765054\n",
            "Loss in iteration no. 85126 ==> 0.30731319077877456\n",
            "Loss in iteration no. 85127 ==> 0.3073131824403911\n",
            "Loss in iteration no. 85128 ==> 0.3073131741024992\n",
            "Loss in iteration no. 85129 ==> 0.3073131657651001\n",
            "Loss in iteration no. 85130 ==> 0.30731315742819376\n",
            "Loss in iteration no. 85131 ==> 0.3073131490917784\n",
            "Loss in iteration no. 85132 ==> 0.30731314075585636\n",
            "Loss in iteration no. 85133 ==> 0.3073131324204256\n",
            "Loss in iteration no. 85134 ==> 0.30731312408548694\n",
            "Loss in iteration no. 85135 ==> 0.30731311575104053\n",
            "Loss in iteration no. 85136 ==> 0.30731310741708606\n",
            "Loss in iteration no. 85137 ==> 0.3073130990836242\n",
            "Loss in iteration no. 85138 ==> 0.3073130907506543\n",
            "Loss in iteration no. 85139 ==> 0.30731308241817545\n",
            "Loss in iteration no. 85140 ==> 0.3073130740861885\n",
            "Loss in iteration no. 85141 ==> 0.30731306575469436\n",
            "Loss in iteration no. 85142 ==> 0.3073130574236917\n",
            "Loss in iteration no. 85143 ==> 0.30731304909318036\n",
            "Loss in iteration no. 85144 ==> 0.30731304076316157\n",
            "Loss in iteration no. 85145 ==> 0.3073130324336336\n",
            "Loss in iteration no. 85146 ==> 0.30731302410459815\n",
            "Loss in iteration no. 85147 ==> 0.30731301577605397\n",
            "Loss in iteration no. 85148 ==> 0.3073130074480019\n",
            "Loss in iteration no. 85149 ==> 0.30731299912044063\n",
            "Loss in iteration no. 85150 ==> 0.3073129907933723\n",
            "Loss in iteration no. 85151 ==> 0.30731298246679406\n",
            "Loss in iteration no. 85152 ==> 0.3073129741407082\n",
            "Loss in iteration no. 85153 ==> 0.3073129658151138\n",
            "Loss in iteration no. 85154 ==> 0.3073129574900104\n",
            "Loss in iteration no. 85155 ==> 0.30731294916539925\n",
            "Loss in iteration no. 85156 ==> 0.3073129408412793\n",
            "Loss in iteration no. 85157 ==> 0.30731293251765013\n",
            "Loss in iteration no. 85158 ==> 0.30731292419451267\n",
            "Loss in iteration no. 85159 ==> 0.30731291587186665\n",
            "Loss in iteration no. 85160 ==> 0.307312907549712\n",
            "Loss in iteration no. 85161 ==> 0.30731289922804833\n",
            "Loss in iteration no. 85162 ==> 0.30731289090687636\n",
            "Loss in iteration no. 85163 ==> 0.3073128825861956\n",
            "Loss in iteration no. 85164 ==> 0.3073128742660056\n",
            "Loss in iteration no. 85165 ==> 0.3073128659463071\n",
            "Loss in iteration no. 85166 ==> 0.3073128576270991\n",
            "Loss in iteration no. 85167 ==> 0.30731284930838215\n",
            "Loss in iteration no. 85168 ==> 0.3073128409901571\n",
            "Loss in iteration no. 85169 ==> 0.30731283267242254\n",
            "Loss in iteration no. 85170 ==> 0.30731282435517965\n",
            "Loss in iteration no. 85171 ==> 0.3073128160384272\n",
            "Loss in iteration no. 85172 ==> 0.30731280772216546\n",
            "Loss in iteration no. 85173 ==> 0.30731279940639505\n",
            "Loss in iteration no. 85174 ==> 0.30731279109111465\n",
            "Loss in iteration no. 85175 ==> 0.30731278277632573\n",
            "Loss in iteration no. 85176 ==> 0.3073127744620281\n",
            "Loss in iteration no. 85177 ==> 0.30731276614822106\n",
            "Loss in iteration no. 85178 ==> 0.3073127578349047\n",
            "Loss in iteration no. 85179 ==> 0.3073127495220787\n",
            "Loss in iteration no. 85180 ==> 0.30731274120974356\n",
            "Loss in iteration no. 85181 ==> 0.3073127328978997\n",
            "Loss in iteration no. 85182 ==> 0.3073127245865452\n",
            "Loss in iteration no. 85183 ==> 0.30731271627568213\n",
            "Loss in iteration no. 85184 ==> 0.30731270796530974\n",
            "Loss in iteration no. 85185 ==> 0.30731269965542746\n",
            "Loss in iteration no. 85186 ==> 0.3073126913460359\n",
            "Loss in iteration no. 85187 ==> 0.30731268303713477\n",
            "Loss in iteration no. 85188 ==> 0.30731267472872464\n",
            "Loss in iteration no. 85189 ==> 0.30731266642080446\n",
            "Loss in iteration no. 85190 ==> 0.3073126581133747\n",
            "Loss in iteration no. 85191 ==> 0.3073126498064347\n",
            "Loss in iteration no. 85192 ==> 0.3073126414999856\n",
            "Loss in iteration no. 85193 ==> 0.3073126331940271\n",
            "Loss in iteration no. 85194 ==> 0.30731262488855887\n",
            "Loss in iteration no. 85195 ==> 0.30731261658358094\n",
            "Loss in iteration no. 85196 ==> 0.30731260827909235\n",
            "Loss in iteration no. 85197 ==> 0.30731259997509464\n",
            "Loss in iteration no. 85198 ==> 0.30731259167158725\n",
            "Loss in iteration no. 85199 ==> 0.3073125833685695\n",
            "Loss in iteration no. 85200 ==> 0.30731257506604154\n",
            "Loss in iteration no. 85201 ==> 0.307312566764005\n",
            "Loss in iteration no. 85202 ==> 0.30731255846245736\n",
            "Loss in iteration no. 85203 ==> 0.3073125501614002\n",
            "Loss in iteration no. 85204 ==> 0.3073125418608326\n",
            "Loss in iteration no. 85205 ==> 0.30731253356075494\n",
            "Loss in iteration no. 85206 ==> 0.3073125252611679\n",
            "Loss in iteration no. 85207 ==> 0.30731251696206985\n",
            "Loss in iteration no. 85208 ==> 0.3073125086634625\n",
            "Loss in iteration no. 85209 ==> 0.3073125003653446\n",
            "Loss in iteration no. 85210 ==> 0.3073124920677158\n",
            "Loss in iteration no. 85211 ==> 0.30731248377057785\n",
            "Loss in iteration no. 85212 ==> 0.30731247547392937\n",
            "Loss in iteration no. 85213 ==> 0.3073124671777697\n",
            "Loss in iteration no. 85214 ==> 0.30731245888210024\n",
            "Loss in iteration no. 85215 ==> 0.3073124505869213\n",
            "Loss in iteration no. 85216 ==> 0.307312442292231\n",
            "Loss in iteration no. 85217 ==> 0.3073124339980306\n",
            "Loss in iteration no. 85218 ==> 0.3073124257043201\n",
            "Loss in iteration no. 85219 ==> 0.30731241741109844\n",
            "Loss in iteration no. 85220 ==> 0.30731240911836627\n",
            "Loss in iteration no. 85221 ==> 0.3073124008261239\n",
            "Loss in iteration no. 85222 ==> 0.3073123925343712\n",
            "Loss in iteration no. 85223 ==> 0.3073123842431076\n",
            "Loss in iteration no. 85224 ==> 0.3073123759523329\n",
            "Loss in iteration no. 85225 ==> 0.30731236766204806\n",
            "Loss in iteration no. 85226 ==> 0.3073123593722525\n",
            "Loss in iteration no. 85227 ==> 0.3073123510829461\n",
            "Loss in iteration no. 85228 ==> 0.3073123427941288\n",
            "Loss in iteration no. 85229 ==> 0.3073123345058014\n",
            "Loss in iteration no. 85230 ==> 0.30731232621796306\n",
            "Loss in iteration no. 85231 ==> 0.30731231793061364\n",
            "Loss in iteration no. 85232 ==> 0.3073123096437531\n",
            "Loss in iteration no. 85233 ==> 0.3073123013573817\n",
            "Loss in iteration no. 85234 ==> 0.3073122930715003\n",
            "Loss in iteration no. 85235 ==> 0.3073122847861062\n",
            "Loss in iteration no. 85236 ==> 0.30731227650120246\n",
            "Loss in iteration no. 85237 ==> 0.3073122682167876\n",
            "Loss in iteration no. 85238 ==> 0.30731225993286154\n",
            "Loss in iteration no. 85239 ==> 0.307312251649424\n",
            "Loss in iteration no. 85240 ==> 0.3073122433664758\n",
            "Loss in iteration no. 85241 ==> 0.3073122350840164\n",
            "Loss in iteration no. 85242 ==> 0.30731222680204584\n",
            "Loss in iteration no. 85243 ==> 0.3073122185205643\n",
            "Loss in iteration no. 85244 ==> 0.3073122102395703\n",
            "Loss in iteration no. 85245 ==> 0.307312201959066\n",
            "Loss in iteration no. 85246 ==> 0.3073121936790507\n",
            "Loss in iteration no. 85247 ==> 0.3073121853995237\n",
            "Loss in iteration no. 85248 ==> 0.30731217712048525\n",
            "Loss in iteration no. 85249 ==> 0.30731216884193613\n",
            "Loss in iteration no. 85250 ==> 0.3073121605638746\n",
            "Loss in iteration no. 85251 ==> 0.3073121522863022\n",
            "Loss in iteration no. 85252 ==> 0.3073121440092177\n",
            "Loss in iteration no. 85253 ==> 0.3073121357326227\n",
            "Loss in iteration no. 85254 ==> 0.3073121274565154\n",
            "Loss in iteration no. 85255 ==> 0.3073121191808974\n",
            "Loss in iteration no. 85256 ==> 0.307312110905767\n",
            "Loss in iteration no. 85257 ==> 0.3073121026311246\n",
            "Loss in iteration no. 85258 ==> 0.30731209435697165\n",
            "Loss in iteration no. 85259 ==> 0.3073120860833065\n",
            "Loss in iteration no. 85260 ==> 0.30731207781013\n",
            "Loss in iteration no. 85261 ==> 0.307312069537441\n",
            "Loss in iteration no. 85262 ==> 0.30731206126524047\n",
            "Loss in iteration no. 85263 ==> 0.30731205299352876\n",
            "Loss in iteration no. 85264 ==> 0.30731204472230483\n",
            "Loss in iteration no. 85265 ==> 0.30731203645156885\n",
            "Loss in iteration no. 85266 ==> 0.30731202818132086\n",
            "Loss in iteration no. 85267 ==> 0.30731201991156176\n",
            "Loss in iteration no. 85268 ==> 0.3073120116422903\n",
            "Loss in iteration no. 85269 ==> 0.3073120033735059\n",
            "Loss in iteration no. 85270 ==> 0.30731199510521057\n",
            "Loss in iteration no. 85271 ==> 0.30731198683740313\n",
            "Loss in iteration no. 85272 ==> 0.3073119785700842\n",
            "Loss in iteration no. 85273 ==> 0.30731197030325164\n",
            "Loss in iteration no. 85274 ==> 0.3073119620369078\n",
            "Loss in iteration no. 85275 ==> 0.30731195377105197\n",
            "Loss in iteration no. 85276 ==> 0.30731194550568364\n",
            "Loss in iteration no. 85277 ==> 0.30731193724080347\n",
            "Loss in iteration no. 85278 ==> 0.3073119289764106\n",
            "Loss in iteration no. 85279 ==> 0.30731192071250574\n",
            "Loss in iteration no. 85280 ==> 0.307311912449088\n",
            "Loss in iteration no. 85281 ==> 0.3073119041861587\n",
            "Loss in iteration no. 85282 ==> 0.3073118959237168\n",
            "Loss in iteration no. 85283 ==> 0.3073118876617622\n",
            "Loss in iteration no. 85284 ==> 0.3073118794002958\n",
            "Loss in iteration no. 85285 ==> 0.30731187113931585\n",
            "Loss in iteration no. 85286 ==> 0.3073118628788241\n",
            "Loss in iteration no. 85287 ==> 0.30731185461882\n",
            "Loss in iteration no. 85288 ==> 0.30731184635930325\n",
            "Loss in iteration no. 85289 ==> 0.30731183810027357\n",
            "Loss in iteration no. 85290 ==> 0.30731182984173144\n",
            "Loss in iteration no. 85291 ==> 0.30731182158367737\n",
            "Loss in iteration no. 85292 ==> 0.3073118133261093\n",
            "Loss in iteration no. 85293 ==> 0.3073118050690291\n",
            "Loss in iteration no. 85294 ==> 0.30731179681243714\n",
            "Loss in iteration no. 85295 ==> 0.3073117885563317\n",
            "Loss in iteration no. 85296 ==> 0.30731178030071316\n",
            "Loss in iteration no. 85297 ==> 0.3073117720455822\n",
            "Loss in iteration no. 85298 ==> 0.3073117637909375\n",
            "Loss in iteration no. 85299 ==> 0.30731175553678086\n",
            "Loss in iteration no. 85300 ==> 0.3073117472831111\n",
            "Loss in iteration no. 85301 ==> 0.3073117390299283\n",
            "Loss in iteration no. 85302 ==> 0.30731173077723245\n",
            "Loss in iteration no. 85303 ==> 0.3073117225250237\n",
            "Loss in iteration no. 85304 ==> 0.3073117142733022\n",
            "Loss in iteration no. 85305 ==> 0.3073117060220677\n",
            "Loss in iteration no. 85306 ==> 0.3073116977713201\n",
            "Loss in iteration no. 85307 ==> 0.30731168952105875\n",
            "Loss in iteration no. 85308 ==> 0.307311681271285\n",
            "Loss in iteration no. 85309 ==> 0.3073116730219977\n",
            "Loss in iteration no. 85310 ==> 0.30731166477319705\n",
            "Loss in iteration no. 85311 ==> 0.30731165652488357\n",
            "Loss in iteration no. 85312 ==> 0.30731164827705626\n",
            "Loss in iteration no. 85313 ==> 0.3073116400297161\n",
            "Loss in iteration no. 85314 ==> 0.3073116317828626\n",
            "Loss in iteration no. 85315 ==> 0.30731162353649494\n",
            "Loss in iteration no. 85316 ==> 0.30731161529061485\n",
            "Loss in iteration no. 85317 ==> 0.30731160704522187\n",
            "Loss in iteration no. 85318 ==> 0.3073115988003138\n",
            "Loss in iteration no. 85319 ==> 0.30731159055589335\n",
            "Loss in iteration no. 85320 ==> 0.3073115823119595\n",
            "Loss in iteration no. 85321 ==> 0.3073115740685119\n",
            "Loss in iteration no. 85322 ==> 0.3073115658255503\n",
            "Loss in iteration no. 85323 ==> 0.3073115575830748\n",
            "Loss in iteration no. 85324 ==> 0.30731154934108645\n",
            "Loss in iteration no. 85325 ==> 0.3073115410995845\n",
            "Loss in iteration no. 85326 ==> 0.3073115328585686\n",
            "Loss in iteration no. 85327 ==> 0.30731152461803907\n",
            "Loss in iteration no. 85328 ==> 0.3073115163779962\n",
            "Loss in iteration no. 85329 ==> 0.30731150813843916\n",
            "Loss in iteration no. 85330 ==> 0.30731149989936835\n",
            "Loss in iteration no. 85331 ==> 0.30731149166078353\n",
            "Loss in iteration no. 85332 ==> 0.3073114834226844\n",
            "Loss in iteration no. 85333 ==> 0.3073114751850724\n",
            "Loss in iteration no. 85334 ==> 0.30731146694794587\n",
            "Loss in iteration no. 85335 ==> 0.3073114587113056\n",
            "Loss in iteration no. 85336 ==> 0.3073114504751507\n",
            "Loss in iteration no. 85337 ==> 0.30731144223948303\n",
            "Loss in iteration no. 85338 ==> 0.30731143400430017\n",
            "Loss in iteration no. 85339 ==> 0.3073114257696036\n",
            "Loss in iteration no. 85340 ==> 0.3073114175353935\n",
            "Loss in iteration no. 85341 ==> 0.30731140930166817\n",
            "Loss in iteration no. 85342 ==> 0.30731140106842947\n",
            "Loss in iteration no. 85343 ==> 0.3073113928356765\n",
            "Loss in iteration no. 85344 ==> 0.30731138460340945\n",
            "Loss in iteration no. 85345 ==> 0.30731137637162803\n",
            "Loss in iteration no. 85346 ==> 0.307311368140332\n",
            "Loss in iteration no. 85347 ==> 0.3073113599095213\n",
            "Loss in iteration no. 85348 ==> 0.30731135167919693\n",
            "Loss in iteration no. 85349 ==> 0.307311343449359\n",
            "Loss in iteration no. 85350 ==> 0.30731133522000526\n",
            "Loss in iteration no. 85351 ==> 0.3073113269911376\n",
            "Loss in iteration no. 85352 ==> 0.3073113187627558\n",
            "Loss in iteration no. 85353 ==> 0.30731131053485855\n",
            "Loss in iteration no. 85354 ==> 0.3073113023074474\n",
            "Loss in iteration no. 85355 ==> 0.30731129408052227\n",
            "Loss in iteration no. 85356 ==> 0.3073112858540812\n",
            "Loss in iteration no. 85357 ==> 0.3073112776281265\n",
            "Loss in iteration no. 85358 ==> 0.30731126940265713\n",
            "Loss in iteration no. 85359 ==> 0.30731126117767316\n",
            "Loss in iteration no. 85360 ==> 0.30731125295317374\n",
            "Loss in iteration no. 85361 ==> 0.3073112447291608\n",
            "Loss in iteration no. 85362 ==> 0.3073112365056317\n",
            "Loss in iteration no. 85363 ==> 0.30731122828258906\n",
            "Loss in iteration no. 85364 ==> 0.3073112200600306\n",
            "Loss in iteration no. 85365 ==> 0.307311211837958\n",
            "Loss in iteration no. 85366 ==> 0.3073112036163701\n",
            "Loss in iteration no. 85367 ==> 0.307311195395268\n",
            "Loss in iteration no. 85368 ==> 0.30731118717465067\n",
            "Loss in iteration no. 85369 ==> 0.3073111789545176\n",
            "Loss in iteration no. 85370 ==> 0.30731117073487024\n",
            "Loss in iteration no. 85371 ==> 0.3073111625157077\n",
            "Loss in iteration no. 85372 ==> 0.30731115429703026\n",
            "Loss in iteration no. 85373 ==> 0.30731114607883736\n",
            "Loss in iteration no. 85374 ==> 0.3073111378611295\n",
            "Loss in iteration no. 85375 ==> 0.30731112964390694\n",
            "Loss in iteration no. 85376 ==> 0.30731112142716793\n",
            "Loss in iteration no. 85377 ==> 0.30731111321091525\n",
            "Loss in iteration no. 85378 ==> 0.30731110499514624\n",
            "Loss in iteration no. 85379 ==> 0.307311096779862\n",
            "Loss in iteration no. 85380 ==> 0.3073110885650634\n",
            "Loss in iteration no. 85381 ==> 0.3073110803507486\n",
            "Loss in iteration no. 85382 ==> 0.30731107213691916\n",
            "Loss in iteration no. 85383 ==> 0.3073110639235745\n",
            "Loss in iteration no. 85384 ==> 0.3073110557107137\n",
            "Loss in iteration no. 85385 ==> 0.30731104749833776\n",
            "Loss in iteration no. 85386 ==> 0.3073110392864454\n",
            "Loss in iteration no. 85387 ==> 0.3073110310750389\n",
            "Loss in iteration no. 85388 ==> 0.30731102286411577\n",
            "Loss in iteration no. 85389 ==> 0.30731101465367844\n",
            "Loss in iteration no. 85390 ==> 0.30731100644372433\n",
            "Loss in iteration no. 85391 ==> 0.3073109982342546\n",
            "Loss in iteration no. 85392 ==> 0.30731099002527007\n",
            "Loss in iteration no. 85393 ==> 0.3073109818167686\n",
            "Loss in iteration no. 85394 ==> 0.30731097360875254\n",
            "Loss in iteration no. 85395 ==> 0.30731096540122016\n",
            "Loss in iteration no. 85396 ==> 0.30731095719417306\n",
            "Loss in iteration no. 85397 ==> 0.3073109489876087\n",
            "Loss in iteration no. 85398 ==> 0.3073109407815292\n",
            "Loss in iteration no. 85399 ==> 0.30731093257593434\n",
            "Loss in iteration no. 85400 ==> 0.3073109243708232\n",
            "Loss in iteration no. 85401 ==> 0.3073109161661954\n",
            "Loss in iteration no. 85402 ==> 0.30731090796205246\n",
            "Loss in iteration no. 85403 ==> 0.3073108997583935\n",
            "Loss in iteration no. 85404 ==> 0.307310891555218\n",
            "Loss in iteration no. 85405 ==> 0.3073108833525269\n",
            "Loss in iteration no. 85406 ==> 0.3073108751503191\n",
            "Loss in iteration no. 85407 ==> 0.30731086694859633\n",
            "Loss in iteration no. 85408 ==> 0.3073108587473566\n",
            "Loss in iteration no. 85409 ==> 0.30731085054660134\n",
            "Loss in iteration no. 85410 ==> 0.3073108423463293\n",
            "Loss in iteration no. 85411 ==> 0.3073108341465413\n",
            "Loss in iteration no. 85412 ==> 0.3073108259472368\n",
            "Loss in iteration no. 85413 ==> 0.30731081774841673\n",
            "Loss in iteration no. 85414 ==> 0.3073108095500792\n",
            "Loss in iteration no. 85415 ==> 0.3073108013522265\n",
            "Loss in iteration no. 85416 ==> 0.30731079315485677\n",
            "Loss in iteration no. 85417 ==> 0.3073107849579709\n",
            "Loss in iteration no. 85418 ==> 0.30731077676156804\n",
            "Loss in iteration no. 85419 ==> 0.30731076856564926\n",
            "Loss in iteration no. 85420 ==> 0.3073107603702145\n",
            "Loss in iteration no. 85421 ==> 0.3073107521752621\n",
            "Loss in iteration no. 85422 ==> 0.307310743980794\n",
            "Loss in iteration no. 85423 ==> 0.3073107357868094\n",
            "Loss in iteration no. 85424 ==> 0.3073107275933073\n",
            "Loss in iteration no. 85425 ==> 0.3073107194002889\n",
            "Loss in iteration no. 85426 ==> 0.3073107112077541\n",
            "Loss in iteration no. 85427 ==> 0.30731070301570296\n",
            "Loss in iteration no. 85428 ==> 0.30731069482413437\n",
            "Loss in iteration no. 85429 ==> 0.30731068663304967\n",
            "Loss in iteration no. 85430 ==> 0.30731067844244786\n",
            "Loss in iteration no. 85431 ==> 0.3073106702523291\n",
            "Loss in iteration no. 85432 ==> 0.3073106620626934\n",
            "Loss in iteration no. 85433 ==> 0.3073106538735409\n",
            "Loss in iteration no. 85434 ==> 0.30731064568487226\n",
            "Loss in iteration no. 85435 ==> 0.30731063749668547\n",
            "Loss in iteration no. 85436 ==> 0.3073106293089829\n",
            "Loss in iteration no. 85437 ==> 0.3073106211217627\n",
            "Loss in iteration no. 85438 ==> 0.3073106129350257\n",
            "Loss in iteration no. 85439 ==> 0.30731060474877103\n",
            "Loss in iteration no. 85440 ==> 0.30731059656299997\n",
            "Loss in iteration no. 85441 ==> 0.30731058837771186\n",
            "Loss in iteration no. 85442 ==> 0.3073105801929059\n",
            "Loss in iteration no. 85443 ==> 0.3073105720085836\n",
            "Loss in iteration no. 85444 ==> 0.30731056382474414\n",
            "Loss in iteration no. 85445 ==> 0.30731055564138643\n",
            "Loss in iteration no. 85446 ==> 0.307310547458512\n",
            "Loss in iteration no. 85447 ==> 0.3073105392761205\n",
            "Loss in iteration no. 85448 ==> 0.3073105310942116\n",
            "Loss in iteration no. 85449 ==> 0.3073105229127851\n",
            "Loss in iteration no. 85450 ==> 0.30731051473184173\n",
            "Loss in iteration no. 85451 ==> 0.3073105065513804\n",
            "Loss in iteration no. 85452 ==> 0.3073104983714017\n",
            "Loss in iteration no. 85453 ==> 0.3073104901919056\n",
            "Loss in iteration no. 85454 ==> 0.3073104820128928\n",
            "Loss in iteration no. 85455 ==> 0.3073104738343618\n",
            "Loss in iteration no. 85456 ==> 0.30731046565631337\n",
            "Loss in iteration no. 85457 ==> 0.30731045747874663\n",
            "Loss in iteration no. 85458 ==> 0.30731044930166324\n",
            "Loss in iteration no. 85459 ==> 0.30731044112506173\n",
            "Loss in iteration no. 85460 ==> 0.3073104329489426\n",
            "Loss in iteration no. 85461 ==> 0.30731042477330606\n",
            "Loss in iteration no. 85462 ==> 0.3073104165981515\n",
            "Loss in iteration no. 85463 ==> 0.30731040842347923\n",
            "Loss in iteration no. 85464 ==> 0.3073104002492897\n",
            "Loss in iteration no. 85465 ==> 0.3073103920755818\n",
            "Loss in iteration no. 85466 ==> 0.30731038390235565\n",
            "Loss in iteration no. 85467 ==> 0.30731037572961273\n",
            "Loss in iteration no. 85468 ==> 0.3073103675573511\n",
            "Loss in iteration no. 85469 ==> 0.3073103593855713\n",
            "Loss in iteration no. 85470 ==> 0.30731035121427414\n",
            "Loss in iteration no. 85471 ==> 0.30731034304345833\n",
            "Loss in iteration no. 85472 ==> 0.3073103348731255\n",
            "Loss in iteration no. 85473 ==> 0.3073103267032739\n",
            "Loss in iteration no. 85474 ==> 0.3073103185339047\n",
            "Loss in iteration no. 85475 ==> 0.3073103103650169\n",
            "Loss in iteration no. 85476 ==> 0.3073103021966106\n",
            "Loss in iteration no. 85477 ==> 0.3073102940286869\n",
            "Loss in iteration no. 85478 ==> 0.30731028586124487\n",
            "Loss in iteration no. 85479 ==> 0.30731027769428454\n",
            "Loss in iteration no. 85480 ==> 0.3073102695278052\n",
            "Loss in iteration no. 85481 ==> 0.3073102613618088\n",
            "Loss in iteration no. 85482 ==> 0.30731025319629335\n",
            "Loss in iteration no. 85483 ==> 0.30731024503126\n",
            "Loss in iteration no. 85484 ==> 0.307310236866708\n",
            "Loss in iteration no. 85485 ==> 0.3073102287026372\n",
            "Loss in iteration no. 85486 ==> 0.30731022053904833\n",
            "Loss in iteration no. 85487 ==> 0.307310212375941\n",
            "Loss in iteration no. 85488 ==> 0.3073102042133159\n",
            "Loss in iteration no. 85489 ==> 0.3073101960511714\n",
            "Loss in iteration no. 85490 ==> 0.30731018788950853\n",
            "Loss in iteration no. 85491 ==> 0.3073101797283265\n",
            "Loss in iteration no. 85492 ==> 0.3073101715676264\n",
            "Loss in iteration no. 85493 ==> 0.3073101634074082\n",
            "Loss in iteration no. 85494 ==> 0.3073101552476703\n",
            "Loss in iteration no. 85495 ==> 0.30731014708841453\n",
            "Loss in iteration no. 85496 ==> 0.30731013892963915\n",
            "Loss in iteration no. 85497 ==> 0.3073101307713459\n",
            "Loss in iteration no. 85498 ==> 0.30731012261353374\n",
            "Loss in iteration no. 85499 ==> 0.30731011445620227\n",
            "Loss in iteration no. 85500 ==> 0.30731010629935224\n",
            "Loss in iteration no. 85501 ==> 0.3073100981429827\n",
            "Loss in iteration no. 85502 ==> 0.3073100899870949\n",
            "Loss in iteration no. 85503 ==> 0.30731008183168834\n",
            "Loss in iteration no. 85504 ==> 0.307310073676762\n",
            "Loss in iteration no. 85505 ==> 0.3073100655223181\n",
            "Loss in iteration no. 85506 ==> 0.30731005736835343\n",
            "Loss in iteration no. 85507 ==> 0.3073100492148711\n",
            "Loss in iteration no. 85508 ==> 0.3073100410618691\n",
            "Loss in iteration no. 85509 ==> 0.30731003290934766\n",
            "Loss in iteration no. 85510 ==> 0.307310024757308\n",
            "Loss in iteration no. 85511 ==> 0.30731001660574825\n",
            "Loss in iteration no. 85512 ==> 0.3073100084546695\n",
            "Loss in iteration no. 85513 ==> 0.3073100003040709\n",
            "Loss in iteration no. 85514 ==> 0.307309992153954\n",
            "Loss in iteration no. 85515 ==> 0.3073099840043179\n",
            "Loss in iteration no. 85516 ==> 0.3073099758551617\n",
            "Loss in iteration no. 85517 ==> 0.3073099677064866\n",
            "Loss in iteration no. 85518 ==> 0.30730995955829205\n",
            "Loss in iteration no. 85519 ==> 0.30730995141057854\n",
            "Loss in iteration no. 85520 ==> 0.3073099432633446\n",
            "Loss in iteration no. 85521 ==> 0.3073099351165924\n",
            "Loss in iteration no. 85522 ==> 0.3073099269703196\n",
            "Loss in iteration no. 85523 ==> 0.30730991882452746\n",
            "Loss in iteration no. 85524 ==> 0.3073099106792163\n",
            "Loss in iteration no. 85525 ==> 0.30730990253438534\n",
            "Loss in iteration no. 85526 ==> 0.30730989439003437\n",
            "Loss in iteration no. 85527 ==> 0.3073098862461643\n",
            "Loss in iteration no. 85528 ==> 0.30730987810277494\n",
            "Loss in iteration no. 85529 ==> 0.307309869959865\n",
            "Loss in iteration no. 85530 ==> 0.3073098618174348\n",
            "Loss in iteration no. 85531 ==> 0.30730985367548597\n",
            "Loss in iteration no. 85532 ==> 0.3073098455340168\n",
            "Loss in iteration no. 85533 ==> 0.30730983739302803\n",
            "Loss in iteration no. 85534 ==> 0.30730982925251915\n",
            "Loss in iteration no. 85535 ==> 0.3073098211124906\n",
            "Loss in iteration no. 85536 ==> 0.30730981297294213\n",
            "Loss in iteration no. 85537 ==> 0.3073098048338738\n",
            "Loss in iteration no. 85538 ==> 0.3073097966952857\n",
            "Loss in iteration no. 85539 ==> 0.30730978855717733\n",
            "Loss in iteration no. 85540 ==> 0.3073097804195486\n",
            "Loss in iteration no. 85541 ==> 0.3073097722823997\n",
            "Loss in iteration no. 85542 ==> 0.30730976414573136\n",
            "Loss in iteration no. 85543 ==> 0.3073097560095428\n",
            "Loss in iteration no. 85544 ==> 0.30730974787383386\n",
            "Loss in iteration no. 85545 ==> 0.3073097397386049\n",
            "Loss in iteration no. 85546 ==> 0.3073097316038558\n",
            "Loss in iteration no. 85547 ==> 0.3073097234695858\n",
            "Loss in iteration no. 85548 ==> 0.307309715335796\n",
            "Loss in iteration no. 85549 ==> 0.30730970720248624\n",
            "Loss in iteration no. 85550 ==> 0.3073096990696554\n",
            "Loss in iteration no. 85551 ==> 0.30730969093730487\n",
            "Loss in iteration no. 85552 ==> 0.3073096828054339\n",
            "Loss in iteration no. 85553 ==> 0.30730967467404197\n",
            "Loss in iteration no. 85554 ==> 0.3073096665431306\n",
            "Loss in iteration no. 85555 ==> 0.30730965841269803\n",
            "Loss in iteration no. 85556 ==> 0.30730965028274493\n",
            "Loss in iteration no. 85557 ==> 0.3073096421532716\n",
            "Loss in iteration no. 85558 ==> 0.3073096340242774\n",
            "Loss in iteration no. 85559 ==> 0.3073096258957628\n",
            "Loss in iteration no. 85560 ==> 0.30730961776772703\n",
            "Loss in iteration no. 85561 ==> 0.30730960964017096\n",
            "Loss in iteration no. 85562 ==> 0.3073096015130946\n",
            "Loss in iteration no. 85563 ==> 0.30730959338649777\n",
            "Loss in iteration no. 85564 ==> 0.30730958526037966\n",
            "Loss in iteration no. 85565 ==> 0.30730957713474055\n",
            "Loss in iteration no. 85566 ==> 0.30730956900958084\n",
            "Loss in iteration no. 85567 ==> 0.30730956088490036\n",
            "Loss in iteration no. 85568 ==> 0.30730955276069927\n",
            "Loss in iteration no. 85569 ==> 0.3073095446369768\n",
            "Loss in iteration no. 85570 ==> 0.3073095365137339\n",
            "Loss in iteration no. 85571 ==> 0.30730952839096953\n",
            "Loss in iteration no. 85572 ==> 0.3073095202686846\n",
            "Loss in iteration no. 85573 ==> 0.3073095121468785\n",
            "Loss in iteration no. 85574 ==> 0.30730950402555085\n",
            "Loss in iteration no. 85575 ==> 0.30730949590470324\n",
            "Loss in iteration no. 85576 ==> 0.3073094877843339\n",
            "Loss in iteration no. 85577 ==> 0.3073094796644436\n",
            "Loss in iteration no. 85578 ==> 0.30730947154503174\n",
            "Loss in iteration no. 85579 ==> 0.30730946342609894\n",
            "Loss in iteration no. 85580 ==> 0.3073094553076448\n",
            "Loss in iteration no. 85581 ==> 0.30730944718967035\n",
            "Loss in iteration no. 85582 ==> 0.30730943907217373\n",
            "Loss in iteration no. 85583 ==> 0.30730943095515617\n",
            "Loss in iteration no. 85584 ==> 0.30730942283861673\n",
            "Loss in iteration no. 85585 ==> 0.3073094147225562\n",
            "Loss in iteration no. 85586 ==> 0.30730940660697487\n",
            "Loss in iteration no. 85587 ==> 0.3073093984918715\n",
            "Loss in iteration no. 85588 ==> 0.30730939037724686\n",
            "Loss in iteration no. 85589 ==> 0.3073093822631008\n",
            "Loss in iteration no. 85590 ==> 0.3073093741494328\n",
            "Loss in iteration no. 85591 ==> 0.30730936603624387\n",
            "Loss in iteration no. 85592 ==> 0.30730935792353287\n",
            "Loss in iteration no. 85593 ==> 0.30730934981130065\n",
            "Loss in iteration no. 85594 ==> 0.30730934169954666\n",
            "Loss in iteration no. 85595 ==> 0.3073093335882713\n",
            "Loss in iteration no. 85596 ==> 0.3073093254774737\n",
            "Loss in iteration no. 85597 ==> 0.3073093173671546\n",
            "Loss in iteration no. 85598 ==> 0.30730930925731387\n",
            "Loss in iteration no. 85599 ==> 0.30730930114795196\n",
            "Loss in iteration no. 85600 ==> 0.30730929303906795\n",
            "Loss in iteration no. 85601 ==> 0.30730928493066173\n",
            "Loss in iteration no. 85602 ==> 0.3073092768227332\n",
            "Loss in iteration no. 85603 ==> 0.30730926871528313\n",
            "Loss in iteration no. 85604 ==> 0.307309260608312\n",
            "Loss in iteration no. 85605 ==> 0.30730925250181834\n",
            "Loss in iteration no. 85606 ==> 0.30730924439580254\n",
            "Loss in iteration no. 85607 ==> 0.3073092362902645\n",
            "Loss in iteration no. 85608 ==> 0.3073092281852046\n",
            "Loss in iteration no. 85609 ==> 0.30730922008062295\n",
            "Loss in iteration no. 85610 ==> 0.3073092119765192\n",
            "Loss in iteration no. 85611 ==> 0.307309203872893\n",
            "Loss in iteration no. 85612 ==> 0.3073091957697451\n",
            "Loss in iteration no. 85613 ==> 0.30730918766707455\n",
            "Loss in iteration no. 85614 ==> 0.3073091795648818\n",
            "Loss in iteration no. 85615 ==> 0.30730917146316755\n",
            "Loss in iteration no. 85616 ==> 0.30730916336193\n",
            "Loss in iteration no. 85617 ==> 0.3073091552611713\n",
            "Loss in iteration no. 85618 ==> 0.3073091471608892\n",
            "Loss in iteration no. 85619 ==> 0.30730913906108537\n",
            "Loss in iteration no. 85620 ==> 0.30730913096175877\n",
            "Loss in iteration no. 85621 ==> 0.30730912286291\n",
            "Loss in iteration no. 85622 ==> 0.30730911476453865\n",
            "Loss in iteration no. 85623 ==> 0.3073091066666449\n",
            "Loss in iteration no. 85624 ==> 0.3073090985692283\n",
            "Loss in iteration no. 85625 ==> 0.3073090904722903\n",
            "Loss in iteration no. 85626 ==> 0.3073090823758292\n",
            "Loss in iteration no. 85627 ==> 0.3073090742798446\n",
            "Loss in iteration no. 85628 ==> 0.3073090661843384\n",
            "Loss in iteration no. 85629 ==> 0.3073090580893088\n",
            "Loss in iteration no. 85630 ==> 0.3073090499947568\n",
            "Loss in iteration no. 85631 ==> 0.3073090419006826\n",
            "Loss in iteration no. 85632 ==> 0.3073090338070853\n",
            "Loss in iteration no. 85633 ==> 0.30730902571396573\n",
            "Loss in iteration no. 85634 ==> 0.30730901762132246\n",
            "Loss in iteration no. 85635 ==> 0.30730900952915685\n",
            "Loss in iteration no. 85636 ==> 0.30730900143746825\n",
            "Loss in iteration no. 85637 ==> 0.30730899334625694\n",
            "Loss in iteration no. 85638 ==> 0.3073089852555227\n",
            "Loss in iteration no. 85639 ==> 0.30730897716526573\n",
            "Loss in iteration no. 85640 ==> 0.3073089690754847\n",
            "Loss in iteration no. 85641 ==> 0.30730896098618155\n",
            "Loss in iteration no. 85642 ==> 0.30730895289735555\n",
            "Loss in iteration no. 85643 ==> 0.30730894480900617\n",
            "Loss in iteration no. 85644 ==> 0.3073089367211341\n",
            "Loss in iteration no. 85645 ==> 0.30730892863373843\n",
            "Loss in iteration no. 85646 ==> 0.30730892054681963\n",
            "Loss in iteration no. 85647 ==> 0.3073089124603775\n",
            "Loss in iteration no. 85648 ==> 0.30730890437441244\n",
            "Loss in iteration no. 85649 ==> 0.30730889628892444\n",
            "Loss in iteration no. 85650 ==> 0.30730888820391244\n",
            "Loss in iteration no. 85651 ==> 0.3073088801193779\n",
            "Loss in iteration no. 85652 ==> 0.30730887203531954\n",
            "Loss in iteration no. 85653 ==> 0.30730886395173806\n",
            "Loss in iteration no. 85654 ==> 0.30730885586863316\n",
            "Loss in iteration no. 85655 ==> 0.3073088477860049\n",
            "Loss in iteration no. 85656 ==> 0.3073088397038536\n",
            "Loss in iteration no. 85657 ==> 0.30730883162217826\n",
            "Loss in iteration no. 85658 ==> 0.3073088235409794\n",
            "Loss in iteration no. 85659 ==> 0.3073088154602572\n",
            "Loss in iteration no. 85660 ==> 0.3073088073800113\n",
            "Loss in iteration no. 85661 ==> 0.30730879930024196\n",
            "Loss in iteration no. 85662 ==> 0.30730879122094884\n",
            "Loss in iteration no. 85663 ==> 0.3073087831421329\n",
            "Loss in iteration no. 85664 ==> 0.30730877506379217\n",
            "Loss in iteration no. 85665 ==> 0.30730876698592774\n",
            "Loss in iteration no. 85666 ==> 0.3073087589085404\n",
            "Loss in iteration no. 85667 ==> 0.3073087508316289\n",
            "Loss in iteration no. 85668 ==> 0.3073087427551938\n",
            "Loss in iteration no. 85669 ==> 0.3073087346792344\n",
            "Loss in iteration no. 85670 ==> 0.3073087266037519\n",
            "Loss in iteration no. 85671 ==> 0.30730871852874525\n",
            "Loss in iteration no. 85672 ==> 0.307308710454214\n",
            "Loss in iteration no. 85673 ==> 0.3073087023801598\n",
            "Loss in iteration no. 85674 ==> 0.30730869430658087\n",
            "Loss in iteration no. 85675 ==> 0.3073086862334784\n",
            "Loss in iteration no. 85676 ==> 0.3073086781608516\n",
            "Loss in iteration no. 85677 ==> 0.3073086700887007\n",
            "Loss in iteration no. 85678 ==> 0.307308662017026\n",
            "Loss in iteration no. 85679 ==> 0.3073086539458268\n",
            "Loss in iteration no. 85680 ==> 0.3073086458751044\n",
            "Loss in iteration no. 85681 ==> 0.3073086378048573\n",
            "Loss in iteration no. 85682 ==> 0.30730862973508577\n",
            "Loss in iteration no. 85683 ==> 0.30730862166578987\n",
            "Loss in iteration no. 85684 ==> 0.3073086135969701\n",
            "Loss in iteration no. 85685 ==> 0.3073086055286257\n",
            "Loss in iteration no. 85686 ==> 0.30730859746075756\n",
            "Loss in iteration no. 85687 ==> 0.30730858939336453\n",
            "Loss in iteration no. 85688 ==> 0.3073085813264472\n",
            "Loss in iteration no. 85689 ==> 0.30730857326000627\n",
            "Loss in iteration no. 85690 ==> 0.3073085651940398\n",
            "Loss in iteration no. 85691 ==> 0.3073085571285495\n",
            "Loss in iteration no. 85692 ==> 0.3073085490635342\n",
            "Loss in iteration no. 85693 ==> 0.307308540998995\n",
            "Loss in iteration no. 85694 ==> 0.307308532934931\n",
            "Loss in iteration no. 85695 ==> 0.30730852487134247\n",
            "Loss in iteration no. 85696 ==> 0.3073085168082294\n",
            "Loss in iteration no. 85697 ==> 0.3073085087455918\n",
            "Loss in iteration no. 85698 ==> 0.30730850068342896\n",
            "Loss in iteration no. 85699 ==> 0.3073084926217414\n",
            "Loss in iteration no. 85700 ==> 0.30730848456053\n",
            "Loss in iteration no. 85701 ==> 0.30730847649979265\n",
            "Loss in iteration no. 85702 ==> 0.30730846843953175\n",
            "Loss in iteration no. 85703 ==> 0.30730846037974535\n",
            "Loss in iteration no. 85704 ==> 0.30730845232043436\n",
            "Loss in iteration no. 85705 ==> 0.3073084442615981\n",
            "Loss in iteration no. 85706 ==> 0.3073084362032371\n",
            "Loss in iteration no. 85707 ==> 0.30730842814535125\n",
            "Loss in iteration no. 85708 ==> 0.3073084200879404\n",
            "Loss in iteration no. 85709 ==> 0.3073084120310054\n",
            "Loss in iteration no. 85710 ==> 0.3073084039745441\n",
            "Loss in iteration no. 85711 ==> 0.30730839591855835\n",
            "Loss in iteration no. 85712 ==> 0.3073083878630475\n",
            "Loss in iteration no. 85713 ==> 0.3073083798080118\n",
            "Loss in iteration no. 85714 ==> 0.30730837175345105\n",
            "Loss in iteration no. 85715 ==> 0.3073083636993645\n",
            "Loss in iteration no. 85716 ==> 0.3073083556457534\n",
            "Loss in iteration no. 85717 ==> 0.3073083475926166\n",
            "Loss in iteration no. 85718 ==> 0.30730833953995457\n",
            "Loss in iteration no. 85719 ==> 0.3073083314877669\n",
            "Loss in iteration no. 85720 ==> 0.3073083234360543\n",
            "Loss in iteration no. 85721 ==> 0.30730831538481673\n",
            "Loss in iteration no. 85722 ==> 0.307308307334054\n",
            "Loss in iteration no. 85723 ==> 0.30730829928376496\n",
            "Loss in iteration no. 85724 ==> 0.30730829123395065\n",
            "Loss in iteration no. 85725 ==> 0.3073082831846112\n",
            "Loss in iteration no. 85726 ==> 0.3073082751357463\n",
            "Loss in iteration no. 85727 ==> 0.3073082670873556\n",
            "Loss in iteration no. 85728 ==> 0.30730825903944065\n",
            "Loss in iteration no. 85729 ==> 0.30730825099199893\n",
            "Loss in iteration no. 85730 ==> 0.3073082429450312\n",
            "Loss in iteration no. 85731 ==> 0.3073082348985389\n",
            "Loss in iteration no. 85732 ==> 0.30730822685251974\n",
            "Loss in iteration no. 85733 ==> 0.30730821880697556\n",
            "Loss in iteration no. 85734 ==> 0.30730821076190634\n",
            "Loss in iteration no. 85735 ==> 0.30730820271731124\n",
            "Loss in iteration no. 85736 ==> 0.30730819467318954\n",
            "Loss in iteration no. 85737 ==> 0.3073081866295418\n",
            "Loss in iteration no. 85738 ==> 0.3073081785863688\n",
            "Loss in iteration no. 85739 ==> 0.3073081705436703\n",
            "Loss in iteration no. 85740 ==> 0.30730816250144516\n",
            "Loss in iteration no. 85741 ==> 0.30730815445969495\n",
            "Loss in iteration no. 85742 ==> 0.30730814641841864\n",
            "Loss in iteration no. 85743 ==> 0.30730813837761584\n",
            "Loss in iteration no. 85744 ==> 0.30730813033728765\n",
            "Loss in iteration no. 85745 ==> 0.307308122297433\n",
            "Loss in iteration no. 85746 ==> 0.3073081142580515\n",
            "Loss in iteration no. 85747 ==> 0.307308106219145\n",
            "Loss in iteration no. 85748 ==> 0.3073080981807124\n",
            "Loss in iteration no. 85749 ==> 0.3073080901427534\n",
            "Loss in iteration no. 85750 ==> 0.3073080821052682\n",
            "Loss in iteration no. 85751 ==> 0.3073080740682568\n",
            "Loss in iteration no. 85752 ==> 0.3073080660317191\n",
            "Loss in iteration no. 85753 ==> 0.30730805799565586\n",
            "Loss in iteration no. 85754 ==> 0.30730804996006506\n",
            "Loss in iteration no. 85755 ==> 0.30730804192494854\n",
            "Loss in iteration no. 85756 ==> 0.3073080338903058\n",
            "Loss in iteration no. 85757 ==> 0.30730802585613615\n",
            "Loss in iteration no. 85758 ==> 0.307308017822441\n",
            "Loss in iteration no. 85759 ==> 0.3073080097892183\n",
            "Loss in iteration no. 85760 ==> 0.3073080017564704\n",
            "Loss in iteration no. 85761 ==> 0.30730799372419565\n",
            "Loss in iteration no. 85762 ==> 0.3073079856923935\n",
            "Loss in iteration no. 85763 ==> 0.30730797766106516\n",
            "Loss in iteration no. 85764 ==> 0.3073079696302105\n",
            "Loss in iteration no. 85765 ==> 0.3073079615998296\n",
            "Loss in iteration no. 85766 ==> 0.3073079535699211\n",
            "Loss in iteration no. 85767 ==> 0.3073079455404868\n",
            "Loss in iteration no. 85768 ==> 0.30730793751152513\n",
            "Loss in iteration no. 85769 ==> 0.3073079294830369\n",
            "Loss in iteration no. 85770 ==> 0.3073079214550225\n",
            "Loss in iteration no. 85771 ==> 0.3073079134274804\n",
            "Loss in iteration no. 85772 ==> 0.3073079054004125\n",
            "Loss in iteration no. 85773 ==> 0.30730789737381675\n",
            "Loss in iteration no. 85774 ==> 0.3073078893476945\n",
            "Loss in iteration no. 85775 ==> 0.3073078813220457\n",
            "Loss in iteration no. 85776 ==> 0.3073078732968702\n",
            "Loss in iteration no. 85777 ==> 0.3073078652721663\n",
            "Loss in iteration no. 85778 ==> 0.3073078572479364\n",
            "Loss in iteration no. 85779 ==> 0.30730784922417964\n",
            "Loss in iteration no. 85780 ==> 0.30730784120089555\n",
            "Loss in iteration no. 85781 ==> 0.3073078331780849\n",
            "Loss in iteration no. 85782 ==> 0.3073078251557467\n",
            "Loss in iteration no. 85783 ==> 0.3073078171338814\n",
            "Loss in iteration no. 85784 ==> 0.3073078091124885\n",
            "Loss in iteration no. 85785 ==> 0.30730780109156874\n",
            "Loss in iteration no. 85786 ==> 0.3073077930711216\n",
            "Loss in iteration no. 85787 ==> 0.3073077850511479\n",
            "Loss in iteration no. 85788 ==> 0.30730777703164663\n",
            "Loss in iteration no. 85789 ==> 0.3073077690126176\n",
            "Loss in iteration no. 85790 ==> 0.30730776099406076\n",
            "Loss in iteration no. 85791 ==> 0.307307752975978\n",
            "Loss in iteration no. 85792 ==> 0.30730774495836666\n",
            "Loss in iteration no. 85793 ==> 0.3073077369412287\n",
            "Loss in iteration no. 85794 ==> 0.30730772892456293\n",
            "Loss in iteration no. 85795 ==> 0.30730772090836994\n",
            "Loss in iteration no. 85796 ==> 0.30730771289264897\n",
            "Loss in iteration no. 85797 ==> 0.30730770487740033\n",
            "Loss in iteration no. 85798 ==> 0.3073076968626244\n",
            "Loss in iteration no. 85799 ==> 0.307307688848321\n",
            "Loss in iteration no. 85800 ==> 0.3073076808344902\n",
            "Loss in iteration no. 85801 ==> 0.3073076728211315\n",
            "Loss in iteration no. 85802 ==> 0.30730766480824506\n",
            "Loss in iteration no. 85803 ==> 0.307307656795831\n",
            "Loss in iteration no. 85804 ==> 0.3073076487838885\n",
            "Loss in iteration no. 85805 ==> 0.30730764077241934\n",
            "Loss in iteration no. 85806 ==> 0.3073076327614219\n",
            "Loss in iteration no. 85807 ==> 0.30730762475089657\n",
            "Loss in iteration no. 85808 ==> 0.3073076167408427\n",
            "Loss in iteration no. 85809 ==> 0.3073076087312621\n",
            "Loss in iteration no. 85810 ==> 0.30730760072215296\n",
            "Loss in iteration no. 85811 ==> 0.30730759271351643\n",
            "Loss in iteration no. 85812 ==> 0.3073075847053512\n",
            "Loss in iteration no. 85813 ==> 0.30730757669765807\n",
            "Loss in iteration no. 85814 ==> 0.3073075686904377\n",
            "Loss in iteration no. 85815 ==> 0.3073075606836881\n",
            "Loss in iteration no. 85816 ==> 0.30730755267741156\n",
            "Loss in iteration no. 85817 ==> 0.3073075446716065\n",
            "Loss in iteration no. 85818 ==> 0.30730753666627264\n",
            "Loss in iteration no. 85819 ==> 0.3073075286614109\n",
            "Loss in iteration no. 85820 ==> 0.3073075206570212\n",
            "Loss in iteration no. 85821 ==> 0.30730751265310385\n",
            "Loss in iteration no. 85822 ==> 0.3073075046496567\n",
            "Loss in iteration no. 85823 ==> 0.3073074966466822\n",
            "Loss in iteration no. 85824 ==> 0.30730748864417945\n",
            "Loss in iteration no. 85825 ==> 0.3073074806421488\n",
            "Loss in iteration no. 85826 ==> 0.3073074726405889\n",
            "Loss in iteration no. 85827 ==> 0.3073074646395006\n",
            "Loss in iteration no. 85828 ==> 0.3073074566388846\n",
            "Loss in iteration no. 85829 ==> 0.3073074486387395\n",
            "Loss in iteration no. 85830 ==> 0.30730744063906623\n",
            "Loss in iteration no. 85831 ==> 0.30730743263986426\n",
            "Loss in iteration no. 85832 ==> 0.30730742464113386\n",
            "Loss in iteration no. 85833 ==> 0.30730741664287414\n",
            "Loss in iteration no. 85834 ==> 0.30730740864508677\n",
            "Loss in iteration no. 85835 ==> 0.30730740064777035\n",
            "Loss in iteration no. 85836 ==> 0.3073073926509253\n",
            "Loss in iteration no. 85837 ==> 0.3073073846545516\n",
            "Loss in iteration no. 85838 ==> 0.307307376658649\n",
            "Loss in iteration no. 85839 ==> 0.30730736866321806\n",
            "Loss in iteration no. 85840 ==> 0.30730736066825814\n",
            "Loss in iteration no. 85841 ==> 0.30730735267376924\n",
            "Loss in iteration no. 85842 ==> 0.3073073446797518\n",
            "Loss in iteration no. 85843 ==> 0.3073073366862055\n",
            "Loss in iteration no. 85844 ==> 0.3073073286931296\n",
            "Loss in iteration no. 85845 ==> 0.30730732070052497\n",
            "Loss in iteration no. 85846 ==> 0.3073073127083921\n",
            "Loss in iteration no. 85847 ==> 0.30730730471672957\n",
            "Loss in iteration no. 85848 ==> 0.3073072967255383\n",
            "Loss in iteration no. 85849 ==> 0.3073072887348176\n",
            "Loss in iteration no. 85850 ==> 0.30730728074456887\n",
            "Loss in iteration no. 85851 ==> 0.30730727275479014\n",
            "Loss in iteration no. 85852 ==> 0.3073072647654823\n",
            "Loss in iteration no. 85853 ==> 0.3073072567766457\n",
            "Loss in iteration no. 85854 ==> 0.30730724878827953\n",
            "Loss in iteration no. 85855 ==> 0.30730724080038435\n",
            "Loss in iteration no. 85856 ==> 0.30730723281295996\n",
            "Loss in iteration no. 85857 ==> 0.3073072248260063\n",
            "Loss in iteration no. 85858 ==> 0.30730721683952295\n",
            "Loss in iteration no. 85859 ==> 0.3073072088535102\n",
            "Loss in iteration no. 85860 ==> 0.30730720086796887\n",
            "Loss in iteration no. 85861 ==> 0.30730719288289804\n",
            "Loss in iteration no. 85862 ==> 0.30730718489829717\n",
            "Loss in iteration no. 85863 ==> 0.30730717691416665\n",
            "Loss in iteration no. 85864 ==> 0.30730716893050714\n",
            "Loss in iteration no. 85865 ==> 0.3073071609473189\n",
            "Loss in iteration no. 85866 ==> 0.3073071529645995\n",
            "Loss in iteration no. 85867 ==> 0.30730714498235173\n",
            "Loss in iteration no. 85868 ==> 0.30730713700057405\n",
            "Loss in iteration no. 85869 ==> 0.3073071290192667\n",
            "Loss in iteration no. 85870 ==> 0.3073071210384297\n",
            "Loss in iteration no. 85871 ==> 0.30730711305806285\n",
            "Loss in iteration no. 85872 ==> 0.3073071050781663\n",
            "Loss in iteration no. 85873 ==> 0.30730709709874054\n",
            "Loss in iteration no. 85874 ==> 0.3073070891197849\n",
            "Loss in iteration no. 85875 ==> 0.3073070811412988\n",
            "Loss in iteration no. 85876 ==> 0.30730707316328365\n",
            "Loss in iteration no. 85877 ==> 0.3073070651857377\n",
            "Loss in iteration no. 85878 ==> 0.30730705720866264\n",
            "Loss in iteration no. 85879 ==> 0.30730704923205776\n",
            "Loss in iteration no. 85880 ==> 0.30730704125592284\n",
            "Loss in iteration no. 85881 ==> 0.3073070332802576\n",
            "Loss in iteration no. 85882 ==> 0.30730702530506215\n",
            "Loss in iteration no. 85883 ==> 0.3073070173303374\n",
            "Loss in iteration no. 85884 ==> 0.307307009356082\n",
            "Loss in iteration no. 85885 ==> 0.3073070013822967\n",
            "Loss in iteration no. 85886 ==> 0.3073069934089815\n",
            "Loss in iteration no. 85887 ==> 0.30730698543613627\n",
            "Loss in iteration no. 85888 ==> 0.3073069774637609\n",
            "Loss in iteration no. 85889 ==> 0.30730696949185454\n",
            "Loss in iteration no. 85890 ==> 0.30730696152041836\n",
            "Loss in iteration no. 85891 ==> 0.3073069535494524\n",
            "Loss in iteration no. 85892 ==> 0.307306945578956\n",
            "Loss in iteration no. 85893 ==> 0.30730693760892874\n",
            "Loss in iteration no. 85894 ==> 0.30730692963937156\n",
            "Loss in iteration no. 85895 ==> 0.3073069216702836\n",
            "Loss in iteration no. 85896 ==> 0.30730691370166596\n",
            "Loss in iteration no. 85897 ==> 0.3073069057335176\n",
            "Loss in iteration no. 85898 ==> 0.3073068977658377\n",
            "Loss in iteration no. 85899 ==> 0.30730688979862864\n",
            "Loss in iteration no. 85900 ==> 0.3073068818318886\n",
            "Loss in iteration no. 85901 ==> 0.307306873865618\n",
            "Loss in iteration no. 85902 ==> 0.3073068658998177\n",
            "Loss in iteration no. 85903 ==> 0.30730685793448537\n",
            "Loss in iteration no. 85904 ==> 0.3073068499696232\n",
            "Loss in iteration no. 85905 ==> 0.30730684200523023\n",
            "Loss in iteration no. 85906 ==> 0.30730683404130715\n",
            "Loss in iteration no. 85907 ==> 0.30730682607785276\n",
            "Loss in iteration no. 85908 ==> 0.3073068181148673\n",
            "Loss in iteration no. 85909 ==> 0.30730681015235156\n",
            "Loss in iteration no. 85910 ==> 0.30730680219030515\n",
            "Loss in iteration no. 85911 ==> 0.30730679422872736\n",
            "Loss in iteration no. 85912 ==> 0.3073067862676185\n",
            "Loss in iteration no. 85913 ==> 0.3073067783069799\n",
            "Loss in iteration no. 85914 ==> 0.30730677034680925\n",
            "Loss in iteration no. 85915 ==> 0.3073067623871082\n",
            "Loss in iteration no. 85916 ==> 0.30730675442787625\n",
            "Loss in iteration no. 85917 ==> 0.3073067464691128\n",
            "Loss in iteration no. 85918 ==> 0.30730673851081874\n",
            "Loss in iteration no. 85919 ==> 0.3073067305529939\n",
            "Loss in iteration no. 85920 ==> 0.30730672259563674\n",
            "Loss in iteration no. 85921 ==> 0.30730671463874976\n",
            "Loss in iteration no. 85922 ==> 0.30730670668233123\n",
            "Loss in iteration no. 85923 ==> 0.3073066987263816\n",
            "Loss in iteration no. 85924 ==> 0.30730669077090067\n",
            "Loss in iteration no. 85925 ==> 0.3073066828158888\n",
            "Loss in iteration no. 85926 ==> 0.30730667486134466\n",
            "Loss in iteration no. 85927 ==> 0.30730666690727065\n",
            "Loss in iteration no. 85928 ==> 0.307306658953664\n",
            "Loss in iteration no. 85929 ==> 0.30730665100052645\n",
            "Loss in iteration no. 85930 ==> 0.30730664304785815\n",
            "Loss in iteration no. 85931 ==> 0.3073066350956581\n",
            "Loss in iteration no. 85932 ==> 0.3073066271439258\n",
            "Loss in iteration no. 85933 ==> 0.30730661919266256\n",
            "Loss in iteration no. 85934 ==> 0.3073066112418681\n",
            "Loss in iteration no. 85935 ==> 0.3073066032915421\n",
            "Loss in iteration no. 85936 ==> 0.30730659534168436\n",
            "Loss in iteration no. 85937 ==> 0.3073065873922949\n",
            "Loss in iteration no. 85938 ==> 0.3073065794433746\n",
            "Loss in iteration no. 85939 ==> 0.3073065714949223\n",
            "Loss in iteration no. 85940 ==> 0.3073065635469374\n",
            "Loss in iteration no. 85941 ==> 0.3073065555994216\n",
            "Loss in iteration no. 85942 ==> 0.3073065476523738\n",
            "Loss in iteration no. 85943 ==> 0.3073065397057943\n",
            "Loss in iteration no. 85944 ==> 0.30730653175968387\n",
            "Loss in iteration no. 85945 ==> 0.3073065238140408\n",
            "Loss in iteration no. 85946 ==> 0.30730651586886604\n",
            "Loss in iteration no. 85947 ==> 0.3073065079241594\n",
            "Loss in iteration no. 85948 ==> 0.30730649997992077\n",
            "Loss in iteration no. 85949 ==> 0.3073064920361508\n",
            "Loss in iteration no. 85950 ==> 0.3073064840928482\n",
            "Loss in iteration no. 85951 ==> 0.3073064761500134\n",
            "Loss in iteration no. 85952 ==> 0.30730646820764707\n",
            "Loss in iteration no. 85953 ==> 0.3073064602657488\n",
            "Loss in iteration no. 85954 ==> 0.30730645232431814\n",
            "Loss in iteration no. 85955 ==> 0.30730644438335575\n",
            "Loss in iteration no. 85956 ==> 0.3073064364428615\n",
            "Loss in iteration no. 85957 ==> 0.30730642850283435\n",
            "Loss in iteration no. 85958 ==> 0.3073064205632752\n",
            "Loss in iteration no. 85959 ==> 0.3073064126241837\n",
            "Loss in iteration no. 85960 ==> 0.3073064046855605\n",
            "Loss in iteration no. 85961 ==> 0.3073063967474049\n",
            "Loss in iteration no. 85962 ==> 0.30730638880971634\n",
            "Loss in iteration no. 85963 ==> 0.30730638087249584\n",
            "Loss in iteration no. 85964 ==> 0.30730637293574353\n",
            "Loss in iteration no. 85965 ==> 0.30730636499945807\n",
            "Loss in iteration no. 85966 ==> 0.30730635706364057\n",
            "Loss in iteration no. 85967 ==> 0.3073063491282902\n",
            "Loss in iteration no. 85968 ==> 0.30730634119340844\n",
            "Loss in iteration no. 85969 ==> 0.3073063332589932\n",
            "Loss in iteration no. 85970 ==> 0.3073063253250458\n",
            "Loss in iteration no. 85971 ==> 0.30730631739156594\n",
            "Loss in iteration no. 85972 ==> 0.30730630945855325\n",
            "Loss in iteration no. 85973 ==> 0.30730630152600774\n",
            "Loss in iteration no. 85974 ==> 0.30730629359392964\n",
            "Loss in iteration no. 85975 ==> 0.3073062856623193\n",
            "Loss in iteration no. 85976 ==> 0.30730627773117597\n",
            "Loss in iteration no. 85977 ==> 0.3073062698004998\n",
            "Loss in iteration no. 85978 ==> 0.3073062618702912\n",
            "Loss in iteration no. 85979 ==> 0.3073062539405502\n",
            "Loss in iteration no. 85980 ==> 0.3073062460112758\n",
            "Loss in iteration no. 85981 ==> 0.30730623808246843\n",
            "Loss in iteration no. 85982 ==> 0.3073062301541283\n",
            "Loss in iteration no. 85983 ==> 0.30730622222625553\n",
            "Loss in iteration no. 85984 ==> 0.3073062142988495\n",
            "Loss in iteration no. 85985 ==> 0.3073062063719106\n",
            "Loss in iteration no. 85986 ==> 0.30730619844543866\n",
            "Loss in iteration no. 85987 ==> 0.3073061905194347\n",
            "Loss in iteration no. 85988 ==> 0.30730618259389636\n",
            "Loss in iteration no. 85989 ==> 0.3073061746688258"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Loss in iteration no. 195001 ==> 0.30716838430114474\n",
            "Loss in iteration no. 195002 ==> 0.30716838428314586\n",
            "Loss in iteration no. 195003 ==> 0.3071683842651471\n",
            "Loss in iteration no. 195004 ==> 0.3071683842471493\n",
            "Loss in iteration no. 195005 ==> 0.30716838422915316\n",
            "Loss in iteration no. 195006 ==> 0.30716838421115755\n",
            "Loss in iteration no. 195007 ==> 0.3071683841931636\n",
            "Loss in iteration no. 195008 ==> 0.3071683841751692\n",
            "Loss in iteration no. 195009 ==> 0.30716838415717784\n",
            "Loss in iteration no. 195010 ==> 0.3071683841391855\n",
            "Loss in iteration no. 195011 ==> 0.3071683841211953\n",
            "Loss in iteration no. 195012 ==> 0.30716838410320635\n",
            "Loss in iteration no. 195013 ==> 0.3071683840852172\n",
            "Loss in iteration no. 195014 ==> 0.3071683840672292\n",
            "Loss in iteration no. 195015 ==> 0.30716838404924335\n",
            "Loss in iteration no. 195016 ==> 0.30716838403125796\n",
            "Loss in iteration no. 195017 ==> 0.30716838401327323\n",
            "Loss in iteration no. 195018 ==> 0.30716838399528906\n",
            "Loss in iteration no. 195019 ==> 0.3071683839773064\n",
            "Loss in iteration no. 195020 ==> 0.30716838395932583\n",
            "Loss in iteration no. 195021 ==> 0.3071683839413443\n",
            "Loss in iteration no. 195022 ==> 0.30716838392336493\n",
            "Loss in iteration no. 195023 ==> 0.3071683839053865\n",
            "Loss in iteration no. 195024 ==> 0.3071683838874092\n",
            "Loss in iteration no. 195025 ==> 0.30716838386943196\n",
            "Loss in iteration no. 195026 ==> 0.3071683838514568\n",
            "Loss in iteration no. 195027 ==> 0.3071683838334811\n",
            "Loss in iteration no. 195028 ==> 0.30716838381550804\n",
            "Loss in iteration no. 195029 ==> 0.3071683837975346\n",
            "Loss in iteration no. 195030 ==> 0.3071683837795637\n",
            "Loss in iteration no. 195031 ==> 0.30716838376159267\n",
            "Loss in iteration no. 195032 ==> 0.30716838374362293\n",
            "Loss in iteration no. 195033 ==> 0.3071683837256537\n",
            "Loss in iteration no. 195034 ==> 0.30716838370768645\n",
            "Loss in iteration no. 195035 ==> 0.30716838368971927\n",
            "Loss in iteration no. 195036 ==> 0.3071683836717531\n",
            "Loss in iteration no. 195037 ==> 0.3071683836537886\n",
            "Loss in iteration no. 195038 ==> 0.30716838363582466\n",
            "Loss in iteration no. 195039 ==> 0.30716838361786214\n",
            "Loss in iteration no. 195040 ==> 0.30716838359990023\n",
            "Loss in iteration no. 195041 ==> 0.30716838358193893\n",
            "Loss in iteration no. 195042 ==> 0.307168383563979\n",
            "Loss in iteration no. 195043 ==> 0.30716838354601983\n",
            "Loss in iteration no. 195044 ==> 0.3071683835280616\n",
            "Loss in iteration no. 195045 ==> 0.3071683835101044\n",
            "Loss in iteration no. 195046 ==> 0.30716838349214926\n",
            "Loss in iteration no. 195047 ==> 0.30716838347419373\n",
            "Loss in iteration no. 195048 ==> 0.30716838345623915\n",
            "Loss in iteration no. 195049 ==> 0.3071683834382866\n",
            "Loss in iteration no. 195050 ==> 0.3071683834203347\n",
            "Loss in iteration no. 195051 ==> 0.3071683834023833\n",
            "Loss in iteration no. 195052 ==> 0.3071683833844334\n",
            "Loss in iteration no. 195053 ==> 0.30716838336648405\n",
            "Loss in iteration no. 195054 ==> 0.30716838334853575\n",
            "Loss in iteration no. 195055 ==> 0.30716838333058855\n",
            "Loss in iteration no. 195056 ==> 0.30716838331264223\n",
            "Loss in iteration no. 195057 ==> 0.3071683832946971\n",
            "Loss in iteration no. 195058 ==> 0.3071683832767529\n",
            "Loss in iteration no. 195059 ==> 0.3071683832588103\n",
            "Loss in iteration no. 195060 ==> 0.3071683832408678\n",
            "Loss in iteration no. 195061 ==> 0.30716838322292617\n",
            "Loss in iteration no. 195062 ==> 0.3071683832049862\n",
            "Loss in iteration no. 195063 ==> 0.30716838318704665\n",
            "Loss in iteration no. 195064 ==> 0.30716838316910827\n",
            "Loss in iteration no. 195065 ==> 0.30716838315117073\n",
            "Loss in iteration no. 195066 ==> 0.3071683831332338\n",
            "Loss in iteration no. 195067 ==> 0.3071683831152989\n",
            "Loss in iteration no. 195068 ==> 0.3071683830973641\n",
            "Loss in iteration no. 195069 ==> 0.30716838307943134\n",
            "Loss in iteration no. 195070 ==> 0.3071683830614989\n",
            "Loss in iteration no. 195071 ==> 0.30716838304356664\n",
            "Loss in iteration no. 195072 ==> 0.30716838302563637\n",
            "Loss in iteration no. 195073 ==> 0.3071683830077067\n",
            "Loss in iteration no. 195074 ==> 0.3071683829897785\n",
            "Loss in iteration no. 195075 ==> 0.30716838297185084\n",
            "Loss in iteration no. 195076 ==> 0.3071683829539251\n",
            "Loss in iteration no. 195077 ==> 0.3071683829359985\n",
            "Loss in iteration no. 195078 ==> 0.3071683829180749\n",
            "Loss in iteration no. 195079 ==> 0.3071683829001513\n",
            "Loss in iteration no. 195080 ==> 0.3071683828822286\n",
            "Loss in iteration no. 195081 ==> 0.307168382864306\n",
            "Loss in iteration no. 195082 ==> 0.3071683828463854\n",
            "Loss in iteration no. 195083 ==> 0.3071683828284664\n",
            "Loss in iteration no. 195084 ==> 0.30716838281054787\n",
            "Loss in iteration no. 195085 ==> 0.30716838279262987\n",
            "Loss in iteration no. 195086 ==> 0.3071683827747133\n",
            "Loss in iteration no. 195087 ==> 0.3071683827567973\n",
            "Loss in iteration no. 195088 ==> 0.3071683827388823\n",
            "Loss in iteration no. 195089 ==> 0.3071683827209683\n",
            "Loss in iteration no. 195090 ==> 0.3071683827030563\n",
            "Loss in iteration no. 195091 ==> 0.3071683826851434\n",
            "Loss in iteration no. 195092 ==> 0.30716838266723334\n",
            "Loss in iteration no. 195093 ==> 0.3071683826493229\n",
            "Loss in iteration no. 195094 ==> 0.3071683826314145\n",
            "Loss in iteration no. 195095 ==> 0.307168382613506\n",
            "Loss in iteration no. 195096 ==> 0.3071683825955991\n",
            "Loss in iteration no. 195097 ==> 0.3071683825776932\n",
            "Loss in iteration no. 195098 ==> 0.3071683825597881\n",
            "Loss in iteration no. 195099 ==> 0.3071683825418847\n",
            "Loss in iteration no. 195100 ==> 0.30716838252398077\n",
            "Loss in iteration no. 195101 ==> 0.30716838250607986\n",
            "Loss in iteration no. 195102 ==> 0.3071683824881784\n",
            "Loss in iteration no. 195103 ==> 0.30716838247027795\n",
            "Loss in iteration no. 195104 ==> 0.30716838245237943\n",
            "Loss in iteration no. 195105 ==> 0.3071683824344816\n",
            "Loss in iteration no. 195106 ==> 0.30716838241658406\n",
            "Loss in iteration no. 195107 ==> 0.3071683823986881\n",
            "Loss in iteration no. 195108 ==> 0.3071683823807926\n",
            "Loss in iteration no. 195109 ==> 0.30716838236289856\n",
            "Loss in iteration no. 195110 ==> 0.3071683823450051\n",
            "Loss in iteration no. 195111 ==> 0.3071683823271126\n",
            "Loss in iteration no. 195112 ==> 0.30716838230922205\n",
            "Loss in iteration no. 195113 ==> 0.30716838229133153\n",
            "Loss in iteration no. 195114 ==> 0.307168382273442\n",
            "Loss in iteration no. 195115 ==> 0.3071683822555535\n",
            "Loss in iteration no. 195116 ==> 0.3071683822376664\n",
            "Loss in iteration no. 195117 ==> 0.30716838221977977\n",
            "Loss in iteration no. 195118 ==> 0.30716838220189463\n",
            "Loss in iteration no. 195119 ==> 0.3071683821840101\n",
            "Loss in iteration no. 195120 ==> 0.307168382166127\n",
            "Loss in iteration no. 195121 ==> 0.30716838214824427\n",
            "Loss in iteration no. 195122 ==> 0.3071683821303637\n",
            "Loss in iteration no. 195123 ==> 0.307168382112483\n",
            "Loss in iteration no. 195124 ==> 0.3071683820946028\n",
            "Loss in iteration no. 195125 ==> 0.30716838207672453\n",
            "Loss in iteration no. 195126 ==> 0.30716838205884683\n",
            "Loss in iteration no. 195127 ==> 0.3071683820409705\n",
            "Loss in iteration no. 195128 ==> 0.3071683820230942\n",
            "Loss in iteration no. 195129 ==> 0.30716838200521984\n",
            "Loss in iteration no. 195130 ==> 0.3071683819873461\n",
            "Loss in iteration no. 195131 ==> 0.3071683819694743\n",
            "Loss in iteration no. 195132 ==> 0.30716838195160234\n",
            "Loss in iteration no. 195133 ==> 0.30716838193373186\n",
            "Loss in iteration no. 195134 ==> 0.3071683819158624\n",
            "Loss in iteration no. 195135 ==> 0.30716838189799295\n",
            "Loss in iteration no. 195136 ==> 0.30716838188012535\n",
            "Loss in iteration no. 195137 ==> 0.3071683818622579\n",
            "Loss in iteration no. 195138 ==> 0.30716838184439227\n",
            "Loss in iteration no. 195139 ==> 0.30716838182652817\n",
            "Loss in iteration no. 195140 ==> 0.30716838180866446\n",
            "Loss in iteration no. 195141 ==> 0.3071683817908013\n",
            "Loss in iteration no. 195142 ==> 0.30716838177293965\n",
            "Loss in iteration no. 195143 ==> 0.3071683817550784\n",
            "Loss in iteration no. 195144 ==> 0.3071683817372191\n",
            "Loss in iteration no. 195145 ==> 0.30716838171935973\n",
            "Loss in iteration no. 195146 ==> 0.30716838170150096\n",
            "Loss in iteration no. 195147 ==> 0.30716838168364397\n",
            "Loss in iteration no. 195148 ==> 0.3071683816657885\n",
            "Loss in iteration no. 195149 ==> 0.30716838164793303\n",
            "Loss in iteration no. 195150 ==> 0.30716838163007953\n",
            "Loss in iteration no. 195151 ==> 0.3071683816122264\n",
            "Loss in iteration no. 195152 ==> 0.3071683815943739\n",
            "Loss in iteration no. 195153 ==> 0.30716838157652265\n",
            "Loss in iteration no. 195154 ==> 0.30716838155867304\n",
            "Loss in iteration no. 195155 ==> 0.30716838154082426\n",
            "Loss in iteration no. 195156 ==> 0.30716838152297543\n",
            "Loss in iteration no. 195157 ==> 0.3071683815051281\n",
            "Loss in iteration no. 195158 ==> 0.3071683814872817\n",
            "Loss in iteration no. 195159 ==> 0.30716838146943676\n",
            "Loss in iteration no. 195160 ==> 0.3071683814515918\n",
            "Loss in iteration no. 195161 ==> 0.3071683814337487\n",
            "Loss in iteration no. 195162 ==> 0.3071683814159072\n",
            "Loss in iteration no. 195163 ==> 0.3071683813980649\n",
            "Loss in iteration no. 195164 ==> 0.3071683813802253\n",
            "Loss in iteration no. 195165 ==> 0.30716838136238506\n",
            "Loss in iteration no. 195166 ==> 0.3071683813445477\n",
            "Loss in iteration no. 195167 ==> 0.30716838132670926\n",
            "Loss in iteration no. 195168 ==> 0.30716838130887336\n",
            "Loss in iteration no. 195169 ==> 0.30716838129103735\n",
            "Loss in iteration no. 195170 ==> 0.30716838127320334\n",
            "Loss in iteration no. 195171 ==> 0.3071683812553692\n",
            "Loss in iteration no. 195172 ==> 0.30716838123753754\n",
            "Loss in iteration no. 195173 ==> 0.30716838121970524\n",
            "Loss in iteration no. 195174 ==> 0.3071683812018745\n",
            "Loss in iteration no. 195175 ==> 0.3071683811840452\n",
            "Loss in iteration no. 195176 ==> 0.30716838116621625\n",
            "Loss in iteration no. 195177 ==> 0.30716838114838885\n",
            "Loss in iteration no. 195178 ==> 0.3071683811305618\n",
            "Loss in iteration no. 195179 ==> 0.3071683811127367\n",
            "Loss in iteration no. 195180 ==> 0.30716838109491146\n",
            "Loss in iteration no. 195181 ==> 0.3071683810770882\n",
            "Loss in iteration no. 195182 ==> 0.30716838105926536\n",
            "Loss in iteration no. 195183 ==> 0.30716838104144345\n",
            "Loss in iteration no. 195184 ==> 0.30716838102362254\n",
            "Loss in iteration no. 195185 ==> 0.307168381005802\n",
            "Loss in iteration no. 195186 ==> 0.3071683809879839\n",
            "Loss in iteration no. 195187 ==> 0.30716838097016524\n",
            "Loss in iteration no. 195188 ==> 0.30716838095234844\n",
            "Loss in iteration no. 195189 ==> 0.3071683809345327\n",
            "Loss in iteration no. 195190 ==> 0.3071683809167172\n",
            "Loss in iteration no. 195191 ==> 0.30716838089890375\n",
            "Loss in iteration no. 195192 ==> 0.3071683808810903\n",
            "Loss in iteration no. 195193 ==> 0.30716838086327863\n",
            "Loss in iteration no. 195194 ==> 0.3071683808454674\n",
            "Loss in iteration no. 195195 ==> 0.307168380827657\n",
            "Loss in iteration no. 195196 ==> 0.30716838080984776\n",
            "Loss in iteration no. 195197 ==> 0.3071683807920398\n",
            "Loss in iteration no. 195198 ==> 0.3071683807742323\n",
            "Loss in iteration no. 195199 ==> 0.30716838075642666\n",
            "Loss in iteration no. 195200 ==> 0.3071683807386209\n",
            "Loss in iteration no. 195201 ==> 0.3071683807208167\n",
            "Loss in iteration no. 195202 ==> 0.3071683807030143\n",
            "Loss in iteration no. 195203 ==> 0.30716838068521085\n",
            "Loss in iteration no. 195204 ==> 0.30716838066741037\n",
            "Loss in iteration no. 195205 ==> 0.3071683806496102\n",
            "Loss in iteration no. 195206 ==> 0.30716838063180996\n",
            "Loss in iteration no. 195207 ==> 0.30716838061401164\n",
            "Loss in iteration no. 195208 ==> 0.3071683805962147\n",
            "Loss in iteration no. 195209 ==> 0.3071683805784183\n",
            "Loss in iteration no. 195210 ==> 0.3071683805606222\n",
            "Loss in iteration no. 195211 ==> 0.30716838054282797\n",
            "Loss in iteration no. 195212 ==> 0.30716838052503476\n",
            "Loss in iteration no. 195213 ==> 0.3071683805072419\n",
            "Loss in iteration no. 195214 ==> 0.30716838048944983\n",
            "Loss in iteration no. 195215 ==> 0.3071683804716594\n",
            "Loss in iteration no. 195216 ==> 0.3071683804538698\n",
            "Loss in iteration no. 195217 ==> 0.30716838043608097\n",
            "Loss in iteration no. 195218 ==> 0.3071683804182936\n",
            "Loss in iteration no. 195219 ==> 0.3071683804005067\n",
            "Loss in iteration no. 195220 ==> 0.3071683803827211\n",
            "Loss in iteration no. 195221 ==> 0.307168380364936\n",
            "Loss in iteration no. 195222 ==> 0.30716838034715227\n",
            "Loss in iteration no. 195223 ==> 0.3071683803293694\n",
            "Loss in iteration no. 195224 ==> 0.30716838031158744\n",
            "Loss in iteration no. 195225 ==> 0.3071683802938068\n",
            "Loss in iteration no. 195226 ==> 0.3071683802760272\n",
            "Loss in iteration no. 195227 ==> 0.30716838025824794\n",
            "Loss in iteration no. 195228 ==> 0.3071683802404695\n",
            "Loss in iteration no. 195229 ==> 0.30716838022269305\n",
            "Loss in iteration no. 195230 ==> 0.30716838020491705\n",
            "Loss in iteration no. 195231 ==> 0.3071683801871422\n",
            "Loss in iteration no. 195232 ==> 0.30716838016936787\n",
            "Loss in iteration no. 195233 ==> 0.307168380151595\n",
            "Loss in iteration no. 195234 ==> 0.30716838013382297\n",
            "Loss in iteration no. 195235 ==> 0.30716838011605185\n",
            "Loss in iteration no. 195236 ==> 0.3071683800982815\n",
            "Loss in iteration no. 195237 ==> 0.3071683800805121\n",
            "Loss in iteration no. 195238 ==> 0.30716838006274366\n",
            "Loss in iteration no. 195239 ==> 0.307168380044976\n",
            "Loss in iteration no. 195240 ==> 0.3071683800272103\n",
            "Loss in iteration no. 195241 ==> 0.30716838000944496\n",
            "Loss in iteration no. 195242 ==> 0.30716837999168095\n",
            "Loss in iteration no. 195243 ==> 0.3071683799739173\n",
            "Loss in iteration no. 195244 ==> 0.30716837995615415\n",
            "Loss in iteration no. 195245 ==> 0.30716837993839385\n",
            "Loss in iteration no. 195246 ==> 0.30716837992063334\n",
            "Loss in iteration no. 195247 ==> 0.3071683799028733\n",
            "Loss in iteration no. 195248 ==> 0.30716837988511514\n",
            "Loss in iteration no. 195249 ==> 0.30716837986735734\n",
            "Loss in iteration no. 195250 ==> 0.3071683798496004\n",
            "Loss in iteration no. 195251 ==> 0.3071683798318453\n",
            "Loss in iteration no. 195252 ==> 0.3071683798140906\n",
            "Loss in iteration no. 195253 ==> 0.30716837979633727\n",
            "Loss in iteration no. 195254 ==> 0.3071683797785843\n",
            "Loss in iteration no. 195255 ==> 0.30716837976083267\n",
            "Loss in iteration no. 195256 ==> 0.3071683797430815\n",
            "Loss in iteration no. 195257 ==> 0.3071683797253321\n",
            "Loss in iteration no. 195258 ==> 0.3071683797075836\n",
            "Loss in iteration no. 195259 ==> 0.30716837968983607\n",
            "Loss in iteration no. 195260 ==> 0.3071683796720883\n",
            "Loss in iteration no. 195261 ==> 0.3071683796543434\n",
            "Loss in iteration no. 195262 ==> 0.3071683796365979\n",
            "Loss in iteration no. 195263 ==> 0.30716837961885424\n",
            "Loss in iteration no. 195264 ==> 0.3071683796011105\n",
            "Loss in iteration no. 195265 ==> 0.307168379583369\n",
            "Loss in iteration no. 195266 ==> 0.30716837956562804\n",
            "Loss in iteration no. 195267 ==> 0.30716837954788784\n",
            "Loss in iteration no. 195268 ==> 0.30716837953014936\n",
            "Loss in iteration no. 195269 ==> 0.3071683795124104\n",
            "Loss in iteration no. 195270 ==> 0.3071683794946733\n",
            "Loss in iteration no. 195271 ==> 0.307168379476937\n",
            "Loss in iteration no. 195272 ==> 0.30716837945920256\n",
            "Loss in iteration no. 195273 ==> 0.30716837944146846\n",
            "Loss in iteration no. 195274 ==> 0.30716837942373476\n",
            "Loss in iteration no. 195275 ==> 0.307168379406002\n",
            "Loss in iteration no. 195276 ==> 0.30716837938827085\n",
            "Loss in iteration no. 195277 ==> 0.3071683793705408\n",
            "Loss in iteration no. 195278 ==> 0.3071683793528115\n",
            "Loss in iteration no. 195279 ==> 0.3071683793350835\n",
            "Loss in iteration no. 195280 ==> 0.3071683793173559\n",
            "Loss in iteration no. 195281 ==> 0.30716837929962915\n",
            "Loss in iteration no. 195282 ==> 0.3071683792819033\n",
            "Loss in iteration no. 195283 ==> 0.3071683792641793\n",
            "Loss in iteration no. 195284 ==> 0.3071683792464555\n",
            "Loss in iteration no. 195285 ==> 0.3071683792287327\n",
            "Loss in iteration no. 195286 ==> 0.3071683792110117\n",
            "Loss in iteration no. 195287 ==> 0.307168379193291\n",
            "Loss in iteration no. 195288 ==> 0.30716837917557166\n",
            "Loss in iteration no. 195289 ==> 0.30716837915785317\n",
            "Loss in iteration no. 195290 ==> 0.3071683791401355\n",
            "Loss in iteration no. 195291 ==> 0.30716837912241823\n",
            "Loss in iteration no. 195292 ==> 0.30716837910470274\n",
            "Loss in iteration no. 195293 ==> 0.30716837908698813\n",
            "Loss in iteration no. 195294 ==> 0.3071683790692743\n",
            "Loss in iteration no. 195295 ==> 0.3071683790515603\n",
            "Loss in iteration no. 195296 ==> 0.30716837903384925\n",
            "Loss in iteration no. 195297 ==> 0.3071683790161384\n",
            "Loss in iteration no. 195298 ==> 0.30716837899842797\n",
            "Loss in iteration no. 195299 ==> 0.30716837898071886\n",
            "Loss in iteration no. 195300 ==> 0.3071683789630112\n",
            "Loss in iteration no. 195301 ==> 0.30716837894530363\n",
            "Loss in iteration no. 195302 ==> 0.3071683789275981\n",
            "Loss in iteration no. 195303 ==> 0.3071683789098933\n",
            "Loss in iteration no. 195304 ==> 0.3071683788921888\n",
            "Loss in iteration no. 195305 ==> 0.3071683788744852\n",
            "Loss in iteration no. 195306 ==> 0.30716837885678394\n",
            "Loss in iteration no. 195307 ==> 0.30716837883908243\n",
            "Loss in iteration no. 195308 ==> 0.3071683788213818\n",
            "Loss in iteration no. 195309 ==> 0.3071683788036824\n",
            "Loss in iteration no. 195310 ==> 0.30716837878598446\n",
            "Loss in iteration no. 195311 ==> 0.3071683787682868\n",
            "Loss in iteration no. 195312 ==> 0.3071683787505904\n",
            "Loss in iteration no. 195313 ==> 0.3071683787328949\n",
            "Loss in iteration no. 195314 ==> 0.30716837871520125\n",
            "Loss in iteration no. 195315 ==> 0.3071683786975068\n",
            "Loss in iteration no. 195316 ==> 0.3071683786798152\n",
            "Loss in iteration no. 195317 ==> 0.307168378662123\n",
            "Loss in iteration no. 195318 ==> 0.3071683786444326\n",
            "Loss in iteration no. 195319 ==> 0.307168378626743\n",
            "Loss in iteration no. 195320 ==> 0.30716837860905466\n",
            "Loss in iteration no. 195321 ==> 0.30716837859136675\n",
            "Loss in iteration no. 195322 ==> 0.30716837857367996\n",
            "Loss in iteration no. 195323 ==> 0.3071683785559947\n",
            "Loss in iteration no. 195324 ==> 0.30716837853830964\n",
            "Loss in iteration no. 195325 ==> 0.30716837852062545\n",
            "Loss in iteration no. 195326 ==> 0.307168378502943\n",
            "Loss in iteration no. 195327 ==> 0.3071683784852613\n",
            "Loss in iteration no. 195328 ==> 0.30716837846757955\n",
            "Loss in iteration no. 195329 ==> 0.30716837844990064\n",
            "Loss in iteration no. 195330 ==> 0.30716837843222206\n",
            "Loss in iteration no. 195331 ==> 0.3071683784145436\n",
            "Loss in iteration no. 195332 ==> 0.30716837839686645\n",
            "Loss in iteration no. 195333 ==> 0.3071683783791908\n",
            "Loss in iteration no. 195334 ==> 0.30716837836151534\n",
            "Loss in iteration no. 195335 ==> 0.30716837834384114\n",
            "Loss in iteration no. 195336 ==> 0.30716837832616833\n",
            "Loss in iteration no. 195337 ==> 0.30716837830849625\n",
            "Loss in iteration no. 195338 ==> 0.30716837829082505\n",
            "Loss in iteration no. 195339 ==> 0.30716837827315463\n",
            "Loss in iteration no. 195340 ==> 0.30716837825548493\n",
            "Loss in iteration no. 195341 ==> 0.3071683782378171\n",
            "Loss in iteration no. 195342 ==> 0.3071683782201496\n",
            "Loss in iteration no. 195343 ==> 0.3071683782024834\n",
            "Loss in iteration no. 195344 ==> 0.30716837818481735\n",
            "Loss in iteration no. 195345 ==> 0.30716837816715375\n",
            "Loss in iteration no. 195346 ==> 0.30716837814948933\n",
            "Loss in iteration no. 195347 ==> 0.3071683781318273\n",
            "Loss in iteration no. 195348 ==> 0.307168378114166\n",
            "Loss in iteration no. 195349 ==> 0.30716837809650555\n",
            "Loss in iteration no. 195350 ==> 0.30716837807884584\n",
            "Loss in iteration no. 195351 ==> 0.30716837806118696\n",
            "Loss in iteration no. 195352 ==> 0.3071683780435288\n",
            "Loss in iteration no. 195353 ==> 0.30716837802587305\n",
            "Loss in iteration no. 195354 ==> 0.3071683780082165\n",
            "Loss in iteration no. 195355 ==> 0.3071683779905623\n",
            "Loss in iteration no. 195356 ==> 0.30716837797290836\n",
            "Loss in iteration no. 195357 ==> 0.3071683779552556\n",
            "Loss in iteration no. 195358 ==> 0.30716837793760327\n",
            "Loss in iteration no. 195359 ==> 0.30716837791995266\n",
            "Loss in iteration no. 195360 ==> 0.30716837790230284\n",
            "Loss in iteration no. 195361 ==> 0.30716837788465373\n",
            "Loss in iteration no. 195362 ==> 0.30716837786700557\n",
            "Loss in iteration no. 195363 ==> 0.307168377849359\n",
            "Loss in iteration no. 195364 ==> 0.30716837783171286\n",
            "Loss in iteration no. 195365 ==> 0.30716837781406797\n",
            "Loss in iteration no. 195366 ==> 0.3071683777964238\n",
            "Loss in iteration no. 195367 ==> 0.3071683777787805\n",
            "Loss in iteration no. 195368 ==> 0.30716837776113887\n",
            "Loss in iteration no. 195369 ==> 0.3071683777434971\n",
            "Loss in iteration no. 195370 ==> 0.30716837772585653\n",
            "Loss in iteration no. 195371 ==> 0.30716837770821775\n",
            "Loss in iteration no. 195372 ==> 0.3071683776905788\n",
            "Loss in iteration no. 195373 ==> 0.30716837767294153\n",
            "Loss in iteration no. 195374 ==> 0.3071683776553052\n",
            "Loss in iteration no. 195375 ==> 0.30716837763766947\n",
            "Loss in iteration no. 195376 ==> 0.307168377620035\n",
            "Loss in iteration no. 195377 ==> 0.3071683776024019\n",
            "Loss in iteration no. 195378 ==> 0.3071683775847691\n",
            "Loss in iteration no. 195379 ==> 0.30716837756713744\n",
            "Loss in iteration no. 195380 ==> 0.3071683775495072\n",
            "Loss in iteration no. 195381 ==> 0.30716837753187703\n",
            "Loss in iteration no. 195382 ==> 0.30716837751424875\n",
            "Loss in iteration no. 195383 ==> 0.30716837749662124\n",
            "Loss in iteration no. 195384 ==> 0.30716837747899445\n",
            "Loss in iteration no. 195385 ==> 0.30716837746136844\n",
            "Loss in iteration no. 195386 ==> 0.3071683774437442\n",
            "Loss in iteration no. 195387 ==> 0.30716837742612024\n",
            "Loss in iteration no. 195388 ==> 0.30716837740849745\n",
            "Loss in iteration no. 195389 ==> 0.307168377390875\n",
            "Loss in iteration no. 195390 ==> 0.30716837737325386\n",
            "Loss in iteration no. 195391 ==> 0.30716837735563385\n",
            "Loss in iteration no. 195392 ==> 0.3071683773380152\n",
            "Loss in iteration no. 195393 ==> 0.3071683773203972\n",
            "Loss in iteration no. 195394 ==> 0.30716837730278007\n",
            "Loss in iteration no. 195395 ==> 0.30716837728516305\n",
            "Loss in iteration no. 195396 ==> 0.307168377267549\n",
            "Loss in iteration no. 195397 ==> 0.30716837724993507\n",
            "Loss in iteration no. 195398 ==> 0.3071683772323213\n",
            "Loss in iteration no. 195399 ==> 0.30716837721470847\n",
            "Loss in iteration no. 195400 ==> 0.30716837719709733\n",
            "Loss in iteration no. 195401 ==> 0.30716837717948736\n",
            "Loss in iteration no. 195402 ==> 0.30716837716187767\n",
            "Loss in iteration no. 195403 ==> 0.30716837714426976\n",
            "Loss in iteration no. 195404 ==> 0.30716837712666156\n",
            "Loss in iteration no. 195405 ==> 0.3071683771090556\n",
            "Loss in iteration no. 195406 ==> 0.30716837709145045\n",
            "Loss in iteration no. 195407 ==> 0.30716837707384503\n",
            "Loss in iteration no. 195408 ==> 0.3071683770562413\n",
            "Loss in iteration no. 195409 ==> 0.30716837703863886\n",
            "Loss in iteration no. 195410 ==> 0.30716837702103766\n",
            "Loss in iteration no. 195411 ==> 0.30716837700343663\n",
            "Loss in iteration no. 195412 ==> 0.30716837698583693\n",
            "Loss in iteration no. 195413 ==> 0.30716837696823845\n",
            "Loss in iteration no. 195414 ==> 0.3071683769506402\n",
            "Loss in iteration no. 195415 ==> 0.3071683769330431\n",
            "Loss in iteration no. 195416 ==> 0.3071683769154479\n",
            "Loss in iteration no. 195417 ==> 0.30716837689785237\n",
            "Loss in iteration no. 195418 ==> 0.30716837688025955\n",
            "Loss in iteration no. 195419 ==> 0.30716837686266546\n",
            "Loss in iteration no. 195420 ==> 0.3071683768450741\n",
            "Loss in iteration no. 195421 ==> 0.307168376827483\n",
            "Loss in iteration no. 195422 ==> 0.3071683768098931\n",
            "Loss in iteration no. 195423 ==> 0.30716837679230347\n",
            "Loss in iteration no. 195424 ==> 0.3071683767747151\n",
            "Loss in iteration no. 195425 ==> 0.3071683767571278\n",
            "Loss in iteration no. 195426 ==> 0.3071683767395418\n",
            "Loss in iteration no. 195427 ==> 0.3071683767219562\n",
            "Loss in iteration no. 195428 ==> 0.30716837670437214\n",
            "Loss in iteration no. 195429 ==> 0.3071683766867889\n",
            "Loss in iteration no. 195430 ==> 0.30716837666920627\n",
            "Loss in iteration no. 195431 ==> 0.307168376651625\n",
            "Loss in iteration no. 195432 ==> 0.30716837663404434\n",
            "Loss in iteration no. 195433 ==> 0.30716837661646457\n",
            "Loss in iteration no. 195434 ==> 0.30716837659888585\n",
            "Loss in iteration no. 195435 ==> 0.3071683765813084\n",
            "Loss in iteration no. 195436 ==> 0.30716837656373214\n",
            "Loss in iteration no. 195437 ==> 0.30716837654615614\n",
            "Loss in iteration no. 195438 ==> 0.3071683765285819\n",
            "Loss in iteration no. 195439 ==> 0.3071683765110083\n",
            "Loss in iteration no. 195440 ==> 0.3071683764934355\n",
            "Loss in iteration no. 195441 ==> 0.30716837647586337\n",
            "Loss in iteration no. 195442 ==> 0.307168376458293\n",
            "Loss in iteration no. 195443 ==> 0.30716837644072276\n",
            "Loss in iteration no. 195444 ==> 0.30716837642315337\n",
            "Loss in iteration no. 195445 ==> 0.3071683764055855\n",
            "Loss in iteration no. 195446 ==> 0.3071683763880189\n",
            "Loss in iteration no. 195447 ==> 0.3071683763704525\n",
            "Loss in iteration no. 195448 ==> 0.30716837635288796\n",
            "Loss in iteration no. 195449 ==> 0.307168376335324\n",
            "Loss in iteration no. 195450 ==> 0.30716837631776034\n",
            "Loss in iteration no. 195451 ==> 0.3071683763001983\n",
            "Loss in iteration no. 195452 ==> 0.307168376282637\n",
            "Loss in iteration no. 195453 ==> 0.30716837626507637\n",
            "Loss in iteration no. 195454 ==> 0.30716837624751797\n",
            "Loss in iteration no. 195455 ==> 0.30716837622995924\n",
            "Loss in iteration no. 195456 ==> 0.3071683762124013\n",
            "Loss in iteration no. 195457 ==> 0.30716837619484544\n",
            "Loss in iteration no. 195458 ==> 0.3071683761772899\n",
            "Loss in iteration no. 195459 ==> 0.30716837615973563\n",
            "Loss in iteration no. 195460 ==> 0.30716837614218184\n",
            "Loss in iteration no. 195461 ==> 0.30716837612462894\n",
            "Loss in iteration no. 195462 ==> 0.30716837610707703\n",
            "Loss in iteration no. 195463 ==> 0.30716837608952696\n",
            "Loss in iteration no. 195464 ==> 0.30716837607197656\n",
            "Loss in iteration no. 195465 ==> 0.3071683760544279\n",
            "Loss in iteration no. 195466 ==> 0.3071683760368804\n",
            "Loss in iteration no. 195467 ==> 0.30716837601933417\n",
            "Loss in iteration no. 195468 ==> 0.30716837600178803\n",
            "Loss in iteration no. 195469 ==> 0.30716837598424307\n",
            "Loss in iteration no. 195470 ==> 0.3071683759666994\n",
            "Loss in iteration no. 195471 ==> 0.30716837594915586\n",
            "Loss in iteration no. 195472 ==> 0.3071683759316135\n",
            "Loss in iteration no. 195473 ==> 0.30716837591407287\n",
            "Loss in iteration no. 195474 ==> 0.3071683758965329\n",
            "Loss in iteration no. 195475 ==> 0.3071683758789937\n",
            "Loss in iteration no. 195476 ==> 0.30716837586145507\n",
            "Loss in iteration no. 195477 ==> 0.30716837584391815\n",
            "Loss in iteration no. 195478 ==> 0.3071683758263824\n",
            "Loss in iteration no. 195479 ==> 0.30716837580884687\n",
            "Loss in iteration no. 195480 ==> 0.30716837579131256\n",
            "Loss in iteration no. 195481 ==> 0.3071683757737794\n",
            "Loss in iteration no. 195482 ==> 0.30716837575624645\n",
            "Loss in iteration no. 195483 ==> 0.30716837573871564\n",
            "Loss in iteration no. 195484 ==> 0.30716837572118555\n",
            "Loss in iteration no. 195485 ==> 0.307168375703655\n",
            "Loss in iteration no. 195486 ==> 0.3071683756861273\n",
            "Loss in iteration no. 195487 ==> 0.30716837566859917\n",
            "Loss in iteration no. 195488 ==> 0.3071683756510728\n",
            "Loss in iteration no. 195489 ==> 0.3071683756335466\n",
            "Loss in iteration no. 195490 ==> 0.30716837561602256\n",
            "Loss in iteration no. 195491 ==> 0.30716837559849863\n",
            "Loss in iteration no. 195492 ==> 0.3071683755809759\n",
            "Loss in iteration no. 195493 ==> 0.30716837556345344\n",
            "Loss in iteration no. 195494 ==> 0.30716837554593307\n",
            "Loss in iteration no. 195495 ==> 0.30716837552841286\n",
            "Loss in iteration no. 195496 ==> 0.3071683755108944\n",
            "Loss in iteration no. 195497 ==> 0.3071683754933755\n",
            "Loss in iteration no. 195498 ==> 0.3071683754758594\n",
            "Loss in iteration no. 195499 ==> 0.3071683754583428\n",
            "Loss in iteration no. 195500 ==> 0.3071683754408269\n",
            "Loss in iteration no. 195501 ==> 0.3071683754233133\n",
            "Loss in iteration no. 195502 ==> 0.3071683754057998\n",
            "Loss in iteration no. 195503 ==> 0.30716837538828745\n",
            "Loss in iteration no. 195504 ==> 0.30716837537077624\n",
            "Loss in iteration no. 195505 ==> 0.3071683753532662\n",
            "Loss in iteration no. 195506 ==> 0.30716837533575686\n",
            "Loss in iteration no. 195507 ==> 0.3071683753182482\n",
            "Loss in iteration no. 195508 ==> 0.30716837530074065\n",
            "Loss in iteration no. 195509 ==> 0.3071683752832348\n",
            "Loss in iteration no. 195510 ==> 0.3071683752657291\n",
            "Loss in iteration no. 195511 ==> 0.307168375248224\n",
            "Loss in iteration no. 195512 ==> 0.3071683752307206\n",
            "Loss in iteration no. 195513 ==> 0.3071683752132183\n",
            "Loss in iteration no. 195514 ==> 0.3071683751957163\n",
            "Loss in iteration no. 195515 ==> 0.3071683751782153\n",
            "Loss in iteration no. 195516 ==> 0.30716837516071555\n",
            "Loss in iteration no. 195517 ==> 0.3071683751432175\n",
            "Loss in iteration no. 195518 ==> 0.30716837512571893\n",
            "Loss in iteration no. 195519 ==> 0.30716837510822165\n",
            "Loss in iteration no. 195520 ==> 0.307168375090726\n",
            "Loss in iteration no. 195521 ==> 0.30716837507323097\n",
            "Loss in iteration no. 195522 ==> 0.3071683750557366\n",
            "Loss in iteration no. 195523 ==> 0.3071683750382444\n",
            "Loss in iteration no. 195524 ==> 0.30716837502075234\n",
            "Loss in iteration no. 195525 ==> 0.30716837500326033\n",
            "Loss in iteration no. 195526 ==> 0.3071683749857706\n",
            "Loss in iteration no. 195527 ==> 0.30716837496828103\n",
            "Loss in iteration no. 195528 ==> 0.30716837495079247\n",
            "Loss in iteration no. 195529 ==> 0.3071683749333052\n",
            "Loss in iteration no. 195530 ==> 0.3071683749158194\n",
            "Loss in iteration no. 195531 ==> 0.3071683748983333\n",
            "Loss in iteration no. 195532 ==> 0.307168374880849\n",
            "Loss in iteration no. 195533 ==> 0.3071683748633651\n",
            "Loss in iteration no. 195534 ==> 0.30716837484588305\n",
            "Loss in iteration no. 195535 ==> 0.3071683748284021\n",
            "Loss in iteration no. 195536 ==> 0.3071683748109211\n",
            "Loss in iteration no. 195537 ==> 0.30716837479344145\n",
            "Loss in iteration no. 195538 ==> 0.3071683747759628\n",
            "Loss in iteration no. 195539 ==> 0.30716837475848435\n",
            "Loss in iteration no. 195540 ==> 0.307168374741008\n",
            "Loss in iteration no. 195541 ==> 0.3071683747235323\n",
            "Loss in iteration no. 195542 ==> 0.3071683747060574\n",
            "Loss in iteration no. 195543 ==> 0.3071683746885829\n",
            "Loss in iteration no. 195544 ==> 0.30716837467111013\n",
            "Loss in iteration no. 195545 ==> 0.30716837465363794\n",
            "Loss in iteration no. 195546 ==> 0.30716837463616686\n",
            "Loss in iteration no. 195547 ==> 0.307168374618697\n",
            "Loss in iteration no. 195548 ==> 0.3071683746012282\n",
            "Loss in iteration no. 195549 ==> 0.30716837458375956\n",
            "Loss in iteration no. 195550 ==> 0.30716837456629204\n",
            "Loss in iteration no. 195551 ==> 0.30716837454882556\n",
            "Loss in iteration no. 195552 ==> 0.3071683745313608\n",
            "Loss in iteration no. 195553 ==> 0.30716837451389667\n",
            "Loss in iteration no. 195554 ==> 0.30716837449643264\n",
            "Loss in iteration no. 195555 ==> 0.3071683744789702\n",
            "Loss in iteration no. 195556 ==> 0.3071683744615089\n",
            "Loss in iteration no. 195557 ==> 0.30716837444404826\n",
            "Loss in iteration no. 195558 ==> 0.3071683744265883\n",
            "Loss in iteration no. 195559 ==> 0.3071683744091304\n",
            "Loss in iteration no. 195560 ==> 0.3071683743916725\n",
            "Loss in iteration no. 195561 ==> 0.30716837437421585\n",
            "Loss in iteration no. 195562 ==> 0.30716837435675975\n",
            "Loss in iteration no. 195563 ==> 0.3071683743393053\n",
            "Loss in iteration no. 195564 ==> 0.30716837432185096\n",
            "Loss in iteration no. 195565 ==> 0.30716837430439814\n",
            "Loss in iteration no. 195566 ==> 0.30716837428694604\n",
            "Loss in iteration no. 195567 ==> 0.3071683742694955\n",
            "Loss in iteration no. 195568 ==> 0.3071683742520453\n",
            "Loss in iteration no. 195569 ==> 0.3071683742345964\n",
            "Loss in iteration no. 195570 ==> 0.30716837421714815\n",
            "Loss in iteration no. 195571 ==> 0.30716837419970106\n",
            "Loss in iteration no. 195572 ==> 0.3071683741822542\n",
            "Loss in iteration no. 195573 ==> 0.30716837416480985\n",
            "Loss in iteration no. 195574 ==> 0.30716837414736514\n",
            "Loss in iteration no. 195575 ==> 0.30716837412992143\n",
            "Loss in iteration no. 195576 ==> 0.3071683741124794\n",
            "Loss in iteration no. 195577 ==> 0.30716837409503794\n",
            "Loss in iteration no. 195578 ==> 0.3071683740775971\n",
            "Loss in iteration no. 195579 ==> 0.30716837406015796\n",
            "Loss in iteration no. 195580 ==> 0.3071683740427193\n",
            "Loss in iteration no. 195581 ==> 0.3071683740252818\n",
            "Loss in iteration no. 195582 ==> 0.30716837400784536\n",
            "Loss in iteration no. 195583 ==> 0.30716837399040897\n",
            "Loss in iteration no. 195584 ==> 0.3071683739729748\n",
            "Loss in iteration no. 195585 ==> 0.30716837395554064\n",
            "Loss in iteration no. 195586 ==> 0.3071683739381081\n",
            "Loss in iteration no. 195587 ==> 0.30716837392067614\n",
            "Loss in iteration no. 195588 ==> 0.30716837390324486\n",
            "Loss in iteration no. 195589 ==> 0.30716837388581514\n",
            "Loss in iteration no. 195590 ==> 0.3071683738683859\n",
            "Loss in iteration no. 195591 ==> 0.3071683738509579\n",
            "Loss in iteration no. 195592 ==> 0.3071683738335304\n",
            "Loss in iteration no. 195593 ==> 0.3071683738161045\n",
            "Loss in iteration no. 195594 ==> 0.30716837379867973\n",
            "Loss in iteration no. 195595 ==> 0.30716837378125506\n",
            "Loss in iteration no. 195596 ==> 0.3071683737638318\n",
            "Loss in iteration no. 195597 ==> 0.30716837374640943\n",
            "Loss in iteration no. 195598 ==> 0.3071683737289879\n",
            "Loss in iteration no. 195599 ==> 0.3071683737115681\n",
            "Loss in iteration no. 195600 ==> 0.30716837369414784\n",
            "Loss in iteration no. 195601 ==> 0.3071683736767301\n",
            "Loss in iteration no. 195602 ==> 0.3071683736593125\n",
            "Loss in iteration no. 195603 ==> 0.3071683736418955\n",
            "Loss in iteration no. 195604 ==> 0.3071683736244801\n",
            "Loss in iteration no. 195605 ==> 0.3071683736070647\n",
            "Loss in iteration no. 195606 ==> 0.3071683735896514\n",
            "Loss in iteration no. 195607 ==> 0.3071683735722383\n",
            "Loss in iteration no. 195608 ==> 0.30716837355482657\n",
            "Loss in iteration no. 195609 ==> 0.3071683735374156\n",
            "Loss in iteration no. 195610 ==> 0.3071683735200056\n",
            "Loss in iteration no. 195611 ==> 0.30716837350259735\n",
            "Loss in iteration no. 195612 ==> 0.3071683734851884\n",
            "Loss in iteration no. 195613 ==> 0.30716837346778114\n",
            "Loss in iteration no. 195614 ==> 0.307168373450376\n",
            "Loss in iteration no. 195615 ==> 0.3071683734329709\n",
            "Loss in iteration no. 195616 ==> 0.3071683734155659\n",
            "Loss in iteration no. 195617 ==> 0.30716837339816294\n",
            "Loss in iteration no. 195618 ==> 0.30716837338076114\n",
            "Loss in iteration no. 195619 ==> 0.30716837336335917\n",
            "Loss in iteration no. 195620 ==> 0.3071683733459585\n",
            "Loss in iteration no. 195621 ==> 0.30716837332855934\n",
            "Loss in iteration no. 195622 ==> 0.3071683733111607\n",
            "Loss in iteration no. 195623 ==> 0.3071683732937636\n",
            "Loss in iteration no. 195624 ==> 0.3071683732763662\n",
            "Loss in iteration no. 195625 ==> 0.3071683732589713\n",
            "Loss in iteration no. 195626 ==> 0.3071683732415765\n",
            "Loss in iteration no. 195627 ==> 0.3071683732241826\n",
            "Loss in iteration no. 195628 ==> 0.30716837320678986\n",
            "Loss in iteration no. 195629 ==> 0.30716837318939827\n",
            "Loss in iteration no. 195630 ==> 0.3071683731720066\n",
            "Loss in iteration no. 195631 ==> 0.30716837315461715\n",
            "Loss in iteration no. 195632 ==> 0.3071683731372281\n",
            "Loss in iteration no. 195633 ==> 0.3071683731198397\n",
            "Loss in iteration no. 195634 ==> 0.3071683731024523\n",
            "Loss in iteration no. 195635 ==> 0.3071683730850665\n",
            "Loss in iteration no. 195636 ==> 0.30716837306768174\n",
            "Loss in iteration no. 195637 ==> 0.30716837305029704\n",
            "Loss in iteration no. 195638 ==> 0.30716837303291394\n",
            "Loss in iteration no. 195639 ==> 0.3071683730155313\n",
            "Loss in iteration no. 195640 ==> 0.30716837299814975\n",
            "Loss in iteration no. 195641 ==> 0.3071683729807692\n",
            "Loss in iteration no. 195642 ==> 0.3071683729633903\n",
            "Loss in iteration no. 195643 ==> 0.3071683729460119\n",
            "Loss in iteration no. 195644 ==> 0.3071683729286335\n",
            "Loss in iteration no. 195645 ==> 0.30716837291125776\n",
            "Loss in iteration no. 195646 ==> 0.30716837289388144\n",
            "Loss in iteration no. 195647 ==> 0.3071683728765068\n",
            "Loss in iteration no. 195648 ==> 0.3071683728591332\n",
            "Loss in iteration no. 195649 ==> 0.30716837284176046\n",
            "Loss in iteration no. 195650 ==> 0.3071683728243889\n",
            "Loss in iteration no. 195651 ==> 0.30716837280701836\n",
            "Loss in iteration no. 195652 ==> 0.307168372789648\n",
            "Loss in iteration no. 195653 ==> 0.3071683727722785\n",
            "Loss in iteration no. 195654 ==> 0.30716837275491105\n",
            "Loss in iteration no. 195655 ==> 0.3071683727375437\n",
            "Loss in iteration no. 195656 ==> 0.3071683727201779\n",
            "Loss in iteration no. 195657 ==> 0.3071683727028126\n",
            "Loss in iteration no. 195658 ==> 0.30716837268544783\n",
            "Loss in iteration no. 195659 ==> 0.3071683726680851\n",
            "Loss in iteration no. 195660 ==> 0.30716837265072194\n",
            "Loss in iteration no. 195661 ==> 0.3071683726333613\n",
            "Loss in iteration no. 195662 ==> 0.3071683726160007\n",
            "Loss in iteration no. 195663 ==> 0.30716837259864116\n",
            "Loss in iteration no. 195664 ==> 0.3071683725812831\n",
            "Loss in iteration no. 195665 ==> 0.3071683725639245\n",
            "Loss in iteration no. 195666 ==> 0.3071683725465681\n",
            "Loss in iteration no. 195667 ==> 0.3071683725292126\n",
            "Loss in iteration no. 195668 ==> 0.3071683725118577\n",
            "Loss in iteration no. 195669 ==> 0.3071683724945038\n",
            "Loss in iteration no. 195670 ==> 0.30716837247715145\n",
            "Loss in iteration no. 195671 ==> 0.30716837245979955\n",
            "Loss in iteration no. 195672 ==> 0.30716837244244877\n",
            "Loss in iteration no. 195673 ==> 0.307168372425099\n",
            "Loss in iteration no. 195674 ==> 0.30716837240774925\n",
            "Loss in iteration no. 195675 ==> 0.30716837239040157\n",
            "Loss in iteration no. 195676 ==> 0.3071683723730538\n",
            "Loss in iteration no. 195677 ==> 0.307168372355708\n",
            "Loss in iteration no. 195678 ==> 0.3071683723383629\n",
            "Loss in iteration no. 195679 ==> 0.30716837232101823\n",
            "Loss in iteration no. 195680 ==> 0.30716837230367505\n",
            "Loss in iteration no. 195681 ==> 0.3071683722863325\n",
            "Loss in iteration no. 195682 ==> 0.3071683722689914\n",
            "Loss in iteration no. 195683 ==> 0.3071683722516502\n",
            "Loss in iteration no. 195684 ==> 0.30716837223431115\n",
            "Loss in iteration no. 195685 ==> 0.30716837221697213\n",
            "Loss in iteration no. 195686 ==> 0.30716837219963516\n",
            "Loss in iteration no. 195687 ==> 0.30716837218229803\n",
            "Loss in iteration no. 195688 ==> 0.30716837216496207\n",
            "Loss in iteration no. 195689 ==> 0.3071683721476271\n",
            "Loss in iteration no. 195690 ==> 0.3071683721302936\n",
            "Loss in iteration no. 195691 ==> 0.30716837211296066\n",
            "Loss in iteration no. 195692 ==> 0.3071683720956291\n",
            "Loss in iteration no. 195693 ==> 0.30716837207829767\n",
            "Loss in iteration no. 195694 ==> 0.30716837206096775\n",
            "Loss in iteration no. 195695 ==> 0.3071683720436382\n",
            "Loss in iteration no. 195696 ==> 0.3071683720263108\n",
            "Loss in iteration no. 195697 ==> 0.30716837200898334\n",
            "Loss in iteration no. 195698 ==> 0.3071683719916569\n",
            "Loss in iteration no. 195699 ==> 0.30716837197433144\n",
            "Loss in iteration no. 195700 ==> 0.3071683719570075\n",
            "Loss in iteration no. 195701 ==> 0.30716837193968416\n",
            "Loss in iteration no. 195702 ==> 0.30716837192236124\n",
            "Loss in iteration no. 195703 ==> 0.30716837190503976\n",
            "Loss in iteration no. 195704 ==> 0.3071683718877199\n",
            "Loss in iteration no. 195705 ==> 0.3071683718703994\n",
            "Loss in iteration no. 195706 ==> 0.3071683718530805\n",
            "Loss in iteration no. 195707 ==> 0.3071683718357636\n",
            "Loss in iteration no. 195708 ==> 0.30716837181844664\n",
            "Loss in iteration no. 195709 ==> 0.3071683718011307\n",
            "Loss in iteration no. 195710 ==> 0.3071683717838158\n",
            "Loss in iteration no. 195711 ==> 0.3071683717665023\n",
            "Loss in iteration no. 195712 ==> 0.3071683717491893\n",
            "Loss in iteration no. 195713 ==> 0.3071683717318764\n",
            "Loss in iteration no. 195714 ==> 0.3071683717145659\n",
            "Loss in iteration no. 195715 ==> 0.3071683716972549\n",
            "Loss in iteration no. 195716 ==> 0.30716837167994643\n",
            "Loss in iteration no. 195717 ==> 0.307168371662638\n",
            "Loss in iteration no. 195718 ==> 0.30716837164533134\n",
            "Loss in iteration no. 195719 ==> 0.30716837162802485\n",
            "Loss in iteration no. 195720 ==> 0.3071683716107193\n",
            "Loss in iteration no. 195721 ==> 0.3071683715934147\n",
            "Loss in iteration no. 195722 ==> 0.3071683715761112\n",
            "Loss in iteration no. 195723 ==> 0.3071683715588086\n",
            "Loss in iteration no. 195724 ==> 0.3071683715415075\n",
            "Loss in iteration no. 195725 ==> 0.3071683715242059\n",
            "Loss in iteration no. 195726 ==> 0.30716837150690673\n",
            "Loss in iteration no. 195727 ==> 0.307168371489608\n",
            "Loss in iteration no. 195728 ==> 0.30716837147230985\n",
            "Loss in iteration no. 195729 ==> 0.30716837145501263\n",
            "Loss in iteration no. 195730 ==> 0.30716837143771747\n",
            "Loss in iteration no. 195731 ==> 0.3071683714204222\n",
            "Loss in iteration no. 195732 ==> 0.3071683714031279\n",
            "Loss in iteration no. 195733 ==> 0.3071683713858345\n",
            "Loss in iteration no. 195734 ==> 0.30716837136854225\n",
            "Loss in iteration no. 195735 ==> 0.3071683713512514\n",
            "Loss in iteration no. 195736 ==> 0.3071683713339611\n",
            "Loss in iteration no. 195737 ==> 0.30716837131667213\n",
            "Loss in iteration no. 195738 ==> 0.30716837129938374\n",
            "Loss in iteration no. 195739 ==> 0.30716837128209684\n",
            "Loss in iteration no. 195740 ==> 0.3071683712648097\n",
            "Loss in iteration no. 195741 ==> 0.3071683712475248\n",
            "Loss in iteration no. 195742 ==> 0.3071683712302397\n",
            "Loss in iteration no. 195743 ==> 0.30716837121295665\n",
            "Loss in iteration no. 195744 ==> 0.3071683711956734\n",
            "Loss in iteration no. 195745 ==> 0.3071683711783923\n",
            "Loss in iteration no. 195746 ==> 0.3071683711611111\n",
            "Loss in iteration no. 195747 ==> 0.30716837114383144\n",
            "Loss in iteration no. 195748 ==> 0.3071683711265522\n",
            "Loss in iteration no. 195749 ==> 0.30716837110927436\n",
            "Loss in iteration no. 195750 ==> 0.307168371091997\n",
            "Loss in iteration no. 195751 ==> 0.3071683710747211\n",
            "Loss in iteration no. 195752 ==> 0.30716837105744627\n",
            "Loss in iteration no. 195753 ==> 0.30716837104017225\n",
            "Loss in iteration no. 195754 ==> 0.30716837102289934\n",
            "Loss in iteration no. 195755 ==> 0.30716837100562633\n",
            "Loss in iteration no. 195756 ==> 0.3071683709883552\n",
            "Loss in iteration no. 195757 ==> 0.30716837097108507\n",
            "Loss in iteration no. 195758 ==> 0.30716837095381533\n",
            "Loss in iteration no. 195759 ==> 0.30716837093654714\n",
            "Loss in iteration no. 195760 ==> 0.3071683709192794\n",
            "Loss in iteration no. 195761 ==> 0.3071683709020131\n",
            "Loss in iteration no. 195762 ==> 0.3071683708847472\n",
            "Loss in iteration no. 195763 ==> 0.3071683708674823\n",
            "Loss in iteration no. 195764 ==> 0.30716837085021936\n",
            "Loss in iteration no. 195765 ==> 0.30716837083295634\n",
            "Loss in iteration no. 195766 ==> 0.3071683708156943\n",
            "Loss in iteration no. 195767 ==> 0.3071683707984331\n",
            "Loss in iteration no. 195768 ==> 0.307168370781173\n",
            "Loss in iteration no. 195769 ==> 0.30716837076391384\n",
            "Loss in iteration no. 195770 ==> 0.30716837074665604\n",
            "Loss in iteration no. 195771 ==> 0.3071683707293987\n",
            "Loss in iteration no. 195772 ==> 0.3071683707121428\n",
            "Loss in iteration no. 195773 ==> 0.3071683706948874\n",
            "Loss in iteration no. 195774 ==> 0.30716837067763336\n",
            "Loss in iteration no. 195775 ==> 0.30716837066037933\n",
            "Loss in iteration no. 195776 ==> 0.3071683706431272\n",
            "Loss in iteration no. 195777 ==> 0.30716837062587593\n",
            "Loss in iteration no. 195778 ==> 0.3071683706086248\n",
            "Loss in iteration no. 195779 ==> 0.3071683705913755\n",
            "Loss in iteration no. 195780 ==> 0.3071683705741271\n",
            "Loss in iteration no. 195781 ==> 0.3071683705568792\n",
            "Loss in iteration no. 195782 ==> 0.3071683705396327\n",
            "Loss in iteration no. 195783 ==> 0.3071683705223867\n",
            "Loss in iteration no. 195784 ==> 0.30716837050514206\n",
            "Loss in iteration no. 195785 ==> 0.30716837048789786\n",
            "Loss in iteration no. 195786 ==> 0.3071683704706556\n",
            "Loss in iteration no. 195787 ==> 0.3071683704534133\n",
            "Loss in iteration no. 195788 ==> 0.3071683704361719\n",
            "Loss in iteration no. 195789 ==> 0.30716837041893136\n",
            "Loss in iteration no. 195790 ==> 0.3071683704016928\n",
            "Loss in iteration no. 195791 ==> 0.30716837038445427\n",
            "Loss in iteration no. 195792 ==> 0.307168370367217\n",
            "Loss in iteration no. 195793 ==> 0.3071683703499803\n",
            "Loss in iteration no. 195794 ==> 0.30716837033274547\n",
            "Loss in iteration no. 195795 ==> 0.30716837031551103\n",
            "Loss in iteration no. 195796 ==> 0.3071683702982776\n",
            "Loss in iteration no. 195797 ==> 0.30716837028104454\n",
            "Loss in iteration no. 195798 ==> 0.30716837026381294\n",
            "Loss in iteration no. 195799 ==> 0.30716837024658217\n",
            "Loss in iteration no. 195800 ==> 0.3071683702293524\n",
            "Loss in iteration no. 195801 ==> 0.3071683702121235\n",
            "Loss in iteration no. 195802 ==> 0.3071683701948956\n",
            "Loss in iteration no. 195803 ==> 0.30716837017766896\n",
            "Loss in iteration no. 195804 ==> 0.30716837016044285\n",
            "Loss in iteration no. 195805 ==> 0.3071683701432182\n",
            "Loss in iteration no. 195806 ==> 0.3071683701259939\n",
            "Loss in iteration no. 195807 ==> 0.30716837010877107\n",
            "Loss in iteration no. 195808 ==> 0.3071683700915486\n",
            "Loss in iteration no. 195809 ==> 0.3071683700743265\n",
            "Loss in iteration no. 195810 ==> 0.3071683700571064\n",
            "Loss in iteration no. 195811 ==> 0.30716837003988723\n",
            "Loss in iteration no. 195812 ==> 0.30716837002266895\n",
            "Loss in iteration no. 195813 ==> 0.3071683700054515\n",
            "Loss in iteration no. 195814 ==> 0.3071683699882355\n",
            "Loss in iteration no. 195815 ==> 0.3071683699710189\n",
            "Loss in iteration no. 195816 ==> 0.3071683699538042\n",
            "Loss in iteration no. 195817 ==> 0.30716836993659097\n",
            "Loss in iteration no. 195818 ==> 0.3071683699193782\n",
            "Loss in iteration no. 195819 ==> 0.3071683699021667\n",
            "Loss in iteration no. 195820 ==> 0.30716836988495516\n",
            "Loss in iteration no. 195821 ==> 0.3071683698677455\n",
            "Loss in iteration no. 195822 ==> 0.30716836985053675\n",
            "Loss in iteration no. 195823 ==> 0.3071683698333289\n",
            "Loss in iteration no. 195824 ==> 0.307168369816121\n",
            "Loss in iteration no. 195825 ==> 0.30716836979891493\n",
            "Loss in iteration no. 195826 ==> 0.30716836978170986\n",
            "Loss in iteration no. 195827 ==> 0.3071683697645057\n",
            "Loss in iteration no. 195828 ==> 0.3071683697473018\n",
            "Loss in iteration no. 195829 ==> 0.30716836973009926\n",
            "Loss in iteration no. 195830 ==> 0.3071683697128983\n",
            "Loss in iteration no. 195831 ==> 0.3071683696956981\n",
            "Loss in iteration no. 195832 ==> 0.3071683696784978\n",
            "Loss in iteration no. 195833 ==> 0.307168369661299\n",
            "Loss in iteration no. 195834 ==> 0.30716836964410155\n",
            "Loss in iteration no. 195835 ==> 0.3071683696269055\n",
            "Loss in iteration no. 195836 ==> 0.3071683696097088\n",
            "Loss in iteration no. 195837 ==> 0.307168369592514\n",
            "Loss in iteration no. 195838 ==> 0.30716836957532007\n",
            "Loss in iteration no. 195839 ==> 0.3071683695581275\n",
            "Loss in iteration no. 195840 ==> 0.3071683695409354\n",
            "Loss in iteration no. 195841 ==> 0.30716836952374366\n",
            "Loss in iteration no. 195842 ==> 0.3071683695065533\n",
            "Loss in iteration no. 195843 ==> 0.3071683694893643\n",
            "Loss in iteration no. 195844 ==> 0.30716836947217624\n",
            "Loss in iteration no. 195845 ==> 0.30716836945498904\n",
            "Loss in iteration no. 195846 ==> 0.3071683694378027\n",
            "Loss in iteration no. 195847 ==> 0.30716836942061726\n",
            "Loss in iteration no. 195848 ==> 0.3071683694034327\n",
            "Loss in iteration no. 195849 ==> 0.30716836938624953\n",
            "Loss in iteration no. 195850 ==> 0.3071683693690658\n",
            "Loss in iteration no. 195851 ==> 0.30716836935188385\n",
            "Loss in iteration no. 195852 ==> 0.3071683693347033\n",
            "Loss in iteration no. 195853 ==> 0.30716836931752367\n",
            "Loss in iteration no. 195854 ==> 0.3071683693003444\n",
            "Loss in iteration no. 195855 ==> 0.30716836928316754\n",
            "Loss in iteration no. 195856 ==> 0.30716836926599045\n",
            "Loss in iteration no. 195857 ==> 0.3071683692488143\n",
            "Loss in iteration no. 195858 ==> 0.307168369231639\n",
            "Loss in iteration no. 195859 ==> 0.3071683692144646\n",
            "Loss in iteration no. 195860 ==> 0.30716836919729107\n",
            "Loss in iteration no. 195861 ==> 0.30716836918011897\n",
            "Loss in iteration no. 195862 ==> 0.3071683691629481\n",
            "Loss in iteration no. 195863 ==> 0.3071683691457777\n",
            "Loss in iteration no. 195864 ==> 0.30716836912860757\n",
            "Loss in iteration no. 195865 ==> 0.3071683691114389\n",
            "Loss in iteration no. 195866 ==> 0.30716836909427214\n",
            "Loss in iteration no. 195867 ==> 0.30716836907710454\n",
            "Loss in iteration no. 195868 ==> 0.3071683690599396\n",
            "Loss in iteration no. 195869 ==> 0.30716836904277434\n",
            "Loss in iteration no. 195870 ==> 0.3071683690256104\n",
            "Loss in iteration no. 195871 ==> 0.30716836900844796\n",
            "Loss in iteration no. 195872 ==> 0.30716836899128525\n",
            "Loss in iteration no. 195873 ==> 0.30716836897412453\n",
            "Loss in iteration no. 195874 ==> 0.30716836895696514\n",
            "Loss in iteration no. 195875 ==> 0.30716836893980504\n",
            "Loss in iteration no. 195876 ==> 0.3071683689226473\n",
            "Loss in iteration no. 195877 ==> 0.3071683689054905\n",
            "Loss in iteration no. 195878 ==> 0.307168368888333\n",
            "Loss in iteration no. 195879 ==> 0.3071683688711779\n",
            "Loss in iteration no. 195880 ==> 0.3071683688540236\n",
            "Loss in iteration no. 195881 ==> 0.3071683688368702\n",
            "Loss in iteration no. 195882 ==> 0.30716836881971815\n",
            "Loss in iteration no. 195883 ==> 0.3071683688025664\n",
            "Loss in iteration no. 195884 ==> 0.30716836878541554\n",
            "Loss in iteration no. 195885 ==> 0.3071683687682661\n",
            "Loss in iteration no. 195886 ==> 0.3071683687511169\n",
            "Loss in iteration no. 195887 ==> 0.307168368733969\n",
            "Loss in iteration no. 195888 ==> 0.3071683687168217\n",
            "Loss in iteration no. 195889 ==> 0.3071683686996755\n",
            "Loss in iteration no. 195890 ==> 0.3071683686825312\n",
            "Loss in iteration no. 195891 ==> 0.3071683686653868\n",
            "Loss in iteration no. 195892 ==> 0.30716836864824326\n",
            "Loss in iteration no. 195893 ==> 0.30716836863110153\n",
            "Loss in iteration no. 195894 ==> 0.30716836861395974\n",
            "Loss in iteration no. 195895 ==> 0.3071683685968197\n",
            "Loss in iteration no. 195896 ==> 0.30716836857968\n",
            "Loss in iteration no. 195897 ==> 0.3071683685625416\n",
            "Loss in iteration no. 195898 ==> 0.3071683685454046\n",
            "Loss in iteration no. 195899 ==> 0.3071683685282679\n",
            "Loss in iteration no. 195900 ==> 0.30716836851113155\n",
            "Loss in iteration no. 195901 ==> 0.3071683684939971\n",
            "Loss in iteration no. 195902 ==> 0.30716836847686335\n",
            "Loss in iteration no. 195903 ==> 0.30716836845973056\n",
            "Loss in iteration no. 195904 ==> 0.30716836844259865\n",
            "Loss in iteration no. 195905 ==> 0.3071683684254674\n",
            "Loss in iteration no. 195906 ==> 0.30716836840833717\n",
            "Loss in iteration no. 195907 ==> 0.3071683683912092\n",
            "Loss in iteration no. 195908 ==> 0.30716836837408057\n",
            "Loss in iteration no. 195909 ==> 0.3071683683569527\n",
            "Loss in iteration no. 195910 ==> 0.3071683683398272\n",
            "Loss in iteration no. 195911 ==> 0.30716836832270156\n",
            "Loss in iteration no. 195912 ==> 0.3071683683055777\n",
            "Loss in iteration no. 195913 ==> 0.30716836828845323\n",
            "Loss in iteration no. 195914 ==> 0.30716836827133104\n",
            "Loss in iteration no. 195915 ==> 0.30716836825420973\n",
            "Loss in iteration no. 195916 ==> 0.3071683682370881\n",
            "Loss in iteration no. 195917 ==> 0.30716836821996896\n",
            "Loss in iteration no. 195918 ==> 0.3071683682028502\n",
            "Loss in iteration no. 195919 ==> 0.30716836818573207\n",
            "Loss in iteration no. 195920 ==> 0.30716836816861537\n",
            "Loss in iteration no. 195921 ==> 0.30716836815149895\n",
            "Loss in iteration no. 195922 ==> 0.30716836813438486\n",
            "Loss in iteration no. 195923 ==> 0.30716836811727066\n",
            "Loss in iteration no. 195924 ==> 0.30716836810015663\n",
            "Loss in iteration no. 195925 ==> 0.30716836808304504\n",
            "Loss in iteration no. 195926 ==> 0.3071683680659333\n",
            "Loss in iteration no. 195927 ==> 0.3071683680488233\n",
            "Loss in iteration no. 195928 ==> 0.30716836803171416\n",
            "Loss in iteration no. 195929 ==> 0.30716836801460523\n",
            "Loss in iteration no. 195930 ==> 0.3071683679974977\n",
            "Loss in iteration no. 195931 ==> 0.30716836798039093\n",
            "Loss in iteration no. 195932 ==> 0.3071683679632856\n",
            "Loss in iteration no. 195933 ==> 0.30716836794618047\n",
            "Loss in iteration no. 195934 ==> 0.30716836792907665\n",
            "Loss in iteration no. 195935 ==> 0.30716836791197366\n",
            "Loss in iteration no. 195936 ==> 0.30716836789487245\n",
            "Loss in iteration no. 195937 ==> 0.30716836787777113\n",
            "Loss in iteration no. 195938 ==> 0.30716836786067164\n",
            "Loss in iteration no. 195939 ==> 0.3071683678435719\n",
            "Loss in iteration no. 195940 ==> 0.3071683678264739\n",
            "Loss in iteration no. 195941 ==> 0.30716836780937684\n",
            "Loss in iteration no. 195942 ==> 0.30716836779227996\n",
            "Loss in iteration no. 195943 ==> 0.30716836777518447\n",
            "Loss in iteration no. 195944 ==> 0.3071683677580902\n",
            "Loss in iteration no. 195945 ==> 0.3071683677409964\n",
            "Loss in iteration no. 195946 ==> 0.3071683677239047\n",
            "Loss in iteration no. 195947 ==> 0.30716836770681283\n",
            "Loss in iteration no. 195948 ==> 0.3071683676897219\n",
            "Loss in iteration no. 195949 ==> 0.30716836767263267\n",
            "Loss in iteration no. 195950 ==> 0.30716836765554323\n",
            "Loss in iteration no. 195951 ==> 0.3071683676384556\n",
            "Loss in iteration no. 195952 ==> 0.3071683676213688\n",
            "Loss in iteration no. 195953 ==> 0.3071683676042828\n",
            "Loss in iteration no. 195954 ==> 0.307168367587198\n",
            "Loss in iteration no. 195955 ==> 0.30716836757011357\n",
            "Loss in iteration no. 195956 ==> 0.30716836755303045\n",
            "Loss in iteration no. 195957 ==> 0.30716836753594756\n",
            "Loss in iteration no. 195958 ==> 0.30716836751886606\n",
            "Loss in iteration no. 195959 ==> 0.30716836750178633\n",
            "Loss in iteration no. 195960 ==> 0.3071683674847062\n",
            "Loss in iteration no. 195961 ==> 0.3071683674676281\n",
            "Loss in iteration no. 195962 ==> 0.3071683674505507\n",
            "Loss in iteration no. 195963 ==> 0.3071683674334741\n",
            "Loss in iteration no. 195964 ==> 0.30716836741639886\n",
            "Loss in iteration no. 195965 ==> 0.3071683673993238\n",
            "Loss in iteration no. 195966 ==> 0.30716836738224956\n",
            "Loss in iteration no. 195967 ==> 0.30716836736517655\n",
            "Loss in iteration no. 195968 ==> 0.3071683673481039\n",
            "Loss in iteration no. 195969 ==> 0.3071683673310335\n",
            "Loss in iteration no. 195970 ==> 0.3071683673139638\n",
            "Loss in iteration no. 195971 ==> 0.30716836729689395\n",
            "Loss in iteration no. 195972 ==> 0.30716836727982605\n",
            "Loss in iteration no. 195973 ==> 0.30716836726275865\n",
            "Loss in iteration no. 195974 ==> 0.3071683672456922\n",
            "Loss in iteration no. 195975 ==> 0.30716836722862645\n",
            "Loss in iteration no. 195976 ==> 0.307168367211562\n",
            "Loss in iteration no. 195977 ==> 0.3071683671944988\n",
            "Loss in iteration no. 195978 ==> 0.3071683671774354\n",
            "Loss in iteration no. 195979 ==> 0.3071683671603743\n",
            "Loss in iteration no. 195980 ==> 0.307168367143314\n",
            "Loss in iteration no. 195981 ==> 0.3071683671262539\n",
            "Loss in iteration no. 195982 ==> 0.3071683671091951\n",
            "Loss in iteration no. 195983 ==> 0.30716836709213713\n",
            "Loss in iteration no. 195984 ==> 0.3071683670750798\n",
            "Loss in iteration no. 195985 ==> 0.3071683670580234\n",
            "Loss in iteration no. 195986 ==> 0.3071683670409686\n",
            "Loss in iteration no. 195987 ==> 0.30716836702391415\n",
            "Loss in iteration no. 195988 ==> 0.30716836700686095\n",
            "Loss in iteration no. 195989 ==> 0.3071683669898091\n",
            "Loss in iteration no. 195990 ==> 0.30716836697275746\n",
            "Loss in iteration no. 195991 ==> 0.3071683669557071\n",
            "Loss in iteration no. 195992 ==> 0.307168366938657\n",
            "Loss in iteration no. 195993 ==> 0.3071683669216081\n",
            "Loss in iteration no. 195994 ==> 0.307168366904561\n",
            "Loss in iteration no. 195995 ==> 0.3071683668875137\n",
            "Loss in iteration no. 195996 ==> 0.30716836687046806\n",
            "Loss in iteration no. 195997 ==> 0.30716836685342336\n",
            "Loss in iteration no. 195998 ==> 0.30716836683637927\n",
            "Loss in iteration no. 195999 ==> 0.30716836681933646\n",
            "Loss in iteration no. 196000 ==> 0.307168366802294\n",
            "Loss in iteration no. 196001 ==> 0.30716836678525367\n",
            "Loss in iteration no. 196002 ==> 0.3071683667682127\n",
            "Loss in iteration no. 196003 ==> 0.30716836675117387\n",
            "Loss in iteration no. 196004 ==> 0.3071683667341344\n",
            "Loss in iteration no. 196005 ==> 0.3071683667170971\n",
            "Loss in iteration no. 196006 ==> 0.30716836670006054\n",
            "Loss in iteration no. 196007 ==> 0.3071683666830259\n",
            "Loss in iteration no. 196008 ==> 0.3071683666659909\n",
            "Loss in iteration no. 196009 ==> 0.3071683666489566\n",
            "Loss in iteration no. 196010 ==> 0.30716836663192465\n",
            "Loss in iteration no. 196011 ==> 0.3071683666148929\n",
            "Loss in iteration no. 196012 ==> 0.3071683665978624\n",
            "Loss in iteration no. 196013 ==> 0.30716836658083213\n",
            "Loss in iteration no. 196014 ==> 0.3071683665638031\n",
            "Loss in iteration no. 196015 ==> 0.3071683665467743\n",
            "Loss in iteration no. 196016 ==> 0.30716836652974683\n",
            "Loss in iteration no. 196017 ==> 0.3071683665127211\n",
            "Loss in iteration no. 196018 ==> 0.30716836649569595\n",
            "Loss in iteration no. 196019 ==> 0.3071683664786718\n",
            "Loss in iteration no. 196020 ==> 0.3071683664616482\n",
            "Loss in iteration no. 196021 ==> 0.30716836644462536\n",
            "Loss in iteration no. 196022 ==> 0.30716836642760376\n",
            "Loss in iteration no. 196023 ==> 0.3071683664105835\n",
            "Loss in iteration no. 196024 ==> 0.3071683663935629\n",
            "Loss in iteration no. 196025 ==> 0.3071683663765445\n",
            "Loss in iteration no. 196026 ==> 0.30716836635952693\n",
            "Loss in iteration no. 196027 ==> 0.30716836634250955\n",
            "Loss in iteration no. 196028 ==> 0.3071683663254933\n",
            "Loss in iteration no. 196029 ==> 0.307168366308479\n",
            "Loss in iteration no. 196030 ==> 0.30716836629146427\n",
            "Loss in iteration no. 196031 ==> 0.3071683662744514\n",
            "Loss in iteration no. 196032 ==> 0.3071683662574391\n",
            "Loss in iteration no. 196033 ==> 0.30716836624042815\n",
            "Loss in iteration no. 196034 ==> 0.3071683662234173\n",
            "Loss in iteration no. 196035 ==> 0.3071683662064073\n",
            "Loss in iteration no. 196036 ==> 0.3071683661893995\n",
            "Loss in iteration no. 196037 ==> 0.307168366172392\n",
            "Loss in iteration no. 196038 ==> 0.30716836615538473\n",
            "Loss in iteration no. 196039 ==> 0.307168366138379\n",
            "Loss in iteration no. 196040 ==> 0.30716836612137516\n",
            "Loss in iteration no. 196041 ==> 0.307168366104371\n",
            "Loss in iteration no. 196042 ==> 0.3071683660873676\n",
            "Loss in iteration no. 196043 ==> 0.30716836607036585\n",
            "Loss in iteration no. 196044 ==> 0.3071683660533649\n",
            "Loss in iteration no. 196045 ==> 0.30716836603636455\n",
            "Loss in iteration no. 196046 ==> 0.3071683660193655\n",
            "Loss in iteration no. 196047 ==> 0.3071683660023667\n",
            "Loss in iteration no. 196048 ==> 0.3071683659853701\n",
            "Loss in iteration no. 196049 ==> 0.30716836596837266\n",
            "Loss in iteration no. 196050 ==> 0.3071683659513775\n",
            "Loss in iteration no. 196051 ==> 0.307168365934383\n",
            "Loss in iteration no. 196052 ==> 0.3071683659173892\n",
            "Loss in iteration no. 196053 ==> 0.3071683659003972\n",
            "Loss in iteration no. 196054 ==> 0.3071683658834049\n",
            "Loss in iteration no. 196055 ==> 0.30716836586641433\n",
            "Loss in iteration no. 196056 ==> 0.3071683658494244\n",
            "Loss in iteration no. 196057 ==> 0.3071683658324357\n",
            "Loss in iteration no. 196058 ==> 0.30716836581544726\n",
            "Loss in iteration no. 196059 ==> 0.30716836579845946\n",
            "Loss in iteration no. 196060 ==> 0.3071683657814739\n",
            "Loss in iteration no. 196061 ==> 0.3071683657644891\n",
            "Loss in iteration no. 196062 ==> 0.30716836574750345\n",
            "Loss in iteration no. 196063 ==> 0.30716836573052103\n",
            "Loss in iteration no. 196064 ==> 0.3071683657135383\n",
            "Loss in iteration no. 196065 ==> 0.30716836569655626\n",
            "Loss in iteration no. 196066 ==> 0.3071683656795759\n",
            "Loss in iteration no. 196067 ==> 0.3071683656625968\n",
            "Loss in iteration no. 196068 ==> 0.30716836564561795\n",
            "Loss in iteration no. 196069 ==> 0.3071683656286397\n",
            "Loss in iteration no. 196070 ==> 0.30716836561166266\n",
            "Loss in iteration no. 196071 ==> 0.3071683655946869\n",
            "Loss in iteration no. 196072 ==> 0.30716836557771227\n",
            "Loss in iteration no. 196073 ==> 0.30716836556073834\n",
            "Loss in iteration no. 196074 ==> 0.30716836554376464\n",
            "Loss in iteration no. 196075 ==> 0.30716836552679216\n",
            "Loss in iteration no. 196076 ==> 0.30716836550982135\n",
            "Loss in iteration no. 196077 ==> 0.30716836549285015\n",
            "Loss in iteration no. 196078 ==> 0.3071683654758808\n",
            "Loss in iteration no. 196079 ==> 0.3071683654589125\n",
            "Loss in iteration no. 196080 ==> 0.3071683654419445\n",
            "Loss in iteration no. 196081 ==> 0.3071683654249781\n",
            "Loss in iteration no. 196082 ==> 0.30716836540801296\n",
            "Loss in iteration no. 196083 ==> 0.30716836539104697\n",
            "Loss in iteration no. 196084 ==> 0.3071683653740832\n",
            "Loss in iteration no. 196085 ==> 0.30716836535712116\n",
            "Loss in iteration no. 196086 ==> 0.3071683653401588\n",
            "Loss in iteration no. 196087 ==> 0.307168365323198\n",
            "Loss in iteration no. 196088 ==> 0.307168365306238\n",
            "Loss in iteration no. 196089 ==> 0.30716836528927866\n",
            "Loss in iteration no. 196090 ==> 0.30716836527231994\n",
            "Loss in iteration no. 196091 ==> 0.30716836525536195\n",
            "Loss in iteration no. 196092 ==> 0.3071683652384057\n",
            "Loss in iteration no. 196093 ==> 0.3071683652214506\n",
            "Loss in iteration no. 196094 ==> 0.30716836520449564\n",
            "Loss in iteration no. 196095 ==> 0.30716836518754187\n",
            "Loss in iteration no. 196096 ==> 0.3071683651705899\n",
            "Loss in iteration no. 196097 ==> 0.3071683651536374\n",
            "Loss in iteration no. 196098 ==> 0.30716836513668616\n",
            "Loss in iteration no. 196099 ==> 0.3071683651197361\n",
            "Loss in iteration no. 196100 ==> 0.3071683651027879\n",
            "Loss in iteration no. 196101 ==> 0.30716836508583956\n",
            "Loss in iteration no. 196102 ==> 0.30716836506889267\n",
            "Loss in iteration no. 196103 ==> 0.3071683650519463\n",
            "Loss in iteration no. 196104 ==> 0.30716836503500056\n",
            "Loss in iteration no. 196105 ==> 0.3071683650180561\n",
            "Loss in iteration no. 196106 ==> 0.3071683650011128\n",
            "Loss in iteration no. 196107 ==> 0.30716836498417077\n",
            "Loss in iteration no. 196108 ==> 0.30716836496722916\n",
            "Loss in iteration no. 196109 ==> 0.3071683649502884\n",
            "Loss in iteration no. 196110 ==> 0.3071683649333483\n",
            "Loss in iteration no. 196111 ==> 0.3071683649164098\n",
            "Loss in iteration no. 196112 ==> 0.30716836489947197\n",
            "Loss in iteration no. 196113 ==> 0.30716836488253485\n",
            "Loss in iteration no. 196114 ==> 0.30716836486559834\n",
            "Loss in iteration no. 196115 ==> 0.3071683648486636\n",
            "Loss in iteration no. 196116 ==> 0.3071683648317289\n",
            "Loss in iteration no. 196117 ==> 0.3071683648147955\n",
            "Loss in iteration no. 196118 ==> 0.30716836479786314\n",
            "Loss in iteration no. 196119 ==> 0.3071683647809325\n",
            "Loss in iteration no. 196120 ==> 0.3071683647640009\n",
            "Loss in iteration no. 196121 ==> 0.3071683647470716\n",
            "Loss in iteration no. 196122 ==> 0.3071683647301429\n",
            "Loss in iteration no. 196123 ==> 0.30716836471321585\n",
            "Loss in iteration no. 196124 ==> 0.3071683646962886\n",
            "Loss in iteration no. 196125 ==> 0.30716836467936337\n",
            "Loss in iteration no. 196126 ==> 0.30716836466243824\n",
            "Loss in iteration no. 196127 ==> 0.3071683646455139\n",
            "Loss in iteration no. 196128 ==> 0.3071683646285916\n",
            "Loss in iteration no. 196129 ==> 0.3071683646116685\n",
            "Loss in iteration no. 196130 ==> 0.30716836459474767\n",
            "Loss in iteration no. 196131 ==> 0.3071683645778273\n",
            "Loss in iteration no. 196132 ==> 0.3071683645609082\n",
            "Loss in iteration no. 196133 ==> 0.30716836454398916\n",
            "Loss in iteration no. 196134 ==> 0.30716836452707186\n",
            "Loss in iteration no. 196135 ==> 0.3071683645101552\n",
            "Loss in iteration no. 196136 ==> 0.3071683644932397\n",
            "Loss in iteration no. 196137 ==> 0.30716836447632523\n",
            "Loss in iteration no. 196138 ==> 0.30716836445941154\n",
            "Loss in iteration no. 196139 ==> 0.3071683644424984\n",
            "Loss in iteration no. 196140 ==> 0.3071683644255865\n",
            "Loss in iteration no. 196141 ==> 0.3071683644086751\n",
            "Loss in iteration no. 196142 ==> 0.307168364391765\n",
            "Loss in iteration no. 196143 ==> 0.30716836437485595\n",
            "Loss in iteration no. 196144 ==> 0.3071683643579476\n",
            "Loss in iteration no. 196145 ==> 0.3071683643410408\n",
            "Loss in iteration no. 196146 ==> 0.30716836432413464\n",
            "Loss in iteration no. 196147 ==> 0.30716836430722816\n",
            "Loss in iteration no. 196148 ==> 0.3071683642903244\n",
            "Loss in iteration no. 196149 ==> 0.30716836427342015\n",
            "Loss in iteration no. 196150 ==> 0.30716836425651806\n",
            "Loss in iteration no. 196151 ==> 0.3071683642396162\n",
            "Loss in iteration no. 196152 ==> 0.3071683642227154\n",
            "Loss in iteration no. 196153 ==> 0.3071683642058147\n",
            "Loss in iteration no. 196154 ==> 0.3071683641889162\n",
            "Loss in iteration no. 196155 ==> 0.30716836417201826\n",
            "Loss in iteration no. 196156 ==> 0.30716836415512094\n",
            "Loss in iteration no. 196157 ==> 0.3071683641382244\n",
            "Loss in iteration no. 196158 ==> 0.3071683641213294\n",
            "Loss in iteration no. 196159 ==> 0.30716836410443504\n",
            "Loss in iteration no. 196160 ==> 0.3071683640875413\n",
            "Loss in iteration no. 196161 ==> 0.3071683640706492\n",
            "Loss in iteration no. 196162 ==> 0.30716836405375714\n",
            "Loss in iteration no. 196163 ==> 0.3071683640368663\n",
            "Loss in iteration no. 196164 ==> 0.3071683640199776\n",
            "Loss in iteration no. 196165 ==> 0.3071683640030879\n",
            "Loss in iteration no. 196166 ==> 0.3071683639862004\n",
            "Loss in iteration no. 196167 ==> 0.3071683639693135\n",
            "Loss in iteration no. 196168 ==> 0.3071683639524273\n",
            "Loss in iteration no. 196169 ==> 0.30716836393554164\n",
            "Loss in iteration no. 196170 ==> 0.3071683639186577\n",
            "Loss in iteration no. 196171 ==> 0.3071683639017743\n",
            "Loss in iteration no. 196172 ==> 0.3071683638848925\n",
            "Loss in iteration no. 196173 ==> 0.30716836386801083\n",
            "Loss in iteration no. 196174 ==> 0.30716836385113033\n",
            "Loss in iteration no. 196175 ==> 0.3071683638342509\n",
            "Loss in iteration no. 196176 ==> 0.3071683638173716\n",
            "Loss in iteration no. 196177 ==> 0.30716836380049434\n",
            "Loss in iteration no. 196178 ==> 0.3071683637836178\n",
            "Loss in iteration no. 196179 ==> 0.30716836376674184\n",
            "Loss in iteration no. 196180 ==> 0.3071683637498664\n",
            "Loss in iteration no. 196181 ==> 0.3071683637329927\n",
            "Loss in iteration no. 196182 ==> 0.3071683637161196\n",
            "Loss in iteration no. 196183 ==> 0.3071683636992471\n",
            "Loss in iteration no. 196184 ==> 0.3071683636823761\n",
            "Loss in iteration no. 196185 ==> 0.30716836366550637\n",
            "Loss in iteration no. 196186 ==> 0.3071683636486366\n",
            "Loss in iteration no. 196187 ==> 0.307168363631768\n",
            "Loss in iteration no. 196188 ==> 0.30716836361490046\n",
            "Loss in iteration no. 196189 ==> 0.3071683635980331\n",
            "Loss in iteration no. 196190 ==> 0.30716836358116834\n",
            "Loss in iteration no. 196191 ==> 0.30716836356430316\n",
            "Loss in iteration no. 196192 ==> 0.3071683635474396\n",
            "Loss in iteration no. 196193 ==> 0.30716836353057664\n",
            "Loss in iteration no. 196194 ==> 0.3071683635137142\n",
            "Loss in iteration no. 196195 ==> 0.30716836349685345\n",
            "Loss in iteration no. 196196 ==> 0.3071683634799928\n",
            "Loss in iteration no. 196197 ==> 0.3071683634631342\n",
            "Loss in iteration no. 196198 ==> 0.30716836344627524\n",
            "Loss in iteration no. 196199 ==> 0.3071683634294183\n",
            "Loss in iteration no. 196200 ==> 0.30716836341256204\n",
            "Loss in iteration no. 196201 ==> 0.30716836339570586\n",
            "Loss in iteration no. 196202 ==> 0.3071683633788508\n",
            "Loss in iteration no. 196203 ==> 0.30716836336199727\n",
            "Loss in iteration no. 196204 ==> 0.3071683633451443\n",
            "Loss in iteration no. 196205 ==> 0.307168363328293\n",
            "Loss in iteration no. 196206 ==> 0.3071683633114418\n",
            "Loss in iteration no. 196207 ==> 0.30716836329459163\n",
            "Loss in iteration no. 196208 ==> 0.30716836327774305\n",
            "Loss in iteration no. 196209 ==> 0.30716836326089464\n",
            "Loss in iteration no. 196210 ==> 0.3071683632440473\n",
            "Loss in iteration no. 196211 ==> 0.3071683632272009\n",
            "Loss in iteration no. 196212 ==> 0.30716836321035573\n",
            "Loss in iteration no. 196213 ==> 0.30716836319351065\n",
            "Loss in iteration no. 196214 ==> 0.3071683631766671\n",
            "Loss in iteration no. 196215 ==> 0.30716836315982504\n",
            "Loss in iteration no. 196216 ==> 0.30716836314298274\n",
            "Loss in iteration no. 196217 ==> 0.30716836312614204\n",
            "Loss in iteration no. 196218 ==> 0.3071683631093018\n",
            "Loss in iteration no. 196219 ==> 0.30716836309246365\n",
            "Loss in iteration no. 196220 ==> 0.3071683630756256\n",
            "Loss in iteration no. 196221 ==> 0.30716836305878864\n",
            "Loss in iteration no. 196222 ==> 0.3071683630419517\n",
            "Loss in iteration no. 196223 ==> 0.30716836302511696\n",
            "Loss in iteration no. 196224 ==> 0.3071683630082827\n",
            "Loss in iteration no. 196225 ==> 0.30716836299144856\n",
            "Loss in iteration no. 196226 ==> 0.30716836297461647\n",
            "Loss in iteration no. 196227 ==> 0.307168362957785\n",
            "Loss in iteration no. 196228 ==> 0.307168362940954\n",
            "Loss in iteration no. 196229 ==> 0.307168362924125\n",
            "Loss in iteration no. 196230 ==> 0.30716836290729527\n",
            "Loss in iteration no. 196231 ==> 0.30716836289046806\n",
            "Loss in iteration no. 196232 ==> 0.3071683628736409\n",
            "Loss in iteration no. 196233 ==> 0.30716836285681487\n",
            "Loss in iteration no. 196234 ==> 0.3071683628399899\n",
            "Loss in iteration no. 196235 ==> 0.30716836282316495\n",
            "Loss in iteration no. 196236 ==> 0.30716836280634197\n",
            "Loss in iteration no. 196237 ==> 0.30716836278951976\n",
            "Loss in iteration no. 196238 ==> 0.30716836277269793\n",
            "Loss in iteration no. 196239 ==> 0.3071683627558778\n",
            "Loss in iteration no. 196240 ==> 0.30716836273905807\n",
            "Loss in iteration no. 196241 ==> 0.307168362722239\n",
            "Loss in iteration no. 196242 ==> 0.3071683627054221\n",
            "Loss in iteration no. 196243 ==> 0.30716836268860515\n",
            "Loss in iteration no. 196244 ==> 0.30716836267178876\n",
            "Loss in iteration no. 196245 ==> 0.30716836265497344\n",
            "Loss in iteration no. 196246 ==> 0.3071683626381596\n",
            "Loss in iteration no. 196247 ==> 0.3071683626213459\n",
            "Loss in iteration no. 196248 ==> 0.3071683626045343\n",
            "Loss in iteration no. 196249 ==> 0.3071683625877232\n",
            "Loss in iteration no. 196250 ==> 0.3071683625709126\n",
            "Loss in iteration no. 196251 ==> 0.30716836255410274\n",
            "Loss in iteration no. 196252 ==> 0.30716836253729424\n",
            "Loss in iteration no. 196253 ==> 0.30716836252048635\n",
            "Loss in iteration no. 196254 ==> 0.3071683625036805\n",
            "Loss in iteration no. 196255 ==> 0.30716836248687474\n",
            "Loss in iteration no. 196256 ==> 0.30716836247007007\n",
            "Loss in iteration no. 196257 ==> 0.3071683624532654\n",
            "Loss in iteration no. 196258 ==> 0.3071683624364627\n",
            "Loss in iteration no. 196259 ==> 0.3071683624196606\n",
            "Loss in iteration no. 196260 ==> 0.3071683624028587\n",
            "Loss in iteration no. 196261 ==> 0.30716836238605866\n",
            "Loss in iteration no. 196262 ==> 0.30716836236925926\n",
            "Loss in iteration no. 196263 ==> 0.3071683623524608\n",
            "Loss in iteration no. 196264 ==> 0.30716836233566347\n",
            "Loss in iteration no. 196265 ==> 0.3071683623188667\n",
            "Loss in iteration no. 196266 ==> 0.30716836230207145\n",
            "Loss in iteration no. 196267 ==> 0.3071683622852762\n",
            "Loss in iteration no. 196268 ==> 0.307168362268482\n",
            "Loss in iteration no. 196269 ==> 0.3071683622516898\n",
            "Loss in iteration no. 196270 ==> 0.3071683622348983\n",
            "Loss in iteration no. 196271 ==> 0.3071683622181067\n",
            "Loss in iteration no. 196272 ==> 0.3071683622013162\n",
            "Loss in iteration no. 196273 ==> 0.3071683621845272\n",
            "Loss in iteration no. 196274 ==> 0.30716836216773874\n",
            "Loss in iteration no. 196275 ==> 0.3071683621509508\n",
            "Loss in iteration no. 196276 ==> 0.307168362134165\n",
            "Loss in iteration no. 196277 ==> 0.3071683621173791\n",
            "Loss in iteration no. 196278 ==> 0.30716836210059484\n",
            "Loss in iteration no. 196279 ==> 0.3071683620838115\n",
            "Loss in iteration no. 196280 ==> 0.3071683620670282\n",
            "Loss in iteration no. 196281 ==> 0.30716836205024606\n",
            "Loss in iteration no. 196282 ==> 0.30716836203346537\n",
            "Loss in iteration no. 196283 ==> 0.3071683620166847\n",
            "Loss in iteration no. 196284 ==> 0.30716836199990605\n",
            "Loss in iteration no. 196285 ==> 0.3071683619831279\n",
            "Loss in iteration no. 196286 ==> 0.3071683619663503\n",
            "Loss in iteration no. 196287 ==> 0.3071683619495748\n",
            "Loss in iteration no. 196288 ==> 0.3071683619327993\n",
            "Loss in iteration no. 196289 ==> 0.3071683619160242\n",
            "Loss in iteration no. 196290 ==> 0.30716836189925123\n",
            "Loss in iteration no. 196291 ==> 0.30716836188247837\n",
            "Loss in iteration no. 196292 ==> 0.3071683618657064\n",
            "Loss in iteration no. 196293 ==> 0.3071683618489355\n",
            "Loss in iteration no. 196294 ==> 0.30716836183216545\n",
            "Loss in iteration no. 196295 ==> 0.30716836181539614\n",
            "Loss in iteration no. 196296 ==> 0.3071683617986283\n",
            "Loss in iteration no. 196297 ==> 0.30716836178186097\n",
            "Loss in iteration no. 196298 ==> 0.3071683617650951\n",
            "Loss in iteration no. 196299 ==> 0.30716836174832873\n",
            "Loss in iteration no. 196300 ==> 0.30716836173156503\n",
            "Loss in iteration no. 196301 ==> 0.30716836171480116\n",
            "Loss in iteration no. 196302 ==> 0.3071683616980384\n",
            "Loss in iteration no. 196303 ==> 0.30716836168127665\n",
            "Loss in iteration no. 196304 ==> 0.307168361664516\n",
            "Loss in iteration no. 196305 ==> 0.3071683616477562\n",
            "Loss in iteration no. 196306 ==> 0.30716836163099803\n",
            "Loss in iteration no. 196307 ==> 0.30716836161423927\n",
            "Loss in iteration no. 196308 ==> 0.307168361597482\n",
            "Loss in iteration no. 196309 ==> 0.30716836158072636\n",
            "Loss in iteration no. 196310 ==> 0.3071683615639712\n",
            "Loss in iteration no. 196311 ==> 0.30716836154721644\n",
            "Loss in iteration no. 196312 ==> 0.30716836153046323\n",
            "Loss in iteration no. 196313 ==> 0.3071683615137111\n",
            "Loss in iteration no. 196314 ==> 0.3071683614969589\n",
            "Loss in iteration no. 196315 ==> 0.30716836148020876\n",
            "Loss in iteration no. 196316 ==> 0.3071683614634586\n",
            "Loss in iteration no. 196317 ==> 0.3071683614467094\n",
            "Loss in iteration no. 196318 ==> 0.30716836142996173\n",
            "Loss in iteration no. 196319 ==> 0.3071683614132145\n",
            "Loss in iteration no. 196320 ==> 0.3071683613964689\n",
            "Loss in iteration no. 196321 ==> 0.30716836137972375\n",
            "Loss in iteration no. 196322 ==> 0.30716836136297904\n",
            "Loss in iteration no. 196323 ==> 0.3071683613462359\n",
            "Loss in iteration no. 196324 ==> 0.3071683613294936\n",
            "Loss in iteration no. 196325 ==> 0.3071683613127515\n",
            "Loss in iteration no. 196326 ==> 0.3071683612960113\n",
            "Loss in iteration no. 196327 ==> 0.3071683612792711\n",
            "Loss in iteration no. 196328 ==> 0.3071683612625329\n",
            "Loss in iteration no. 196329 ==> 0.3071683612457952\n",
            "Loss in iteration no. 196330 ==> 0.30716836122905794\n",
            "Loss in iteration no. 196331 ==> 0.30716836121232166\n",
            "Loss in iteration no. 196332 ==> 0.30716836119558644\n",
            "Loss in iteration no. 196333 ==> 0.3071683611788532\n",
            "Loss in iteration no. 196334 ==> 0.30716836116211993\n",
            "Loss in iteration no. 196335 ==> 0.30716836114538715\n",
            "Loss in iteration no. 196336 ==> 0.3071683611286558\n",
            "Loss in iteration no. 196337 ==> 0.3071683611119255\n",
            "Loss in iteration no. 196338 ==> 0.3071683610951952\n",
            "Loss in iteration no. 196339 ==> 0.3071683610784669\n",
            "Loss in iteration no. 196340 ==> 0.307168361061739\n",
            "Loss in iteration no. 196341 ==> 0.30716836104501266\n",
            "Loss in iteration no. 196342 ==> 0.30716836102828626\n",
            "Loss in iteration no. 196343 ==> 0.30716836101156086\n",
            "Loss in iteration no. 196344 ==> 0.3071683609948369\n",
            "Loss in iteration no. 196345 ==> 0.3071683609781139\n",
            "Loss in iteration no. 196346 ==> 0.307168360961392\n",
            "Loss in iteration no. 196347 ==> 0.30716836094467037\n",
            "Loss in iteration no. 196348 ==> 0.30716836092794936\n",
            "Loss in iteration no. 196349 ==> 0.30716836091123034\n",
            "Loss in iteration no. 196350 ==> 0.30716836089451177\n",
            "Loss in iteration no. 196351 ==> 0.3071683608777942\n",
            "Loss in iteration no. 196352 ==> 0.30716836086107757\n",
            "Loss in iteration no. 196353 ==> 0.30716836084436133\n",
            "Loss in iteration no. 196354 ==> 0.30716836082764665\n",
            "Loss in iteration no. 196355 ==> 0.3071683608109324\n",
            "Loss in iteration no. 196356 ==> 0.3071683607942197\n",
            "Loss in iteration no. 196357 ==> 0.3071683607775074\n",
            "Loss in iteration no. 196358 ==> 0.30716836076079557\n",
            "Loss in iteration no. 196359 ==> 0.30716836074408527\n",
            "Loss in iteration no. 196360 ==> 0.3071683607273759\n",
            "Loss in iteration no. 196361 ==> 0.3071683607106675\n",
            "Loss in iteration no. 196362 ==> 0.3071683606939601\n",
            "Loss in iteration no. 196363 ==> 0.3071683606772531\n",
            "Loss in iteration no. 196364 ==> 0.30716836066054704\n",
            "Loss in iteration no. 196365 ==> 0.307168360643842\n",
            "Loss in iteration no. 196366 ==> 0.3071683606271384\n",
            "Loss in iteration no. 196367 ==> 0.3071683606104353\n",
            "Loss in iteration no. 196368 ==> 0.30716836059373265\n",
            "Loss in iteration no. 196369 ==> 0.30716836057703195\n",
            "Loss in iteration no. 196370 ==> 0.3071683605603322\n",
            "Loss in iteration no. 196371 ==> 0.3071683605436319\n",
            "Loss in iteration no. 196372 ==> 0.3071683605269336\n",
            "Loss in iteration no. 196373 ==> 0.3071683605102362\n",
            "Loss in iteration no. 196374 ==> 0.3071683604935398\n",
            "Loss in iteration no. 196375 ==> 0.30716836047684376\n",
            "Loss in iteration no. 196376 ==> 0.3071683604601488\n",
            "Loss in iteration no. 196377 ==> 0.3071683604434547\n",
            "Loss in iteration no. 196378 ==> 0.3071683604267621\n",
            "Loss in iteration no. 196379 ==> 0.30716836041006995\n",
            "Loss in iteration no. 196380 ==> 0.30716836039337825\n",
            "Loss in iteration no. 196381 ==> 0.3071683603766885\n",
            "Loss in iteration no. 196382 ==> 0.30716836035999967\n",
            "Loss in iteration no. 196383 ==> 0.3071683603433103\n",
            "Loss in iteration no. 196384 ==> 0.30716836032662387\n",
            "Loss in iteration no. 196385 ==> 0.30716836030993644\n",
            "Loss in iteration no. 196386 ==> 0.3071683602932509\n",
            "Loss in iteration no. 196387 ==> 0.3071683602765668\n",
            "Loss in iteration no. 196388 ==> 0.3071683602598822\n",
            "Loss in iteration no. 196389 ==> 0.30716836024319943\n",
            "Loss in iteration no. 196390 ==> 0.3071683602265167\n",
            "Loss in iteration no. 196391 ==> 0.30716836020983646\n",
            "Loss in iteration no. 196392 ==> 0.3071683601931561\n",
            "Loss in iteration no. 196393 ==> 0.30716836017647664\n",
            "Loss in iteration no. 196394 ==> 0.30716836015979865\n",
            "Loss in iteration no. 196395 ==> 0.3071683601431206\n",
            "Loss in iteration no. 196396 ==> 0.30716836012644455\n",
            "Loss in iteration no. 196397 ==> 0.30716836010976833\n",
            "Loss in iteration no. 196398 ==> 0.3071683600930942\n",
            "Loss in iteration no. 196399 ==> 0.30716836007641984\n",
            "Loss in iteration no. 196400 ==> 0.30716836005974696\n",
            "Loss in iteration no. 196401 ==> 0.3071683600430755\n",
            "Loss in iteration no. 196402 ==> 0.30716836002640446\n",
            "Loss in iteration no. 196403 ==> 0.307168360009734\n",
            "Loss in iteration no. 196404 ==> 0.30716835999306485\n",
            "Loss in iteration no. 196405 ==> 0.3071683599763966\n",
            "Loss in iteration no. 196406 ==> 0.30716835995972935\n",
            "Loss in iteration no. 196407 ==> 0.3071683599430625\n",
            "Loss in iteration no. 196408 ==> 0.3071683599263966\n",
            "Loss in iteration no. 196409 ==> 0.30716835990973207\n",
            "Loss in iteration no. 196410 ==> 0.30716835989306857\n",
            "Loss in iteration no. 196411 ==> 0.3071683598764059\n",
            "Loss in iteration no. 196412 ==> 0.30716835985974367\n",
            "Loss in iteration no. 196413 ==> 0.3071683598430828\n",
            "Loss in iteration no. 196414 ==> 0.3071683598264225\n",
            "Loss in iteration no. 196415 ==> 0.30716835980976354\n",
            "Loss in iteration no. 196416 ==> 0.3071683597931051\n",
            "Loss in iteration no. 196417 ==> 0.3071683597764476\n",
            "Loss in iteration no. 196418 ==> 0.30716835975979084\n",
            "Loss in iteration no. 196419 ==> 0.3071683597431356\n",
            "Loss in iteration no. 196420 ==> 0.3071683597264812\n",
            "Loss in iteration no. 196421 ==> 0.30716835970982725\n",
            "Loss in iteration no. 196422 ==> 0.3071683596931742\n",
            "Loss in iteration no. 196423 ==> 0.3071683596765221\n",
            "Loss in iteration no. 196424 ==> 0.3071683596598715\n",
            "Loss in iteration no. 196425 ==> 0.3071683596432213\n",
            "Loss in iteration no. 196426 ==> 0.3071683596265724\n",
            "Loss in iteration no. 196427 ==> 0.307168359609924\n",
            "Loss in iteration no. 196428 ==> 0.30716835959327643\n",
            "Loss in iteration no. 196429 ==> 0.3071683595766298\n",
            "Loss in iteration no. 196430 ==> 0.3071683595599846\n",
            "Loss in iteration no. 196431 ==> 0.3071683595433404\n",
            "Loss in iteration no. 196432 ==> 0.3071683595266959\n",
            "Loss in iteration no. 196433 ==> 0.3071683595100535\n",
            "Loss in iteration no. 196434 ==> 0.3071683594934114\n",
            "Loss in iteration no. 196435 ==> 0.30716835947677074\n",
            "Loss in iteration no. 196436 ==> 0.3071683594601305\n",
            "Loss in iteration no. 196437 ==> 0.30716835944349163\n",
            "Loss in iteration no. 196438 ==> 0.3071683594268532\n",
            "Loss in iteration no. 196439 ==> 0.3071683594102152\n",
            "Loss in iteration no. 196440 ==> 0.30716835939357856\n",
            "Loss in iteration no. 196441 ==> 0.3071683593769438\n",
            "Loss in iteration no. 196442 ==> 0.30716835936030895\n",
            "Loss in iteration no. 196443 ==> 0.30716835934367603\n",
            "Loss in iteration no. 196444 ==> 0.30716835932704195\n",
            "Loss in iteration no. 196445 ==> 0.30716835931041087\n",
            "Loss in iteration no. 196446 ==> 0.30716835929378017\n",
            "Loss in iteration no. 196447 ==> 0.3071683592771498\n",
            "Loss in iteration no. 196448 ==> 0.3071683592605208\n",
            "Loss in iteration no. 196449 ==> 0.30716835924389213\n",
            "Loss in iteration no. 196450 ==> 0.30716835922726504\n",
            "Loss in iteration no. 196451 ==> 0.30716835921063823\n",
            "Loss in iteration no. 196452 ==> 0.307168359194013\n",
            "Loss in iteration no. 196453 ==> 0.30716835917738844\n",
            "Loss in iteration no. 196454 ==> 0.30716835916076485\n",
            "Loss in iteration no. 196455 ==> 0.3071683591441422\n",
            "Loss in iteration no. 196456 ==> 0.30716835912752033\n",
            "Loss in iteration no. 196457 ==> 0.30716835911089946\n",
            "Loss in iteration no. 196458 ==> 0.3071683590942789\n",
            "Loss in iteration no. 196459 ==> 0.30716835907765977\n",
            "Loss in iteration no. 196460 ==> 0.307168359061042\n",
            "Loss in iteration no. 196461 ==> 0.3071683590444247\n",
            "Loss in iteration no. 196462 ==> 0.30716835902780765\n",
            "Loss in iteration no. 196463 ==> 0.30716835901119205\n",
            "Loss in iteration no. 196464 ==> 0.30716835899457834\n",
            "Loss in iteration no. 196465 ==> 0.30716835897796446\n",
            "Loss in iteration no. 196466 ==> 0.30716835896135103\n",
            "Loss in iteration no. 196467 ==> 0.30716835894473943\n",
            "Loss in iteration no. 196468 ==> 0.3071683589281292\n",
            "Loss in iteration no. 196469 ==> 0.30716835891151895\n",
            "Loss in iteration no. 196470 ==> 0.3071683588949095\n",
            "Loss in iteration no. 196471 ==> 0.3071683588783014\n",
            "Loss in iteration no. 196472 ==> 0.30716835886169375\n",
            "Loss in iteration no. 196473 ==> 0.3071683588450874\n",
            "Loss in iteration no. 196474 ==> 0.307168358828482\n",
            "Loss in iteration no. 196475 ==> 0.30716835881187743\n",
            "Loss in iteration no. 196476 ==> 0.30716835879527427\n",
            "Loss in iteration no. 196477 ==> 0.307168358778672\n",
            "Loss in iteration no. 196478 ==> 0.30716835876206944\n",
            "Loss in iteration no. 196479 ==> 0.3071683587454689\n",
            "Loss in iteration no. 196480 ==> 0.3071683587288683\n",
            "Loss in iteration no. 196481 ==> 0.3071683587122694\n",
            "Loss in iteration no. 196482 ==> 0.307168358695671\n",
            "Loss in iteration no. 196483 ==> 0.3071683586790738\n",
            "Loss in iteration no. 196484 ==> 0.3071683586624771\n",
            "Loss in iteration no. 196485 ==> 0.3071683586458818\n",
            "Loss in iteration no. 196486 ==> 0.30716835862928676\n",
            "Loss in iteration no. 196487 ==> 0.30716835861269376\n",
            "Loss in iteration no. 196488 ==> 0.3071683585961004\n",
            "Loss in iteration no. 196489 ==> 0.30716835857950847\n",
            "Loss in iteration no. 196490 ==> 0.3071683585629184\n",
            "Loss in iteration no. 196491 ==> 0.3071683585463278\n",
            "Loss in iteration no. 196492 ==> 0.30716835852973895\n",
            "Loss in iteration no. 196493 ==> 0.3071683585131511\n",
            "Loss in iteration no. 196494 ==> 0.30716835849656343\n",
            "Loss in iteration no. 196495 ==> 0.30716835847997714\n",
            "Loss in iteration no. 196496 ==> 0.3071683584633913\n",
            "Loss in iteration no. 196497 ==> 0.3071683584468068\n",
            "Loss in iteration no. 196498 ==> 0.30716835843022305\n",
            "Loss in iteration no. 196499 ==> 0.3071683584136403\n",
            "Loss in iteration no. 196500 ==> 0.30716835839705886\n",
            "Loss in iteration no. 196501 ==> 0.30716835838047823\n",
            "Loss in iteration no. 196502 ==> 0.30716835836389744\n",
            "Loss in iteration no. 196503 ==> 0.3071683583473186\n",
            "Loss in iteration no. 196504 ==> 0.30716835833074\n",
            "Loss in iteration no. 196505 ==> 0.30716835831416284\n",
            "Loss in iteration no. 196506 ==> 0.30716835829758643\n",
            "Loss in iteration no. 196507 ==> 0.30716835828101097\n",
            "Loss in iteration no. 196508 ==> 0.30716835826443645\n",
            "Loss in iteration no. 196509 ==> 0.30716835824786254\n",
            "Loss in iteration no. 196510 ==> 0.3071683582312901\n",
            "Loss in iteration no. 196511 ==> 0.307168358214718\n",
            "Loss in iteration no. 196512 ==> 0.3071683581981467\n",
            "Loss in iteration no. 196513 ==> 0.30716835818157734\n",
            "Loss in iteration no. 196514 ==> 0.30716835816500776\n",
            "Loss in iteration no. 196515 ==> 0.3071683581484394\n",
            "Loss in iteration no. 196516 ==> 0.3071683581318721\n",
            "Loss in iteration no. 196517 ==> 0.3071683581153056\n",
            "Loss in iteration no. 196518 ==> 0.30716835809874027\n",
            "Loss in iteration no. 196519 ==> 0.30716835808217546\n",
            "Loss in iteration no. 196520 ==> 0.3071683580656119\n",
            "Loss in iteration no. 196521 ==> 0.3071683580490487\n",
            "Loss in iteration no. 196522 ==> 0.3071683580324873\n",
            "Loss in iteration no. 196523 ==> 0.3071683580159258\n",
            "Loss in iteration no. 196524 ==> 0.30716835799936604\n",
            "Loss in iteration no. 196525 ==> 0.3071683579828073\n",
            "Loss in iteration no. 196526 ==> 0.30716835796624925\n",
            "Loss in iteration no. 196527 ==> 0.30716835794969105\n",
            "Loss in iteration no. 196528 ==> 0.3071683579331347\n",
            "Loss in iteration no. 196529 ==> 0.3071683579165796\n",
            "Loss in iteration no. 196530 ==> 0.30716835790002495\n",
            "Loss in iteration no. 196531 ==> 0.3071683578834705\n",
            "Loss in iteration no. 196532 ==> 0.3071683578669176\n",
            "Loss in iteration no. 196533 ==> 0.30716835785036584\n",
            "Loss in iteration no. 196534 ==> 0.30716835783381485\n",
            "Loss in iteration no. 196535 ==> 0.30716835781726487\n",
            "Loss in iteration no. 196536 ==> 0.30716835780071566\n",
            "Loss in iteration no. 196537 ==> 0.3071683577841672\n",
            "Loss in iteration no. 196538 ==> 0.30716835776762064\n",
            "Loss in iteration no. 196539 ==> 0.3071683577510734\n",
            "Loss in iteration no. 196540 ==> 0.30716835773452794\n",
            "Loss in iteration no. 196541 ==> 0.3071683577179833\n",
            "Loss in iteration no. 196542 ==> 0.3071683577014391\n",
            "Loss in iteration no. 196543 ==> 0.3071683576848961\n",
            "Loss in iteration no. 196544 ==> 0.3071683576683543\n",
            "Loss in iteration no. 196545 ==> 0.30716835765181355\n",
            "Loss in iteration no. 196546 ==> 0.30716835763527356\n",
            "Loss in iteration no. 196547 ==> 0.30716835761873384\n",
            "Loss in iteration no. 196548 ==> 0.30716835760219596\n",
            "Loss in iteration no. 196549 ==> 0.30716835758565836\n",
            "Loss in iteration no. 196550 ==> 0.30716835756912164\n",
            "Loss in iteration no. 196551 ==> 0.3071683575525867\n",
            "Loss in iteration no. 196552 ==> 0.3071683575360521\n",
            "Loss in iteration no. 196553 ==> 0.30716835751951777\n",
            "Loss in iteration no. 196554 ==> 0.3071683575029847\n",
            "Loss in iteration no. 196555 ==> 0.30716835748645305\n",
            "Loss in iteration no. 196556 ==> 0.3071683574699217\n",
            "Loss in iteration no. 196557 ==> 0.30716835745339155\n",
            "Loss in iteration no. 196558 ==> 0.30716835743686227\n",
            "Loss in iteration no. 196559 ==> 0.30716835742033377\n",
            "Loss in iteration no. 196560 ==> 0.3071683574038071\n",
            "Loss in iteration no. 196561 ==> 0.3071683573872793\n",
            "Loss in iteration no. 196562 ==> 0.3071683573707542\n",
            "Loss in iteration no. 196563 ==> 0.30716835735422954\n",
            "Loss in iteration no. 196564 ==> 0.3071683573377061\n",
            "Loss in iteration no. 196565 ==> 0.3071683573211824\n",
            "Loss in iteration no. 196566 ==> 0.30716835730466113\n",
            "Loss in iteration no. 196567 ==> 0.30716835728813957\n",
            "Loss in iteration no. 196568 ==> 0.3071683572716193\n",
            "Loss in iteration no. 196569 ==> 0.3071683572550994\n",
            "Loss in iteration no. 196570 ==> 0.30716835723858127\n",
            "Loss in iteration no. 196571 ==> 0.3071683572220639\n",
            "Loss in iteration no. 196572 ==> 0.3071683572055474\n",
            "Loss in iteration no. 196573 ==> 0.3071683571890316\n",
            "Loss in iteration no. 196574 ==> 0.3071683571725167\n",
            "Loss in iteration no. 196575 ==> 0.307168357156003\n",
            "Loss in iteration no. 196576 ==> 0.30716835713948965\n",
            "Loss in iteration no. 196577 ==> 0.3071683571229776\n",
            "Loss in iteration no. 196578 ==> 0.30716835710646684\n",
            "Loss in iteration no. 196579 ==> 0.3071683570899563\n",
            "Loss in iteration no. 196580 ==> 0.30716835707344714\n",
            "Loss in iteration no. 196581 ==> 0.30716835705693823\n",
            "Loss in iteration no. 196582 ==> 0.3071683570404311\n",
            "Loss in iteration no. 196583 ==> 0.3071683570239238\n",
            "Loss in iteration no. 196584 ==> 0.30716835700741824\n",
            "Loss in iteration no. 196585 ==> 0.3071683569909135\n",
            "Loss in iteration no. 196586 ==> 0.30716835697440953\n",
            "Loss in iteration no. 196587 ==> 0.30716835695790684\n",
            "Loss in iteration no. 196588 ==> 0.30716835694140443\n",
            "Loss in iteration no. 196589 ==> 0.3071683569249034\n",
            "Loss in iteration no. 196590 ==> 0.30716835690840244\n",
            "Loss in iteration no. 196591 ==> 0.3071683568919029\n",
            "Loss in iteration no. 196592 ==> 0.30716835687540467\n",
            "Loss in iteration no. 196593 ==> 0.30716835685890714\n",
            "Loss in iteration no. 196594 ==> 0.30716835684241045\n",
            "Loss in iteration no. 196595 ==> 0.3071683568259145\n",
            "Loss in iteration no. 196596 ==> 0.3071683568094193\n",
            "Loss in iteration no. 196597 ==> 0.307168356792926\n",
            "Loss in iteration no. 196598 ==> 0.30716835677643284\n",
            "Loss in iteration no. 196599 ==> 0.30716835675993953\n",
            "Loss in iteration no. 196600 ==> 0.3071683567434489\n",
            "Loss in iteration no. 196601 ==> 0.3071683567269587\n",
            "Loss in iteration no. 196602 ==> 0.3071683567104686\n",
            "Loss in iteration no. 196603 ==> 0.3071683566939804\n",
            "Loss in iteration no. 196604 ==> 0.3071683566774929\n",
            "Loss in iteration no. 196605 ==> 0.3071683566610057\n",
            "Loss in iteration no. 196606 ==> 0.30716835664452036\n",
            "Loss in iteration no. 196607 ==> 0.3071683566280347\n",
            "Loss in iteration no. 196608 ==> 0.30716835661155073\n",
            "Loss in iteration no. 196609 ==> 0.3071683565950681\n",
            "Loss in iteration no. 196610 ==> 0.3071683565785854\n",
            "Loss in iteration no. 196611 ==> 0.3071683565621042\n",
            "Loss in iteration no. 196612 ==> 0.3071683565456234\n",
            "Loss in iteration no. 196613 ==> 0.3071683565291438\n",
            "Loss in iteration no. 196614 ==> 0.30716835651266455\n",
            "Loss in iteration no. 196615 ==> 0.30716835649618807\n",
            "Loss in iteration no. 196616 ==> 0.3071683564797103\n",
            "Loss in iteration no. 196617 ==> 0.3071683564632347\n",
            "Loss in iteration no. 196618 ==> 0.30716835644675994\n",
            "Loss in iteration no. 196619 ==> 0.307168356430285\n",
            "Loss in iteration no. 196620 ==> 0.3071683564138117\n",
            "Loss in iteration no. 196621 ==> 0.30716835639733975\n",
            "Loss in iteration no. 196622 ==> 0.30716835638086754\n",
            "Loss in iteration no. 196623 ==> 0.3071683563643971\n",
            "Loss in iteration no. 196624 ==> 0.30716835634792783\n",
            "Loss in iteration no. 196625 ==> 0.30716835633145895\n",
            "Loss in iteration no. 196626 ==> 0.30716835631499123\n",
            "Loss in iteration no. 196627 ==> 0.3071683562985243\n",
            "Loss in iteration no. 196628 ==> 0.3071683562820581\n",
            "Loss in iteration no. 196629 ==> 0.30716835626559313\n",
            "Loss in iteration no. 196630 ==> 0.30716835624912897\n",
            "Loss in iteration no. 196631 ==> 0.3071683562326656\n",
            "Loss in iteration no. 196632 ==> 0.30716835621620286\n",
            "Loss in iteration no. 196633 ==> 0.30716835619974137\n",
            "Loss in iteration no. 196634 ==> 0.30716835618328125\n",
            "Loss in iteration no. 196635 ==> 0.30716835616682125\n",
            "Loss in iteration no. 196636 ==> 0.30716835615036253\n",
            "Loss in iteration no. 196637 ==> 0.30716835613390503\n",
            "Loss in iteration no. 196638 ==> 0.3071683561174478\n",
            "Loss in iteration no. 196639 ==> 0.30716835610099086\n",
            "Loss in iteration no. 196640 ==> 0.3071683560845361\n",
            "Loss in iteration no. 196641 ==> 0.3071683560680822\n",
            "Loss in iteration no. 196642 ==> 0.30716835605162784\n",
            "Loss in iteration no. 196643 ==> 0.30716835603517534\n",
            "Loss in iteration no. 196644 ==> 0.3071683560187241\n",
            "Loss in iteration no. 196645 ==> 0.3071683560022736\n",
            "Loss in iteration no. 196646 ==> 0.3071683559858238\n",
            "Loss in iteration no. 196647 ==> 0.3071683559693742\n",
            "Loss in iteration no. 196648 ==> 0.3071683559529259\n",
            "Loss in iteration no. 196649 ==> 0.3071683559364788\n",
            "Loss in iteration no. 196650 ==> 0.307168355920033\n",
            "Loss in iteration no. 196651 ==> 0.30716835590358793\n",
            "Loss in iteration no. 196652 ==> 0.30716835588714353\n",
            "Loss in iteration no. 196653 ==> 0.3071683558706993\n",
            "Loss in iteration no. 196654 ==> 0.3071683558542569\n",
            "Loss in iteration no. 196655 ==> 0.3071683558378157\n",
            "Loss in iteration no. 196656 ==> 0.3071683558213743\n",
            "Loss in iteration no. 196657 ==> 0.30716835580493457\n",
            "Loss in iteration no. 196658 ==> 0.30716835578849605\n",
            "Loss in iteration no. 196659 ==> 0.30716835577205776\n",
            "Loss in iteration no. 196660 ==> 0.30716835575562074\n",
            "Loss in iteration no. 196661 ==> 0.3071683557391839\n",
            "Loss in iteration no. 196662 ==> 0.3071683557227483\n",
            "Loss in iteration no. 196663 ==> 0.30716835570631446\n",
            "Loss in iteration no. 196664 ==> 0.30716835568988027\n",
            "Loss in iteration no. 196665 ==> 0.30716835567344736\n",
            "Loss in iteration no. 196666 ==> 0.30716835565701617\n",
            "Loss in iteration no. 196667 ==> 0.3071683556405852\n",
            "Loss in iteration no. 196668 ==> 0.30716835562415484\n",
            "Loss in iteration no. 196669 ==> 0.3071683556077254\n",
            "Loss in iteration no. 196670 ==> 0.30716835559129707\n",
            "Loss in iteration no. 196671 ==> 0.30716835557486993\n",
            "Loss in iteration no. 196672 ==> 0.307168355558444\n",
            "Loss in iteration no. 196673 ==> 0.3071683555420183\n",
            "Loss in iteration no. 196674 ==> 0.3071683555255929\n",
            "Loss in iteration no. 196675 ==> 0.30716835550917027\n",
            "Loss in iteration no. 196676 ==> 0.3071683554927471\n",
            "Loss in iteration no. 196677 ==> 0.3071683554763248\n",
            "Loss in iteration no. 196678 ==> 0.30716835545990423\n",
            "Loss in iteration no. 196679 ==> 0.3071683554434843\n",
            "Loss in iteration no. 196680 ==> 0.3071683554270646\n",
            "Loss in iteration no. 196681 ==> 0.3071683554106457\n",
            "Loss in iteration no. 196682 ==> 0.30716835539422843\n",
            "Loss in iteration no. 196683 ==> 0.3071683553778124\n",
            "Loss in iteration no. 196684 ==> 0.30716835536139653\n",
            "Loss in iteration no. 196685 ==> 0.3071683553449819\n",
            "Loss in iteration no. 196686 ==> 0.30716835532856795\n",
            "Loss in iteration no. 196687 ==> 0.30716835531215475\n",
            "Loss in iteration no. 196688 ==> 0.3071683552957427\n",
            "Loss in iteration no. 196689 ==> 0.3071683552793314\n",
            "Loss in iteration no. 196690 ==> 0.30716835526292235\n",
            "Loss in iteration no. 196691 ==> 0.3071683552465118\n",
            "Loss in iteration no. 196692 ==> 0.30716835523010416\n",
            "Loss in iteration no. 196693 ==> 0.30716835521369656\n",
            "Loss in iteration no. 196694 ==> 0.3071683551972893\n",
            "Loss in iteration no. 196695 ==> 0.30716835518088415\n",
            "Loss in iteration no. 196696 ==> 0.30716835516447927\n",
            "Loss in iteration no. 196697 ==> 0.30716835514807456\n",
            "Loss in iteration no. 196698 ==> 0.3071683551316721\n",
            "Loss in iteration no. 196699 ==> 0.3071683551152702\n",
            "Loss in iteration no. 196700 ==> 0.30716835509886803\n",
            "Loss in iteration no. 196701 ==> 0.30716835508246865\n",
            "Loss in iteration no. 196702 ==> 0.3071683550660689\n",
            "Loss in iteration no. 196703 ==> 0.30716835504966983\n",
            "Loss in iteration no. 196704 ==> 0.30716835503327294\n",
            "Loss in iteration no. 196705 ==> 0.3071683550168763\n",
            "Loss in iteration no. 196706 ==> 0.3071683550004793\n",
            "Loss in iteration no. 196707 ==> 0.307168354984084\n",
            "Loss in iteration no. 196708 ==> 0.3071683549676904\n",
            "Loss in iteration no. 196709 ==> 0.3071683549512975\n",
            "Loss in iteration no. 196710 ==> 0.3071683549349047\n",
            "Loss in iteration no. 196711 ==> 0.3071683549185132\n",
            "Loss in iteration no. 196712 ==> 0.3071683549021234\n",
            "Loss in iteration no. 196713 ==> 0.3071683548857332\n",
            "Loss in iteration no. 196714 ==> 0.3071683548693446\n",
            "Loss in iteration no. 196715 ==> 0.30716835485295735\n",
            "Loss in iteration no. 196716 ==> 0.3071683548365703\n",
            "Loss in iteration no. 196717 ==> 0.30716835482018384\n",
            "Loss in iteration no. 196718 ==> 0.307168354803799\n",
            "Loss in iteration no. 196719 ==> 0.30716835478741444\n",
            "Loss in iteration no. 196720 ==> 0.30716835477103155\n",
            "Loss in iteration no. 196721 ==> 0.3071683547546493\n",
            "Loss in iteration no. 196722 ==> 0.3071683547382673\n",
            "Loss in iteration no. 196723 ==> 0.30716835472188647\n",
            "Loss in iteration no. 196724 ==> 0.3071683547055072\n",
            "Loss in iteration no. 196725 ==> 0.3071683546891282\n",
            "Loss in iteration no. 196726 ==> 0.3071683546727508\n",
            "Loss in iteration no. 196727 ==> 0.3071683546563731\n",
            "Loss in iteration no. 196728 ==> 0.3071683546399977\n",
            "Loss in iteration no. 196729 ==> 0.3071683546236223\n",
            "Loss in iteration no. 196730 ==> 0.3071683546072482\n",
            "Loss in iteration no. 196731 ==> 0.30716835459087416\n",
            "Loss in iteration no. 196732 ==> 0.30716835457450137\n",
            "Loss in iteration no. 196733 ==> 0.30716835455812974\n",
            "Loss in iteration no. 196734 ==> 0.3071683545417593\n",
            "Loss in iteration no. 196735 ==> 0.30716835452538943\n",
            "Loss in iteration no. 196736 ==> 0.30716835450902025\n",
            "Loss in iteration no. 196737 ==> 0.3071683544926528\n",
            "Loss in iteration no. 196738 ==> 0.307168354476285\n",
            "Loss in iteration no. 196739 ==> 0.3071683544599188\n",
            "Loss in iteration no. 196740 ==> 0.3071683544435539\n",
            "Loss in iteration no. 196741 ==> 0.307168354427189\n",
            "Loss in iteration no. 196742 ==> 0.3071683544108253\n",
            "Loss in iteration no. 196743 ==> 0.3071683543944628\n",
            "Loss in iteration no. 196744 ==> 0.3071683543781005\n",
            "Loss in iteration no. 196745 ==> 0.3071683543617393\n",
            "Loss in iteration no. 196746 ==> 0.30716835434537976\n",
            "Loss in iteration no. 196747 ==> 0.30716835432902084\n",
            "Loss in iteration no. 196748 ==> 0.30716835431266265\n",
            "Loss in iteration no. 196749 ==> 0.307168354296305\n",
            "Loss in iteration no. 196750 ==> 0.3071683542799492\n",
            "Loss in iteration no. 196751 ==> 0.3071683542635934\n",
            "Loss in iteration no. 196752 ==> 0.3071683542472388\n",
            "Loss in iteration no. 196753 ==> 0.3071683542308853\n",
            "Loss in iteration no. 196754 ==> 0.3071683542145321\n",
            "Loss in iteration no. 196755 ==> 0.3071683541981799\n",
            "Loss in iteration no. 196756 ==> 0.3071683541818289\n",
            "Loss in iteration no. 196757 ==> 0.3071683541654791\n",
            "Loss in iteration no. 196758 ==> 0.30716835414912935\n",
            "Loss in iteration no. 196759 ==> 0.3071683541327813\n",
            "Loss in iteration no. 196760 ==> 0.30716835411643395\n",
            "Loss in iteration no. 196761 ==> 0.30716835410008714\n",
            "Loss in iteration no. 196762 ==> 0.30716835408374155\n",
            "Loss in iteration no. 196763 ==> 0.30716835406739657\n",
            "Loss in iteration no. 196764 ==> 0.30716835405105225\n",
            "Loss in iteration no. 196765 ==> 0.3071683540347091\n",
            "Loss in iteration no. 196766 ==> 0.3071683540183671\n",
            "Loss in iteration no. 196767 ==> 0.3071683540020262\n",
            "Loss in iteration no. 196768 ==> 0.3071683539856859\n",
            "Loss in iteration no. 196769 ==> 0.3071683539693464\n",
            "Loss in iteration no. 196770 ==> 0.3071683539530078\n",
            "Loss in iteration no. 196771 ==> 0.30716835393667097\n",
            "Loss in iteration no. 196772 ==> 0.3071683539203338\n",
            "Loss in iteration no. 196773 ==> 0.3071683539039982\n",
            "Loss in iteration no. 196774 ==> 0.3071683538876628\n",
            "Loss in iteration no. 196775 ==> 0.30716835387132896\n",
            "Loss in iteration no. 196776 ==> 0.3071683538549959\n",
            "Loss in iteration no. 196777 ==> 0.3071683538386628\n",
            "Loss in iteration no. 196778 ==> 0.30716835382233193\n",
            "Loss in iteration no. 196779 ==> 0.3071683538060012\n",
            "Loss in iteration no. 196780 ==> 0.30716835378967206\n",
            "Loss in iteration no. 196781 ==> 0.30716835377334356\n",
            "Loss in iteration no. 196782 ==> 0.30716835375701523\n",
            "Loss in iteration no. 196783 ==> 0.3071683537406885\n",
            "Loss in iteration no. 196784 ==> 0.30716835372436235\n",
            "Loss in iteration no. 196785 ==> 0.3071683537080379\n",
            "Loss in iteration no. 196786 ==> 0.30716835369171347\n",
            "Loss in iteration no. 196787 ==> 0.30716835367539036\n",
            "Loss in iteration no. 196788 ==> 0.30716835365906775\n",
            "Loss in iteration no. 196789 ==> 0.3071683536427457\n",
            "Loss in iteration no. 196790 ==> 0.30716835362642536\n",
            "Loss in iteration no. 196791 ==> 0.3071683536101056\n",
            "Loss in iteration no. 196792 ==> 0.3071683535937871\n",
            "Loss in iteration no. 196793 ==> 0.3071683535774685\n",
            "Loss in iteration no. 196794 ==> 0.3071683535611517\n",
            "Loss in iteration no. 196795 ==> 0.30716835354483535\n",
            "Loss in iteration no. 196796 ==> 0.3071683535285208\n",
            "Loss in iteration no. 196797 ==> 0.30716835351220567\n",
            "Loss in iteration no. 196798 ==> 0.30716835349589233\n",
            "Loss in iteration no. 196799 ==> 0.30716835347958005\n",
            "Loss in iteration no. 196800 ==> 0.30716835346326793\n",
            "Loss in iteration no. 196801 ==> 0.30716835344695687\n",
            "Loss in iteration no. 196802 ==> 0.3071683534306469\n",
            "Loss in iteration no. 196803 ==> 0.30716835341433807\n",
            "Loss in iteration no. 196804 ==> 0.30716835339802934\n",
            "Loss in iteration no. 196805 ==> 0.30716835338172327\n",
            "Loss in iteration no. 196806 ==> 0.30716835336541676\n",
            "Loss in iteration no. 196807 ==> 0.30716835334911086\n",
            "Loss in iteration no. 196808 ==> 0.3071683533328066\n",
            "Loss in iteration no. 196809 ==> 0.307168353316503\n",
            "Loss in iteration no. 196810 ==> 0.3071683533002004\n",
            "Loss in iteration no. 196811 ==> 0.3071683532838974\n",
            "Loss in iteration no. 196812 ==> 0.3071683532675971\n",
            "Loss in iteration no. 196813 ==> 0.3071683532512968\n",
            "Loss in iteration no. 196814 ==> 0.3071683532349977\n",
            "Loss in iteration no. 196815 ==> 0.30716835321869923\n",
            "Loss in iteration no. 196816 ==> 0.3071683532024023\n",
            "Loss in iteration no. 196817 ==> 0.3071683531861054\n",
            "Loss in iteration no. 196818 ==> 0.30716835316981017\n",
            "Loss in iteration no. 196819 ==> 0.3071683531535146\n",
            "Loss in iteration no. 196820 ==> 0.3071683531372216\n",
            "Loss in iteration no. 196821 ==> 0.30716835312092866\n",
            "Loss in iteration no. 196822 ==> 0.3071683531046363\n",
            "Loss in iteration no. 196823 ==> 0.30716835308834456\n",
            "Loss in iteration no. 196824 ==> 0.307168353072055\n",
            "Loss in iteration no. 196825 ==> 0.30716835305576534\n",
            "Loss in iteration no. 196826 ==> 0.30716835303947704\n",
            "Loss in iteration no. 196827 ==> 0.3071683530231887\n",
            "Loss in iteration no. 196828 ==> 0.3071683530069028\n",
            "Loss in iteration no. 196829 ==> 0.3071683529906167\n",
            "Loss in iteration no. 196830 ==> 0.3071683529743321\n",
            "Loss in iteration no. 196831 ==> 0.3071683529580471\n",
            "Loss in iteration no. 196832 ==> 0.3071683529417647\n",
            "Loss in iteration no. 196833 ==> 0.3071683529254819\n",
            "Loss in iteration no. 196834 ==> 0.3071683529092007\n",
            "Loss in iteration no. 196835 ==> 0.30716835289292055\n",
            "Loss in iteration no. 196836 ==> 0.30716835287664046\n",
            "Loss in iteration no. 196837 ==> 0.3071683528603616\n",
            "Loss in iteration no. 196838 ==> 0.3071683528440837\n",
            "Loss in iteration no. 196839 ==> 0.3071683528278069\n",
            "Loss in iteration no. 196840 ==> 0.3071683528115318\n",
            "Loss in iteration no. 196841 ==> 0.30716835279525617\n",
            "Loss in iteration no. 196842 ==> 0.307168352778982\n",
            "Loss in iteration no. 196843 ==> 0.3071683527627087\n",
            "Loss in iteration no. 196844 ==> 0.3071683527464357\n",
            "Loss in iteration no. 196845 ==> 0.30716835273016446\n",
            "Loss in iteration no. 196846 ==> 0.3071683527138937\n",
            "Loss in iteration no. 196847 ==> 0.3071683526976241\n",
            "Loss in iteration no. 196848 ==> 0.3071683526813545\n",
            "Loss in iteration no. 196849 ==> 0.307168352665087\n",
            "Loss in iteration no. 196850 ==> 0.3071683526488196\n",
            "Loss in iteration no. 196851 ==> 0.30716835263255376\n",
            "Loss in iteration no. 196852 ==> 0.3071683526162885\n",
            "Loss in iteration no. 196853 ==> 0.30716835260002334\n",
            "Loss in iteration no. 196854 ==> 0.30716835258376074\n",
            "Loss in iteration no. 196855 ==> 0.3071683525674977\n",
            "Loss in iteration no. 196856 ==> 0.3071683525512362\n",
            "Loss in iteration no. 196857 ==> 0.3071683525349748\n",
            "Loss in iteration no. 196858 ==> 0.30716835251871544\n",
            "Loss in iteration no. 196859 ==> 0.3071683525024557\n",
            "Loss in iteration no. 196860 ==> 0.3071683524861975\n",
            "Loss in iteration no. 196861 ==> 0.3071683524699409\n",
            "Loss in iteration no. 196862 ==> 0.30716835245368385\n",
            "Loss in iteration no. 196863 ==> 0.3071683524374278\n",
            "Loss in iteration no. 196864 ==> 0.3071683524211739\n",
            "Loss in iteration no. 196865 ==> 0.3071683524049196\n",
            "Loss in iteration no. 196866 ==> 0.3071683523886667\n",
            "Loss in iteration no. 196867 ==> 0.30716835237241547\n",
            "Loss in iteration no. 196868 ==> 0.3071683523561638\n",
            "Loss in iteration no. 196869 ==> 0.30716835233991363\n",
            "Loss in iteration no. 196870 ==> 0.3071683523236647\n",
            "Loss in iteration no. 196871 ==> 0.3071683523074156\n",
            "Loss in iteration no. 196872 ==> 0.3071683522911686\n",
            "Loss in iteration no. 196873 ==> 0.30716835227492184\n",
            "Loss in iteration no. 196874 ==> 0.307168352258676\n",
            "Loss in iteration no. 196875 ==> 0.3071683522424312\n",
            "Loss in iteration no. 196876 ==> 0.30716835222618694\n",
            "Loss in iteration no. 196877 ==> 0.3071683522099444\n",
            "Loss in iteration no. 196878 ==> 0.30716835219370214\n",
            "Loss in iteration no. 196879 ==> 0.30716835217746064\n",
            "Loss in iteration no. 196880 ==> 0.3071683521612196\n",
            "Loss in iteration no. 196881 ==> 0.3071683521449807\n",
            "Loss in iteration no. 196882 ==> 0.3071683521287418\n",
            "Loss in iteration no. 196883 ==> 0.30716835211250343\n",
            "Loss in iteration no. 196884 ==> 0.3071683520962667\n",
            "Loss in iteration no. 196885 ==> 0.30716835208003135\n",
            "Loss in iteration no. 196886 ==> 0.30716835206379667\n",
            "Loss in iteration no. 196887 ==> 0.307168352047562\n",
            "Loss in iteration no. 196888 ==> 0.30716835203132836\n",
            "Loss in iteration no. 196889 ==> 0.3071683520150963\n",
            "Loss in iteration no. 196890 ==> 0.3071683519988648\n",
            "Loss in iteration no. 196891 ==> 0.3071683519826338\n",
            "Loss in iteration no. 196892 ==> 0.30716835196640485\n",
            "Loss in iteration no. 196893 ==> 0.3071683519501754\n",
            "Loss in iteration no. 196894 ==> 0.30716835193394754\n",
            "Loss in iteration no. 196895 ==> 0.30716835191771974\n",
            "Loss in iteration no. 196896 ==> 0.307168351901494\n",
            "Loss in iteration no. 196897 ==> 0.3071683518852683\n",
            "Loss in iteration no. 196898 ==> 0.307168351869045\n",
            "Loss in iteration no. 196899 ==> 0.3071683518528213\n",
            "Loss in iteration no. 196900 ==> 0.30716835183659774\n",
            "Loss in iteration no. 196901 ==> 0.30716835182037666\n",
            "Loss in iteration no. 196902 ==> 0.307168351804155\n",
            "Loss in iteration no. 196903 ==> 0.30716835178793606\n",
            "Loss in iteration no. 196904 ==> 0.3071683517717171\n",
            "Loss in iteration no. 196905 ==> 0.3071683517554986\n",
            "Loss in iteration no. 196906 ==> 0.30716835173928064\n",
            "Loss in iteration no. 196907 ==> 0.3071683517230648\n",
            "Loss in iteration no. 196908 ==> 0.3071683517068489\n",
            "Loss in iteration no. 196909 ==> 0.30716835169063406\n",
            "Loss in iteration no. 196910 ==> 0.30716835167442075\n",
            "Loss in iteration no. 196911 ==> 0.307168351658208\n",
            "Loss in iteration no. 196912 ==> 0.30716835164199524\n",
            "Loss in iteration no. 196913 ==> 0.307168351625785\n",
            "Loss in iteration no. 196914 ==> 0.3071683516095743\n",
            "Loss in iteration no. 196915 ==> 0.30716835159336503\n",
            "Loss in iteration no. 196916 ==> 0.30716835157715694\n",
            "Loss in iteration no. 196917 ==> 0.30716835156094935\n",
            "Loss in iteration no. 196918 ==> 0.3071683515447422\n",
            "Loss in iteration no. 196919 ==> 0.3071683515285361\n",
            "Loss in iteration no. 196920 ==> 0.307168351512332\n",
            "Loss in iteration no. 196921 ==> 0.307168351496128\n",
            "Loss in iteration no. 196922 ==> 0.30716835147992444\n",
            "Loss in iteration no. 196923 ==> 0.3071683514637224\n",
            "Loss in iteration no. 196924 ==> 0.3071683514475204\n",
            "Loss in iteration no. 196925 ==> 0.307168351431321\n",
            "Loss in iteration no. 196926 ==> 0.307168351415121\n",
            "Loss in iteration no. 196927 ==> 0.3071683513989225\n",
            "Loss in iteration no. 196928 ==> 0.307168351382725\n",
            "Loss in iteration no. 196929 ==> 0.30716835136652765\n",
            "Loss in iteration no. 196930 ==> 0.3071683513503317\n",
            "Loss in iteration no. 196931 ==> 0.30716835133413634\n",
            "Loss in iteration no. 196932 ==> 0.30716835131794246\n",
            "Loss in iteration no. 196933 ==> 0.3071683513017491\n",
            "Loss in iteration no. 196934 ==> 0.3071683512855567\n",
            "Loss in iteration no. 196935 ==> 0.30716835126936437\n",
            "Loss in iteration no. 196936 ==> 0.30716835125317443\n",
            "Loss in iteration no. 196937 ==> 0.3071683512369841\n",
            "Loss in iteration no. 196938 ==> 0.3071683512207953\n",
            "Loss in iteration no. 196939 ==> 0.30716835120460695\n",
            "Loss in iteration no. 196940 ==> 0.30716835118842006\n",
            "Loss in iteration no. 196941 ==> 0.3071683511722343\n",
            "Loss in iteration no. 196942 ==> 0.30716835115604846\n",
            "Loss in iteration no. 196943 ==> 0.3071683511398637\n",
            "Loss in iteration no. 196944 ==> 0.3071683511236798\n",
            "Loss in iteration no. 196945 ==> 0.307168351107497\n",
            "Loss in iteration no. 196946 ==> 0.3071683510913152\n",
            "Loss in iteration no. 196947 ==> 0.30716835107513485\n",
            "Loss in iteration no. 196948 ==> 0.30716835105895507\n",
            "Loss in iteration no. 196949 ==> 0.30716835104277573\n",
            "Loss in iteration no. 196950 ==> 0.30716835102659695\n",
            "Loss in iteration no. 196951 ==> 0.3071683510104195\n",
            "Loss in iteration no. 196952 ==> 0.3071683509942433\n",
            "Loss in iteration no. 196953 ==> 0.3071683509780674\n",
            "Loss in iteration no. 196954 ==> 0.307168350961893\n",
            "Loss in iteration no. 196955 ==> 0.3071683509457186\n",
            "Loss in iteration no. 196956 ==> 0.3071683509295453\n",
            "Loss in iteration no. 196957 ==> 0.3071683509133744\n",
            "Loss in iteration no. 196958 ==> 0.30716835089720307\n",
            "Loss in iteration no. 196959 ==> 0.3071683508810326\n",
            "Loss in iteration no. 196960 ==> 0.30716835086486277\n",
            "Loss in iteration no. 196961 ==> 0.30716835084869426\n",
            "Loss in iteration no. 196962 ==> 0.30716835083252636\n",
            "Loss in iteration no. 196963 ==> 0.30716835081635996\n",
            "Loss in iteration no. 196964 ==> 0.307168350800194\n",
            "Loss in iteration no. 196965 ==> 0.30716835078402904\n",
            "Loss in iteration no. 196966 ==> 0.3071683507678651\n",
            "Loss in iteration no. 196967 ==> 0.307168350751702\n",
            "Loss in iteration no. 196968 ==> 0.307168350735539\n",
            "Loss in iteration no. 196969 ==> 0.3071683507193779\n",
            "Loss in iteration no. 196970 ==> 0.30716835070321735\n",
            "Loss in iteration no. 196971 ==> 0.3071683506870573\n",
            "Loss in iteration no. 196972 ==> 0.30716835067089815\n",
            "Loss in iteration no. 196973 ==> 0.3071683506547405\n",
            "Loss in iteration no. 196974 ==> 0.3071683506385834\n",
            "Loss in iteration no. 196975 ==> 0.30716835062242775\n",
            "Loss in iteration no. 196976 ==> 0.30716835060627207\n",
            "Loss in iteration no. 196977 ==> 0.3071683505901173\n",
            "Loss in iteration no. 196978 ==> 0.3071683505739645\n",
            "Loss in iteration no. 196979 ==> 0.3071683505578118\n",
            "Loss in iteration no. 196980 ==> 0.3071683505416601\n",
            "Loss in iteration no. 196981 ==> 0.3071683505255093\n",
            "Loss in iteration no. 196982 ==> 0.3071683505093584\n",
            "Loss in iteration no. 196983 ==> 0.30716835049320995\n",
            "Loss in iteration no. 196984 ==> 0.30716835047706204\n",
            "Loss in iteration no. 196985 ==> 0.3071683504609146\n",
            "Loss in iteration no. 196986 ==> 0.30716835044476765\n",
            "Loss in iteration no. 196987 ==> 0.30716835042862217\n",
            "Loss in iteration no. 196988 ==> 0.30716835041247764\n",
            "Loss in iteration no. 196989 ==> 0.30716835039633406\n",
            "Loss in iteration no. 196990 ==> 0.30716835038019136\n",
            "Loss in iteration no. 196991 ==> 0.3071683503640488\n",
            "Loss in iteration no. 196992 ==> 0.30716835034790807\n",
            "Loss in iteration no. 196993 ==> 0.3071683503317673\n",
            "Loss in iteration no. 196994 ==> 0.3071683503156276\n",
            "Loss in iteration no. 196995 ==> 0.3071683502994903\n",
            "Loss in iteration no. 196996 ==> 0.30716835028335254\n",
            "Loss in iteration no. 196997 ==> 0.3071683502672152\n",
            "Loss in iteration no. 196998 ==> 0.30716835025107925\n",
            "Loss in iteration no. 196999 ==> 0.3071683502349447\n",
            "Loss in iteration no. 197000 ==> 0.3071683502188102\n",
            "Loss in iteration no. 197001 ==> 0.3071683502026777\n",
            "Loss in iteration no. 197002 ==> 0.3071683501865451\n",
            "Loss in iteration no. 197003 ==> 0.30716835017041344\n",
            "Loss in iteration no. 197004 ==> 0.30716835015428273\n",
            "Loss in iteration no. 197005 ==> 0.307168350138153\n",
            "Loss in iteration no. 197006 ==> 0.3071683501220243\n",
            "Loss in iteration no. 197007 ==> 0.307168350105897\n",
            "Loss in iteration no. 197008 ==> 0.30716835008977006\n",
            "Loss in iteration no. 197009 ==> 0.3071683500736436\n",
            "Loss in iteration no. 197010 ==> 0.3071683500575177\n",
            "Loss in iteration no. 197011 ==> 0.3071683500413942\n",
            "Loss in iteration no. 197012 ==> 0.3071683500252706\n",
            "Loss in iteration no. 197013 ==> 0.307168350009148\n",
            "Loss in iteration no. 197014 ==> 0.30716834999302634\n",
            "Loss in iteration no. 197015 ==> 0.3071683499769055\n",
            "Loss in iteration no. 197016 ==> 0.3071683499607858\n",
            "Loss in iteration no. 197017 ==> 0.3071683499446659\n",
            "Loss in iteration no. 197018 ==> 0.30716834992854847\n",
            "Loss in iteration no. 197019 ==> 0.3071683499124305\n",
            "Loss in iteration no. 197020 ==> 0.3071683498963145\n",
            "Loss in iteration no. 197021 ==> 0.3071683498801989\n",
            "Loss in iteration no. 197022 ==> 0.30716834986408426\n",
            "Loss in iteration no. 197023 ==> 0.3071683498479701\n",
            "Loss in iteration no. 197024 ==> 0.30716834983185737\n",
            "Loss in iteration no. 197025 ==> 0.3071683498157454\n",
            "Loss in iteration no. 197026 ==> 0.30716834979963464\n",
            "Loss in iteration no. 197027 ==> 0.30716834978352475\n",
            "Loss in iteration no. 197028 ==> 0.3071683497674146\n",
            "Loss in iteration no. 197029 ==> 0.307168349751307\n",
            "Loss in iteration no. 197030 ==> 0.30716834973519896\n",
            "Loss in iteration no. 197031 ==> 0.3071683497190917\n",
            "Loss in iteration no. 197032 ==> 0.3071683497029869\n",
            "Loss in iteration no. 197033 ==> 0.3071683496868815\n",
            "Loss in iteration no. 197034 ==> 0.3071683496707776\n",
            "Loss in iteration no. 197035 ==> 0.30716834965467466\n",
            "Loss in iteration no. 197036 ==> 0.3071683496385726\n",
            "Loss in iteration no. 197037 ==> 0.30716834962246997\n",
            "Loss in iteration no. 197038 ==> 0.30716834960636974\n",
            "Loss in iteration no. 197039 ==> 0.30716834959027095\n",
            "Loss in iteration no. 197040 ==> 0.30716834957417155\n",
            "Loss in iteration no. 197041 ==> 0.3071683495580731\n",
            "Loss in iteration no. 197042 ==> 0.3071683495419767\n",
            "Loss in iteration no. 197043 ==> 0.3071683495258805\n",
            "Loss in iteration no. 197044 ==> 0.30716834950978494\n",
            "Loss in iteration no. 197045 ==> 0.3071683494936906\n",
            "Loss in iteration no. 197046 ==> 0.3071683494775968\n",
            "Loss in iteration no. 197047 ==> 0.3071683494615044\n",
            "Loss in iteration no. 197048 ==> 0.30716834944541294\n",
            "Loss in iteration no. 197049 ==> 0.3071683494293224\n",
            "Loss in iteration no. 197050 ==> 0.30716834941323173\n",
            "Loss in iteration no. 197051 ==> 0.307168349397143\n",
            "Loss in iteration no. 197052 ==> 0.30716834938105525\n",
            "Loss in iteration no. 197053 ==> 0.30716834936496734\n",
            "Loss in iteration no. 197054 ==> 0.3071683493488808\n",
            "Loss in iteration no. 197055 ==> 0.3071683493327958\n",
            "Loss in iteration no. 197056 ==> 0.3071683493167111\n",
            "Loss in iteration no. 197057 ==> 0.30716834930062686\n",
            "Loss in iteration no. 197058 ==> 0.30716834928454406\n",
            "Loss in iteration no. 197059 ==> 0.3071683492684621\n",
            "Loss in iteration no. 197060 ==> 0.3071683492523811\n",
            "Loss in iteration no. 197061 ==> 0.307168349236301\n",
            "Loss in iteration no. 197062 ==> 0.30716834922022185\n",
            "Loss in iteration no. 197063 ==> 0.3071683492041426\n",
            "Loss in iteration no. 197064 ==> 0.30716834918806524\n",
            "Loss in iteration no. 197065 ==> 0.3071683491719887\n",
            "Loss in iteration no. 197066 ==> 0.3071683491559122\n",
            "Loss in iteration no. 197067 ==> 0.3071683491398379\n",
            "Loss in iteration no. 197068 ==> 0.30716834912376323\n",
            "Loss in iteration no. 197069 ==> 0.30716834910768986\n",
            "Loss in iteration no. 197070 ==> 0.3071683490916185\n",
            "Loss in iteration no. 197071 ==> 0.30716834907554635\n",
            "Loss in iteration no. 197072 ==> 0.3071683490594757\n",
            "Loss in iteration no. 197073 ==> 0.307168349043406\n",
            "Loss in iteration no. 197074 ==> 0.30716834902733714\n",
            "Loss in iteration no. 197075 ==> 0.30716834901126916\n",
            "Loss in iteration no. 197076 ==> 0.3071683489952021\n",
            "Loss in iteration no. 197077 ==> 0.3071683489791364\n",
            "Loss in iteration no. 197078 ==> 0.3071683489630702\n",
            "Loss in iteration no. 197079 ==> 0.3071683489470063\n",
            "Loss in iteration no. 197080 ==> 0.3071683489309429\n",
            "Loss in iteration no. 197081 ==> 0.3071683489148797\n",
            "Loss in iteration no. 197082 ==> 0.3071683488988181\n",
            "Loss in iteration no. 197083 ==> 0.30716834888275674\n",
            "Loss in iteration no. 197084 ==> 0.3071683488666974\n",
            "Loss in iteration no. 197085 ==> 0.30716834885063793\n",
            "Loss in iteration no. 197086 ==> 0.3071683488345802\n",
            "Loss in iteration no. 197087 ==> 0.3071683488185225\n",
            "Loss in iteration no. 197088 ==> 0.3071683488024657\n",
            "Loss in iteration no. 197089 ==> 0.3071683487864102\n",
            "Loss in iteration no. 197090 ==> 0.3071683487703551\n",
            "Loss in iteration no. 197091 ==> 0.30716834875430093\n",
            "Loss in iteration no. 197092 ==> 0.3071683487382492\n",
            "Loss in iteration no. 197093 ==> 0.3071683487221962\n",
            "Loss in iteration no. 197094 ==> 0.3071683487061447\n",
            "Loss in iteration no. 197095 ==> 0.3071683486900945\n",
            "Loss in iteration no. 197096 ==> 0.3071683486740453\n",
            "Loss in iteration no. 197097 ==> 0.3071683486579968\n",
            "Loss in iteration no. 197098 ==> 0.30716834864194936\n",
            "Loss in iteration no. 197099 ==> 0.3071683486259017\n",
            "Loss in iteration no. 197100 ==> 0.3071683486098559\n",
            "Loss in iteration no. 197101 ==> 0.3071683485938111\n",
            "Loss in iteration no. 197102 ==> 0.3071683485777666\n",
            "Loss in iteration no. 197103 ==> 0.3071683485617235\n",
            "Loss in iteration no. 197104 ==> 0.30716834854568065\n",
            "Loss in iteration no. 197105 ==> 0.3071683485296394\n",
            "Loss in iteration no. 197106 ==> 0.3071683485135983\n",
            "Loss in iteration no. 197107 ==> 0.30716834849755925\n",
            "Loss in iteration no. 197108 ==> 0.30716834848151997\n",
            "Loss in iteration no. 197109 ==> 0.30716834846548163\n",
            "Loss in iteration no. 197110 ==> 0.307168348449445\n",
            "Loss in iteration no. 197111 ==> 0.30716834843340846\n",
            "Loss in iteration no. 197112 ==> 0.3071683484173726\n",
            "Loss in iteration no. 197113 ==> 0.3071683484013377\n",
            "Loss in iteration no. 197114 ==> 0.30716834838530527\n",
            "Loss in iteration no. 197115 ==> 0.30716834836927204\n",
            "Loss in iteration no. 197116 ==> 0.3071683483532403\n",
            "Loss in iteration no. 197117 ==> 0.30716834833720874\n",
            "Loss in iteration no. 197118 ==> 0.3071683483211788\n",
            "Loss in iteration no. 197119 ==> 0.3071683483051495\n",
            "Loss in iteration no. 197120 ==> 0.3071683482891212\n",
            "Loss in iteration no. 197121 ==> 0.3071683482730937\n",
            "Loss in iteration no. 197122 ==> 0.30716834825706707\n",
            "Loss in iteration no. 197123 ==> 0.30716834824104133\n",
            "Loss in iteration no. 197124 ==> 0.30716834822501643\n",
            "Loss in iteration no. 197125 ==> 0.3071683482089924\n",
            "Loss in iteration no. 197126 ==> 0.3071683481929686\n",
            "Loss in iteration no. 197127 ==> 0.3071683481769463\n",
            "Loss in iteration no. 197128 ==> 0.30716834816092536\n",
            "Loss in iteration no. 197129 ==> 0.3071683481449053\n",
            "Loss in iteration no. 197130 ==> 0.3071683481288855\n",
            "Loss in iteration no. 197131 ==> 0.30716834811286614\n",
            "Loss in iteration no. 197132 ==> 0.3071683480968485\n",
            "Loss in iteration no. 197133 ==> 0.30716834808083193\n",
            "Loss in iteration no. 197134 ==> 0.30716834806481497\n",
            "Loss in iteration no. 197135 ==> 0.3071683480488\n",
            "Loss in iteration no. 197136 ==> 0.30716834803278575\n",
            "Loss in iteration no. 197137 ==> 0.30716834801677206\n",
            "Loss in iteration no. 197138 ==> 0.3071683480007596\n",
            "Loss in iteration no. 197139 ==> 0.30716834798474857\n",
            "Loss in iteration no. 197140 ==> 0.3071683479687367\n",
            "Loss in iteration no. 197141 ==> 0.3071683479527273\n",
            "Loss in iteration no. 197142 ==> 0.30716834793671727\n",
            "Loss in iteration no. 197143 ==> 0.3071683479207096\n",
            "Loss in iteration no. 197144 ==> 0.30716834790470177\n",
            "Loss in iteration no. 197145 ==> 0.3071683478886957\n",
            "Loss in iteration no. 197146 ==> 0.30716834787269043\n",
            "Loss in iteration no. 197147 ==> 0.30716834785668506\n",
            "Loss in iteration no. 197148 ==> 0.3071683478406821\n",
            "Loss in iteration no. 197149 ==> 0.3071683478246784\n",
            "Loss in iteration no. 197150 ==> 0.3071683478086766\n",
            "Loss in iteration no. 197151 ==> 0.30716834779267516\n",
            "Loss in iteration no. 197152 ==> 0.30716834777667495\n",
            "Loss in iteration no. 197153 ==> 0.30716834776067514\n",
            "Loss in iteration no. 197154 ==> 0.30716834774467716\n",
            "Loss in iteration no. 197155 ==> 0.3071683477286785\n",
            "Loss in iteration no. 197156 ==> 0.3071683477126822\n",
            "Loss in iteration no. 197157 ==> 0.3071683476966857\n",
            "Loss in iteration no. 197158 ==> 0.3071683476806911\n",
            "Loss in iteration no. 197159 ==> 0.30716834766469686\n",
            "Loss in iteration no. 197160 ==> 0.30716834764870377\n",
            "Loss in iteration no. 197161 ==> 0.3071683476327106\n",
            "Loss in iteration no. 197162 ==> 0.30716834761671985\n",
            "Loss in iteration no. 197163 ==> 0.30716834760072836\n",
            "Loss in iteration no. 197164 ==> 0.3071683475847392\n",
            "Loss in iteration no. 197165 ==> 0.3071683475687494\n",
            "Loss in iteration no. 197166 ==> 0.3071683475527618\n",
            "Loss in iteration no. 197167 ==> 0.30716834753677424\n",
            "Loss in iteration no. 197168 ==> 0.3071683475207884\n",
            "Loss in iteration no. 197169 ==> 0.3071683475048033\n",
            "Loss in iteration no. 197170 ==> 0.30716834748881816\n",
            "Loss in iteration no. 197171 ==> 0.3071683474728347\n",
            "Loss in iteration no. 197172 ==> 0.3071683474568512\n",
            "Loss in iteration no. 197173 ==> 0.3071683474408694\n",
            "Loss in iteration no. 197174 ==> 0.307168347424889\n",
            "Loss in iteration no. 197175 ==> 0.30716834740890786\n",
            "Loss in iteration no. 197176 ==> 0.3071683473929291\n",
            "Loss in iteration no. 197177 ==> 0.30716834737695015\n",
            "Loss in iteration no. 197178 ==> 0.30716834736097254\n",
            "Loss in iteration no. 197179 ==> 0.3071683473449962\n",
            "Loss in iteration no. 197180 ==> 0.3071683473290207\n",
            "Loss in iteration no. 197181 ==> 0.30716834731304493\n",
            "Loss in iteration no. 197182 ==> 0.3071683472970711\n",
            "Loss in iteration no. 197183 ==> 0.30716834728109804\n",
            "Loss in iteration no. 197184 ==> 0.30716834726512626\n",
            "Loss in iteration no. 197185 ==> 0.30716834724915376\n",
            "Loss in iteration no. 197186 ==> 0.30716834723318315\n",
            "Loss in iteration no. 197187 ==> 0.30716834721721387\n",
            "Loss in iteration no. 197188 ==> 0.3071683472012448\n",
            "Loss in iteration no. 197189 ==> 0.307168347185277\n",
            "Loss in iteration no. 197190 ==> 0.3071683471693102\n",
            "Loss in iteration no. 197191 ==> 0.3071683471533441\n",
            "Loss in iteration no. 197192 ==> 0.30716834713737884\n",
            "Loss in iteration no. 197193 ==> 0.30716834712141444\n",
            "Loss in iteration no. 197194 ==> 0.30716834710545066\n",
            "Loss in iteration no. 197195 ==> 0.3071683470894878\n",
            "Loss in iteration no. 197196 ==> 0.3071683470735258\n",
            "Loss in iteration no. 197197 ==> 0.30716834705756446\n",
            "Loss in iteration no. 197198 ==> 0.3071683470416045\n",
            "Loss in iteration no. 197199 ==> 0.30716834702564494\n",
            "Loss in iteration no. 197200 ==> 0.3071683470096874\n",
            "Loss in iteration no. 197201 ==> 0.30716834699372997\n",
            "Loss in iteration no. 197202 ==> 0.3071683469777727\n",
            "Loss in iteration no. 197203 ==> 0.3071683469618167\n",
            "Loss in iteration no. 197204 ==> 0.3071683469458626\n",
            "Loss in iteration no. 197205 ==> 0.3071683469299082\n",
            "Loss in iteration no. 197206 ==> 0.30716834691395456\n",
            "Loss in iteration no. 197207 ==> 0.3071683468980027\n",
            "Loss in iteration no. 197208 ==> 0.30716834688205136\n",
            "Loss in iteration no. 197209 ==> 0.3071683468661011\n",
            "Loss in iteration no. 197210 ==> 0.30716834685015065\n",
            "Loss in iteration no. 197211 ==> 0.30716834683420263\n",
            "Loss in iteration no. 197212 ==> 0.3071683468182547\n",
            "Loss in iteration no. 197213 ==> 0.30716834680230715\n",
            "Loss in iteration no. 197214 ==> 0.30716834678636146\n",
            "Loss in iteration no. 197215 ==> 0.3071683467704165\n",
            "Loss in iteration no. 197216 ==> 0.30716834675447235\n",
            "Loss in iteration no. 197217 ==> 0.307168346738529\n",
            "Loss in iteration no. 197218 ==> 0.3071683467225864\n",
            "Loss in iteration no. 197219 ==> 0.3071683467066436\n",
            "Loss in iteration no. 197220 ==> 0.30716834669070253\n",
            "Loss in iteration no. 197221 ==> 0.30716834667476334\n",
            "Loss in iteration no. 197222 ==> 0.3071683466588243\n",
            "Loss in iteration no. 197223 ==> 0.30716834664288567\n",
            "Loss in iteration no. 197224 ==> 0.30716834662694825\n",
            "Loss in iteration no. 197225 ==> 0.3071683466110116\n",
            "Loss in iteration no. 197226 ==> 0.30716834659507525\n",
            "Loss in iteration no. 197227 ==> 0.3071683465791412\n",
            "Loss in iteration no. 197228 ==> 0.30716834656320696\n",
            "Loss in iteration no. 197229 ==> 0.3071683465472745\n",
            "Loss in iteration no. 197230 ==> 0.3071683465313417\n",
            "Loss in iteration no. 197231 ==> 0.30716834651541075\n",
            "Loss in iteration no. 197232 ==> 0.30716834649948016\n",
            "Loss in iteration no. 197233 ==> 0.30716834648355074\n",
            "Loss in iteration no. 197234 ==> 0.3071683464676221\n",
            "Loss in iteration no. 197235 ==> 0.3071683464516948\n",
            "Loss in iteration no. 197236 ==> 0.30716834643576724\n",
            "Loss in iteration no. 197237 ==> 0.30716834641984087\n",
            "Loss in iteration no. 197238 ==> 0.3071683464039158\n",
            "Loss in iteration no. 197239 ==> 0.3071683463879915\n",
            "Loss in iteration no. 197240 ==> 0.3071683463720681\n",
            "Loss in iteration no. 197241 ==> 0.30716834635614526\n",
            "Loss in iteration no. 197242 ==> 0.3071683463402244\n",
            "Loss in iteration no. 197243 ==> 0.3071683463243032\n",
            "Loss in iteration no. 197244 ==> 0.3071683463083827\n",
            "Loss in iteration no. 197245 ==> 0.3071683462924646\n",
            "Loss in iteration no. 197246 ==> 0.3071683462765456\n",
            "Loss in iteration no. 197247 ==> 0.30716834626062905\n",
            "Loss in iteration no. 197248 ==> 0.3071683462447117\n",
            "Loss in iteration no. 197249 ==> 0.3071683462287965\n",
            "Loss in iteration no. 197250 ==> 0.30716834621288214\n",
            "Loss in iteration no. 197251 ==> 0.3071683461969686\n",
            "Loss in iteration no. 197252 ==> 0.3071683461810542\n",
            "Loss in iteration no. 197253 ==> 0.30716834616514216\n",
            "Loss in iteration no. 197254 ==> 0.30716834614923133\n",
            "Loss in iteration no. 197255 ==> 0.30716834613332067\n",
            "Loss in iteration no. 197256 ==> 0.30716834611741195\n",
            "Loss in iteration no. 197257 ==> 0.3071683461015029\n",
            "Loss in iteration no. 197258 ==> 0.307168346085595\n",
            "Loss in iteration no. 197259 ==> 0.30716834606968857\n",
            "Loss in iteration no. 197260 ==> 0.3071683460537822\n",
            "Loss in iteration no. 197261 ==> 0.30716834603787774\n",
            "Loss in iteration no. 197262 ==> 0.30716834602197235\n",
            "Loss in iteration no. 197263 ==> 0.30716834600606946\n",
            "Loss in iteration no. 197264 ==> 0.3071683459901671\n",
            "Loss in iteration no. 197265 ==> 0.3071683459742646\n",
            "Loss in iteration no. 197266 ==> 0.30716834595836373\n",
            "Loss in iteration no. 197267 ==> 0.3071683459424637\n",
            "Loss in iteration no. 197268 ==> 0.30716834592656594\n",
            "Loss in iteration no. 197269 ==> 0.3071683459106674\n",
            "Loss in iteration no. 197270 ==> 0.3071683458947701\n",
            "Loss in iteration no. 197271 ==> 0.3071683458788731\n",
            "Loss in iteration no. 197272 ==> 0.30716834586297825\n",
            "Loss in iteration no. 197273 ==> 0.30716834584708264\n",
            "Loss in iteration no. 197274 ==> 0.3071683458311893\n",
            "Loss in iteration no. 197275 ==> 0.30716834581529673\n",
            "Loss in iteration no. 197276 ==> 0.30716834579940383\n",
            "Loss in iteration no. 197277 ==> 0.30716834578351265\n",
            "Loss in iteration no. 197278 ==> 0.3071683457676225\n",
            "Loss in iteration no. 197279 ==> 0.30716834575173274\n",
            "Loss in iteration no. 197280 ==> 0.3071683457358439\n",
            "Loss in iteration no. 197281 ==> 0.30716834571995727\n",
            "Loss in iteration no. 197282 ==> 0.30716834570406976\n",
            "Loss in iteration no. 197283 ==> 0.3071683456881837\n",
            "Loss in iteration no. 197284 ==> 0.3071683456722986\n",
            "Loss in iteration no. 197285 ==> 0.30716834565641393\n",
            "Loss in iteration no. 197286 ==> 0.307168345640531\n",
            "Loss in iteration no. 197287 ==> 0.30716834562464873\n",
            "Loss in iteration no. 197288 ==> 0.3071683456087672\n",
            "Loss in iteration no. 197289 ==> 0.3071683455928864\n",
            "Loss in iteration no. 197290 ==> 0.30716834557700645\n",
            "Loss in iteration no. 197291 ==> 0.307168345561127\n",
            "Loss in iteration no. 197292 ==> 0.3071683455452484\n",
            "Loss in iteration no. 197293 ==> 0.30716834552937206\n",
            "Loss in iteration no. 197294 ==> 0.30716834551349487\n",
            "Loss in iteration no. 197295 ==> 0.30716834549761995\n",
            "Loss in iteration no. 197296 ==> 0.3071683454817443\n",
            "Loss in iteration no. 197297 ==> 0.30716834546587085\n",
            "Loss in iteration no. 197298 ==> 0.30716834544999805\n",
            "Loss in iteration no. 197299 ==> 0.3071683454341255\n",
            "Loss in iteration no. 197300 ==> 0.30716834541825416\n",
            "Loss in iteration no. 197301 ==> 0.30716834540238364\n",
            "Loss in iteration no. 197302 ==> 0.3071683453865152\n",
            "Loss in iteration no. 197303 ==> 0.30716834537064613\n",
            "Loss in iteration no. 197304 ==> 0.30716834535477866\n",
            "Loss in iteration no. 197305 ==> 0.30716834533891096\n",
            "Loss in iteration no. 197306 ==> 0.3071683453230455\n",
            "Loss in iteration no. 197307 ==> 0.30716834530718023\n",
            "Loss in iteration no. 197308 ==> 0.30716834529131615\n",
            "Loss in iteration no. 197309 ==> 0.30716834527545284\n",
            "Loss in iteration no. 197310 ==> 0.30716834525958964\n",
            "Loss in iteration no. 197311 ==> 0.3071683452437288\n",
            "Loss in iteration no. 197312 ==> 0.3071683452278675\n",
            "Loss in iteration no. 197313 ==> 0.3071683452120081\n",
            "Loss in iteration no. 197314 ==> 0.3071683451961483\n",
            "Loss in iteration no. 197315 ==> 0.30716834518029074\n",
            "Loss in iteration no. 197316 ==> 0.30716834516443337\n",
            "Loss in iteration no. 197317 ==> 0.30716834514857677\n",
            "Loss in iteration no. 197318 ==> 0.3071683451327213\n",
            "Loss in iteration no. 197319 ==> 0.307168345116866\n",
            "Loss in iteration no. 197320 ==> 0.3071683451010131\n",
            "Loss in iteration no. 197321 ==> 0.3071683450851591\n",
            "Loss in iteration no. 197322 ==> 0.30716834506930757\n",
            "Loss in iteration no. 197323 ==> 0.3071683450534556\n",
            "Loss in iteration no. 197324 ==> 0.3071683450376054\n",
            "Loss in iteration no. 197325 ==> 0.3071683450217559\n",
            "Loss in iteration no. 197326 ==> 0.3071683450059071\n",
            "Loss in iteration no. 197327 ==> 0.30716834499005996\n",
            "Loss in iteration no. 197328 ==> 0.3071683449742131\n",
            "Loss in iteration no. 197329 ==> 0.30716834495836637\n",
            "Loss in iteration no. 197330 ==> 0.3071683449425213\n",
            "Loss in iteration no. 197331 ==> 0.3071683449266775\n",
            "Loss in iteration no. 197332 ==> 0.30716834491083445\n",
            "Loss in iteration no. 197333 ==> 0.3071683448949915\n",
            "Loss in iteration no. 197334 ==> 0.30716834487914974\n",
            "Loss in iteration no. 197335 ==> 0.3071683448633087\n",
            "Loss in iteration no. 197336 ==> 0.30716834484746836\n",
            "Loss in iteration no. 197337 ==> 0.3071683448316297\n",
            "Loss in iteration no. 197338 ==> 0.3071683448157918\n",
            "Loss in iteration no. 197339 ==> 0.3071683447999535\n",
            "Loss in iteration no. 197340 ==> 0.3071683447841169\n",
            "Loss in iteration no. 197341 ==> 0.3071683447682816\n",
            "Loss in iteration no. 197342 ==> 0.30716834475244736\n",
            "Loss in iteration no. 197343 ==> 0.30716834473661336\n",
            "Loss in iteration no. 197344 ==> 0.3071683447207795\n",
            "Loss in iteration no. 197345 ==> 0.3071683447049479\n",
            "Loss in iteration no. 197346 ==> 0.30716834468911697\n",
            "Loss in iteration no. 197347 ==> 0.3071683446732867\n",
            "Loss in iteration no. 197348 ==> 0.3071683446574572\n",
            "Loss in iteration no. 197349 ==> 0.3071683446416283\n",
            "Loss in iteration no. 197350 ==> 0.30716834462580006\n",
            "Loss in iteration no. 197351 ==> 0.3071683446099735\n",
            "Loss in iteration no. 197352 ==> 0.3071683445941466\n",
            "Loss in iteration no. 197353 ==> 0.30716834457832204\n",
            "Loss in iteration no. 197354 ==> 0.30716834456249753\n",
            "Loss in iteration no. 197355 ==> 0.3071683445466743\n",
            "Loss in iteration no. 197356 ==> 0.3071683445308511\n",
            "Loss in iteration no. 197357 ==> 0.30716834451502917\n",
            "Loss in iteration no. 197358 ==> 0.3071683444992089\n",
            "Loss in iteration no. 197359 ==> 0.30716834448338837\n",
            "Loss in iteration no. 197360 ==> 0.30716834446756885\n",
            "Loss in iteration no. 197361 ==> 0.3071683444517511\n",
            "Loss in iteration no. 197362 ==> 0.3071683444359335\n",
            "Loss in iteration no. 197363 ==> 0.30716834442011665\n",
            "Loss in iteration no. 197364 ==> 0.30716834440430146\n",
            "Loss in iteration no. 197365 ==> 0.3071683443884859\n",
            "Loss in iteration no. 197366 ==> 0.30716834437267243\n",
            "Loss in iteration no. 197367 ==> 0.3071683443568593\n",
            "Loss in iteration no. 197368 ==> 0.30716834434104723\n",
            "Loss in iteration no. 197369 ==> 0.3071683443252358\n",
            "Loss in iteration no. 197370 ==> 0.3071683443094245\n",
            "Loss in iteration no. 197371 ==> 0.30716834429361556\n",
            "Loss in iteration no. 197372 ==> 0.30716834427780615\n",
            "Loss in iteration no. 197373 ==> 0.3071683442619984\n",
            "Loss in iteration no. 197374 ==> 0.3071683442461914\n",
            "Loss in iteration no. 197375 ==> 0.3071683442303855\n",
            "Loss in iteration no. 197376 ==> 0.3071683442145797\n",
            "Loss in iteration no. 197377 ==> 0.3071683441987757\n",
            "Loss in iteration no. 197378 ==> 0.3071683441829718\n",
            "Loss in iteration no. 197379 ==> 0.30716834416716904\n",
            "Loss in iteration no. 197380 ==> 0.3071683441513675\n",
            "Loss in iteration no. 197381 ==> 0.3071683441355666\n",
            "Loss in iteration no. 197382 ==> 0.3071683441197658\n",
            "Loss in iteration no. 197383 ==> 0.30716834410396715\n",
            "Loss in iteration no. 197384 ==> 0.30716834408816823\n",
            "Loss in iteration no. 197385 ==> 0.3071683440723709\n",
            "Loss in iteration no. 197386 ==> 0.30716834405657434\n",
            "Loss in iteration no. 197387 ==> 0.3071683440407783\n",
            "Loss in iteration no. 197388 ==> 0.3071683440249835\n",
            "Loss in iteration no. 197389 ==> 0.30716834400918974\n",
            "Loss in iteration no. 197390 ==> 0.3071683439933962\n",
            "Loss in iteration no. 197391 ==> 0.3071683439776039\n",
            "Loss in iteration no. 197392 ==> 0.30716834396181264\n",
            "Loss in iteration no. 197393 ==> 0.30716834394602155\n",
            "Loss in iteration no. 197394 ==> 0.3071683439302326\n",
            "Loss in iteration no. 197395 ==> 0.3071683439144433\n",
            "Loss in iteration no. 197396 ==> 0.3071683438986557\n",
            "Loss in iteration no. 197397 ==> 0.3071683438828677\n",
            "Loss in iteration no. 197398 ==> 0.30716834386708136\n",
            "Loss in iteration no. 197399 ==> 0.30716834385129665\n",
            "Loss in iteration no. 197400 ==> 0.30716834383551167\n",
            "Loss in iteration no. 197401 ==> 0.3071683438197277\n",
            "Loss in iteration no. 197402 ==> 0.3071683438039449\n",
            "Loss in iteration no. 197403 ==> 0.30716834378816327\n",
            "Loss in iteration no. 197404 ==> 0.3071683437723818\n",
            "Loss in iteration no. 197405 ==> 0.3071683437566014\n",
            "Loss in iteration no. 197406 ==> 0.3071683437408227\n",
            "Loss in iteration no. 197407 ==> 0.30716834372504365\n",
            "Loss in iteration no. 197408 ==> 0.3071683437092662\n",
            "Loss in iteration no. 197409 ==> 0.3071683436934894\n",
            "Loss in iteration no. 197410 ==> 0.3071683436777133\n",
            "Loss in iteration no. 197411 ==> 0.30716834366193874\n",
            "Loss in iteration no. 197412 ==> 0.3071683436461638\n",
            "Loss in iteration no. 197413 ==> 0.3071683436303911\n",
            "Loss in iteration no. 197414 ==> 0.3071683436146184\n",
            "Loss in iteration no. 197415 ==> 0.30716834359884687\n",
            "Loss in iteration no. 197416 ==> 0.30716834358307554\n",
            "Loss in iteration no. 197417 ==> 0.3071683435673063\n",
            "Loss in iteration no. 197418 ==> 0.30716834355153777\n",
            "Loss in iteration no. 197419 ==> 0.3071683435357688\n",
            "Loss in iteration no. 197420 ==> 0.30716834352000194\n",
            "Loss in iteration no. 197421 ==> 0.30716834350423516\n",
            "Loss in iteration no. 197422 ==> 0.30716834348846966\n",
            "Loss in iteration no. 197423 ==> 0.30716834347270516\n",
            "Loss in iteration no. 197424 ==> 0.30716834345694133\n",
            "Loss in iteration no. 197425 ==> 0.3071683434411781\n",
            "Loss in iteration no. 197426 ==> 0.30716834342541605\n",
            "Loss in iteration no. 197427 ==> 0.30716834340965504\n",
            "Loss in iteration no. 197428 ==> 0.3071683433938942\n",
            "Loss in iteration no. 197429 ==> 0.307168343378135\n",
            "Loss in iteration no. 197430 ==> 0.30716834336237586\n",
            "Loss in iteration no. 197431 ==> 0.30716834334661786\n",
            "Loss in iteration no. 197432 ==> 0.3071683433308615\n",
            "Loss in iteration no. 197433 ==> 0.30716834331510473\n",
            "Loss in iteration no. 197434 ==> 0.30716834329934967\n",
            "Loss in iteration no. 197435 ==> 0.30716834328359516\n",
            "Loss in iteration no. 197436 ==> 0.30716834326784276\n",
            "Loss in iteration no. 197437 ==> 0.3071683432520895\n",
            "Loss in iteration no. 197438 ==> 0.30716834323633824\n",
            "Loss in iteration no. 197439 ==> 0.3071683432205872\n",
            "Loss in iteration no. 197440 ==> 0.30716834320483727\n",
            "Loss in iteration no. 197441 ==> 0.3071683431890875\n",
            "Loss in iteration no. 197442 ==> 0.3071683431733397\n",
            "Loss in iteration no. 197443 ==> 0.3071683431575917\n",
            "Loss in iteration no. 197444 ==> 0.3071683431418451\n",
            "Loss in iteration no. 197445 ==> 0.30716834312609925\n",
            "Loss in iteration no. 197446 ==> 0.307168343110355\n",
            "Loss in iteration no. 197447 ==> 0.30716834309461033\n",
            "Loss in iteration no. 197448 ==> 0.30716834307886726\n",
            "Loss in iteration no. 197449 ==> 0.30716834306312524\n",
            "Loss in iteration no. 197450 ==> 0.30716834304738344\n",
            "Loss in iteration no. 197451 ==> 0.3071683430316436\n",
            "Loss in iteration no. 197452 ==> 0.307168343015903\n",
            "Loss in iteration no. 197453 ==> 0.30716834300016455\n",
            "Loss in iteration no. 197454 ==> 0.3071683429844265\n",
            "Loss in iteration no. 197455 ==> 0.30716834296869017\n",
            "Loss in iteration no. 197456 ==> 0.3071683429529535\n",
            "Loss in iteration no. 197457 ==> 0.30716834293721834\n",
            "Loss in iteration no. 197458 ==> 0.30716834292148376\n",
            "Loss in iteration no. 197459 ==> 0.3071683429057498\n",
            "Loss in iteration no. 197460 ==> 0.30716834289001743\n",
            "Loss in iteration no. 197461 ==> 0.3071683428742847\n",
            "Loss in iteration no. 197462 ==> 0.30716834285855404\n",
            "Loss in iteration no. 197463 ==> 0.30716834284282346\n",
            "Loss in iteration no. 197464 ==> 0.3071683428270941\n",
            "Loss in iteration no. 197465 ==> 0.3071683428113662\n",
            "Loss in iteration no. 197466 ==> 0.3071683427956384\n",
            "Loss in iteration no. 197467 ==> 0.30716834277991173\n",
            "Loss in iteration no. 197468 ==> 0.3071683427641856\n",
            "Loss in iteration no. 197469 ==> 0.30716834274846\n",
            "Loss in iteration no. 197470 ==> 0.3071683427327361\n",
            "Loss in iteration no. 197471 ==> 0.3071683427170128\n",
            "Loss in iteration no. 197472 ==> 0.3071683427012905\n",
            "Loss in iteration no. 197473 ==> 0.3071683426855684\n",
            "Loss in iteration no. 197474 ==> 0.3071683426698478\n",
            "Loss in iteration no. 197475 ==> 0.30716834265412835\n",
            "Loss in iteration no. 197476 ==> 0.3071683426384095\n",
            "Loss in iteration no. 197477 ==> 0.30716834262269066\n",
            "Loss in iteration no. 197478 ==> 0.3071683426069739\n",
            "Loss in iteration no. 197479 ==> 0.3071683425912578\n",
            "Loss in iteration no. 197480 ==> 0.30716834257554226\n",
            "Loss in iteration no. 197481 ==> 0.3071683425598272\n",
            "Loss in iteration no. 197482 ==> 0.3071683425441128\n",
            "Loss in iteration no. 197483 ==> 0.3071683425283999\n",
            "Loss in iteration no. 197484 ==> 0.30716834251268776\n",
            "Loss in iteration no. 197485 ==> 0.30716834249697655\n",
            "Loss in iteration no. 197486 ==> 0.3071683424812665\n",
            "Loss in iteration no. 197487 ==> 0.3071683424655564\n",
            "Loss in iteration no. 197488 ==> 0.30716834244984753\n",
            "Loss in iteration no. 197489 ==> 0.30716834243414065\n",
            "Loss in iteration no. 197490 ==> 0.3071683424184333\n",
            "Loss in iteration no. 197491 ==> 0.3071683424027271\n",
            "Loss in iteration no. 197492 ==> 0.30716834238702195\n",
            "Loss in iteration no. 197493 ==> 0.30716834237131746\n",
            "Loss in iteration no. 197494 ==> 0.3071683423556135\n",
            "Loss in iteration no. 197495 ==> 0.30716834233991147\n",
            "Loss in iteration no. 197496 ==> 0.30716834232420964\n",
            "Loss in iteration no. 197497 ==> 0.30716834230850837\n",
            "Loss in iteration no. 197498 ==> 0.30716834229280815\n",
            "Loss in iteration no. 197499 ==> 0.30716834227710893\n",
            "Loss in iteration no. 197500 ==> 0.3071683422614108\n",
            "Loss in iteration no. 197501 ==> 0.3071683422457129\n",
            "Loss in iteration no. 197502 ==> 0.3071683422300158\n",
            "Loss in iteration no. 197503 ==> 0.3071683422143205\n",
            "Loss in iteration no. 197504 ==> 0.3071683421986256\n",
            "Loss in iteration no. 197505 ==> 0.3071683421829314\n",
            "Loss in iteration no. 197506 ==> 0.30716834216723865\n",
            "Loss in iteration no. 197507 ==> 0.3071683421515454\n",
            "Loss in iteration no. 197508 ==> 0.30716834213585387\n",
            "Loss in iteration no. 197509 ==> 0.30716834212016436\n",
            "Loss in iteration no. 197510 ==> 0.3071683421044739\n",
            "Loss in iteration no. 197511 ==> 0.3071683420887854\n",
            "Loss in iteration no. 197512 ==> 0.3071683420730972\n",
            "Loss in iteration no. 197513 ==> 0.3071683420574097\n",
            "Loss in iteration no. 197514 ==> 0.307168342041724\n",
            "Loss in iteration no. 197515 ==> 0.3071683420260372\n",
            "Loss in iteration no. 197516 ==> 0.3071683420103527\n",
            "Loss in iteration no. 197517 ==> 0.3071683419946696\n",
            "Loss in iteration no. 197518 ==> 0.30716834197898607\n",
            "Loss in iteration no. 197519 ==> 0.307168341963304\n",
            "Loss in iteration no. 197520 ==> 0.30716834194762305\n",
            "Loss in iteration no. 197521 ==> 0.3071683419319432\n",
            "Loss in iteration no. 197522 ==> 0.30716834191626285\n",
            "Loss in iteration no. 197523 ==> 0.3071683419005846\n",
            "Loss in iteration no. 197524 ==> 0.30716834188490677\n",
            "Loss in iteration no. 197525 ==> 0.3071683418692302\n",
            "Loss in iteration no. 197526 ==> 0.3071683418535535\n",
            "Loss in iteration no. 197527 ==> 0.3071683418378784\n",
            "Loss in iteration no. 197528 ==> 0.30716834182220487\n",
            "Loss in iteration no. 197529 ==> 0.3071683418065309\n",
            "Loss in iteration no. 197530 ==> 0.30716834179085833\n",
            "Loss in iteration no. 197531 ==> 0.3071683417751864\n",
            "Loss in iteration no. 197532 ==> 0.3071683417595161\n",
            "Loss in iteration no. 197533 ==> 0.3071683417438452\n",
            "Loss in iteration no. 197534 ==> 0.30716834172817636\n",
            "Loss in iteration no. 197535 ==> 0.30716834171250756\n",
            "Loss in iteration no. 197536 ==> 0.30716834169684093\n",
            "Loss in iteration no. 197537 ==> 0.3071683416811737\n",
            "Loss in iteration no. 197538 ==> 0.30716834166550755\n",
            "Loss in iteration no. 197539 ==> 0.30716834164984347\n",
            "Loss in iteration no. 197540 ==> 0.30716834163417883\n",
            "Loss in iteration no. 197541 ==> 0.30716834161851575\n",
            "Loss in iteration no. 197542 ==> 0.3071683416028533\n",
            "Loss in iteration no. 197543 ==> 0.3071683415871923\n",
            "Loss in iteration no. 197544 ==> 0.30716834157153183\n",
            "Loss in iteration no. 197545 ==> 0.30716834155587236\n",
            "Loss in iteration no. 197546 ==> 0.30716834154021305\n",
            "Loss in iteration no. 197547 ==> 0.30716834152455463\n",
            "Loss in iteration no. 197548 ==> 0.30716834150889727\n",
            "Loss in iteration no. 197549 ==> 0.30716834149324107\n",
            "Loss in iteration no. 197550 ==> 0.3071683414775862\n",
            "Loss in iteration no. 197551 ==> 0.30716834146193145\n",
            "Loss in iteration no. 197552 ==> 0.30716834144627775\n",
            "Loss in iteration no. 197553 ==> 0.30716834143062455\n",
            "Loss in iteration no. 197554 ==> 0.3071683414149729\n",
            "Loss in iteration no. 197555 ==> 0.30716834139932064\n",
            "Loss in iteration no. 197556 ==> 0.30716834138367155\n",
            "Loss in iteration no. 197557 ==> 0.30716834136802146\n",
            "Loss in iteration no. 197558 ==> 0.3071683413523729\n",
            "Loss in iteration no. 197559 ==> 0.3071683413367254\n",
            "Loss in iteration no. 197560 ==> 0.30716834132107784\n",
            "Loss in iteration no. 197561 ==> 0.30716834130543225\n",
            "Loss in iteration no. 197562 ==> 0.3071683412897872\n",
            "Loss in iteration no. 197563 ==> 0.3071683412741428\n",
            "Loss in iteration no. 197564 ==> 0.3071683412584993\n",
            "Loss in iteration no. 197565 ==> 0.30716834124285675\n",
            "Loss in iteration no. 197566 ==> 0.3071683412272149\n",
            "Loss in iteration no. 197567 ==> 0.30716834121157394\n",
            "Loss in iteration no. 197568 ==> 0.30716834119593406\n",
            "Loss in iteration no. 197569 ==> 0.30716834118029457\n",
            "Loss in iteration no. 197570 ==> 0.30716834116465574\n",
            "Loss in iteration no. 197571 ==> 0.3071683411490188\n",
            "Loss in iteration no. 197572 ==> 0.30716834113338204\n",
            "Loss in iteration no. 197573 ==> 0.30716834111774605\n",
            "Loss in iteration no. 197574 ==> 0.3071683411021118\n",
            "Loss in iteration no. 197575 ==> 0.30716834108647795\n",
            "Loss in iteration no. 197576 ==> 0.3071683410708446\n",
            "Loss in iteration no. 197577 ==> 0.30716834105521124\n",
            "Loss in iteration no. 197578 ==> 0.30716834103958046\n",
            "Loss in iteration no. 197579 ==> 0.3071683410239496\n",
            "Loss in iteration no. 197580 ==> 0.3071683410083203\n",
            "Loss in iteration no. 197581 ==> 0.3071683409926905\n",
            "Loss in iteration no. 197582 ==> 0.3071683409770627\n",
            "Loss in iteration no. 197583 ==> 0.30716834096143586\n",
            "Loss in iteration no. 197584 ==> 0.3071683409458091\n",
            "Loss in iteration no. 197585 ==> 0.3071683409301833\n",
            "Loss in iteration no. 197586 ==> 0.30716834091455947\n",
            "Loss in iteration no. 197587 ==> 0.3071683408989352\n",
            "Loss in iteration no. 197588 ==> 0.3071683408833123\n",
            "Loss in iteration no. 197589 ==> 0.307168340867691\n",
            "Loss in iteration no. 197590 ==> 0.30716834085206923\n",
            "Loss in iteration no. 197591 ==> 0.3071683408364489\n",
            "Loss in iteration no. 197592 ==> 0.3071683408208291\n",
            "Loss in iteration no. 197593 ==> 0.3071683408052107\n",
            "Loss in iteration no. 197594 ==> 0.3071683407895934\n",
            "Loss in iteration no. 197595 ==> 0.3071683407739761\n",
            "Loss in iteration no. 197596 ==> 0.3071683407583597\n",
            "Loss in iteration no. 197597 ==> 0.30716834074274435\n",
            "Loss in iteration no. 197598 ==> 0.30716834072712995\n",
            "Loss in iteration no. 197599 ==> 0.30716834071151705\n",
            "Loss in iteration no. 197600 ==> 0.3071683406959036\n",
            "Loss in iteration no. 197601 ==> 0.3071683406802923\n",
            "Loss in iteration no. 197602 ==> 0.30716834066468085\n",
            "Loss in iteration no. 197603 ==> 0.30716834064907145\n",
            "Loss in iteration no. 197604 ==> 0.30716834063346193\n",
            "Loss in iteration no. 197605 ==> 0.307168340617853\n",
            "Loss in iteration no. 197606 ==> 0.30716834060224557\n",
            "Loss in iteration no. 197607 ==> 0.30716834058663905\n",
            "Loss in iteration no. 197608 ==> 0.3071683405710324\n",
            "Loss in iteration no. 197609 ==> 0.307168340555428\n",
            "Loss in iteration no. 197610 ==> 0.30716834053982395\n",
            "Loss in iteration no. 197611 ==> 0.3071683405242214\n",
            "Loss in iteration no. 197612 ==> 0.30716834050861774\n",
            "Loss in iteration no. 197613 ==> 0.3071683404930161\n",
            "Loss in iteration no. 197614 ==> 0.307168340477416\n",
            "Loss in iteration no. 197615 ==> 0.30716834046181635\n",
            "Loss in iteration no. 197616 ==> 0.30716834044621766\n",
            "Loss in iteration no. 197617 ==> 0.30716834043061897\n",
            "Loss in iteration no. 197618 ==> 0.3071683404150217\n",
            "Loss in iteration no. 197619 ==> 0.3071683403994255\n",
            "Loss in iteration no. 197620 ==> 0.3071683403838291\n",
            "Loss in iteration no. 197621 ==> 0.30716834036823487\n",
            "Loss in iteration no. 197622 ==> 0.30716834035264096\n",
            "Loss in iteration no. 197623 ==> 0.3071683403370482\n",
            "Loss in iteration no. 197624 ==> 0.30716834032145623\n",
            "Loss in iteration no. 197625 ==> 0.3071683403058648\n",
            "Loss in iteration no. 197626 ==> 0.30716834029027384\n",
            "Loss in iteration no. 197627 ==> 0.30716834027468437\n",
            "Loss in iteration no. 197628 ==> 0.3071683402590954\n",
            "Loss in iteration no. 197629 ==> 0.3071683402435083\n",
            "Loss in iteration no. 197630 ==> 0.3071683402279211\n",
            "Loss in iteration no. 197631 ==> 0.3071683402123346\n",
            "Loss in iteration no. 197632 ==> 0.3071683401967488\n",
            "Loss in iteration no. 197633 ==> 0.3071683401811646\n",
            "Loss in iteration no. 197634 ==> 0.3071683401655805\n",
            "Loss in iteration no. 197635 ==> 0.3071683401499982\n",
            "Loss in iteration no. 197636 ==> 0.3071683401344163\n",
            "Loss in iteration no. 197637 ==> 0.307168340118835\n",
            "Loss in iteration no. 197638 ==> 0.3071683401032551\n",
            "Loss in iteration no. 197639 ==> 0.3071683400876757\n",
            "Loss in iteration no. 197640 ==> 0.3071683400720967\n",
            "Loss in iteration no. 197641 ==> 0.3071683400565191\n",
            "Loss in iteration no. 197642 ==> 0.30716834004094257\n",
            "Loss in iteration no. 197643 ==> 0.3071683400253669\n",
            "Loss in iteration no. 197644 ==> 0.30716834000979126\n",
            "Loss in iteration no. 197645 ==> 0.3071683399942176\n",
            "Loss in iteration no. 197646 ==> 0.30716833997864385\n",
            "Loss in iteration no. 197647 ==> 0.3071683399630715\n",
            "Loss in iteration no. 197648 ==> 0.3071683399474991\n",
            "Loss in iteration no. 197649 ==> 0.3071683399319288\n",
            "Loss in iteration no. 197650 ==> 0.30716833991635883\n",
            "Loss in iteration no. 197651 ==> 0.3071683399007894\n",
            "Loss in iteration no. 197652 ==> 0.3071683398852218\n",
            "Loss in iteration no. 197653 ==> 0.30716833986965425\n",
            "Loss in iteration no. 197654 ==> 0.3071683398540871\n",
            "Loss in iteration no. 197655 ==> 0.3071683398385218\n",
            "Loss in iteration no. 197656 ==> 0.30716833982295655\n",
            "Loss in iteration no. 197657 ==> 0.30716833980739333\n",
            "Loss in iteration no. 197658 ==> 0.30716833979182884\n",
            "Loss in iteration no. 197659 ==> 0.3071683397762674\n",
            "Loss in iteration no. 197660 ==> 0.30716833976070546\n",
            "Loss in iteration no. 197661 ==> 0.3071683397451449\n",
            "Loss in iteration no. 197662 ==> 0.3071683397295858\n",
            "Loss in iteration no. 197663 ==> 0.30716833971402613\n",
            "Loss in iteration no. 197664 ==> 0.30716833969846796\n",
            "Loss in iteration no. 197665 ==> 0.3071683396829111\n",
            "Loss in iteration no. 197666 ==> 0.30716833966735524\n",
            "Loss in iteration no. 197667 ==> 0.30716833965179946\n",
            "Loss in iteration no. 197668 ==> 0.3071683396362438\n",
            "Loss in iteration no. 197669 ==> 0.3071683396206903\n",
            "Loss in iteration no. 197670 ==> 0.3071683396051382\n",
            "Loss in iteration no. 197671 ==> 0.30716833958958506\n",
            "Loss in iteration no. 197672 ==> 0.3071683395740337\n",
            "Loss in iteration no. 197673 ==> 0.30716833955848394\n",
            "Loss in iteration no. 197674 ==> 0.3071683395429346\n",
            "Loss in iteration no. 197675 ==> 0.3071683395273857\n",
            "Loss in iteration no. 197676 ==> 0.30716833951183814\n",
            "Loss in iteration no. 197677 ==> 0.3071683394962915\n",
            "Loss in iteration no. 197678 ==> 0.30716833948074485\n",
            "Loss in iteration no. 197679 ==> 0.30716833946519967\n",
            "Loss in iteration no. 197680 ==> 0.3071683394496554\n",
            "Loss in iteration no. 197681 ==> 0.307168339434111\n",
            "Loss in iteration no. 197682 ==> 0.30716833941856847\n",
            "Loss in iteration no. 197683 ==> 0.3071683394030265\n",
            "Loss in iteration no. 197684 ==> 0.30716833938748533\n",
            "Loss in iteration no. 197685 ==> 0.3071683393719452\n",
            "Loss in iteration no. 197686 ==> 0.3071683393564064\n",
            "Loss in iteration no. 197687 ==> 0.30716833934086707\n",
            "Loss in iteration no. 197688 ==> 0.3071683393253306\n",
            "Loss in iteration no. 197689 ==> 0.30716833930979315\n",
            "Loss in iteration no. 197690 ==> 0.307168339294257\n",
            "Loss in iteration no. 197691 ==> 0.30716833927872234\n",
            "Loss in iteration no. 197692 ==> 0.30716833926318765\n",
            "Loss in iteration no. 197693 ==> 0.30716833924765385\n",
            "Loss in iteration no. 197694 ==> 0.30716833923212195\n",
            "Loss in iteration no. 197695 ==> 0.3071683392165904\n",
            "Loss in iteration no. 197696 ==> 0.30716833920105935\n",
            "Loss in iteration no. 197697 ==> 0.30716833918552966\n",
            "Loss in iteration no. 197698 ==> 0.3071683391699999\n",
            "Loss in iteration no. 197699 ==> 0.30716833915447256\n",
            "Loss in iteration no. 197700 ==> 0.30716833913894515\n",
            "Loss in iteration no. 197701 ==> 0.3071683391234182\n",
            "Loss in iteration no. 197702 ==> 0.30716833910789254\n",
            "Loss in iteration no. 197703 ==> 0.3071683390923678\n",
            "Loss in iteration no. 197704 ==> 0.30716833907684293\n",
            "Loss in iteration no. 197705 ==> 0.30716833906132013\n",
            "Loss in iteration no. 197706 ==> 0.30716833904579816\n",
            "Loss in iteration no. 197707 ==> 0.307168339030276\n",
            "Loss in iteration no. 197708 ==> 0.3071683390147565\n",
            "Loss in iteration no. 197709 ==> 0.3071683389992361\n",
            "Loss in iteration no. 197710 ==> 0.30716833898371676\n",
            "Loss in iteration no. 197711 ==> 0.30716833896819884\n",
            "Loss in iteration no. 197712 ==> 0.30716833895268175\n",
            "Loss in iteration no. 197713 ==> 0.3071683389371651\n",
            "Loss in iteration no. 197714 ==> 0.30716833892164985\n",
            "Loss in iteration no. 197715 ==> 0.307168338906135\n",
            "Loss in iteration no. 197716 ==> 0.30716833889062106\n",
            "Loss in iteration no. 197717 ==> 0.3071683388751079\n",
            "Loss in iteration no. 197718 ==> 0.3071683388595958\n",
            "Loss in iteration no. 197719 ==> 0.30716833884408506\n",
            "Loss in iteration no. 197720 ==> 0.30716833882857475\n",
            "Loss in iteration no. 197721 ==> 0.30716833881306416\n",
            "Loss in iteration no. 197722 ==> 0.3071683387975556\n",
            "Loss in iteration no. 197723 ==> 0.30716833878204747\n",
            "Loss in iteration no. 197724 ==> 0.3071683387665407\n",
            "Loss in iteration no. 197725 ==> 0.30716833875103483\n",
            "Loss in iteration no. 197726 ==> 0.3071683387355298\n",
            "Loss in iteration no. 197727 ==> 0.30716833872002525\n",
            "Loss in iteration no. 197728 ==> 0.3071683387045215\n",
            "Loss in iteration no. 197729 ==> 0.30716833868901866\n",
            "Loss in iteration no. 197730 ==> 0.30716833867351667\n",
            "Loss in iteration no. 197731 ==> 0.30716833865801607\n",
            "Loss in iteration no. 197732 ==> 0.3071683386425154\n",
            "Loss in iteration no. 197733 ==> 0.30716833862701565\n",
            "Loss in iteration no. 197734 ==> 0.3071683386115172\n",
            "Loss in iteration no. 197735 ==> 0.30716833859601916\n",
            "Loss in iteration no. 197736 ==> 0.30716833858052256\n",
            "Loss in iteration no. 197737 ==> 0.3071683385650263\n",
            "Loss in iteration no. 197738 ==> 0.307168338549532\n",
            "Loss in iteration no. 197739 ==> 0.3071683385340374\n",
            "Loss in iteration no. 197740 ==> 0.30716833851854336\n",
            "Loss in iteration no. 197741 ==> 0.3071683385030512\n",
            "Loss in iteration no. 197742 ==> 0.30716833848755926\n",
            "Loss in iteration no. 197743 ==> 0.30716833847206826\n",
            "Loss in iteration no. 197744 ==> 0.3071683384565782\n",
            "Loss in iteration no. 197745 ==> 0.3071683384410895\n",
            "Loss in iteration no. 197746 ==> 0.3071683384256011\n",
            "Loss in iteration no. 197747 ==> 0.3071683384101132\n",
            "Loss in iteration no. 197748 ==> 0.3071683383946266\n",
            "Loss in iteration no. 197749 ==> 0.3071683383791404\n",
            "Loss in iteration no. 197750 ==> 0.3071683383636554\n",
            "Loss in iteration no. 197751 ==> 0.3071683383481716\n",
            "Loss in iteration no. 197752 ==> 0.3071683383326884\n",
            "Loss in iteration no. 197753 ==> 0.3071683383172057\n",
            "Loss in iteration no. 197754 ==> 0.3071683383017239\n",
            "Loss in iteration no. 197755 ==> 0.3071683382862434\n",
            "Loss in iteration no. 197756 ==> 0.3071683382707638\n",
            "Loss in iteration no. 197757 ==> 0.30716833825528395\n",
            "Loss in iteration no. 197758 ==> 0.30716833823980666\n",
            "Loss in iteration no. 197759 ==> 0.3071683382243286\n",
            "Loss in iteration no. 197760 ==> 0.30716833820885187\n",
            "Loss in iteration no. 197761 ==> 0.30716833819337663\n",
            "Loss in iteration no. 197762 ==> 0.3071683381779022\n",
            "Loss in iteration no. 197763 ==> 0.3071683381624276\n",
            "Loss in iteration no. 197764 ==> 0.3071683381469544\n",
            "Loss in iteration no. 197765 ==> 0.3071683381314831\n",
            "Loss in iteration no. 197766 ==> 0.30716833811601063\n",
            "Loss in iteration no. 197767 ==> 0.307168338100541\n",
            "Loss in iteration no. 197768 ==> 0.30716833808507077\n",
            "Loss in iteration no. 197769 ==> 0.30716833806960187\n",
            "Loss in iteration no. 197770 ==> 0.30716833805413435\n",
            "Loss in iteration no. 197771 ==> 0.3071683380386671\n",
            "Loss in iteration no. 197772 ==> 0.30716833802320026\n",
            "Loss in iteration no. 197773 ==> 0.30716833800773474\n",
            "Loss in iteration no. 197774 ==> 0.3071683379922706\n",
            "Loss in iteration no. 197775 ==> 0.30716833797680587\n",
            "Loss in iteration no. 197776 ==> 0.3071683379613439\n",
            "Loss in iteration no. 197777 ==> 0.3071683379458809\n",
            "Loss in iteration no. 197778 ==> 0.30716833793042064\n",
            "Loss in iteration no. 197779 ==> 0.30716833791495934\n",
            "Loss in iteration no. 197780 ==> 0.30716833789949977\n",
            "Loss in iteration no. 197781 ==> 0.3071683378840416\n",
            "Loss in iteration no. 197782 ==> 0.3071683378685838\n",
            "Loss in iteration no. 197783 ==> 0.30716833785312636\n",
            "Loss in iteration no. 197784 ==> 0.30716833783767017\n",
            "Loss in iteration no. 197785 ==> 0.3071683378222155\n",
            "Loss in iteration no. 197786 ==> 0.30716833780675995\n",
            "Loss in iteration no. 197787 ==> 0.3071683377913069\n",
            "Loss in iteration no. 197788 ==> 0.3071683377758537\n",
            "Loss in iteration no. 197789 ==> 0.3071683377604022\n",
            "Loss in iteration no. 197790 ==> 0.30716833774495067\n",
            "Loss in iteration no. 197791 ==> 0.3071683377294999\n",
            "Loss in iteration no. 197792 ==> 0.3071683377140511\n",
            "Loss in iteration no. 197793 ==> 0.3071683376986025\n",
            "Loss in iteration no. 197794 ==> 0.3071683376831554\n",
            "Loss in iteration no. 197795 ==> 0.30716833766770846\n",
            "Loss in iteration no. 197796 ==> 0.3071683376522619\n",
            "Loss in iteration no. 197797 ==> 0.30716833763681684\n",
            "Loss in iteration no. 197798 ==> 0.30716833762137186\n",
            "Loss in iteration no. 197799 ==> 0.3071683376059284\n",
            "Loss in iteration no. 197800 ==> 0.30716833759048673\n",
            "Loss in iteration no. 197801 ==> 0.3071683375750439\n",
            "Loss in iteration no. 197802 ==> 0.3071683375596038\n",
            "Loss in iteration no. 197803 ==> 0.30716833754416273\n",
            "Loss in iteration no. 197804 ==> 0.30716833752872436\n",
            "Loss in iteration no. 197805 ==> 0.3071683375132853\n",
            "Loss in iteration no. 197806 ==> 0.3071683374978486\n",
            "Loss in iteration no. 197807 ==> 0.3071683374824113\n",
            "Loss in iteration no. 197808 ==> 0.3071683374669752\n",
            "Loss in iteration no. 197809 ==> 0.30716833745154043\n",
            "Loss in iteration no. 197810 ==> 0.3071683374361061\n",
            "Loss in iteration no. 197811 ==> 0.30716833742067307\n",
            "Loss in iteration no. 197812 ==> 0.3071683374052408\n",
            "Loss in iteration no. 197813 ==> 0.3071683373898084\n",
            "Loss in iteration no. 197814 ==> 0.3071683373743774\n",
            "Loss in iteration no. 197815 ==> 0.30716833735894805\n",
            "Loss in iteration no. 197816 ==> 0.30716833734351917\n",
            "Loss in iteration no. 197817 ==> 0.3071683373280905\n",
            "Loss in iteration no. 197818 ==> 0.3071683373126627\n",
            "Loss in iteration no. 197819 ==> 0.3071683372972358\n",
            "Loss in iteration no. 197820 ==> 0.3071683372818101\n",
            "Loss in iteration no. 197821 ==> 0.3071683372663857\n",
            "Loss in iteration no. 197822 ==> 0.3071683372509612\n",
            "Loss in iteration no. 197823 ==> 0.30716833723553855\n",
            "Loss in iteration no. 197824 ==> 0.3071683372201161\n",
            "Loss in iteration no. 197825 ==> 0.3071683372046946\n",
            "Loss in iteration no. 197826 ==> 0.30716833718927383\n",
            "Loss in iteration no. 197827 ==> 0.30716833717385383\n",
            "Loss in iteration no. 197828 ==> 0.3071683371584348\n",
            "Loss in iteration no. 197829 ==> 0.3071683371430164\n",
            "Loss in iteration no. 197830 ==> 0.30716833712759944\n",
            "Loss in iteration no. 197831 ==> 0.3071683371121828\n",
            "Loss in iteration no. 197832 ==> 0.30716833709676733\n",
            "Loss in iteration no. 197833 ==> 0.3071683370813522\n",
            "Loss in iteration no. 197834 ==> 0.30716833706593855\n",
            "Loss in iteration no. 197835 ==> 0.30716833705052504\n",
            "Loss in iteration no. 197836 ==> 0.3071683370351133\n",
            "Loss in iteration no. 197837 ==> 0.3071683370197015\n",
            "Loss in iteration no. 197838 ==> 0.3071683370042916\n",
            "Loss in iteration no. 197839 ==> 0.3071683369888813\n",
            "Loss in iteration no. 197840 ==> 0.30716833697347284\n",
            "Loss in iteration no. 197841 ==> 0.30716833695806467\n",
            "Loss in iteration no. 197842 ==> 0.3071683369426574\n",
            "Loss in iteration no. 197843 ==> 0.3071683369272509\n",
            "Loss in iteration no. 197844 ==> 0.3071683369118456\n",
            "Loss in iteration no. 197845 ==> 0.3071683368964406\n",
            "Loss in iteration no. 197846 ==> 0.307168336881037\n",
            "Loss in iteration no. 197847 ==> 0.3071683368656343\n",
            "Loss in iteration no. 197848 ==> 0.30716833685023215\n",
            "Loss in iteration no. 197849 ==> 0.30716833683483047\n",
            "Loss in iteration no. 197850 ==> 0.30716833681943045\n",
            "Loss in iteration no. 197851 ==> 0.30716833680403033\n",
            "Loss in iteration no. 197852 ==> 0.307168336788632\n",
            "Loss in iteration no. 197853 ==> 0.3071683367732339\n",
            "Loss in iteration no. 197854 ==> 0.30716833675783717\n",
            "Loss in iteration no. 197855 ==> 0.3071683367424402\n",
            "Loss in iteration no. 197856 ==> 0.3071683367270449\n",
            "Loss in iteration no. 197857 ==> 0.30716833671165006\n",
            "Loss in iteration no. 197858 ==> 0.307168336696257\n",
            "Loss in iteration no. 197859 ==> 0.30716833668086474\n",
            "Loss in iteration no. 197860 ==> 0.3071683366654716\n",
            "Loss in iteration no. 197861 ==> 0.3071683366500814\n",
            "Loss in iteration no. 197862 ==> 0.307168336634691\n",
            "Loss in iteration no. 197863 ==> 0.3071683366193013\n",
            "Loss in iteration no. 197864 ==> 0.30716833660391235\n",
            "Loss in iteration no. 197865 ==> 0.3071683365885243\n",
            "Loss in iteration no. 197866 ==> 0.3071683365731375\n",
            "Loss in iteration no. 197867 ==> 0.307168336557752\n",
            "Loss in iteration no. 197868 ==> 0.30716833654236625\n",
            "Loss in iteration no. 197869 ==> 0.3071683365269813\n",
            "Loss in iteration no. 197870 ==> 0.30716833651159803\n",
            "Loss in iteration no. 197871 ==> 0.3071683364962157\n",
            "Loss in iteration no. 197872 ==> 0.3071683364808335\n",
            "Loss in iteration no. 197873 ==> 0.30716833646545266\n",
            "Loss in iteration no. 197874 ==> 0.3071683364500726\n",
            "Loss in iteration no. 197875 ==> 0.3071683364346923\n",
            "Loss in iteration no. 197876 ==> 0.3071683364193148\n",
            "Loss in iteration no. 197877 ==> 0.3071683364039366\n",
            "Loss in iteration no. 197878 ==> 0.30716833638856056\n",
            "Loss in iteration no. 197879 ==> 0.3071683363731834\n",
            "Loss in iteration no. 197880 ==> 0.307168336357809\n",
            "Loss in iteration no. 197881 ==> 0.3071683363424338\n",
            "Loss in iteration no. 197882 ==> 0.3071683363270609\n",
            "Loss in iteration no. 197883 ==> 0.3071683363116888\n",
            "Loss in iteration no. 197884 ==> 0.3071683362963165\n",
            "Loss in iteration no. 197885 ==> 0.3071683362809454\n",
            "Loss in iteration no. 197886 ==> 0.3071683362655751\n",
            "Loss in iteration no. 197887 ==> 0.3071683362502056\n",
            "Loss in iteration no. 197888 ==> 0.30716833623483786\n",
            "Loss in iteration no. 197889 ==> 0.3071683362194698\n",
            "Loss in iteration no. 197890 ==> 0.30716833620410355\n",
            "Loss in iteration no. 197891 ==> 0.3071683361887377\n",
            "Loss in iteration no. 197892 ==> 0.307168336173372\n",
            "Loss in iteration no. 197893 ==> 0.3071683361580085\n",
            "Loss in iteration no. 197894 ==> 0.3071683361426444\n",
            "Loss in iteration no. 197895 ==> 0.30716833612728245\n",
            "Loss in iteration no. 197896 ==> 0.3071683361119198\n",
            "Loss in iteration no. 197897 ==> 0.30716833609655986\n",
            "Loss in iteration no. 197898 ==> 0.3071683360811997\n",
            "Loss in iteration no. 197899 ==> 0.3071683360658403\n",
            "Loss in iteration no. 197900 ==> 0.30716833605048177\n",
            "Loss in iteration no. 197901 ==> 0.3071683360351249\n",
            "Loss in iteration no. 197902 ==> 0.3071683360197683\n",
            "Loss in iteration no. 197903 ==> 0.3071683360044119\n",
            "Loss in iteration no. 197904 ==> 0.30716833598905724\n",
            "Loss in iteration no. 197905 ==> 0.3071683359737024\n",
            "Loss in iteration no. 197906 ==> 0.30716833595835036\n",
            "Loss in iteration no. 197907 ==> 0.30716833594299703\n",
            "Loss in iteration no. 197908 ==> 0.3071683359276459\n",
            "Loss in iteration no. 197909 ==> 0.3071683359122951\n",
            "Loss in iteration no. 197910 ==> 0.307168335896945\n",
            "Loss in iteration no. 197911 ==> 0.3071683358815956\n",
            "Loss in iteration no. 197912 ==> 0.3071683358662481\n",
            "Loss in iteration no. 197913 ==> 0.30716833585090014\n",
            "Loss in iteration no. 197914 ==> 0.3071683358355531\n",
            "Loss in iteration no. 197915 ==> 0.30716833582020825\n",
            "Loss in iteration no. 197916 ==> 0.3071683358048627\n",
            "Loss in iteration no. 197917 ==> 0.30716833578951924\n",
            "Loss in iteration no. 197918 ==> 0.3071683357741752\n",
            "Loss in iteration no. 197919 ==> 0.30716833575883334\n",
            "Loss in iteration no. 197920 ==> 0.3071683357434917\n",
            "Loss in iteration no. 197921 ==> 0.30716833572815033\n",
            "Loss in iteration no. 197922 ==> 0.30716833571281166\n",
            "Loss in iteration no. 197923 ==> 0.3071683356974717\n",
            "Loss in iteration no. 197924 ==> 0.3071683356821336\n",
            "Loss in iteration no. 197925 ==> 0.30716833566679613\n",
            "Loss in iteration no. 197926 ==> 0.30716833565146046\n",
            "Loss in iteration no. 197927 ==> 0.30716833563612395\n",
            "Loss in iteration no. 197928 ==> 0.3071683356207898\n",
            "Loss in iteration no. 197929 ==> 0.30716833560545576\n",
            "Loss in iteration no. 197930 ==> 0.30716833559012197\n",
            "Loss in iteration no. 197931 ==> 0.30716833557479056\n",
            "Loss in iteration no. 197932 ==> 0.30716833555945827\n",
            "Loss in iteration no. 197933 ==> 0.3071683355441281\n",
            "Loss in iteration no. 197934 ==> 0.30716833552879785\n",
            "Loss in iteration no. 197935 ==> 0.3071683355134692\n",
            "Loss in iteration no. 197936 ==> 0.30716833549814143\n",
            "Loss in iteration no. 197937 ==> 0.3071683354828133\n",
            "Loss in iteration no. 197938 ==> 0.30716833546748795\n",
            "Loss in iteration no. 197939 ==> 0.3071683354521617\n",
            "Loss in iteration no. 197940 ==> 0.30716833543683775\n",
            "Loss in iteration no. 197941 ==> 0.30716833542151306\n",
            "Loss in iteration no. 197942 ==> 0.30716833540619054\n",
            "Loss in iteration no. 197943 ==> 0.3071683353908683\n",
            "Loss in iteration no. 197944 ==> 0.3071683353755462\n",
            "Loss in iteration no. 197945 ==> 0.3071683353602254\n",
            "Loss in iteration no. 197946 ==> 0.3071683353449063\n",
            "Loss in iteration no. 197947 ==> 0.307168335329587\n",
            "Loss in iteration no. 197948 ==> 0.3071683353142693\n",
            "Loss in iteration no. 197949 ==> 0.3071683352989523\n",
            "Loss in iteration no. 197950 ==> 0.30716833528363613\n",
            "Loss in iteration no. 197951 ==> 0.3071683352683201\n",
            "Loss in iteration no. 197952 ==> 0.3071683352530059\n",
            "Loss in iteration no. 197953 ==> 0.3071683352376912\n",
            "Loss in iteration no. 197954 ==> 0.30716833522237896\n",
            "Loss in iteration no. 197955 ==> 0.3071683352070668\n",
            "Loss in iteration no. 197956 ==> 0.30716833519175535\n",
            "Loss in iteration no. 197957 ==> 0.30716833517644465\n",
            "Loss in iteration no. 197958 ==> 0.3071683351611352\n",
            "Loss in iteration no. 197959 ==> 0.30716833514582637\n",
            "Loss in iteration no. 197960 ==> 0.30716833513051833\n",
            "Loss in iteration no. 197961 ==> 0.3071683351152109\n",
            "Loss in iteration no. 197962 ==> 0.30716833509990427\n",
            "Loss in iteration no. 197963 ==> 0.3071683350845994\n",
            "Loss in iteration no. 197964 ==> 0.30716833506929464\n",
            "Loss in iteration no. 197965 ==> 0.3071683350539911\n",
            "Loss in iteration no. 197966 ==> 0.3071683350386878\n",
            "Loss in iteration no. 197967 ==> 0.30716833502338564\n",
            "Loss in iteration no. 197968 ==> 0.30716833500808477\n",
            "Loss in iteration no. 197969 ==> 0.3071683349927841\n",
            "Loss in iteration no. 197970 ==> 0.30716833497748514\n",
            "Loss in iteration no. 197971 ==> 0.3071683349621858\n",
            "Loss in iteration no. 197972 ==> 0.3071683349468877\n",
            "Loss in iteration no. 197973 ==> 0.3071683349315914\n",
            "Loss in iteration no. 197974 ==> 0.30716833491629525\n",
            "Loss in iteration no. 197975 ==> 0.30716833490099865\n",
            "Loss in iteration no. 197976 ==> 0.3071683348857049\n",
            "Loss in iteration no. 197977 ==> 0.3071683348704113\n",
            "Loss in iteration no. 197978 ==> 0.3071683348551179\n",
            "Loss in iteration no. 197979 ==> 0.30716833483982564\n",
            "Loss in iteration no. 197980 ==> 0.30716833482453465\n",
            "Loss in iteration no. 197981 ==> 0.3071683348092439\n",
            "Loss in iteration no. 197982 ==> 0.3071683347939548\n",
            "Loss in iteration no. 197983 ==> 0.3071683347786664\n",
            "Loss in iteration no. 197984 ==> 0.3071683347633787\n",
            "Loss in iteration no. 197985 ==> 0.30716833474809063\n",
            "Loss in iteration no. 197986 ==> 0.3071683347328053\n",
            "Loss in iteration no. 197987 ==> 0.30716833471751964\n",
            "Loss in iteration no. 197988 ==> 0.30716833470223476\n",
            "Loss in iteration no. 197989 ==> 0.30716833468695093\n",
            "Loss in iteration no. 197990 ==> 0.3071683346716684\n",
            "Loss in iteration no. 197991 ==> 0.30716833465638593\n",
            "Loss in iteration no. 197992 ==> 0.30716833464110477\n",
            "Loss in iteration no. 197993 ==> 0.3071683346258249\n",
            "Loss in iteration no. 197994 ==> 0.30716833461054555\n",
            "Loss in iteration no. 197995 ==> 0.3071683345952669\n",
            "Loss in iteration no. 197996 ==> 0.30716833457998893\n",
            "Loss in iteration no. 197997 ==> 0.30716833456471154\n",
            "Loss in iteration no. 197998 ==> 0.307168334549436\n",
            "Loss in iteration no. 197999 ==> 0.3071683345341601\n",
            "Loss in iteration no. 198000 ==> 0.3071683345188859\n",
            "Loss in iteration no. 198001 ==> 0.3071683345036118\n",
            "Loss in iteration no. 198002 ==> 0.30716833448833997\n",
            "Loss in iteration no. 198003 ==> 0.30716833447306724\n",
            "Loss in iteration no. 198004 ==> 0.30716833445779673\n",
            "Loss in iteration no. 198005 ==> 0.3071683344425254\n",
            "Loss in iteration no. 198006 ==> 0.3071683344272562\n",
            "Loss in iteration no. 198007 ==> 0.3071683344119877\n",
            "Loss in iteration no. 198008 ==> 0.30716833439672\n",
            "Loss in iteration no. 198009 ==> 0.3071683343814528\n",
            "Loss in iteration no. 198010 ==> 0.3071683343661863\n",
            "Loss in iteration no. 198011 ==> 0.3071683343509215\n",
            "Loss in iteration no. 198012 ==> 0.307168334335657\n",
            "Loss in iteration no. 198013 ==> 0.3071683343203935\n",
            "Loss in iteration no. 198014 ==> 0.30716833430513074\n",
            "Loss in iteration no. 198015 ==> 0.30716833428986856\n",
            "Loss in iteration no. 198016 ==> 0.3071683342746081\n",
            "Loss in iteration no. 198017 ==> 0.3071683342593474\n",
            "Loss in iteration no. 198018 ==> 0.3071683342440878\n",
            "Loss in iteration no. 198019 ==> 0.3071683342288294\n",
            "Loss in iteration no. 198020 ==> 0.3071683342135716\n",
            "Loss in iteration no. 198021 ==> 0.3071683341983145\n",
            "Loss in iteration no. 198022 ==> 0.30716833418305906\n",
            "Loss in iteration no. 198023 ==> 0.3071683341678033\n",
            "Loss in iteration no. 198024 ==> 0.3071683341525492\n",
            "Loss in iteration no. 198025 ==> 0.3071683341372953\n",
            "Loss in iteration no. 198026 ==> 0.3071683341220424\n",
            "Loss in iteration no. 198027 ==> 0.3071683341067908\n",
            "Loss in iteration no. 198028 ==> 0.3071683340915393\n",
            "Loss in iteration no. 198029 ==> 0.307168334076289\n",
            "Loss in iteration no. 198030 ==> 0.30716833406103994\n",
            "Loss in iteration no. 198031 ==> 0.3071683340457914\n",
            "Loss in iteration no. 198032 ==> 0.3071683340305436\n",
            "Loss in iteration no. 198033 ==> 0.30716833401529586\n",
            "Loss in iteration no. 198034 ==> 0.30716833400005084\n",
            "Loss in iteration no. 198035 ==> 0.30716833398480503\n",
            "Loss in iteration no. 198036 ==> 0.3071683339695608\n",
            "Loss in iteration no. 198037 ==> 0.30716833395431714\n",
            "Loss in iteration no. 198038 ==> 0.3071683339390748\n",
            "Loss in iteration no. 198039 ==> 0.3071683339238325\n",
            "Loss in iteration no. 198040 ==> 0.3071683339085914\n",
            "Loss in iteration no. 198041 ==> 0.30716833389335146\n",
            "Loss in iteration no. 198042 ==> 0.3071683338781116\n",
            "Loss in iteration no. 198043 ==> 0.3071683338628734\n",
            "Loss in iteration no. 198044 ==> 0.3071683338476359\n",
            "Loss in iteration no. 198045 ==> 0.3071683338323985\n",
            "Loss in iteration no. 198046 ==> 0.30716833381716285\n",
            "Loss in iteration no. 198047 ==> 0.3071683338019267\n",
            "Loss in iteration no. 198048 ==> 0.3071683337866923\n",
            "Loss in iteration no. 198049 ==> 0.307168333771459\n",
            "Loss in iteration no. 198050 ==> 0.3071683337562269\n",
            "Loss in iteration no. 198051 ==> 0.30716833374099484\n",
            "Loss in iteration no. 198052 ==> 0.3071683337257641\n",
            "Loss in iteration no. 198053 ==> 0.3071683337105333\n",
            "Loss in iteration no. 198054 ==> 0.30716833369530366\n",
            "Loss in iteration no. 198055 ==> 0.30716833368007523\n",
            "Loss in iteration no. 198056 ==> 0.30716833366484736\n",
            "Loss in iteration no. 198057 ==> 0.30716833364962026\n",
            "Loss in iteration no. 198058 ==> 0.3071683336343947\n",
            "Loss in iteration no. 198059 ==> 0.30716833361916884\n",
            "Loss in iteration no. 198060 ==> 0.3071683336039445\n",
            "Loss in iteration no. 198061 ==> 0.3071683335887214\n",
            "Loss in iteration no. 198062 ==> 0.30716833357349793\n",
            "Loss in iteration no. 198063 ==> 0.3071683335582761\n",
            "Loss in iteration no. 198064 ==> 0.3071683335430553\n",
            "Loss in iteration no. 198065 ==> 0.3071683335278347\n",
            "Loss in iteration no. 198066 ==> 0.30716833351261574\n",
            "Loss in iteration no. 198067 ==> 0.3071683334973974\n",
            "Loss in iteration no. 198068 ==> 0.3071683334821792\n",
            "Loss in iteration no. 198069 ==> 0.3071683334669626\n",
            "Loss in iteration no. 198070 ==> 0.3071683334517466\n",
            "Loss in iteration no. 198071 ==> 0.3071683334365313\n",
            "Loss in iteration no. 198072 ==> 0.3071683334213166\n",
            "Loss in iteration no. 198073 ==> 0.30716833340610356\n",
            "Loss in iteration no. 198074 ==> 0.3071683333908906\n",
            "Loss in iteration no. 198075 ==> 0.3071683333756788\n",
            "Loss in iteration no. 198076 ==> 0.3071683333604681\n",
            "Loss in iteration no. 198077 ==> 0.30716833334525745\n",
            "Loss in iteration no. 198078 ==> 0.3071683333300481\n",
            "Loss in iteration no. 198079 ==> 0.3071683333148397\n",
            "Loss in iteration no. 198080 ==> 0.3071683332996315\n",
            "Loss in iteration no. 198081 ==> 0.30716833328442494\n",
            "Loss in iteration no. 198082 ==> 0.30716833326921894\n",
            "Loss in iteration no. 198083 ==> 0.30716833325401355\n",
            "Loss in iteration no. 198084 ==> 0.3071683332388088\n",
            "Loss in iteration no. 198085 ==> 0.3071683332236057\n",
            "Loss in iteration no. 198086 ==> 0.3071683332084027\n",
            "Loss in iteration no. 198087 ==> 0.3071683331932008\n",
            "Loss in iteration no. 198088 ==> 0.307168333178\n",
            "Loss in iteration no. 198089 ==> 0.30716833316279935\n",
            "Loss in iteration no. 198090 ==> 0.3071683331475998\n",
            "Loss in iteration no. 198091 ==> 0.30716833313240127\n",
            "Loss in iteration no. 198092 ==> 0.307168333117204\n",
            "Loss in iteration no. 198093 ==> 0.3071683331020072\n",
            "Loss in iteration no. 198094 ==> 0.30716833308681113\n",
            "Loss in iteration no. 198095 ==> 0.3071683330716156\n",
            "Loss in iteration no. 198096 ==> 0.3071683330564207\n",
            "Loss in iteration no. 198097 ==> 0.3071683330412274\n",
            "Loss in iteration no. 198098 ==> 0.30716833302603525\n",
            "Loss in iteration no. 198099 ==> 0.3071683330108431\n",
            "Loss in iteration no. 198100 ==> 0.3071683329956522\n",
            "Loss in iteration no. 198101 ==> 0.3071683329804613\n",
            "Loss in iteration no. 198102 ==> 0.3071683329652725\n",
            "Loss in iteration no. 198103 ==> 0.3071683329500839\n",
            "Loss in iteration no. 198104 ==> 0.30716833293489537\n",
            "Loss in iteration no. 198105 ==> 0.3071683329197093\n",
            "Loss in iteration no. 198106 ==> 0.30716833290452294\n",
            "Loss in iteration no. 198107 ==> 0.3071683328893367\n",
            "Loss in iteration no. 198108 ==> 0.30716833287415307\n",
            "Loss in iteration no. 198109 ==> 0.30716833285896944\n",
            "Loss in iteration no. 198110 ==> 0.307168332843787\n",
            "Loss in iteration no. 198111 ==> 0.3071683328286042\n",
            "Loss in iteration no. 198112 ==> 0.30716833281342387\n",
            "Loss in iteration no. 198113 ==> 0.3071683327982427\n",
            "Loss in iteration no. 198114 ==> 0.30716833278306355\n",
            "Loss in iteration no. 198115 ==> 0.3071683327678846\n",
            "Loss in iteration no. 198116 ==> 0.30716833275270716\n",
            "Loss in iteration no. 198117 ==> 0.3071683327375303\n",
            "Loss in iteration no. 198118 ==> 0.3071683327223536\n",
            "Loss in iteration no. 198119 ==> 0.3071683327071785\n",
            "Loss in iteration no. 198120 ==> 0.3071683326920044\n",
            "Loss in iteration no. 198121 ==> 0.3071683326768309\n",
            "Loss in iteration no. 198122 ==> 0.30716833266165816\n",
            "Loss in iteration no. 198123 ==> 0.30716833264648635\n",
            "Loss in iteration no. 198124 ==> 0.30716833263131466\n",
            "Loss in iteration no. 198125 ==> 0.3071683326161451\n",
            "Loss in iteration no. 198126 ==> 0.30716833260097554\n",
            "Loss in iteration no. 198127 ==> 0.3071683325858061\n",
            "Loss in iteration no. 198128 ==> 0.30716833257063875\n",
            "Loss in iteration no. 198129 ==> 0.3071683325554715\n",
            "Loss in iteration no. 198130 ==> 0.3071683325403058\n",
            "Loss in iteration no. 198131 ==> 0.3071683325251397\n",
            "Loss in iteration no. 198132 ==> 0.30716833250997616\n",
            "Loss in iteration no. 198133 ==> 0.3071683324948122\n",
            "Loss in iteration no. 198134 ==> 0.30716833247964886\n",
            "Loss in iteration no. 198135 ==> 0.3071683324644875\n",
            "Loss in iteration no. 198136 ==> 0.3071683324493263\n",
            "Loss in iteration no. 198137 ==> 0.30716833243416514\n",
            "Loss in iteration no. 198138 ==> 0.30716833241900615\n",
            "Loss in iteration no. 198139 ==> 0.30716833240384706\n",
            "Loss in iteration no. 198140 ==> 0.3071683323886893\n",
            "Loss in iteration no. 198141 ==> 0.30716833237353236\n",
            "Loss in iteration no. 198142 ==> 0.3071683323583761\n",
            "Loss in iteration no. 198143 ==> 0.30716833234322044\n",
            "Loss in iteration no. 198144 ==> 0.3071683323280663\n",
            "Loss in iteration no. 198145 ==> 0.30716833231291274\n",
            "Loss in iteration no. 198146 ==> 0.30716833229775975\n",
            "Loss in iteration no. 198147 ==> 0.3071683322826078\n",
            "Loss in iteration no. 198148 ==> 0.30716833226745655\n",
            "Loss in iteration no. 198149 ==> 0.30716833225230566\n",
            "Loss in iteration no. 198150 ==> 0.307168332237156\n",
            "Loss in iteration no. 198151 ==> 0.3071683322220073\n",
            "Loss in iteration no. 198152 ==> 0.30716833220686024\n",
            "Loss in iteration no. 198153 ==> 0.30716833219171275\n",
            "Loss in iteration no. 198154 ==> 0.30716833217656625\n",
            "Loss in iteration no. 198155 ==> 0.3071683321614214\n",
            "Loss in iteration no. 198156 ==> 0.3071683321462761\n",
            "Loss in iteration no. 198157 ==> 0.3071683321311323\n",
            "Loss in iteration no. 198158 ==> 0.30716833211598904\n",
            "Loss in iteration no. 198159 ==> 0.30716833210084743\n",
            "Loss in iteration no. 198160 ==> 0.3071683320857059\n",
            "Loss in iteration no. 198161 ==> 0.3071683320705654\n",
            "Loss in iteration no. 198162 ==> 0.3071683320554259\n",
            "Loss in iteration no. 198163 ==> 0.3071683320402875\n",
            "Loss in iteration no. 198164 ==> 0.3071683320251491\n",
            "Loss in iteration no. 198165 ==> 0.30716833201001187\n",
            "Loss in iteration no. 198166 ==> 0.3071683319948761\n",
            "Loss in iteration no. 198167 ==> 0.30716833197974086\n",
            "Loss in iteration no. 198168 ==> 0.30716833196460624\n",
            "Loss in iteration no. 198169 ==> 0.30716833194947213\n",
            "Loss in iteration no. 198170 ==> 0.3071683319343386\n",
            "Loss in iteration no. 198171 ==> 0.30716833191920656\n",
            "Loss in iteration no. 198172 ==> 0.30716833190407516\n",
            "Loss in iteration no. 198173 ==> 0.3071683318889448\n",
            "Loss in iteration no. 198174 ==> 0.3071683318738154\n",
            "Loss in iteration no. 198175 ==> 0.3071683318586862\n",
            "Loss in iteration no. 198176 ==> 0.3071683318435579\n",
            "Loss in iteration no. 198177 ==> 0.30716833182843073\n",
            "Loss in iteration no. 198178 ==> 0.307168331813305\n",
            "Loss in iteration no. 198179 ==> 0.30716833179817893\n",
            "Loss in iteration no. 198180 ==> 0.3071683317830544\n",
            "Loss in iteration no. 198181 ==> 0.30716833176793035\n",
            "Loss in iteration no. 198182 ==> 0.3071683317528079\n",
            "Loss in iteration no. 198183 ==> 0.30716833173768493\n",
            "Loss in iteration no. 198184 ==> 0.3071683317225635\n",
            "Loss in iteration no. 198185 ==> 0.30716833170744323\n",
            "Loss in iteration no. 198186 ==> 0.30716833169232377\n",
            "Loss in iteration no. 198187 ==> 0.3071683316772046\n",
            "Loss in iteration no. 198188 ==> 0.3071683316620864\n",
            "Loss in iteration no. 198189 ==> 0.30716833164696916\n",
            "Loss in iteration no. 198190 ==> 0.3071683316318535\n",
            "Loss in iteration no. 198191 ==> 0.30716833161673734\n",
            "Loss in iteration no. 198192 ==> 0.30716833160162227\n",
            "Loss in iteration no. 198193 ==> 0.3071683315865087\n",
            "Loss in iteration no. 198194 ==> 0.30716833157139567\n",
            "Loss in iteration no. 198195 ==> 0.30716833155628315\n",
            "Loss in iteration no. 198196 ==> 0.3071683315411717\n",
            "Loss in iteration no. 198197 ==> 0.30716833152606127\n",
            "Loss in iteration no. 198198 ==> 0.30716833151095185\n",
            "Loss in iteration no. 198199 ==> 0.30716833149584244\n",
            "Loss in iteration no. 198200 ==> 0.3071683314807341\n",
            "Loss in iteration no. 198201 ==> 0.3071683314656268\n",
            "Loss in iteration no. 198202 ==> 0.3071683314505205\n",
            "Loss in iteration no. 198203 ==> 0.3071683314354143\n",
            "Loss in iteration no. 198204 ==> 0.30716833142030947\n",
            "Loss in iteration no. 198205 ==> 0.30716833140520533\n",
            "Loss in iteration no. 198206 ==> 0.3071683313901026\n",
            "Loss in iteration no. 198207 ==> 0.30716833137499994\n",
            "Loss in iteration no. 198208 ==> 0.30716833135989874\n",
            "Loss in iteration no. 198209 ==> 0.3071683313447981\n",
            "Loss in iteration no. 198210 ==> 0.3071683313296975\n",
            "Loss in iteration no. 198211 ==> 0.307168331314599\n",
            "Loss in iteration no. 198212 ==> 0.3071683312995004\n",
            "Loss in iteration no. 198213 ==> 0.3071683312844028\n",
            "Loss in iteration no. 198214 ==> 0.30716833126930637\n",
            "Loss in iteration no. 198215 ==> 0.30716833125421134\n",
            "Loss in iteration no. 198216 ==> 0.3071683312391158\n",
            "Loss in iteration no. 198217 ==> 0.3071683312240213\n",
            "Loss in iteration no. 198218 ==> 0.3071683312089284\n",
            "Loss in iteration no. 198219 ==> 0.30716833119383646\n",
            "Loss in iteration no. 198220 ==> 0.30716833117874415\n",
            "Loss in iteration no. 198221 ==> 0.30716833116365416\n",
            "Loss in iteration no. 198222 ==> 0.3071683311485642\n",
            "Loss in iteration no. 198223 ==> 0.30716833113347436\n",
            "Loss in iteration no. 198224 ==> 0.30716833111838643\n",
            "Loss in iteration no. 198225 ==> 0.30716833110329855\n",
            "Loss in iteration no. 198226 ==> 0.30716833108821173\n",
            "Loss in iteration no. 198227 ==> 0.3071683310731263\n",
            "Loss in iteration no. 198228 ==> 0.30716833105804153\n",
            "Loss in iteration no. 198229 ==> 0.30716833104295665\n",
            "Loss in iteration no. 198230 ==> 0.30716833102787333\n",
            "Loss in iteration no. 198231 ==> 0.3071683310127905\n",
            "Loss in iteration no. 198232 ==> 0.3071683309977092\n",
            "Loss in iteration no. 198233 ==> 0.3071683309826288\n",
            "Loss in iteration no. 198234 ==> 0.3071683309675485\n",
            "Loss in iteration no. 198235 ==> 0.30716833095246915\n",
            "Loss in iteration no. 198236 ==> 0.3071683309373908\n",
            "Loss in iteration no. 198237 ==> 0.30716833092231355\n",
            "Loss in iteration no. 198238 ==> 0.30716833090723616\n",
            "Loss in iteration no. 198239 ==> 0.3071683308921609\n",
            "Loss in iteration no. 198240 ==> 0.3071683308770855\n",
            "Loss in iteration no. 198241 ==> 0.30716833086201073\n",
            "Loss in iteration no. 198242 ==> 0.3071683308469374\n",
            "Loss in iteration no. 198243 ==> 0.3071683308318646\n",
            "Loss in iteration no. 198244 ==> 0.3071683308167938\n",
            "Loss in iteration no. 198245 ==> 0.3071683308017224\n",
            "Loss in iteration no. 198246 ==> 0.3071683307866515\n",
            "Loss in iteration no. 198247 ==> 0.3071683307715827\n",
            "Loss in iteration no. 198248 ==> 0.30716833075651384\n",
            "Loss in iteration no. 198249 ==> 0.307168330741447\n",
            "Loss in iteration no. 198250 ==> 0.30716833072637906\n",
            "Loss in iteration no. 198251 ==> 0.30716833071131316\n",
            "Loss in iteration no. 198252 ==> 0.3071683306962487\n",
            "Loss in iteration no. 198253 ==> 0.3071683306811839\n",
            "Loss in iteration no. 198254 ==> 0.3071683306661205\n",
            "Loss in iteration no. 198255 ==> 0.3071683306510575\n",
            "Loss in iteration no. 198256 ==> 0.30716833063599597\n",
            "Loss in iteration no. 198257 ==> 0.30716833062093457\n",
            "Loss in iteration no. 198258 ==> 0.30716833060587456\n",
            "Loss in iteration no. 198259 ==> 0.307168330590815\n",
            "Loss in iteration no. 198260 ==> 0.30716833057575665\n",
            "Loss in iteration no. 198261 ==> 0.30716833056069803\n",
            "Loss in iteration no. 198262 ==> 0.3071683305456415\n",
            "Loss in iteration no. 198263 ==> 0.3071683305305849\n",
            "Loss in iteration no. 198264 ==> 0.30716833051552983\n",
            "Loss in iteration no. 198265 ==> 0.30716833050047515\n",
            "Loss in iteration no. 198266 ==> 0.3071683304854221\n",
            "Loss in iteration no. 198267 ==> 0.3071683304703694\n",
            "Loss in iteration no. 198268 ==> 0.3071683304553173\n",
            "Loss in iteration no. 198269 ==> 0.30716833044026554\n",
            "Loss in iteration no. 198270 ==> 0.30716833042521535\n",
            "Loss in iteration no. 198271 ==> 0.3071683304101661\n",
            "Loss in iteration no. 198272 ==> 0.3071683303951178\n",
            "Loss in iteration no. 198273 ==> 0.3071683303800695\n",
            "Loss in iteration no. 198274 ==> 0.30716833036502217\n",
            "Loss in iteration no. 198275 ==> 0.3071683303499758\n",
            "Loss in iteration no. 198276 ==> 0.30716833033493046\n",
            "Loss in iteration no. 198277 ==> 0.3071683303198865\n",
            "Loss in iteration no. 198278 ==> 0.307168330304842\n",
            "Loss in iteration no. 198279 ==> 0.30716833028979906\n",
            "Loss in iteration no. 198280 ==> 0.3071683302747566\n",
            "Loss in iteration no. 198281 ==> 0.30716833025971557\n",
            "Loss in iteration no. 198282 ==> 0.30716833024467544\n",
            "Loss in iteration no. 198283 ==> 0.30716833022963586\n",
            "Loss in iteration no. 198284 ==> 0.30716833021459666\n",
            "Loss in iteration no. 198285 ==> 0.30716833019955847\n",
            "Loss in iteration no. 198286 ==> 0.30716833018452133\n",
            "Loss in iteration no. 198287 ==> 0.3071683301694855\n",
            "Loss in iteration no. 198288 ==> 0.3071683301544502\n",
            "Loss in iteration no. 198289 ==> 0.30716833013941486\n",
            "Loss in iteration no. 198290 ==> 0.30716833012438055\n",
            "Loss in iteration no. 198291 ==> 0.30716833010934763\n",
            "Loss in iteration no. 198292 ==> 0.30716833009431516\n",
            "Loss in iteration no. 198293 ==> 0.3071683300792841\n",
            "Loss in iteration no. 198294 ==> 0.30716833006425415\n",
            "Loss in iteration no. 198295 ==> 0.30716833004922406\n",
            "Loss in iteration no. 198296 ==> 0.3071683300341949\n",
            "Loss in iteration no. 198297 ==> 0.30716833001916616\n",
            "Loss in iteration no. 198298 ==> 0.307168330004139\n",
            "Loss in iteration no. 198299 ==> 0.30716832998911325\n",
            "Loss in iteration no. 198300 ==> 0.307168329974087\n",
            "Loss in iteration no. 198301 ==> 0.30716832995906257\n",
            "Loss in iteration no. 198302 ==> 0.3071683299440382\n",
            "Loss in iteration no. 198303 ==> 0.3071683299290152\n",
            "Loss in iteration no. 198304 ==> 0.3071683299139926\n",
            "Loss in iteration no. 198305 ==> 0.3071683298989716\n",
            "Loss in iteration no. 198306 ==> 0.3071683298839505\n",
            "Loss in iteration no. 198307 ==> 0.3071683298689299\n",
            "Loss in iteration no. 198308 ==> 0.3071683298539116\n",
            "Loss in iteration no. 198309 ==> 0.30716832983889336\n",
            "Loss in iteration no. 198310 ==> 0.3071683298238761\n",
            "Loss in iteration no. 198311 ==> 0.30716832980885866\n",
            "Loss in iteration no. 198312 ==> 0.30716832979384373\n",
            "Loss in iteration no. 198313 ==> 0.3071683297788282\n",
            "Loss in iteration no. 198314 ==> 0.30716832976381364\n",
            "Loss in iteration no. 198315 ==> 0.30716832974880054\n",
            "Loss in iteration no. 198316 ==> 0.3071683297337879\n",
            "Loss in iteration no. 198317 ==> 0.3071683297187767\n",
            "Loss in iteration no. 198318 ==> 0.3071683297037659\n",
            "Loss in iteration no. 198319 ==> 0.30716832968875557\n",
            "Loss in iteration no. 198320 ==> 0.30716832967374613\n",
            "Loss in iteration no. 198321 ==> 0.3071683296587386\n",
            "Loss in iteration no. 198322 ==> 0.30716832964373003\n",
            "Loss in iteration no. 198323 ==> 0.30716832962872354\n",
            "Loss in iteration no. 198324 ==> 0.30716832961371776\n",
            "Loss in iteration no. 198325 ==> 0.30716832959871204\n",
            "Loss in iteration no. 198326 ==> 0.30716832958370827\n",
            "Loss in iteration no. 198327 ==> 0.3071683295687049\n",
            "Loss in iteration no. 198328 ==> 0.307168329553702\n",
            "Loss in iteration no. 198329 ==> 0.3071683295387005\n",
            "Loss in iteration no. 198330 ==> 0.30716832952369943\n",
            "Loss in iteration no. 198331 ==> 0.30716832950869877\n",
            "Loss in iteration no. 198332 ==> 0.30716832949370004\n",
            "Loss in iteration no. 198333 ==> 0.3071683294787012\n",
            "Loss in iteration no. 198334 ==> 0.30716832946370337\n",
            "Loss in iteration no. 198335 ==> 0.3071683294487064\n",
            "Loss in iteration no. 198336 ==> 0.30716832943371036\n",
            "Loss in iteration no. 198337 ==> 0.3071683294187153\n",
            "Loss in iteration no. 198338 ==> 0.30716832940372013\n",
            "Loss in iteration no. 198339 ==> 0.30716832938872746\n",
            "Loss in iteration no. 198340 ==> 0.30716832937373406\n",
            "Loss in iteration no. 198341 ==> 0.30716832935874216\n",
            "Loss in iteration no. 198342 ==> 0.3071683293437507\n",
            "Loss in iteration no. 198343 ==> 0.3071683293287607\n",
            "Loss in iteration no. 198344 ==> 0.3071683293137715\n",
            "Loss in iteration no. 198345 ==> 0.3071683292987823\n",
            "Loss in iteration no. 198346 ==> 0.307168329283795\n",
            "Loss in iteration no. 198347 ==> 0.3071683292688076\n",
            "Loss in iteration no. 198348 ==> 0.30716832925382115\n",
            "Loss in iteration no. 198349 ==> 0.30716832923883564\n",
            "Loss in iteration no. 198350 ==> 0.307168329223851\n",
            "Loss in iteration no. 198351 ==> 0.3071683292088673\n",
            "Loss in iteration no. 198352 ==> 0.307168329193885\n",
            "Loss in iteration no. 198353 ==> 0.307168329178902\n",
            "Loss in iteration no. 198354 ==> 0.3071683291639216\n",
            "Loss in iteration no. 198355 ==> 0.307168329148941\n",
            "Loss in iteration no. 198356 ==> 0.30716832913396086\n",
            "Loss in iteration no. 198357 ==> 0.30716832911898206\n",
            "Loss in iteration no. 198358 ==> 0.30716832910400427\n",
            "Loss in iteration no. 198359 ==> 0.3071683290890263\n",
            "Loss in iteration no. 198360 ==> 0.3071683290740503\n",
            "Loss in iteration no. 198361 ==> 0.30716832905907515\n",
            "Loss in iteration no. 198362 ==> 0.3071683290440999\n",
            "Loss in iteration no. 198363 ==> 0.3071683290291262\n",
            "Loss in iteration no. 198364 ==> 0.30716832901415275\n",
            "Loss in iteration no. 198365 ==> 0.3071683289991808\n",
            "Loss in iteration no. 198366 ==> 0.30716832898420915\n",
            "Loss in iteration no. 198367 ==> 0.3071683289692389\n",
            "Loss in iteration no. 198368 ==> 0.3071683289542681\n",
            "Loss in iteration no. 198369 ==> 0.3071683289392998\n",
            "Loss in iteration no. 198370 ==> 0.30716832892433127\n",
            "Loss in iteration no. 198371 ==> 0.30716832890936363\n",
            "Loss in iteration no. 198372 ==> 0.307168328894397\n",
            "Loss in iteration no. 198373 ==> 0.30716832887943113\n",
            "Loss in iteration no. 198374 ==> 0.3071683288644662\n",
            "Loss in iteration no. 198375 ==> 0.3071683288495028\n",
            "Loss in iteration no. 198376 ==> 0.3071683288345396\n",
            "Loss in iteration no. 198377 ==> 0.30716832881957645\n",
            "Loss in iteration no. 198378 ==> 0.30716832880461564\n",
            "Loss in iteration no. 198379 ==> 0.3071683287896542\n",
            "Loss in iteration no. 198380 ==> 0.3071683287746941\n",
            "Loss in iteration no. 198381 ==> 0.30716832875973504\n",
            "Loss in iteration no. 198382 ==> 0.3071683287447768\n",
            "Loss in iteration no. 198383 ==> 0.30716832872981936\n",
            "Loss in iteration no. 198384 ==> 0.30716832871486294\n",
            "Loss in iteration no. 198385 ==> 0.3071683286999064\n",
            "Loss in iteration no. 198386 ==> 0.30716832868495164\n",
            "Loss in iteration no. 198387 ==> 0.3071683286699967\n",
            "Loss in iteration no. 198388 ==> 0.30716832865504445\n",
            "Loss in iteration no. 198389 ==> 0.3071683286400914\n",
            "Loss in iteration no. 198390 ==> 0.3071683286251392\n",
            "Loss in iteration no. 198391 ==> 0.30716832861018833\n",
            "Loss in iteration no. 198392 ==> 0.30716832859523857\n",
            "Loss in iteration no. 198393 ==> 0.30716832858028903\n",
            "Loss in iteration no. 198394 ==> 0.30716832856533993\n",
            "Loss in iteration no. 198395 ==> 0.3071683285503927\n",
            "Loss in iteration no. 198396 ==> 0.30716832853544523\n",
            "Loss in iteration no. 198397 ==> 0.3071683285204998\n",
            "Loss in iteration no. 198398 ==> 0.30716832850555426\n",
            "Loss in iteration no. 198399 ==> 0.30716832849060943\n",
            "Loss in iteration no. 198400 ==> 0.30716832847566616\n",
            "Loss in iteration no. 198401 ==> 0.3071683284607231\n",
            "Loss in iteration no. 198402 ==> 0.30716832844578157\n",
            "Loss in iteration no. 198403 ==> 0.30716832843084035\n",
            "Loss in iteration no. 198404 ==> 0.3071683284158995\n",
            "Loss in iteration no. 198405 ==> 0.30716832840096003\n",
            "Loss in iteration no. 198406 ==> 0.307168328386021\n",
            "Loss in iteration no. 198407 ==> 0.3071683283710838\n",
            "Loss in iteration no. 198408 ==> 0.3071683283561463\n",
            "Loss in iteration no. 198409 ==> 0.30716832834120983\n",
            "Loss in iteration no. 198410 ==> 0.3071683283262742\n",
            "Loss in iteration no. 198411 ==> 0.30716832831133944\n",
            "Loss in iteration no. 198412 ==> 0.3071683282964061\n",
            "Loss in iteration no. 198413 ==> 0.30716832828147306\n",
            "Loss in iteration no. 198414 ==> 0.30716832826654095\n",
            "Loss in iteration no. 198415 ==> 0.3071683282516092\n",
            "Loss in iteration no. 198416 ==> 0.3071683282366787\n",
            "Loss in iteration no. 198417 ==> 0.3071683282217497\n",
            "Loss in iteration no. 198418 ==> 0.30716832820682055\n",
            "Loss in iteration no. 198419 ==> 0.3071683281918922\n",
            "Loss in iteration no. 198420 ==> 0.3071683281769647\n",
            "Loss in iteration no. 198421 ==> 0.30716832816203915\n",
            "Loss in iteration no. 198422 ==> 0.3071683281471134\n",
            "Loss in iteration no. 198423 ==> 0.30716832813218853\n",
            "Loss in iteration no. 198424 ==> 0.3071683281172634\n",
            "Loss in iteration no. 198425 ==> 0.3071683281023403\n",
            "Loss in iteration no. 198426 ==> 0.30716832808741856\n",
            "Loss in iteration no. 198427 ==> 0.30716832807249705\n",
            "Loss in iteration no. 198428 ==> 0.307168328057576\n",
            "Loss in iteration no. 198429 ==> 0.30716832804265626\n",
            "Loss in iteration no. 198430 ==> 0.3071683280277369\n",
            "Loss in iteration no. 198431 ==> 0.3071683280128183\n",
            "Loss in iteration no. 198432 ==> 0.3071683279979017\n",
            "Loss in iteration no. 198433 ==> 0.30716832798298477\n",
            "Loss in iteration no. 198434 ==> 0.30716832796806887\n",
            "Loss in iteration no. 198435 ==> 0.3071683279531537\n",
            "Loss in iteration no. 198436 ==> 0.3071683279382395\n",
            "Loss in iteration no. 198437 ==> 0.3071683279233261\n",
            "Loss in iteration no. 198438 ==> 0.30716832790841386\n",
            "Loss in iteration no. 198439 ==> 0.30716832789350124\n",
            "Loss in iteration no. 198440 ==> 0.30716832787859094\n",
            "Loss in iteration no. 198441 ==> 0.3071683278636808\n",
            "Loss in iteration no. 198442 ==> 0.30716832784877107\n",
            "Loss in iteration no. 198443 ==> 0.30716832783386333\n",
            "Loss in iteration no. 198444 ==> 0.30716832781895537\n",
            "Loss in iteration no. 198445 ==> 0.3071683278040481\n",
            "Loss in iteration no. 198446 ==> 0.3071683277891419\n",
            "Loss in iteration no. 198447 ==> 0.30716832777423736\n",
            "Loss in iteration no. 198448 ==> 0.3071683277593327\n",
            "Loss in iteration no. 198449 ==> 0.3071683277444289\n",
            "Loss in iteration no. 198450 ==> 0.30716832772952596\n",
            "Loss in iteration no. 198451 ==> 0.30716832771462443\n",
            "Loss in iteration no. 198452 ==> 0.30716832769972313\n",
            "Loss in iteration no. 198453 ==> 0.30716832768482216\n",
            "Loss in iteration no. 198454 ==> 0.3071683276699231\n",
            "Loss in iteration no. 198455 ==> 0.3071683276550243\n",
            "Loss in iteration no. 198456 ==> 0.30716832764012586\n",
            "Loss in iteration no. 198457 ==> 0.3071683276252293\n",
            "Loss in iteration no. 198458 ==> 0.3071683276103325\n",
            "Loss in iteration no. 198459 ==> 0.3071683275954376\n",
            "Loss in iteration no. 198460 ==> 0.30716832758054247\n",
            "Loss in iteration no. 198461 ==> 0.30716832756564927\n",
            "Loss in iteration no. 198462 ==> 0.30716832755075635\n",
            "Loss in iteration no. 198463 ==> 0.30716832753586365\n",
            "Loss in iteration no. 198464 ==> 0.30716832752097245\n",
            "Loss in iteration no. 198465 ==> 0.3071683275060814\n",
            "Loss in iteration no. 198466 ==> 0.30716832749119194\n",
            "Loss in iteration no. 198467 ==> 0.3071683274763026\n",
            "Loss in iteration no. 198468 ==> 0.3071683274614146\n",
            "Loss in iteration no. 198469 ==> 0.3071683274465274\n",
            "Loss in iteration no. 198470 ==> 0.3071683274316412\n",
            "Loss in iteration no. 198471 ==> 0.3071683274167556\n",
            "Loss in iteration no. 198472 ==> 0.307168327401871\n",
            "Loss in iteration no. 198473 ==> 0.3071683273869861\n",
            "Loss in iteration no. 198474 ==> 0.30716832737210364\n",
            "Loss in iteration no. 198475 ==> 0.30716832735722144\n",
            "Loss in iteration no. 198476 ==> 0.307168327342339\n",
            "Loss in iteration no. 198477 ==> 0.30716832732745897\n",
            "Loss in iteration no. 198478 ==> 0.3071683273125787\n",
            "Loss in iteration no. 198479 ==> 0.3071683272976998\n",
            "Loss in iteration no. 198480 ==> 0.3071683272828212\n",
            "Loss in iteration no. 198481 ==> 0.3071683272679444\n",
            "Loss in iteration no. 198482 ==> 0.3071683272530674\n",
            "Loss in iteration no. 198483 ==> 0.3071683272381912\n",
            "Loss in iteration no. 198484 ==> 0.3071683272233159\n",
            "Loss in iteration no. 198485 ==> 0.3071683272084423\n",
            "Loss in iteration no. 198486 ==> 0.3071683271935686\n",
            "Loss in iteration no. 198487 ==> 0.3071683271786962\n",
            "Loss in iteration no. 198488 ==> 0.30716832716382403\n",
            "Loss in iteration no. 198489 ==> 0.3071683271489527\n",
            "Loss in iteration no. 198490 ==> 0.3071683271340828\n",
            "Loss in iteration no. 198491 ==> 0.30716832711921366\n",
            "Loss in iteration no. 198492 ==> 0.3071683271043447\n",
            "Loss in iteration no. 198493 ==> 0.30716832708947717\n",
            "Loss in iteration no. 198494 ==> 0.3071683270746104\n",
            "Loss in iteration no. 198495 ==> 0.30716832705974445\n",
            "Loss in iteration no. 198496 ==> 0.30716832704487834\n",
            "Loss in iteration no. 198497 ==> 0.30716832703001395\n",
            "Loss in iteration no. 198498 ==> 0.30716832701515046\n",
            "Loss in iteration no. 198499 ==> 0.3071683270002882\n",
            "Loss in iteration no. 198500 ==> 0.3071683269854253\n",
            "Loss in iteration no. 198501 ==> 0.30716832697056407\n",
            "Loss in iteration no. 198502 ==> 0.3071683269557043\n",
            "Loss in iteration no. 198503 ==> 0.3071683269408442\n",
            "Loss in iteration no. 198504 ==> 0.30716832692598545\n",
            "Loss in iteration no. 198505 ==> 0.3071683269111271\n",
            "Loss in iteration no. 198506 ==> 0.3071683268962704\n",
            "Loss in iteration no. 198507 ==> 0.3071683268814136\n",
            "Loss in iteration no. 198508 ==> 0.30716832686655854\n",
            "Loss in iteration no. 198509 ==> 0.3071683268517033\n",
            "Loss in iteration no. 198510 ==> 0.3071683268368498\n",
            "Loss in iteration no. 198511 ==> 0.3071683268219962\n",
            "Loss in iteration no. 198512 ==> 0.3071683268071448\n",
            "Loss in iteration no. 198513 ==> 0.30716832679229267\n",
            "Loss in iteration no. 198514 ==> 0.30716832677744194\n",
            "Loss in iteration no. 198515 ==> 0.3071683267625924\n",
            "Loss in iteration no. 198516 ==> 0.3071683267477432\n",
            "Loss in iteration no. 198517 ==> 0.3071683267328948\n",
            "Loss in iteration no. 198518 ==> 0.30716832671804767\n",
            "Loss in iteration no. 198519 ==> 0.3071683267032008\n",
            "Loss in iteration no. 198520 ==> 0.30716832668835475\n",
            "Loss in iteration no. 198521 ==> 0.30716832667351057\n",
            "Loss in iteration no. 198522 ==> 0.307168326658666\n",
            "Loss in iteration no. 198523 ==> 0.30716832664382276\n",
            "Loss in iteration no. 198524 ==> 0.30716832662897986\n",
            "Loss in iteration no. 198525 ==> 0.3071683266141378\n",
            "Loss in iteration no. 198526 ==> 0.3071683265992978\n",
            "Loss in iteration no. 198527 ==> 0.30716832658445725\n",
            "Loss in iteration no. 198528 ==> 0.30716832656961807\n",
            "Loss in iteration no. 198529 ==> 0.30716832655477955\n",
            "Loss in iteration no. 198530 ==> 0.30716832653994186\n",
            "Loss in iteration no. 198531 ==> 0.3071683265251053\n",
            "Loss in iteration no. 198532 ==> 0.30716832651026915\n",
            "Loss in iteration no. 198533 ==> 0.30716832649543374\n",
            "Loss in iteration no. 198534 ==> 0.30716832648059916\n",
            "Loss in iteration no. 198535 ==> 0.30716832646576586\n",
            "Loss in iteration no. 198536 ==> 0.3071683264509327\n",
            "Loss in iteration no. 198537 ==> 0.3071683264361005\n",
            "Loss in iteration no. 198538 ==> 0.30716832642127045\n",
            "Loss in iteration no. 198539 ==> 0.3071683264064397\n",
            "Loss in iteration no. 198540 ==> 0.3071683263916102\n",
            "Loss in iteration no. 198541 ==> 0.307168326376781\n",
            "Loss in iteration no. 198542 ==> 0.30716832636195307\n",
            "Loss in iteration no. 198543 ==> 0.30716832634712593\n",
            "Loss in iteration no. 198544 ==> 0.3071683263322995\n",
            "Loss in iteration no. 198545 ==> 0.30716832631747387\n",
            "Loss in iteration no. 198546 ==> 0.30716832630265\n",
            "Loss in iteration no. 198547 ==> 0.3071683262878259\n",
            "Loss in iteration no. 198548 ==> 0.30716832627300256\n",
            "Loss in iteration no. 198549 ==> 0.30716832625818047\n",
            "Loss in iteration no. 198550 ==> 0.3071683262433587\n",
            "Loss in iteration no. 198551 ==> 0.3071683262285382\n",
            "Loss in iteration no. 198552 ==> 0.3071683262137189\n",
            "Loss in iteration no. 198553 ==> 0.3071683261988999\n",
            "Loss in iteration no. 198554 ==> 0.30716832618408113\n",
            "Loss in iteration no. 198555 ==> 0.30716832616926365\n",
            "Loss in iteration no. 198556 ==> 0.30716832615444695\n",
            "Loss in iteration no. 198557 ==> 0.307168326139632\n",
            "Loss in iteration no. 198558 ==> 0.30716832612481676\n",
            "Loss in iteration no. 198559 ==> 0.3071683261100022\n",
            "Loss in iteration no. 198560 ==> 0.3071683260951895\n",
            "Loss in iteration no. 198561 ==> 0.3071683260803772\n",
            "Loss in iteration no. 198562 ==> 0.307168326065565\n",
            "Loss in iteration no. 198563 ==> 0.307168326050754\n",
            "Loss in iteration no. 198564 ==> 0.30716832603594435\n",
            "Loss in iteration no. 198565 ==> 0.307168326021135\n",
            "Loss in iteration no. 198566 ==> 0.30716832600632665\n",
            "Loss in iteration no. 198567 ==> 0.30716832599151883\n",
            "Loss in iteration no. 198568 ==> 0.3071683259767116\n",
            "Loss in iteration no. 198569 ==> 0.3071683259619062\n",
            "Loss in iteration no. 198570 ==> 0.3071683259471004\n",
            "Loss in iteration no. 198571 ==> 0.30716832593229654\n",
            "Loss in iteration no. 198572 ==> 0.30716832591749244\n",
            "Loss in iteration no. 198573 ==> 0.30716832590268994\n",
            "Loss in iteration no. 198574 ==> 0.3071683258878878\n",
            "Loss in iteration no. 198575 ==> 0.3071683258730869\n",
            "Loss in iteration no. 198576 ==> 0.3071683258582862\n",
            "Loss in iteration no. 198577 ==> 0.30716832584348674\n",
            "Loss in iteration no. 198578 ==> 0.3071683258286885\n",
            "Loss in iteration no. 198579 ==> 0.30716832581389003\n",
            "Loss in iteration no. 198580 ==> 0.3071683257990928\n",
            "Loss in iteration no. 198581 ==> 0.3071683257842968\n",
            "Loss in iteration no. 198582 ==> 0.30716832576950154\n",
            "Loss in iteration no. 198583 ==> 0.30716832575470604\n",
            "Loss in iteration no. 198584 ==> 0.3071683257399124\n",
            "Loss in iteration no. 198585 ==> 0.30716832572511976\n",
            "Loss in iteration no. 198586 ==> 0.30716832571032754\n",
            "Loss in iteration no. 198587 ==> 0.3071683256955359\n",
            "Loss in iteration no. 198588 ==> 0.3071683256807456\n",
            "Loss in iteration no. 198589 ==> 0.30716832566595553\n",
            "Loss in iteration no. 198590 ==> 0.3071683256511667\n",
            "Loss in iteration no. 198591 ==> 0.3071683256363785\n",
            "Loss in iteration no. 198592 ==> 0.30716832562159074\n",
            "Loss in iteration no. 198593 ==> 0.307168325606804\n",
            "Loss in iteration no. 198594 ==> 0.3071683255920181\n",
            "Loss in iteration no. 198595 ==> 0.30716832557723395\n",
            "Loss in iteration no. 198596 ==> 0.30716832556244944\n",
            "Loss in iteration no. 198597 ==> 0.30716832554766577\n",
            "Loss in iteration no. 198598 ==> 0.3071683255328842\n",
            "Loss in iteration no. 198599 ==> 0.30716832551810197\n",
            "Loss in iteration no. 198600 ==> 0.30716832550332046\n",
            "Loss in iteration no. 198601 ==> 0.30716832548854106\n",
            "Loss in iteration no. 198602 ==> 0.3071683254737615\n",
            "Loss in iteration no. 198603 ==> 0.3071683254589831\n",
            "Loss in iteration no. 198604 ==> 0.307168325444205\n",
            "Loss in iteration no. 198605 ==> 0.30716832542942857\n",
            "Loss in iteration no. 198606 ==> 0.3071683254146529\n",
            "Loss in iteration no. 198607 ==> 0.3071683253998779\n",
            "Loss in iteration no. 198608 ==> 0.30716832538510264\n",
            "Loss in iteration no. 198609 ==> 0.30716832537032895\n",
            "Loss in iteration no. 198610 ==> 0.3071683253555562\n",
            "Loss in iteration no. 198611 ==> 0.30716832534078414\n",
            "Loss in iteration no. 198612 ==> 0.3071683253260133\n",
            "Loss in iteration no. 198613 ==> 0.3071683253112426\n",
            "Loss in iteration no. 198614 ==> 0.30716832529647303\n",
            "Loss in iteration no. 198615 ==> 0.30716832528170385\n",
            "Loss in iteration no. 198616 ==> 0.30716832526693594\n",
            "Loss in iteration no. 198617 ==> 0.3071683252521696\n",
            "Loss in iteration no. 198618 ==> 0.307168325237403\n",
            "Loss in iteration no. 198619 ==> 0.30716832522263704\n",
            "Loss in iteration no. 198620 ==> 0.3071683252078729\n",
            "Loss in iteration no. 198621 ==> 0.30716832519310844\n",
            "Loss in iteration no. 198622 ==> 0.3071683251783457\n",
            "Loss in iteration no. 198623 ==> 0.30716832516358267\n",
            "Loss in iteration no. 198624 ==> 0.3071683251488219\n",
            "Loss in iteration no. 198625 ==> 0.3071683251340612\n",
            "Loss in iteration no. 198626 ==> 0.30716832511930026\n",
            "Loss in iteration no. 198627 ==> 0.30716832510454156\n",
            "Loss in iteration no. 198628 ==> 0.30716832508978353\n",
            "Loss in iteration no. 198629 ==> 0.3071683250750258\n",
            "Loss in iteration no. 198630 ==> 0.3071683250602692\n",
            "Loss in iteration no. 198631 ==> 0.30716832504551334\n",
            "Loss in iteration no. 198632 ==> 0.3071683250307581\n",
            "Loss in iteration no. 198633 ==> 0.30716832501600466\n",
            "Loss in iteration no. 198634 ==> 0.3071683250012508\n",
            "Loss in iteration no. 198635 ==> 0.3071683249864982\n",
            "Loss in iteration no. 198636 ==> 0.30716832497174684\n",
            "Loss in iteration no. 198637 ==> 0.30716832495699514\n",
            "Loss in iteration no. 198638 ==> 0.3071683249422457\n",
            "Loss in iteration no. 198639 ==> 0.3071683249274954\n",
            "Loss in iteration no. 198640 ==> 0.3071683249127473\n",
            "Loss in iteration no. 198641 ==> 0.3071683248979999\n",
            "Loss in iteration no. 198642 ==> 0.3071683248832527\n",
            "Loss in iteration no. 198643 ==> 0.3071683248685057\n",
            "Loss in iteration no. 198644 ==> 0.30716832485376044\n",
            "Loss in iteration no. 198645 ==> 0.3071683248390158\n",
            "Loss in iteration no. 198646 ==> 0.3071683248242728\n",
            "Loss in iteration no. 198647 ==> 0.3071683248095301\n",
            "Loss in iteration no. 198648 ==> 0.3071683247947876\n",
            "Loss in iteration no. 198649 ==> 0.30716832478004574\n",
            "Loss in iteration no. 198650 ==> 0.30716832476530603\n",
            "Loss in iteration no. 198651 ==> 0.3071683247505656\n",
            "Loss in iteration no. 198652 ==> 0.3071683247358272\n",
            "Loss in iteration no. 198653 ==> 0.3071683247210891\n",
            "Loss in iteration no. 198654 ==> 0.30716832470635125\n",
            "Loss in iteration no. 198655 ==> 0.30716832469161504\n",
            "Loss in iteration no. 198656 ==> 0.30716832467687943\n",
            "Loss in iteration no. 198657 ==> 0.3071683246621446\n",
            "Loss in iteration no. 198658 ==> 0.3071683246474103\n",
            "Loss in iteration no. 198659 ==> 0.3071683246326769\n",
            "Loss in iteration no. 198660 ==> 0.307168324617945\n",
            "Loss in iteration no. 198661 ==> 0.30716832460321347\n",
            "Loss in iteration no. 198662 ==> 0.307168324588482\n",
            "Loss in iteration no. 198663 ==> 0.30716832457375276\n",
            "Loss in iteration no. 198664 ==> 0.3071683245590236\n",
            "Loss in iteration no. 198665 ==> 0.30716832454429466\n",
            "Loss in iteration no. 198666 ==> 0.3071683245295675\n",
            "Loss in iteration no. 198667 ==> 0.3071683245148404\n",
            "Loss in iteration no. 198668 ==> 0.30716832450011444\n",
            "Loss in iteration no. 198669 ==> 0.3071683244853893\n",
            "Loss in iteration no. 198670 ==> 0.3071683244706647\n",
            "Loss in iteration no. 198671 ==> 0.3071683244559408\n",
            "Loss in iteration no. 198672 ==> 0.30716832444121916\n",
            "Loss in iteration no. 198673 ==> 0.3071683244264966\n",
            "Loss in iteration no. 198674 ==> 0.3071683244117748\n",
            "Loss in iteration no. 198675 ==> 0.30716832439705505\n",
            "Loss in iteration no. 198676 ==> 0.3071683243823356\n",
            "Loss in iteration no. 198677 ==> 0.30716832436761726\n",
            "Loss in iteration no. 198678 ==> 0.3071683243528981\n",
            "Loss in iteration no. 198679 ==> 0.307168324338181\n",
            "Loss in iteration no. 198680 ==> 0.3071683243234657\n",
            "Loss in iteration no. 198681 ==> 0.30716832430875\n",
            "Loss in iteration no. 198682 ==> 0.307168324294035\n",
            "Loss in iteration no. 198683 ==> 0.30716832427932067\n",
            "Loss in iteration no. 198684 ==> 0.307168324264608\n",
            "Loss in iteration no. 198685 ==> 0.307168324249896\n",
            "Loss in iteration no. 198686 ==> 0.3071683242351842\n",
            "Loss in iteration no. 198687 ==> 0.3071683242204734\n",
            "Loss in iteration no. 198688 ==> 0.3071683242057639\n",
            "Loss in iteration no. 198689 ==> 0.30716832419105455\n",
            "Loss in iteration no. 198690 ==> 0.3071683241763463\n",
            "Loss in iteration no. 198691 ==> 0.30716832416163886\n",
            "Loss in iteration no. 198692 ==> 0.3071683241469323\n",
            "Loss in iteration no. 198693 ==> 0.3071683241322261\n",
            "Loss in iteration no. 198694 ==> 0.30716832411752154\n",
            "Loss in iteration no. 198695 ==> 0.30716832410281664\n",
            "Loss in iteration no. 198696 ==> 0.30716832408811334\n",
            "Loss in iteration no. 198697 ==> 0.3071683240734111\n",
            "Loss in iteration no. 198698 ==> 0.3071683240587092\n",
            "Loss in iteration no. 198699 ==> 0.3071683240440079\n",
            "Loss in iteration no. 198700 ==> 0.30716832402930777\n",
            "Loss in iteration no. 198701 ==> 0.30716832401460875\n",
            "Loss in iteration no. 198702 ==> 0.3071683239999099\n",
            "Loss in iteration no. 198703 ==> 0.30716832398521215\n",
            "Loss in iteration no. 198704 ==> 0.30716832397051463\n",
            "Loss in iteration no. 198705 ==> 0.3071683239558187\n",
            "Loss in iteration no. 198706 ==> 0.3071683239411235\n",
            "Loss in iteration no. 198707 ==> 0.3071683239264288\n",
            "Loss in iteration no. 198708 ==> 0.3071683239117348\n",
            "Loss in iteration no. 198709 ==> 0.30716832389704146\n",
            "Loss in iteration no. 198710 ==> 0.30716832388234977\n",
            "Loss in iteration no. 198711 ==> 0.30716832386765824\n",
            "Loss in iteration no. 198712 ==> 0.3071683238529679\n",
            "Loss in iteration no. 198713 ==> 0.30716832383827863\n",
            "Loss in iteration no. 198714 ==> 0.3071683238235895\n",
            "Loss in iteration no. 198715 ==> 0.3071683238089015\n",
            "Loss in iteration no. 198716 ==> 0.3071683237942142\n",
            "Loss in iteration no. 198717 ==> 0.30716832377952696\n",
            "Loss in iteration no. 198718 ==> 0.30716832376484093\n",
            "Loss in iteration no. 198719 ==> 0.3071683237501565\n",
            "Loss in iteration no. 198720 ==> 0.3071683237354717\n",
            "Loss in iteration no. 198721 ==> 0.3071683237207885\n",
            "Loss in iteration no. 198722 ==> 0.3071683237061065\n",
            "Loss in iteration no. 198723 ==> 0.3071683236914247\n",
            "Loss in iteration no. 198724 ==> 0.30716832367674346\n",
            "Loss in iteration no. 198725 ==> 0.30716832366206326\n",
            "Loss in iteration no. 198726 ==> 0.3071683236473844\n",
            "Loss in iteration no. 198727 ==> 0.3071683236327055\n",
            "Loss in iteration no. 198728 ==> 0.30716832361802826\n",
            "Loss in iteration no. 198729 ==> 0.3071683236033512\n",
            "Loss in iteration no. 198730 ==> 0.3071683235886752\n",
            "Loss in iteration no. 198731 ==> 0.3071683235739999\n",
            "Loss in iteration no. 198732 ==> 0.3071683235593252\n",
            "Loss in iteration no. 198733 ==> 0.30716832354465107\n",
            "Loss in iteration no. 198734 ==> 0.3071683235299787\n",
            "Loss in iteration no. 198735 ==> 0.3071683235153063\n",
            "Loss in iteration no. 198736 ==> 0.30716832350063517\n",
            "Loss in iteration no. 198737 ==> 0.3071683234859646\n",
            "Loss in iteration no. 198738 ==> 0.30716832347129513\n",
            "Loss in iteration no. 198739 ==> 0.3071683234566258\n",
            "Loss in iteration no. 198740 ==> 0.3071683234419586\n",
            "Loss in iteration no. 198741 ==> 0.307168323427291\n",
            "Loss in iteration no. 198742 ==> 0.30716832341262507\n",
            "Loss in iteration no. 198743 ==> 0.30716832339795813\n",
            "Loss in iteration no. 198744 ==> 0.3071683233832935\n",
            "Loss in iteration no. 198745 ==> 0.30716832336862937\n",
            "Loss in iteration no. 198746 ==> 0.3071683233539673\n",
            "Loss in iteration no. 198747 ==> 0.30716832333930455\n",
            "Loss in iteration no. 198748 ==> 0.3071683233246423\n",
            "Loss in iteration no. 198749 ==> 0.30716832330998156\n",
            "Loss in iteration no. 198750 ==> 0.30716832329532207\n",
            "Loss in iteration no. 198751 ==> 0.30716832328066257\n",
            "Loss in iteration no. 198752 ==> 0.3071683232660044\n",
            "Loss in iteration no. 198753 ==> 0.3071683232513467\n",
            "Loss in iteration no. 198754 ==> 0.3071683232366895\n",
            "Loss in iteration no. 198755 ==> 0.30716832322203363\n",
            "Loss in iteration no. 198756 ==> 0.30716832320737775\n",
            "Loss in iteration no. 198757 ==> 0.30716832319272347\n",
            "Loss in iteration no. 198758 ==> 0.3071683231780699\n",
            "Loss in iteration no. 198759 ==> 0.30716832316341736\n",
            "Loss in iteration no. 198760 ==> 0.30716832314876596\n",
            "Loss in iteration no. 198761 ==> 0.3071683231341141\n",
            "Loss in iteration no. 198762 ==> 0.30716832311946446\n",
            "Loss in iteration no. 198763 ==> 0.3071683231048138\n",
            "Loss in iteration no. 198764 ==> 0.3071683230901653\n",
            "Loss in iteration no. 198765 ==> 0.30716832307551695\n",
            "Loss in iteration no. 198766 ==> 0.30716832306087055\n",
            "Loss in iteration no. 198767 ==> 0.3071683230462239\n",
            "Loss in iteration no. 198768 ==> 0.30716832303157887\n",
            "Loss in iteration no. 198769 ==> 0.30716832301693336\n",
            "Loss in iteration no. 198770 ==> 0.3071683230022894\n",
            "Loss in iteration no. 198771 ==> 0.3071683229876461\n",
            "Loss in iteration no. 198772 ==> 0.3071683229730034\n",
            "Loss in iteration no. 198773 ==> 0.3071683229583624\n",
            "Loss in iteration no. 198774 ==> 0.3071683229437214\n",
            "Loss in iteration no. 198775 ==> 0.30716832292908136\n",
            "Loss in iteration no. 198776 ==> 0.3071683229144426\n",
            "Loss in iteration no. 198777 ==> 0.30716832289980384\n",
            "Loss in iteration no. 198778 ==> 0.3071683228851662\n",
            "Loss in iteration no. 198779 ==> 0.3071683228705292\n",
            "Loss in iteration no. 198780 ==> 0.30716832285589374\n",
            "Loss in iteration no. 198781 ==> 0.3071683228412584\n",
            "Loss in iteration no. 198782 ==> 0.3071683228266232\n",
            "Loss in iteration no. 198783 ==> 0.307168322811991\n",
            "Loss in iteration no. 198784 ==> 0.3071683227973579\n",
            "Loss in iteration no. 198785 ==> 0.3071683227827253\n",
            "Loss in iteration no. 198786 ==> 0.3071683227680945\n",
            "Loss in iteration no. 198787 ==> 0.3071683227534636\n",
            "Loss in iteration no. 198788 ==> 0.3071683227388339\n",
            "Loss in iteration no. 198789 ==> 0.3071683227242053\n",
            "Loss in iteration no. 198790 ==> 0.3071683227095777\n",
            "Loss in iteration no. 198791 ==> 0.30716832269495026\n",
            "Loss in iteration no. 198792 ==> 0.30716832268032435\n",
            "Loss in iteration no. 198793 ==> 0.30716832266569905\n",
            "Loss in iteration no. 198794 ==> 0.30716832265107435\n",
            "Loss in iteration no. 198795 ==> 0.3071683226364502\n",
            "Loss in iteration no. 198796 ==> 0.30716832262182664\n",
            "Loss in iteration no. 198797 ==> 0.3071683226072046\n",
            "Loss in iteration no. 198798 ==> 0.3071683225925822\n",
            "Loss in iteration no. 198799 ==> 0.30716832257796184\n",
            "Loss in iteration no. 198800 ==> 0.3071683225633416\n",
            "Loss in iteration no. 198801 ==> 0.30716832254872245\n",
            "Loss in iteration no. 198802 ==> 0.30716832253410425\n",
            "Loss in iteration no. 198803 ==> 0.30716832251948634\n",
            "Loss in iteration no. 198804 ==> 0.3071683225048698\n",
            "Loss in iteration no. 198805 ==> 0.3071683224902539\n",
            "Loss in iteration no. 198806 ==> 0.3071683224756386\n",
            "Loss in iteration no. 198807 ==> 0.3071683224610249\n",
            "Loss in iteration no. 198808 ==> 0.3071683224464107\n",
            "Loss in iteration no. 198809 ==> 0.3071683224317981\n",
            "Loss in iteration no. 198810 ==> 0.3071683224171861\n",
            "Loss in iteration no. 198811 ==> 0.3071683224025746\n",
            "Loss in iteration no. 198812 ==> 0.30716832238796526\n",
            "Loss in iteration no. 198813 ==> 0.3071683223733548\n",
            "Loss in iteration no. 198814 ==> 0.3071683223587466\n",
            "Loss in iteration no. 198815 ==> 0.30716832234413893\n",
            "Loss in iteration no. 198816 ==> 0.30716832232953134\n",
            "Loss in iteration no. 198817 ==> 0.30716832231492475\n",
            "Loss in iteration no. 198818 ==> 0.3071683223003197\n",
            "Loss in iteration no. 198819 ==> 0.30716832228571433\n",
            "Loss in iteration no. 198820 ==> 0.30716832227111046\n",
            "Loss in iteration no. 198821 ==> 0.30716832225650714\n",
            "Loss in iteration no. 198822 ==> 0.3071683222419044\n",
            "Loss in iteration no. 198823 ==> 0.30716832222730367\n",
            "Loss in iteration no. 198824 ==> 0.3071683222127031\n",
            "Loss in iteration no. 198825 ==> 0.307168322198102\n",
            "Loss in iteration no. 198826 ==> 0.307168322183504\n",
            "Loss in iteration no. 198827 ==> 0.30716832216890555\n",
            "Loss in iteration no. 198828 ==> 0.3071683221543071\n",
            "Loss in iteration no. 198829 ==> 0.3071683221397109\n",
            "Loss in iteration no. 198830 ==> 0.3071683221251149\n",
            "Loss in iteration no. 198831 ==> 0.3071683221105197\n",
            "Loss in iteration no. 198832 ==> 0.30716832209592504\n",
            "Loss in iteration no. 198833 ==> 0.30716832208133193\n",
            "Loss in iteration no. 198834 ==> 0.30716832206673933\n",
            "Loss in iteration no. 198835 ==> 0.3071683220521463\n",
            "Loss in iteration no. 198836 ==> 0.30716832203755634\n",
            "Loss in iteration no. 198837 ==> 0.3071683220229654\n",
            "Loss in iteration no. 198838 ==> 0.307168322008375\n",
            "Loss in iteration no. 198839 ==> 0.3071683219937867\n",
            "Loss in iteration no. 198840 ==> 0.3071683219791989\n",
            "Loss in iteration no. 198841 ==> 0.30716832196461114\n",
            "Loss in iteration no. 198842 ==> 0.3071683219500254\n",
            "Loss in iteration no. 198843 ==> 0.3071683219354393\n",
            "Loss in iteration no. 198844 ==> 0.30716832192085475\n",
            "Loss in iteration no. 198845 ==> 0.3071683219062707\n",
            "Loss in iteration no. 198846 ==> 0.30716832189168813\n",
            "Loss in iteration no. 198847 ==> 0.3071683218771052\n",
            "Loss in iteration no. 198848 ==> 0.3071683218625242\n",
            "Loss in iteration no. 198849 ==> 0.3071683218479434\n",
            "Loss in iteration no. 198850 ==> 0.30716832183336296\n",
            "Loss in iteration no. 198851 ==> 0.3071683218187837\n",
            "Loss in iteration no. 198852 ==> 0.30716832180420595\n",
            "Loss in iteration no. 198853 ==> 0.30716832178962716\n",
            "Loss in iteration no. 198854 ==> 0.30716832177505043\n",
            "Loss in iteration no. 198855 ==> 0.30716832176047526\n",
            "Loss in iteration no. 198856 ==> 0.3071683217458997\n",
            "Loss in iteration no. 198857 ==> 0.3071683217313256\n",
            "Loss in iteration no. 198858 ==> 0.30716832171675196\n",
            "Loss in iteration no. 198859 ==> 0.30716832170217895\n",
            "Loss in iteration no. 198860 ==> 0.3071683216876065\n",
            "Loss in iteration no. 198861 ==> 0.3071683216730359\n",
            "Loss in iteration no. 198862 ==> 0.3071683216584656\n",
            "Loss in iteration no. 198863 ==> 0.3071683216438957\n",
            "Loss in iteration no. 198864 ==> 0.3071683216293267\n",
            "Loss in iteration no. 198865 ==> 0.30716832161475843\n",
            "Loss in iteration no. 198866 ==> 0.3071683216001911\n",
            "Loss in iteration no. 198867 ==> 0.3071683215856248\n",
            "Loss in iteration no. 198868 ==> 0.30716832157105906\n",
            "Loss in iteration no. 198869 ==> 0.3071683215564948\n",
            "Loss in iteration no. 198870 ==> 0.3071683215419301\n",
            "Loss in iteration no. 198871 ==> 0.3071683215273669\n",
            "Loss in iteration no. 198872 ==> 0.30716832151280427\n",
            "Loss in iteration no. 198873 ==> 0.30716832149824363\n",
            "Loss in iteration no. 198874 ==> 0.30716832148368195\n",
            "Loss in iteration no. 198875 ==> 0.3071683214691218\n",
            "Loss in iteration no. 198876 ==> 0.3071683214545628\n",
            "Loss in iteration no. 198877 ==> 0.30716832144000367\n",
            "Loss in iteration no. 198878 ==> 0.30716832142544676\n",
            "Loss in iteration no. 198879 ==> 0.30716832141089023\n",
            "Loss in iteration no. 198880 ==> 0.30716832139633415\n",
            "Loss in iteration no. 198881 ==> 0.30716832138177863\n",
            "Loss in iteration no. 198882 ==> 0.3071683213672238\n",
            "Loss in iteration no. 198883 ==> 0.30716832135267025\n",
            "Loss in iteration no. 198884 ==> 0.3071683213381173\n",
            "Loss in iteration no. 198885 ==> 0.3071683213235649\n",
            "Loss in iteration no. 198886 ==> 0.30716832130901395\n",
            "Loss in iteration no. 198887 ==> 0.30716832129446303\n",
            "Loss in iteration no. 198888 ==> 0.3071683212799131\n",
            "Loss in iteration no. 198889 ==> 0.30716832126536525\n",
            "Loss in iteration no. 198890 ==> 0.30716832125081645\n",
            "Loss in iteration no. 198891 ==> 0.3071683212362696\n",
            "Loss in iteration no. 198892 ==> 0.3071683212217232\n",
            "Loss in iteration no. 198893 ==> 0.30716832120717735\n",
            "Loss in iteration no. 198894 ==> 0.30716832119263204\n",
            "Loss in iteration no. 198895 ==> 0.3071683211780882\n",
            "Loss in iteration no. 198896 ==> 0.30716832116354487\n",
            "Loss in iteration no. 198897 ==> 0.307168321149002\n",
            "Loss in iteration no. 198898 ==> 0.30716832113445974\n",
            "Loss in iteration no. 198899 ==> 0.3071683211199194\n",
            "Loss in iteration no. 198900 ==> 0.3071683211053791\n",
            "Loss in iteration no. 198901 ==> 0.30716832109083975\n",
            "Loss in iteration no. 198902 ==> 0.3071683210763015\n",
            "Loss in iteration no. 198903 ==> 0.30716832106176317\n",
            "Loss in iteration no. 198904 ==> 0.30716832104722636\n",
            "Loss in iteration no. 198905 ==> 0.3071683210326906\n",
            "Loss in iteration no. 198906 ==> 0.3071683210181548\n",
            "Loss in iteration no. 198907 ==> 0.30716832100362046\n",
            "Loss in iteration no. 198908 ==> 0.30716832098908664\n",
            "Loss in iteration no. 198909 ==> 0.3071683209745537\n",
            "Loss in iteration no. 198910 ==> 0.30716832096002195\n",
            "Loss in iteration no. 198911 ==> 0.3071683209454897\n",
            "Loss in iteration no. 198912 ==> 0.30716832093095875\n",
            "Loss in iteration no. 198913 ==> 0.30716832091643\n",
            "Loss in iteration no. 198914 ==> 0.30716832090190005\n",
            "Loss in iteration no. 198915 ==> 0.3071683208873722\n",
            "Loss in iteration no. 198916 ==> 0.3071683208728449\n",
            "Loss in iteration no. 198917 ==> 0.307168320858319\n",
            "Loss in iteration no. 198918 ==> 0.3071683208437921\n",
            "Loss in iteration no. 198919 ==> 0.3071683208292672\n",
            "Loss in iteration no. 198920 ==> 0.30716832081474277\n",
            "Loss in iteration no. 198921 ==> 0.3071683208002198\n",
            "Loss in iteration no. 198922 ==> 0.3071683207856969\n",
            "Loss in iteration no. 198923 ==> 0.30716832077117495\n",
            "Loss in iteration no. 198924 ==> 0.30716832075665446\n",
            "Loss in iteration no. 198925 ==> 0.30716832074213396\n",
            "Loss in iteration no. 198926 ==> 0.3071683207276145\n",
            "Loss in iteration no. 198927 ==> 0.3071683207130959\n",
            "Loss in iteration no. 198928 ==> 0.30716832069857747\n",
            "Loss in iteration no. 198929 ==> 0.3071683206840609\n",
            "Loss in iteration no. 198930 ==> 0.3071683206695448\n",
            "Loss in iteration no. 198931 ==> 0.3071683206550292\n",
            "Loss in iteration no. 198932 ==> 0.307168320640514\n",
            "Loss in iteration no. 198933 ==> 0.3071683206260004\n",
            "Loss in iteration no. 198934 ==> 0.30716832061148724\n",
            "Loss in iteration no. 198935 ==> 0.3071683205969746\n",
            "Loss in iteration no. 198936 ==> 0.3071683205824638\n",
            "Loss in iteration no. 198937 ==> 0.3071683205679531\n",
            "Loss in iteration no. 198938 ==> 0.3071683205534429\n",
            "Loss in iteration no. 198939 ==> 0.30716832053893356\n",
            "Loss in iteration no. 198940 ==> 0.3071683205244252\n",
            "Loss in iteration no. 198941 ==> 0.3071683205099179\n",
            "Loss in iteration no. 198942 ==> 0.3071683204954111\n",
            "Loss in iteration no. 198943 ==> 0.30716832048090464\n",
            "Loss in iteration no. 198944 ==> 0.30716832046639964\n",
            "Loss in iteration no. 198945 ==> 0.30716832045189524\n",
            "Loss in iteration no. 198946 ==> 0.3071683204373922\n",
            "Loss in iteration no. 198947 ==> 0.30716832042288866\n",
            "Loss in iteration no. 198948 ==> 0.30716832040838665\n",
            "Loss in iteration no. 198949 ==> 0.3071683203938856\n",
            "Loss in iteration no. 198950 ==> 0.30716832037938546\n",
            "Loss in iteration no. 198951 ==> 0.30716832036488584\n",
            "Loss in iteration no. 198952 ==> 0.30716832035038705\n",
            "Loss in iteration no. 198953 ==> 0.30716832033588887\n",
            "Loss in iteration no. 198954 ==> 0.3071683203213915\n",
            "Loss in iteration no. 198955 ==> 0.3071683203068953\n",
            "Loss in iteration no. 198956 ==> 0.30716832029239943\n",
            "Loss in iteration no. 198957 ==> 0.30716832027790497\n",
            "Loss in iteration no. 198958 ==> 0.3071683202634111\n",
            "Loss in iteration no. 198959 ==> 0.30716832024891766\n",
            "Loss in iteration no. 198960 ==> 0.3071683202344246\n",
            "Loss in iteration no. 198961 ==> 0.3071683202199336\n",
            "Loss in iteration no. 198962 ==> 0.3071683202054424\n",
            "Loss in iteration no. 198963 ==> 0.3071683201909523\n",
            "Loss in iteration no. 198964 ==> 0.3071683201764631\n",
            "Loss in iteration no. 198965 ==> 0.3071683201619749\n",
            "Loss in iteration no. 198966 ==> 0.3071683201474867\n",
            "Loss in iteration no. 198967 ==> 0.30716832013300027\n",
            "Loss in iteration no. 198968 ==> 0.30716832011851336\n",
            "Loss in iteration no. 198969 ==> 0.30716832010402795\n",
            "Loss in iteration no. 198970 ==> 0.307168320089544\n",
            "Loss in iteration no. 198971 ==> 0.3071683200750605\n",
            "Loss in iteration no. 198972 ==> 0.30716832006057737\n",
            "Loss in iteration no. 198973 ==> 0.3071683200460948\n",
            "Loss in iteration no. 198974 ==> 0.3071683200316141\n",
            "Loss in iteration no. 198975 ==> 0.3071683200171334\n",
            "Loss in iteration no. 198976 ==> 0.3071683200026536\n",
            "Loss in iteration no. 198977 ==> 0.30716831998817373\n",
            "Loss in iteration no. 198978 ==> 0.3071683199736958\n",
            "Loss in iteration no. 198979 ==> 0.3071683199592179\n",
            "Loss in iteration no. 198980 ==> 0.307168319944742\n",
            "Loss in iteration no. 198981 ==> 0.30716831993026633\n",
            "Loss in iteration no. 198982 ==> 0.3071683199157913\n",
            "Loss in iteration no. 198983 ==> 0.3071683199013166\n",
            "Loss in iteration no. 198984 ==> 0.3071683198868433\n",
            "Loss in iteration no. 198985 ==> 0.3071683198723706\n",
            "Loss in iteration no. 198986 ==> 0.30716831985789866\n",
            "Loss in iteration no. 198987 ==> 0.3071683198434277\n",
            "Loss in iteration no. 198988 ==> 0.3071683198289572\n",
            "Loss in iteration no. 198989 ==> 0.30716831981448756\n",
            "Loss in iteration no. 198990 ==> 0.3071683198000195\n",
            "Loss in iteration no. 198991 ==> 0.3071683197855513\n",
            "Loss in iteration no. 198992 ==> 0.30716831977108416\n",
            "Loss in iteration no. 198993 ==> 0.30716831975661824\n",
            "Loss in iteration no. 198994 ==> 0.3071683197421529\n",
            "Loss in iteration no. 198995 ==> 0.30716831972768793\n",
            "Loss in iteration no. 198996 ==> 0.3071683197132245\n",
            "Loss in iteration no. 198997 ==> 0.3071683196987603\n",
            "Loss in iteration no. 198998 ==> 0.30716831968429875\n",
            "Loss in iteration no. 198999 ==> 0.30716831966983654\n",
            "Loss in iteration no. 199000 ==> 0.3071683196553761\n",
            "Loss in iteration no. 199001 ==> 0.3071683196409159\n",
            "Loss in iteration no. 199002 ==> 0.30716831962645746\n",
            "Loss in iteration no. 199003 ==> 0.3071683196119978\n",
            "Loss in iteration no. 199004 ==> 0.3071683195975402\n",
            "Loss in iteration no. 199005 ==> 0.30716831958308405\n",
            "Loss in iteration no. 199006 ==> 0.3071683195686284\n",
            "Loss in iteration no. 199007 ==> 0.3071683195541732\n",
            "Loss in iteration no. 199008 ==> 0.3071683195397181\n",
            "Loss in iteration no. 199009 ==> 0.3071683195252647\n",
            "Loss in iteration no. 199010 ==> 0.3071683195108116\n",
            "Loss in iteration no. 199011 ==> 0.3071683194963599\n",
            "Loss in iteration no. 199012 ==> 0.30716831948190826\n",
            "Loss in iteration no. 199013 ==> 0.3071683194674575\n",
            "Loss in iteration no. 199014 ==> 0.3071683194530081\n",
            "Loss in iteration no. 199015 ==> 0.3071683194385596\n",
            "Loss in iteration no. 199016 ==> 0.30716831942411155\n",
            "Loss in iteration no. 199017 ==> 0.3071683194096635\n",
            "Loss in iteration no. 199018 ==> 0.30716831939521727\n",
            "Loss in iteration no. 199019 ==> 0.30716831938077144\n",
            "Loss in iteration no. 199020 ==> 0.307168319366327\n",
            "Loss in iteration no. 199021 ==> 0.30716831935188216\n",
            "Loss in iteration no. 199022 ==> 0.3071683193374385\n",
            "Loss in iteration no. 199023 ==> 0.3071683193229969\n",
            "Loss in iteration no. 199024 ==> 0.30716831930855515\n",
            "Loss in iteration no. 199025 ==> 0.30716831929411376\n",
            "Loss in iteration no. 199026 ==> 0.3071683192796733\n",
            "Loss in iteration no. 199027 ==> 0.30716831926523386\n",
            "Loss in iteration no. 199028 ==> 0.3071683192507953\n",
            "Loss in iteration no. 199029 ==> 0.3071683192363576\n",
            "Loss in iteration no. 199030 ==> 0.3071683192219207\n",
            "Loss in iteration no. 199031 ==> 0.30716831920748444\n",
            "Loss in iteration no. 199032 ==> 0.3071683191930484\n",
            "Loss in iteration no. 199033 ==> 0.30716831917861387\n",
            "Loss in iteration no. 199034 ==> 0.30716831916418064\n",
            "Loss in iteration no. 199035 ==> 0.30716831914974685\n",
            "Loss in iteration no. 199036 ==> 0.3071683191353145\n",
            "Loss in iteration no. 199037 ==> 0.307168319120883\n",
            "Loss in iteration no. 199038 ==> 0.30716831910645254\n",
            "Loss in iteration no. 199039 ==> 0.30716831909202286\n",
            "Loss in iteration no. 199040 ==> 0.307168319077593\n",
            "Loss in iteration no. 199041 ==> 0.30716831906316516\n",
            "Loss in iteration no. 199042 ==> 0.30716831904873765\n",
            "Loss in iteration no. 199043 ==> 0.30716831903431113\n",
            "Loss in iteration no. 199044 ==> 0.30716831901988445\n",
            "Loss in iteration no. 199045 ==> 0.3071683190054591\n",
            "Loss in iteration no. 199046 ==> 0.3071683189910353\n",
            "Loss in iteration no. 199047 ==> 0.3071683189766118\n",
            "Loss in iteration no. 199048 ==> 0.3071683189621892\n",
            "Loss in iteration no. 199049 ==> 0.30716831894776647\n",
            "Loss in iteration no. 199050 ==> 0.3071683189333451\n",
            "Loss in iteration no. 199051 ==> 0.30716831891892565\n",
            "Loss in iteration no. 199052 ==> 0.3071683189045052\n",
            "Loss in iteration no. 199053 ==> 0.3071683188900865\n",
            "Loss in iteration no. 199054 ==> 0.30716831887566876\n",
            "Loss in iteration no. 199055 ==> 0.3071683188612509\n",
            "Loss in iteration no. 199056 ==> 0.3071683188468344\n",
            "Loss in iteration no. 199057 ==> 0.3071683188324193\n",
            "Loss in iteration no. 199058 ==> 0.3071683188180045\n",
            "Loss in iteration no. 199059 ==> 0.30716831880359025\n",
            "Loss in iteration no. 199060 ==> 0.3071683187891763\n",
            "Loss in iteration no. 199061 ==> 0.3071683187747637\n",
            "Loss in iteration no. 199062 ==> 0.30716831876035194\n",
            "Loss in iteration no. 199063 ==> 0.3071683187459412\n",
            "Loss in iteration no. 199064 ==> 0.3071683187315313\n",
            "Loss in iteration no. 199065 ==> 0.3071683187171212\n",
            "Loss in iteration no. 199066 ==> 0.3071683187027131\n",
            "Loss in iteration no. 199067 ==> 0.3071683186883048\n",
            "Loss in iteration no. 199068 ==> 0.3071683186738984\n",
            "Loss in iteration no. 199069 ==> 0.30716831865949135\n",
            "Loss in iteration no. 199070 ==> 0.30716831864508676\n",
            "Loss in iteration no. 199071 ==> 0.30716831863068145\n",
            "Loss in iteration no. 199072 ==> 0.3071683186162775\n",
            "Loss in iteration no. 199073 ==> 0.307168318601875\n",
            "Loss in iteration no. 199074 ==> 0.3071683185874723\n",
            "Loss in iteration no. 199075 ==> 0.3071683185730706\n",
            "Loss in iteration no. 199076 ==> 0.30716831855867016\n",
            "Loss in iteration no. 199077 ==> 0.30716831854427057\n",
            "Loss in iteration no. 199078 ==> 0.30716831852987103\n",
            "Loss in iteration no. 199079 ==> 0.30716831851547216\n",
            "Loss in iteration no. 199080 ==> 0.3071683185010748\n",
            "Loss in iteration no. 199081 ==> 0.3071683184866787\n",
            "Loss in iteration no. 199082 ==> 0.30716831847228143\n",
            "Loss in iteration no. 199083 ==> 0.30716831845788717\n",
            "Loss in iteration no. 199084 ==> 0.30716831844349224\n",
            "Loss in iteration no. 199085 ==> 0.3071683184290991\n",
            "Loss in iteration no. 199086 ==> 0.30716831841470593\n",
            "Loss in iteration no. 199087 ==> 0.30716831840031406\n",
            "Loss in iteration no. 199088 ==> 0.3071683183859225\n",
            "Loss in iteration no. 199089 ==> 0.30716831837153186\n",
            "Loss in iteration no. 199090 ==> 0.30716831835714214\n",
            "Loss in iteration no. 199091 ==> 0.3071683183427532\n",
            "Loss in iteration no. 199092 ==> 0.30716831832836566\n",
            "Loss in iteration no. 199093 ==> 0.307168318313978\n",
            "Loss in iteration no. 199094 ==> 0.3071683182995912\n",
            "Loss in iteration no. 199095 ==> 0.30716831828520574\n",
            "Loss in iteration no. 199096 ==> 0.30716831827082053\n",
            "Loss in iteration no. 199097 ==> 0.3071683182564368\n",
            "Loss in iteration no. 199098 ==> 0.3071683182420534\n",
            "Loss in iteration no. 199099 ==> 0.30716831822767077\n",
            "Loss in iteration no. 199100 ==> 0.30716831821328916\n",
            "Loss in iteration no. 199101 ==> 0.30716831819890783\n",
            "Loss in iteration no. 199102 ==> 0.3071683181845273\n",
            "Loss in iteration no. 199103 ==> 0.30716831817014767\n",
            "Loss in iteration no. 199104 ==> 0.3071683181557689\n",
            "Loss in iteration no. 199105 ==> 0.30716831814139145\n",
            "Loss in iteration no. 199106 ==> 0.30716831812701434\n",
            "Loss in iteration no. 199107 ==> 0.3071683181126381\n",
            "Loss in iteration no. 199108 ==> 0.30716831809826173\n",
            "Loss in iteration no. 199109 ==> 0.30716831808388767\n",
            "Loss in iteration no. 199110 ==> 0.3071683180695135\n",
            "Loss in iteration no. 199111 ==> 0.30716831805514117\n",
            "Loss in iteration no. 199112 ==> 0.30716831804076816\n",
            "Loss in iteration no. 199113 ==> 0.30716831802639644\n",
            "Loss in iteration no. 199114 ==> 0.30716831801202565\n",
            "Loss in iteration no. 199115 ==> 0.3071683179976558\n",
            "Loss in iteration no. 199116 ==> 0.30716831798328653\n",
            "Loss in iteration no. 199117 ==> 0.30716831796891786\n",
            "Loss in iteration no. 199118 ==> 0.30716831795454985\n",
            "Loss in iteration no. 199119 ==> 0.3071683179401838\n",
            "Loss in iteration no. 199120 ==> 0.307168317925817\n",
            "Loss in iteration no. 199121 ==> 0.3071683179114515\n",
            "Loss in iteration no. 199122 ==> 0.3071683178970875\n",
            "Loss in iteration no. 199123 ==> 0.30716831788272375\n",
            "Loss in iteration no. 199124 ==> 0.3071683178683603\n",
            "Loss in iteration no. 199125 ==> 0.30716831785399873\n",
            "Loss in iteration no. 199126 ==> 0.307168317839637\n",
            "Loss in iteration no. 199127 ==> 0.3071683178252771\n",
            "Loss in iteration no. 199128 ==> 0.307168317810917\n",
            "Loss in iteration no. 199129 ==> 0.30716831779655784\n",
            "Loss in iteration no. 199130 ==> 0.3071683177821993\n",
            "Loss in iteration no. 199131 ==> 0.30716831776784176\n",
            "Loss in iteration no. 199132 ==> 0.3071683177534855\n",
            "Loss in iteration no. 199133 ==> 0.3071683177391296\n",
            "Loss in iteration no. 199134 ==> 0.30716831772477504\n",
            "Loss in iteration no. 199135 ==> 0.30716831771041975\n",
            "Loss in iteration no. 199136 ==> 0.3071683176960669\n",
            "Loss in iteration no. 199137 ==> 0.30716831768171426\n",
            "Loss in iteration no. 199138 ==> 0.30716831766736247\n",
            "Loss in iteration no. 199139 ==> 0.30716831765301056\n",
            "Loss in iteration no. 199140 ==> 0.30716831763866037\n",
            "Loss in iteration no. 199141 ==> 0.3071683176243111\n",
            "Loss in iteration no. 199142 ==> 0.3071683176099626\n",
            "Loss in iteration no. 199143 ==> 0.3071683175956144\n",
            "Loss in iteration no. 199144 ==> 0.3071683175812671\n",
            "Loss in iteration no. 199145 ==> 0.30716831756692065\n",
            "Loss in iteration no. 199146 ==> 0.30716831755257434\n",
            "Loss in iteration no. 199147 ==> 0.3071683175382295\n",
            "Loss in iteration no. 199148 ==> 0.30716831752388596\n",
            "Loss in iteration no. 199149 ==> 0.3071683175095432\n",
            "Loss in iteration no. 199150 ==> 0.30716831749520035\n",
            "Loss in iteration no. 199151 ==> 0.30716831748085777\n",
            "Loss in iteration no. 199152 ==> 0.3071683174665179\n",
            "Loss in iteration no. 199153 ==> 0.30716831745217693\n",
            "Loss in iteration no. 199154 ==> 0.30716831743783785\n",
            "Loss in iteration no. 199155 ==> 0.3071683174234994\n",
            "Loss in iteration no. 199156 ==> 0.30716831740916095\n",
            "Loss in iteration no. 199157 ==> 0.30716831739482464\n",
            "Loss in iteration no. 199158 ==> 0.3071683173804878\n",
            "Loss in iteration no. 199159 ==> 0.3071683173661522\n",
            "Loss in iteration no. 199160 ==> 0.30716831735181793\n",
            "Loss in iteration no. 199161 ==> 0.30716831733748395\n",
            "Loss in iteration no. 199162 ==> 0.30716831732315125\n",
            "Loss in iteration no. 199163 ==> 0.3071683173088184\n",
            "Loss in iteration no. 199164 ==> 0.30716831729448735\n",
            "Loss in iteration no. 199165 ==> 0.3071683172801572\n",
            "Loss in iteration no. 199166 ==> 0.3071683172658267\n",
            "Loss in iteration no. 199167 ==> 0.30716831725149707\n",
            "Loss in iteration no. 199168 ==> 0.30716831723716825\n",
            "Loss in iteration no. 199169 ==> 0.3071683172228412\n",
            "Loss in iteration no. 199170 ==> 0.3071683172085145\n",
            "Loss in iteration no. 199171 ==> 0.307168317194188\n",
            "Loss in iteration no. 199172 ==> 0.307168317179863\n",
            "Loss in iteration no. 199173 ==> 0.3071683171655381\n",
            "Loss in iteration no. 199174 ==> 0.3071683171512146\n",
            "Loss in iteration no. 199175 ==> 0.30716831713689186\n",
            "Loss in iteration no. 199176 ==> 0.30716831712257\n",
            "Loss in iteration no. 199177 ==> 0.3071683171082483\n",
            "Loss in iteration no. 199178 ==> 0.30716831709392856\n",
            "Loss in iteration no. 199179 ==> 0.3071683170796085\n",
            "Loss in iteration no. 199180 ==> 0.30716831706528924\n",
            "Loss in iteration no. 199181 ==> 0.30716831705097136\n",
            "Loss in iteration no. 199182 ==> 0.3071683170366536\n",
            "Loss in iteration no. 199183 ==> 0.3071683170223368\n",
            "Loss in iteration no. 199184 ==> 0.30716831700802066\n",
            "Loss in iteration no. 199185 ==> 0.30716831699370595\n",
            "Loss in iteration no. 199186 ==> 0.30716831697939195\n",
            "Loss in iteration no. 199187 ==> 0.30716831696507885\n",
            "Loss in iteration no. 199188 ==> 0.3071683169507659\n",
            "Loss in iteration no. 199189 ==> 0.30716831693645325\n",
            "Loss in iteration no. 199190 ==> 0.30716831692214247\n",
            "Loss in iteration no. 199191 ==> 0.30716831690783236\n",
            "Loss in iteration no. 199192 ==> 0.3071683168935221\n",
            "Loss in iteration no. 199193 ==> 0.3071683168792142\n",
            "Loss in iteration no. 199194 ==> 0.3071683168649061\n",
            "Loss in iteration no. 199195 ==> 0.3071683168505987\n",
            "Loss in iteration no. 199196 ==> 0.30716831683629253\n",
            "Loss in iteration no. 199197 ==> 0.3071683168219867\n",
            "Loss in iteration no. 199198 ==> 0.3071683168076811\n",
            "Loss in iteration no. 199199 ==> 0.3071683167933769\n",
            "Loss in iteration no. 199200 ==> 0.3071683167790744\n",
            "Loss in iteration no. 199201 ==> 0.30716831676477163\n",
            "Loss in iteration no. 199202 ==> 0.3071683167504693\n",
            "Loss in iteration no. 199203 ==> 0.3071683167361687\n",
            "Loss in iteration no. 199204 ==> 0.3071683167218688\n",
            "Loss in iteration no. 199205 ==> 0.30716831670756967\n",
            "Loss in iteration no. 199206 ==> 0.3071683166932709\n",
            "Loss in iteration no. 199207 ==> 0.3071683166789728\n",
            "Loss in iteration no. 199208 ==> 0.30716831666467553\n",
            "Loss in iteration no. 199209 ==> 0.3071683166503795\n",
            "Loss in iteration no. 199210 ==> 0.30716831663608385\n",
            "Loss in iteration no. 199211 ==> 0.3071683166217894\n",
            "Loss in iteration no. 199212 ==> 0.3071683166074952\n",
            "Loss in iteration no. 199213 ==> 0.3071683165932028\n",
            "Loss in iteration no. 199214 ==> 0.30716831657891014\n",
            "Loss in iteration no. 199215 ==> 0.30716831656461785\n",
            "Loss in iteration no. 199216 ==> 0.30716831655032717\n",
            "Loss in iteration no. 199217 ==> 0.3071683165360379\n",
            "Loss in iteration no. 199218 ==> 0.3071683165217483\n",
            "Loss in iteration no. 199219 ==> 0.30716831650745957\n",
            "Loss in iteration no. 199220 ==> 0.30716831649317206\n",
            "Loss in iteration no. 199221 ==> 0.30716831647888576\n",
            "Loss in iteration no. 199222 ==> 0.30716831646459974\n",
            "Loss in iteration no. 199223 ==> 0.307168316450314\n",
            "Loss in iteration no. 199224 ==> 0.3071683164360296\n",
            "Loss in iteration no. 199225 ==> 0.3071683164217454\n",
            "Loss in iteration no. 199226 ==> 0.3071683164074624\n",
            "Loss in iteration no. 199227 ==> 0.3071683163931802\n",
            "Loss in iteration no. 199228 ==> 0.3071683163788988\n",
            "Loss in iteration no. 199229 ==> 0.30716831636461817\n",
            "Loss in iteration no. 199230 ==> 0.30716831635033814\n",
            "Loss in iteration no. 199231 ==> 0.307168316336059\n",
            "Loss in iteration no. 199232 ==> 0.30716831632178115\n",
            "Loss in iteration no. 199233 ==> 0.307168316307503\n",
            "Loss in iteration no. 199234 ==> 0.30716831629322666\n",
            "Loss in iteration no. 199235 ==> 0.3071683162789506\n",
            "Loss in iteration no. 199236 ==> 0.30716831626467567\n",
            "Loss in iteration no. 199237 ==> 0.30716831625040153\n",
            "Loss in iteration no. 199238 ==> 0.30716831623612817\n",
            "Loss in iteration no. 199239 ==> 0.3071683162218551\n",
            "Loss in iteration no. 199240 ==> 0.30716831620758367\n",
            "Loss in iteration no. 199241 ==> 0.30716831619331203\n",
            "Loss in iteration no. 199242 ==> 0.30716831617904117\n",
            "Loss in iteration no. 199243 ==> 0.30716831616477114\n",
            "Loss in iteration no. 199244 ==> 0.3071683161505028\n",
            "Loss in iteration no. 199245 ==> 0.30716831613623463\n",
            "Loss in iteration no. 199246 ==> 0.30716831612196727\n",
            "Loss in iteration no. 199247 ==> 0.3071683161077007\n",
            "Loss in iteration no. 199248 ==> 0.3071683160934343\n",
            "Loss in iteration no. 199249 ==> 0.3071683160791696\n",
            "Loss in iteration no. 199250 ==> 0.30716831606490563\n",
            "Loss in iteration no. 199251 ==> 0.3071683160506421\n",
            "Loss in iteration no. 199252 ==> 0.3071683160363797\n",
            "Loss in iteration no. 199253 ==> 0.30716831602211797\n",
            "Loss in iteration no. 199254 ==> 0.30716831600785605\n",
            "Loss in iteration no. 199255 ==> 0.3071683159935959\n",
            "Loss in iteration no. 199256 ==> 0.3071683159793364\n",
            "Loss in iteration no. 199257 ==> 0.30716831596507777\n",
            "Loss in iteration no. 199258 ==> 0.3071683159508203\n",
            "Loss in iteration no. 199259 ==> 0.307168315936563\n",
            "Loss in iteration no. 199260 ==> 0.3071683159223061\n",
            "Loss in iteration no. 199261 ==> 0.30716831590805027\n",
            "Loss in iteration no. 199262 ==> 0.3071683158937958\n",
            "Loss in iteration no. 199263 ==> 0.3071683158795414\n",
            "Loss in iteration no. 199264 ==> 0.3071683158652884\n",
            "Loss in iteration no. 199265 ==> 0.3071683158510361\n",
            "Loss in iteration no. 199266 ==> 0.30716831583678456\n",
            "Loss in iteration no. 199267 ==> 0.3071683158225336\n",
            "Loss in iteration no. 199268 ==> 0.3071683158082825\n",
            "Loss in iteration no. 199269 ==> 0.3071683157940341\n",
            "Loss in iteration no. 199270 ==> 0.307168315779785\n",
            "Loss in iteration no. 199271 ==> 0.307168315765537\n",
            "Loss in iteration no. 199272 ==> 0.3071683157512903\n",
            "Loss in iteration no. 199273 ==> 0.3071683157370439\n",
            "Loss in iteration no. 199274 ==> 0.3071683157227985\n",
            "Loss in iteration no. 199275 ==> 0.3071683157085535\n",
            "Loss in iteration no. 199276 ==> 0.3071683156943097\n",
            "Loss in iteration no. 199277 ==> 0.30716831568006603\n",
            "Loss in iteration no. 199278 ==> 0.30716831566582425\n",
            "Loss in iteration no. 199279 ==> 0.30716831565158215\n",
            "Loss in iteration no. 199280 ==> 0.30716831563734165\n",
            "Loss in iteration no. 199281 ==> 0.307168315623102\n",
            "Loss in iteration no. 199282 ==> 0.307168315608862\n",
            "Loss in iteration no. 199283 ==> 0.3071683155946242\n",
            "Loss in iteration no. 199284 ==> 0.3071683155803867\n",
            "Loss in iteration no. 199285 ==> 0.30716831556614943\n",
            "Loss in iteration no. 199286 ==> 0.3071683155519132\n",
            "Loss in iteration no. 199287 ==> 0.3071683155376784\n",
            "Loss in iteration no. 199288 ==> 0.3071683155234437\n",
            "Loss in iteration no. 199289 ==> 0.30716831550920926\n",
            "Loss in iteration no. 199290 ==> 0.307168315494976\n",
            "Loss in iteration no. 199291 ==> 0.3071683154807445\n",
            "Loss in iteration no. 199292 ==> 0.30716831546651274\n",
            "Loss in iteration no. 199293 ==> 0.3071683154522825\n",
            "Loss in iteration no. 199294 ==> 0.3071683154380527\n",
            "Loss in iteration no. 199295 ==> 0.3071683154238225\n",
            "Loss in iteration no. 199296 ==> 0.307168315409595\n",
            "Loss in iteration no. 199297 ==> 0.3071683153953668\n",
            "Loss in iteration no. 199298 ==> 0.3071683153811407\n",
            "Loss in iteration no. 199299 ==> 0.30716831536691386\n",
            "Loss in iteration no. 199300 ==> 0.30716831535268924\n",
            "Loss in iteration no. 199301 ==> 0.3071683153384647\n",
            "Loss in iteration no. 199302 ==> 0.3071683153242411\n",
            "Loss in iteration no. 199303 ==> 0.30716831531001815\n",
            "Loss in iteration no. 199304 ==> 0.30716831529579625\n",
            "Loss in iteration no. 199305 ==> 0.3071683152815751\n",
            "Loss in iteration no. 199306 ==> 0.3071683152673537\n",
            "Loss in iteration no. 199307 ==> 0.30716831525313404\n",
            "Loss in iteration no. 199308 ==> 0.3071683152389156\n",
            "Loss in iteration no. 199309 ==> 0.3071683152246972\n",
            "Loss in iteration no. 199310 ==> 0.30716831521048016\n",
            "Loss in iteration no. 199311 ==> 0.3071683151962632\n",
            "Loss in iteration no. 199312 ==> 0.30716831518204746\n",
            "Loss in iteration no. 199313 ==> 0.307168315167832\n",
            "Loss in iteration no. 199314 ==> 0.3071683151536177\n",
            "Loss in iteration no. 199315 ==> 0.3071683151394035\n",
            "Loss in iteration no. 199316 ==> 0.30716831512519116\n",
            "Loss in iteration no. 199317 ==> 0.30716831511097936\n",
            "Loss in iteration no. 199318 ==> 0.3071683150967684\n",
            "Loss in iteration no. 199319 ==> 0.30716831508255704\n",
            "Loss in iteration no. 199320 ==> 0.30716831506834835\n",
            "Loss in iteration no. 199321 ==> 0.30716831505413894\n",
            "Loss in iteration no. 199322 ==> 0.30716831503993064\n",
            "Loss in iteration no. 199323 ==> 0.30716831502572356\n",
            "Loss in iteration no. 199324 ==> 0.30716831501151776\n",
            "Loss in iteration no. 199325 ==> 0.307168314997311\n",
            "Loss in iteration no. 199326 ==> 0.3071683149831065\n",
            "Loss in iteration no. 199327 ==> 0.3071683149689021\n",
            "Loss in iteration no. 199328 ==> 0.30716831495469804\n",
            "Loss in iteration no. 199329 ==> 0.3071683149404956\n",
            "Loss in iteration no. 199330 ==> 0.3071683149262938\n",
            "Loss in iteration no. 199331 ==> 0.3071683149120927\n",
            "Loss in iteration no. 199332 ==> 0.3071683148978923\n",
            "Loss in iteration no. 199333 ==> 0.3071683148836926\n",
            "Loss in iteration no. 199334 ==> 0.30716831486949403\n",
            "Loss in iteration no. 199335 ==> 0.3071683148552967\n",
            "Loss in iteration no. 199336 ==> 0.3071683148410996\n",
            "Loss in iteration no. 199337 ==> 0.3071683148269025\n",
            "Loss in iteration no. 199338 ==> 0.30716831481270673\n",
            "Loss in iteration no. 199339 ==> 0.3071683147985121\n",
            "Loss in iteration no. 199340 ==> 0.30716831478431766\n",
            "Loss in iteration no. 199341 ==> 0.3071683147701249\n",
            "Loss in iteration no. 199342 ==> 0.30716831475593176\n",
            "Loss in iteration no. 199343 ==> 0.30716831474174033\n",
            "Loss in iteration no. 199344 ==> 0.30716831472754846\n",
            "Loss in iteration no. 199345 ==> 0.3071683147133585\n",
            "Loss in iteration no. 199346 ==> 0.3071683146991696\n",
            "Loss in iteration no. 199347 ==> 0.30716831468498035\n",
            "Loss in iteration no. 199348 ==> 0.30716831467079286\n",
            "Loss in iteration no. 199349 ==> 0.30716831465660543\n",
            "Loss in iteration no. 199350 ==> 0.3071683146424193\n",
            "Loss in iteration no. 199351 ==> 0.30716831462823363\n",
            "Loss in iteration no. 199352 ==> 0.3071683146140487\n",
            "Loss in iteration no. 199353 ==> 0.30716831459986504\n",
            "Loss in iteration no. 199354 ==> 0.30716831458568156\n",
            "Loss in iteration no. 199355 ==> 0.3071683145714996\n",
            "Loss in iteration no. 199356 ==> 0.3071683145573174\n",
            "Loss in iteration no. 199357 ==> 0.30716831454313687\n",
            "Loss in iteration no. 199358 ==> 0.3071683145289565\n",
            "Loss in iteration no. 199359 ==> 0.3071683145147767\n",
            "Loss in iteration no. 199360 ==> 0.3071683145005987\n",
            "Loss in iteration no. 199361 ==> 0.30716831448642073\n",
            "Loss in iteration no. 199362 ==> 0.30716831447224413\n",
            "Loss in iteration no. 199363 ==> 0.30716831445806747\n",
            "Loss in iteration no. 199364 ==> 0.3071683144438921\n",
            "Loss in iteration no. 199365 ==> 0.3071683144297173\n",
            "Loss in iteration no. 199366 ==> 0.30716831441554315\n",
            "Loss in iteration no. 199367 ==> 0.30716831440137027\n",
            "Loss in iteration no. 199368 ==> 0.30716831438719805\n",
            "Loss in iteration no. 199369 ==> 0.3071683143730264\n",
            "Loss in iteration no. 199370 ==> 0.30716831435885544\n",
            "Loss in iteration no. 199371 ==> 0.3071683143446856\n",
            "Loss in iteration no. 199372 ==> 0.307168314330516\n",
            "Loss in iteration no. 199373 ==> 0.307168314316347\n",
            "Loss in iteration no. 199374 ==> 0.3071683143021796\n",
            "Loss in iteration no. 199375 ==> 0.30716831428801245\n",
            "Loss in iteration no. 199376 ==> 0.3071683142738464\n",
            "Loss in iteration no. 199377 ==> 0.30716831425968094\n",
            "Loss in iteration no. 199378 ==> 0.30716831424551616\n",
            "Loss in iteration no. 199379 ==> 0.30716831423135266\n",
            "Loss in iteration no. 199380 ==> 0.30716831421718965\n",
            "Loss in iteration no. 199381 ==> 0.30716831420302737\n",
            "Loss in iteration no. 199382 ==> 0.3071683141888657\n",
            "Loss in iteration no. 199383 ==> 0.3071683141747047\n",
            "Loss in iteration no. 199384 ==> 0.3071683141605454\n",
            "Loss in iteration no. 199385 ==> 0.3071683141463861\n",
            "Loss in iteration no. 199386 ==> 0.30716831413222806\n",
            "Loss in iteration no. 199387 ==> 0.30716831411807016\n",
            "Loss in iteration no. 199388 ==> 0.3071683141039133\n",
            "Loss in iteration no. 199389 ==> 0.30716831408975664\n",
            "Loss in iteration no. 199390 ==> 0.3071683140756012\n",
            "Loss in iteration no. 199391 ==> 0.30716831406144685\n",
            "Loss in iteration no. 199392 ==> 0.30716831404729317\n",
            "Loss in iteration no. 199393 ==> 0.30716831403314004\n",
            "Loss in iteration no. 199394 ==> 0.30716831401898853\n",
            "Loss in iteration no. 199395 ==> 0.3071683140048368\n",
            "Loss in iteration no. 199396 ==> 0.30716831399068556\n",
            "Loss in iteration no. 199397 ==> 0.30716831397653654\n",
            "Loss in iteration no. 199398 ==> 0.3071683139623872\n",
            "Loss in iteration no. 199399 ==> 0.30716831394823846\n",
            "Loss in iteration no. 199400 ==> 0.3071683139340907\n",
            "Loss in iteration no. 199401 ==> 0.30716831391994426\n",
            "Loss in iteration no. 199402 ==> 0.30716831390579835\n",
            "Loss in iteration no. 199403 ==> 0.30716831389165317\n",
            "Loss in iteration no. 199404 ==> 0.30716831387750804\n",
            "Loss in iteration no. 199405 ==> 0.307168313863364\n",
            "Loss in iteration no. 199406 ==> 0.3071683138492217\n",
            "Loss in iteration no. 199407 ==> 0.307168313835079\n",
            "Loss in iteration no. 199408 ==> 0.30716831382093784\n",
            "Loss in iteration no. 199409 ==> 0.30716831380679793\n",
            "Loss in iteration no. 199410 ==> 0.307168313792658\n",
            "Loss in iteration no. 199411 ==> 0.3071683137785189\n",
            "Loss in iteration no. 199412 ==> 0.30716831376438025\n",
            "Loss in iteration no. 199413 ==> 0.30716831375024284\n",
            "Loss in iteration no. 199414 ==> 0.30716831373610554\n",
            "Loss in iteration no. 199415 ==> 0.3071683137219708\n",
            "Loss in iteration no. 199416 ==> 0.30716831370783465\n",
            "Loss in iteration no. 199417 ==> 0.30716831369370073\n",
            "Loss in iteration no. 199418 ==> 0.3071683136795673\n",
            "Loss in iteration no. 199419 ==> 0.3071683136654336\n",
            "Loss in iteration no. 199420 ==> 0.30716831365130254\n",
            "Loss in iteration no. 199421 ==> 0.307168313637171\n",
            "Loss in iteration no. 199422 ==> 0.30716831362304015\n",
            "Loss in iteration no. 199423 ==> 0.3071683136089104\n",
            "Loss in iteration no. 199424 ==> 0.3071683135947817\n",
            "Loss in iteration no. 199425 ==> 0.3071683135806532\n",
            "Loss in iteration no. 199426 ==> 0.3071683135665258\n",
            "Loss in iteration no. 199427 ==> 0.3071683135523995\n",
            "Loss in iteration no. 199428 ==> 0.3071683135382733\n",
            "Loss in iteration no. 199429 ==> 0.30716831352414825\n",
            "Loss in iteration no. 199430 ==> 0.3071683135100233\n",
            "Loss in iteration no. 199431 ==> 0.3071683134958999\n",
            "Loss in iteration no. 199432 ==> 0.30716831348177714\n",
            "Loss in iteration no. 199433 ==> 0.30716831346765505\n",
            "Loss in iteration no. 199434 ==> 0.307168313453534\n",
            "Loss in iteration no. 199435 ==> 0.3071683134394136\n",
            "Loss in iteration no. 199436 ==> 0.30716831342529377\n",
            "Loss in iteration no. 199437 ==> 0.3071683134111751\n",
            "Loss in iteration no. 199438 ==> 0.30716831339705647\n",
            "Loss in iteration no. 199439 ==> 0.30716831338293904\n",
            "Loss in iteration no. 199440 ==> 0.3071683133688226\n",
            "Loss in iteration no. 199441 ==> 0.30716831335470635\n",
            "Loss in iteration no. 199442 ==> 0.30716831334059175\n",
            "Loss in iteration no. 199443 ==> 0.30716831332647765\n",
            "Loss in iteration no. 199444 ==> 0.3071683133123636\n",
            "Loss in iteration no. 199445 ==> 0.30716831329825117\n",
            "Loss in iteration no. 199446 ==> 0.307168313284139\n",
            "Loss in iteration no. 199447 ==> 0.3071683132700273\n",
            "Loss in iteration no. 199448 ==> 0.3071683132559172\n",
            "Loss in iteration no. 199449 ==> 0.3071683132418072\n",
            "Loss in iteration no. 199450 ==> 0.3071683132276984\n",
            "Loss in iteration no. 199451 ==> 0.30716831321359067\n",
            "Loss in iteration no. 199452 ==> 0.3071683131994829\n",
            "Loss in iteration no. 199453 ==> 0.30716831318537635\n",
            "Loss in iteration no. 199454 ==> 0.3071683131712709\n",
            "Loss in iteration no. 199455 ==> 0.30716831315716536\n",
            "Loss in iteration no. 199456 ==> 0.30716831314306164\n",
            "Loss in iteration no. 199457 ==> 0.3071683131289573\n",
            "Loss in iteration no. 199458 ==> 0.3071683131148548\n",
            "Loss in iteration no. 199459 ==> 0.30716831310075277\n",
            "Loss in iteration no. 199460 ==> 0.3071683130866523\n",
            "Loss in iteration no. 199461 ==> 0.307168313072552\n",
            "Loss in iteration no. 199462 ==> 0.30716831305845166\n",
            "Loss in iteration no. 199463 ==> 0.30716831304435355\n",
            "Loss in iteration no. 199464 ==> 0.3071683130302554\n",
            "Loss in iteration no. 199465 ==> 0.3071683130161574\n",
            "Loss in iteration no. 199466 ==> 0.30716831300206143\n",
            "Loss in iteration no. 199467 ==> 0.3071683129879656\n",
            "Loss in iteration no. 199468 ==> 0.3071683129738698\n",
            "Loss in iteration no. 199469 ==> 0.3071683129597757\n",
            "Loss in iteration no. 199470 ==> 0.3071683129456821\n",
            "Loss in iteration no. 199471 ==> 0.30716831293159014\n",
            "Loss in iteration no. 199472 ==> 0.3071683129174982\n",
            "Loss in iteration no. 199473 ==> 0.30716831290340685\n",
            "Loss in iteration no. 199474 ==> 0.307168312889316\n",
            "Loss in iteration no. 199475 ==> 0.30716831287522733\n",
            "Loss in iteration no. 199476 ==> 0.30716831286113777\n",
            "Loss in iteration no. 199477 ==> 0.3071683128470502\n",
            "Loss in iteration no. 199478 ==> 0.3071683128329628\n",
            "Loss in iteration no. 199479 ==> 0.3071683128188764\n",
            "Loss in iteration no. 199480 ==> 0.3071683128047902\n",
            "Loss in iteration no. 199481 ==> 0.3071683127907053\n",
            "Loss in iteration no. 199482 ==> 0.30716831277662116\n",
            "Loss in iteration no. 199483 ==> 0.3071683127625376\n",
            "Loss in iteration no. 199484 ==> 0.3071683127484545\n",
            "Loss in iteration no. 199485 ==> 0.3071683127343731\n",
            "Loss in iteration no. 199486 ==> 0.3071683127202918\n",
            "Loss in iteration no. 199487 ==> 0.3071683127062109\n",
            "Loss in iteration no. 199488 ==> 0.3071683126921317\n",
            "Loss in iteration no. 199489 ==> 0.30716831267805256\n",
            "Loss in iteration no. 199490 ==> 0.3071683126639745\n",
            "Loss in iteration no. 199491 ==> 0.3071683126498974\n",
            "Loss in iteration no. 199492 ==> 0.30716831263582195\n",
            "Loss in iteration no. 199493 ==> 0.3071683126217461\n",
            "Loss in iteration no. 199494 ==> 0.3071683126076703\n",
            "Loss in iteration no. 199495 ==> 0.307168312593597\n",
            "Loss in iteration no. 199496 ==> 0.3071683125795233\n",
            "Loss in iteration no. 199497 ==> 0.30716831256545013\n",
            "Loss in iteration no. 199498 ==> 0.3071683125513791\n",
            "Loss in iteration no. 199499 ==> 0.30716831253730764\n",
            "Loss in iteration no. 199500 ==> 0.3071683125232367\n",
            "Loss in iteration no. 199501 ==> 0.3071683125091677\n",
            "Loss in iteration no. 199502 ==> 0.3071683124950989\n",
            "Loss in iteration no. 199503 ==> 0.3071683124810301\n",
            "Loss in iteration no. 199504 ==> 0.3071683124669634\n",
            "Loss in iteration no. 199505 ==> 0.3071683124528968\n",
            "Loss in iteration no. 199506 ==> 0.30716831243883164\n",
            "Loss in iteration no. 199507 ==> 0.30716831242476617\n",
            "Loss in iteration no. 199508 ==> 0.3071683124107021\n",
            "Loss in iteration no. 199509 ==> 0.3071683123966387\n",
            "Loss in iteration no. 199510 ==> 0.30716831238257575\n",
            "Loss in iteration no. 199511 ==> 0.3071683123685135\n",
            "Loss in iteration no. 199512 ==> 0.30716831235445263\n",
            "Loss in iteration no. 199513 ==> 0.30716831234039293\n",
            "Loss in iteration no. 199514 ==> 0.30716831232633324\n",
            "Loss in iteration no. 199515 ==> 0.30716831231227465\n",
            "Loss in iteration no. 199516 ==> 0.307168312298216\n",
            "Loss in iteration no. 199517 ==> 0.30716831228415853\n",
            "Loss in iteration no. 199518 ==> 0.307168312270102\n",
            "Loss in iteration no. 199519 ==> 0.30716831225604707\n",
            "Loss in iteration no. 199520 ==> 0.3071683122419917\n",
            "Loss in iteration no. 199521 ==> 0.3071683122279379\n",
            "Loss in iteration no. 199522 ==> 0.3071683122138845\n",
            "Loss in iteration no. 199523 ==> 0.30716831219983176\n",
            "Loss in iteration no. 199524 ==> 0.3071683121857796\n",
            "Loss in iteration no. 199525 ==> 0.30716831217172896\n",
            "Loss in iteration no. 199526 ==> 0.30716831215767826\n",
            "Loss in iteration no. 199527 ==> 0.30716831214362866\n",
            "Loss in iteration no. 199528 ==> 0.3071683121295802\n",
            "Loss in iteration no. 199529 ==> 0.3071683121155316\n",
            "Loss in iteration no. 199530 ==> 0.3071683121014841\n",
            "Loss in iteration no. 199531 ==> 0.30716831208743817\n",
            "Loss in iteration no. 199532 ==> 0.30716831207339285\n",
            "Loss in iteration no. 199533 ==> 0.3071683120593474\n",
            "Loss in iteration no. 199534 ==> 0.30716831204530365\n",
            "Loss in iteration no. 199535 ==> 0.3071683120312593\n",
            "Loss in iteration no. 199536 ==> 0.30716831201721756\n",
            "Loss in iteration no. 199537 ==> 0.3071683120031758\n",
            "Loss in iteration no. 199538 ==> 0.30716831198913414\n",
            "Loss in iteration no. 199539 ==> 0.30716831197509403\n",
            "Loss in iteration no. 199540 ==> 0.3071683119610544\n",
            "Loss in iteration no. 199541 ==> 0.30716831194701577\n",
            "Loss in iteration no. 199542 ==> 0.3071683119329777\n",
            "Loss in iteration no. 199543 ==> 0.3071683119189402\n",
            "Loss in iteration no. 199544 ==> 0.30716831190490373\n",
            "Loss in iteration no. 199545 ==> 0.3071683118908682\n",
            "Loss in iteration no. 199546 ==> 0.30716831187683324\n",
            "Loss in iteration no. 199547 ==> 0.30716831186279886\n",
            "Loss in iteration no. 199548 ==> 0.3071683118487659\n",
            "Loss in iteration no. 199549 ==> 0.3071683118347331\n",
            "Loss in iteration no. 199550 ==> 0.30716831182070076\n",
            "Loss in iteration no. 199551 ==> 0.30716831180666987\n",
            "Loss in iteration no. 199552 ==> 0.30716831179263904\n",
            "Loss in iteration no. 199553 ==> 0.3071683117786103\n",
            "Loss in iteration no. 199554 ==> 0.30716831176458054\n",
            "Loss in iteration no. 199555 ==> 0.30716831175055276\n",
            "Loss in iteration no. 199556 ==> 0.3071683117365251\n",
            "Loss in iteration no. 199557 ==> 0.30716831172249986\n",
            "Loss in iteration no. 199558 ==> 0.30716831170847314\n",
            "Loss in iteration no. 199559 ==> 0.307168311694449\n",
            "Loss in iteration no. 199560 ==> 0.30716831168042436\n",
            "Loss in iteration no. 199561 ==> 0.3071683116664013\n",
            "Loss in iteration no. 199562 ==> 0.3071683116523777\n",
            "Loss in iteration no. 199563 ==> 0.30716831163835656\n",
            "Loss in iteration no. 199564 ==> 0.3071683116243355\n",
            "Loss in iteration no. 199565 ==> 0.3071683116103154\n",
            "Loss in iteration no. 199566 ==> 0.30716831159629526\n",
            "Loss in iteration no. 199567 ==> 0.30716831158227625\n",
            "Loss in iteration no. 199568 ==> 0.30716831156825825\n",
            "Loss in iteration no. 199569 ==> 0.3071683115542412\n",
            "Loss in iteration no. 199570 ==> 0.3071683115402247\n",
            "Loss in iteration no. 199571 ==> 0.30716831152620866\n",
            "Loss in iteration no. 199572 ==> 0.3071683115121936\n",
            "Loss in iteration no. 199573 ==> 0.3071683114981792\n",
            "Loss in iteration no. 199574 ==> 0.3071683114841667\n",
            "Loss in iteration no. 199575 ==> 0.30716831147015267\n",
            "Loss in iteration no. 199576 ==> 0.30716831145614126\n",
            "Loss in iteration no. 199577 ==> 0.30716831144213075\n",
            "Loss in iteration no. 199578 ==> 0.3071683114281203\n",
            "Loss in iteration no. 199579 ==> 0.3071683114141098\n",
            "Loss in iteration no. 199580 ==> 0.3071683114001013\n",
            "Loss in iteration no. 199581 ==> 0.30716831138609296\n",
            "Loss in iteration no. 199582 ==> 0.3071683113720854\n",
            "Loss in iteration no. 199583 ==> 0.3071683113580794\n",
            "Loss in iteration no. 199584 ==> 0.3071683113440731\n",
            "Loss in iteration no. 199585 ==> 0.3071683113300691\n",
            "Loss in iteration no. 199586 ==> 0.3071683113160646\n",
            "Loss in iteration no. 199587 ==> 0.3071683113020606\n",
            "Loss in iteration no. 199588 ==> 0.3071683112880581\n",
            "Loss in iteration no. 199589 ==> 0.30716831127405625\n",
            "Loss in iteration no. 199590 ==> 0.30716831126005517\n",
            "Loss in iteration no. 199591 ==> 0.30716831124605415\n",
            "Loss in iteration no. 199592 ==> 0.30716831123205524\n",
            "Loss in iteration no. 199593 ==> 0.30716831121805616\n",
            "Loss in iteration no. 199594 ==> 0.30716831120405724\n",
            "Loss in iteration no. 199595 ==> 0.30716831119006066\n",
            "Loss in iteration no. 199596 ==> 0.30716831117606364\n",
            "Loss in iteration no. 199597 ==> 0.30716831116206755\n",
            "Loss in iteration no. 199598 ==> 0.3071683111480731\n",
            "Loss in iteration no. 199599 ==> 0.30716831113407805\n",
            "Loss in iteration no. 199600 ==> 0.30716831112008547\n",
            "Loss in iteration no. 199601 ==> 0.30716831110609294\n",
            "Loss in iteration no. 199602 ==> 0.30716831109210024\n",
            "Loss in iteration no. 199603 ==> 0.30716831107810916\n",
            "Loss in iteration no. 199604 ==> 0.3071683110641185\n",
            "Loss in iteration no. 199605 ==> 0.30716831105012893\n",
            "Loss in iteration no. 199606 ==> 0.30716831103613973\n",
            "Loss in iteration no. 199607 ==> 0.3071683110221521\n",
            "Loss in iteration no. 199608 ==> 0.30716831100816444\n",
            "Loss in iteration no. 199609 ==> 0.30716831099417763\n",
            "Loss in iteration no. 199610 ==> 0.3071683109801915\n",
            "Loss in iteration no. 199611 ==> 0.30716831096620667\n",
            "Loss in iteration no. 199612 ==> 0.30716831095222247\n",
            "Loss in iteration no. 199613 ==> 0.30716831093823915\n",
            "Loss in iteration no. 199614 ==> 0.30716831092425534\n",
            "Loss in iteration no. 199615 ==> 0.30716831091027397\n",
            "Loss in iteration no. 199616 ==> 0.30716831089629265\n",
            "Loss in iteration no. 199617 ==> 0.30716831088231217\n",
            "Loss in iteration no. 199618 ==> 0.3071683108683328\n",
            "Loss in iteration no. 199619 ==> 0.30716831085435337\n",
            "Loss in iteration no. 199620 ==> 0.30716831084037494\n",
            "Loss in iteration no. 199621 ==> 0.30716831082639795\n",
            "Loss in iteration no. 199622 ==> 0.3071683108124214\n",
            "Loss in iteration no. 199623 ==> 0.30716831079844525\n",
            "Loss in iteration no. 199624 ==> 0.30716831078446977\n",
            "Loss in iteration no. 199625 ==> 0.30716831077049567\n",
            "Loss in iteration no. 199626 ==> 0.307168310756522\n",
            "Loss in iteration no. 199627 ==> 0.30716831074254886\n",
            "Loss in iteration no. 199628 ==> 0.30716831072857664\n",
            "Loss in iteration no. 199629 ==> 0.3071683107146054\n",
            "Loss in iteration no. 199630 ==> 0.3071683107006351\n",
            "Loss in iteration no. 199631 ==> 0.30716831068666484\n",
            "Loss in iteration no. 199632 ==> 0.30716831067269645\n",
            "Loss in iteration no. 199633 ==> 0.30716831065872807\n",
            "Loss in iteration no. 199634 ==> 0.3071683106447602\n",
            "Loss in iteration no. 199635 ==> 0.3071683106307937\n",
            "Loss in iteration no. 199636 ==> 0.30716831061682726\n",
            "Loss in iteration no. 199637 ==> 0.30716831060286215\n",
            "Loss in iteration no. 199638 ==> 0.30716831058889815\n",
            "Loss in iteration no. 199639 ==> 0.3071683105749345\n",
            "Loss in iteration no. 199640 ==> 0.30716831056097127\n",
            "Loss in iteration no. 199641 ==> 0.30716831054700916\n",
            "Loss in iteration no. 199642 ==> 0.30716831053304794\n",
            "Loss in iteration no. 199643 ==> 0.30716831051908766\n",
            "Loss in iteration no. 199644 ==> 0.30716831050512733\n",
            "Loss in iteration no. 199645 ==> 0.30716831049116794\n",
            "Loss in iteration no. 199646 ==> 0.30716831047720955\n",
            "Loss in iteration no. 199647 ==> 0.30716831046325255\n",
            "Loss in iteration no. 199648 ==> 0.307168310449295\n",
            "Loss in iteration no. 199649 ==> 0.30716831043533954\n",
            "Loss in iteration no. 199650 ==> 0.30716831042138437\n",
            "Loss in iteration no. 199651 ==> 0.30716831040743026\n",
            "Loss in iteration no. 199652 ==> 0.3071683103934755\n",
            "Loss in iteration no. 199653 ==> 0.30716831037952225\n",
            "Loss in iteration no. 199654 ==> 0.30716831036557096\n",
            "Loss in iteration no. 199655 ==> 0.30716831035161957\n",
            "Loss in iteration no. 199656 ==> 0.30716831033766817\n",
            "Loss in iteration no. 199657 ==> 0.3071683103237187\n",
            "Loss in iteration no. 199658 ==> 0.3071683103097691\n",
            "Loss in iteration no. 199659 ==> 0.3071683102958211\n",
            "Loss in iteration no. 199660 ==> 0.30716831028187347\n",
            "Loss in iteration no. 199661 ==> 0.30716831026792574\n",
            "Loss in iteration no. 199662 ==> 0.3071683102539805\n",
            "Loss in iteration no. 199663 ==> 0.30716831024003477\n",
            "Loss in iteration no. 199664 ==> 0.3071683102260903\n",
            "Loss in iteration no. 199665 ==> 0.3071683102121469\n",
            "Loss in iteration no. 199666 ==> 0.3071683101982029\n",
            "Loss in iteration no. 199667 ==> 0.30716831018426133\n",
            "Loss in iteration no. 199668 ==> 0.3071683101703198\n",
            "Loss in iteration no. 199669 ==> 0.30716831015637813\n",
            "Loss in iteration no. 199670 ==> 0.30716831014243845\n",
            "Loss in iteration no. 199671 ==> 0.3071683101285001\n",
            "Loss in iteration no. 199672 ==> 0.3071683101145612\n",
            "Loss in iteration no. 199673 ==> 0.3071683101006233\n",
            "Loss in iteration no. 199674 ==> 0.3071683100866868\n",
            "Loss in iteration no. 199675 ==> 0.30716831007274975\n",
            "Loss in iteration no. 199676 ==> 0.30716831005881506\n",
            "Loss in iteration no. 199677 ==> 0.3071683100448799\n",
            "Loss in iteration no. 199678 ==> 0.30716831003094613\n",
            "Loss in iteration no. 199679 ==> 0.30716831001701334\n",
            "Loss in iteration no. 199680 ==> 0.3071683100030805\n",
            "Loss in iteration no. 199681 ==> 0.3071683099891494\n",
            "Loss in iteration no. 199682 ==> 0.30716830997521843\n",
            "Loss in iteration no. 199683 ==> 0.3071683099612883\n",
            "Loss in iteration no. 199684 ==> 0.30716830994735805\n",
            "Loss in iteration no. 199685 ==> 0.3071683099334298\n",
            "Loss in iteration no. 199686 ==> 0.30716830991950195\n",
            "Loss in iteration no. 199687 ==> 0.3071683099055746\n",
            "Loss in iteration no. 199688 ==> 0.30716830989164856\n",
            "Loss in iteration no. 199689 ==> 0.307168309877723\n",
            "Loss in iteration no. 199690 ==> 0.30716830986379884\n",
            "Loss in iteration no. 199691 ==> 0.30716830984987453\n",
            "Loss in iteration no. 199692 ==> 0.30716830983595134\n",
            "Loss in iteration no. 199693 ==> 0.3071683098220285\n",
            "Loss in iteration no. 199694 ==> 0.30716830980810694\n",
            "Loss in iteration no. 199695 ==> 0.30716830979418697\n",
            "Loss in iteration no. 199696 ==> 0.30716830978026627\n",
            "Loss in iteration no. 199697 ==> 0.30716830976634657\n",
            "Loss in iteration no. 199698 ==> 0.30716830975242776\n",
            "Loss in iteration no. 199699 ==> 0.3071683097385105\n",
            "Loss in iteration no. 199700 ==> 0.3071683097245924\n",
            "Loss in iteration no. 199701 ==> 0.307168309710677\n",
            "Loss in iteration no. 199702 ==> 0.3071683096967608\n",
            "Loss in iteration no. 199703 ==> 0.30716830968284603\n",
            "Loss in iteration no. 199704 ==> 0.3071683096689322\n",
            "Loss in iteration no. 199705 ==> 0.30716830965501885\n",
            "Loss in iteration no. 199706 ==> 0.30716830964110586\n",
            "Loss in iteration no. 199707 ==> 0.30716830962719377\n",
            "Loss in iteration no. 199708 ==> 0.30716830961328256\n",
            "Loss in iteration no. 199709 ==> 0.30716830959937286\n",
            "Loss in iteration no. 199710 ==> 0.3071683095854635\n",
            "Loss in iteration no. 199711 ==> 0.30716830957155405\n",
            "Loss in iteration no. 199712 ==> 0.30716830955764657\n",
            "Loss in iteration no. 199713 ==> 0.3071683095437394\n",
            "Loss in iteration no. 199714 ==> 0.30716830952983265\n",
            "Loss in iteration no. 199715 ==> 0.3071683095159274\n",
            "Loss in iteration no. 199716 ==> 0.30716830950202195\n",
            "Loss in iteration no. 199717 ==> 0.30716830948811796\n",
            "Loss in iteration no. 199718 ==> 0.30716830947421436\n",
            "Loss in iteration no. 199719 ==> 0.3071683094603116\n",
            "Loss in iteration no. 199720 ==> 0.30716830944640977\n",
            "Loss in iteration no. 199721 ==> 0.3071683094325089\n",
            "Loss in iteration no. 199722 ==> 0.3071683094186084\n",
            "Loss in iteration no. 199723 ==> 0.30716830940470924\n",
            "Loss in iteration no. 199724 ==> 0.3071683093908101\n",
            "Loss in iteration no. 199725 ==> 0.30716830937691175\n",
            "Loss in iteration no. 199726 ==> 0.3071683093630148\n",
            "Loss in iteration no. 199727 ==> 0.3071683093491173\n",
            "Loss in iteration no. 199728 ==> 0.3071683093352221\n",
            "Loss in iteration no. 199729 ==> 0.3071683093213269\n",
            "Loss in iteration no. 199730 ==> 0.30716830930743255\n",
            "Loss in iteration no. 199731 ==> 0.3071683092935386\n",
            "Loss in iteration no. 199732 ==> 0.30716830927964595\n",
            "Loss in iteration no. 199733 ==> 0.30716830926575434\n",
            "Loss in iteration no. 199734 ==> 0.30716830925186306\n",
            "Loss in iteration no. 199735 ==> 0.3071683092379721\n",
            "Loss in iteration no. 199736 ==> 0.30716830922408317\n",
            "Loss in iteration no. 199737 ==> 0.30716830921019406\n",
            "Loss in iteration no. 199738 ==> 0.3071683091963053\n",
            "Loss in iteration no. 199739 ==> 0.307168309182418\n",
            "Loss in iteration no. 199740 ==> 0.30716830916853105\n",
            "Loss in iteration no. 199741 ==> 0.30716830915464555\n",
            "Loss in iteration no. 199742 ==> 0.30716830914076027\n",
            "Loss in iteration no. 199743 ==> 0.307168309126876\n",
            "Loss in iteration no. 199744 ==> 0.3071683091129926\n",
            "Loss in iteration no. 199745 ==> 0.3071683090991091\n",
            "Loss in iteration no. 199746 ==> 0.3071683090852274\n",
            "Loss in iteration no. 199747 ==> 0.3071683090713456\n",
            "Loss in iteration no. 199748 ==> 0.30716830905746473\n",
            "Loss in iteration no. 199749 ==> 0.3071683090435848\n",
            "Loss in iteration no. 199750 ==> 0.3071683090297061\n",
            "Loss in iteration no. 199751 ==> 0.3071683090158279\n",
            "Loss in iteration no. 199752 ==> 0.30716830900194997\n",
            "Loss in iteration no. 199753 ==> 0.3071683089880735\n",
            "Loss in iteration no. 199754 ==> 0.30716830897419733\n",
            "Loss in iteration no. 199755 ==> 0.30716830896032155\n",
            "Loss in iteration no. 199756 ==> 0.3071683089464472\n",
            "Loss in iteration no. 199757 ==> 0.30716830893257374\n",
            "Loss in iteration no. 199758 ==> 0.3071683089187001\n",
            "Loss in iteration no. 199759 ==> 0.30716830890482844\n",
            "Loss in iteration no. 199760 ==> 0.3071683088909565\n",
            "Loss in iteration no. 199761 ==> 0.3071683088770854\n",
            "Loss in iteration no. 199762 ==> 0.3071683088632158\n",
            "Loss in iteration no. 199763 ==> 0.30716830884934654\n",
            "Loss in iteration no. 199764 ==> 0.30716830883547813\n",
            "Loss in iteration no. 199765 ==> 0.3071683088216111\n",
            "Loss in iteration no. 199766 ==> 0.3071683088077439\n",
            "Loss in iteration no. 199767 ==> 0.30716830879387713\n",
            "Loss in iteration no. 199768 ==> 0.30716830878001167\n",
            "Loss in iteration no. 199769 ==> 0.3071683087661471\n",
            "Loss in iteration no. 199770 ==> 0.30716830875228346\n",
            "Loss in iteration no. 199771 ==> 0.3071683087384206\n",
            "Loss in iteration no. 199772 ==> 0.3071683087245576\n",
            "Loss in iteration no. 199773 ==> 0.30716830871069645\n",
            "Loss in iteration no. 199774 ==> 0.30716830869683526\n",
            "Loss in iteration no. 199775 ==> 0.30716830868297473\n",
            "Loss in iteration no. 199776 ==> 0.3071683086691158\n",
            "Loss in iteration no. 199777 ==> 0.30716830865525707\n",
            "Loss in iteration no. 199778 ==> 0.3071683086413999\n",
            "Loss in iteration no. 199779 ==> 0.30716830862754185\n",
            "Loss in iteration no. 199780 ==> 0.3071683086136863\n",
            "Loss in iteration no. 199781 ==> 0.30716830859983063\n",
            "Loss in iteration no. 199782 ==> 0.3071683085859751\n",
            "Loss in iteration no. 199783 ==> 0.3071683085721211\n",
            "Loss in iteration no. 199784 ==> 0.30716830855826793\n",
            "Loss in iteration no. 199785 ==> 0.30716830854441557\n",
            "Loss in iteration no. 199786 ==> 0.30716830853056465\n",
            "Loss in iteration no. 199787 ==> 0.307168308516713\n",
            "Loss in iteration no. 199788 ==> 0.30716830850286225\n",
            "Loss in iteration no. 199789 ==> 0.3071683084890133\n",
            "Loss in iteration no. 199790 ==> 0.30716830847516474\n",
            "Loss in iteration no. 199791 ==> 0.30716830846131654\n",
            "Loss in iteration no. 199792 ==> 0.3071683084474697\n",
            "Loss in iteration no. 199793 ==> 0.3071683084336227\n",
            "Loss in iteration no. 199794 ==> 0.3071683084197769\n",
            "Loss in iteration no. 199795 ==> 0.3071683084059316\n",
            "Loss in iteration no. 199796 ==> 0.3071683083920881\n",
            "Loss in iteration no. 199797 ==> 0.30716830837824444\n",
            "Loss in iteration no. 199798 ==> 0.30716830836440173\n",
            "Loss in iteration no. 199799 ==> 0.3071683083505597\n",
            "Loss in iteration no. 199800 ==> 0.30716830833671915\n",
            "Loss in iteration no. 199801 ==> 0.3071683083228778\n",
            "Loss in iteration no. 199802 ==> 0.3071683083090384\n",
            "Loss in iteration no. 199803 ==> 0.3071683082951993\n",
            "Loss in iteration no. 199804 ==> 0.30716830828136155\n",
            "Loss in iteration no. 199805 ==> 0.30716830826752417\n",
            "Loss in iteration no. 199806 ==> 0.3071683082536876\n",
            "Loss in iteration no. 199807 ==> 0.3071683082398514\n",
            "Loss in iteration no. 199808 ==> 0.3071683082260165\n",
            "Loss in iteration no. 199809 ==> 0.30716830821218244\n",
            "Loss in iteration no. 199810 ==> 0.3071683081983481\n",
            "Loss in iteration no. 199811 ==> 0.30716830818451585\n",
            "Loss in iteration no. 199812 ==> 0.30716830817068314\n",
            "Loss in iteration no. 199813 ==> 0.30716830815685203\n",
            "Loss in iteration no. 199814 ==> 0.3071683081430221\n",
            "Loss in iteration no. 199815 ==> 0.3071683081291921\n",
            "Loss in iteration no. 199816 ==> 0.3071683081153634\n",
            "Loss in iteration no. 199817 ==> 0.30716830810153395\n",
            "Loss in iteration no. 199818 ==> 0.3071683080877069\n",
            "Loss in iteration no. 199819 ==> 0.3071683080738807\n",
            "Loss in iteration no. 199820 ==> 0.30716830806005374\n",
            "Loss in iteration no. 199821 ==> 0.30716830804622924\n",
            "Loss in iteration no. 199822 ==> 0.3071683080324044\n",
            "Loss in iteration no. 199823 ==> 0.3071683080185806\n",
            "Loss in iteration no. 199824 ==> 0.3071683080047574\n",
            "Loss in iteration no. 199825 ==> 0.3071683079909352\n",
            "Loss in iteration no. 199826 ==> 0.30716830797711414\n",
            "Loss in iteration no. 199827 ==> 0.3071683079632936\n",
            "Loss in iteration no. 199828 ==> 0.30716830794947275\n",
            "Loss in iteration no. 199829 ==> 0.30716830793565425\n",
            "Loss in iteration no. 199830 ==> 0.3071683079218351\n",
            "Loss in iteration no. 199831 ==> 0.3071683079080183\n",
            "Loss in iteration no. 199832 ==> 0.3071683078942012\n",
            "Loss in iteration no. 199833 ==> 0.307168307880385\n",
            "Loss in iteration no. 199834 ==> 0.3071683078665691\n",
            "Loss in iteration no. 199835 ==> 0.30716830785275456\n",
            "Loss in iteration no. 199836 ==> 0.3071683078389408\n",
            "Loss in iteration no. 199837 ==> 0.30716830782512683\n",
            "Loss in iteration no. 199838 ==> 0.30716830781131527\n",
            "Loss in iteration no. 199839 ==> 0.307168307797504\n",
            "Loss in iteration no. 199840 ==> 0.3071683077836924\n",
            "Loss in iteration no. 199841 ==> 0.3071683077698823\n",
            "Loss in iteration no. 199842 ==> 0.3071683077560734\n",
            "Loss in iteration no. 199843 ==> 0.30716830774226483\n",
            "Loss in iteration no. 199844 ==> 0.3071683077284566\n",
            "Loss in iteration no. 199845 ==> 0.3071683077146497\n",
            "Loss in iteration no. 199846 ==> 0.3071683077008436\n",
            "Loss in iteration no. 199847 ==> 0.30716830768703723\n",
            "Loss in iteration no. 199848 ==> 0.3071683076732327\n",
            "Loss in iteration no. 199849 ==> 0.307168307659429\n",
            "Loss in iteration no. 199850 ==> 0.307168307645625\n",
            "Loss in iteration no. 199851 ==> 0.307168307631823\n",
            "Loss in iteration no. 199852 ==> 0.3071683076180207\n",
            "Loss in iteration no. 199853 ==> 0.30716830760421976\n",
            "Loss in iteration no. 199854 ==> 0.3071683075904191\n",
            "Loss in iteration no. 199855 ==> 0.3071683075766192\n",
            "Loss in iteration no. 199856 ==> 0.3071683075628206\n",
            "Loss in iteration no. 199857 ==> 0.30716830754902286\n",
            "Loss in iteration no. 199858 ==> 0.3071683075352253\n",
            "Loss in iteration no. 199859 ==> 0.3071683075214292\n",
            "Loss in iteration no. 199860 ==> 0.3071683075076328\n",
            "Loss in iteration no. 199861 ==> 0.3071683074938382\n",
            "Loss in iteration no. 199862 ==> 0.30716830748004453\n",
            "Loss in iteration no. 199863 ==> 0.30716830746625057\n",
            "Loss in iteration no. 199864 ==> 0.3071683074524574\n",
            "Loss in iteration no. 199865 ==> 0.30716830743866536\n",
            "Loss in iteration no. 199866 ==> 0.3071683074248749\n",
            "Loss in iteration no. 199867 ==> 0.30716830741108403\n",
            "Loss in iteration no. 199868 ==> 0.30716830739729456\n",
            "Loss in iteration no. 199869 ==> 0.30716830738350537\n",
            "Loss in iteration no. 199870 ==> 0.3071683073697164\n",
            "Loss in iteration no. 199871 ==> 0.30716830735592926\n",
            "Loss in iteration no. 199872 ==> 0.307168307342143\n",
            "Loss in iteration no. 199873 ==> 0.3071683073283574\n",
            "Loss in iteration no. 199874 ==> 0.3071683073145712\n",
            "Loss in iteration no. 199875 ==> 0.30716830730078776\n",
            "Loss in iteration no. 199876 ==> 0.30716830728700356\n",
            "Loss in iteration no. 199877 ==> 0.30716830727322014\n",
            "Loss in iteration no. 199878 ==> 0.3071683072594385\n",
            "Loss in iteration no. 199879 ==> 0.3071683072456567\n",
            "Loss in iteration no. 199880 ==> 0.30716830723187616\n",
            "Loss in iteration no. 199881 ==> 0.3071683072180959\n",
            "Loss in iteration no. 199882 ==> 0.3071683072043169\n",
            "Loss in iteration no. 199883 ==> 0.3071683071905388\n",
            "Loss in iteration no. 199884 ==> 0.3071683071767609\n",
            "Loss in iteration no. 199885 ==> 0.30716830716298427\n",
            "Loss in iteration no. 199886 ==> 0.30716830714920734\n",
            "Loss in iteration no. 199887 ==> 0.3071683071354323\n",
            "Loss in iteration no. 199888 ==> 0.3071683071216581\n",
            "Loss in iteration no. 199889 ==> 0.3071683071078836\n",
            "Loss in iteration no. 199890 ==> 0.30716830709411086\n",
            "Loss in iteration no. 199891 ==> 0.3071683070803383\n",
            "Loss in iteration no. 199892 ==> 0.30716830706656617\n",
            "Loss in iteration no. 199893 ==> 0.30716830705279585\n",
            "Loss in iteration no. 199894 ==> 0.30716830703902565\n",
            "Loss in iteration no. 199895 ==> 0.3071683070252563\n",
            "Loss in iteration no. 199896 ==> 0.30716830701148723\n",
            "Loss in iteration no. 199897 ==> 0.3071683069977194\n",
            "Loss in iteration no. 199898 ==> 0.30716830698395253\n",
            "Loss in iteration no. 199899 ==> 0.3071683069701861\n",
            "Loss in iteration no. 199900 ==> 0.3071683069564207\n",
            "Loss in iteration no. 199901 ==> 0.30716830694265596\n",
            "Loss in iteration no. 199902 ==> 0.307168306928892\n",
            "Loss in iteration no. 199903 ==> 0.3071683069151278\n",
            "Loss in iteration no. 199904 ==> 0.3071683069013654\n",
            "Loss in iteration no. 199905 ==> 0.30716830688760427\n",
            "Loss in iteration no. 199906 ==> 0.3071683068738424\n",
            "Loss in iteration no. 199907 ==> 0.3071683068600828\n",
            "Loss in iteration no. 199908 ==> 0.30716830684632246\n",
            "Loss in iteration no. 199909 ==> 0.30716830683256435\n",
            "Loss in iteration no. 199910 ==> 0.30716830681880597\n",
            "Loss in iteration no. 199911 ==> 0.3071683068050484\n",
            "Loss in iteration no. 199912 ==> 0.3071683067912922\n",
            "Loss in iteration no. 199913 ==> 0.3071683067775361\n",
            "Loss in iteration no. 199914 ==> 0.3071683067637813\n",
            "Loss in iteration no. 199915 ==> 0.3071683067500268\n",
            "Loss in iteration no. 199916 ==> 0.3071683067362731\n",
            "Loss in iteration no. 199917 ==> 0.30716830672252005\n",
            "Loss in iteration no. 199918 ==> 0.3071683067087683\n",
            "Loss in iteration no. 199919 ==> 0.3071683066950168\n",
            "Loss in iteration no. 199920 ==> 0.3071683066812666\n",
            "Loss in iteration no. 199921 ==> 0.3071683066675166\n",
            "Loss in iteration no. 199922 ==> 0.3071683066537679\n",
            "Loss in iteration no. 199923 ==> 0.30716830664002\n",
            "Loss in iteration no. 199924 ==> 0.30716830662627126\n",
            "Loss in iteration no. 199925 ==> 0.30716830661252476\n",
            "Loss in iteration no. 199926 ==> 0.30716830659877903\n",
            "Loss in iteration no. 199927 ==> 0.3071683065850331\n",
            "Loss in iteration no. 199928 ==> 0.30716830657128885\n",
            "Loss in iteration no. 199929 ==> 0.3071683065575459\n",
            "Loss in iteration no. 199930 ==> 0.3071683065438022\n",
            "Loss in iteration no. 199931 ==> 0.3071683065300602\n",
            "Loss in iteration no. 199932 ==> 0.3071683065163186\n",
            "Loss in iteration no. 199933 ==> 0.3071683065025781\n",
            "Loss in iteration no. 199934 ==> 0.3071683064888378\n",
            "Loss in iteration no. 199935 ==> 0.3071683064750984\n",
            "Loss in iteration no. 199936 ==> 0.3071683064613602\n",
            "Loss in iteration no. 199937 ==> 0.3071683064476222\n",
            "Loss in iteration no. 199938 ==> 0.3071683064338849\n",
            "Loss in iteration no. 199939 ==> 0.3071683064201484\n",
            "Loss in iteration no. 199940 ==> 0.3071683064064137\n",
            "Loss in iteration no. 199941 ==> 0.30716830639267867\n",
            "Loss in iteration no. 199942 ==> 0.3071683063789449\n",
            "Loss in iteration no. 199943 ==> 0.3071683063652113\n",
            "Loss in iteration no. 199944 ==> 0.30716830635147846\n",
            "Loss in iteration no. 199945 ==> 0.307168306337747\n",
            "Loss in iteration no. 199946 ==> 0.3071683063240156\n",
            "Loss in iteration no. 199947 ==> 0.3071683063102856\n",
            "Loss in iteration no. 199948 ==> 0.3071683062965563\n",
            "Loss in iteration no. 199949 ==> 0.30716830628282704\n",
            "Loss in iteration no. 199950 ==> 0.3071683062690992\n",
            "Loss in iteration no. 199951 ==> 0.30716830625537206\n",
            "Loss in iteration no. 199952 ==> 0.3071683062416456\n",
            "Loss in iteration no. 199953 ==> 0.30716830622791996\n",
            "Loss in iteration no. 199954 ==> 0.307168306214195\n",
            "Loss in iteration no. 199955 ==> 0.30716830620047125\n",
            "Loss in iteration no. 199956 ==> 0.3071683061867478\n",
            "Loss in iteration no. 199957 ==> 0.3071683061730251\n",
            "Loss in iteration no. 199958 ==> 0.30716830615930346\n",
            "Loss in iteration no. 199959 ==> 0.30716830614558116\n",
            "Loss in iteration no. 199960 ==> 0.30716830613186114\n",
            "Loss in iteration no. 199961 ==> 0.3071683061181417\n",
            "Loss in iteration no. 199962 ==> 0.3071683061044226\n",
            "Loss in iteration no. 199963 ==> 0.3071683060907037\n",
            "Loss in iteration no. 199964 ==> 0.3071683060769866\n",
            "Loss in iteration no. 199965 ==> 0.30716830606327006\n",
            "Loss in iteration no. 199966 ==> 0.30716830604955436\n",
            "Loss in iteration no. 199967 ==> 0.30716830603583833\n",
            "Loss in iteration no. 199968 ==> 0.3071683060221246\n",
            "Loss in iteration no. 199969 ==> 0.307168306008411\n",
            "Loss in iteration no. 199970 ==> 0.30716830599469713\n",
            "Loss in iteration no. 199971 ==> 0.30716830598098555\n",
            "Loss in iteration no. 199972 ==> 0.3071683059672741\n",
            "Loss in iteration no. 199973 ==> 0.307168305953563\n",
            "Loss in iteration no. 199974 ==> 0.30716830593985345\n",
            "Loss in iteration no. 199975 ==> 0.3071683059261447\n",
            "Loss in iteration no. 199976 ==> 0.30716830591243516\n",
            "Loss in iteration no. 199977 ==> 0.3071683058987279\n",
            "Loss in iteration no. 199978 ==> 0.30716830588502125\n",
            "Loss in iteration no. 199979 ==> 0.3071683058713144\n",
            "Loss in iteration no. 199980 ==> 0.3071683058576096\n",
            "Loss in iteration no. 199981 ==> 0.3071683058439052\n",
            "Loss in iteration no. 199982 ==> 0.30716830583020044\n",
            "Loss in iteration no. 199983 ==> 0.3071683058164979\n",
            "Loss in iteration no. 199984 ==> 0.3071683058027946\n",
            "Loss in iteration no. 199985 ==> 0.30716830578909343\n",
            "Loss in iteration no. 199986 ==> 0.3071683057753925\n",
            "Loss in iteration no. 199987 ==> 0.3071683057616918\n",
            "Loss in iteration no. 199988 ==> 0.30716830574799275\n",
            "Loss in iteration no. 199989 ==> 0.3071683057342945\n",
            "Loss in iteration no. 199990 ==> 0.3071683057205954\n",
            "Loss in iteration no. 199991 ==> 0.3071683057068984\n",
            "Loss in iteration no. 199992 ==> 0.30716830569320275\n",
            "Loss in iteration no. 199993 ==> 0.30716830567950626\n",
            "Loss in iteration no. 199994 ==> 0.30716830566581155\n",
            "Loss in iteration no. 199995 ==> 0.30716830565211745\n",
            "Loss in iteration no. 199996 ==> 0.30716830563842357\n",
            "Loss in iteration no. 199997 ==> 0.3071683056247309\n",
            "Loss in iteration no. 199998 ==> 0.3071683056110394\n",
            "Loss in iteration no. 199999 ==> 0.3071683055973481\n",
            "Loss in iteration no. 200000 ==> 0.30716830558365704\n"
          ]
        }
      ],
      "source": [
        "for i,loss in enumerate(model.model_loss):\n",
        "  print(f\"Loss in iteration no. {i+1} ==> {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjhEDqQArtEd"
      },
      "outputs": [],
      "source": [
        "# Saving the values of the weights for the highest accuracy obtained\n",
        "\n",
        "with open(\"soubhiks_imotapar_assignment1_part_2.pkl\", \"wb\") as f:\n",
        "  pickle.dump(model.weights.tolist(), f)\n",
        "  !cp soubhiks_imotapar_assignment1_part_2.pkl \"drive/My Drive/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnjXV1tGsKsu",
        "outputId": "6ac5074a-ece4-4320-a8fc-f5aa6ea405c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-11.123115440795031,\n",
              " -3.0307682591837106,\n",
              " 0.027828069248468246,\n",
              " 6.1099154025473075,\n",
              " 7.344389514658723,\n",
              " 2.888345818012927,\n",
              " 15.352090619246486]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Checking whether the weights saved can be loaded and seen again\n",
        "\n",
        "with open(\"soubhiks_imotapar_assignment1_part_2.pkl\", \"rb\") as f:\n",
        "  weights_loaded = pickle.load(f)\n",
        "\n",
        "weights_loaded"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
